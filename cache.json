{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-25T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Identifying Risk Patterns in Brazilian Police Reports Preceding Femicides: A Long Short Term Memory (LSTM) Based Analysis. (arXiv:2401.12980v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12980","description":"<p>Femicide refers to the killing of a female victim, often perpetrated by an\nintimate partner or family member, and is also associated with gender-based\nviolence. Studies have shown that there is a pattern of escalating violence\nleading up to these killings, highlighting the potential for prevention if the\nlevel of danger to the victim can be assessed. Machine learning offers a\npromising approach to address this challenge by predicting risk levels based on\ntextual descriptions of the violence. In this study, we employed the Long Short\nTerm Memory (LSTM) technique to identify patterns of behavior in Brazilian\npolice reports preceding femicides. Our first objective was to classify the\ncontent of these reports as indicating either a lower or higher risk of the\nvictim being murdered, achieving an accuracy of 66%. In the second approach, we\ndeveloped a model to predict the next action a victim might experience within a\nsequence of patterned events. Both approaches contribute to the understanding\nand assessment of the risks associated with domestic violence, providing\nauthorities with valuable insights to protect women and prevent situations from\nescalating.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lima_V/0/1/0/all/0/1\">Vinicius Lima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_J/0/1/0/all/0/1\">Jaque Almeida de Oliveira</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A General-purpose AI Avatar in Healthcare. (arXiv:2401.12981v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12981","description":"<p>Recent advancements in machine learning and natural language processing have\nled to the rapid development of artificial intelligence (AI) as a valuable tool\nin the healthcare industry. Using large language models (LLMs) as\nconversational agents or chatbots has the potential to assist doctors in\ndiagnosing patients, detecting early symptoms of diseases, and providing health\nadvice to patients. This paper focuses on the role of chatbots in healthcare\nand explores the use of avatars to make AI interactions more appealing to\npatients. A framework of a general-purpose AI avatar application is\ndemonstrated by using a three-category prompt dictionary and prompt improvement\nmechanism. A two-phase approach is suggested to fine-tune a general-purpose AI\nlanguage model and create different AI avatars to discuss medical issues with\nusers. Prompt engineering enhances the chatbot's conversational abilities and\npersonality traits, fostering a more human-like interaction with patients.\nUltimately, the injection of personality into the chatbot could potentially\nincrease patient engagement. Future directions for research include\ninvestigating ways to improve chatbots' understanding of context and ensuring\nthe accuracy of their outputs through fine-tuning with specialized medical data\nsets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_N/0/1/0/all/0/1\">Nicholas Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alterovitz_G/0/1/0/all/0/1\">Gil Alterovitz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Classification: A Review, Empirical, and Experimental Evaluation. (arXiv:2401.12982v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12982","description":"<p>The explosive and widespread growth of data necessitates the use of text\nclassification to extract crucial information from vast amounts of data.\nConsequently, there has been a surge of research in both classical and deep\nlearning text classification methods. Despite the numerous methods proposed in\nthe literature, there is still a pressing need for a comprehensive and\nup-to-date survey. Existing survey papers categorize algorithms for text\nclassification into broad classes, which can lead to the misclassification of\nunrelated algorithms and incorrect assessments of their qualities and behaviors\nusing the same metrics. To address these limitations, our paper introduces a\nnovel methodological taxonomy that classifies algorithms hierarchically into\nfine-grained classes and specific techniques. The taxonomy includes methodology\ncategories, methodology techniques, and methodology sub-techniques. Our study\nis the first survey to utilize this methodological taxonomy for classifying\nalgorithms for text classification. Furthermore, our study also conducts\nempirical evaluation and experimental comparisons and rankings of different\nalgorithms that employ the same specific sub-technique, different\nsub-techniques within the same technique, different techniques within the same\ncategory, and categories\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Taha_K/0/1/0/all/0/1\">Kamal Taha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_P/0/1/0/all/0/1\">Paul D. Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeun_C/0/1/0/all/0/1\">Chan Yeun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taha_A/0/1/0/all/0/1\">Aya Taha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding. (arXiv:2401.12983v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12983","description":"<p>This study is a pioneering endeavor to investigate the capabilities of Large\nLanguage Models (LLMs) in addressing conceptual questions within the domain of\nmechanical engineering with a focus on mechanics. Our examination involves a\nmanually crafted exam encompassing 126 multiple-choice questions, spanning\nvarious aspects of mechanics courses, including Fluid Mechanics, Mechanical\nVibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of\nElasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5),\nChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against\nengineering faculties and students with or without mechanical engineering\nbackground. The findings reveal GPT-4's superior performance over the other two\nLLMs and human cohorts in answering questions across various mechanics topics,\nexcept for Continuum Mechanics. This signals the potential future improvements\nfor GPT models in handling symbolic calculations and tensor analyses. The\nperformances of LLMs were all significantly improved with explanations prompted\nprior to direct responses, underscoring the crucial role of prompt engineering.\nInterestingly, GPT-3.5 demonstrates improved performance with prompts covering\na broader domain, while GPT-4 excels with prompts focusing on specific\nsubjects. Finally, GPT-4 exhibits notable advancements in mitigating input\nbias, as evidenced by guessing preferences for humans. This study unveils the\nsubstantial potential of LLMs as highly knowledgeable assistants in both\nmechanical pedagogy and scientific research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Jie Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">Jixin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_P/0/1/0/all/0/1\">Peng Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1\">Yujie Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1\">Beikang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filla_N/0/1/0/all/0/1\">Nicholas Filla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xianyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Keke Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xianqiao Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Effect of Human v/s Synthetic Test Data and Round-tripping on Assessment of Sentiment Analysis Systems for Bias. (arXiv:2401.12985v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12985","description":"<p>Sentiment Analysis Systems (SASs) are data-driven Artificial Intelligence\n(AI) systems that output polarity and emotional intensity when given a piece of\ntext as input. Like other AIs, SASs are also known to have unstable behavior\nwhen subjected to changes in data which can make it problematic to trust out of\nconcerns like bias when AI works with humans and data has protected attributes\nlike gender, race, and age. Recently, an approach was introduced to assess SASs\nin a blackbox setting without training data or code, and rating them for bias\nusing synthetic English data. We augment it by introducing two human-generated\nchatbot datasets and also consider a round-trip setting of translating the data\nfrom one language to the same through an intermediate language. We find that\nthese settings show SASs performance in a more realistic light. Specifically,\nwe find that rating SASs on the chatbot data showed more bias compared to the\nsynthetic data, and round-tripping using Spanish and Danish as intermediate\nlanguages reduces the bias (up to 68% reduction) in human-generated data while,\nin synthetic data, it takes a surprising turn by increasing the bias! Our\nfindings will help researchers and practitioners refine their SAS testing\nstrategies and foster trust as SASs are considered part of more\nmission-critical applications for global use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_K/0/1/0/all/0/1\">Kausik Lakkaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Aniket Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1\">Biplav Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valtorta_M/0/1/0/all/0/1\">Marco Valtorta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Dezhi Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Crowdsourced Adaptive Surveys. (arXiv:2401.12986v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12986","description":"<p>Public opinion surveys are vital for informing democratic decision-making,\nbut responding to rapidly changing information environments and measuring\nbeliefs within niche communities can be challenging for traditional survey\nmethods. This paper introduces a crowdsourced adaptive survey methodology\n(CSAS) that unites advances in natural language processing and adaptive\nalgorithms to generate question banks that evolve with user input. The CSAS\nmethod converts open-ended text provided by participants into Likert-style\nitems and applies a multi-armed bandit algorithm to determine user-provided\nquestions that should be prioritized in the survey. The method's adaptive\nnature allows for the exploration of new survey questions, while imposing\nminimal costs in survey length. Applications in the domains of Latino\ninformation environments and issue importance showcase CSAS's ability to\nidentify claims or issues that might otherwise be difficult to track using\nstandard approaches. I conclude by discussing the method's potential for\nstudying topics where participant-generated content might improve our\nunderstanding of public opinion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Velez_Y/0/1/0/all/0/1\">Yamil Velez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition in Conversation. (arXiv:2401.12987v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12987","description":"<p>Emotion Recognition in Conversation (ERC) plays a crucial role in enabling\ndialogue systems to effectively respond to user requests. The emotions in a\nconversation can be identified by the representations from various modalities,\nsuch as audio, visual, and text. However, due to the weak contribution of\nnon-verbal modalities to recognize emotions, multimodal ERC has always been\nconsidered a challenging task. In this paper, we propose Teacher-leading\nMultimodal fusion network for ERC (TelME). TelME incorporates cross-modal\nknowledge distillation to transfer information from a language model acting as\nthe teacher to the non-verbal students, thereby optimizing the efficacy of the\nweak modalities. We then combine multimodal features using a shifting fusion\napproach in which student networks support the teacher. TelME achieves\nstate-of-the-art performance in MELD, a multi-speaker conversation dataset for\nERC. Finally, we demonstrate the effectiveness of our components through\nadditional experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Taeyang Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1\">Hyunkuk Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jeonghwan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Min Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Learning for Chronic Disease Management: Leveraging Large Language Models and Multi-Prompt Engineering with Medical Knowledge Injection. (arXiv:2401.12988v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12988","description":"<p>This study harnesses state-of-the-art AI technology for chronic disease\nmanagement, specifically in detecting various mental disorders through\nuser-generated textual content. Existing studies typically rely on fully\nsupervised machine learning, which presents challenges such as the\nlabor-intensive manual process of annotating extensive training data for each\ndisease and the need to design specialized deep learning architectures for each\nproblem. To address such challenges, we propose a novel framework that\nleverages advanced AI techniques, including large language models and\nmulti-prompt engineering. Specifically, we address two key technical challenges\nin data-driven chronic disease management: (1) developing personalized prompts\nto represent each user's uniqueness and (2) incorporating medical knowledge\ninto prompts to provide context for chronic disease detection, instruct\nlearning objectives, and operationalize prediction goals. We evaluate our\nmethod using four mental disorders, which are prevalent chronic diseases\nworldwide, as research cases. On the depression detection task, our method (F1\n= 0.975~0.978) significantly outperforms traditional supervised learning\nparadigms, including feature engineering (F1 = 0.760) and architecture\nengineering (F1 = 0.756). Meanwhile, our approach demonstrates success in\nfew-shot learning, i.e., requiring only a minimal number of training examples\nto detect chronic diseases based on user-generated textual content (i.e., only\n2, 10, or 100 subjects). Moreover, our method can be generalized to other\nmental disorder detection tasks, including anorexia, pathological gambling, and\nself-harm (F1 = 0.919~0.978).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haoxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jiaheng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Buomsoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1\">Yidong Chai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Into the crossfire: evaluating the use of a language model to crowdsource gun violence reports. (arXiv:2401.12989v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12989","description":"<p>Gun violence is a pressing and growing human rights issue that affects nearly\nevery dimension of the social fabric, from healthcare and education to\npsychology and the economy. Reliable data on firearm events is paramount to\ndeveloping more effective public policy and emergency responses. However, the\nlack of comprehensive databases and the risks of in-person surveys prevent\nhuman rights organizations from collecting needed data in most countries. Here,\nwe partner with a Brazilian human rights organization to conduct a systematic\nevaluation of language models to assist with monitoring real-world firearm\nevents from social media data. We propose a fine-tuned BERT-based model trained\non Twitter (now X) texts to distinguish gun violence reports from ordinary\nPortuguese texts. Our model achieves a high AUC score of 0.97. We then\nincorporate our model into a web application and test it in a live\nintervention. We study and interview Brazilian analysts who continuously\nfact-check social media texts to identify new gun violence events. Qualitative\nassessments show that our solution helped all analysts use their time more\nefficiently and expanded their search capacities. Quantitative assessments show\nthat the use of our model was associated with more analysts' interactions with\nonline users reporting gun violence. Taken together, our findings suggest that\nmodern Natural Language Processing techniques can help support the work of\nhuman rights organizations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belisario_A/0/1/0/all/0/1\">Adriano Belisario</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott Hale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocher_L/0/1/0/all/0/1\">Luc Rocher</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic Modelling: Going Beyond Token Outputs. (arXiv:2401.12990v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12990","description":"<p>Topic modelling is a text mining technique for identifying salient themes\nfrom a number of documents. The output is commonly a set of topics consisting\nof isolated tokens that often co-occur in such documents. Manual effort is\noften associated with interpreting a topic's description from such tokens.\nHowever, from a human's perspective, such outputs may not adequately provide\nenough information to infer the meaning of the topics; thus, their\ninterpretability is often inaccurately understood. Although several studies\nhave attempted to automatically extend topic descriptions as a means of\nenhancing the interpretation of topic models, they rely on external language\nsources that may become unavailable, must be kept up-to-date to generate\nrelevant results, and present privacy issues when training on or processing\ndata. This paper presents a novel approach towards extending the output of\ntraditional topic modelling methods beyond a list of isolated tokens. This\napproach removes the dependence on external sources by using the textual data\nitself by extracting high-scoring keywords and mapping them to the topic\nmodel's token outputs. To measure the interpretability of the proposed outputs\nagainst those of the traditional topic modelling approach, independent\nannotators manually scored each output based on their quality and usefulness,\nas well as the efficiency of the annotation task. The proposed approach\ndemonstrated higher quality and usefulness, as well as higher efficiency in the\nannotation task, in comparison to the outputs of a traditional topic modelling\nmethod, demonstrating an increase in their interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1\">Lowri Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anthi_E/0/1/0/all/0/1\">Eirini Anthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arman_L/0/1/0/all/0/1\">Laura Arman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnap_P/0/1/0/all/0/1\">Pete Burnap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TranSentence: Speech-to-speech Translation via Language-agnostic Sentence-level Speech Encoding without Language-parallel Data. (arXiv:2401.12992v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12992","description":"<p>Although there has been significant advancement in the field of\nspeech-to-speech translation, conventional models still require\nlanguage-parallel speech data between the source and target languages for\ntraining. In this paper, we introduce TranSentence, a novel speech-to-speech\ntranslation without language-parallel speech data. To achieve this, we first\nadopt a language-agnostic sentence-level speech encoding that captures the\nsemantic information of speech, irrespective of language. We then train our\nmodel to generate speech based on the encoded embedding obtained from a\nlanguage-agnostic sentence-level speech encoder that is pre-trained with\nvarious languages. With this method, despite training exclusively on the target\nlanguage's monolingual data, we can generate target language speech in the\ninference stage using language-agnostic speech embedding from the source\nlanguage speech. Furthermore, we extend TranSentence to multilingual\nspeech-to-speech translation. The experimental results demonstrate that\nTranSentence is superior to other models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seung-Bin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Hoon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seong-Whan Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Estimating the severity of dental and oral problems via sentiment classification over clinical reports. (arXiv:2401.12993v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12993","description":"<p>Analyzing authors' sentiments in texts as a technique for identifying text\npolarity can be practical and useful in various fields, including medicine and\ndentistry. Currently, due to factors such as patients' limited knowledge about\ntheir condition, difficulties in accessing specialist doctors, or fear of\nillness, particularly in pandemic conditions, there might be a delay between\nreceiving a radiology report and consulting a doctor. In some cases, this delay\ncan pose significant risks to the patient, making timely decision-making\ncrucial. Having an automatic system that can inform patients about the\ndeterioration of their condition by analyzing the text of radiology reports\ncould greatly impact timely decision-making. In this study, a dataset\ncomprising 1,134 cone-beam computed tomography (CBCT) photo reports was\ncollected from the Shiraz University of Medical Sciences. Each case was\nexamined, and an expert labeled a severity level for the patient's condition on\neach document. After preprocessing all the text data, a deep learning model\nbased on Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM)\nnetwork architecture, known as CNN-LSTM, was developed to detect the severity\nlevel of the patient's problem based on sentiment analysis in the radiologist's\nreport. The model's performance was evaluated on two datasets, each with two\nand four classes, in both imbalanced and balanced scenarios. Finally, to\ndemonstrate the effectiveness of our model, we compared its performance with\nthat of other classification models. The results, along with one-way ANOVA and\nTukey's test, indicated that our proposed model (CNN-LSTM) performed the best\naccording to precision, recall, and f-measure criteria. This suggests that it\ncan be a reliable model for estimating the severity of oral and dental\ndiseases, thereby assisting patients.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mahdavifar_S/0/1/0/all/0/1\">Sare Mahdavifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhrahmad_S/0/1/0/all/0/1\">Seyed Mostafa Fakhrahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ansarifard_E/0/1/0/all/0/1\">Elham Ansarifard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Scoring of Clinical Patient Notes using Advanced NLP and Pseudo Labeling. (arXiv:2401.12994v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12994","description":"<p>Clinical patient notes are critical for documenting patient interactions,\ndiagnoses, and treatment plans in medical practice. Ensuring accurate\nevaluation of these notes is essential for medical education and certification.\nHowever, manual evaluation is complex and time-consuming, often resulting in\nvariability and resource-intensive assessments. To tackle these challenges,\nthis research introduces an approach leveraging state-of-the-art Natural\nLanguage Processing (NLP) techniques, specifically Masked Language Modeling\n(MLM) pretraining, and pseudo labeling. Our methodology enhances efficiency and\neffectiveness, significantly reducing training time without compromising\nperformance. Experimental results showcase improved model performance,\nindicating a potential transformation in clinical note assessment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1\">Bin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shulin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_T/0/1/0/all/0/1\">Tianbo Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues. (arXiv:2401.12995v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12995","description":"<p>Code-mixing, the blending of multiple languages within a single conversation,\nintroduces a distinctive challenge, particularly in the context of response\ngeneration. Capturing the intricacies of code-mixing proves to be a formidable\ntask, given the wide-ranging variations influenced by individual speaking\nstyles and cultural backgrounds. In this study, we explore response generation\nwithin code-mixed conversations. We introduce a novel approach centered on\nharnessing the Big Five personality traits acquired in an unsupervised manner\nfrom the conversations to bolster the performance of response generation. These\ninferred personality attributes are seamlessly woven into the fabric of the\ndialogue context, using a novel fusion mechanism, PA3. It uses an effective\ntwo-step attention formulation to fuse the dialogue and personality\ninformation. This fusion not only enhances the contextual relevance of\ngenerated responses but also elevates the overall performance of the model. Our\nexperimental results, grounded in a dataset comprising of multi-party\nHindi-English code-mix conversations, highlight the substantial advantages\noffered by personality-infused models over their conventional counterparts.\nThis is evident in the increase observed in ROUGE and BLUE scores for the\nresponse generation task when the identified personality is seamlessly\nintegrated into the dialogue context. Qualitative assessment for personality\nidentification and response generation aligns well with our quantitative\nresults.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shivani Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparison of Veterans with Problematic Opioid Use Identified through Natural Language Processing of Clinical Notes versus Using Diagnostic Codes. (arXiv:2401.12996v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12996","description":"<p>Background: Electronic health records (EHRs) are a data source for opioid\nresearch. Opioid use disorder is known to be under-coded as a diagnosis, yet\nproblematic opioid use can be documented in clinical notes.\n</p>\n<p>Objectives: Our goals were 1) to identify problematic opioid use from a full\nrange of clinical notes; and 2) to compare the characteristics of patients\nidentified as having problematic opioid use, exclusively documented in clinical\nnotes, to those having documented ICD opioid use disorder diagnostic codes.\n</p>\n<p>Materials and Methods: We developed and applied a natural language processing\n(NLP) tool to the clinical notes of a patient cohort (n=222,371) from two\nVeteran Affairs service regions to identify patients with problematic opioid\nuse. We also used a set of ICD diagnostic codes to identify patients with\nopioid use disorder from the same cohort. We compared the demographic and\nclinical characteristics of patients identified only through NLP, to those of\npatients identified through ICD codes.\n</p>\n<p>Results: NLP exclusively identified 57,331 patients; 6,997 patients had\npositive ICD code identifications. Patients exclusively identified through NLP\nwere more likely to be women. Those identified through ICD codes were more\nlikely to be male, younger, have concurrent benzodiazepine prescriptions, more\ncomorbidities, more care encounters, and less likely to be married. Patients in\nthe NLP and ICD groups had substantially elevated comorbidity levels compared\nto patients not documented as experiencing problematic opioid use.\n</p>\n<p>Conclusions: NLP is a feasible approach for identifying problematic opioid\nuse not otherwise recorded by ICD codes. Clinicians may be reluctant to code\nfor opioid use disorder. It is therefore incumbent on the healthcare team to\nsearch for documentation of opioid concerns within clinical notes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Workman_T/0/1/0/all/0/1\">Terri Elizabeth Workman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kupersmith_J/0/1/0/all/0/1\">Joel Kupersmith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1\">Phillip Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spevak_C/0/1/0/all/0/1\">Christopher Spevak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandbrink_F/0/1/0/all/0/1\">Friedhelm Sandbrink</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Treitler_Y/0/1/0/all/0/1\">Yan Cheng Qing Zeng-Treitler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressive Distillation Based on Masked Generation Feature Method for Knowledge Graph Completion. (arXiv:2401.12997v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12997","description":"<p>In recent years, knowledge graph completion (KGC) models based on pre-trained\nlanguage model (PLM) have shown promising results. However, the large number of\nparameters and high computational cost of PLM models pose challenges for their\napplication in downstream tasks. This paper proposes a progressive distillation\nmethod based on masked generation features for KGC task, aiming to\nsignificantly reduce the complexity of pre-trained models. Specifically, we\nperform pre-distillation on PLM to obtain high-quality teacher models, and\ncompress the PLM network to obtain multi-grade student models. However,\ntraditional feature distillation suffers from the limitation of having a single\nrepresentation of information in teacher models. To solve this problem, we\npropose masked generation of teacher-student features, which contain richer\nrepresentation information. Furthermore, there is a significant gap in\nrepresentation ability between teacher and student. Therefore, we design a\nprogressive distillation method to distill student models at each grade level,\nenabling efficient knowledge transfer from teachers to students. The\nexperimental results demonstrate that the model in the pre-distillation stage\nsurpasses the existing state-of-the-art methods. Furthermore, in the\nprogressive distillation stage, the model significantly reduces the model\nparameters while maintaining a certain level of performance. Specifically, the\nmodel parameters of the lower-grade student model are reduced by 56.7\\%\ncompared to the baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Cunhang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yujie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jun Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1\">Yonghui Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Z/0/1/0/all/0/1\">Zhao Lv</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating and Enhancing Large Language Models Performance in Domain-specific Medicine: Osteoarthritis Management with DocOA. (arXiv:2401.12998v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12998","description":"<p>The efficacy of large language models (LLMs) in domain-specific medicine,\nparticularly for managing complex diseases such as osteoarthritis (OA), remains\nlargely unexplored. This study focused on evaluating and enhancing the clinical\ncapabilities of LLMs in specific domains, using osteoarthritis (OA) management\nas a case study. A domain specific benchmark framework was developed, which\nevaluate LLMs across a spectrum from domain-specific knowledge to clinical\napplications in real-world clinical scenarios. DocOA, a specialized LLM\ntailored for OA management that integrates retrieval-augmented generation (RAG)\nand instruction prompts, was developed. The study compared the performance of\nGPT-3.5, GPT-4, and a specialized assistant, DocOA, using objective and human\nevaluations. Results showed that general LLMs like GPT-3.5 and GPT-4 were less\neffective in the specialized domain of OA management, particularly in providing\npersonalized treatment recommendations. However, DocOA showed significant\nimprovements. This study introduces a novel benchmark framework which assesses\nthe domain-specific abilities of LLMs in multiple aspects, highlights the\nlimitations of generalized LLMs in clinical contexts, and demonstrates the\npotential of tailored approaches for developing domain-specific medical LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_M/0/1/0/all/0/1\">MingKe You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Li Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">WeiZhi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaoting Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TCE at Qur'an QA 2023 Shared Task: Low Resource Enhanced Transformer-based Ensemble Approach for Qur'anic QA. (arXiv:2401.13060v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13060","description":"<p>In this paper, we present our approach to tackle Qur'an QA 2023 shared tasks\nA and B. To address the challenge of low-resourced training data, we rely on\ntransfer learning together with a voting ensemble to improve prediction\nstability across multiple runs. Additionally, we employ different architectures\nand learning mechanisms for a range of Arabic pre-trained transformer-based\nmodels for both tasks. To identify unanswerable questions, we propose using a\nthresholding mechanism. Our top-performing systems greatly surpass the baseline\nperformance on the hidden split, achieving a MAP score of 25.05% for task A and\na partial Average Precision (pAP) of 57.11% for task B.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elkomy_M/0/1/0/all/0/1\">Mohammed Alaa Elkomy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarhan_A/0/1/0/all/0/1\">Amany Sarhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IndiText Boost: Text Augmentation for Low Resource India Languages. (arXiv:2401.13085v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13085","description":"<p>Text Augmentation is an important task for low-resource languages. It helps\ndeal with the problem of data scarcity. A data augmentation strategy is used to\ndeal with the problem of data scarcity. Through the years, much work has been\ndone on data augmentation for the English language. In contrast, very less work\nhas been done on Indian languages. This is contrary to the fact that data\naugmentation is used to deal with data scarcity. In this work, we focus on\nimplementing techniques like Easy Data Augmentation, Back Translation,\nParaphrasing, Text Generation using LLMs, and Text Expansion using LLMs for\ntext classification on different languages. We focus on 6 Indian languages\nnamely: Sindhi, Marathi, Hindi, Gujarati, Telugu, and Sanskrit. According to\nour knowledge, no such work exists for text augmentation on Indian languages.\nWe carry out binary as well as multi-class text classification to make our\nresults more comparable. We get surprising results as basic data augmentation\ntechniques surpass LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Litake_O/0/1/0/all/0/1\">Onkar Litake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yagnik_N/0/1/0/all/0/1\">Niraj Yagnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labhsetwar_S/0/1/0/all/0/1\">Shreyas Labhsetwar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Trustable Language Models: Investigating Information Quality of Large Language Models. (arXiv:2401.13086v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13086","description":"<p>Large language models (LLM) are generating information at a rapid pace,\nrequiring users to increasingly rely and trust the data. Despite remarkable\nadvances of LLM, Information generated by LLM is not completely trustworthy,\ndue to challenges in information quality. Specifically, integrity of\nInformation quality decreases due to unreliable, biased, tokenization during\npre-training of LLM. Moreover, due to decreased information quality issues, has\nled towards hallucination, fabricated information. Unreliable information can\nlead towards flawed decisions in businesses, which impacts economic activity.\nIn this work, we introduce novel mathematical information quality evaluation of\nLLM, we furthermore analyze and highlight information quality challenges,\nscaling laws to systematically scale language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rejeleene_R/0/1/0/all/0/1\">Rick Rejeleene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaowei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talburt_J/0/1/0/all/0/1\">John Talburt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Seed-Guided Fine-Grained Entity Typing in Science and Engineering Domains. (arXiv:2401.13129v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13129","description":"<p>Accurately typing entity mentions from text segments is a fundamental task\nfor various natural language processing applications. Many previous approaches\nrely on massive human-annotated data to perform entity typing. Nevertheless,\ncollecting such data in highly specialized science and engineering domains\n(e.g., software engineering and security) can be time-consuming and costly,\nwithout mentioning the domain gaps between training and inference data if the\nmodel needs to be applied to confidential datasets. In this paper, we study the\ntask of seed-guided fine-grained entity typing in science and engineering\ndomains, which takes the name and a few seed entities for each entity type as\nthe only supervision and aims to classify new entity mentions into both seen\nand unseen types (i.e., those without seed entities). To solve this problem, we\npropose SEType which first enriches the weak supervision by finding more\nentities for each seen type from an unlabeled corpus using the contextualized\nrepresentations of pre-trained language models. It then matches the enriched\nentities to unlabeled text to get pseudo-labeled samples and trains a textual\nentailment model that can make inferences for both seen and unseen types.\nExtensive experiments on two datasets covering four domains demonstrate the\neffectiveness of SEType in comparison with various baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanzhen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yu Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1\">Lucian Popa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_L/0/1/0/all/0/1\">Larisa Shwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace: Insights from a Manually Annotated Twitter Dataset. (arXiv:2401.13133v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13133","description":"<p>Numerous successes have been achieved in combating the COVID-19 pandemic,\ninitially using various precautionary measures like lockdowns, social\ndistancing, and the use of face masks. More recently, various vaccinations have\nbeen developed to aid in the prevention or reduction of the severity of the\nCOVID-19 infection. Despite the effectiveness of the precautionary measures and\nthe vaccines, there are several controversies that are massively shared on\nsocial media platforms like Twitter. In this paper, we explore the use of\nstate-of-the-art transformer-based language models to study people's acceptance\nof vaccines in Nigeria. We developed a novel dataset by crawling multi-lingual\ntweets using relevant hashtags and keywords. Our analysis and visualizations\nrevealed that most tweets expressed neutral sentiments about COVID-19 vaccines,\nwith some individuals expressing positive views, and there was no strong\npreference for specific vaccine types, although Moderna received slightly more\npositive sentiment. We also found out that fine-tuning a pre-trained LLM with\nan appropriate dataset can yield competitive results, even if the LLM was not\ninitially pre-trained on the specific language of that dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ibrahim Said Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aliyu_L/0/1/0/all/0/1\">Lukman Jibril Aliyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalid_A/0/1/0/all/0/1\">Abubakar Auwal Khalid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aliyu_S/0/1/0/all/0/1\">Saminu Muhammad Aliyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shamsuddeen Hassan Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulmumin_I/0/1/0/all/0/1\">Idris Abdulmumin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abduljalil_B/0/1/0/all/0/1\">Bala Mairiga Abduljalil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_B/0/1/0/all/0/1\">Bello Shehu Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abubakar_A/0/1/0/all/0/1\">Amina Imam Abubakar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts. (arXiv:2401.13136v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13136","description":"<p>As the influence of large language models (LLMs) spans across global\ncommunities, their safety challenges in multilingual settings become paramount\nfor alignment research. This paper examines the variations in safety challenges\nfaced by LLMs across different languages and discusses approaches to\nalleviating such concerns. By comparing how state-of-the-art LLMs respond to\nthe same set of malicious prompts written in higher- vs. lower-resource\nlanguages, we observe that (1) LLMs tend to generate unsafe responses much more\noften when a malicious prompt is written in a lower-resource language, and (2)\nLLMs tend to generate more irrelevant responses to malicious prompts in\nlower-resource languages. To understand where the discrepancy can be\nattributed, we study the effect of instruction tuning with reinforcement\nlearning from human feedback (RLHF) or supervised finetuning (SFT) on the\nHH-RLHF dataset. Surprisingly, while training with high-resource languages\nimproves model alignment, training in lower-resource languages yields minimal\nimprovement. This suggests that the bottleneck of cross-lingual alignment is\nrooted in the pretraining stage. Our findings highlight the challenges in\ncross-lingual LLM safety, and we hope they inform future research in this\ndirection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weiting Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Boyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Locality enhanced dynamic biasing and sampling strategies for contextual ASR. (arXiv:2401.13146v1 [eess.AS])","link":"http://arxiv.org/abs/2401.13146","description":"<p>Automatic Speech Recognition (ASR) still face challenges when recognizing\ntime-variant rare-phrases. Contextual biasing (CB) modules bias ASR model\ntowards such contextually-relevant phrases. During training, a list of biasing\nphrases are selected from a large pool of phrases following a sampling\nstrategy. In this work we firstly analyse different sampling strategies to\nprovide insights into the training of CB for ASR with correlation plots between\nthe bias embeddings among various training stages. Secondly, we introduce a\nneighbourhood attention (NA) that localizes self attention (SA) to the nearest\nneighbouring frames to further refine the CB output. The results show that this\nproposed approach provides on average a 25.84% relative WER improvement on\nLibriSpeech sets and rare-word evaluation compared to the baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Jalal_M/0/1/0/all/0/1\">Md Asif Jalal</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Parada_P/0/1/0/all/0/1\">Pablo Peso Parada</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pavlidis_G/0/1/0/all/0/1\">George Pavlidis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moschopoulos_V/0/1/0/all/0/1\">Vasileios Moschopoulos</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Saravanan_K/0/1/0/all/0/1\">Karthikeyan Saravanan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kontoulis_C/0/1/0/all/0/1\">Chrysovalantis-Giorgos Kontoulis</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jisi Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Drosou_A/0/1/0/all/0/1\">Anastasios Drosou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_G/0/1/0/all/0/1\">Gil Ho Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Jungin Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jung_S/0/1/0/all/0/1\">Seokyeong Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpacTor-T5: Pre-training T5 Models with Span Corruption and Replaced Token Detection. (arXiv:2401.13160v1 [cs.LG])","link":"http://arxiv.org/abs/2401.13160","description":"<p>Pre-training large language models is known to be extremely resource\nintensive and often times inefficient, under-utilizing the information\nencapsulated in the training text sequences. In this paper, we present SpacTor,\na new training procedure consisting of (1) a hybrid objective combining span\ncorruption (SC) and token replacement detection (RTD), and (2) a two-stage\ncurriculum that optimizes the hybrid objective over the initial $\\tau$\niterations, then transitions to standard SC loss. We show empirically that the\neffectiveness of the hybrid objective is tied to the two-stage pre-training\nschedule, and provide extensive analysis on why this is the case. In our\nexperiments with encoder-decoder architectures (T5) on a variety of NLP tasks,\nSpacTor-T5 yields the same downstream performance as standard SC pre-training,\nwhile enabling a 50% reduction in pre-training iterations and 40% reduction in\ntotal FLOPs. Alternatively, given the same amount of computing budget, we find\nthat SpacTor results in significantly improved downstream benchmark\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1\">Ke Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Heinrich Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1\">Afshin Rostamizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1\">Ayan Chakrabarti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeSalvo_G/0/1/0/all/0/1\">Giulia DeSalvo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kagy_J/0/1/0/all/0/1\">Jean-Fran&#xe7;ois Kagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karydas_L/0/1/0/all/0/1\">Lazaros Karydas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Citovsky_G/0/1/0/all/0/1\">Gui Citovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sanjiv Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Misgendering and Assuming Gender in Machine Translation when Working with Low-Resource Languages. (arXiv:2401.13165v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13165","description":"<p>This chapter focuses on gender-related errors in machine translation (MT) in\nthe context of low-resource languages. We begin by explaining what low-resource\nlanguages are, examining the inseparable social and computational factors that\ncreate such linguistic hierarchies. We demonstrate through a case study of our\nmother tongue Bengali, a global language spoken by almost 300 million people\nbut still classified as low-resource, how gender is assumed and inferred in\ntranslations to and from the high(est)-resource English when no such\ninformation is provided in source texts. We discuss the postcolonial and\nsocietal impacts of such errors leading to linguistic erasure and\nrepresentational harms, and conclude by discussing potential solutions towards\nuplifting languages by providing them more agency in MT conversations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sourojit Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1\">Srishti Chatterjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert Judgments For Open-Domain Question Answering. (arXiv:2401.13170v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13170","description":"<p>Question answering (QA) can only make progress if we know if an answer is\ncorrect, but for many of the most challenging and interesting QA examples,\ncurrent evaluation metrics to determine answer equivalence (AE) often do not\nalign with human judgments, particularly more verbose, free-form answers from\nlarge language models (LLM). There are two challenges: a lack of data and that\nmodels are too big: LLM-based scorers can correlate better with human judges,\nbut this task has only been tested on limited QA datasets, and even when\navailable, update of the model is limited because LLMs are large and often\nexpensive. We rectify both of these issues by providing clear and consistent\nguidelines for evaluating AE in machine QA adopted from professional human QA\ncontests. We also introduce a combination of standard evaluation and a more\nefficient, robust, and lightweight discriminate AE classifier-based matching\nmethod (CFMatch, smaller than 1 MB), trained and validated to more accurately\nevaluate answer correctness in accordance with adopted expert AE rules that are\nmore aligned with human judgments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongxia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_I/0/1/0/all/0/1\">Ishani Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yijun Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nghiem_H/0/1/0/all/0/1\">Huy Nghiem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents. (arXiv:2401.13178v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13178","description":"<p>Evaluating large language models (LLMs) as general-purpose agents is\nessential for understanding their capabilities and facilitating their\nintegration into practical applications. However, the evaluation process\npresents substantial challenges. A primary obstacle is the benchmarking of\nagent performance across diverse scenarios within a unified framework,\nespecially in maintaining partially-observable environments and ensuring\nmulti-round interactions. Moreover, current evaluation frameworks mostly focus\non the final success rate, revealing few insights during the process and\nfailing to provide a deep understanding of the model abilities. To address\nthese challenges, we introduce AgentBoard, a pioneering comprehensive benchmark\nand accompanied open-source evaluation framework tailored to analytical\nevaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric\nthat captures incremental advancements as well as a comprehensive evaluation\ntoolkit that features easy assessment of agents for multi-faceted analysis\nthrough interactive visualization. This not only sheds light on the\ncapabilities and limitations of LLM agents but also propels the\ninterpretability of their performance to the forefront. Ultimately, AgentBoard\nserves as a significant step towards demystifying agent behaviors and\naccelerating the development of stronger LLM agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junlei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaohui Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MLLMReID: Multimodal Large Language Model-based Person Re-identification. (arXiv:2401.13201v1 [cs.CV])","link":"http://arxiv.org/abs/2401.13201","description":"<p>Multimodal large language models (MLLM) have achieved satisfactory results in\nmany tasks. However, their performance in the task of person re-identification\n(ReID) has not been explored to date. This paper will investigate how to adapt\nthem for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID\nimage-text datasets, and then use their visual encoder as a backbone for ReID.\nHowever, there still exist two apparent issues: (1) Designing instructions for\nReID, MLLMs may overfit specific instructions, and designing a variety of\ninstructions will lead to higher costs. (2) Latent image feature vectors from\nLLMs are not involved in loss computation. Instructional learning, aligning\nimage-text features, results in indirect optimization and a learning objective\nthat inadequately utilizes features, limiting effectiveness in person feature\nlearning. To address these problems, this paper proposes MLLMReID: Multimodal\nLarge Language Model-based ReID. Firstly, we proposed Common Instruction, a\nsimple approach that leverages the essence ability of LLMs to continue writing,\navoiding complex and diverse instruction design. Secondly, we proposed\nDirectReID, which effectively employs the latent image feature vectors of\nimages outputted by LLMs in ReID tasks. The experimental results demonstrate\nthe superiority of our method. We will open-source the code on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ULTRA: Unleash LLMs' Potential for Event Argument Extraction through Hierarchical Modeling and Pair-wise Refinement. (arXiv:2401.13218v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13218","description":"<p>Structural extraction of events within discourse is critical since it avails\na deeper understanding of communication patterns and behavior trends. Event\nargument extraction (EAE), at the core of event-centric understanding, is the\ntask of identifying role-specific text spans (i.e., arguments) for a given\nevent. Document-level EAE (DocEAE) focuses on arguments that are scattered\nacross an entire document. In this work, we explore the capabilities of open\nsource Large Language Models (LLMs), i.e., Flan-UL2, for the DocEAE task. To\nthis end, we propose ULTRA, a hierarchical framework that extracts event\narguments more cost-effectively -- the method needs as few as 50 annotations\nand doesn't require hitting costly API endpoints. Further, it alleviates the\npositional bias issue intrinsic to LLMs. ULTRA first sequentially reads text\nchunks of a document to generate a candidate argument set, upon which ULTRA\nlearns to drop non-pertinent candidates through self-refinement. We further\nintroduce LEAFER to address the challenge LLMs face in locating the exact\nboundary of an argument span. ULTRA outperforms strong baselines, which include\nstrong supervised models and ChatGPT, by 9.8% when evaluated by the exact match\n(EM) metric.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinliang Frederick Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blum_C/0/1/0/all/0/1\">Carter Blum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choji_T/0/1/0/all/0/1\">Temma Choji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Shalin Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vempala_A/0/1/0/all/0/1\">Alakananda Vempala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data. (arXiv:2401.13223v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13223","description":"<p>In this work, we address question answering (QA) over a hybrid of tabular and\ntextual data that are very common content on the Web (e.g. SEC filings), where\ndiscrete reasoning capabilities are often required. Recently, large language\nmodels (LLMs) like GPT-4 have demonstrated strong multi-step reasoning\ncapabilities. We then consider harnessing the amazing power of LLMs to solve\nour task. We abstract a Step-wise Pipeline for tabular and textual QA, which\nconsists of three key steps, including Extractor, Reasoner and Executor, and\ninitially design an instruction to instantiate the pipeline and validate that\nGPT-4 outperforms all existing methods. However, utilizing an online LLM like\nGPT-4 holds various challenges in terms of cost, latency, and data security\nrisk, which motivates us to specialize smaller LLMs in this task. We develop a\nTAT-LLM language model by fine-tuning LLaMA 2 with the training data generated\nautomatically from existing expert-annotated datasets following the Step-wise\nPipeline. The experimental results have verified that our TAT-LLM model can\noutperform all baseline models, including the previous best fine-tuned models\nand very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks.\nWe hope our work can serve as a pioneering example of specializing smaller\nlanguage models for specific tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Fengbin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Moxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scalable Link Prediction on Large-Scale Heterogeneous Graphs with Large Language Models. (arXiv:2401.13227v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13227","description":"<p>Exploring the application of large-scale language models to graph learning is\na novel endeavor. However, the vast amount of information inherent in large\ngraphs poses significant challenges to this process. This paper focuses on the\nlink prediction task and introduces LPNL (Link Prediction via Natural\nLanguage), a framework based on a large language model designed for scalable\nlink prediction on large-scale heterogeneous graphs.We design novel prompts for\nlink prediction that articulate graph details in natural language. We propose a\ntwo-stage sampling pipeline to extract crucial information from large-scale\nheterogeneous graphs, and a divide-and-conquer strategy to control the input\ntoken count within predefined limits, addressing the challenge of overwhelming\ninformation. We fine-tune a T5 model based on our self-supervised learning\ndesigned for for link prediction. Extensive experiments on a large public\nheterogeneous graphs demonstrate that LPNL outperforms various advanced\nbaselines, highlighting its remarkable performance in link prediction tasks on\nlarge-scale graphs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1\">Baolong Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shenghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_L/0/1/0/all/0/1\">Lingrui Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xueqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning. (arXiv:2401.13229v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13229","description":"<p>A major challenge in Natural Language Processing is obtaining annotated data\nfor supervised learning. An option is the use of crowdsourcing platforms for\ndata annotation. However, crowdsourcing introduces issues related to the\nannotator's experience, consistency, and biases. An alternative is to use\nzero-shot methods, which in turn have limitations compared to their few-shot or\nfully supervised counterparts. Recent advancements driven by large language\nmodels show potential, but struggle to adapt to specialized domains with\nseverely limited data. The most common approaches therefore involve the human\nitself randomly annotating a set of datapoints to build initial datasets. But\nrandomly sampling data to be annotated is often inefficient as it ignores the\ncharacteristics of the data and the specific needs of the model. The situation\nworsens when working with imbalanced datasets, as random sampling tends to\nheavily bias towards the majority classes, leading to excessive annotated data.\nTo address these issues, this paper contributes an automatic and informed data\nselection architecture to build a small dataset for few-shot learning. Our\nproposal minimizes the quantity and maximizes diversity of data selected for\nhuman annotation, while improving model performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alcoforado_A/0/1/0/all/0/1\">Alexandre Alcoforado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferraz_T/0/1/0/all/0/1\">Thomas Palmeira Ferraz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okamura_L/0/1/0/all/0/1\">Lucas Hideki Okamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fama_I/0/1/0/all/0/1\">Israel Campos Fama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavado_A/0/1/0/all/0/1\">Arnold Moya Lavado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bueno_B/0/1/0/all/0/1\">B&#xe1;rbara Dias Bueno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veloso_B/0/1/0/all/0/1\">Bruno Veloso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_A/0/1/0/all/0/1\">Anna Helena Reali Costa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SEER: Facilitating Structured Reasoning and Explanation via Reinforcement Learning. (arXiv:2401.13246v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13246","description":"<p>Elucidating the reasoning process with structured explanations from question\nto answer is fundamentally crucial, as it significantly enhances the\ninterpretability and trustworthiness of question-answering (QA) systems.\nHowever, structured explanations demand models to perform intricate structured\nreasoning, which poses great challenges. Most existing methods focus on\nsingle-step reasoning through supervised learning, ignoring logical\ndependencies between steps. Meanwhile, existing reinforcement learning\n(RL)-based methods overlook the structured relationships, impeding RL's\npotential in structured reasoning. In this paper, we propose SEER, a novel\nmethod that maximizes a structure-based return to facilitate structured\nreasoning and explanation. Our proposed structure-based return precisely\ndescribes the hierarchical and branching structure inherent in structured\nreasoning, effectively capturing the intricate relationships between states. We\nalso introduce a fine-grained reward function to meticulously delineate diverse\nreasoning steps. Extensive experiments show that SEER significantly outperforms\nstate-of-the-art methods, achieving an absolute improvement of 6.9% over\nRL-based methods on EntailmentBank, a 4.4% average improvement on STREET\nbenchmark, and exhibiting outstanding efficiency and cross-dataset\ngeneralization performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guoxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Kexin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_F/0/1/0/all/0/1\">Fuying Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yiming Qian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems. (arXiv:2401.13256v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13256","description":"<p>Large Language Models (LLMs) has shown exceptional capabilities in many\nnatual language understanding and generation tasks. However, the\npersonalization issue still remains a much-coveted property, especially when it\ncomes to the multiple sources involved in the dialogue system. To better plan\nand incorporate the use of multiple sources in generating personalized\nresponse, we firstly decompose it into three sub-tasks: Knowledge Source\nSelection, Knowledge Retrieval, and Response Generation. We then propose a\nnovel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG)\nSpecifically, we unify these three sub-tasks with different formulations into\nthe same sequence-to-sequence paradigm during the training, to adaptively\nretrieve evidences and evaluate the relevance on-demand using special tokens,\ncalled acting tokens and evaluation tokens. Enabling language models to\ngenerate acting tokens facilitates interaction with various knowledge sources,\nallowing them to adapt their behavior to diverse task requirements. Meanwhile,\nevaluation tokens gauge the relevance score between the dialogue context and\nthe retrieved evidence. In addition, we carefully design a self-refinement\nmechanism to iteratively refine the generated response considering 1) the\nconsistency scores between the generated response and retrieved evidence; and\n2) the relevance scores. Experiments on two personalized datasets (DuLeMon and\nKBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledge\nsource selection and response generation task with itself as a retriever in a\nunified manner. Extensive analyses and discussions are provided for shedding\nsome new perspectives for personalized dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zezhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yufei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jeff Z. Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion, ASR Error Detection, and ASR Error Correction. (arXiv:2401.13260v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13260","description":"<p>The prevalent approach in speech emotion recognition (SER) involves\nintegrating both audio and textual information to comprehensively identify the\nspeaker's emotion, with the text generally obtained through automatic speech\nrecognition (ASR). An essential issue of this approach is that ASR errors from\nthe text modality can worsen the performance of SER. Previous studies have\nproposed using an auxiliary ASR error detection task to adaptively assign\nweights of each word in ASR hypotheses. However, this approach has limited\nimprovement potential because it does not address the coherence of semantic\ninformation in the text. Additionally, the inherent heterogeneity of different\nmodalities leads to distribution gaps between their representations, making\ntheir fusion challenging. Therefore, in this paper, we incorporate two\nauxiliary tasks, ASR error detection (AED) and ASR error correction (AEC), to\nenhance the semantic coherence of ASR text, and further introduce a novel\nmulti-modal fusion (MF) method to learn shared representations across\nmodalities. We refer to our method as MF-AED-AEC. Experimental results indicate\nthat MF-AED-AEC significantly outperforms the baseline model by a margin of\n4.1\\%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiajun He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaohan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingfeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can AI Assistants Know What They Don't Know?. (arXiv:2401.13275v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13275","description":"<p>Recently, AI assistants based on large language models (LLMs) show surprising\nperformance in many tasks, such as dialogue, solving math problems, writing\ncode, and using tools. Although LLMs possess intensive world knowledge, they\nstill make factual errors when facing some knowledge intensive tasks, like\nopen-domain question answering. These untruthful responses from the AI\nassistant may cause significant risks in practical applications. We believe\nthat an AI assistant's refusal to answer questions it does not know is a\ncrucial method for reducing hallucinations and making the assistant truthful.\nTherefore, in this paper, we ask the question \"Can AI assistants know what they\ndon't know and express them through natural language?\" To answer this question,\nwe construct a model-specific \"I don't know\" (Idk) dataset for an assistant,\nwhich contains its known and unknown questions, based on existing open-domain\nquestion answering datasets. Then we align the assistant with its corresponding\nIdk dataset and observe whether it can refuse to answer its unknown questions\nafter alignment. Experimental results show that after alignment with Idk\ndatasets, the assistant can refuse to answer most its unknown questions. For\nquestions they attempt to answer, the accuracy is significantly higher than\nbefore the alignment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qinyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models. (arXiv:2401.13298v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13298","description":"<p>The age of social media is flooded with Internet memes, necessitating a clear\ngrasp and effective identification of harmful ones. This task presents a\nsignificant challenge due to the implicit meaning embedded in memes, which is\nnot explicitly conveyed through the surface text and image. However, existing\nharmful meme detection methods do not present readable explanations that unveil\nsuch implicit meaning to support their detection decisions. In this paper, we\npropose an explainable approach to detect harmful memes, achieved through\nreasoning over conflicting rationales from both harmless and harmful positions.\nSpecifically, inspired by the powerful capacity of Large Language Models (LLMs)\non text generation and reasoning, we first elicit multimodal debate between\nLLMs to generate the explanations derived from the contradictory arguments.\nThen we propose to fine-tune a small language model as the debate judge for\nharmfulness inference, to facilitate multimodal fusion between the harmfulness\nrationales and the intrinsic multimodal information within memes. In this way,\nour model is empowered to perform dialectical reasoning over intricate and\nimplicit harm-indicative patterns, utilizing multimodal explanations\noriginating from both harmless and harmful arguments. Extensive experiments on\nthree public meme datasets demonstrate that our harmful meme detection approach\nachieves much better performance than state-of-the-art methods and exhibits a\nsuperior capacity for explaining the meme harmfulness of the model predictions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Ziyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruichao Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MaLA-500: Massive Language Adaptation of Large Language Models. (arXiv:2401.13303v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13303","description":"<p>Large language models have advanced the state of the art in natural language\nprocessing. However, their predominant design for English or a limited set of\nlanguages creates a substantial gap in their effectiveness for low-resource\nlanguages. To bridge this gap, we introduce MaLA-500, a novel large language\nmodel designed to cover an extensive range of 534 languages. To train MaLA-500,\nwe employ vocabulary extension and continued pretraining on LLaMA 2 with\nGlot500-c. Our experiments on SIB-200 show that MaLA-500 achieves\nstate-of-the-art in-context learning results. We release MaLA-500 at\nhttps://huggingface.co/MaLA-LM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Peiqin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shaoxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiedemann_J/0/1/0/all/0/1\">J&#xf6;rg Tiedemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document Understanding with Instructions. (arXiv:2401.13313v1 [cs.CV])","link":"http://arxiv.org/abs/2401.13313","description":"<p>We study the problem of completing various visual document understanding\n(VDU) tasks, e.g., question answering and information extraction, on real-world\ndocuments through human-written instructions. To this end, we propose\nInstructDoc, the first large-scale collection of 30 publicly available VDU\ndatasets, each with diverse instructions in a unified format, which covers a\nwide range of 12 tasks and includes open document types/formats. Furthermore,\nto enhance the generalization performance on VDU tasks, we design a new\ninstruction-based document reading and understanding model, InstructDr, that\nconnects document images, image encoders, and large language models (LLMs)\nthrough a trainable bridging module. Experiments demonstrate that InstructDr\ncan effectively adapt to new VDU datasets, tasks, and domains via given\ninstructions and outperforms existing multimodal LLMs and ChatGPT without\nspecific training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_R/0/1/0/all/0/1\">Ryota Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iki_T/0/1/0/all/0/1\">Taichi Iki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishida_K/0/1/0/all/0/1\">Kyosuke Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_K/0/1/0/all/0/1\">Kuniko Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_J/0/1/0/all/0/1\">Jun Suzuki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Categorization Can Enhance Domain-Agnostic Stopword Extraction. (arXiv:2401.13398v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13398","description":"<p>This paper investigates the role of text categorization in streamlining\nstopword extraction in natural language processing (NLP), specifically focusing\non nine African languages alongside French. By leveraging the MasakhaNEWS,\nAfrican Stopwords Project, and MasakhaPOS datasets, our findings emphasize that\ntext categorization effectively identifies domain-agnostic stopwords with over\n80% detection success rate for most examined languages. Nevertheless,\nlinguistic variances result in lower detection rates for certain languages.\nInterestingly, we find that while over 40% of stopwords are common across news\ncategories, less than 15% are unique to a single category. Uncommon stopwords\nadd depth to text but their classification as stopwords depends on context.\nTherefore combining statistical and linguistic approaches creates comprehensive\nstopword lists, highlighting the value of our hybrid method. This research\nenhances NLP for African languages and underscores the importance of text\ncategorization in stopword extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Turki_H/0/1/0/all/0/1\">Houcemeddine Turki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etori_N/0/1/0/all/0/1\">Naome A. Etori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taieb_M/0/1/0/all/0/1\">Mohamed Ali Hadj Taieb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omotayo_A/0/1/0/all/0/1\">Abdul-Hakeem Omotayo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emezue_C/0/1/0/all/0/1\">Chris Chinenye Emezue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aouicha_M/0/1/0/all/0/1\">Mohamed Ben Aouicha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awokoya_A/0/1/0/all/0/1\">Ayodele Awokoya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawan_F/0/1/0/all/0/1\">Falalu Ibrahim Lawan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nixdorf_D/0/1/0/all/0/1\">Doreen Nixdorf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clue-Guided Path Exploration: An Efficient Knowledge Base Question-Answering Framework with Low Computational Resource Consumption. (arXiv:2401.13444v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13444","description":"<p>In recent times, large language models (LLMs) have showcased remarkable\ncapabilities. However, updating their knowledge poses challenges, potentially\nleading to inaccuracies when confronted with unfamiliar queries. While\nintegrating knowledge graphs with LLMs has been explored, existing approaches\ntreat LLMs as primary decision-makers, imposing high demands on their\ncapabilities. This is particularly unsuitable for LLMs with lower computational\ncosts and relatively poorer performance. In this paper, we introduce a\nClue-Guided Path Exploration framework (CGPE) that efficiently merges a\nknowledge base with an LLM, placing less stringent requirements on the model's\ncapabilities. Inspired by the method humans use to manually retrieve knowledge,\nCGPE employs information from the question as clues to systematically explore\nthe required knowledge path within the knowledge base. Experiments on\nopen-source datasets reveal that CGPE outperforms previous methods and is\nhighly applicable to LLMs with fewer parameters. In some instances, even\nChatGLM3, with its 6 billion parameters, can rival the performance of GPT-4.\nFurthermore, the results indicate a minimal invocation frequency of CGPE on\nLLMs, suggesting reduced computational overhead. For organizations and\nindividuals facing constraints in computational resources, our research offers\nsignificant practical value.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dehao Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Feng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minghu Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken Question Answering. (arXiv:2401.13463v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13463","description":"<p>Spoken Question Answering (SQA) is essential for machines to reply to user's\nquestion by finding the answer span within a given spoken passage. SQA has been\npreviously achieved without ASR to avoid recognition errors and\nOut-of-Vocabulary (OOV) problems. However, the real-world problem of\nOpen-domain SQA (openSQA), in which the machine needs to first retrieve\npassages that possibly contain the answer from a spoken archive in addition,\nwas never considered. This paper proposes the first known end-to-end framework,\nSpeech Dense Passage Retriever (SpeechDPR), for the retrieval component of the\nopenSQA problem. SpeechDPR learns a sentence-level semantic representation by\ndistilling knowledge from the cascading model of unsupervised ASR (UASR) and\ntext dense retriever (TDR). No manually transcribed speech data is needed.\nInitial experiments showed performance comparable to the cascading model of\nUASR and TDR, and significantly better when UASR was poor, verifying this\napproach is more robust to speech recognition errors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chyi-Jiunn Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1\">Guan-Ting Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1\">Lin-shan Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval. (arXiv:2401.13478v1 [cs.IR])","link":"http://arxiv.org/abs/2401.13478","description":"<p>Multi-modal information retrieval (MMIR) is a rapidly evolving field, where\nsignificant progress, particularly in image-text pairing, has been made through\nadvanced representation learning and cross-modality alignment research.\nHowever, current benchmarks for evaluating MMIR performance in image-text\npairing within the scientific domain show a notable gap, where chart and table\nimages described in scholarly language usually do not play a significant role.\nTo bridge this gap, we develop a specialised scientific MMIR (SciMMIR)\nbenchmark by leveraging open-access paper collections to extract data relevant\nto the scientific domain. This benchmark comprises 530K meticulously curated\nimage-text pairs, extracted from figures and tables with detailed captions in\nscientific documents. We further annotate the image-text pairs with two-level\nsubset-subcategory hierarchy annotations to facilitate a more comprehensive\nevaluation of the baselines. We conducted zero-shot and fine-tuning evaluations\non prominent multi-modal image-captioning and visual language models, such as\nCLIP and BLIP. Our analysis offers critical insights for MMIR in the scientific\ndomain, including the impact of pre-training and fine-tuning settings and the\ninfluence of the visual and textual encoders. All our data and checkpoints are\npublicly available at https://github.com/Wusiwei0410/SciMMIR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yizhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yiming Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kaijing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chenghao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoran Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bohao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment. (arXiv:2401.13481v1 [cs.CY])","link":"http://arxiv.org/abs/2401.13481","description":"<p>Exposure to large language model output is rapidly increasing. How will\nseeing AI-generated ideas affect human ideas? We conducted an experiment (800+\nparticipants, 40+ countries) where participants viewed creative ideas that were\nfrom ChatGPT or prior experimental participants and then brainstormed their own\nidea. We varied the number of AI-generated examples (none, low, or high\nexposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic\nexperiment design -- ideas from prior participants in an experimental condition\nare used as stimuli for future participants in the same experimental condition\n-- mimics the interdependent process of cultural creation: creative ideas are\nbuilt upon prior ideas. Hence, we capture the compounding effects of having\nLLMs 'in the culture loop'. We find that high AI exposure (but not low AI\nexposure) did not affect the creativity of individual ideas but did increase\nthe average amount and rate of change of collective idea diversity. AI made\nideas different, not better. There were no main effects of disclosure. We also\nfound that self-reported creative people were less influenced by knowing an\nidea was from AI, and that participants were more likely to knowingly adopt AI\nideas when the task was difficult. Our findings suggest that introducing AI\nideas into society may increase collective diversity but not individual\ncreativity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ashkinaze_J/0/1/0/all/0/1\">Joshua Ashkinaze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendelsohn_J/0/1/0/all/0/1\">Julia Mendelsohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiwei_L/0/1/0/all/0/1\">Li Qiwei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Budak_C/0/1/0/all/0/1\">Ceren Budak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilbert_E/0/1/0/all/0/1\">Eric Gilbert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can GPT-3.5 Generate and Code Discharge Summaries?. (arXiv:2401.13512v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13512","description":"<p>Objective: To investigate GPT-3.5 in generating and coding medical documents\nwith ICD-10 codes for data augmentation on low-resources labels.\n</p>\n<p>Materials and Methods: Employing GPT-3.5 we generated and coded 9,606\ndischarge summaries based on lists of ICD-10 code descriptions of patients with\ninfrequent (generation) codes within the MIMIC-IV dataset. Combined with the\nbaseline training set, this formed an augmented training set. Neural coding\nmodels were trained on baseline and augmented data and evaluated on a MIMIC-IV\ntest set. We report micro- and macro-F1 scores on the full codeset, generation\ncodes, and their families. Weak Hierarchical Confusion Matrices were employed\nto determine within-family and outside-of-family coding errors in the latter\ncodesets. The coding performance of GPT-3.5 was evaluated both on prompt-guided\nself-generated data and real MIMIC-IV data. Clinical professionals evaluated\nthe clinical acceptability of the generated documents.\n</p>\n<p>Results: Augmentation slightly hinders the overall performance of the models\nbut improves performance for the generation candidate codes and their families,\nincluding one unseen in the baseline training data. Augmented models display\nlower out-of-family error rates. GPT-3.5 can identify ICD-10 codes by the\nprompted descriptions, but performs poorly on real data. Evaluators note the\ncorrectness of generated concepts while suffering in variety, supporting\ninformation, and narrative.\n</p>\n<p>Discussion and Conclusion: GPT-3.5 alone is unsuitable for ICD-10 coding.\nAugmentation positively affects generation code families but mainly benefits\ncodes with existing examples. Augmentation reduces out-of-family errors.\nDischarge summaries generated by GPT-3.5 state prompted concepts correctly but\nlack variety, and authenticity in narratives. They are unsuitable for clinical\npractice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Falis_M/0/1/0/all/0/1\">Mat&#xfa;&#x161; Falis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gema_A/0/1/0/all/0/1\">Aryo Pradipta Gema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daines_L/0/1/0/all/0/1\">Luke Daines</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basetti_S/0/1/0/all/0/1\">Siddharth Basetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holder_M/0/1/0/all/0/1\">Michael Holder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penfold_R/0/1/0/all/0/1\">Rose S Penfold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alex_B/0/1/0/all/0/1\">Beatrice Alex</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation. (arXiv:2401.13527v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13527","description":"<p>Benefiting from effective speech modeling, current Speech Large Language\nModels (SLLMs) have demonstrated exceptional capabilities in in-context speech\ngeneration and efficient generalization to unseen speakers. However, the\nprevailing information modeling process is encumbered by certain redundancies,\nleading to inefficiencies in speech generation. We propose Chain-of-Information\nGeneration (CoIG), a method for decoupling semantic and perceptual information\nin large-scale speech generation. Building on this, we develop SpeechGPT-Gen,\nan 8-billion-parameter SLLM efficient in semantic and perceptual information\nmodeling. It comprises an autoregressive model based on LLM for semantic\ninformation modeling and a non-autoregressive model employing flow matching for\nperceptual information modeling. Additionally, we introduce the novel approach\nof infusing semantic information into the prior distribution to enhance the\nefficiency of flow matching. Extensive experimental results demonstrate that\nSpeechGPT-Gen markedly excels in zero-shot text-to-speech, zero-shot voice\nconversion, and speech-to-speech dialogue, underscoring CoIG's remarkable\nproficiency in capturing and modeling speech's semantic and perceptual\ndimensions. Code and models are available at\nhttps://github.com/0nutation/SpeechGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1\">Jun Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yaqian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Malaysian Language Model Based on Mistral for Enhanced Local Language Understanding. (arXiv:2401.13565v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13565","description":"<p>In this paper, we present significant advancements in the pretraining of\nMistral 7B, a large-scale language model, using a dataset of 32.6 GB,\nequivalent to 1.1 billion tokens. We explore the impact of extending the\ncontext length, releasing models with context lengths of 4096 and 32768 tokens,\nand further refining performance with a specialized 16384 context length\ninstruction-tuned model, we called it Malaysian Mistral.\n</p>\n<p>Our experiments demonstrate the efficacy of continue pretraining and the\ninfluence of extended context lengths on Mistral 7B's language understanding\ncapabilities. Additionally, we release a model specifically tuned with a 16384\ncontext length instruction, showcasing its potential for capturing nuanced\nlanguage intricacies.\n</p>\n<p>Furthermore, our research contributes to the benchmarking of Malaysian\nMistral against prominent language models, including ChatGPT3.5 and Claude 2.\nWe present compelling results indicating Malaysian Mistral's superior\nperformance on Tatabahasa (Malay grammar) test set, particularly when\nfine-tuned with instructions.\n</p>\n<p>All models released at\nhttps://huggingface.co/collections/mesolitica/malaysian-mistral-7b-6528f2ec825f4bba46c1700c\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zolkepli_H/0/1/0/all/0/1\">Husein Zolkepli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razak_A/0/1/0/all/0/1\">Aisyah Razak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adha_K/0/1/0/all/0/1\">Kamarul Adha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nazhan_A/0/1/0/all/0/1\">Ariff Nazhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt Weight Experiments for LLM Instruction Fine-Tuning. (arXiv:2401.13586v1 [cs.LG])","link":"http://arxiv.org/abs/2401.13586","description":"<p>We present a small study analyzing how prompt token classification loss\nweighting (PLW) affects the performance of 7B-size LLaMA models fine-tuned on\ninstruction tasks. We recreated Stanford's Alpaca experiment with both LLaMA 1\nand LLaMA 2 using multiple instruction datasets. We found that models\nfine-tuned on our short-completion dataset have a negative quadratic\nrelationship with PLW while models fine-tuned on long-completion datasets were\nunaffected by PLW.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huerta_Enochian_M/0/1/0/all/0/1\">Mathew Huerta-Enochian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes. (arXiv:2401.13588v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13588","description":"<p>The field of healthcare has increasingly turned its focus towards Large\nLanguage Models (LLMs) due to their remarkable performance. However, their\nperformance in actual clinical applications has been underexplored. Traditional\nevaluations based on question-answering tasks don't fully capture the nuanced\ncontexts. This gap highlights the need for more in-depth and practical\nassessments of LLMs in real-world healthcare settings. Objective: We sought to\nevaluate the performance of LLMs in the complex clinical context of adult\ncritical care medicine using systematic and comprehensible analytic methods,\nincluding clinician annotation and adjudication. Methods: We investigated the\nperformance of three general LLMs in understanding and processing real-world\nclinical notes. Concepts from 150 clinical notes were identified by MetaMap and\nthen labeled by 9 clinicians. Each LLM's proficiency was evaluated by\nidentifying the temporality and negation of these concepts using different\nprompts for an in-depth analysis. Results: GPT-4 showed overall superior\nperformance compared to other LLMs. In contrast, both GPT-3.5 and\ntext-davinci-003 exhibit enhanced performance when the appropriate prompting\nstrategies are employed. The GPT family models have demonstrated considerable\nefficiency, evidenced by their cost-effectiveness and time-saving capabilities.\nConclusion: A comprehensive qualitative performance evaluation framework for\nLLMs is developed and operationalized. This framework goes beyond singular\nperformance aspects. With expert annotations, this methodology not only\nvalidates LLMs' capabilities in processing complex medical data but also\nestablishes a benchmark for future LLM evaluations across specialized domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Darren Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Cheng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bold_D/0/1/0/all/0/1\">Delgersuren Bold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouvier_M/0/1/0/all/0/1\">Monique Bouvier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiaying Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shickel_B/0/1/0/all/0/1\">Benjamin Shickel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jabaley_C/0/1/0/all/0/1\">Craig S. Jabaley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soojin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_M/0/1/0/all/0/1\">Michael J. Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wainwright_M/0/1/0/all/0/1\">Mark S. Wainwright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clermont_G/0/1/0/all/0/1\">Gilles Clermont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashidi_P/0/1/0/all/0/1\">Parisa Rashidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenthal_E/0/1/0/all/0/1\">Eric S. Rosenthal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimisko_L/0/1/0/all/0/1\">Laurie Dimisko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Ran Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Joo Heung Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiao Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graph Guided Question Answer Generation for Procedural Question-Answering. (arXiv:2401.13594v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13594","description":"<p>In this paper, we focus on task-specific question answering (QA). To this\nend, we introduce a method for generating exhaustive and high-quality training\ndata, which allows us to train compact (e.g., run on a mobile device),\ntask-specific QA models that are competitive against GPT variants. The key\ntechnological enabler is a novel mechanism for automatic question-answer\ngeneration from procedural text which can ingest large amounts of textual\ninstructions and produce exhaustive in-domain QA training data. While current\nQA data generation methods can produce well-formed and varied data, their\nnon-exhaustive nature is sub-optimal for training a QA model. In contrast, we\nleverage the highly structured aspect of procedural text and represent each\nstep and the overall flow of the procedure as graphs. We then condition on\ngraph nodes to automatically generate QA pairs in an exhaustive and\ncontrollable manner. Comprehensive evaluations of our method show that: 1)\nsmall models trained with our data achieve excellent performance on the target\nQA task, even exceeding that of GPT3 and ChatGPT despite being several orders\nof magnitude smaller. 2) semantic coverage is the key indicator for downstream\nQA performance. Crucially, while large language models excel at syntactic\ndiversity, this does not necessarily result in improvements on the end QA\nmodel. In contrast, the higher semantic coverage provided by our method is\ncritical for QA performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hai X. Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadji_I/0/1/0/all/0/1\">Isma Hadji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xinnuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Degutyte_Z/0/1/0/all/0/1\">Ziedune Degutyte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rainey_J/0/1/0/all/0/1\">Jay Rainey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazakos_E/0/1/0/all/0/1\">Evangelos Kazakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazly_A/0/1/0/all/0/1\">Afsaneh Fazly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzimiropoulos_G/0/1/0/all/0/1\">Georgios Tzimiropoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1\">Brais Martinez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction. (arXiv:2401.13598v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13598","description":"<p>Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in\ninformation systems that aims to simultaneously extract entities with semantic\nrelations from a document. Existing methods heavily rely on a substantial\namount of fully labeled data. However, collecting and annotating data for newly\nemerging relations is time-consuming and labor-intensive. Recent advanced Large\nLanguage Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text\ngeneration capabilities, inspiring us to explore an alternative approach for\nobtaining auto-labeled documents with new relations. In this paper, we propose\na Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework,\nwhich generates labeled data by retrieval and denoising knowledge from LLMs,\ncalled GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide\nChatGPT to generate labeled long-text data step by step. To improve the quality\nof synthetic data, we propose a denoising strategy based on the consistency of\ncross-document knowledge. Leveraging our denoised synthetic data, we proceed to\nfine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets.\nWe perform experiments for both zero-shot document-level relation and triplet\nextraction on two public datasets. The experimental results illustrate that our\nGenRDK framework outperforms strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaocui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_R/0/1/0/all/0/1\">Rong Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-LLMs: Recent Advances in MultiModal Large Language Models. (arXiv:2401.13601v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13601","description":"<p>In the past year, MultiModal Large Language Models (MM-LLMs) have undergone\nsubstantial advancements, augmenting off-the-shelf LLMs to support MM inputs or\noutputs via cost-effective training strategies. The resulting models not only\npreserve the inherent reasoning and decision-making capabilities of LLMs but\nalso empower a diverse range of MM tasks. In this paper, we provide a\ncomprehensive survey aimed at facilitating further research of MM-LLMs.\nSpecifically, we first outline general design formulations for model\narchitecture and training pipeline. Subsequently, we provide brief\nintroductions of $26$ existing MM-LLMs, each characterized by its specific\nformulations. Additionally, we review the performance of MM-LLMs on mainstream\nbenchmarks and summarize key training recipes to enhance the potency of\nMM-LLMs. Lastly, we explore promising directions for MM-LLMs while concurrently\nmaintaining a real-time tracking website for the latest developments in the\nfield. We hope that this survey contributes to the ongoing advancement of the\nMM-LLMs domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Duzhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yahan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1\">Jiahua Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DenoSent: A Denoising Objective for Self-Supervised Sentence Representation Learning. (arXiv:2401.13621v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13621","description":"<p>Contrastive-learning-based methods have dominated sentence representation\nlearning. These methods regularize the representation space by pulling similar\nsentence representations closer and pushing away the dissimilar ones and have\nbeen proven effective in various NLP tasks, e.g., semantic textual similarity\n(STS) tasks. However, it is challenging for these methods to learn fine-grained\nsemantics as they only learn from the inter-sentence perspective, i.e., their\nsupervision signal comes from the relationship between data samples. In this\nwork, we propose a novel denoising objective that inherits from another\nperspective, i.e., the intra-sentence perspective. By introducing both discrete\nand continuous noise, we generate noisy sentences and then train our model to\nrestore them to their original form. Our empirical evaluations demonstrate that\nthis approach delivers competitive results on both semantic textual similarity\n(STS) and a wide range of transfer tasks, standing up well in comparison to\ncontrastive-learning-based methods. Notably, the proposed intra-sentence\ndenoising objective complements existing inter-sentence contrastive\nmethodologies and can be integrated with them to further enhance performance.\nOur code is available at https://github.com/xinghaow99/DenoSent.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinghao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yunhua Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VisualWebArena: Evaluating Multimodal Agents on Realistic Visual Web Tasks. (arXiv:2401.13649v1 [cs.LG])","link":"http://arxiv.org/abs/2401.13649","description":"<p>Autonomous agents capable of planning, reasoning, and executing actions on\nthe web offer a promising avenue for automating computer tasks. However, the\nmajority of existing benchmarks primarily focus on text-based agents,\nneglecting many natural tasks that require visual information to effectively\nsolve. Given that most computer interfaces cater to human perception, visual\ninformation often augments textual data in ways that text-only models struggle\nto harness effectively. To bridge this gap, we introduce VisualWebArena, a\nbenchmark designed to assess the performance of multimodal web agents on\nrealistic \\textit{visually grounded tasks}. VisualWebArena comprises of a set\nof diverse and complex web-based tasks that evaluate various capabilities of\nautonomous multimodal agents. To perform on this benchmark, agents need to\naccurately process image-text inputs, interpret natural language instructions,\nand execute actions on websites to accomplish user-defined objectives. We\nconduct an extensive evaluation of state-of-the-art LLM-based autonomous\nagents, including several multimodal models. Through extensive quantitative and\nqualitative analysis, we identify several limitations of text-only LLM agents,\nand reveal gaps in the capabilities of state-of-the-art multimodal language\nagents. VisualWebArena provides a framework for evaluating multimodal\nautonomous language agents, and offers insights towards building stronger\nautonomous agents for the web. Our code, baseline models, and data is publicly\navailable at https://jykoh.com/vwa.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1\">Jing Yu Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1\">Robert Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_L/0/1/0/all/0/1\">Lawrence Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvvur_V/0/1/0/all/0/1\">Vikram Duvvur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1\">Ming Chong Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Po-Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MambaByte: Token-free Selective State Space Model. (arXiv:2401.13660v1 [cs.CL])","link":"http://arxiv.org/abs/2401.13660","description":"<p>Token-free language models learn directly from raw bytes and remove the bias\nof subword tokenization. Operating on bytes, however, results in significantly\nlonger sequences, and standard autoregressive Transformers scale poorly in such\nsettings. We experiment with MambaByte, a token-free adaptation of the Mamba\nstate space model, trained autoregressively on byte sequences. Our experiments\nindicate the computational efficiency of MambaByte compared to other byte-level\nmodels. We also find MambaByte to be competitive with and even outperform\nstate-of-the-art subword Transformers. Furthermore, owing to linear scaling in\nlength, MambaByte benefits from fast inference compared to Transformers. Our\nfindings establish the viability of MambaByte in enabling token-free language\nmodeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangavarapu_T/0/1/0/all/0/1\">Tushaar Gangavarapu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jing Nathan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M Rush</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A New Sentence Extraction Strategy for Unsupervised Extractive Summarization Methods. (arXiv:2112.03203v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.03203","description":"<p>In recent years, text summarization methods have attracted much attention\nagain thanks to the researches on neural network models. Most of the current\ntext summarization methods based on neural network models are supervised\nmethods which need large-scale datasets. However, large-scale datasets are\ndifficult to obtain in practical applications. In this paper, we model the task\nof extractive text summarization methods from the perspective of Information\nTheory, and then describe the unsupervised extractive methods with a uniform\nframework. To improve the feature distribution and to decrease the mutual\ninformation of summarization sentences, we propose a new sentence extraction\nstrategy which can be applied to existing unsupervised extractive methods.\nExperiments are carried out on different datasets, and results show that our\nstrategy is indeed effective and in line with expectations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dehao Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yingzhu Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhongliang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Oolong: Investigating What Makes Transfer Learning Hard with Controlled Studies. (arXiv:2202.12312v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.12312","description":"<p>When we transfer a pretrained language model to a new language, there are\nmany axes of variation that change at once. To disentangle the impact of\ndifferent factors like syntactic similarity and vocabulary similarity, we\npropose a set of controlled transfer studies: we systematically transform the\nlanguage of the GLUE benchmark, altering one axis of crosslingual variation at\na time, and then measure the resulting drops in a pretrained model's downstream\nperformance. We find that models can largely recover from syntactic-style\nshifts, but cannot recover from vocabulary misalignment and embedding matrix\nre-initialization, even with continued pretraining on 15 million tokens. %On\nthe other hand, transferring to a dataset with an unaligned vocabulary is\nextremely hard to recover from in the low-data regime. Moreover, good-quality\ntokenizers in the transfer language do not make vocabulary alignment easier.\nOur experiments provide insights into the factors of cross-lingual transfer\nthat researchers should most focus on when designing language transfer\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhengxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamkin_A/0/1/0/all/0/1\">Alex Tamkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_I/0/1/0/all/0/1\">Isabel Papadimitriou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReCOGS: How Incidental Details of a Logical Form Overshadow an Evaluation of Semantic Interpretation. (arXiv:2303.13716v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13716","description":"<p>Compositional generalization benchmarks for semantic parsing seek to assess\nwhether models can accurately compute meanings for novel sentences, but\noperationalize this in terms of logical form (LF) prediction. This raises the\nconcern that semantically irrelevant details of the chosen LFs could shape\nmodel performance. We argue that this concern is realized for the COGS\nbenchmark. COGS poses generalization splits that appear impossible for\npresent-day models, which could be taken as an indictment of those models.\nHowever, we show that the negative results trace to incidental features of COGS\nLFs. Converting these LFs to semantically equivalent ones and factoring out\ncapabilities unrelated to semantic interpretation, we find that even baseline\nmodels get traction. A recent variable-free translation of COGS LFs suggests\nsimilar conclusions, but we observe this format is not semantically equivalent;\nit is incapable of accurately representing some COGS meanings. These findings\ninform our proposal for ReCOGS, a modified version of COGS that comes closer to\nassessing the target semantic capabilities while remaining very challenging.\nOverall, our results reaffirm the importance of compositional generalization\nand careful benchmark task design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhengxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher D. Manning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretability at Scale: Identifying Causal Mechanisms in Alpaca. (arXiv:2305.08809v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08809","description":"<p>Obtaining human-interpretable explanations of large, general-purpose language\nmodels is an urgent goal for AI safety. However, it is just as important that\nour interpretability methods are faithful to the causal dynamics underlying\nmodel behavior and able to robustly generalize to unseen inputs. Distributed\nAlignment Search (DAS) is a powerful gradient descent method grounded in a\ntheory of causal abstraction that has uncovered perfect alignments between\ninterpretable symbolic algorithms and small deep learning models fine-tuned for\nspecific tasks. In the present paper, we scale DAS significantly by replacing\nthe remaining brute-force search steps with learned parameters -- an approach\nwe call Boundless DAS. This enables us to efficiently search for interpretable\ncausal structure in large language models while they follow instructions. We\napply Boundless DAS to the Alpaca model (7B parameters), which, off the shelf,\nsolves a simple numerical reasoning problem. With Boundless DAS, we discover\nthat Alpaca does this by implementing a causal model with two interpretable\nboolean variables. Furthermore, we find that the alignment of neural\nrepresentations with these variables is robust to changes in inputs and\ninstructions. These findings mark a first step toward faithfully understanding\nthe inner-workings of our ever-growing and most widely deployed language\nmodels. Our tool is extensible to larger LLMs and is released publicly at\n`https://github.com/stanfordnlp/pyvene`.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhengxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Atticus Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Zero-Shot Rankers for Recommender Systems. (arXiv:2305.08845v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.08845","description":"<p>Recently, large language models (LLMs) (e.g., GPT-4) have demonstrated\nimpressive general-purpose task-solving abilities, including the potential to\napproach recommendation tasks. Along this line of research, this work aims to\ninvestigate the capacity of LLMs that act as the ranking model for recommender\nsystems. We first formalize the recommendation problem as a conditional ranking\ntask, considering sequential interaction histories as conditions and the items\nretrieved by other candidate generation models as candidates. To solve the\nranking task by LLMs, we carefully design the prompting template and conduct\nextensive experiments on two widely-used datasets. We show that LLMs have\npromising zero-shot ranking abilities but (1) struggle to perceive the order of\nhistorical interactions, and (2) can be biased by popularity or item positions\nin the prompts. We demonstrate that these issues can be alleviated using\nspecially designed prompting and bootstrapping strategies. Equipped with these\ninsights, zero-shot LLMs can even challenge conventional recommendation models\nwhen ranking candidates are retrieved by multiple candidate generators. The\ncode and processed datasets are available at\nhttps://github.com/RUCAIBox/LLMRank.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yupeng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zihan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and Inference of Large Language Models. (arXiv:2306.02272v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02272","description":"<p>Large language models (LLMs) with hundreds of billions of parameters require\npowerful server-grade GPUs for inference, limiting their practical deployment.\nTo address this challenge, we introduce the outlier-aware weight quantization\n(OWQ) method, which aims to minimize LLM's footprint through low-precision\nrepresentation. OWQ prioritizes a small subset of structured weights sensitive\nto quantization, storing them in high-precision, while applying highly tuned\nquantization to the remaining dense weights. This sensitivity-aware\nmixed-precision scheme reduces the quantization error notably, and extensive\nexperiments demonstrate that 3.1-bit models using OWQ perform comparably to\n4-bit models optimized by OPTQ. Furthermore, OWQ incorporates a\nparameter-efficient fine-tuning for task-specific adaptation, called weak\ncolumn tuning (WCT), enabling accurate task-specific LLM adaptation with\nminimal memory overhead in the optimized format. OWQ represents a notable\nadvancement in the flexibility, efficiency, and practicality of LLM\noptimization literature. The source code is available at\nhttps://github.com/xvyaward/owq\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changhun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jungyu Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunhyeok Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Medium\" LMs of Code in the Era of LLMs: Lessons From StackOverflow. (arXiv:2306.03268v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03268","description":"<p>Large pre-trained neural language models have brought immense progress to\nboth NLP and software engineering. Models in OpenAI's GPT series now dwarf\nGoogle's BERT and Meta's RoBERTa, which previously set new benchmarks on a wide\nrange of NLP applications. These models are trained on massive corpora of\nheterogeneous data from web crawls, which enables them to learn general\nlanguage patterns and semantic relationships. However, the largest models are\nboth expensive to train and deploy and are often closed-source, so we lack\naccess to their data and design decisions. We argue that this trend towards\nlarge, general-purpose models should be complemented with single-purpose, more\nmodestly sized pre-trained models. In this work, we take StackOverflow (SO) as\na domain example in which large volumes of rich aligned code and text data is\navailable. We adopt standard practices for pre-training large language models,\nincluding using a very large context size (2,048 tokens), batch size (0.5M\ntokens) and training set (27B tokens), coupled with a powerful toolkit\n(Megatron-LM), to train two models: SOBertBase, with 109M parameters, and\nSOBertLarge with 762M parameters, at a budget of just $\\$187$ and $\\$800$ each.\nWe compare the performance of our models with both the previous SOTA model\ntrained on SO data exclusively as well general-purpose BERT models and OpenAI's\nChatGPT on four SO-specific downstream tasks - question quality prediction,\nclosed question prediction, named entity recognition and obsoletion prediction\n(a new task we introduce). Not only do our models consistently outperform all\nbaselines, the smaller model is often sufficient for strong results. Both\nmodels are released to the public. These results demonstrate that pre-training\nboth extensively and properly on in-domain data can yield a powerful and\naffordable alternative to leveraging closed-source general-purpose models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_M/0/1/0/all/0/1\">Manisha Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hellendoorn_V/0/1/0/all/0/1\">Vincent J. Hellendoorn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment. (arXiv:2306.08877v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.08877","description":"<p>Text-conditioned image generation models often generate incorrect\nassociations between entities and their visual attributes. This reflects an\nimpaired mapping between linguistic binding of entities and modifiers in the\nprompt and visual binding of the corresponding elements in the generated image.\nAs one notable example, a query like \"a pink sunflower and a yellow flamingo\"\nmay incorrectly produce an image of a yellow sunflower and a pink flamingo. To\nremedy this issue, we propose SynGen, an approach which first syntactically\nanalyses the prompt to identify entities and their modifiers, and then uses a\nnovel loss function that encourages the cross-attention maps to agree with the\nlinguistic binding reflected by the syntax. Specifically, we encourage large\noverlap between attention maps of entities and their modifiers, and small\noverlap with other entities and modifier words. The loss is optimized during\ninference, without retraining or fine-tuning the model. Human evaluation on\nthree datasets, including one new and challenging set, demonstrate significant\nimprovements of SynGen compared with current state of the art methods. This\nwork highlights how making use of sentence structure during inference can\nefficiently and substantially improve the faithfulness of text-to-image\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rassin_R/0/1/0/all/0/1\">Royi Rassin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_E/0/1/0/all/0/1\">Eran Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glickman_D/0/1/0/all/0/1\">Daniel Glickman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VELMA: Verbalization Embodiment of LLM Agents for Vision and Language Navigation in Street View. (arXiv:2307.06082v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.06082","description":"<p>Incremental decision making in real-world environments is one of the most\nchallenging tasks in embodied artificial intelligence. One particularly\ndemanding scenario is Vision and Language Navigation~(VLN) which requires\nvisual and natural language understanding as well as spatial and temporal\nreasoning capabilities. The embodied agent needs to ground its understanding of\nnavigation instructions in observations of a real-world environment like Street\nView. Despite the impressive results of LLMs in other research areas, it is an\nongoing problem of how to best connect them with an interactive visual\nenvironment. In this work, we propose VELMA, an embodied LLM agent that uses a\nverbalization of the trajectory and of visual environment observations as\ncontextual prompt for the next action. Visual information is verbalized by a\npipeline that extracts landmarks from the human written navigation instructions\nand uses CLIP to determine their visibility in the current panorama view. We\nshow that VELMA is able to successfully follow navigation instructions in\nStreet View with only two in-context examples. We further finetune the LLM\nagent on a few thousand examples and achieve 25%-30% relative improvement in\ntask completion over the previous state-of-the-art for two datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schumann_R/0/1/0/all/0/1\">Raphael Schumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Weixi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1\">Tsu-Jui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12539","description":"<p>As language models (LMs) become increasingly powerful and widely used, it is\nimportant to quantify them for sociodemographic bias with potential for harm.\nPrior measures of bias are sensitive to perturbations in the templates designed\nto compare performance across social groups, due to factors such as low\ndiversity or limited number of templates. Also, most previous work considers\nonly one NLP task. We introduce Comprehensive Assessment of Language Models\n(CALM) for robust measurement of two types of universally relevant\nsociodemographic bias, gender and race. CALM integrates sixteen datasets for\nquestion-answering, sentiment analysis and natural language inference. Examples\nfrom each dataset are filtered to produce 224 templates with high diversity\n(e.g., length, vocabulary). We assemble 50 highly frequent person names for\neach of seven distinct demographic groups to generate 78,400 prompts covering\nthe three NLP tasks. Our empirical evaluation shows that CALM bias scores are\nmore robust and far less sensitive than previous bias measurements to\nperturbations in the templates, such as synonym substitution, or to random\nsubset selection of templates. We apply CALM to 20 large language models, and\nfind that for 2 language model series, larger parameter models tend to be more\nbiased than smaller ones. The T0 series is the least biased model families, of\nthe 20 LLMs investigated here. The code is available at\nhttps://github.com/vipulgupta1011/CALM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vipul Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1\">Pranav Narayanan Venkit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurencon_H/0/1/0/all/0/1\">Hugo Lauren&#xe7;on</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1\">Shomir Wilson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passonneau_R/0/1/0/all/0/1\">Rebecca J. Passonneau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models. (arXiv:2308.15812v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.15812","description":"<p>Aligning large language models (LLMs) with human values and intents\ncritically involves the use of human or AI feedback. While dense feedback\nannotations are expensive to acquire and integrate, sparse feedback presents a\nstructural design choice between ratings (e.g., score Response A on a scale of\n1-7) and rankings (e.g., is Response A better than Response B?). In this work,\nwe analyze the effect of this design choice for the alignment and evaluation of\nLLMs. We uncover an inconsistency problem wherein the preferences inferred from\nratings and rankings significantly disagree 60% for both human and AI\nannotators. Our subsequent analysis identifies various facets of annotator\nbiases that explain this phenomena, such as human annotators would rate denser\nresponses higher while preferring accuracy during pairwise judgments. To our\nsurprise, we also observe that the choice of feedback protocol also has a\nsignificant effect on the evaluation of aligned LLMs. In particular, we find\nthat LLMs that leverage rankings data for alignment (say model X) are preferred\nover those that leverage ratings data (say model Y), with a rank-based\nevaluation protocol (is X/Y's response better than reference response?) but not\nwith a rating-based evaluation protocol (score Rank X/Y's response on a scale\nof 1-7). Our findings thus shed light on critical gaps in methods for\nevaluating the real-world utility of language models and their strong\ndependence on the feedback protocol used for alignment. Our code and data are\navailable at https://github.com/Hritikbansal/sparse_feedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1\">Hritik Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_J/0/1/0/all/0/1\">John Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1\">Aditya Grover</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Statistical Rejection Sampling Improves Preference Optimization. (arXiv:2309.06657v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06657","description":"<p>Improving the alignment of language models with human preferences remains an\nactive research challenge. Previous approaches have primarily utilized\nReinforcement Learning from Human Feedback (RLHF) via online RL methods such as\nProximal Policy Optimization (PPO). Recently, offline methods such as Sequence\nLikelihood Calibration (SLiC) and Direct Preference Optimization (DPO) have\nemerged as attractive alternatives, offering improvements in stability and\nscalability while maintaining competitive performance. SLiC refines its loss\nfunction using sequence pairs sampled from a supervised fine-tuned (SFT)\npolicy, while DPO directly optimizes language models based on preference data,\nforegoing the need for a separate reward model. However, the maximum likelihood\nestimator (MLE) of the target optimal policy requires labeled preference pairs\nsampled from that policy. DPO's lack of a reward model constrains its ability\nto sample preference pairs from the optimal policy, and SLiC is restricted to\nsampling preference pairs only from the SFT policy. To address these\nlimitations, we introduce a novel approach called Statistical Rejection\nSampling Optimization (RSO) that aims to source preference data from the target\noptimal policy using rejection sampling, enabling a more accurate estimation of\nthe optimal policy. We also propose a unified framework that enhances the loss\nfunctions used in both SLiC and DPO from a preference modeling standpoint.\nThrough extensive experiments across three diverse tasks, we demonstrate that\nRSO consistently outperforms both SLiC and DPO on evaluations from both Large\nLanguage Model (LLM) and human raters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Rishabh Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalman_M/0/1/0/all/0/1\">Misha Khalman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_M/0/1/0/all/0/1\">Mohammad Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peter J. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jialu Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptASR for contextualized ASR with controllable style. (arXiv:2309.07414v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.07414","description":"<p>Prompts are crucial to large language models as they provide context\ninformation such as topic or logical relationships. Inspired by this, we\npropose PromptASR, a framework that integrates prompts in end-to-end automatic\nspeech recognition (E2E ASR) systems to achieve contextualized ASR with\ncontrollable style of transcriptions. Specifically, a dedicated text encoder\nencodes the text prompts and the encodings are injected into the speech encoder\nby cross-attending the features from two modalities. When using the ground\ntruth text from preceding utterances as content prompt, the proposed system\nachieves 21.9% and 6.8% relative word error rate reductions on a book reading\ndataset and an in-house dataset compared to a baseline ASR system. The system\ncan also take word-level biasing lists as prompt to improve recognition\naccuracy on rare words. An additional style prompt can be given to the text\nencoder and guide the ASR system to output different styles of transcriptions.\nThe code is available at icefall.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoyu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kang_W/0/1/0/all/0/1\">Wei Kang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yao_Z/0/1/0/all/0/1\">Zengwei Yao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_L/0/1/0/all/0/1\">Liyong Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kuang_F/0/1/0/all/0/1\">Fangjun Kuang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_L/0/1/0/all/0/1\">Long Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Povey_D/0/1/0/all/0/1\">Daniel Povey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reward Engineering for Generating Semi-structured Explanation. (arXiv:2309.08347v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08347","description":"<p>Semi-structured explanation depicts the implicit process of a reasoner with\nan explicit representation. This explanation highlights how available\ninformation in a specific query is utilised and supplemented with information a\nreasoner produces from its internal weights towards generating an answer.\nDespite the recent improvements in generative capabilities of language models,\nproducing structured explanations to verify a model's true reasoning\ncapabilities remains a challenge. This issue is particularly pronounced for\nnot-so-large LMs (e.g., FLAN-T5-XXL). In this work, we first underscore the\nlimitations of supervised fine-tuning (SFT) in tackling this challenge, and\nthen introduce a carefully crafted reward engineering method in reinforcement\nlearning (RL) to better address this problem. We investigate multiple reward\naggregation methods and provide a detailed discussion which sheds light on the\npromising potential of RL for future research. Our proposed method on two\nsemi-structured explanation generation benchmarks (ExplaGraph and COPA-SSE)\nachieves new state-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiuzhou Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1\">Wray Buntine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08565","description":"<p>Customizing machine translation models to comply with desired attributes\n(e.g., formality or grammatical gender) is a well-studied topic. However, most\ncurrent approaches rely on (semi-)supervised data with attribute annotations.\nThis data scarcity bottlenecks democratizing such customization possibilities\nto a wider range of languages, particularly lower-resource ones. This gap is\nout of sync with recent progress in pretrained massively multilingual\ntranslation models. In response, we transfer the attribute controlling\ncapabilities to languages without attribute-annotated data with an NLLB-200\nmodel as a foundation. Inspired by techniques from controllable generation, we\nemploy a gradient-based inference-time controller to steer the pretrained\nmodel. The controller transfers well to zero-shot conditions, as it operates on\npretrained multilingual representations and is attribute -- rather than\nlanguage-specific. With a comprehensive comparison to finetuning-based control,\nwe demonstrate that, despite finetuning's clear dominance in supervised\nsettings, the gap to inference-time control closes when moving to zero-shot\nconditions, especially with new and distant target languages. The latter also\nshows stronger domain robustness. We further show that our inference-time\ncontrol complements finetuning. A human evaluation on a real low-resource\nlanguage, Bengali, confirms our findings. Our code is\nhttps://github.com/dannigt/attribute-controller-transfer\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Danni Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1\">Jan Niehues</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering. (arXiv:2309.17249v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.17249","description":"<p>Prompting and in-context learning (ICL) have become efficient learning\nparadigms for large language models (LLMs). However, LLMs suffer from prompt\nbrittleness and various bias factors in the prompt, including but not limited\nto the formatting, the choice verbalizers, and the ICL examples. To address\nthis problem that results in unexpected performance degradation, calibration\nmethods have been developed to mitigate the effects of these biases while\nrecovering LLM performance. In this work, we first conduct a systematic\nanalysis of the existing calibration methods, where we both provide a unified\nview and reveal the failure cases. Inspired by these analyses, we propose Batch\nCalibration (BC), a simple yet intuitive method that controls the contextual\nbias from the batched input, unifies various prior approaches, and effectively\naddresses the aforementioned issues. BC is zero-shot, inference-only, and\nincurs negligible additional costs. In the few-shot setup, we further extend BC\nto allow it to learn the contextual bias from labeled data. We validate the\neffectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate\nstate-of-the-art performance over previous calibration baselines across more\nthan 10 natural language understanding and image classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proleev_L/0/1/0/all/0/1\">Lev Proleev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1\">Diana Mincu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1\">Katherine Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Subhrajit Roy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns. (arXiv:2310.01749v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01749","description":"<p>Attention, specifically scaled dot-product attention, has proven effective\nfor natural language, but it does not have a mechanism for handling\nhierarchical patterns of arbitrary nesting depth, which limits its ability to\nrecognize certain syntactic structures. To address this shortcoming, we propose\nstack attention: an attention operator that incorporates stacks, inspired by\ntheir theoretical connections to context-free languages (CFLs). We show that\nstack attention is analogous to standard attention, but with a latent model of\nsyntax that requires no syntactic supervision. We propose two variants: one\nrelated to deterministic pushdown automata (PDAs) and one based on\nnondeterministic PDAs, which allows transformers to recognize arbitrary CFLs.\nWe show that transformers with stack attention are very effective at learning\nCFLs that standard transformers struggle on, achieving strong results on a CFL\nwith theoretically maximal parsing difficulty. We also show that stack\nattention is more effective at natural language modeling under a constrained\nparameter budget, and we include results on machine translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DuSell_B/0/1/0/all/0/1\">Brian DuSell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1\">David Chiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Health Agents: A Personalized LLM-Powered Agent Framework. (arXiv:2310.02374v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02374","description":"<p>Conversational Health Agents (CHAs) are interactive systems that provide\nhealthcare services, such as assistance and diagnosis. Current CHAs, especially\nthose utilizing Large Language Models (LLMs), primarily focus on conversation\naspects. However, they offer limited agent capabilities, specifically lacking\nmulti-step problem-solving, personalized conversations, and multimodal data\nanalysis. Our aim is to overcome these limitations. We propose openCHA, an\nopen-source LLM-powered framework, to empower conversational agents to generate\na personalized response for users' healthcare queries. This framework enables\ndevelopers to integrate external sources including data sources, knowledge\nbases, and analysis models, into their LLM-based solutions. openCHA includes an\norchestrator to plan and execute actions for gathering information from\nexternal sources, essential for formulating responses to user inquiries. It\nfacilitates knowledge acquisition, problem-solving capabilities, multilingual\nand multimodal conversations, and fosters interaction with various AI\nplatforms. We illustrate the framework's proficiency in handling complex\nhealthcare tasks via three demonstrations. Moreover, we release openCHA as open\nsource available to the community via GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abbasian_M/0/1/0/all/0/1\">Mahyar Abbasian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azimi_I/0/1/0/all/0/1\">Iman Azimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1\">Amir M. Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Ramesh Jain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Formally Specifying the High-Level Behavior of LLM-Based Agents. (arXiv:2310.08535v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.08535","description":"<p>Autonomous, goal-driven agents powered by LLMs have recently emerged as\npromising tools for solving challenging problems without the need for\ntask-specific finetuned models that can be expensive to procure. Currently, the\ndesign and implementation of such agents is ad hoc, as the wide variety of\ntasks that LLM-based agents may be applied to naturally means there can be no\none-size-fits-all approach to agent design. In this work we aim to alleviate\nthe difficulty of designing and implementing new agents by proposing a\nminimalistic generation framework that simplifies the process of building\nagents. The framework we introduce allows the user to define desired agent\nbehaviors in a high-level, declarative specification that is then used to\nconstruct a decoding monitor which guarantees the LLM will produce an output\nexhibiting the desired behavior. Our declarative approach, in which the\nbehavior is described without concern for how it should be implemented or\nenforced, enables rapid design, implementation, and experimentation with\ndifferent LLM-based agents. We demonstrate how the proposed framework can be\nused to implement recent LLM-based agents (e.g., ReACT), and show how the\nflexibility of our approach can be leveraged to define a new agent with more\ncomplex behavior, the Plan-Act-Summarize-Solve (PASS) agent. Lastly, we\ndemonstrate that our method outperforms other agents on multiple popular\nreasoning-centric question-answering benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1\">Maxwell Crouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1\">Ibrahim Abdelaziz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1\">Ramon Astudillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_K/0/1/0/all/0/1\">Kinjal Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1\">Soham Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaravel_S/0/1/0/all/0/1\">Sadhana Kumaravel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fokoue_A/0/1/0/all/0/1\">Achille Fokoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1\">Pavan Kapanipathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lastras_L/0/1/0/all/0/1\">Luis Lastras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Baseline Analysis of Reward Models' Ability To Accurately Analyze Foundation Models Under Distribution Shift. (arXiv:2311.14743v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.14743","description":"<p>Foundation models, specifically Large Language Models (LLMs), have lately\ngained wide-spread attention and adoption. Reinforcement Learning with Human\nFeedback (RLHF) involves training a reward model to capture desired behaviors,\nwhich is then used to align LLM's. These reward models are additionally used at\ninference-time to estimate LLM responses' adherence to those desired behaviors.\nHowever, there is little work measuring how robust these reward models are to\ndistribution shifts. In this work, we evaluate how reward model performance -\nmeasured via accuracy and calibration (i.e. alignment between accuracy and\nconfidence) - is affected by distribution shift. We show novel calibration\npatterns and accuracy drops due to OOD prompts and responses, and that the\nreward model is more sensitive to shifts in responses than prompts.\nAdditionally, we adapt an OOD detection technique commonly used in\nclassification to the reward model setting to detect these distribution shifts\nin prompts and responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+LeVine_W/0/1/0/all/0/1\">Will LeVine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pikus_B/0/1/0/all/0/1\">Benjamin Pikus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendryx_S/0/1/0/all/0/1\">Sean Hendryx</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Modeling on a SpiNNaker 2 Neuromorphic Chip. (arXiv:2312.09084v3 [cs.NE] UPDATED)","link":"http://arxiv.org/abs/2312.09084","description":"<p>As large language models continue to scale in size rapidly, so too does the\ncomputational power required to run them. Event-based networks on neuromorphic\ndevices offer a potential way to reduce energy consumption for inference\nsignificantly. However, to date, most event-based networks that can run on\nneuromorphic hardware, including spiking neural networks (SNNs), have not\nachieved task performance even on par with LSTM models for language modeling.\nAs a result, language modeling on neuromorphic devices has seemed a distant\nprospect. In this work, we demonstrate the first-ever implementation of a\nlanguage model on a neuromorphic device - specifically the SpiNNaker 2 chip -\nbased on a recently published event-based architecture called the EGRU.\nSpiNNaker 2 is a many-core neuromorphic chip designed for large-scale\nasynchronous processing, while the EGRU is architected to leverage such\nhardware efficiently while maintaining competitive task performance. This\nimplementation marks the first time a neuromorphic language model matches\nLSTMs, setting the stage for taking task performance to the level of large\nlanguage models. We also demonstrate results on a gesture recognition task\nbased on inputs from a DVS camera. Overall, our results showcase the\nfeasibility of this neuro-inspired neural network in hardware, highlighting\nsignificant gains versus conventional hardware in energy efficiency for the\ncommon use case of single batch inference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nazeer_K/0/1/0/all/0/1\">Khaleelulla Khan Nazeer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schone_M/0/1/0/all/0/1\">Mark Sch&#xf6;ne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherji_R/0/1/0/all/0/1\">Rishav Mukherji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogginger_B/0/1/0/all/0/1\">Bernhard Vogginger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayr_C/0/1/0/all/0/1\">Christian Mayr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kappel_D/0/1/0/all/0/1\">David Kappel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramoney_A/0/1/0/all/0/1\">Anand Subramoney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLP for Maternal Healthcare: Perspectives and Guiding Principles in the Age of LLMs. (arXiv:2312.11803v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.11803","description":"<p>Ethical frameworks for the use of natural language processing (NLP) are\nurgently needed to shape how large language models (LLMs) and similar tools are\nused for healthcare applications. Healthcare faces existing challenges\nincluding the balance of power in clinician-patient relationships, systemic\nhealth disparities, historical injustices, and economic constraints. Drawing\ndirectly from the voices of those most affected, and focusing on a case study\nof a specific healthcare setting, we propose a set of guiding principles for\nthe use of NLP in maternal healthcare. We led an interactive session centered\non an LLM-based chatbot demonstration during a full-day workshop with 39\nparticipants, and additionally surveyed 30 healthcare workers and 30 birthing\npeople about their values, needs, and perceptions of NLP tools in the context\nof maternal health. We conducted quantitative and qualitative analyses of the\nsurvey results and interactive discussions to consolidate our findings into a\nset of guiding principles. We propose nine principles for ethical use of NLP\nfor maternal healthcare, grouped into three themes: (i) recognizing contextual\nsignificance (ii) holistic measurements, and (iii) who/what is valued. For each\nprinciple, we describe its underlying rationale and provide practical advice.\nThis set of principles can provide a methodological pattern for other\nresearchers and serve as a resource to practitioners working on maternal health\nand other healthcare fields to emphasize the importance of technical nuance,\nhistorical context, and inclusive design when developing NLP technologies for\nclinical use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Antoniak_M/0/1/0/all/0/1\">Maria Antoniak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_A/0/1/0/all/0/1\">Aakanksha Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarado_C/0/1/0/all/0/1\">Carla S. Alvarado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lucy Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_I/0/1/0/all/0/1\">Irene Y. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuning and Utilization Methods of Domain-specific LLMs. (arXiv:2401.02981v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.02981","description":"<p>Recent releases of pre-trained Large Language Models (LLMs) have gained\nconsiderable traction, yet research on fine-tuning and employing\ndomain-specific LLMs remains scarce. This study investigates approaches for\nfine-tuning and leveraging domain-specific LLMs, highlighting trends in LLMs,\nfoundational models, and methods for domain-specific pre-training. Focusing on\nthe financial sector, it details dataset selection, preprocessing, model\nchoice, and considerations crucial for LLM fine-tuning in finance. Addressing\nthe unique characteristics of financial data, the study explores the\nconstruction of domain-specific vocabularies and considerations for security\nand regulatory compliance. In the practical application of LLM fine-tuning, the\nstudy outlines the procedure and implementation for generating domain-specific\nLLMs in finance. Various financial cases, including stock price prediction,\nsentiment analysis of financial news, automated document processing, research,\ninformation extraction, and customer service enhancement, are exemplified. The\nstudy explores the potential of LLMs in the financial domain, identifies\nlimitations, and proposes directions for improvement, contributing valuable\ninsights for future research. Ultimately, it advances natural language\nprocessing technology in business, suggesting proactive LLM utilization in\nfinancial services across industries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1\">Cheonsu Jeong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Johnny Can Persuade LLMs to Jailbreak Them: Rethinking Persuasion to Challenge AI Safety by Humanizing LLMs. (arXiv:2401.06373v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.06373","description":"<p>Most traditional AI safety research has approached AI models as machines and\ncentered on algorithm-focused attacks developed by security experts. As large\nlanguage models (LLMs) become increasingly common and competent, non-expert\nusers can also impose risks during daily interactions. This paper introduces a\nnew perspective to jailbreak LLMs as human-like communicators, to explore this\noverlooked intersection between everyday language interaction and AI safety.\nSpecifically, we study how to persuade LLMs to jailbreak them. First, we\npropose a persuasion taxonomy derived from decades of social science research.\nThen, we apply the taxonomy to automatically generate interpretable persuasive\nadversarial prompts (PAP) to jailbreak LLMs. Results show that persuasion\nsignificantly increases the jailbreak performance across all risk categories:\nPAP consistently achieves an attack success rate of over $92\\%$ on Llama 2-7b\nChat, GPT-3.5, and GPT-4 in $10$ trials, surpassing recent algorithm-focused\nattacks. On the defense side, we explore various mechanisms against PAP and,\nfound a significant gap in existing defenses, and advocate for more fundamental\nmitigation for highly interactive LLMs\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongpeng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2401.06461","description":"<p>Large language models have catalyzed an unprecedented wave in code\ngeneration. While achieving significant advances, they blur the distinctions\nbetween machine-and human-authored source code, causing integrity and\nauthenticity issues of software artifacts. Previous methods such as DetectGPT\nhave proven effective in discerning machine-generated texts, but they do not\nidentify and harness the unique patterns of machine-generated code. Thus, its\napplicability falters when applied to code. In this paper, we carefully study\nthe specific patterns that characterize machine and human-authored code.\nThrough a rigorous analysis of code attributes such as length, lexical\ndiversity, and naturalness, we expose unique pat-terns inherent to each source.\nWe particularly notice that the structural segmentation of code is a critical\nfactor in identifying its provenance. Based on our findings, we propose a novel\nmachine-generated code detection method called DetectCodeGPT, which improves\nDetectGPT by capturing the distinct structural patterns of code. Diverging from\nconventional techniques that depend on external LLMs for perturbations,\nDetectCodeGPT perturbs the code corpus by strategically inserting spaces and\nnewlines, ensuring both efficacy and efficiency. Experiment results show that\nour approach significantly outperforms state-of-the-art techniques in detecting\nmachine-generated code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuling Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Chengcheng Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1\">Xiaodong Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine. (arXiv:2401.08396v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2401.08396","description":"<p>Recent studies indicate that Generative Pre-trained Transformer 4 with Vision\n(GPT-4V) outperforms human physicians in medical challenge tasks. However,\nthese evaluations primarily focused on the accuracy of multi-choice questions\nalone. Our study extends the current scope by conducting a comprehensive\nanalysis of GPT-4V's rationales of image comprehension, recall of medical\nknowledge, and step-by-step multimodal reasoning when solving New England\nJournal of Medicine (NEJM) Image Challenges - an imaging quiz designed to test\nthe knowledge and diagnostic capabilities of medical professionals. Evaluation\nresults confirmed that GPT-4V outperforms human physicians regarding\nmulti-choice accuracy (88.0% vs. 77.0%, p=0.034). GPT-4V also performs well in\ncases where physicians incorrectly answer, with over 80% accuracy. However, we\ndiscovered that GPT-4V frequently presents flawed rationales in cases where it\nmakes the correct final choices (27.3%), most prominent in image comprehension\n(21.6%). Regardless of GPT-4V's high accuracy in multi-choice questions, our\nfindings emphasize the necessity for further in-depth evaluations of its\nrationales before integrating such models into clinical workflows.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fangyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yiliang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_J/0/1/0/all/0/1\">Justin M. Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Robert Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Summers_R/0/1/0/all/0/1\">Ronald M. Summers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rousseau_J/0/1/0/all/0/1\">Justin F. Rousseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_P/0/1/0/all/0/1\">Peiyun Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landsman_M/0/1/0/all/0/1\">Marc J Landsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baxter_S/0/1/0/all/0/1\">Sally L. Baxter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlAref_S/0/1/0/all/0/1\">Subhi J. Al&#x27;Aref</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yijia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1\">Michael F. Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring. (arXiv:2401.08517v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2401.08517","description":"<p>Student commitment towards a learning recommendation is not separable from\ntheir understanding of the reasons it was recommended to them; and their\nability to modify it based on that understanding. Among explainability\napproaches, chatbots offer the potential to engage the student in a\nconversation, similar to a discussion with a peer or a mentor. The capabilities\nof chatbots, however, are still not sufficient to replace a human mentor,\ndespite the advancements of generative AI (GenAI) and large language models\n(LLM). Therefore, we propose an approach to utilize chatbots as mediators of\nthe conversation and sources of limited and controlled generation of\nexplanations, to harvest the potential of LLMs while reducing their potential\nrisks at the same time. The proposed LLM-based chatbot supports students in\nunderstanding learning-paths recommendations. We use a knowledge graph (KG) as\na human-curated source of information, to regulate the LLM's output through\ndefining its prompt's context. A group chat approach is developed to connect\nstudents with human mentors, either on demand or in cases that exceed the\nchatbot's pre-defined tasks. We evaluate the chatbot with a user study, to\nprovide a proof-of-concept and highlight the potential requirements and\nlimitations of utilizing chatbots in conversational explainability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abu_Rasheed_H/0/1/0/all/0/1\">Hasan Abu-Rasheed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulsalam_M/0/1/0/all/0/1\">Mohamad Hussam Abdulsalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1\">Christian Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fathi_M/0/1/0/all/0/1\">Madjid Fathi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using LLMs to discover emerging coded antisemitic hate-speech in extremist social media. (arXiv:2401.10841v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.10841","description":"<p>Online hate speech proliferation has created a difficult problem for social\nmedia platforms. A particular challenge relates to the use of coded language by\ngroups interested in both creating a sense of belonging for its users and\nevading detection. Coded language evolves quickly and its use varies over time.\nThis paper proposes a methodology for detecting emerging coded hate-laden\nterminology. The methodology is tested in the context of online antisemitic\ndiscourse. The approach considers posts scraped from social media platforms,\noften used by extremist users. The posts are scraped using seed expressions\nrelated to previously known discourse of hatred towards Jews. The method begins\nby identifying the expressions most representative of each post and calculating\ntheir frequency in the whole corpus. It filters out grammatically incoherent\nexpressions as well as previously encountered ones so as to focus on emergent\nwell-formed terminology. This is followed by an assessment of semantic\nsimilarity to known antisemitic terminology using a fine-tuned large language\nmodel, and subsequent filtering out of the expressions that are too distant\nfrom known expressions of hatred. Emergent antisemitic expressions containing\nterms clearly relating to Jewish topics are then removed to return only coded\nexpressions of hatred.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kikkisetti_D/0/1/0/all/0/1\">Dhanush Kikkisetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mustafa_R/0/1/0/all/0/1\">Raza Ul Mustafa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melillo_W/0/1/0/all/0/1\">Wendy Melillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corizzo_R/0/1/0/all/0/1\">Roberto Corizzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boukouvalas_Z/0/1/0/all/0/1\">Zois Boukouvalas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gill_J/0/1/0/all/0/1\">Jeff Gill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1\">Nathalie Japkowicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines. (arXiv:2401.11120v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.11120","description":"<p>Background Large Language Models (LLMs), enhanced with Clinical Practice\nGuidelines (CPGs), can significantly improve Clinical Decision Support (CDS).\nHowever, methods for incorporating CPGs into LLMs are not well studied. Methods\nWe develop three distinct methods for incorporating CPGs into LLMs: Binary\nDecision Tree (BDT), Program-Aided Graph Construction (PAGC), and\nChain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of\nthe proposed methods, we create a set of synthetic patient descriptions and\nconduct both automatic and human evaluation of the responses generated by four\nLLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was\nused as the baseline method. We focus on CDS for COVID-19 outpatient treatment\nas the case study. Results All four LLMs exhibit improved performance when\nenhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP\nand PAGC in automatic evaluation. All of the proposed methods demonstrated high\nperformance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate\nsuperior performance, as compared to plain LLMs with ZSP, in providing accurate\nrecommendations for COVID-19 outpatient treatment, which also highlights the\npotential for broader applications beyond the case study.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1\">David Oniani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xizhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Visweswaran_S/0/1/0/all/0/1\">Shyam Visweswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sumit Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kooragayalu_S/0/1/0/all/0/1\">Shravan Kooragayalu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polanska_K/0/1/0/all/0/1\">Katelyn Polanska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanshan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Anisotropy Is Inherent to Self-Attention in Transformers. (arXiv:2401.12143v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.12143","description":"<p>The representation degeneration problem is a phenomenon that is widely\nobserved among self-supervised learning methods based on Transformers. In NLP,\nit takes the form of anisotropy, a singular property of hidden representations\nwhich makes them unexpectedly close to each other in terms of angular distance\n(cosine-similarity). Some recent works tend to show that anisotropy is a\nconsequence of optimizing the cross-entropy loss on long-tailed distributions\nof tokens. We show in this paper that anisotropy can also be observed\nempirically in language models with specific objectives that should not suffer\ndirectly from the same consequences. We also show that the anisotropy problem\nextends to Transformers trained on other modalities. Our observations suggest\nthat anisotropy is actually inherent to Transformers-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Godey_N/0/1/0/all/0/1\">Nathan Godey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clergerie_E/0/1/0/all/0/1\">&#xc9;ric de la Clergerie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagot_B/0/1/0/all/0/1\">Beno&#xee;t Sagot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-24T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}