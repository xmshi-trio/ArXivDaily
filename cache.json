{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-10T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Working with Trouble and Failures in Conversation between Humans and Robots (WTF 2023) & Is CUI Design Ready Yet?. (arXiv:2401.04108v1 [cs.HC])","link":"http://arxiv.org/abs/2401.04108","description":"<p>Workshop proceedings of two co-located workshops \"Working with Troubles and\nFailures in Conversation with Humans and Robots\" (WTF 2023) and \"Is CUI Design\nReady Yet?\", both of which were part of the ACM conference on conversational\nuser interfaces 2023.\n</p>\n<p>WTF 23 aimed at bringing together researchers from human-robot interaction,\ndialogue systems, human-computer interaction, and conversation analysis.\nDespite all progress, robotic speech interfaces continue to be brittle in a\nnumber of ways and the experience of failure of such interfaces is commonplace\namongst roboticists. However, the technical literature is positively skewed\ntoward their good performance. The workshop aims to provide a platform for\ndiscussing communicative troubles and failures in human-robot interactions and\nrelated failures in non-robotic speech interfaces. Aims include a scrupulous\ninvestigation into communicative failures, to begin working on a taxonomy of\nsuch failures, and enable a preliminary discussion on possible mitigating\nstrategies. Workshop website: https://sites.google.com/view/wtf2023/overview\n</p>\n<p>Is CUI Design Ready Yet? As CUIs become more prevalent in both academic\nresearch and the commercial market, it becomes more essential to design usable\nand adoptable CUIs. While research has been growing on the methods for\ndesigning CUIs for commercial use, there has been little discussion on the\noverall community practice of developing design resources to aid in practical\nCUI design. The aim of this workshop, therefore, is to bring the CUI community\ntogether to discuss the current practices for developing tools and resources\nfor practical CUI design, the adoption (or non-adoption) of these tools and\nresources, and how these resources are utilized in the training and education\nof new CUI designers entering the field. Workshop website:\nhttps://speech-interaction.org/cui2023_design_workshop/index.html\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Forster_F/0/1/0/all/0/1\">Frank F&#xf6;rster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romeo_M/0/1/0/all/0/1\">Marta Romeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holthaus_P/0/1/0/all/0/1\">Patrick Holthaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trigo_M/0/1/0/all/0/1\">Maria Jose Galvez Trigo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_J/0/1/0/all/0/1\">Joel E. Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nesset_B/0/1/0/all/0/1\">Birthe Nesset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dondrup_C/0/1/0/all/0/1\">Christian Dondrup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murad_C/0/1/0/all/0/1\">Christine Murad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munteanu_C/0/1/0/all/0/1\">Cosmin Munteanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cowan_B/0/1/0/all/0/1\">Benjamin R. Cowan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_L/0/1/0/all/0/1\">Leigh Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porcheron_M/0/1/0/all/0/1\">Martin Porcheron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candello_H/0/1/0/all/0/1\">Heloisa Candello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langevin_R/0/1/0/all/0/1\">Raina Langevin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generation Z's Ability to Discriminate Between AI-generated and Human-Authored Text on Discord. (arXiv:2401.04120v1 [cs.HC])","link":"http://arxiv.org/abs/2401.04120","description":"<p>The growing popularity of generative artificial intelligence (AI) chatbots\nsuch as ChatGPT is having transformative effects on social media. As the\nprevalence of AI-generated content grows, concerns have been raised regarding\nprivacy and misinformation online. Among social media platforms, Discord\nenables AI integrations -- making their primarily \"Generation Z\" userbase\nparticularly exposed to AI-generated content. We surveyed Generation Z aged\nindividuals (n = 335) to evaluate their proficiency in discriminating between\nAI-generated and human-authored text on Discord. The investigation employed\none-shot prompting of ChatGPT, disguised as a text message received on the\nDiscord.com platform. We explore the influence of demographic factors on\nability, as well as participants' familiarity with Discord and artificial\nintelligence technologies. We find that Generation Z individuals are unable to\ndiscern between AI and human-authored text (p = 0.011), and that those with\nlower self-reported familiarity with Discord demonstrated an improved ability\nin identifying human-authored compared to those with self-reported experience\nwith AI (p &lt;&lt; 0.0001). Our results suggest that there is a nuanced relationship\nbetween AI technology and popular modes of communication for Generation Z,\ncontributing valuable insights into human-computer interactions, digital\ncommunication, and artificial intelligence literacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramu_D/0/1/0/all/0/1\">Dhruv Ramu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Rishab Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Aditya Jain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain of LoRA: Efficient Fine-tuning of Language Models via Residual Learning. (arXiv:2401.04151v1 [cs.LG])","link":"http://arxiv.org/abs/2401.04151","description":"<p>Fine-tuning is the primary methodology for tailoring pre-trained large\nlanguage models to specific tasks. As the model's scale and the diversity of\ntasks expand, parameter-efficient fine-tuning methods are of paramount\nimportance. One of the most widely used family of methods is low-rank\nadaptation (LoRA) and its variants. LoRA encodes weight update as the product\nof two low-rank matrices. Despite its advantages, LoRA falls short of\nfull-parameter fine-tuning in terms of generalization error for certain tasks.\n</p>\n<p>We introduce Chain of LoRA (COLA), an iterative optimization framework\ninspired by the Frank-Wolfe algorithm, to bridge the gap between LoRA and full\nparameter fine-tuning, without incurring additional computational costs or\nmemory overheads. COLA employs a residual learning procedure where it merges\nlearned LoRA modules into the pre-trained language model parameters and\nre-initilize optimization for new born LoRA modules. We provide theoretical\nconvergence guarantees as well as empirical results to validate the\neffectiveness of our algorithm. Across various models (OPT and llama-2) and\nseven benchmarking tasks, we demonstrate that COLA can consistently outperform\nLoRA without additional computational or memory costs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1\">Wenhan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazan_E/0/1/0/all/0/1\">Elad Hazan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Speaker Encoding Network for Multi-Talker Speech Recognition. (arXiv:2401.04152v1 [cs.SD])","link":"http://arxiv.org/abs/2401.04152","description":"<p>End-to-end multi-talker speech recognition has garnered great interest as an\neffective approach to directly transcribe overlapped speech from multiple\nspeakers. Current methods typically adopt either 1) single-input\nmultiple-output (SIMO) models with a branched encoder, or 2) single-input\nsingle-output (SISO) models based on attention-based encoder-decoder\narchitecture with serialized output training (SOT). In this work, we propose a\nCross-Speaker Encoding (CSE) network to address the limitations of SIMO models\nby aggregating cross-speaker representations. Furthermore, the CSE model is\nintegrated with SOT to leverage both the advantages of SIMO and SISO while\nmitigating their drawbacks. To the best of our knowledge, this work represents\nan early effort to integrate SIMO and SISO for multi-talker speech recognition.\nExperiments on the two-speaker LibrispeechMix dataset show that the CES model\nreduces word error rate (WER) by 8% over the SIMO baseline. The CSE-SOT model\nreduces WER by 10% overall and by 16% on high-overlap speech compared to the\nSOT model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jiawen Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Lingwei Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1\">Mingyu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Haohan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xixin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xunying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large language models in bioinformatics: applications and perspectives. (arXiv:2401.04155v1 [q-bio.QM])","link":"http://arxiv.org/abs/2401.04155","description":"<p>Large language models (LLMs) are a class of artificial intelligence models\nbased on deep learning, which have great performance in various tasks,\nespecially in natural language processing (NLP). Large language models\ntypically consist of artificial neural networks with numerous parameters,\ntrained on large amounts of unlabeled input using self-supervised or\nsemi-supervised learning. However, their potential for solving bioinformatics\nproblems may even exceed their proficiency in modeling human language. In this\nreview, we will present a summary of the prominent large language models used\nin natural language processing, such as BERT and GPT, and focus on exploring\nthe applications of large language models at different omics levels in\nbioinformatics, mainly including applications of large language models in\ngenomics, transcriptomics, proteomics, drug discovery and single cell analysis.\nFinally, this review summarizes the potential and prospects of large language\nmodels in solving bioinformatic problems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_J/0/1/0/all/0/1\">Jiajia Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yang_M/0/1/0/all/0/1\">Mengyuan Yang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Yu_Y/0/1/0/all/0/1\">Yankai Yu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_H/0/1/0/all/0/1\">Haixia Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_K/0/1/0/all/0/1\">Kang Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaobo Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FunnyNet-W: Multimodal Learning of Funny Moments in Videos in the Wild. (arXiv:2401.04210v1 [cs.CV])","link":"http://arxiv.org/abs/2401.04210","description":"<p>Automatically understanding funny moments (i.e., the moments that make people\nlaugh) when watching comedy is challenging, as they relate to various features,\nsuch as body language, dialogues and culture. In this paper, we propose\nFunnyNet-W, a model that relies on cross- and self-attention for visual, audio\nand text data to predict funny moments in videos. Unlike most methods that rely\non ground truth data in the form of subtitles, in this work we exploit\nmodalities that come naturally with videos: (a) video frames as they contain\nvisual information indispensable for scene understanding, (b) audio as it\ncontains higher-level cues associated with funny moments, such as intonation,\npitch and pauses and (c) text automatically extracted with a speech-to-text\nmodel as it can provide rich information when processed by a Large Language\nModel. To acquire labels for training, we propose an unsupervised approach that\nspots and labels funny audio moments. We provide experiments on five datasets:\nthe sitcoms TBBT, MHD, MUStARD, Friends, and the TED talk UR-Funny. Extensive\nexperiments and analysis show that FunnyNet-W successfully exploits visual,\nauditory and textual cues to identify funny moments, while our findings reveal\nFunnyNet-W's ability to predict funny moments in the wild. FunnyNet-W sets the\nnew state of the art for funny moment detection with multimodal cues on all\ndatasets with and without using ground truth information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhi-Song Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Courant_R/0/1/0/all/0/1\">Robin Courant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalogeiton_V/0/1/0/all/0/1\">Vicky Kalogeiton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distortions in Judged Spatial Relations in Large Language Models: The Dawn of Natural Language Geographic Data?. (arXiv:2401.04218v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04218","description":"<p>We present a benchmark for assessing the capability of Large Language Models\n(LLMs) to discern intercardinal directions between geographic locations and\napply it to three prominent LLMs: GPT-3.5, GPT-4, and Llama-2. This benchmark\nspecifically evaluates whether LLMs exhibit a hierarchical spatial bias similar\nto humans, where judgments about individual locations' spatial relationships\nare influenced by the perceived relationships of the larger groups that contain\nthem. To investigate this, we formulated 14 questions focusing on well-known\nAmerican cities. Seven questions were designed to challenge the LLMs with\nscenarios potentially influenced by the orientation of larger geographical\nunits, such as states or countries, while the remaining seven targeted\nlocations less susceptible to such hierarchical categorization. Among the\ntested models, GPT-4 exhibited superior performance with 55.3% accuracy,\nfollowed by GPT-3.5 at 47.3%, and Llama-2 at 44.7%. The models showed\nsignificantly reduced accuracy on tasks with suspected hierarchical bias. For\nexample, GPT-4's accuracy dropped to 32.9% on these tasks, compared to 85.7% on\nothers. Despite these inaccuracies, the models identified the nearest cardinal\ndirection in most cases, suggesting associative learning, embodying human-like\nmisconceptions. We discuss the potential of text-based data representing\ngeographic relationships directly to improve the spatial reasoning capabilities\nof LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fulman_N/0/1/0/all/0/1\">Nir Fulman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Memduhoglu_A/0/1/0/all/0/1\">Abdulkadir Memduho&#x11f;lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zipf_A/0/1/0/all/0/1\">Alexander Zipf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"High-precision Voice Search Query Correction via Retrievable Speech-text Embedings. (arXiv:2401.04235v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04235","description":"<p>Automatic speech recognition (ASR) systems can suffer from poor recall for\nvarious reasons, such as noisy audio, lack of sufficient training data, etc.\n</p>\n<p>Previous work has shown that recall can be improved by retrieving rewrite\ncandidates from a large database of likely, contextually-relevant alternatives\nto the hypothesis text using nearest-neighbors search over embeddings of the\nASR hypothesis text to correct and candidate corrections.\n</p>\n<p>However, ASR-hypothesis-based retrieval can yield poor precision if the\ntextual hypotheses are too phonetically dissimilar to the transcript truth. In\nthis paper, we eliminate the hypothesis-audio mismatch problem by querying the\ncorrection database directly using embeddings derived from the utterance audio;\nthe embeddings of the utterance audio and candidate corrections are produced by\nmultimodal speech-text embedding networks trained to place the embedding of the\naudio of an utterance and the embedding of its corresponding textual transcript\nclose together.\n</p>\n<p>After locating an appropriate correction candidate using nearest-neighbor\nsearch, we score the candidate with its speech-text embedding distance before\nadding the candidate to the original n-best list.\n</p>\n<p>We show a relative word error rate (WER) reduction of 6% on utterances whose\ntranscripts appear in the candidate set, without increasing WER on general\nutterances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Christopher Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Gary Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kastner_K/0/1/0/all/0/1\">Kyle Kastner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Heng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Allen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosenberg_A/0/1/0/all/0/1\">Andrew Rosenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhehuai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zelin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velikovich_L/0/1/0/all/0/1\">Leonid Velikovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rondon_P/0/1/0/all/0/1\">Pat Rondon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caseiro_D/0/1/0/all/0/1\">Diamantino Caseiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aleksic_P/0/1/0/all/0/1\">Petar Aleksic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MARG: Multi-Agent Review Generation for Scientific Papers. (arXiv:2401.04259v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04259","description":"<p>We study the ability of LLMs to generate feedback for scientific papers and\ndevelop MARG, a feedback generation approach using multiple LLM instances that\nengage in internal discussion. By distributing paper text across agents, MARG\ncan consume the full text of papers beyond the input length limitations of the\nbase LLM, and by specializing agents and incorporating sub-tasks tailored to\ndifferent comment types (experiments, clarity, impact) it improves the\nhelpfulness and specificity of feedback. In a user study, baseline methods\nusing GPT-4 were rated as producing generic or very generic comments more than\nhalf the time, and only 1.7 comments per paper were rated as good overall in\nthe best baseline. Our system substantially improves the ability of GPT-4 to\ngenerate specific and helpful feedback, reducing the rate of generic comments\nfrom 60% to 29% and generating 3.7 good comments per paper (a 2.2x\nimprovement).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DArcy_M/0/1/0/all/0/1\">Mike D&#x27;Arcy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birnbaum_L/0/1/0/all/0/1\">Larry Birnbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vision Reimagined: AI-Powered Breakthroughs in WiFi Indoor Imaging. (arXiv:2401.04317v1 [cs.CV])","link":"http://arxiv.org/abs/2401.04317","description":"<p>Indoor imaging is a critical task for robotics and internet-of-things. WiFi\nas an omnipresent signal is a promising candidate for carrying out passive\nimaging and synchronizing the up-to-date information to all connected devices.\nThis is the first research work to consider WiFi indoor imaging as a\nmulti-modal image generation task that converts the measured WiFi power into a\nhigh-resolution indoor image. Our proposed WiFi-GEN network achieves a shape\nreconstruction accuracy that is 275% of that achieved by physical model-based\ninversion methods. Additionally, the Frechet Inception Distance score has been\nsignificantly reduced by 82%. To examine the effectiveness of models for this\ntask, the first large-scale dataset is released containing 80,000 pairs of WiFi\nsignal and imaging target. Our model absorbs challenges for the model-based\nmethods including the non-linearity, ill-posedness and non-certainty into\nmassive parameters of our generative AI network. The network is also designed\nto best fit measured WiFi signals and the desired imaging output. For\nreproducibility, we will release the data and code upon acceptance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jianyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1\">Amartansh Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murch_R/0/1/0/all/0/1\">Ross Murch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Liwen Jing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Know Your Needs Better: Towards Structured Understanding of Marketer Demands with Analogical Reasoning Augmented LLMs. (arXiv:2401.04319v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04319","description":"<p>In this paper, we explore a new way for user targeting, where non-expert\nmarketers could select their target users solely given demands in natural\nlanguage form. The key to this issue is how to transform natural languages into\npractical structured logical languages, i.e., the structured understanding of\nmarketer demands. Considering the impressive natural language processing\nability of large language models (LLMs), we try to leverage LLMs to solve this\nissue. Past research indicates that the reasoning ability of LLMs can be\neffectively enhanced through chain-of-thought (CoT) prompting. But existing\nmethods still have some limitations: (1) Previous methods either use simple\n\"Let's think step by step\" spells or provide fixed examples in demonstrations\nwithout considering compatibility between prompts and questions, making LLMs\nineffective in some complex reasoning tasks such as structured language\ntransformation. (2) Previous methods are often implemented in closed-source\nmodels or excessively large models, which is not suitable in industrial\npractical scenarios. Based on these, we propose ARALLM (i.e., Analogical\nReasoning Augmented Large Language Models) consisting of two modules:\nAnalogical Reasoning based Prompting and Reasoning-Augmented Multi-Task Model\nDistillation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Binbin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiqiang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Private Fine-tuning of Large Language Models with Zeroth-order Optimization. (arXiv:2401.04343v1 [cs.LG])","link":"http://arxiv.org/abs/2401.04343","description":"<p>Fine-tuning large pretrained models on private datasets may run the risk of\nviolating privacy. Differential privacy is a framework for mitigating privacy\nrisks by enforcing algorithmic stability. DP-SGD enables training models with\nprivate data in a privacy-preserving manner, but raises new obstacles in the\nform of performance loss and significant engineering challenges. We introduce\nDP-ZO, a new method for fine-tuning large language models that preserves the\nprivacy of training data by privatizing zeroth-order optimization. A key\ninsight into the design of our method is that the direction of the gradient in\nSPSA, the zeroth-order algorithm we use, is always random and the only\ninformation that depends on private data is the step size, i.e., a scalar.\nTherefore, we only need to privatize the scalar step size, which is\nmemory-efficient. DP-ZO, which can be instantiated with either Laplace or\nGaussian noise, provides a strong privacy-utility trade-off across different\ntasks, and model sizes, under conservative privacy budgets. One noteworthy\nresult is that DP-ZO exhibits just $1.86\\%$ performance degradation due to\nprivacy at $(1,10^{-5})$-DP when fine-tuning OPT-66B on 1000 training samples\nfrom SQuAD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xinyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_A/0/1/0/all/0/1\">Ashwinee Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasr_M/0/1/0/all/0/1\">Milad Nasr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1\">Saeed Mahloujifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LAMPAT: Low-Rank Adaption for Multilingual Paraphrasing Using Adversarial Training. (arXiv:2401.04348v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04348","description":"<p>Paraphrases are texts that convey the same meaning while using different\nwords or sentence structures. It can be used as an automatic data augmentation\ntool for many Natural Language Processing tasks, especially when dealing with\nlow-resource languages, where data shortage is a significant problem. To\ngenerate a paraphrase in multilingual settings, previous studies have leveraged\nthe knowledge from the machine translation field, i.e., forming a paraphrase\nthrough zero-shot machine translation in the same language. Despite good\nperformance on human evaluation, those methods still require parallel\ntranslation datasets, thus making them inapplicable to languages that do not\nhave parallel corpora. To mitigate that problem, we proposed the first\nunsupervised multilingual paraphrasing model, LAMPAT ($\\textbf{L}$ow-rank\n$\\textbf{A}$daptation for $\\textbf{M}$ultilingual $\\textbf{P}$araphrasing using\n$\\textbf{A}$dversarial $\\textbf{T}$raining), by which monolingual dataset is\nsufficient enough to generate a human-like and diverse sentence. Throughout the\nexperiments, we found out that our method not only works well for English but\ncan generalize on unseen languages as well. Data and code are available at\nhttps://github.com/phkhanhtrinh23/LAMPAT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_K/0/1/0/all/0/1\">Khoi M.Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1\">Trinh Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_T/0/1/0/all/0/1\">Tho Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning. (arXiv:2401.04361v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04361","description":"<p>Knowledge-grounded dialogue (KGD) learns to generate an informative response\nbased on a given dialogue context and external knowledge (\\emph{e.g.},\nknowledge graphs; KGs). Recently, the emergence of large language models (LLMs)\nand pre-training techniques has brought great success to knowledge-grounded\ndialogue. However, when building KGD systems in real applications, there are\nvarious real-world noises that are inevitable to face. For example, the\ndialogue context might involve perturbations such as misspellings and\nabbreviations. In addition, KGs typically suffer from incompletion and also\nmight contain erroneous and outdated facts. Such real-world noises pose a\nchallenge to the robustness of KGD systems and hinder their applications in the\nreal world. In this paper, we propose an entity-based contrastive learning\nframework for improving the robustness of KGD. Specifically, we make use of the\nentity information in a KGD sample to create both its positive and negative\nsamples which involve semantic-irrelevant and semantic-relevant perturbations,\nrespectively. The contrastive learning framework ensures the KGD model is aware\nof these two types of perturbations, thus generating informative responses with\nthe potentially noisy inputs in real applications. Experimental results on\nthree benchmark datasets show that our method achieves new state-of-the-art\nperformance in terms of automatic evaluation scores, verifying its\neffectiveness and potentiality. Furthermore, we show that our method can\ngenerate better responses than comparison models in both the noisy and the\nfew-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_J/0/1/0/all/0/1\">Jianfeng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kexin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhixu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wen Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Ximing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">An Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probabilistic emotion and sentiment modelling of patient-reported experiences. (arXiv:2401.04367v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04367","description":"<p>This study introduces a novel methodology for modelling patient emotions from\nonline patient experience narratives. We employed metadata network topic\nmodelling to analyse patient-reported experiences from Care Opinion, revealing\nkey emotional themes linked to patient-caregiver interactions and clinical\noutcomes. We develop a probabilistic, context-specific emotion recommender\nsystem capable of predicting both multilabel emotions and binary sentiments\nusing a naive Bayes classifier using contextually meaningful topics as\npredictors. The superior performance of our predicted emotions under this model\ncompared to baseline models was assessed using the information retrieval\nmetrics nDCG and Q-measure, and our predicted sentiments achieved an F1 score\nof 0.921, significantly outperforming standard sentiment lexicons. This method\noffers a transparent, cost-effective way to understand patient feedback,\nenhancing traditional collection methods and informing individualised patient\ncare. Our findings are accessible via an R package and interactive dashboard,\nproviding valuable tools for healthcare researchers and practitioners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Murray_C/0/1/0/all/0/1\">Curtis Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_L/0/1/0/all/0/1\">Lewis Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuke_J/0/1/0/all/0/1\">Jonathan Tuke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackay_M/0/1/0/all/0/1\">Mark Mackay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding. (arXiv:2401.04398v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04398","description":"<p>Table-based reasoning with large language models (LLMs) is a promising\ndirection to tackle many table understanding tasks, such as table-based\nquestion answering and fact verification. Compared with generic reasoning,\ntable-based reasoning requires the extraction of underlying semantics from both\nfree-form questions and semi-structured tabular data. Chain-of-Thought and its\nsimilar approaches incorporate the reasoning chain in the form of textual\ncontext, but it is still an open question how to effectively leverage tabular\ndata in the reasoning chain. We propose the Chain-of-Table framework, where\ntabular data is explicitly used in the reasoning chain as a proxy for\nintermediate thoughts. Specifically, we guide LLMs using in-context learning to\niteratively generate operations and update the table to represent a tabular\nreasoning chain. LLMs can therefore dynamically plan the next operation based\non the results of the previous ones. This continuous evolution of the table\nforms a chain, showing the reasoning process for a given tabular problem. The\nchain carries structured information of the intermediate results, enabling more\naccurate and reliable predictions. Chain-of-Table achieves new state-of-the-art\nperformance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM\nchoices.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chun-Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1\">Julian Martin Eisenschlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perot_V/0/1/0/all/0/1\">Vincent Perot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miculicich_L/0/1/0/all/0/1\">Lesly Miculicich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujii_Y/0/1/0/all/0/1\">Yasuhisa Fujii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chen-Yu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Estimating Text Similarity based on Semantic Concept Embeddings. (arXiv:2401.04422v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04422","description":"<p>Due to their ease of use and high accuracy, Word2Vec (W2V) word embeddings\nenjoy great success in the semantic representation of words, sentences, and\nwhole documents as well as for semantic similarity estimation. However, they\nhave the shortcoming that they are directly extracted from a surface\nrepresentation, which does not adequately represent human thought processes and\nalso performs poorly for highly ambiguous words. Therefore, we propose Semantic\nConcept Embeddings (CE) based on the MultiNet Semantic Network (SN) formalism,\nwhich addresses both shortcomings. The evaluation on a marketing target group\ndistribution task showed that the accuracy of predicted target groups can be\nincreased by combining traditional word embeddings with semantic CEs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bruck_T/0/1/0/all/0/1\">Tim vor der Br&#xfc;ck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouly_M/0/1/0/all/0/1\">Marc Pouly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TransportationGames: Benchmarking Transportation Knowledge of (Multimodal) Large Language Models. (arXiv:2401.04471v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04471","description":"<p>Large language models (LLMs) and multimodal large language models (MLLMs)\nhave shown excellent general capabilities, even exhibiting adaptability in many\nprofessional domains such as law, economics, transportation, and medicine.\nCurrently, many domain-specific benchmarks have been proposed to verify the\nperformance of (M)LLMs in specific fields. Among various domains,\ntransportation plays a crucial role in modern society as it impacts the\neconomy, the environment, and the quality of life for billions of people.\nHowever, it is unclear how much traffic knowledge (M)LLMs possess and whether\nthey can reliably perform transportation-related tasks. To address this gap, we\npropose TransportationGames, a carefully designed and thorough evaluation\nbenchmark for assessing (M)LLMs in the transportation domain. By\ncomprehensively considering the applications in real-world scenarios and\nreferring to the first three levels in Bloom's Taxonomy, we test the\nperformance of various (M)LLMs in memorizing, understanding, and applying\ntransportation knowledge by the selected tasks. The experimental results show\nthat although some models perform well in some tasks, there is still much room\nfor improvement overall. We hope the release of TransportationGames can serve\nas a foundation for future research, thereby accelerating the implementation\nand application of (M)LLMs in the transportation domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiangyu Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_X/0/1/0/all/0/1\">Xinyue Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_R/0/1/0/all/0/1\">Rui Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenjuan Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TwinBooster: Synergising Large Language Models with Barlow Twins and Gradient Boosting for Enhanced Molecular Property Prediction. (arXiv:2401.04478v1 [q-bio.BM])","link":"http://arxiv.org/abs/2401.04478","description":"<p>The success of drug discovery and development relies on the precise\nprediction of molecular activities and properties. While in silico molecular\nproperty prediction has shown remarkable potential, its use has been limited so\nfar to assays for which large amounts of data are available. In this study, we\nuse a fine-tuned large language model to integrate biological assays based on\ntheir textual information, coupled with Barlow Twins, a Siamese neural network\nusing a novel self-supervised learning approach. This architecture uses both\nassay information and molecular fingerprints to extract the true molecular\ninformation. TwinBooster enables the prediction of properties of unseen\nbioassays and molecules by providing state-of-the-art zero-shot learning tasks.\nRemarkably, our artificial intelligence pipeline shows excellent performance on\nthe FS-Mol benchmark. This breakthrough demonstrates the application of deep\nlearning to critical property prediction tasks where data is typically scarce.\nBy accelerating the early identification of active molecules in drug discovery\nand development, this method has the potential to help streamline the\nidentification of novel therapeutics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Schuh_M/0/1/0/all/0/1\">Maximilian G. Schuh</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Boldini_D/0/1/0/all/0/1\">Davide Boldini</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Sieber_S/0/1/0/all/0/1\">Stephan A. Sieber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fighting Fire with Fire: Adversarial Prompting to Generate a Misinformation Detection Dataset. (arXiv:2401.04481v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04481","description":"<p>The recent success in language generation capabilities of large language\nmodels (LLMs), such as GPT, Bard, Llama etc., can potentially lead to concerns\nabout their possible misuse in inducing mass agitation and communal hatred via\ngenerating fake news and spreading misinformation. Traditional means of\ndeveloping a misinformation ground-truth dataset does not scale well because of\nthe extensive manual effort required to annotate the data. In this paper, we\npropose an LLM-based approach of creating silver-standard ground-truth datasets\nfor identifying misinformation. Specifically speaking, given a trusted news\narticle, our proposed approach involves prompting LLMs to automatically\ngenerate a summarised version of the original article. The prompts in our\nproposed approach act as a controlling mechanism to generate specific types of\nfactual incorrectness in the generated summaries, e.g., incorrect quantities,\nfalse attributions etc. To investigate the usefulness of this dataset, we\nconduct a set of experiments where we train a range of supervised models for\nthe task of misinformation detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Satapara_S/0/1/0/all/0/1\">Shrey Satapara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_P/0/1/0/all/0/1\">Parth Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_D/0/1/0/all/0/1\">Debasis Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modha_S/0/1/0/all/0/1\">Sandip Modha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continuously Learning New Words in Automatic Speech Recognition. (arXiv:2401.04482v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04482","description":"<p>Despite recent advances, Automatic Speech Recognition (ASR) systems are still\nfar from perfect. Typical errors include acronyms, named entities and\ndomain-specific special words for which little or no data is available. To\naddress the problem of recognizing these words, we propose an self-supervised\ncontinual learning approach. Given the audio of a lecture talk with\ncorresponding slides, we bias the model towards decoding new words from the\nslides by using a memory-enhanced ASR model from previous work. Then, we\nperform inference on the talk, collecting utterances that contain detected new\nwords into an adaptation dataset. Continual learning is then performed on this\nset by adapting low-rank matrix weights added to each weight matrix of the\nmodel. The whole procedure is iterated for many talks. We show that with this\napproach, we obtain increasing performance on the new words when they occur\nmore frequently (more than 80% recall) while preserving the general performance\nof the model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1\">Christian Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alexander Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TechGPT-2.0: A large language model project to solve the task of knowledge graph construction. (arXiv:2401.04507v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04507","description":"<p>Large language models have exhibited robust performance across diverse\nnatural language processing tasks. This report introduces TechGPT-2.0, a\nproject designed to enhance the capabilities of large language models\nspecifically in knowledge graph construction tasks, including named entity\nrecognition (NER) and relationship triple extraction (RTE) tasks in NLP\napplications. Additionally, it serves as a LLM accessible for research within\nthe Chinese open-source model community. We offer two 7B large language model\nweights and a QLoRA weight specialized for processing lengthy texts.Notably,\nTechGPT-2.0 is trained on Huawei's Ascend server. Inheriting all\nfunctionalities from TechGPT-1.0, it exhibits robust text processing\ncapabilities, particularly in the domains of medicine and law. Furthermore, we\nintroduce new capabilities to the model, enabling it to process texts in\nvarious domains such as geographical areas, transportation, organizations,\nliterary works, biology, natural sciences, astronomical objects, and\narchitecture. These enhancements also fortified the model's adeptness in\nhandling hallucinations, unanswerable queries, and lengthy texts. This report\nprovides a comprehensive and detailed introduction to the full fine-tuning\nprocess on Huawei's Ascend servers, encompassing experiences in Ascend server\ndebugging, instruction fine-tuning data processing, and model training. Our\ncode is available at https://github.com/neukg/TechGPT-2.0\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yuying Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_N/0/1/0/all/0/1\">Ning An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1\">Qi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hei_L/0/1/0/all/0/1\">Lei Hei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haibo Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yifei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1\">Feiliang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rewriting the Code: A Simple Method for Large Language Model Augmented Code Search. (arXiv:2401.04514v1 [cs.SE])","link":"http://arxiv.org/abs/2401.04514","description":"<p>In code search, the Generation-Augmented Retrieval (GAR) framework, which\ngenerates exemplar code snippets to augment queries, has emerged as a promising\nstrategy to address the principal challenge of modality misalignment between\ncode snippets and natural language queries, particularly with the demonstrated\ncode generation capabilities of Large Language Models (LLMs). Nevertheless, our\npreliminary investigations indicate that the improvements conferred by such an\nLLM-augmented framework are somewhat constrained. This limitation could\npotentially be ascribed to the fact that the generated codes, albeit\nfunctionally accurate, frequently display a pronounced stylistic deviation from\nthe ground truth code in the codebase. In this paper, we extend the\nfoundational GAR framework and propose a simple yet effective method that\nadditionally Rewrites the Code (ReCo) within the codebase for style\nnormalization. Experimental results demonstrate that ReCo significantly boosts\nretrieval accuracy across sparse (up to 35.7%), zero-shot dense (up to 27.6%),\nand fine-tuned dense (up to 23.6%) retrieval settings in diverse search\nscenarios. To further elucidate the advantages of ReCo and stimulate research\nin code style normalization, we introduce Code Style Similarity, the first\nmetric tailored to quantify stylistic similarities in code. Notably, our\nempirical findings reveal the inadequacy of existing metrics in capturing\nstylistic nuances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haochen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqi Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with Large Language Models. (arXiv:2401.04515v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04515","description":"<p>This article investigates a zero-shot approach to hypernymy prediction using\nlarge language models (LLMs). The study employs a method based on text\nprobability calculation, applying it to various generated prompts. The\nexperiments demonstrate a strong correlation between the effectiveness of\nlanguage model prompts and classic patterns, indicating that preliminary prompt\nselection can be carried out using smaller models before moving to larger ones.\nWe also explore prompts for predicting co-hyponyms and improving hypernymy\npredictions by augmenting prompts with additional information through\nautomatically identified co-hyponyms. An iterative approach is developed for\npredicting higher-level concepts, which further improves the quality on the\nBLESS dataset (MAP = 0.8).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tikhomirov_M/0/1/0/all/0/1\">Mikhail Tikhomirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loukachevitch_N/0/1/0/all/0/1\">Natalia Loukachevitch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Critique of Critique. (arXiv:2401.04518v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04518","description":"<p>Critique, as a natural language description for assessing the quality of\nmodel-generated content, has been proven to play an essential role in the\ntraining, evaluation, and refinement of Large Language Models (LLMs). However,\nthere is a lack of principled understanding in evaluating the quality of the\ncritique itself. In this paper, we pioneer the critique of critique, termed\nMetaCritique, which is a framework to evaluate the critique from two aspects,\ni.e., factuality as precision score and comprehensiveness as recall score. We\ncalculate the harmonic mean of precision and recall as the overall rating\ncalled F1 score. To obtain a reliable evaluation outcome, we propose Atomic\nInformation Units (AIUs), which describe the critique in a more fine-grained\nmanner. MetaCritique takes each AIU into account and aggregates each AIU's\njudgment for the overall score. Moreover, given the evaluation process involves\nintricate reasoning, our MetaCritique provides a natural language rationale to\nsupport each judgment. We construct a meta-evaluation dataset containing 300\ncritiques (2653 AIUs) across four tasks (question answering, reasoning,\nentailment, and summarization), and we conduct a comparative study to\ndemonstrate the feasibility and effectiveness. Experiments also show superior\ncritique judged by MetaCritique leads to better refinement, indicating\ngenerative artificial intelligence indeed has the potential to be significantly\nadvanced with our MetaCritique. We will release relevant code and\nmeta-evaluation datasets at https://github.com/GAIR-NLP/MetaCritique.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Weizhe Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Ruifeng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LUNA: A Framework for Language Understanding and Naturalness Assessment. (arXiv:2401.04522v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04522","description":"<p>The evaluation of Natural Language Generation (NLG) models has gained\nincreased attention, urging the development of metrics that evaluate various\naspects of generated text. LUNA addresses this challenge by introducing a\nunified interface for 20 NLG evaluation metrics. These metrics are categorized\nbased on their reference-dependence and the type of text representation they\nemploy, from string-based n-gram overlap to the utilization of static\nembeddings and pre-trained language models.\n</p>\n<p>The straightforward design of LUNA allows for easy extension with novel\nmetrics, requiring just a few lines of code. LUNA offers a user-friendly tool\nfor evaluating generated texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saidov_M/0/1/0/all/0/1\">Marat Saidov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakalova_A/0/1/0/all/0/1\">Aleksandra Bakalova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taktasheva_E/0/1/0/all/0/1\">Ekaterina Taktasheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhailov_V/0/1/0/all/0/1\">Vladislav Mikhailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1\">Ekaterina Artemova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MERA: A Comprehensive LLM Evaluation in Russian. (arXiv:2401.04531v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04531","description":"<p>Over the past few years, one of the most notable advancements in AI research\nhas been in foundation models (FMs), headlined by the rise of language models\n(LMs). As the models' size increases, LMs demonstrate enhancements in\nmeasurable aspects and the development of new qualitative features. However,\ndespite researchers' attention and the rapid growth in LM application, the\ncapabilities, limitations, and associated risks still need to be better\nunderstood. To address these issues, we introduce an open Multimodal Evaluation\nof Russian-language Architectures (MERA), a new instruction benchmark for\nevaluating foundation models oriented towards the Russian language. The\nbenchmark encompasses 21 evaluation tasks for generative models in 11 skill\ndomains and is designed as a black-box test to ensure the exclusion of data\nleakage. The paper introduces a methodology to evaluate FMs and LMs in zero-\nand few-shot fixed instruction settings that can be extended to other\nmodalities. We propose an evaluation methodology, an open-source code base for\nthe MERA assessment, and a leaderboard with a submission system. We evaluate\nopen LMs as baselines and find that they are still far behind the human level.\nWe publicly release MERA to guide forthcoming research, anticipate\ngroundbreaking model features, standardize the evaluation procedure, and\naddress potential societal drawbacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fenogenova_A/0/1/0/all/0/1\">Alena Fenogenova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chervyakov_A/0/1/0/all/0/1\">Artem Chervyakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martynov_N/0/1/0/all/0/1\">Nikita Martynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozlova_A/0/1/0/all/0/1\">Anastasia Kozlova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonova_M/0/1/0/all/0/1\">Maria Tikhonova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhmetgareeva_A/0/1/0/all/0/1\">Albina Akhmetgareeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emelyanov_A/0/1/0/all/0/1\">Anton Emelyanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shevelev_D/0/1/0/all/0/1\">Denis Shevelev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebedev_P/0/1/0/all/0/1\">Pavel Lebedev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinev_L/0/1/0/all/0/1\">Leonid Sinev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isaeva_U/0/1/0/all/0/1\">Ulyana Isaeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolomeytseva_K/0/1/0/all/0/1\">Katerina Kolomeytseva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moskovskiy_D/0/1/0/all/0/1\">Daniil Moskovskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncharova_E/0/1/0/all/0/1\">Elizaveta Goncharova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savushkin_N/0/1/0/all/0/1\">Nikita Savushkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhailova_P/0/1/0/all/0/1\">Polina Mikhailova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrov_D/0/1/0/all/0/1\">Denis Dimitrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panchenko_A/0/1/0/all/0/1\">Alexander Panchenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markov_S/0/1/0/all/0/1\">Sergei Markov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Language Model Agency through Negotiations. (arXiv:2401.04536v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04536","description":"<p>Companies, organizations, and governments increasingly exploit Language\nModels' (LM) remarkable capability to display agent-like behavior. As LMs are\nadopted to perform tasks with growing autonomy, there exists an urgent need for\nreliable and scalable evaluation benchmarks. Current, predominantly static LM\nbenchmarks are ill-suited to evaluate such dynamic applications. Thus, we\npropose jointly evaluating LM performance and alignment through the lenses of\nnegotiation games. We argue that this common task better reflects real-world\ndeployment conditions while offering insights into LMs' decision-making\nprocesses. Crucially, negotiation games allow us to study multi-turn, and\ncross-model interactions, modulate complexity, and side-step accidental data\nleakage in evaluation. We report results for six publicly accessible LMs from\nseveral major providers on a variety of negotiation games, evaluating both\nself-play and cross-play performance. Noteworthy findings include: (i)\nopen-source models are currently unable to complete these tasks; (ii)\ncooperative bargaining games prove challenging; and (iii) the most powerful\nmodels do not always \"win\".\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Davidson_T/0/1/0/all/0/1\">Tim R. Davidson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veselovsky_V/0/1/0/all/0/1\">Veniamin Veselovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosinski_M/0/1/0/all/0/1\">Michal Kosinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Assessment on Comprehending Mental Health through Large Language Models. (arXiv:2401.04592v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04592","description":"<p>Mental health challenges pose considerable global burdens on individuals and\ncommunities. Recent data indicates that more than 20% of adults may encounter\nat least one mental disorder in their lifetime. On the one hand, the\nadvancements in large language models have facilitated diverse applications,\nyet a significant research gap persists in understanding and enhancing the\npotential of large language models within the domain of mental health. On the\nother hand, across various applications, an outstanding question involves the\ncapacity of large language models to comprehend expressions of human mental\nhealth conditions in natural language. This study presents an initial\nevaluation of large language models in addressing this gap. Due to this, we\ncompare the performance of Llama-2 and ChatGPT with classical Machine as well\nas Deep learning models. Our results on the DAIC-WOZ dataset show that\ntransformer-based models, like BERT or XLNet, outperform the large language\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arcan_M/0/1/0/all/0/1\">Mihael Arcan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niland_P/0/1/0/all/0/1\">Paul-David Niland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delahunty_F/0/1/0/all/0/1\">Fionn Delahunty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Detection for Transliterated Content. (arXiv:2401.04619v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04619","description":"<p>In the contemporary digital era, the Internet functions as an unparalleled\ncatalyst, dismantling geographical and linguistic barriers particularly evident\nin texting. This evolution facilitates global communication, transcending\nphysical distances and fostering dynamic cultural exchange. A notable trend is\nthe widespread use of transliteration, where the English alphabet is employed\nto convey messages in native languages, posing a unique challenge for language\ntechnology in accurately detecting the source language. This paper addresses\nthis challenge through a dataset of phone text messages in Hindi and Russian\ntransliterated into English utilizing BERT for language classification and\nGoogle Translate API for transliteration conversion. The research pioneers\ninnovative approaches to identify and convert transliterated text, navigating\nchallenges in the diverse linguistic landscape of digital communication.\nEmphasizing the pivotal role of comprehensive datasets for training Large\nLanguage Models LLMs like BERT, our model showcases exceptional proficiency in\naccurately identifying and classifying languages from transliterated text. With\na validation accuracy of 99% our models robust performance underscores its\nreliability. The comprehensive exploration of transliteration dynamics\nsupported by innovative approaches and cutting edge technologies like BERT,\npositions our research at the forefront of addressing unique challenges in the\nlinguistic landscape of digital communication. Beyond contributing to language\nidentification and transliteration capabilities this work holds promise for\napplications in content moderation, analytics and fostering a globally\nconnected community engaged in meaningful dialogue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Selva Kumar S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Afifah Khan Mohammed Ajmal Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manjeshwar_C/0/1/0/all/0/1\">Chirag Manjeshwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banday_I/0/1/0/all/0/1\">Imadh Ajaz Banday</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04620","description":"<p>Agents based on Large Language Models (LLMs) are increasingly permeating\nvarious domains of human production and life, highlighting the importance of\naligning them with human values. The current alignment of AI systems primarily\nfocuses on passively aligning LLMs through human intervention. However, agents\npossess characteristics like receiving environmental feedback and\nself-evolution, rendering the LLM alignment methods inadequate. In response, we\npropose an evolutionary framework for agent evolution and alignment, named\nEvolutionaryAgent, which transforms agent alignment into a process of evolution\nand selection under the principle of survival of the fittest. In an environment\nwhere social norms continuously evolve, agents better adapted to the current\nsocial norms will have a higher probability of survival and proliferation,\nwhile those inadequately aligned dwindle over time. Experimental results\nassessing the agents from multiple perspectives in aligning with social norms\ndemonstrate that EvolutionaryAgent possesses the capability to align\nprogressively better with the evolving social norms while maintaining its\nproficiency in general tasks. Effectiveness tests conducted on various open and\nclosed-source LLMs as the foundation for agents also prove the applicability of\nour approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DebugBench: Evaluating Debugging Capability of Large Language Models. (arXiv:2401.04621v1 [cs.SE])","link":"http://arxiv.org/abs/2401.04621","description":"<p>Large Language Models (LLMs) have demonstrated exceptional coding capability.\nHowever, as another critical component of programming proficiency, the\ndebugging capability of LLMs remains relatively unexplored. Previous\nevaluations of LLMs' debugging ability are significantly limited by the risk of\ndata leakage, the scale of the dataset, and the variety of tested bugs. To\novercome these deficiencies, we introduce `DebugBench', an LLM debugging\nbenchmark consisting of 4,253 instances. It covers four major bug categories\nand 18 minor types in C++, Java, and Python. To construct DebugBench, we\ncollect code snippets from the LeetCode community, implant bugs into source\ndata with GPT-4, and assure rigorous quality checks. We evaluate two commercial\nand three open-source models in a zero-shot scenario. We find that (1) while\nclosed-source models like GPT-4 exhibit inferior debugging performance compared\nto humans, open-source models such as Code Llama fail to attain any pass rate\nscores; (2) the complexity of debugging notably fluctuates depending on the bug\ncategory; (3) incorporating runtime feedback has a clear impact on debugging\nperformance which is not always helpful. As an extension, we also compare LLM\ndebugging and code generation, revealing a strong correlation between them for\nclosed-source models. These findings will benefit the development of LLMs in\ndebugging.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_R/0/1/0/all/0/1\">Runchu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yining Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Applying Large Language Models API to Issue Classification Problem. (arXiv:2401.04637v1 [cs.SE])","link":"http://arxiv.org/abs/2401.04637","description":"<p>Effective prioritization of issue reports is crucial in software engineering\nto optimize resource allocation and address critical problems promptly.\nHowever, the manual classification of issue reports for prioritization is\nlaborious and lacks scalability. Alternatively, many open source software (OSS)\nprojects employ automated processes for this task, albeit relying on\nsubstantial datasets for adequate training. This research seeks to devise an\nautomated approach that ensures reliability in issue prioritization, even when\ntrained on smaller datasets. Our proposed methodology harnesses the power of\nGenerative Pre-trained Transformers (GPT), recognizing their potential to\nefficiently handle this task. By leveraging the capabilities of such models, we\naim to develop a robust system for prioritizing issue reports accurately,\nmitigating the necessity for extensive training data while maintaining\nreliability. In our research, we have developed a reliable GPT-based approach\nto accurately label and prioritize issue reports with a reduced training\ndataset. By reducing reliance on massive data requirements and focusing on\nfew-shot fine-tuning, our methodology offers a more accessible and efficient\nsolution for issue prioritization in software engineering. Our model predicted\nissue types in individual projects up to 93.2% in precision, 95% in recall, and\n89.3% in F1-score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aracena_G/0/1/0/all/0/1\">Gabriel Aracena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luster_K/0/1/0/all/0/1\">Kyle Luster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_F/0/1/0/all/0/1\">Fabio Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinmacher_I/0/1/0/all/0/1\">Igor Steinmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerosa_M/0/1/0/all/0/1\">Marco A. Gerosa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DepressionEmo: A novel dataset for multilabel classification of depression emotions. (arXiv:2401.04655v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04655","description":"<p>Emotions are integral to human social interactions, with diverse responses\nelicited by various situational contexts. Particularly, the prevalence of\nnegative emotional states has been correlated with negative outcomes for mental\nhealth, necessitating a comprehensive analysis of their occurrence and impact\non individuals. In this paper, we introduce a novel dataset named DepressionEmo\ndesigned to detect 8 emotions associated with depression by 6037 examples of\nlong Reddit user posts. This dataset was created through a majority vote over\ninputs by zero-shot classifications from pre-trained models and validating the\nquality by annotators and ChatGPT, exhibiting an acceptable level of interrater\nreliability between annotators. The correlation between emotions, their\ndistribution over time, and linguistic analysis are conducted on DepressionEmo.\nBesides, we provide several text classification methods classified into two\ngroups: machine learning methods such as SVM, XGBoost, and Light GBM; and deep\nlearning methods such as BERT, GAN-BERT, and BART. The pretrained BART model,\nbart-base allows us to obtain the highest F1- Macro of 0.76, showing its\noutperformance compared to other methods evaluated in our analysis. Across all\nemotions, the highest F1-Macro value is achieved by suicide intent, indicating\na certain value of our dataset in identifying emotions in individuals with\ndepression symptoms through text analysis. The curated dataset is publicly\navailable at: https://github.com/abuBakarSiddiqurRahman/DepressionEmo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1\">Abu Bakar Siddiqur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ta_H/0/1/0/all/0/1\">Hoang-Thang Ta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najjar_L/0/1/0/all/0/1\">Lotfollah Najjar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azadmanesh_A/0/1/0/all/0/1\">Azad Azadmanesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonul_A/0/1/0/all/0/1\">Ali Saffet G&#xf6;n&#xfc;l</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models. (arXiv:2401.04658v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04658","description":"<p>Linear attention is an efficient attention mechanism that has recently\nemerged as a promising alternative to conventional softmax attention. With its\nability to process tokens in linear computational complexities, linear\nattention, in theory, can handle sequences of unlimited length without\nsacrificing speed, i.e., maintaining a constant training speed for various\nsequence lengths with a fixed memory consumption. However, due to the issue\nwith cumulative summation (cumsum), current linear attention algorithms cannot\ndemonstrate their theoretical advantage in a causal setting. In this paper, we\npresent Lightning Attention-2, the first linear attention implementation that\nenables linear attention to realize its theoretical computational benefits. To\nachieve this, we leverage the thought of tiling, separately handling the\nintra-block and inter-block components in linear attention calculation.\nSpecifically, we utilize the conventional attention computation mechanism for\nthe intra-blocks and apply linear attention kernel tricks for the inter-blocks.\nA tiling technique is adopted through both forward and backward procedures to\ntake full advantage of the GPU hardware. We implement our algorithm in Triton\nto make it IO-aware and hardware-friendly. Various experiments are conducted on\ndifferent model sizes and sequence lengths. Lightning Attention-2 retains\nconsistent training and inference speed regardless of input sequence length and\nis significantly faster than other attention mechanisms. The source code is\navailable at https://github.com/OpenNLPLab/lightning-attention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weigao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xuyang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weixuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiran Zhong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04679","description":"<p>We investigate parameter-efficient fine-tuning (PEFT) methods that can\nprovide good accuracy under limited computational and memory budgets in the\ncontext of large language models (LLMs). We present a new PEFT method called\nRobust Adaptation (RoSA) inspired by robust principal component analysis (PCA)\nthat jointly trains $\\textit{low-rank}$ and $\\textit{highly-sparse}$ components\non top of a set of fixed pretrained weights to efficiently approximate the\nperformance of a full-fine-tuning (FFT) solution. Across a series of\nchallenging generative tasks such as grade-school math and SQL query\ngeneration, which require fine-tuning for good performance, we show that RoSA\noutperforms both LoRA and pure sparse fine-tuning, at the same parameter\nbudget. We provide system support for RoSA to complement the training\nalgorithm, specifically in the form of sparse GPU kernels which enable memory-\nand computationally-efficient training. Our code will be made available at\nhttps://github.com/IST-DASLab/RoSA}{\\texttt{https://github.com/IST-DASLab/RoSA\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nikdan_M/0/1/0/all/0/1\">Mahdi Nikdan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tabesh_S/0/1/0/all/0/1\">Soroush Tabesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering with Multi-Granularity Answers. (arXiv:2401.04695v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04695","description":"<p>Factual questions typically can be answered correctly at different levels of\ngranularity. For example, both ``August 4, 1961'' and ``1961'' are correct\nanswers to the question ``When was Barack Obama born?''. Standard question\nanswering (QA) evaluation protocols, however, do not explicitly take this into\naccount and compare a predicted answer against answers of a single granularity\nlevel. In this work, we propose GRANOLA QA, a novel evaluation setting where a\npredicted answer is evaluated in terms of accuracy and informativeness against\na set of multi-granularity answers. We present a simple methodology for\nenriching existing datasets with multi-granularity answers, and create\nGRANOLA-EQ, a multi-granularity version of the EntityQuestions dataset. We\nevaluate a range of decoding methods on GRANOLA-EQ, including a new algorithm,\ncalled Decoding with Response Aggregation (DRAG), that is geared towards\naligning the response granularity with the model's uncertainty. Our experiments\nshow that large language models with standard decoding tend to generate\nspecific answers, which are often incorrect. In contrast, when evaluated on\nmulti-granularity answers, DRAG yields a nearly 20 point increase in accuracy\non average, which further increases for rare entities. Overall, this reveals\nthat standard evaluation and decoding schemes may significantly underestimate\nthe knowledge encapsulated in LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yona_G/0/1/0/all/0/1\">Gal Yona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Model Editing Can Hurt General Abilities of Large Language Models. (arXiv:2401.04700v1 [cs.CL])","link":"http://arxiv.org/abs/2401.04700","description":"<p>Recent advances in large language models (LLMs) have opened up new paradigms\nfor accessing the knowledge stored in their parameters. One critical challenge\nthat has emerged is the presence of hallucinations in LLM outputs due to false\nor outdated knowledge. Since retraining LLMs with updated information is\nresource-intensive, there has been a growing interest in model editing.\nHowever, many model editing methods, while effective in various scenarios, tend\nto overemphasize aspects such as efficacy, generalization, and locality in\nediting performance, often overlooking potential side effects on the general\nabilities of LLMs. In this paper, we raise concerns that the improvement of\nmodel factuality may come at the cost of a significant degradation of these\ngeneral abilities, which is not conducive to the sustainable development of\nLLMs. Systematically, we analyze side effects by evaluating four popular\nediting methods on two LLMs across eight representative task categories.\nExtensive empirical research reveals that model editing does improve model\nfactuality but at the expense of substantially impairing general abilities.\nTherefore, we advocate for more research efforts to minimize the loss of\ngeneral abilities acquired during LLM pre-training and to ultimately preserve\nthem during model editing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hao-Xiang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jun-Yu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation. (arXiv:2205.14912v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.14912","description":"<p>Sequence-to-sequence (seq2seq) learning is a popular fashion for large-scale\npretraining language models. However, the prior seq2seq pretraining models\ngenerally focus on reconstructive objectives on the decoder side and neglect\nthe effect of encoder-side supervision, which we argue may lead to sub-optimal\nperformance. To verify our hypothesis, we first empirically study the\nfunctionalities of the encoder and decoder in seq2seq pretrained language\nmodels, and find that the encoder takes an important but under-exploitation\nrole than the decoder regarding the downstream performance and neuron\nactivation. Therefore, we propose an encoding-enhanced seq2seq pretraining\nstrategy, namely E2S2, which improves the seq2seq models via integrating more\nefficient self-supervised information into the encoders. Specifically, E2S2\nadopts two self-supervised objectives on the encoder side from two aspects: 1)\nlocally denoising the corrupted sentence (denoising objective); and 2) globally\nlearning better sentence representations (contrastive objective). With the help\nof both objectives, the encoder can effectively distinguish the noise tokens\nand capture high-level (i.e., syntactic and semantic) knowledge, thus\nstrengthening the ability of seq2seq model to accurately achieve the\nconditional generation. On a large diversity of downstream natural language\nunderstanding and generation tasks, E2S2 dominantly improves the performance of\nits powerful backbone models, e.g., BART and T5. For example, upon BART\nbackbone, we achieve +1.1% averaged gain on the general language understanding\nevaluation (GLUE) benchmark and +1.75% F_0.5 score improvement on CoNLL2014\ndataset. We also provide in-depth analyses to show the improvement stems from\nbetter linguistic representation. We hope that our work will foster future\nself-supervision research on seq2seq language model pretraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Juhua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entailment Semantics Can Be Extracted from an Ideal Language Model. (arXiv:2209.12407v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.12407","description":"<p>Language models are often trained on text alone, without additional\ngrounding. There is debate as to how much of natural language semantics can be\ninferred from such a procedure. We prove that entailment judgments between\nsentences can be extracted from an ideal language model that has perfectly\nlearned its target distribution, assuming the training sentences are generated\nby Gricean agents, i.e., agents who follow fundamental principles of\ncommunication from the linguistic theory of pragmatics. We also show entailment\njudgments can be decoded from the predictions of a language model trained on\nsuch Gricean data. Our results reveal a pathway for understanding the semantic\ninformation encoded in unlabeled linguistic data and a potential framework for\nextracting semantics from language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1\">Alex Warstadt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1\">Tal Linzen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"P-Transformer: A Prompt-based Multimodal Transformer Architecture For Medical Tabular Data. (arXiv:2303.17408v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.17408","description":"<p>Medical tabular data, abundant in Electronic Health Records (EHRs), is a\nvaluable resource for diverse medical tasks such as risk prediction. While deep\nlearning approaches, particularly transformer-based models, have shown\nremarkable performance in tabular data prediction, there are still problems\nremained for existing work to be effectively adapted into medical domain, such\nas under-utilization of unstructured free-texts, limited exploration of textual\ninformation in structured data, and data corruption. To address these issues,\nwe propose P-Transformer, a Prompt-based multimodal Transformer architecture\ndesigned specifically for medical tabular data. This framework consists two\ncritical components: a tabular cell embedding generator and a tabular\ntransformer. The former efficiently encodes diverse modalities from both\nstructured and unstructured tabular data into a harmonized language semantic\nspace with the help of pre-trained sentence encoder and medical prompts. The\nlatter integrates cell representations to generate patient embeddings for\nvarious medical tasks. In comprehensive experiments on two real-world datasets\nfor three medical tasks, P-Transformer demonstrated the improvements with\n10.9%/11.0% on RMSE/MAE, 0.5%/2.2% on RMSE/MAE, and 1.6%/0.8% on BACC/AUROC\ncompared to state-of-the-art (SOTA) baselines in predictability. Notably, the\nmodel exhibited strong resilience to data corruption in the structured data,\nparticularly when the corruption rates are high.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_Y/0/1/0/all/0/1\">Yucheng Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_X/0/1/0/all/0/1\">Xiang Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_D/0/1/0/all/0/1\">Daniel J. Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullah_H/0/1/0/all/0/1\">Hairil Rizal Abdullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_M/0/1/0/all/0/1\">Mengling Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HCAM -- Hierarchical Cross Attention Model for Multi-modal Emotion Recognition. (arXiv:2304.06910v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2304.06910","description":"<p>Emotion recognition in conversations is challenging due to the multi-modal\nnature of the emotion expression. We propose a hierarchical cross-attention\nmodel (HCAM) approach to multi-modal emotion recognition using a combination of\nrecurrent and co-attention neural network models. The input to the model\nconsists of two modalities, i) audio data, processed through a learnable\nwav2vec approach and, ii) text data represented using a bidirectional encoder\nrepresentations from transformers (BERT) model. The audio and text\nrepresentations are processed using a set of bi-directional recurrent neural\nnetwork layers with self-attention that converts each utterance in a given\nconversation to a fixed dimensional embedding. In order to incorporate\ncontextual knowledge and the information across the two modalities, the audio\nand text embeddings are combined using a co-attention layer that attempts to\nweigh the utterance level embeddings relevant to the task of emotion\nrecognition. The neural network parameters in the audio layers, text layers as\nwell as the multi-modal co-attention layers, are hierarchically trained for the\nemotion classification task. We perform experiments on three established\ndatasets namely, IEMOCAP, MELD and CMU-MOSI, where we illustrate that the\nproposed model improves significantly over other benchmarks and helps achieve\nstate-of-art results on all these datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Dutta_S/0/1/0/all/0/1\">Soumya Dutta</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ganapathy_S/0/1/0/all/0/1\">Sriram Ganapathy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Query Generation for Privacy-Preserving Deep Retrieval Systems using Differentially Private Language Models. (arXiv:2305.05973v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.05973","description":"<p>We address the challenge of ensuring differential privacy (DP) guarantees in\ntraining deep retrieval systems. Training these systems often involves the use\nof contrastive-style losses, which are typically non-per-example decomposable,\nmaking them difficult to directly DP-train with since common techniques require\nper-example gradient. To address this issue, we propose an approach that\nprioritizes ensuring query privacy prior to training a deep retrieval system.\nOur method employs DP language models (LMs) to generate private synthetic\nqueries representative of the original data. These synthetic queries can be\nused in downstream retrieval system training without compromising privacy. Our\napproach demonstrates a significant enhancement in retrieval quality compared\nto direct DP-training, all while maintaining query-level privacy guarantees.\nThis work highlights the potential of harnessing LMs to overcome limitations in\nstandard DP-training methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Carranza_A/0/1/0/all/0/1\">Aldo Gael Carranza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahani_R/0/1/0/all/0/1\">Rezsa Farahani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponomareva_N/0/1/0/all/0/1\">Natalia Ponomareva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1\">Alex Kurakin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagielski_M/0/1/0/all/0/1\">Matthew Jagielski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasr_M/0/1/0/all/0/1\">Milad Nasr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations. (arXiv:2308.02053v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.02053","description":"<p>Large Language Models (LLMs) have seen widespread deployment in various\nreal-world applications. Understanding these biases is crucial to comprehend\nthe potential downstream consequences when using LLMs to make decisions,\nparticularly for historically disadvantaged groups. In this work, we propose a\nsimple method for analyzing and comparing demographic bias in LLMs, through the\nlens of job recommendations. We demonstrate the effectiveness of our method by\nmeasuring intersectional biases within ChatGPT and LLaMA, two cutting-edge\nLLMs. Our experiments primarily focus on uncovering gender identity and\nnationality bias; however, our method can be extended to examine biases\nassociated with any intersection of demographic identities. We identify\ndistinct biases in both models toward various demographic identities, such as\nboth models consistently suggesting low-paying jobs for Mexican workers or\npreferring to recommend secretarial roles to women. Our study highlights the\nimportance of measuring the bias of LLMs in downstream applications to\nunderstand the potential for harm and inequitable outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salinas_A/0/1/0/all/0/1\">Abel Salinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_P/0/1/0/all/0/1\">Parth Vipul Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuzhong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCormack_R/0/1/0/all/0/1\">Robert McCormack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1\">Fred Morstatter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Text-based Dialogue State Tracker for Spoken Dialogues. (arXiv:2308.15053v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.15053","description":"<p>Although there have been remarkable advances in dialogue systems through the\ndialogue systems technology competition (DSTC), it remains one of the key\nchallenges to building a robust task-oriented dialogue system with a speech\ninterface. Most of the progress has been made for text-based dialogue systems\nsince there are abundant datasets with written corpora while those with spoken\ndialogues are very scarce. However, as can be seen from voice assistant systems\nsuch as Siri and Alexa, it is of practical importance to transfer the success\nto spoken dialogues. In this paper, we describe our engineering effort in\nbuilding a highly successful model that participated in the speech-aware\ndialogue systems technology challenge track in DSTC11. Our model consists of\nthree major modules: (1) automatic speech recognition error correction to\nbridge the gap between the spoken and the text utterances, (2) text-based\ndialogue system (D3ST) for estimating the slots and values using slot\ndescriptions, and (3) post-processing for recovering the error of the estimated\nslot value. Our experiments show that it is important to use an explicit\nautomatic speech recognition error correction module, post-processing, and data\naugmentation to adapt a text-based dialogue state tracker for spoken dialogue\ncorpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaeseok Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Seunghyun Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1\">Ran Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bang_J/0/1/0/all/0/1\">Jeonguk Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kee-Eung Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentations for Improved (Large) Language Model Generalization. (arXiv:2310.12803v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.12803","description":"<p>The reliance of text classifiers on spurious correlations can lead to poor\ngeneralization at deployment, raising concerns about their use in\nsafety-critical domains such as healthcare. In this work, we propose to use\ncounterfactual data augmentation, guided by knowledge of the causal structure\nof the data, to simulate interventions on spurious features and to learn more\nrobust text classifiers. We show that this strategy is appropriate in\nprediction problems where the label is spuriously correlated with an attribute.\nUnder the assumptions of such problems, we discuss the favorable sample\ncomplexity of counterfactual data augmentation, compared to importance\nre-weighting. Pragmatically, we match examples using auxiliary data, based on\ndiff-in-diff methodology, and use a large language model (LLM) to represent a\nconditional probability of text. Through extensive experimentation on learning\ncaregiver-invariant predictors of clinical diagnoses from medical narratives\nand on semi-synthetic data, we demonstrate that our method for simulating\ninterventions improves out-of-distribution (OOD) accuracy compared to baseline\ninvariant learning algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Claudia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saria_S/0/1/0/all/0/1\">Suchi Saria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1\">David Blei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Logical Forms improve fidelity in Table-to-Text generation. (arXiv:2310.17279v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.17279","description":"<p>Table-to-text systems generate natural language statements from structured\ndata like tables. While end-to-end techniques suffer from low factual\ncorrectness (fidelity), a previous study reported gains when using manual\nlogical forms (LF) that represent the selected content and the semantics of the\ntarget text. Given the manual step, it was not clear whether automatic LFs\nwould be effective, or whether the improvement came from content selection\nalone. We present TlT which, given a table and a selection of the content,\nfirst produces LFs and then the textual statement. We show for the first time\nthat automatic LFs improve quality, with an increase in fidelity of 30 points\nover a comparable system not using LFs. Our experiments allow to quantify the\nremaining challenges for high factual correctness, with automatic selection of\ncontent coming first, followed by better Logic-to-Text generation and, to a\nlesser extent, better Table-to-Logic parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alonso_I/0/1/0/all/0/1\">I&#xf1;igo Alonso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs cannot find reasoning errors, but can correct them!. (arXiv:2311.08516v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2311.08516","description":"<p>While self-correction has shown promise in improving LLM outputs in terms of\nstyle and quality (e.g. Chen et al., 2023; Madaan et al., 2023), recent\nattempts to self-correct logical or reasoning errors often cause correct\nanswers to become incorrect, resulting in worse performances overall (Huang et\nal., 2023). In this paper, we break down the self-correction process into two\ncore components: mistake finding and output correction. For mistake finding, we\nrelease BIG-Bench Mistake, a dataset of logical mistakes in Chain-of-Thought\nreasoning traces. We provide benchmark numbers for several state-of-the-art\nLLMs, and demonstrate that LLMs generally struggle with finding logical\nmistakes. For output correction, we propose a backtracking method which\nprovides large improvements when given information on mistake location. We\nconstrue backtracking as a lightweight alternative to reinforcement learning\nmethods, and show that it remains effective with a reward model at 60-70%\naccuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tyen_G/0/1/0/all/0/1\">Gladys Tyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansoor_H/0/1/0/all/0/1\">Hassan Mansoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carbune_V/0/1/0/all/0/1\">Victor C&#x103;rbune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Peter Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_T/0/1/0/all/0/1\">Tony Mak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mPLUG-PaperOwl: Scientific Diagram Analysis with the Multimodal Large Language Model. (arXiv:2311.18248v2 [cs.MM] UPDATED)","link":"http://arxiv.org/abs/2311.18248","description":"<p>Recently, the strong text creation ability of Large Language Models(LLMs) has\ngiven rise to many tools for assisting paper reading or even writing. However,\nthe weak diagram analysis abilities of LLMs or Multimodal LLMs greatly limit\ntheir application scenarios, especially for scientific academic paper writing.\nIn this work, towards a more versatile copilot for academic paper writing, we\nmainly focus on strengthening the multi-modal diagram analysis ability of\nMultimodal LLMs. By parsing Latex source files of high-quality papers, we\ncarefully build a multi-modal diagram understanding dataset M-Paper. By\naligning diagrams in the paper with related paragraphs, we construct\nprofessional diagram analysis samples for training and evaluation. M-Paper is\nthe first dataset to support joint comprehension of multiple scientific\ndiagrams, including figures and tables in the format of images or Latex codes.\nBesides, to better align the copilot with the user's intention, we introduce\nthe `outline' as the control signal, which could be directly given by the user\nor revised based on auto-generated ones. Comprehensive experiments with a\nstate-of-the-art Mumtimodal LLM demonstrate that training on our dataset shows\nstronger scientific diagram understanding performance, including diagram\ncaptioning, diagram analysis, and outline recommendation. The dataset, code,\nand model are available at\nhttps://github.com/X-PLUG/mPLUG-DocOwl/tree/main/PaperOwl.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1\">Anwen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yaya Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiabo Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinghao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Q/0/1/0/all/0/1\">Qi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Expand BERT Representation with Visual Information via Grounded Language Learning with Multimodal Partial Alignment. (arXiv:2312.01592v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.01592","description":"<p>Language models have been supervised with both language-only objective and\nvisual grounding in existing studies of visual-grounded language learning.\nHowever, due to differences in the distribution and scale of visual-grounded\ndatasets and language corpora, the language model tends to mix up the context\nof the tokens that occurred in the grounded data with those that do not. As a\nresult, during representation learning, there is a mismatch between the visual\ninformation and the contextual meaning of the sentence. To overcome this\nlimitation, we propose GroundedBERT - a grounded language learning method that\nenhances the BERT representation with visually grounded information.\nGroundedBERT comprises two components: (i) the original BERT which captures the\ncontextual representation of words learned from the language corpora, and (ii)\na visual grounding module which captures visual information learned from\nvisual-grounded datasets. Moreover, we employ Optimal Transport (OT),\nspecifically its partial variant, to solve the fractional alignment problem\nbetween the two modalities. Our proposed method significantly outperforms the\nbaseline language models on various language tasks of the GLUE and SQuAD\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cong-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_Le_T/0/1/0/all/0/1\">The-Anh Vu-Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_T/0/1/0/all/0/1\">Tho Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is Bigger and Deeper Always Better? Probing LLaMA Across Scales and Layers. (arXiv:2312.04333v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.04333","description":"<p>This paper presents an in-depth analysis of Large Language Models (LLMs),\nfocusing on LLaMA, a prominent open-source foundational model in natural\nlanguage processing. Instead of assessing LLaMA through its generative output,\nwe design multiple-choice tasks to probe its intrinsic understanding in\nhigh-order tasks such as reasoning and computation. We examine the model\nhorizontally, comparing different sizes, and vertically, assessing different\nlayers. We unveil several key and uncommon findings based on the designed\nprobing tasks: (1) Horizontally, enlarging model sizes almost could not\nautomatically impart additional knowledge or computational prowess. Instead, it\ncan enhance reasoning abilities, especially in math problem solving, and helps\nreduce hallucinations, but only beyond certain size thresholds; (2) In vertical\nanalysis, the lower layers of LLaMA lack substantial arithmetic and factual\nknowledge, showcasing logical thinking, multilingual and recognitive abilities,\nwith top layers housing most computational power and real-world knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Ning Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shining Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Ming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1\">Linjun Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparable Demonstrations are Important in In-Context Learning: A Novel Perspective on Demonstration Selection. (arXiv:2312.07476v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.07476","description":"<p>In-Context Learning (ICL) is an important paradigm for adapting Large\nLanguage Models (LLMs) to downstream tasks through a few demonstrations.\nDespite the great success of ICL, the limitation of the demonstration number\nmay lead to demonstration bias, i.e. the input-label mapping induced by LLMs\nmisunderstands the task's essence. Inspired by human experience, we attempt to\nmitigate such bias through the perspective of the inter-demonstration\nrelationship. Specifically, we construct Comparable Demonstrations (CDs) by\nminimally editing the texts to flip the corresponding labels, in order to\nhighlight the task's essence and eliminate potential spurious correlations\nthrough the inter-demonstration comparison. Through a series of experiments on\nCDs, we find that (1) demonstration bias does exist in LLMs, and CDs can\nsignificantly reduce such bias; (2) CDs exhibit good performance in ICL,\nespecially in out-of-distribution scenarios. In summary, this study explores\nthe ICL mechanisms from a novel perspective, providing a deeper insight into\nthe demonstration selection strategy for ICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Caoyun Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Jidong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yitian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yaohui Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation. (arXiv:2312.09085v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.09085","description":"<p>Large Language Models (LLMs) encapsulate vast amounts of knowledge but still\nremain vulnerable to external misinformation. Existing research mainly studied\nthis susceptibility behavior in a single-turn setting. However, belief can\nchange during a multi-turn conversation, especially a persuasive one.\nTherefore, in this study, we delve into LLMs' susceptibility to persuasive\nconversations, particularly on factual questions that they can answer\ncorrectly. We first curate the Farm (i.e., Fact to Misinform) dataset, which\ncontains factual questions paired with systematically generated persuasive\nmisinformation. Then, we develop a testing framework to track LLMs' belief\nchanges in a persuasive dialogue. Through extensive experiments, we find that\nLLMs' correct beliefs on factual knowledge can be easily manipulated by various\npersuasive strategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Rongwu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Brian S. Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shujian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhixuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Han Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jatmo: Prompt Injection Defense by Task-Specific Finetuning. (arXiv:2312.17673v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2312.17673","description":"<p>Large Language Models (LLMs) are attracting significant research attention\ndue to their instruction-following abilities, allowing users and developers to\nleverage LLMs for a variety of tasks. However, LLMs are vulnerable to\nprompt-injection attacks: a class of attacks that hijack the model's\ninstruction-following abilities, changing responses to prompts to undesired,\npossibly malicious ones. In this work, we introduce Jatmo, a method for\ngenerating task-specific models resilient to prompt-injection attacks. Jatmo\nleverages the fact that LLMs can only follow instructions once they have\nundergone instruction tuning. It harnesses a teacher instruction-tuned model to\ngenerate a task-specific dataset, which is then used to fine-tune a base model\n(i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a\ndataset of inputs for the task: it uses the teacher model to generate outputs.\nFor situations with no pre-existing datasets, Jatmo can use a single example,\nor in some cases none at all, to produce a fully synthetic dataset. Our\nexperiments on seven tasks show that Jatmo models provide similar quality of\noutputs on their specific task as standard LLMs, while being resilient to\nprompt injections. The best attacks succeeded in less than 0.5% of cases\nagainst our models, versus 87% success rate against GPT-3.5-Turbo. We release\nJatmo at https://github.com/wagner-group/prompt-injection-defense.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Piet_J/0/1/0/all/0/1\">Julien Piet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alrashed_M/0/1/0/all/0/1\">Maha Alrashed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitawarin_C/0/1/0/all/0/1\">Chawin Sitawarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sizhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zeming Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1\">Elizabeth Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alomair_B/0/1/0/all/0/1\">Basel Alomair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1\">David Wagner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CharacterEval: A Chinese Benchmark for Role-Playing Conversational Agent Evaluation. (arXiv:2401.01275v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01275","description":"<p>Recently, the advent of large language models (LLMs) has revolutionized\ngenerative agents. Among them, Role-Playing Conversational Agents (RPCAs)\nattract considerable attention due to their ability to emotionally engage\nusers. However, the absence of a comprehensive benchmark impedes progress in\nthis field. To bridge this gap, we introduce CharacterEval, a Chinese benchmark\nfor comprehensive RPCA assessment, complemented by a tailored high-quality\ndataset. The dataset comprises 1,785 multi-turn role-playing dialogues,\nencompassing 23,020 examples and featuring 77 characters derived from Chinese\nnovels and scripts. It was carefully constructed, beginning with initial\ndialogue extraction via GPT-4, followed by rigorous human-led quality control,\nand enhanced with in-depth character profiles sourced from Baidu Baike.\nCharacterEval employs a multifaceted evaluation approach, encompassing thirteen\ntargeted metrics on four dimensions. Comprehensive experiments on CharacterEval\ndemonstrate that Chinese LLMs exhibit more promising capabilities than GPT-4 in\nChinese role-playing conversation. Source code, data source and reward model\nwill be publicly accessible at https://github.com/morecry/CharacterEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_Q/0/1/0/all/0/1\">Quan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Shilong Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zihang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01286","description":"<p>Large Language Models (LLMs) have shown extraordinary capabilities in\nunderstanding and generating text that closely mirrors human communication.\nHowever, a primary limitation lies in the significant computational demands\nduring training, arising from their extensive parameterization. This challenge\nis further intensified by the dynamic nature of the world, necessitating\nfrequent updates to LLMs to correct outdated information or integrate new\nknowledge, thereby ensuring their continued relevance. Note that many\napplications demand continual model adjustments post-training to address\ndeficiencies or undesirable behaviors. There is an increasing interest in\nefficient, lightweight methods for on-the-fly model modifications. To this end,\nrecent years have seen a burgeoning in the techniques of knowledge editing for\nLLMs, which aim to efficiently modify LLMs' behaviors within specific domains\nwhile preserving overall performance across various inputs. In this paper, we\nfirst define the knowledge editing problem and then provide a comprehensive\nreview of cutting-edge approaches. Drawing inspiration from educational and\ncognitive research theories, we propose a unified categorization criterion that\nclassifies knowledge editing methods into three groups: resorting to external\nknowledge, merging knowledge into the model, and editing intrinsic knowledge.\nFurthermore, we introduce a new benchmark, KnowEdit, for a comprehensive\nempirical evaluation of representative knowledge editing approaches.\nAdditionally, we provide an in-depth analysis of knowledge location, which can\ngive a deeper understanding of the knowledge structures inherent within LLMs.\nFinally, we discuss several potential applications of knowledge editing,\noutlining its broad and impactful implications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1\">Bozhong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zekun Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shengyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jintian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1\">Yuansheng Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Siyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Lei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaowei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Instruction Tuning With Just a Pinch of Multilinguality. (arXiv:2401.01854v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01854","description":"<p>As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. One promising approach is cross-lingual transfer, where a model\nacquires specific functionality on some language by finetuning on another\nlanguage. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages. We\nfirst show that many languages transfer some instruction-following capabilities\nto other languages from even monolingual tuning. Furthermore, we find that only\n40 multilingual examples in an English tuning set substantially improve\nmultilingual instruction-following, both in seen and unseen languages during\ntuning. In general, we observe that models tuned on multilingual mixtures\nexhibit comparable or superior performance in several languages compared to\nmonolingually tuned models, despite training on 10x fewer examples in those\nlanguages. Finally, we find that increasing the number of languages in the\ninstruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual\ngeneralization. Our results suggest that building massively multilingual\ninstruction-tuned models can be done with only a very small set of multilingual\ninstruction-responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1\">Uri Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsarfaty_R/0/1/0/all/0/1\">Reut Tsarfaty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eyal_M/0/1/0/all/0/1\">Matan Eyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.02994","description":"<p>In conversational AI research, there's a noticeable trend towards developing\nmodels with a larger number of parameters, exemplified by models like ChatGPT.\nWhile these expansive models tend to generate increasingly better chat\nresponses, they demand significant computational resources and memory. This\nstudy explores a pertinent question: Can a combination of smaller models\ncollaboratively achieve comparable or enhanced performance relative to a\nsingular large model? We introduce an approach termed \"blending\", a\nstraightforward yet effective method of integrating multiple chat AIs. Our\nempirical evidence suggests that when specific smaller models are\nsynergistically blended, they can potentially outperform or match the\ncapabilities of much larger counterparts. For instance, integrating just three\nmodels of moderate size (6B/13B paramaeters) can rival or even surpass the\nperformance metrics of a substantially larger model like ChatGPT (175B+\nparamaters). This hypothesis is rigorously tested using A/B testing\nmethodologies with a large user base on the Chai research platform over a span\nof thirty days. The findings underscore the potential of the \"blending\"\nstrategy as a viable approach for enhancing chat AI efficacy without a\ncorresponding surge in computational demands.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaoding Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vyas Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beauchamp_W/0/1/0/all/0/1\">William Beauchamp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Token-free LLMs Can Generate Chinese Classical Poetry with More Accurate Format. (arXiv:2401.03512v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.03512","description":"<p>Finetuned large language models (such as ChatGPT and Qwen-chat) can generate\nChinese classical poetry following human's instructions. LLMs perform well in\ncontent, but are usually lacking in format, with occasionally excess or\ninsufficient number of characters in each line. Since most SOTA LLMs are\ntoken-based, we assume that the format inaccuracy is due to the difficulty of\nthe \"token planning\" task, which means that the LLM need to know exactly how\nmuch characters are contained in each token and do length-control planning\nbased on that knowledge. In this paper, we first confirm our assumption by\nshowing that existing token-based large language models has limited knowledge\non token-character relationship. We use a spelling bee probing procedure, and\nfind that Qwen-chat failed in nearly 15% Chinese spelling test. We then show\nthat a token-based model can be easily tailored into a token-free model (in\nterms of Chinese), which can largely solve the format accuracy problem. Our\ntailoring procedure removes long-tokens from the vocabulary and the language\nmodel head, and keeps only character-level or byte-level tokens. As part of our\ncontribution, we release the finetuned token-free model (which is based on\nQwen-chat-7B), which can generate chinese classical poetry following complex\ninstructions like LLMs (such as story paraphrasing), and also perform well in\nformat. On the test set, our token-free model achives an format accuracy of\n0.96, compared to 0.84 for token-based equivalents and 0.38 for GPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chengyue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zang_L/0/1/0/all/0/1\">Lei Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaotuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_C/0/1/0/all/0/1\">Chenyi Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ROIC-DM: Robust Text Inference and Classification via Diffusion Model. (arXiv:2401.03514v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.03514","description":"<p>While language models have made many milestones in text inference and\nclassification tasks, they remain susceptible to adversarial attacks that can\nlead to unforeseen outcomes. Existing works alleviate this problem by equipping\nlanguage models with defense patches. However, these defense strategies often\nrely on impractical assumptions or entail substantial sacrifices in model\nperformance. Consequently, enhancing the resilience of the target model using\nsuch defense mechanisms is a formidable challenge. This paper introduces an\ninnovative model for robust text inference and classification, built upon\ndiffusion models (ROIC-DM). Benefiting from its training involving denoising\nstages, ROIC-DM inherently exhibits greater robustness compared to conventional\nlanguage models. Moreover, ROIC-DM can attain comparable, and in some cases,\nsuperior performance to language models, by effectively incorporating them as\nadvisory components. Extensive experiments conducted with several strong\ntextual adversarial attacks on three datasets demonstrate that (1) ROIC-DM\noutperforms traditional language models in robustness, even when the latter are\nfortified with advanced defense mechanisms; (2) ROIC-DM can achieve comparable\nand even better performance than traditional language models by using them as\nadvisors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shilong Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Wei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hongzhi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tieke He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance. (arXiv:2401.03729v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.03729","description":"<p>Large Language Models (LLMs) are regularly being used to label data across\nmany domains and for myriad tasks. By simply asking the LLM for an answer, or\n``prompting,'' practitioners are able to use LLMs to quickly get a response for\nan arbitrary task. This prompting is done through a series of decisions by the\npractitioner, from simple wording of the prompt, to requesting the output in a\ncertain data format, to jailbreaking in the case of prompts that address more\nsensitive topics. In this work, we ask: do variations in the way a prompt is\nconstructed change the ultimate decision of the LLM? We answer this using a\nseries of prompt variations across a variety of text classification tasks. We\nfind that even the smallest of perturbations, such as adding a space at the end\nof a prompt, can cause the LLM to change its answer. Further, we find that\nrequesting responses in XML and commonly used jailbreaks can have cataclysmic\neffects on the data labeled by LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salinas_A/0/1/0/all/0/1\">Abel Salinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1\">Fred Morstatter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-09T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}