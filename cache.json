{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-04T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Quantifying the Uniqueness of Donald Trump in Presidential Discourse. (arXiv:2401.01405v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01405","description":"<p>Does Donald Trump speak differently from other presidents? If so, in what\nways? Are these differences confined to any single medium of communication? To\ninvestigate these questions, this paper introduces a novel metric of uniqueness\nbased on large language models, develops a new lexicon for divisive speech, and\npresents a framework for comparing the lexical features of political opponents.\nApplying these tools to a variety of corpora of presidential speeches, we find\nconsiderable evidence that Trump's speech patterns diverge from those of all\nmajor party nominees for the presidency in recent history. Some notable\nfindings include Trump's employment of particularly divisive and antagonistic\nlanguage targeting of his political opponents and his patterns of repetition\nfor emphasis. Furthermore, Trump is significantly more distinctive than his\nfellow Republicans, whose uniqueness values are comparably closer to those of\nthe Democrats. These differences hold across a variety of measurement\nstrategies, arise on both the campaign trail and in official presidential\naddresses, and do not appear to be an artifact of secular time trends.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Karen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meitus_A/0/1/0/all/0/1\">Alexander A. Meitus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chase_M/0/1/0/all/0/1\">Milo Chase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Grace Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mykland_A/0/1/0/all/0/1\">Anne Mykland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howell_W/0/1/0/all/0/1\">William Howell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine Translation vs Human Translation. (arXiv:2401.01419v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01419","description":"<p>We conduct a large-scale fine-grained comparative analysis of machine\ntranslations (MT) against human translations (HT) through the lens of\nmorphosyntactic divergence. Across three language pairs and two types of\ndivergence defined as the structural difference between the source and the\ntarget, MT is consistently more conservative than HT, with less morphosyntactic\ndiversity, more convergent patterns, and more one-to-one alignments. Through\nanalysis on different decoding algorithms, we attribute this discrepancy to the\nuse of beam search that biases MT towards more convergent patterns. This bias\nis most amplified when the convergent pattern appears around 50% of the time in\ntraining data. Lastly, we show that for a majority of morphosyntactic\ndivergences, their presence in HT is correlated with decreased MT performance,\npresenting a greater challenge for MT systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiaming Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherry_C/0/1/0/all/0/1\">Colin Cherry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_G/0/1/0/all/0/1\">George Foster</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Question-Answering Based Summarization of Electronic Health Records using Retrieval Augmented Generation. (arXiv:2401.01469v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01469","description":"<p>Summarization of electronic health records (EHRs) can substantially minimize\n'screen time' for both patients as well as medical personnel. In recent years\nsummarization of EHRs have employed machine learning pipelines using state of\nthe art neural models. However, these models have produced less than adequate\nresults that are attributed to the difficulty of obtaining sufficient annotated\ndata for training. Moreover, the requirement to consider the entire content of\nan EHR in summarization has resulted in poor performance due to the fact that\nattention mechanisms in modern large language models (LLMs) adds a quadratic\ncomplexity in terms of the size of the input. We propose here a method that\nmitigates these shortcomings by combining semantic search, retrieval augmented\ngeneration (RAG) and question-answering using the latest LLMs. In our approach\nsummarization is the extraction of answers to specific questions that are\ndeemed important by subject-matter experts (SMEs). Our approach is quite\nefficient; requires minimal to no training; does not suffer from the\n'hallucination' problem of LLMs; and it ensures diversity, since the summary\nwill not have repeated content but diverse answers to specific questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saba_W/0/1/0/all/0/1\">Walid Saba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wendelken_S/0/1/0/all/0/1\">Suzanne Wendelken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_J/0/1/0/all/0/1\">James. Shanahan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A First Look at Information Highlighting in Stack Overflow Answers. (arXiv:2401.01472v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01472","description":"<p>Context: Navigating the knowledge of Stack Overflow (SO) remains challenging.\nTo make the posts vivid to users, SO allows users to write and edit posts with\nMarkdown or HTML so that users can leverage various formatting styles (e.g.,\nbold, italic, and code) to highlight the important information. Nonetheless,\nthere have been limited studies on the highlighted information. Objective: We\ncarried out the first large-scale exploratory study on the information\nhighlighted in SO answers in our recent study. To extend our previous study, we\ndevelop approaches to automatically recommend highlighted content with\nformatting styles using neural network architectures initially designed for the\nNamed Entity Recognition task. Method: In this paper, we studied 31,169,429\nanswers of Stack Overflow. For training recommendation models, we choose CNN\nand BERT models for each type of formatting (i.e., Bold, Italic, Code, and\nHeading) using the information highlighting dataset we collected from SO\nanswers. Results: Our models based on CNN architecture achieve precision\nranging from 0.71 to 0.82. The trained model for automatic code content\nhighlighting achieves a recall of 0.73 and an F1 score of 0.71, outperforming\nthe trained models for other formatting styles. The BERT models have even lower\nrecalls and F1 scores than the CNN models. Our analysis of failure cases\nindicates that the majority of the failure cases are missing identification\n(i.e., the model misses the content that is supposed to be highlighted) due to\nthe models tend to learn the frequently highlighted words while struggling to\nlearn less frequent words. Conclusion: Our findings suggest that it is possible\nto develop recommendation models for highlighting information for answers with\ndifferent formatting styles on Stack Overflow.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Shahla Shaan Ahmed</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shaowei Wang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Tse-Hsun/0/1/0/all/0/1\">Tse-Hsun</a> (Peter) <a href=\"http://arxiv.org/find/cs/1/au:+Chen/0/1/0/all/0/1\">Chen</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoxiang Zhang</a> (4) ((1) Department of Computer Science, University of Manitoba, Canada, (2) School of Computing, Queen&#x27;s University, Canada, (3) Department of Computer Science and Software Engineering, Concordia University, Canada, (4) Huawei, Canada)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Language Processing and Multimodal Stock Price Prediction. (arXiv:2401.01487v1 [cs.LG])","link":"http://arxiv.org/abs/2401.01487","description":"<p>In the realm of financial decision-making, predicting stock prices is\npivotal. Artificial intelligence techniques such as long short-term memory\nnetworks (LSTMs), support-vector machines (SVMs), and natural language\nprocessing (NLP) models are commonly employed to predict said prices. This\npaper utilizes stock percentage change as training data, in contrast to the\ntraditional use of raw currency values, with a focus on analyzing publicly\nreleased news articles. The choice of percentage change aims to provide models\nwith context regarding the significance of price fluctuations and overall price\nchange impact on a given stock. The study employs specialized BERT natural\nlanguage processing models to predict stock price trends, with a particular\nemphasis on various data modalities. The results showcase the capabilities of\nsuch strategies with a small natural language processing model to accurately\npredict overall stock trends, and highlight the effectiveness of certain data\nfeatures and sector-specific data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Taylor_K/0/1/0/all/0/1\">Kevin Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_J/0/1/0/all/0/1\">Jerry Ng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Two-Stage Multimodal Emotion Recognition Model Based on Graph Contrastive Learning. (arXiv:2401.01495v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01495","description":"<p>In terms of human-computer interaction, it is becoming more and more\nimportant to correctly understand the user's emotional state in a conversation,\nso the task of multimodal emotion recognition (MER) started to receive more\nattention. However, existing emotion classification methods usually perform\nclassification only once. Sentences are likely to be misclassified in a single\nround of classification. Previous work usually ignores the similarities and\ndifferences between different morphological features in the fusion process. To\naddress the above issues, we propose a two-stage emotion recognition model\nbased on graph contrastive learning (TS-GCL). First, we encode the original\ndataset with different preprocessing modalities. Second, a graph contrastive\nlearning (GCL) strategy is introduced for these three modal data with other\nstructures to learn similarities and differences within and between modalities.\nFinally, we use MLP twice to achieve the final emotion classification. This\nstaged classification method can help the model to better focus on different\nlevels of emotional information, thereby improving the performance of the\nmodel. Extensive experiments show that TS-GCL has superior performance on\nIEMOCAP and MELD datasets compared with previous methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ai_W/0/1/0/all/0/1\">Wei Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">FuChen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_T/0/1/0/all/0/1\">Tao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_Y/0/1/0/all/0/1\">YunTao Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1\">HongEn Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Keqin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic Token Prediction. (arXiv:2401.01498v1 [eess.AS])","link":"http://arxiv.org/abs/2401.01498","description":"<p>We propose a novel text-to-speech (TTS) framework centered around a neural\ntransducer. Our approach divides the whole TTS pipeline into semantic-level\nsequence-to-sequence (seq2seq) modeling and fine-grained acoustic modeling\nstages, utilizing discrete semantic tokens obtained from wav2vec2.0 embeddings.\nFor a robust and efficient alignment modeling, we employ a neural transducer\nnamed token transducer for the semantic token prediction, benefiting from its\nhard monotonic alignment constraints. Subsequently, a non-autoregressive (NAR)\nspeech generator efficiently synthesizes waveforms from these semantic tokens.\nAdditionally, a reference speech controls temporal dynamics and acoustic\nconditions at each stage. This decoupled framework reduces the training\ncomplexity of TTS while allowing each stage to focus on semantic and acoustic\nmodeling. Our experimental results on zero-shot adaptive TTS demonstrate that\nour model surpasses the baseline in terms of speech quality and speaker\nsimilarity, both objectively and subjectively. We also delve into the inference\nspeed and prosody control capabilities of our approach, highlighting the\npotential of neural transducers in TTS frameworks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Kim_M/0/1/0/all/0/1\">Minchan Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Jeong_M/0/1/0/all/0/1\">Myeonghun Jeong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Choi_B/0/1/0/all/0/1\">Byoung Jin Choi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1\">Semin Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1\">Joun Yeop Lee</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_N/0/1/0/all/0/1\">Nam Soo Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse. (arXiv:2401.01523v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01523","description":"<p>The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and imagery. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Ziyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models. (arXiv:2401.01572v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01572","description":"<p>Hallucinations are a type of output error produced by deep neural networks.\nWhile this has been studied in natural language processing, they have not been\nresearched previously in automatic speech recognition. Here, we define\nhallucinations in ASR as transcriptions generated by a model that are\nsemantically unrelated to the source utterance, yet still fluent and coherent.\nThe similarity of hallucinations to probable natural language outputs of the\nmodel creates a danger of deception and impacts the credibility of the system.\nWe show that commonly used metrics, such as word error rates, cannot\ndifferentiate between hallucinatory and non-hallucinatory models. To address\nthis, we propose a perturbation-based method for assessing the susceptibility\nof an automatic speech recognition (ASR) model to hallucination at test time,\nwhich does not require access to the training dataset. We demonstrate that this\nmethod helps to distinguish between hallucinatory and non-hallucinatory models\nthat have similar baseline word error rates. We further explore the\nrelationship between the types of ASR errors and the types of dataset noise to\ndetermine what types of noise are most likely to create hallucinatory outputs.\nWe devise a framework for identifying hallucinations by analysing their\nsemantic connection with the ground truth and their fluency. Finally, we\ndiscover how to induce hallucinations with a random noise injection to the\nutterance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Frieske_R/0/1/0/all/0/1\">Rita Frieske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bertram E. Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English Clinical Queries. (arXiv:2401.01596v1 [cs.AI])","link":"http://arxiv.org/abs/2401.01596","description":"<p>In the healthcare domain, summarizing medical questions posed by patients is\ncritical for improving doctor-patient interactions and medical decision-making.\nAlthough medical data has grown in complexity and quantity, the current body of\nresearch in this domain has primarily concentrated on text-based methods,\noverlooking the integration of visual cues. Also prior works in the area of\nmedical question summarisation have been limited to the English language. This\nwork introduces the task of multimodal medical question summarization for\ncodemixed input in a low-resource setting. To address this gap, we introduce\nthe Multimodal Medical Codemixed Question Summarization MMCQS dataset, which\ncombines Hindi-English codemixed medical queries with visual aids. This\nintegration enriches the representation of a patient's medical condition,\nproviding a more comprehensive perspective. We also propose a framework named\nMedSumm that leverages the power of LLMs and VLMs for this task. By utilizing\nour MMCQS dataset, we demonstrate the value of integrating visual information\nfrom images to improve the creation of medically detailed summaries. This\nmultimodal strategy not only improves healthcare decision-making but also\npromotes a deeper comprehension of patient queries, paving the way for future\nexploration in personalized and responsive medical care. Our dataset, code, and\npre-trained models will be made publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Akash Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Arkadeep Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_P/0/1/0/all/0/1\">Prince Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaudgaul_A/0/1/0/all/0/1\">Aniket Gaudgaul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_R/0/1/0/all/0/1\">Rajdeep Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Sriparna Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Raghav Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_S/0/1/0/all/0/1\">Setu Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Shivani Agarwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PLLaMa: An Open-source Large Language Model for Plant Science. (arXiv:2401.01600v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01600","description":"<p>Large Language Models (LLMs) have exhibited remarkable capabilities in\nunderstanding and interacting with natural language across various sectors.\nHowever, their effectiveness is limited in specialized areas requiring high\naccuracy, such as plant science, due to a lack of specific expertise in these\nfields. This paper introduces PLLaMa, an open-source language model that\nevolved from LLaMa-2. It's enhanced with a comprehensive database, comprising\nmore than 1.5 million scholarly articles in plant science. This development\nsignificantly enriches PLLaMa with extensive knowledge and proficiency in plant\nand agricultural sciences. Our initial tests, involving specific datasets\nrelated to plants and agriculture, show that PLLaMa substantially improves its\nunderstanding of plant science-related topics. Moreover, we have formed an\ninternational panel of professionals, including plant scientists, agricultural\nengineers, and plant breeders. This team plays a crucial role in verifying the\naccuracy of PLLaMa's responses to various academic inquiries, ensuring its\neffective and reliable application in the field. To support further research\nand development, we have made the model's checkpoints and source codes\naccessible to the scientific community. These resources are available for\ndownload at \\url{https://github.com/Xianjun-Yang/PLLaMa}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Junfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wenxin Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexandersson_E/0/1/0/all/0/1\">Erik Alexandersson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-4V(ision) is a Generalist Web Agent, if Grounded. (arXiv:2401.01614v1 [cs.IR])","link":"http://arxiv.org/abs/2401.01614","description":"<p>The recent development on large multimodal models (LMMs), especially\nGPT-4V(ision) and Gemini, has been quickly expanding the capability boundaries\nof multimodal models beyond traditional tasks like image captioning and visual\nquestion answering. In this work, we explore the potential of LMMs like GPT-4V\nas a generalist web agent that can follow natural language instructions to\ncomplete tasks on any given website. We propose SEEACT, a generalist web agent\nthat harnesses the power of LMMs for integrated visual understanding and acting\non the web. We evaluate on the recent MIND2WEB benchmark. In addition to\nstandard offline evaluation on cached websites, we enable a new online\nevaluation setting by developing a tool that allows running web agents on live\nwebsites. We show that GPT-4V presents a great potential for web agents - it\ncan successfully complete 50% of the tasks on live websites if we manually\nground its textual plans into actions on the websites. This substantially\noutperforms text-only LLMs like GPT-4 or smaller models (FLAN-T5 and BLIP-2)\nspecifically fine-tuned for web agents. However, grounding still remains a\nmajor challenge. Existing LMM grounding strategies like set-of-mark prompting\nturns out not effective for web agents, and the best grounding strategy we\ndevelop in this paper leverages both the HTML text and visuals. Yet, there is\nstill a substantial gap with oracle grounding, leaving ample room for further\nimprovement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Boyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gou_B/0/1/0/all/0/1\">Boyu Gou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kil_J/0/1/0/all/0/1\">Jihyung Kil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model Capabilities in Perioperative Risk Prediction and Prognostication. (arXiv:2401.01620v1 [cs.AI])","link":"http://arxiv.org/abs/2401.01620","description":"<p>We investigate whether general-domain large language models such as GPT-4\nTurbo can perform risk stratification and predict post-operative outcome\nmeasures using a description of the procedure and a patient's clinical notes\nderived from the electronic health record. We examine predictive performance on\n8 different tasks: prediction of ASA Physical Status Classification, hospital\nadmission, ICU admission, unplanned admission, hospital mortality, PACU Phase 1\nduration, hospital duration, and ICU duration. Few-shot and chain-of-thought\nprompting improves predictive performance for several of the tasks. We achieve\nF1 scores of 0.50 for ASA Physical Status Classification, 0.81 for ICU\nadmission, and 0.86 for hospital mortality. Performance on duration prediction\ntasks were universally poor across all prompt strategies. Current generation\nlarge language models can assist clinicians in perioperative risk\nstratification on classification tasks and produce high-quality natural\nlanguage summaries and explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chung_P/0/1/0/all/0/1\">Philip Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fong_C/0/1/0/all/0/1\">Christine T Fong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walters_A/0/1/0/all/0/1\">Andrew M Walters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghaeepour_N/0/1/0/all/0/1\">Nima Aghaeepour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1\">Meliha Yetisgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OReilly_Shah_V/0/1/0/all/0/1\">Vikas N O&#x27;Reilly-Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can AI Be as Creative as Humans?. (arXiv:2401.01623v1 [cs.AI])","link":"http://arxiv.org/abs/2401.01623","description":"<p>Creativity serves as a cornerstone for societal progress and innovation, but\nits assessment remains a complex and often subjective endeavor. With the rise\nof advanced generative AI models capable of tasks once reserved for human\ncreativity, the study of AI's creative potential becomes imperative for its\nresponsible development and application. This paper addresses the complexities\nin defining and evaluating creativity by introducing a new concept called\nRelative Creativity. Instead of trying to define creativity universally, we\nshift the focus to whether AI can match the creative abilities of a\nhypothetical human. This perspective draws inspiration from the Turing Test,\nexpanding upon it to address the challenges and subjectivities inherent in\nevaluating creativity. This methodological shift facilitates a statistically\nquantifiable evaluation of AI's creativity, which we term Statistical\nCreativity. This approach allows for direct comparisons of AI's creative\nabilities with those of specific human groups. Building on this foundation, we\ndiscuss the application of statistical creativity in contemporary\nprompt-conditioned autoregressive models. In addition to defining and analyzing\na measure of creativity, we introduce an actionable training guideline,\neffectively bridging the gap between theoretical quantification of creativity\nand practical model training. Through these multifaceted contributions, the\npaper establishes a cohesive, continuously evolving, and transformative\nframework for assessing and fostering statistical creativity in AI models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haonan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1\">Michael Mozer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linjun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1\">Alex Lamb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1\">Michael Qizhe Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_H/0/1/0/all/0/1\">Hannah Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Social Media Ready Caption Generation for Brands. (arXiv:2401.01637v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01637","description":"<p>Social media advertisements are key for brand marketing, aiming to attract\nconsumers with captivating captions and pictures or logos. While previous\nresearch has focused on generating captions for general images, incorporating\nbrand personalities into social media captioning remains unexplored. Brand\npersonalities are shown to be affecting consumers' behaviours and social\ninteractions and thus are proven to be a key aspect of marketing strategies.\nCurrent open-source multimodal LLMs are not directly suited for this task.\nHence, we propose a pipeline solution to assist brands in creating engaging\nsocial media captions that align with the image and the brand personalities.\nOur architecture is based on two parts: a the first part contains an image\ncaptioning model that takes in an image that the brand wants to post online and\ngives a plain English caption; b the second part takes in the generated caption\nalong with the target brand personality and outputs a catchy\npersonality-aligned social media caption. Along with brand personality, our\nsystem also gives users the flexibility to provide hashtags, Instagram handles,\nURLs, and named entities they want the caption to contain, making the captions\nmore semantically related to the social media handles. Comparative evaluations\nagainst various baselines demonstrate the effectiveness of our approach, both\nqualitatively and quantitatively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_H/0/1/0/all/0/1\">Himanshu Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_K/0/1/0/all/0/1\">Koustava Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1\">Apoorv Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balaji Vasan Srinivasan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MLPs Compass: What is learned when MLPs are combined with PLMs?. (arXiv:2401.01667v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01667","description":"<p>While Transformer-based pre-trained language models and their variants\nexhibit strong semantic representation capabilities, the question of\ncomprehending the information gain derived from the additional components of\nPLMs remains an open question in this field. Motivated by recent efforts that\nprove Multilayer-Perceptrons (MLPs) modules achieving robust structural capture\ncapabilities, even outperforming Graph Neural Networks (GNNs), this paper aims\nto quantify whether simple MLPs can further enhance the already potent ability\nof PLMs to capture linguistic information. Specifically, we design a simple yet\neffective probing framework containing MLPs components based on BERT structure\nand conduct extensive experiments encompassing 10 probing tasks spanning three\ndistinct linguistic levels. The experimental results demonstrate that MLPs can\nindeed enhance the comprehension of linguistic structure by PLMs. Our research\nprovides interpretable and valuable insights into crafting variations of PLMs\nutilizing MLPs for tasks that emphasize diverse linguistic structures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Li Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Dingyi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanlong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Hong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predicting challenge moments from students' discourse: A comparison of GPT-4 to two traditional natural language processing approaches. (arXiv:2401.01692v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01692","description":"<p>Effective collaboration requires groups to strategically regulate themselves\nto overcome challenges. Research has shown that groups may fail to regulate due\nto differences in members' perceptions of challenges which may benefit from\nexternal support. In this study, we investigated the potential of leveraging\nthree distinct natural language processing models: an expert knowledge\nrule-based model, a supervised machine learning (ML) model and a Large Language\nmodel (LLM), in challenge detection and challenge dimension identification\n(cognitive, metacognitive, emotional and technical/other challenges) from\nstudent discourse, was investigated. The results show that the supervised ML\nand the LLM approaches performed considerably well in both tasks, in contrast\nto the rule-based approach, whose efficacy heavily relies on the engineered\nfeatures by experts. The paper provides an extensive discussion of the three\napproaches' performance for automated detection and support of students'\nchallenge moments in collaborative learning activities. It argues that,\nalthough LLMs provide many advantages, they are unlikely to be the panacea to\nissues of the detection and feedback provision of socially shared regulation of\nlearning due to their lack of reliability, as well as issues of validity\nevaluation, privacy and confabulation. We conclude the paper with a discussion\non additional considerations, including model transparency to explore feasible\nand meaningful analytical feedback for students and educators using LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suraworachet_W/0/1/0/all/0/1\">Wannapon Suraworachet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seon_J/0/1/0/all/0/1\">Jennifer Seon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cukurova_M/0/1/0/all/0/1\">Mutlu Cukurova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Patterns of Persistence and Diffusibility across World's Languages. (arXiv:2401.01698v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01698","description":"<p>Language similarities can be caused by genetic relatedness, areal contact,\nuniversality, or chance. Colexification, i.e.~a type of similarity where a\nsingle lexical form is used to convey multiple meanings, is underexplored. In\nour work, we shed light on the linguistic causes of cross-lingual similarity in\ncolexification and phonology, by exploring genealogical stability (persistence)\nand contact-induced change (diffusibility). We construct large-scale graphs\nincorporating semantic, genealogical, phonological and geographical data for\n1,966 languages. We then show the potential of this resource, by investigating\nseveral established hypotheses from previous work in linguistics, while\nproposing new ones. Our results strongly support a previously established\nhypothesis in the linguistic literature, while offering contradicting evidence\nto another. Our large scale resource opens for further research across\ndisciplines, e.g.~in multilingual NLP and comparative linguistics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bjerva_J/0/1/0/all/0/1\">Johannes Bjerva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WordArt Designer API: User-Driven Artistic Typography Synthesis with Large Language Models on ModelScope. (arXiv:2401.01699v1 [cs.CV])","link":"http://arxiv.org/abs/2401.01699","description":"<p>This paper introduces the WordArt Designer API, a novel framework for\nuser-driven artistic typography synthesis utilizing Large Language Models\n(LLMs) on ModelScope. We address the challenge of simplifying artistic\ntypography for non-professionals by offering a dynamic, adaptive, and\ncomputationally efficient alternative to traditional rigid templates. Our\napproach leverages the power of LLMs to understand and interpret user input,\nfacilitating a more intuitive design process. We demonstrate through various\ncase studies how users can articulate their aesthetic preferences and\nfunctional requirements, which the system then translates into unique and\ncreative typographic designs. Our evaluations indicate significant improvements\nin user satisfaction, design flexibility, and creative expression over existing\nsystems. The WordArt Designer API not only democratizes the art of typography\nbut also opens up new possibilities for personalized digital communication and\ndesign.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jun-Yan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zhi-Qi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jingdong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1\">Wangmeng Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yusen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xianhui Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1\">Xiaoyang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zengke Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1\">Bin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1\">Yifeng Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xuansong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs. (arXiv:2401.01711v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01711","description":"<p>Conversational question answering systems often rely on semantic parsing to\nenable interactive information retrieval, which involves the generation of\nstructured database queries from a natural language input. For\ninformation-seeking conversations about facts stored within a knowledge graph,\ndialogue utterances are transformed into graph queries in a process that is\ncalled knowledge-based conversational question answering. This paper evaluates\nthe performance of large language models that have not been explicitly\npre-trained on this task. Through a series of experiments on an extensive\nbenchmark dataset, we compare models of varying sizes with different prompting\ntechniques and identify common issue types in the generated output. Our results\ndemonstrate that large language models are capable of generating graph queries\nfrom dialogues, with significant improvements achievable through few-shot\nprompting and fine-tuning techniques, especially for smaller models that\nexhibit lower zero-shot performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1\">Phillip Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klettner_M/0/1/0/all/0/1\">Manuel Klettner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jokinen_K/0/1/0/all/0/1\">Kristiina Jokinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simperl_E/0/1/0/all/0/1\">Elena Simperl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VGA: Vision and Graph Fused Attention Network for Rumor Detection. (arXiv:2401.01759v1 [cs.SI])","link":"http://arxiv.org/abs/2401.01759","description":"<p>With the development of social media, rumors have been spread broadly on\nsocial media platforms, causing great harm to society. Beside textual\ninformation, many rumors also use manipulated images or conceal textual\ninformation within images to deceive people and avoid being detected, making\nmultimodal rumor detection be a critical problem. The majority of multimodal\nrumor detection methods mainly concentrate on extracting features of source\nclaims and their corresponding images, while ignoring the comments of rumors\nand their propagation structures. These comments and structures imply the\nwisdom of crowds and are proved to be crucial to debunk rumors. Moreover, these\nmethods usually only extract visual features in a basic manner, seldom consider\ntampering or textual information in images. Therefore, in this study, we\npropose a novel Vision and Graph Fused Attention Network (VGA) for rumor\ndetection to utilize propagation structures among posts so as to obtain the\ncrowd opinions and further explore visual tampering features, as well as the\ntextual information hidden in images. We conduct extensive experiments on three\ndatasets, demonstrating that VGA can effectively detect multimodal rumors and\noutperform state-of-the-art methods significantly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1\">Lin Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Caiyan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Ziying Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Chaoqun Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-target Stance Detection by Exploiting Target Analytical Perspectives. (arXiv:2401.01761v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01761","description":"<p>Cross-target stance detection (CTSD) is an important task, which infers the\nattitude of the destination target by utilizing annotated data derived from the\nsource target. One important approach in CTSD is to extract domain-invariant\nfeatures to bridge the knowledge gap between multiple targets. However, the\nanalysis of informal and short text structure, and implicit expressions,\ncomplicate the extraction of domain-invariant knowledge. In this paper, we\npropose a Multi-Perspective Prompt-Tuning (MPPT) model for CTSD that uses the\nanalysis perspective as a bridge to transfer knowledge. First, we develop a\ntwo-stage instruct-based chain-of-thought method (TsCoT) to elicit target\nanalysis perspectives and provide natural language explanations (NLEs) from\nmultiple viewpoints by formulating instructions based on large language model\n(LLM). Second, we propose a multi-perspective prompt-tuning framework\n(MultiPLN) to fuse the NLEs into the stance predictor. Extensive experiments\nresults demonstrate the superiority of MPPT against the state-of-the-art\nbaseline methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1\">Daijun Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Rong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bowen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaowen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1\">Ge Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Liwen Jing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Navigating Uncertainty: Optimizing API Dependency for Hallucination Reduction in Closed-Book Question Answering. (arXiv:2401.01780v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01780","description":"<p>While Large Language Models (LLM) are able to accumulate and restore\nknowledge, they are still prone to hallucination. Especially when faced with\nfactual questions, LLM cannot only rely on knowledge stored in parameters to\nguarantee truthful and correct answers. Augmenting these models with the\nability to search on external information sources, such as the web, is a\npromising approach to ground knowledge to retrieve information. However,\nsearching in a large collection of documents introduces additional\ncomputational/time costs. An optimal behavior would be to query external\nresources only when the LLM is not confident about answers. In this paper, we\npropose a new LLM able to self-estimate if it is able to answer directly or\nneeds to request an external tool. We investigate a supervised approach by\nintroducing a hallucination masking mechanism in which labels are generated\nusing a close book question-answering task. In addition, we propose to leverage\nparameter-efficient fine-tuning techniques to train our model on a small amount\nof data. Our model directly provides answers for $78.2\\%$ of the known queries\nand opts to search for $77.2\\%$ of the unknown ones. This results in the API\nbeing utilized only $62\\%$ of the time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Erbacher_P/0/1/0/all/0/1\">Pierre Erbacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falissar_L/0/1/0/all/0/1\">Louis Falissar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1\">Vincent Guigue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soulier_L/0/1/0/all/0/1\">Laure Soulier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Physio: An LLM-Based Physiotherapy Advisor. (arXiv:2401.01825v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01825","description":"<p>The capabilities of the most recent language models have increased the\ninterest in integrating them into real-world applications. However, the fact\nthat these models generate plausible, yet incorrect text poses a constraint\nwhen considering their use in several domains. Healthcare is a prime example of\na domain where text-generative trustworthiness is a hard requirement to\nsafeguard patient well-being. In this paper, we present Physio, a chat-based\napplication for physical rehabilitation. Physio is capable of making an initial\ndiagnosis while citing reliable health sources to support the information\nprovided. Furthermore, drawing upon external knowledge databases, Physio can\nrecommend rehabilitation exercises and over-the-counter medication for symptom\nrelief. By combining these features, Physio can leverage the power of\ngenerative models for language processing while also conditioning its response\non dependable and verifiable sources. A live demo of Physio is available at\nhttps://physio.inesctec.pt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Almeida_R/0/1/0/all/0/1\">R&#xfa;ben Almeida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sousa_H/0/1/0/all/0/1\">Hugo Sousa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cunha_L/0/1/0/all/0/1\">Lu&#xed;s F. Cunha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guimaraes_N/0/1/0/all/0/1\">Nuno Guimar&#xe3;es</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campos_R/0/1/0/all/0/1\">Ricardo Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorge_A/0/1/0/all/0/1\">Al&#xed;pio Jorge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Iterative Mask Filling: An Effective Text Augmentation Method Using Masked Language Modeling. (arXiv:2401.01830v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01830","description":"<p>Data augmentation is an effective technique for improving the performance of\nmachine learning models. However, it has not been explored as extensively in\nnatural language processing (NLP) as it has in computer vision. In this paper,\nwe propose a novel text augmentation method that leverages the Fill-Mask\nfeature of the transformer-based BERT model. Our method involves iteratively\nmasking words in a sentence and replacing them with language model predictions.\nWe have tested our proposed method on various NLP tasks and found it to be\neffective in many cases. Our results are presented along with a comparison to\nexisting augmentation methods. Experimental results show that our proposed\nmethod significantly improves performance, especially on topic classification\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kesgin_H/0/1/0/all/0/1\">Himmet Toprak Kesgin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amasyali_M/0/1/0/all/0/1\">Mehmet Fatih Amasyali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Semi-Supervised Learning Algorithms in Text Datasets. (arXiv:2401.01843v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01843","description":"<p>Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kesgin_H/0/1/0/all/0/1\">Himmet Toprak Kesgin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amasyali_M/0/1/0/all/0/1\">Mehmet Fatih Amasyali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Instruction Tuning With Just a Pinch of Multilinguality. (arXiv:2401.01854v1 [cs.CL])","link":"http://arxiv.org/abs/2401.01854","description":"<p>As instruction-tuned large language models (LLMs) gain global adoption, their\nability to follow instructions in multiple languages becomes increasingly\ncrucial. One promising approach is cross-lingual transfer, where a model\nacquires specific functionality on some language by finetuning on another\nlanguage. In this work, we investigate how multilinguality during instruction\ntuning of a multilingual LLM affects instruction-following across languages. We\nfirst show that many languages transfer some instruction-following capabilities\nto other languages from even monolingual tuning. Furthermore, we find that only\n40 multilingual examples in an English tuning set substantially improve\nmultilingual instruction-following, both in seen and unseen languages during\ntuning. In general, we observe that models tuned on multilingual mixtures\nexhibit comparable or superior performance in several languages compared to\nmonolingually tuned models, despite training on 10x fewer examples in those\nlanguages. Finally, we find that increasing the number of languages in the\ninstruction tuning set from 1 to only 2, 3, or 4 increases cross-lingual\ngeneralization. Our results suggest that building massively multilingual\ninstruction-tuned models can be done with only a very small set of multilingual\ninstruction-responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1\">Uri Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsarfaty_R/0/1/0/all/0/1\">Reut Tsarfaty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eyal_M/0/1/0/all/0/1\">Matan Eyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Vision Check-up for Language Models. (arXiv:2401.01862v1 [cs.CV])","link":"http://arxiv.org/abs/2401.01862","description":"<p>What does learning to model relationships between strings teach large\nlanguage models (LLMs) about the visual world? We systematically evaluate LLMs'\nabilities to generate and recognize an assortment of visual concepts of\nincreasing complexity and then demonstrate how a preliminary visual\nrepresentation learning system can be trained using models of text. As language\nmodels lack the ability to consume or output visual information as pixels, we\nuse code to represent images in our study. Although LLM-generated images do not\nlook like natural images, results on image generation and the ability of models\nto correct these generated images indicate that precise modeling of strings can\nteach language models about numerous aspects of the visual world. Furthermore,\nexperiments on self-supervised visual representation learning, utilizing images\ngenerated with text models, highlight the potential to train vision models\ncapable of making semantic assessments of natural images using just LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Pratyusha Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1\">Tamar Rott Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baradad_M/0/1/0/all/0/1\">Manel Baradad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_S/0/1/0/all/0/1\">Stephanie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_Munoz_A/0/1/0/all/0/1\">Adrian Rodriguez-Munoz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duggal_S/0/1/0/all/0/1\">Shivam Duggal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Theoretical guarantees on the best-of-n alignment policy. (arXiv:2401.01879v1 [cs.LG])","link":"http://arxiv.org/abs/2401.01879","description":"<p>A simple and effective method for the alignment of generative models is the\nbest-of-$n$ policy, where $n$ samples are drawn from a base policy, and ranked\nbased on a reward function, and the highest ranking one is selected. A commonly\nused analytical expression in the literature claims that the KL divergence\nbetween the best-of-$n$ policy and the base policy is equal to $\\log (n) -\n(n-1)/n.$ We disprove the validity of this claim, and show that it is an upper\nbound on the actual KL divergence. We also explore the tightness of this upper\nbound in different regimes. Finally, we propose a new estimator for the KL\ndivergence and empirically show that it provides a tight approximation through\na few examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Alekh Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DAmour_A/0/1/0/all/0/1\">Alexander D&#x27;Amour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenstein_J/0/1/0/all/0/1\">Jacob Eisenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagpal_C/0/1/0/all/0/1\">Chirag Nagpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1\">Ananda Theertha Suresh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In the Name of Fairness: Assessing the Bias in Clinical Record De-identification. (arXiv:2305.11348v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.11348","description":"<p>Data sharing is crucial for open science and reproducible research, but the\nlegal sharing of clinical data requires the removal of protected health\ninformation from electronic health records. This process, known as\nde-identification, is often achieved through the use of machine learning\nalgorithms by many commercial and open-source systems. While these systems have\nshown compelling results on average, the variation in their performance across\ndifferent demographic groups has not been thoroughly examined. In this work, we\ninvestigate the bias of de-identification systems on names in clinical notes\nvia a large-scale empirical analysis. To achieve this, we create 16 name sets\nthat vary along four demographic dimensions: gender, race, name popularity, and\nthe decade of popularity. We insert these names into 100 manually curated\nclinical templates and evaluate the performance of nine public and private\nde-identification methods. Our findings reveal that there are statistically\nsignificant performance gaps along a majority of the demographic dimensions in\nmost methods. We further illustrate that de-identification quality is affected\nby polysemy in names, gender context, and clinical note characteristics. To\nmitigate the identified gaps, we propose a simple and method-agnostic solution\nby fine-tuning de-identification methods with clinical context and diverse\nnames. Overall, it is imperative to address the bias in existing methods\nimmediately so that downstream stakeholders can build high-quality systems to\nserve all demographic parties fairly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yuxin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Shulammite Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pollard_T/0/1/0/all/0/1\">Tom Joseph Pollard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Are Not Strong Abstract Reasoners. (arXiv:2305.19555v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19555","description":"<p>Large Language Models have shown tremendous performance on a large variety of\nnatural language processing tasks, ranging from text comprehension to common\nsense reasoning. However, the mechanisms responsible for this success remain\nopaque, and it is unclear whether LLMs can achieve human-like cognitive\ncapabilities or whether these models are still fundamentally circumscribed.\nAbstract reasoning is a fundamental task for cognition, consisting of finding\nand applying a general pattern from few data. Evaluating deep neural\narchitectures on this task could give insight into their potential limitations\nregarding reasoning and their broad generalisation abilities, yet this is\ncurrently an under-explored area. In this paper, we introduce a new benchmark\nfor evaluating language models beyond memorization on abstract reasoning tasks.\nWe perform extensive evaluations of state-of-the-art LLMs, showing that they\ncurrently achieve very limited performance in contrast with other natural\nlanguage tasks, even when applying techniques that have been shown to improve\nperformance on other NLP tasks. We argue that guiding LLM generation to follow\ncausal paths could help improve the generalisation and reasoning abilities of\nLLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1\">Ga&#xeb;l Gendron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobbie_G/0/1/0/all/0/1\">Gillian Dobbie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conflicts, Villains, Resolutions: Towards models of Narrative Media Framing. (arXiv:2306.02052v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02052","description":"<p>Despite increasing interest in the automatic detection of media frames in\nNLP, the problem is typically simplified as single-label classification and\nadopts a topic-like view on frames, evading modelling the broader\ndocument-level narrative. In this work, we revisit a widely used\nconceptualization of framing from the communication sciences which explicitly\ncaptures elements of narratives, including conflict and its resolution, and\nintegrate it with the narrative framing of key entities in the story as heroes,\nvictims or villains. We adapt an effective annotation paradigm that breaks a\ncomplex annotation task into a series of simpler binary questions, and present\nan annotated data set of English news articles, and a case study on the framing\nof climate change in articles from news outlets across the political spectrum.\nFinally, we explore automatic multi-label prediction of our frames with\nsupervised and semi-supervised approaches, and present a novel retrieval-based\nmethod which is both effective and transparent in its predictions. We conclude\nwith a discussion of opportunities and challenges for future work on\ndocument-level models of narrative framing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Frermann_L/0/1/0/all/0/1\">Lea Frermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiatong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khanehzar_S/0/1/0/all/0/1\">Shima Khanehzar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikolajczak_G/0/1/0/all/0/1\">Gosia Mikolajczak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2306.17408","description":"<p>As malicious actors employ increasingly advanced and widespread bots to\ndisseminate misinformation and manipulate public opinion, the detection of\nTwitter bots has become a crucial task. Though graph-based Twitter bot\ndetection methods achieve state-of-the-art performance, we find that their\ninference depends on the neighbor users multi-hop away from the targets, and\nfetching neighbors is time-consuming and may introduce bias. At the same time,\nwe find that after finetuning on Twitter bot detection, pretrained language\nmodels achieve competitive performance and do not require a graph structure\nduring deployment. Inspired by this finding, we propose a novel bot detection\nframework LMBot that distills the knowledge of graph neural networks (GNNs)\ninto language models (LMs) for graph-less deployment in Twitter bot detection\nto combat the challenge of data dependency. Moreover, LMBot is compatible with\ngraph-based and graph-less datasets. Specifically, we first represent each user\nas a textual sequence and feed them into the LM for domain adaptation. For\ngraph-based datasets, the output of LMs provides input features for the GNN,\nenabling it to optimize for bot detection and distill knowledge back to the LM\nin an iterative, mutually enhancing process. Armed with the LM, we can perform\ngraph-less inference, which resolves the graph data dependency and sampling\nbias issues. For datasets without graph structure, we simply replace the GNN\nwith an MLP, which has also shown strong performance. Our experiments\ndemonstrate that LMBot achieves state-of-the-art performance on four Twitter\nbot detection benchmarks. Extensive studies also show that LMBot is more\nrobust, versatile, and efficient compared to graph-based Twitter bot detection\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zijian Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zhaoxuan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1\">Zhenyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zifeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongrui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinghua Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Minnan Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation. (arXiv:2307.05134v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.05134","description":"<p>The progress in the generation of synthetic images has made it crucial to\nassess their quality. While several metrics have been proposed to assess the\nrendering of images, it is crucial for Text-to-Image (T2I) models, which\ngenerate images based on a prompt, to consider additional aspects such as to\nwhich extent the generated image matches the important content of the prompt.\nMoreover, although the generated images usually result from a random starting\npoint, the influence of this one is generally not considered. In this article,\nwe propose a new metric based on prompt templates to study the alignment\nbetween the content specified in the prompt and the corresponding generated\nimages. It allows us to better characterize the alignment in terms of the type\nof the specified objects, their number, and their color. We conducted a study\non several recent T2I models about various aspects. An additional interesting\nresult we obtained with our approach is that image quality can vary drastically\ndepending on the noise used as a seed for the images. We also quantify the\ninfluence of the number of concepts in the prompt, their order as well as their\n(color) attributes. Finally, our method allows us to identify some seeds that\nproduce better images than others, opening novel directions of research on this\nunderstudied topic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Grimal_P/0/1/0/all/0/1\">Paul Grimal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borgne_H/0/1/0/all/0/1\">Herv&#xe9; Le Borgne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferret_O/0/1/0/all/0/1\">Olivier Ferret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tourille_J/0/1/0/all/0/1\">Julien Tourille</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Assessment Tests are Unreliable Measures of LLM Personality. (arXiv:2309.08163v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08163","description":"<p>As large language models (LLM) evolve in their capabilities, various recent\nstudies have tried to quantify their behavior using psychological tools created\nto study human behavior. One such example is the measurement of \"personality\"\nof LLMs using self-assessment personality tests developed to measure human\npersonality. Yet almost none of these works verify the applicability of these\ntests on LLMs. In this paper, we analyze the reliability of LLM personality\nscores obtained from self-assessment personality tests using two simple\nexperiments. We first introduce the property of prompt sensitivity, where three\nsemantically equivalent prompts representing three intuitive ways of\nadministering self-assessment tests on LLMs are used to measure the personality\nof the same LLM. We find that all three prompts lead to very different\npersonality scores, a difference that is statistically significant for all\ntraits in a large majority of scenarios. We then introduce the property of\noption-order symmetry for personality measurement of LLMs. Since most of the\nself-assessment tests exist in the form of multiple choice question (MCQ)\nquestions, we argue that the scores should also be robust to not just the\nprompt template but also the order in which the options are presented. This\ntest unsurprisingly reveals that the self-assessment test scores are not robust\nto the order of the options. These simple tests, done on ChatGPT and three\nLlama2 models of different sizes, show that self-assessment personality tests\ncreated for humans are unreliable measures of personality in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Akshat Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaoyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What's the Magic Word? A Control Theory of LLM Prompting. (arXiv:2310.04444v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04444","description":"<p>Prompt engineering is crucial for deploying LLMs but is poorly understood\nmathematically. We formalize LLM systems as a class of discrete stochastic\ndynamical systems to explore prompt engineering through the lens of control\ntheory. We investigate the reachable set of output token sequences $R_y(\\mathbf\nx_0)$ for which there exists a control input sequence $\\mathbf u$ for each\n$\\mathbf y \\in R_y(\\mathbf x_0)$ that steers the LLM to output $\\mathbf y$ from\ninitial state sequence $\\mathbf x_0$. We offer analytic analysis on the\nlimitations on the controllability of self-attention in terms of reachable set,\nwhere we prove an upper bound on the reachable set of outputs $R_y(\\mathbf\nx_0)$ as a function of the singular values of the parameter matrices. We\npresent complementary empirical analysis on the controllability of a panel of\nLLMs, including Falcon-7b, Llama-7b, and Falcon-40b. Our results demonstrate a\nlower bound on the reachable set of outputs $R_y(\\mathbf x_0)$ w.r.t. initial\nstate sequences $\\mathbf x_0$ sampled from the Wikitext dataset. We find that\nthe correct next Wikitext token following sequence $\\mathbf x_0$ is reachable\nover 97% of the time with prompts of $k\\leq 10$ tokens. We also establish that\nthe top 75 most likely next tokens, as estimated by the LLM itself, are\nreachable at least 85% of the time with prompts of $k\\leq 10$ tokens.\nIntriguingly, short prompt sequences can dramatically alter the likelihood of\nspecific outputs, even making the least likely tokens become the most likely\nones. This control-centric analysis of LLMs demonstrates the significant and\npoorly understood role of input sequences in steering output probabilities,\noffering a foundational perspective for enhancing language model system\ncapabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_A/0/1/0/all/0/1\">Aman Bhargava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witkowski_C/0/1/0/all/0/1\">Cameron Witkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Manav Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thomson_M/0/1/0/all/0/1\">Matt Thomson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding the Effects of RLHF on LLM Generalisation and Diversity. (arXiv:2310.06452v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.06452","description":"<p>Large language models (LLMs) fine-tuned with reinforcement learning from\nhuman feedback (RLHF) have been used in some of the most widely deployed AI\nmodels to date, such as OpenAI's ChatGPT or Anthropic's Claude. % , or Meta's\nLLaMA-2. While there has been significant work developing these methods, our\nunderstanding of the benefits and downsides of each stage in RLHF is still\nlimited. To fill this gap, we present an extensive analysis of how each stage\nof the process (i.e.~supervised fine-tuning (SFT), reward modelling, and RLHF)\naffects two key properties: out-of-distribution (OOD) generalisation and output\ndiversity. OOD generalisation is crucial given the wide range of real-world\nscenarios in which these models are being used, while output diversity refers\nto the model's ability to generate varied outputs and is important for a\nvariety of use cases. We perform our analysis across two base models on both\nsummarisation and instruction following tasks, the latter being highly relevant\nfor current LLM use cases. We find that RLHF generalises better than SFT to new\ninputs, particularly as the distribution shift between train and test becomes\nlarger. However, RLHF significantly reduces output diversity compared to SFT\nacross a variety of measures, implying a tradeoff in current LLM fine-tuning\nmethods between generalisation and diversity. Our results provide guidance on\nwhich fine-tuning method should be used depending on the application, and show\nthat more research is needed to improve the tradeoff between generalisation and\ndiversity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirk_R/0/1/0/all/0/1\">Robert Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mediratta_I/0/1/0/all/0/1\">Ishita Mediratta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nalmpantis_C/0/1/0/all/0/1\">Christoforos Nalmpantis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luketina_J/0/1/0/all/0/1\">Jelena Luketina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hambro_E/0/1/0/all/0/1\">Eric Hambro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grefenstette_E/0/1/0/all/0/1\">Edward Grefenstette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPEED: Speculative Pipelined Execution for Efficient Decoding. (arXiv:2310.12072v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12072","description":"<p>Generative Large Language Models (LLMs) based on the Transformer architecture\nhave recently emerged as a dominant foundation model for a wide range of\nNatural Language Processing tasks. Nevertheless, their application in real-time\nscenarios has been highly restricted due to the significant inference latency\nassociated with these models. This is particularly pronounced due to the\nautoregressive nature of generative LLM inference, where tokens are generated\nsequentially since each token depends on all previous output tokens. It is\ntherefore challenging to achieve any token-level parallelism, making inference\nextremely memory-bound. In this work, we propose SPEED, which improves\ninference efficiency by speculatively executing multiple future tokens in\nparallel with the current token using predicted values based on early-layer\nhidden states. For Transformer decoders that employ parameter sharing, the\nmemory operations for the tokens executing in parallel can be amortized, which\nallows us to accelerate generative LLM inference. We demonstrate the efficiency\nof our method in terms of latency reduction relative to model accuracy and\ndemonstrate how speculation allows for training deeper decoders with parameter\nsharing with minimal runtime overhead.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hooper_C/0/1/0/all/0/1\">Coleman Hooper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadzadeh_H/0/1/0/all/0/1\">Hiva Mohammadzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genc_H/0/1/0/all/0/1\">Hasan Genc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1\">Amir Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1\">Sophia Shao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ViCrop: Perceiving Small Visual Details in Zero-shot Visual Question Answering with Multimodal Large Language Models. (arXiv:2310.16033v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.16033","description":"<p>Multimodal Large Language Models (MLLMs) have recently achieved promising\nzero-shot accuracy on visual question answering (VQA) -- a fundamental task\naffecting various downstream applications and domains. Given the great\npotential for the broad use of these models, it is important to investigate\ntheir limitations in dealing with different image and question properties. In\nthis work, we investigate whether MLLMs can perceive details as well as larger\ncomponents in images. In particular, we show that their zero-shot accuracy in\nanswering visual questions is very sensitive to the size of the visual subject\nrelated to the question, declining up to $45.91\\%$ with size. Furthermore, we\nshow that this effect is causal by observing that human visual cropping can\nsignificantly mitigate their sensitivity to size. To scale up the usefulness of\nhuman cropping, we propose ViCrop, a general framework that utilizes automatic\nvisual cropping to enhance zero-shot VQA of MLLMs. We construct five variants\nof ViCrop leveraging either external localization models or the decision\nprocess of the given MLLM itself. Our results show that ViCrop improves MLLMs'\nzero-shot accuracy across different VQA datasets, for example, enhances\nBLIP2-T5's performance by $32.23\\%$ on the TextVQA test set. To facilitate\nfurther investigation of MLLMs' behaviors, our code is publicly released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiarui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khayatkhoei_M/0/1/0/all/0/1\">Mahyar Khayatkhoei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhikara_P/0/1/0/all/0/1\">Prateek Chhikara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1\">Filip Ilievski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19923","description":"<p>Text embedding models have emerged as powerful tools for transforming\nsentences into fixed-sized feature vectors that encapsulate semantic\ninformation. While these models are essential for tasks like information\nretrieval, semantic clustering, and text re-ranking, most existing open-source\nmodels, especially those built on architectures like BERT, struggle to\nrepresent lengthy documents and often resort to truncation. One common approach\nto mitigate this challenge involves splitting documents into smaller paragraphs\nfor embedding. However, this strategy results in a much larger set of vectors,\nconsequently leading to increased memory consumption and computationally\nintensive vector searches with elevated latency.\n</p>\n<p>To address these challenges, we introduce Jina Embeddings 2, an open-source\ntext embedding model capable of accommodating up to 8192 tokens. This model is\ndesigned to transcend the conventional 512-token limit and adeptly process long\ndocuments. Jina Embeddings 2 not only achieves state-of-the-art performance on\na range of embedding-related tasks in the MTEB benchmark but also matches the\nperformance of OpenAI's proprietary ada-002 model. Additionally, our\nexperiments indicate that an extended context can enhance performance in tasks\nsuch as NarrativeQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gunther_M/0/1/0/all/0/1\">Michael G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_J/0/1/0/all/0/1\">Jackmin Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohr_I/0/1/0/all/0/1\">Isabelle Mohr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdessalem_A/0/1/0/all/0/1\">Alaeddine Abdessalem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abel_T/0/1/0/all/0/1\">Tanguy Abel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akram_M/0/1/0/all/0/1\">Mohammad Kalim Akram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_S/0/1/0/all/0/1\">Susana Guzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mastrapas_G/0/1/0/all/0/1\">Georgios Mastrapas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sturua_S/0/1/0/all/0/1\">Saba Sturua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werk_M/0/1/0/all/0/1\">Maximilian Werk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Han Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models. (arXiv:2312.06281v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.06281","description":"<p>We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of\nemotional intelligence in Large Language Models (LLMs). We assess the ability\nof LLMs to understand complex emotions and social interactions by asking them\nto predict the intensity of emotional states of characters in a dialogue. The\nbenchmark is able to discriminate effectively between a wide range of models.\nWe find that EQ-Bench correlates strongly with comprehensive multi-domain\nbenchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may\nbe capturing similar aspects of broad intelligence. Our benchmark produces\nhighly repeatable results using a set of 60 English-language questions. We also\nprovide open-source code for an automated benchmarking pipeline at\nhttps://github.com/EQ-bench/EQ-Bench and a leaderboard at https://eqbench.com\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paech_S/0/1/0/all/0/1\">Samuel J. Paech</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Text Watermarking in the Era of Large Language Models. (arXiv:2312.07913v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.07913","description":"<p>Text watermarking algorithms play a crucial role in the copyright protection\nof textual content, yet their capabilities and application scenarios have been\nlimited historically. The recent developments in large language models (LLMs)\nhave opened new opportunities for the advancement of text watermarking\ntechniques. LLMs not only enhance the capabilities of text watermarking\nalgorithms through their text understanding and generation abilities but also\nnecessitate the use of text watermarking algorithms for their own copyright\nprotection. This paper conducts a comprehensive survey of the current state of\ntext watermarking technology, covering four main aspects: (1) an overview and\ncomparison of different text watermarking techniques; (2) evaluation methods\nfor text watermarking algorithms, including their success rates, impact on text\nquality, robustness, and unforgeability; (3) potential application scenarios\nfor text watermarking technology; (4) current challenges and future directions\nfor development. This survey aims to provide researchers with a thorough\nunderstanding of text watermarking technology, thereby promoting its further\nadvancement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Aiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Leyi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yijian Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingjing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Augmented Generation for Large Language Models: A Survey. (arXiv:2312.10997v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.10997","description":"<p>Large Language Models (LLMs) demonstrate significant capabilities but face\nchallenges such as hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Retrieval-Augmented Generation (RAG) has\nemerged as a promising solution by incorporating knowledge from external\ndatabases. This enhances the accuracy and credibility of the models,\nparticularly for knowledge-intensive tasks, and allows for continuous knowledge\nupdates and integration of domain-specific information. RAG synergistically\nmerges LLMs' intrinsic knowledge with the vast, dynamic repositories of\nexternal databases. This comprehensive review paper offers a detailed\nexamination of the progression of RAG paradigms, encompassing the Naive RAG,\nthe Advanced RAG, and the Modular RAG. It meticulously scrutinizes the\ntripartite foundation of RAG frameworks, which includes the retrieval , the\ngeneration and the augmentation techniques. The paper highlights the\nstate-of-the-art technologies embedded in each of these critical components,\nproviding a profound understanding of the advancements in RAG systems.\nFurthermore, this paper introduces the metrics and benchmarks for assessing RAG\nmodels, along with the most up-to-date evaluation framework. In conclusion, the\npaper delineates prospective avenues for research, including the identification\nof challenges, the expansion of multi-modalities, and the progression of the\nRAG infrastructure and its ecosystem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunfan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kangxiang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jinliu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1\">Yuxi Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiawei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qianyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haofen Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialCLIP: Empowering CLIP as Multi-Modal Dialog Retriever. (arXiv:2401.01076v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01076","description":"<p>Recently, substantial advancements in pre-trained vision-language models have\ngreatly enhanced the capabilities of multi-modal dialog systems. These models\nhave demonstrated significant improvements by fine-tuning on downstream tasks.\nHowever, the existing pre-trained models primarily focus on effectively\ncapturing the alignment between vision and language modalities, often ignoring\nthe intricate nature of dialog context. In this paper, we propose a\nparameter-efficient prompt-tuning method named DialCLIP for multi-modal dialog\nretrieval. Specifically, our approach introduces a multi-modal context prompt\ngenerator to learn context features which are subsequently distilled into\nprompts within the pre-trained vision-language model CLIP. Besides, we\nintroduce domain prompt to mitigate the disc repancy from the downstream dialog\ndata. To facilitate various types of retrieval, we also design multiple experts\nto learn mappings from CLIP outputs to multi-modal representation space, with\neach expert being responsible to one specific retrieval type. Extensive\nexperiments show that DialCLIP achieves state-of-the-art performance on two\nwidely recognized benchmark datasets (i.e., PhotoChat and MMDialog) by tuning a\nmere 0.04% of the total parameters. These results highlight the efficacy and\nefficiency of our proposed approach, underscoring its potential to advance the\nfield of multi-modal dialog retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhichao Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_B/0/1/0/all/0/1\">Binyuan Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongbin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01078","description":"<p>Poetry generation has been a challenging task in the field of Natural\nLanguage Processing, as it requires the model to understand the nuances of\nlanguage, sentiment, and style. In this paper, we propose using Large Language\nModels to generate Vietnamese poems from natural language prompts, thereby\nfacilitating an intuitive process with enhanced content control. Our most\nefficacious model, the GPT-3 Babbage variant, achieves a custom evaluation\nscore of 0.8, specifically tailored to the \"luc bat\" genre of Vietnamese\npoetry. Furthermore, we also explore the idea of paraphrasing poems into normal\ntext prompts and yield a relatively high score of 0.718 in the \"luc bat\" genre.\nThis experiment presents the potential for cross-Language poem-to-poem\ntranslation with translated poems as the inputs while concurrently maintaining\ncomplete control over the generated content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_T/0/1/0/all/0/1\">Triet Minh Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Quan Le Bao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01262","description":"<p>Natural Language Processing (NLP) plays an important role in our daily lives,\nparticularly due to the enormous progress of Large Language Models (LLM).\nHowever, NLP has many fairness-critical use cases, e.g., as an expert system in\nrecruitment or as an LLM-based tutor in education. Since NLP is based on human\nlanguage, potentially harmful biases can diffuse into NLP systems and produce\nunfair results, discriminate against minorities or generate legal issues.\nHence, it is important to develop a fairness certification for NLP approaches.\nWe follow a qualitative research approach towards a fairness certification for\nNLP. In particular, we have reviewed a large body of literature on algorithmic\nfairness, and we have conducted semi-structured expert interviews with a wide\nrange of experts from that area. We have systematically devised six fairness\ncriteria for NLP, which can be further refined into 18 sub-categories. Our\ncriteria offer a foundation for operationalizing and testing processes to\ncertify fairness, both from the perspective of the auditor and the audited\norganization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Freiberger_V/0/1/0/all/0/1\">Vincent Freiberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buchmann_E/0/1/0/all/0/1\">Erik Buchmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quality and Quantity of Machine Translation References for Automated Metrics. (arXiv:2401.01283v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01283","description":"<p>Automatic machine translation metrics often use human translations to\ndetermine the quality system translations. Common wisdom in the field dictates\nthat the human references should be of very high quality. However, there are no\ncost-benefit analyses that could be used to guide practitioners who plan to\ncollect references for machine translation evaluation. We find that\nhigher-quality references lead to better metric correlations with humans at the\nsegment-level. Having up to 7 references per segment and taking their average\nhelps all metrics. Interestingly, the references from vendors of different\nqualities can be mixed together and improve metric success. Higher quality\nreferences, however, cost more to create and we frame this as an optimization\nproblem: given a specific budget, what references should be collected to\nmaximize metric success. These findings can be used by evaluators of shared\ntasks when references need to be created under a certain budget.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojar_O/0/1/0/all/0/1\">Ond&#x159;ej Bojar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models. (arXiv:2401.01313v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01313","description":"<p>As Large Language Models (LLMs) continue to advance in their ability to write\nhuman-like text, a key challenge remains around their tendency to hallucinate\ngenerating content that appears factual but is ungrounded. This issue of\nhallucination is arguably the biggest hindrance to safely deploying these\npowerful LLMs into real-world production systems that impact people's lives.\nThe journey toward widespread adoption of LLMs in practical settings heavily\nrelies on addressing and mitigating hallucinations. Unlike traditional AI\nsystems focused on limited tasks, LLMs have been exposed to vast amounts of\nonline text data during training. While this allows them to display impressive\nlanguage fluency, it also means they are capable of extrapolating information\nfrom the biases in training data, misinterpreting ambiguous prompts, or\nmodifying the information to align superficially with the input. This becomes\nhugely alarming when we rely on language generation capabilities for sensitive\napplications, such as summarizing medical records, financial analysis reports,\netc. This paper presents a comprehensive survey of over 32 techniques developed\nto mitigate hallucination in LLMs. Notable among these are Retrieval Augmented\nGeneration (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023),\nCoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we\nintroduce a detailed taxonomy categorizing these methods based on various\nparameters, such as dataset utilization, common tasks, feedback mechanisms, and\nretriever types. This classification helps distinguish the diverse approaches\nspecifically designed to tackle hallucination issues in LLMs. Additionally, we\nanalyze the challenges and limitations inherent in these techniques, providing\na solid foundation for future research in addressing hallucinations and related\nphenomena within the realm of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tonmoy_S/0/1/0/all/0/1\">S.M Towhidul Islam Tonmoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaman_S/0/1/0/all/0/1\">S M Mehedi Zaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawte_V/0/1/0/all/0/1\">Vipula Rawte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-03T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}