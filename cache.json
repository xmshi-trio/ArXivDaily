{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-07-20T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Can Model Fusing Help Transformers in Long Document Classification? An Empirical Study. (arXiv:2307.09532v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09532","description":"<p>Text classification is an area of research which has been studied over the\nyears in Natural Language Processing (NLP). Adapting NLP to multiple domains\nhas introduced many new challenges for text classification and one of them is\nlong document classification. While state-of-the-art transformer models provide\nexcellent results in text classification, most of them have limitations in the\nmaximum sequence length of the input sequence. The majority of the transformer\nmodels are limited to 512 tokens, and therefore, they struggle with long\ndocument classification problems. In this research, we explore on employing\nModel Fusing for long document classification while comparing the results with\nwell-known BERT and Longformer architectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Premasiri_D/0/1/0/all/0/1\">Damith Premasiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitkov_R/0/1/0/all/0/1\">Ruslan Mitkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots. (arXiv:2307.09579v1 [cs.CR])","link":"http://arxiv.org/abs/2307.09579","description":"<p>Recent advances in natural language processing and machine learning have led\nto the development of chatbot models, such as ChatGPT, that can engage in\nconversational dialogue with human users. However, the ability of these models\nto generate toxic or harmful responses during a non-toxic multi-turn\nconversation remains an open research question. Existing research focuses on\nsingle-turn sentence testing, while we find that 82\\% of the individual\nnon-toxic sentences that elicit toxic behaviors in a conversation are\nconsidered safe by existing tools. In this paper, we design a new attack,\n\\toxicbot, by fine-tuning a chatbot to engage in conversation with a target\nopen-domain chatbot. The chatbot is fine-tuned with a collection of crafted\nconversation sequences. Particularly, each conversation begins with a sentence\nfrom a crafted prompt sentences dataset. Our extensive evaluation shows that\nopen-domain chatbot models can be triggered to generate toxic responses in a\nmulti-turn conversation. In the best scenario, \\toxicbot achieves a 67\\%\nactivation rate. The conversation sequences in the fine-tuning stage help\ntrigger the toxicity in a conversation, which allows the attack to bypass two\ndefense methods. Our findings suggest that further research is needed to\naddress chatbot toxicity in a dynamic interactive environment. The proposed\n\\toxicbot can be used by both industry and researchers to develop methods for\ndetecting and mitigating toxic responses in conversational dialogue and improve\nthe robustness of chatbots for end users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bocheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangjing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hanqing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanda Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Q/0/1/0/all/0/1\">Qiben Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Noor-Ghateh: A Benchmark Dataset for Evaluating Arabic Word Segmenters in Hadith Domain. (arXiv:2307.09630v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09630","description":"<p>There are many complex and rich morphological subtleties in the Arabic\nlanguage, which are very useful when analyzing traditional Arabic texts,\nespecially in the historical and religious contexts, and help in understanding\nthe meaning of the texts. Vocabulary separation means separating the word into\ndifferent parts such as root and affix. In the morphological datasets, the\nvariety of labels and the number of data samples helps to evaluate the\nmorphological methods. In this paper, we present a benchmark data set for\nevaluating the methods of separating Arabic words which include about 223,690\nwords from the book of Sharia alIslam, which have been labeled by experts. In\nterms of the volume and variety of words, this dataset is superior to other\nexisting data sets, and as far as we know, there are no Arabic Hadith Domain\ntexts. To evaluate the dataset, we applied different methods such as Farasa,\nCamel, Madamira, and ALP to the dataset and we reported the annotation quality\nthrough four evaluation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+AlShuhayeb_H/0/1/0/all/0/1\">Huda AlShuhayeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minaei_Bidgoli_B/0/1/0/all/0/1\">Behrouz Minaei-Bidgoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenassa_M/0/1/0/all/0/1\">Mohammad E. Shenassa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossayni_S/0/1/0/all/0/1\">Sayyed-Ali Hossayni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation. (arXiv:2307.09701v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09701","description":"<p>Rising computational demands of modern natural language processing (NLP)\nsystems have increased the barrier to entry for cutting-edge research while\nposing serious environmental concerns. Yet, progress on model efficiency has\nbeen impeded by practical challenges in model evaluation and comparison. For\nexample, hardware is challenging to control due to disparate levels of\naccessibility across different institutions. Moreover, improvements in metrics\nsuch as FLOPs often fail to translate to progress in real-world applications.\nIn response, we introduce Pentathlon, a benchmark for holistic and realistic\nevaluation of model efficiency. Pentathlon focuses on inference, which accounts\nfor a majority of the compute in a model's lifecycle. It offers a\nstrictly-controlled hardware platform, and is designed to mirror real-world\napplications scenarios. It incorporates a suite of metrics that target\ndifferent aspects of efficiency, including latency, throughput, memory\noverhead, and energy consumption. Pentathlon also comes with a software library\nthat can be seamlessly integrated into any codebase and enable evaluation. As a\nstandardized and centralized evaluation platform, Pentathlon can drastically\nreduce the workload to make fair and reproducible efficiency comparisons. While\ninitially focused on natural language processing (NLP) models, Pentathlon is\ndesigned to allow flexible extension to other fields. We envision Pentathlon\nwill stimulate algorithmic innovations in building efficient models, and foster\nan increased awareness of the social and environmental implications in the\ndevelopment of future-generation NLP models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingqing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodge_J/0/1/0/all/0/1\">Jesse Dodge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_M/0/1/0/all/0/1\">Matthew E. Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_J/0/1/0/all/0/1\">Jared Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1\">Tom Sherborne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">Kyle Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skjonsberg_S/0/1/0/all/0/1\">Sam Skjonsberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plessas_D/0/1/0/all/0/1\">Darrell Plessas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walsh_E/0/1/0/all/0/1\">Evan Pete Walsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Guided Generation for LLMs. (arXiv:2307.09702v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09702","description":"<p>In this article we describe an efficient approach to guiding language model\ntext generation with regular expressions and context-free grammars. Our\napproach adds little to no overhead to the token sequence generation process,\nand makes guided generation feasible in practice. An implementation is provided\nin the open source Python library Outlines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Willard_B/0/1/0/all/0/1\">Brandon T. Willard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louf_R/0/1/0/all/0/1\">R&#xe9;mi Louf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CValues: Measuring the Values of Chinese Large Language Models from Safety to Responsibility. (arXiv:2307.09705v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09705","description":"<p>With the rapid evolution of large language models (LLMs), there is a growing\nconcern that they may pose risks or have negative social impacts. Therefore,\nevaluation of human values alignment is becoming increasingly important.\nPrevious work mainly focuses on assessing the performance of LLMs on certain\nknowledge and reasoning abilities, while neglecting the alignment to human\nvalues, especially in a Chinese context. In this paper, we present CValues, the\nfirst Chinese human values evaluation benchmark to measure the alignment\nability of LLMs in terms of both safety and responsibility criteria. As a\nresult, we have manually collected adversarial safety prompts across 10\nscenarios and induced responsibility prompts from 8 domains by professional\nexperts. To provide a comprehensive values evaluation of Chinese LLMs, we not\nonly conduct human evaluation for reliable comparison, but also construct\nmulti-choice prompts for automatic evaluation. Our findings suggest that while\nmost Chinese LLMs perform well in terms of safety, there is considerable room\nfor improvement in terms of responsibility. Moreover, both the automatic and\nhuman evaluation are important for assessing the human values alignment in\ndifferent aspects. The benchmark and code is available on ModelScope and\nGithub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guohai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiayi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haotian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_J/0/1/0/all/0/1\">Jinghui Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhuoran Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_P/0/1/0/all/0/1\">Peng Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xing Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jitao Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Chao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RaTE: a Reproducible automatic Taxonomy Evaluation by Filling the Gap. (arXiv:2307.09706v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09706","description":"<p>Taxonomies are an essential knowledge representation, yet most studies on\nautomatic taxonomy construction (ATC) resort to manual evaluation to score\nproposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just\nas important as taxonomy construction. We propose RaTE, an automatic label-free\ntaxonomy scoring procedure, which relies on a large pre-trained language model.\nWe apply our evaluation procedure to three state-of-the-art ATC algorithms with\nwhich we built seven taxonomies from the Yelp domain, and show that 1) RaTE\ncorrelates well with human judgments and 2) artificially degrading a taxonomy\nleads to decreasing RaTE score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianjian Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlais_P/0/1/0/all/0/1\">Phillipe Langlais</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction. (arXiv:2307.09744v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09744","description":"<p>The integration of natural language processing (NLP) technologies into\neducational applications has shown promising results, particularly in the\nlanguage learning domain. Recently, many spoken open-domain chatbots have been\nused as speaking partners, helping language learners improve their language\nskills. However, one of the significant challenges is the high word-error-rate\n(WER) when recognizing non-native/non-fluent speech, which interrupts\nconversation flow and leads to disappointment for learners. This paper explores\nthe use of GPT4 for ASR error correction in conversational settings. In\naddition to WER, we propose to use semantic textual similarity (STS) and next\nresponse sensibility (NRS) metrics to evaluate the impact of error correction\nmodels on the quality of the conversation. We find that transcriptions\ncorrected by GPT4 lead to higher conversation quality, despite an increase in\nWER. GPT4 also outperforms standard error correction methods without the need\nfor in-domain training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1\">Long Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carson_Berndsen_J/0/1/0/all/0/1\">Julie Carson-Berndsen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats. (arXiv:2307.09782v1 [cs.LG])","link":"http://arxiv.org/abs/2307.09782","description":"<p>In the complex domain of large language models (LLMs), striking a balance\nbetween computational efficiency and maintaining model quality is a formidable\nchallenge. Navigating the inherent limitations of uniform quantization,\nparticularly when dealing with outliers, and motivated by the launch of\nNVIDIA's H100 hardware, this study delves into the viability of floating-point\n(FP) quantization, particularly focusing on FP8 and FP4, as a potential\nsolution. Our comprehensive investigation reveals that for LLMs, FP8 activation\nconsistently outshines its integer (INT8) equivalent, with the performance edge\nbecoming more noticeable in models possessing parameters beyond one billion.\nFor weight quantization, our findings indicate that FP4 exhibits comparable, if\nnot superior, performance to INT4, simplifying deployment on FP-supported\nhardware like H100. To mitigate the overhead from precision alignment caused by\nthe disparity between weights and activations, we propose two scaling\nconstraints for weight quantization that negligibly impact the performance\ncompared to the standard W4A8 model. We additionally enhance our quantization\nmethods by integrating the Low Rank Compensation (LoRC) strategy, yielding\nimprovements especially in smaller models. The results of our investigation\nemphasize the immense potential of FP quantization for LLMs, paving the way for\nhigh-efficiency deployment in resource-limited settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhewei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models. (arXiv:2307.09793v1 [cs.DL])","link":"http://arxiv.org/abs/2307.09793","description":"<p>Since late 2022, Large Language Models (LLMs) have become very prominent with\nLLMs like ChatGPT and Bard receiving millions of users. Hundreds of new LLMs\nare announced each week, many of which are deposited to Hugging Face, a\nrepository of machine learning models and datasets. To date, nearly 16,000 Text\nGeneration models have been uploaded to the site. Given the huge influx of\nLLMs, it is of interest to know which LLM backbones, settings, training\nmethods, and families are popular or trending. However, there is no\ncomprehensive index of LLMs available. We take advantage of the relatively\nsystematic nomenclature of Hugging Face LLMs to perform hierarchical clustering\nand identify communities amongst LLMs using n-grams and term frequency-inverse\ndocument frequency. Our methods successfully identify families of LLMs and\naccurately cluster LLMs into meaningful subgroups. We present a public web\napplication to navigate and explore Constellation, our atlas of 15,821 LLMs.\nConstellation rapidly generates a variety of visualizations, namely\ndendrograms, graphs, word clouds, and scatter plots. Constellation is available\nat the following link: https://constellation.sites.stanford.edu/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Sarah Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_A/0/1/0/all/0/1\">Andrew Kean Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DAPrompt: Deterministic Assumption Prompt Learning for Event Causality Identification. (arXiv:2307.09813v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09813","description":"<p>Event Causality Identification (ECI) aims at determining whether there is a\ncausal relation between two event mentions. Conventional prompt learning\ndesigns a prompt template to first predict an answer word and then maps it to\nthe final decision. Unlike conventional prompts, we argue that predicting an\nanswer word may not be a necessary prerequisite for the ECI task. Instead, we\ncan first make a deterministic assumption on the existence of causal relation\nbetween two events and then evaluate its rationality to either accept or reject\nthe assumption. The design motivation is to try the most utilization of the\nencyclopedia-like knowledge embedded in a pre-trained language model. In light\nof such considerations, we propose a deterministic assumption prompt learning\nmodel, called DAPrompt, for the ECI task. In particular, we design a simple\ndeterministic assumption template concatenating with the input event pair,\nwhich includes two masks as predicted events' tokens. We use the probabilities\nof predicted events to evaluate the assumption rationality for the final event\ncausality decision. Experiments on the EventStoryLine corpus and\nCausal-TimeBank corpus validate our design objective in terms of significant\nperformance improvements over the state-of-the-art algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1\">Wei Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_C/0/1/0/all/0/1\">Chuanhong Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Test-takers have a say: understanding the implications of the use of AI in language tests. (arXiv:2307.09885v1 [cs.CY])","link":"http://arxiv.org/abs/2307.09885","description":"<p>Language tests measure a person's ability to use a language in terms of\nlistening, speaking, reading, or writing. Such tests play an integral role in\nacademic, professional, and immigration domains, with entities such as\neducational institutions, professional accreditation bodies, and governments\nusing them to assess candidate language proficiency. Recent advances in\nArtificial Intelligence (AI) and the discipline of Natural Language Processing\nhave prompted language test providers to explore AI's potential applicability\nwithin language testing, leading to transformative activity patterns\nsurrounding language instruction and learning. However, with concerns over AI's\ntrustworthiness, it is imperative to understand the implications of integrating\nAI into language testing. This knowledge will enable stakeholders to make\nwell-informed decisions, thus safeguarding community well-being and testing\nintegrity. To understand the concerns and effects of AI usage in language\ntests, we conducted interviews and surveys with English test-takers. To the\nbest of our knowledge, this is the first empirical study aimed at identifying\nthe implications of AI adoption in language tests from a test-taker\nperspective. Our study reveals test-taker perceptions and behavioral patterns.\nSpecifically, we identify that AI integration may enhance perceptions of\nfairness, consistency, and availability. Conversely, it might incite mistrust\nregarding reliability and interactivity aspects, subsequently influencing the\nbehaviors and well-being of test-takers. These insights provide a better\nunderstanding of potential societal implications and assist stakeholders in\nmaking informed decisions concerning AI usage in language testing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dawen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1\">Thong Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shidong Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yongquan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staples_M/0/1/0/all/0/1\">Mark Staples</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qinghua Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quigley_A/0/1/0/all/0/1\">Aaron Quigley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models can accomplish Business Process Management Tasks. (arXiv:2307.09923v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09923","description":"<p>Business Process Management (BPM) aims to improve organizational activities\nand their outcomes by managing the underlying processes. To achieve this, it is\noften necessary to consider information from various sources, including\nunstructured textual documents. Therefore, researchers have developed several\nBPM-specific solutions that extract information from textual documents using\nNatural Language Processing techniques. These solutions are specific to their\nrespective tasks and cannot accomplish multiple process-related problems as a\ngeneral-purpose instrument. However, in light of the recent emergence of Large\nLanguage Models (LLMs) with remarkable reasoning capabilities, such a\ngeneral-purpose instrument with multiple applications now appears attainable.\nIn this paper, we illustrate how LLMs can accomplish text-related BPM tasks by\napplying a specific LLM to three exemplary tasks: mining imperative process\nmodels from textual descriptions, mining declarative process models from\ntextual descriptions, and assessing the suitability of process tasks from\ntextual descriptions for robotic process automation. We show that, without\nextensive configuration or prompt engineering, LLMs perform comparably to or\nbetter than existing solutions and discuss implications for future BPM research\nas well as practical usage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Grohs_M/0/1/0/all/0/1\">Michael Grohs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abb_L/0/1/0/all/0/1\">Luka Abb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elsayed_N/0/1/0/all/0/1\">Nourhan Elsayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehse_J/0/1/0/all/0/1\">Jana-Rebecca Rehse</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GUIDO: A Hybrid Approach to Guideline Discovery & Ordering from Natural Language Texts. (arXiv:2307.09959v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09959","description":"<p>Extracting workflow nets from textual descriptions can be used to simplify\nguidelines or formalize textual descriptions of formal processes like business\nprocesses and algorithms. The task of manually extracting processes, however,\nrequires domain expertise and effort. While automatic process model extraction\nis desirable, annotating texts with formalized process models is expensive.\nTherefore, there are only a few machine-learning-based extraction approaches.\nRule-based approaches, in turn, require domain specificity to work well and can\nrarely distinguish relevant and irrelevant information in textual descriptions.\nIn this paper, we present GUIDO, a hybrid approach to the process model\nextraction task that first, classifies sentences regarding their relevance to\nthe process model, using a BERT-based sentence classifier, and second, extracts\na process model from the sentences classified as relevant, using dependency\nparsing. The presented approach achieves significantly better results than a\npure rule-based approach. GUIDO achieves an average behavioral similarity score\nof $0.93$. Still, in comparison to purely machine-learning-based approaches,\nthe annotation costs stay low.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Freyer_N/0/1/0/all/0/1\">Nils Freyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thewes_D/0/1/0/all/0/1\">Dustin Thewes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinecke_M/0/1/0/all/0/1\">Matthias Meinecke</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Mathematical Derivations with Large Language Models. (arXiv:2307.09998v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09998","description":"<p>The derivation of mathematical results in specialised fields using Large\nLanguage Models (LLMs) is an emerging research direction that can help identify\nmodels' limitations, and potentially support mathematical discovery. In this\npaper, we leverage a symbolic engine to generate derivations of equations at\nscale, and investigate the capabilities of LLMs when deriving goal equations\nfrom premises. Specifically, we employ in-context learning for GPT and\nfine-tune a range of T5 models to compare the robustness and generalisation of\npre-training strategies to specialised models. Empirical results show that\nfine-tuned FLAN-T5-large (MathT5) outperforms GPT models on all static and\nout-of-distribution test sets in terms of absolute performance. However, an\nin-depth analysis reveals that the fine-tuned models are more sensitive to\nperturbations involving unseen symbols and (to a lesser extent) changes to\nequation structure. In addition, we analyse 1.7K equations and over 200\nderivations to highlight common reasoning errors such as the inclusion of\nincorrect, irrelevant, and redundant equations, along with the tendency to skip\nderivation steps. Finally, we explore the suitability of existing metrics for\nevaluating mathematical derivations finding evidence that, while they capture\ngeneral properties such as sensitivity to perturbations, they fail to highlight\nfine-grained reasoning errors and essential differences between models.\nOverall, this work demonstrates that training models on synthetic data can\nimprove their mathematical capabilities beyond larger architectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meadows_J/0/1/0/all/0/1\">Jordan Meadows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andre Freitas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods. (arXiv:2307.10025v1 [cs.HC])","link":"http://arxiv.org/abs/2307.10025","description":"<p>Fertility issues are closely related to population security, in 60 years\nChina's population for the first time in a negative growth trend, the change of\nfertility policy is of great concern to the community. 2023 ``two sessions\"\nproposal ``suggests that the country in the form of legislation, the birth of\nthe registration of the cancellation of the marriage restriction\" This topic\nwas once a hot topic on the Internet, and ``unbundling\" the relationship\nbetween birth registration and marriage has become the focus of social debate.\nIn this paper, we adopt co-occurrence semantic analysis, topic analysis and\nsentiment analysis to conduct multi-granularity semantic analysis of microblog\ncomments. It is found that the discussion on the proposal of ``removing\nmarriage restrictions from birth registration\" involves the individual, society\nand the state at three dimensions, and is detailed into social issues such as\npersonal behaviour, social ethics and law, and national policy, with people's\nsentiment inclined to be negative in most of the topics. Based on this, eight\nproposals were made to provide a reference for governmental decision making and\nto form a reference method for researching public opinion on political issues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yulin Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Android in the Wild: A Large-Scale Dataset for Android Device Control. (arXiv:2307.10088v1 [cs.LG])","link":"http://arxiv.org/abs/2307.10088","description":"<p>There is a growing interest in device-control systems that can interpret\nhuman natural language instructions and execute them on a digital device by\ndirectly controlling its user interface. We present a dataset for\ndevice-control research, Android in the Wild (AITW), which is orders of\nmagnitude larger than current datasets. The dataset contains human\ndemonstrations of device interactions, including the screens and actions, and\ncorresponding natural language instructions. It consists of 715k episodes\nspanning 30k unique instructions, four versions of Android (v10-13),and eight\ndevice types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It\ncontains multi-step tasks that require semantic understanding of language and\nvisual context. This dataset poses a new challenge: actions available through\nthe user interface must be inferred from their visual appearance. And, instead\nof simple UI element-based actions, the action space consists of precise\ngestures (e.g., horizontal scrolls to operate carousel widgets). We organize\nour dataset to encourage robustness analysis of device-control systems, i.e.,\nhow well a system performs in the presence of new task descriptions, new\napplications, or new platform versions. We develop two agents and report\nperformance across the dataset. The dataset is available at\nhttps://github.com/google-research/google-research/tree/master/android_in_the_wild.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rawles_C/0/1/0/all/0/1\">Christopher Rawles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Alice Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_D/0/1/0/all/0/1\">Daniel Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riva_O/0/1/0/all/0/1\">Oriana Riva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lillicrap_T/0/1/0/all/0/1\">Timothy Lillicrap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient Sparsification For Masked Fine-Tuning of Transformers. (arXiv:2307.10098v1 [cs.CL])","link":"http://arxiv.org/abs/2307.10098","description":"<p>Fine-tuning pretrained self-supervised language models is widely adopted for\ntransfer learning to downstream tasks. Fine-tuning can be achieved by freezing\ngradients of the pretrained network and only updating gradients of a newly\nadded classification layer, or by performing gradient updates on all\nparameters. Gradual unfreezing makes a trade-off between the two by gradually\nunfreezing gradients of whole layers during training. This has been an\neffective strategy to trade-off between storage and training speed with\ngeneralization performance. However, it is not clear whether gradually\nunfreezing layers throughout training is optimal, compared to sparse variants\nof gradual unfreezing which may improve fine-tuning performance. In this paper,\nwe propose to stochastically mask gradients to regularize pretrained language\nmodels for improving overall fine-tuned performance. We introduce GradDrop and\nvariants thereof, a class of gradient sparsification methods that mask\ngradients during the backward pass, acting as gradient noise. GradDrop is\nsparse and stochastic unlike gradual freezing. Extensive experiments on the\nmultilingual XGLUE benchmark with XLMR-Large show that GradDrop is competitive\nagainst methods that use additional translated data for intermediate\npretraining and outperforms standard fine-tuning and gradual unfreezing. A\npost-analysis shows how GradDrop improves performance with languages it was not\ntrained on, such as under-resourced languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Neill_J/0/1/0/all/0/1\">James O&#x27; Neill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1\">Sourav Dutta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Transformer Extrapolation. (arXiv:2307.10156v1 [cs.CL])","link":"http://arxiv.org/abs/2307.10156","description":"<p>Length extrapolation has attracted considerable attention recently since it\nallows transformers to be tested on longer sequences than those used in\ntraining. Previous research has shown that this property can be attained by\nusing carefully designed Relative Positional Encodings (RPEs). While these\nmethods perform well on a variety of corpora, the conditions for length\nextrapolation have yet to be investigated. This paper attempts to determine\nwhat types of RPEs allow for length extrapolation through a thorough\nmathematical and empirical analysis. We discover that a transformer is certain\nto possess this property as long as the series that corresponds to the RPE's\nexponential converges. Two practices are derived from the conditions and\nexamined in language modeling tasks on a variety of corpora. As a bonus from\nthe conditions, we derive a new Theoretical Receptive Field (TRF) to measure\nthe receptive field of RPEs without taking any training steps. Extensive\nexperiments are conducted on the Wikitext-103, Books, Github, and WikiBook\ndatasets to demonstrate the viability of our discovered conditions. We also\ncompare TRF to Empirical Receptive Field (ERF) across different models, showing\nconsistently matched trends on the aforementioned datasets. The code is\navailable at https://github.com/OpenNLPLab/Rpe.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiran Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Hui Deng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs as Workers in Human-Computational Algorithms? Replicating Crowdsourcing Pipelines with LLMs. (arXiv:2307.10168v1 [cs.CL])","link":"http://arxiv.org/abs/2307.10168","description":"<p>LLMs have shown promise in replicating human-like behavior in crowdsourcing\ntasks that were previously thought to be exclusive to human abilities. However,\ncurrent efforts focus mainly on simple atomic tasks. We explore whether LLMs\ncan replicate more complex crowdsourcing pipelines. We find that modern LLMs\ncan simulate some of crowdworkers' abilities in these \"human computation\nalgorithms,\" but the level of success is variable and influenced by requesters'\nunderstanding of LLM capabilities, the specific skills required for sub-tasks,\nand the optimal interaction modality for performing these sub-tasks. We reflect\non human and LLMs' different sensitivities to instructions, stress the\nimportance of enabling human-facing safeguards for LLMs, and discuss the\npotential of training humans and LLMs with complementary skill sets. Crucially,\nwe show that replicating crowdsourcing pipelines offers a valuable platform to\ninvestigate (1) the relative strengths of LLMs on different tasks (by\ncross-comparing their performances on sub-tasks) and (2) LLMs' potential in\ncomplex tasks, where they can complete part of the tasks while leaving others\nto humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Haiyi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albayrak_M/0/1/0/all/0/1\">Maya Albayrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Axon_A/0/1/0/all/0/1\">Alexis Axon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bertsch_A/0/1/0/all/0/1\">Amanda Bertsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Wenxing Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Ziqi Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_B/0/1/0/all/0/1\">Bill Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gururaja_S/0/1/0/all/0/1\">Sireesh Gururaja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_T/0/1/0/all/0/1\">Tzu-Sheng Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jenny T. Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ryan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandal_I/0/1/0/all/0/1\">Ihita Mandal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milbauer_J/0/1/0/all/0/1\">Jeremiah Milbauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_X/0/1/0/all/0/1\">Xiaolin Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmanabhan_N/0/1/0/all/0/1\">Namrata Padmanabhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramkumar_S/0/1/0/all/0/1\">Subhashini Ramkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sudjianto_A/0/1/0/all/0/1\">Alexis Sudjianto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_J/0/1/0/all/0/1\">Jordan Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_Y/0/1/0/all/0/1\">Ying-Jui Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaidos_P/0/1/0/all/0/1\">Patricia Vaidos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhijin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenyang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenges and Applications of Large Language Models. (arXiv:2307.10169v1 [cs.CL])","link":"http://arxiv.org/abs/2307.10169","description":"<p>Large Language Models (LLMs) went from non-existent to ubiquitous in the\nmachine learning discourse within a few years. Due to the fast pace of the\nfield, it is difficult to identify the remaining challenges and already\nfruitful application areas. In this paper, we aim to establish a systematic set\nof open problems and application successes so that ML researchers can\ncomprehend the field's current state more quickly and become productive.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1\">Jean Kaddour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harris_J/0/1/0/all/0/1\">Joshua Harris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mozes_M/0/1/0/all/0/1\">Maximilian Mozes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradley_H/0/1/0/all/0/1\">Herbie Bradley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1\">Roberta Raileanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McHardy_R/0/1/0/all/0/1\">Robert McHardy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI. (arXiv:2307.10172v1 [cs.CL])","link":"http://arxiv.org/abs/2307.10172","description":"<p>Despite advancements in conversational AI, language models encounter\nchallenges to handle diverse conversational tasks, and existing dialogue\ndataset collections often lack diversity and comprehensiveness. To tackle these\nissues, we introduce DialogStudio: the largest and most diverse collection of\ndialogue datasets, unified under a consistent format while preserving their\noriginal information. Our collection encompasses data from open-domain\ndialogues, task-oriented dialogues, natural language understanding,\nconversational recommendation, dialogue summarization, and knowledge-grounded\ndialogues, making it an incredibly rich and diverse resource for dialogue\nresearch and model training. To further enhance the utility of DialogStudio, we\nidentify the licenses for each dataset and design domain-aware prompts for\nselected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we\ndevelop conversational AI models using the dataset collection, and our\nexperiments in both zero-shot and few-shot learning scenarios demonstrate the\nsuperiority of DialogStudio. To improve transparency and support dataset and\ntask-based research, as well as language model pre-training, all datasets,\nlicenses, codes, and models associated with DialogStudio are made publicly\naccessible at https://github.com/salesforce/DialogStudio\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1\">Shelby Heinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Softmax for Uncertainty Approximation in Text Classification. (arXiv:2210.14037v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2210.14037","description":"<p>Uncertainty approximation in text classification is an important area with\napplications in domain adaptation and interpretability. One of the most widely\nused uncertainty approximation methods is Monte Carlo (MC) Dropout, which is\ncomputationally expensive as it requires multiple forward passes through the\nmodel. A cheaper alternative is to simply use the softmax based on a single\nforward pass without dropout to estimate model uncertainty. However, prior work\nhas indicated that these predictions tend to be overconfident. In this paper,\nwe perform a thorough empirical analysis of these methods on five datasets with\ntwo base neural architectures in order to identify the trade-offs between the\ntwo. We compare both softmax and an efficient version of MC Dropout on their\nuncertainty approximations and downstream text classification performance,\nwhile weighing their runtime (cost) against performance (benefit). We find\nthat, while MC dropout produces the best uncertainty approximations, using a\nsimple softmax leads to competitive and in some cases better uncertainty\nestimation for text classification at a much lower computational cost,\nsuggesting that softmax can in fact be a sufficient uncertainty estimate when\ncomputational resources are a concern.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holm_A/0/1/0/all/0/1\">Andreas Nugaard Holm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_D/0/1/0/all/0/1\">Dustin Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can In-context Learners Learn a Reasoning Concept from Demonstrations?. (arXiv:2212.01692v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.01692","description":"<p>Language models exhibit an emergent ability to learn a new task from a small\nnumber of input-output demonstrations. However, recent work shows that\nin-context learners largely rely on their pre-trained knowledge, such as the\nsentiment of the labels, instead of learning new associations from the input.\nWe argue that the commonly-used few-shot evaluation using a random selection of\nin-context demonstrations can not disentangle models' reliance on such biases,\nas most of the randomly-selected demonstrations do not present relations\ninformative for prediction beyond exposing the task's input-output\ndistribution.\n</p>\n<p>Therefore, to evaluate models' in-context learning ability independent of\nmodels' memory, we introduce a Concept-sharing few-shot learning method\nchoosing the demonstrations that share an underlying concept with the predicted\nsample. We extract a set of such concepts from available human explanations and\nmeasure how much models can benefit from presenting these concepts in few-shot\ndemonstrations.\n</p>\n<p>We find that most of the recent in-context learners can not consistently\nbenefit from the demonstrated concepts, irrespective of the model size.\nHowever, we note that T0 models are more sensitive to exhibited concepts,\nbenefiting from concept-sharing demonstrations in 7 out of 8 evaluation\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stefanik_M/0/1/0/all/0/1\">Michal &#x160;tef&#xe1;nik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadlcik_M/0/1/0/all/0/1\">Marek Kadl&#x10d;&#xed;k</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lego-MT: Learning Detachable Models for Massively Multilingual Machine Translation. (arXiv:2212.10551v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10551","description":"<p>Multilingual neural machine translation (MNMT) aims to build a unified model\nfor many language directions. Existing monolithic models for MNMT encounter two\nchallenges: parameter interference among languages and inefficient inference\nfor large models. In this paper, we revisit the classic multi-way structures\nand develop a detachable model by assigning each language (or group of\nlanguages) to an individual branch that supports plug-and-play training and\ninference. To address the needs of learning representations for all languages\nin a unified space, we propose a novel efficient training recipe, upon which we\nbuild an effective detachable model, Lego-MT. For a fair comparison, we collect\ndata from OPUS and build a translation benchmark covering 433 languages and\n1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings\nan average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters.\nThe proposed training recipe brings a 28.2$\\times$ speedup over the\nconventional multi-way training method.\\footnote{\n\\url{https://github.com/CONE-MT/Lego-MT}.}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1\">Fei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yinquan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">WenHao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11596","description":"<p>Large language models (LLMs) such as GPT-4 have recently demonstrated\nimpressive results across a wide range of tasks. LLMs are still limited,\nhowever, in that they frequently fail at complex reasoning, their reasoning\nprocesses are opaque, they are prone to 'hallucinate' facts, and there are\nconcerns about their underlying biases. Letting models verbalize reasoning\nsteps as natural language, a technique known as chain-of-thought prompting, has\nrecently been proposed as a way to address some of these issues. Here we\npresent ThoughtSource, a meta-dataset and software library for chain-of-thought\n(CoT) reasoning. The goal of ThoughtSource is to improve future artificial\nintelligence systems by facilitating qualitative understanding of CoTs,\nenabling empirical evaluations, and providing training data. This first release\nof ThoughtSource integrates six scientific/medical, three general-domain and\nfive math word question answering datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ott_S/0/1/0/all/0/1\">Simon Ott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hebenstreit_K/0/1/0/all/0/1\">Konstantin Hebenstreit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lievin_V/0/1/0/all/0/1\">Valentin Li&#xe9;vin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hother_C/0/1/0/all/0/1\">Christoffer Egeberg Hother</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moradi_M/0/1/0/all/0/1\">Milad Moradi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayrhauser_M/0/1/0/all/0/1\">Maximilian Mayrhauser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Praas_R/0/1/0/all/0/1\">Robert Praas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1\">Ole Winther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samwald_M/0/1/0/all/0/1\">Matthias Samwald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12135","description":"<p>The growth of pending legal cases in populous countries, such as India, has\nbecome a major issue. Developing effective techniques to process and understand\nlegal documents is extremely useful in resolving this problem. In this paper,\nwe present our systems for SemEval-2023 Task 6: understanding legal texts (Modi\net al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that\nconsiders the comprehensive context information in both intra- and\ninter-sentence levels to predict rhetorical roles (subtask A) and then train a\nLegal-LUKE model, which is legal-contextualized and entity-aware, to recognize\nlegal entities (subtask B). Our evaluations demonstrate that our designed\nmodels are more accurate than baselines, e.g., with an up to 15.0% better F1\nscore in subtask B. We achieved notable performance in the task leaderboard,\ne.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuchen Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT Outperforms Crowd-Workers for Text-Annotation Tasks. (arXiv:2303.15056v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.15056","description":"<p>Many NLP applications require manual data annotations for a variety of tasks,\nnotably to train classifiers or evaluate the performance of unsupervised\nmodels. Depending on the size and degree of complexity, the tasks may be\nconducted by crowd-workers on platforms such as MTurk as well as trained\nannotators, such as research assistants. Using a sample of 2,382 tweets, we\ndemonstrate that ChatGPT outperforms crowd-workers for several annotation\ntasks, including relevance, stance, topics, and frames detection. Specifically,\nthe zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of\nfive tasks, while ChatGPT's intercoder agreement exceeds that of both\ncrowd-workers and trained annotators for all tasks. Moreover, the\nper-annotation cost of ChatGPT is less than $0.003 -- about twenty times\ncheaper than MTurk. These results show the potential of large language models\nto drastically increase the efficiency of text classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gilardi_F/0/1/0/all/0/1\">Fabrizio Gilardi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alizadeh_M/0/1/0/all/0/1\">Meysam Alizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kubli_M/0/1/0/all/0/1\">Ma&#xeb;l Kubli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.07848","description":"<p>Contrastive learning based cross-modality pretraining methods have recently\nexhibited impressive success in diverse fields. In this paper, we propose\nGEmo-CLAP, a kind of gender-attribute-enhanced contrastive language-audio\npretraining (CLAP) method for speech emotion recognition. Specifically, a novel\nemotion CLAP model (Emo-CLAP) is first built, utilizing various self-supervised\npre-trained models. Second, considering the importance of gender attribute in\nspeech emotion modeling, the soft label based GEmo-CLAP (SL-GEmo-CLAP) and\nmulti-task learning based GEmo-CLAP (ML-GEmo-CLAP) are further proposed to\nintegrate the emotion and gender information of speech signals, forming more\nreasonable objectives. Extensive experiments on IEMOCAP show that our proposed\ntwo GEmo-CLAP models consistently outperform the baseline Emo-CLAP with\ndifferent pre-trained models, while also achieving the best recognition\nperformance compared with recent state-of-the-art methods. Noticeably, the\nproposed WavLM-based ML-GEmo-CLAP obtains the best UAR of 80.16\\% and WAR of\n82.06\\%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lei Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Iterated Piecewise Affine (IPA) Approximation for Language Modeling. (arXiv:2306.12317v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.12317","description":"<p>In this work, we demonstrate the application of a simple first-order Taylor\nexpansion to approximate a generic function $F: R^{n \\times m} \\to R^{n \\times\nm}$ and utilize it in language modeling. To enhance the basic Taylor expansion,\nwe introduce iteration and piecewise modeling, leading us to name the algorithm\nthe Iterative Piecewise Affine (IPA) approximation. The final algorithm\nexhibits interesting resemblances to the Transformers decoder architecture. By\ncomparing parameter arrangements in IPA and Transformers, we observe a\nstrikingly similar performance, with IPA outperforming Transformers by 1.5\\% in\nthe next token prediction task with cross-entropy loss for smaller sequence\nlengths.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shamsi_D/0/1/0/all/0/1\">Davood Shamsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wen-yu Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_B/0/1/0/all/0/1\">Brian Williams</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LongNet: Scaling Transformers to 1,000,000,000 Tokens. (arXiv:2307.02486v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.02486","description":"<p>Scaling sequence length has become a critical demand in the era of large\nlanguage models. However, existing methods struggle with either computational\ncomplexity or model expressivity, rendering the maximum sequence length\nrestricted. To address this issue, we introduce LongNet, a Transformer variant\nthat can scale sequence length to more than 1 billion tokens, without\nsacrificing the performance on shorter sequences. Specifically, we propose\ndilated attention, which expands the attentive field exponentially as the\ndistance grows. LongNet has significant advantages: 1) it has a linear\ncomputation complexity and a logarithm dependency between any two tokens in a\nsequence; 2) it can be served as a distributed trainer for extremely long\nsequences; 3) its dilated attention is a drop-in replacement for standard\nattention, which can be seamlessly integrated with the existing\nTransformer-based optimization. Experiments results demonstrate that LongNet\nyields strong performance on both long-sequence modeling and general language\ntasks. Our work opens up new possibilities for modeling very long sequences,\ne.g., treating a whole corpus or even the entire Internet as a sequence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jiayu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1\">Nanning Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.03135","description":"<p>Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Code released at\nhttps://github.com/xuanlinli17/large_vlm_distillation_ood\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yunhao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retentive Network: A Successor to Transformer for Large Language Models. (arXiv:2307.08621v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.08621","description":"<p>In this work, we propose Retentive Network (RetNet) as a foundation\narchitecture for large language models, simultaneously achieving training\nparallelism, low-cost inference, and good performance. We theoretically derive\nthe connection between recurrence and attention. Then we propose the retention\nmechanism for sequence modeling, which supports three computation paradigms,\ni.e., parallel, recurrent, and chunkwise recurrent. Specifically, the parallel\nrepresentation allows for training parallelism. The recurrent representation\nenables low-cost $O(1)$ inference, which improves decoding throughput, latency,\nand GPU memory without sacrificing performance. The chunkwise recurrent\nrepresentation facilitates efficient long-sequence modeling with linear\ncomplexity, where each chunk is encoded parallelly while recurrently\nsummarizing the chunks. Experimental results on language modeling show that\nRetNet achieves favorable scaling results, parallel training, low-cost\ndeployment, and efficient inference. The intriguing properties make RetNet a\nstrong successor to Transformer for large language models. Code will be\navailable at https://aka.ms/retnet.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yutao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yuqing Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jilong Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models. (arXiv:2307.09288v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09288","description":"<p>In this work, we develop and release Llama 2, a collection of pretrained and\nfine-tuned large language models (LLMs) ranging in scale from 7 billion to 70\nbillion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for\ndialogue use cases. Our models outperform open-source chat models on most\nbenchmarks we tested, and based on our human evaluations for helpfulness and\nsafety, may be a suitable substitute for closed-source models. We provide a\ndetailed description of our approach to fine-tuning and safety improvements of\nLlama 2-Chat in order to enable the community to build on our work and\ncontribute to the responsible development of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Louis Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_K/0/1/0/all/0/1\">Kevin Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albert_P/0/1/0/all/0/1\">Peter Albert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1\">Amjad Almahairi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babaei_Y/0/1/0/all/0/1\">Yasmine Babaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bashlykov_N/0/1/0/all/0/1\">Nikolay Bashlykov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batra_S/0/1/0/all/0/1\">Soumya Batra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_P/0/1/0/all/0/1\">Prajjwal Bhargava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1\">Shruti Bhosale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bikel_D/0/1/0/all/0/1\">Dan Bikel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blecher_L/0/1/0/all/0/1\">Lukas Blecher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Moya Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucurull_G/0/1/0/all/0/1\">Guillem Cucurull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esiobu_D/0/1/0/all/0/1\">David Esiobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_J/0/1/0/all/0/1\">Jude Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jeremy Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wenyin Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuller_B/0/1/0/all/0/1\">Brian Fuller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Cynthia Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Naman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartshorn_A/0/1/0/all/0/1\">Anthony Hartshorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Saghar Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Hakan Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardas_M/0/1/0/all/0/1\">Marcin Kardas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerkez_V/0/1/0/all/0/1\">Viktor Kerkez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kloumann_I/0/1/0/all/0/1\">Isabel Kloumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korenev_A/0/1/0/all/0/1\">Artem Korenev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koura_P/0/1/0/all/0/1\">Punit Singh Koura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lachaux_M/0/1/0/all/0/1\">Marie-Anne Lachaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavril_T/0/1/0/all/0/1\">Thibaut Lavril</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jenya Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liskovich_D/0/1/0/all/0/1\">Diana Liskovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yinghai Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinet_X/0/1/0/all/0/1\">Xavier Martinet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihaylov_T/0/1/0/all/0/1\">Todor Mihaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Pushkar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molybog_I/0/1/0/all/0/1\">Igor Molybog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulton_A/0/1/0/all/0/1\">Andrew Poulton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reizenstein_J/0/1/0/all/0/1\">Jeremy Reizenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rungta_R/0/1/0/all/0/1\">Rashi Rungta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saladi_K/0/1/0/all/0/1\">Kalyan Saladi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schelten_A/0/1/0/all/0/1\">Alan Schelten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ruan Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_E/0/1/0/all/0/1\">Eric Michael Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_R/0/1/0/all/0/1\">Ranjan Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiaoqing Ellen Tan</a>, et al. (15 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation. (arXiv:2307.09416v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.09416","description":"<p>Research in Image Generation has recently made significant progress,\nparticularly boosted by the introduction of Vision-Language models which are\nable to produce high-quality visual content based on textual inputs. Despite\nongoing advancements in terms of generation quality and realism, no methodical\nframeworks have been defined yet to quantitatively measure the quality of the\ngenerated content and the adherence with the prompted requests: so far, only\nhuman-based evaluations have been adopted for quality satisfaction and for\ncomparing different generative methods. We introduce a novel automated method\nfor Visual Concept Evaluation (ViCE), i.e. to assess consistency between a\ngenerated/edited image and the corresponding prompt/instructions, with a\nprocess inspired by the human cognitive behaviour. ViCE combines the strengths\nof Large Language Models (LLMs) and Visual Question Answering (VQA) into a\nunified pipeline, aiming to replicate the human cognitive process in quality\nassessment. This method outlines visual concepts, formulates image-specific\nverification questions, utilizes the Q&amp;A system to investigate the image, and\nscores the combined outcome. Although this brave new hypothesis of mimicking\nhumans in the image evaluation process is in its preliminary assessment stage,\nresults are promising and open the door to a new form of automatic evaluation\nwhich could have significant impact as the image generation or the image target\nediting tasks become more and more sophisticated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Betti_F/0/1/0/all/0/1\">Federico Betti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1\">Jacopo Staiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1\">Rita Cucchiara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers. (arXiv:2307.09455v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09455","description":"<p>For real-world language applications, detecting an out-of-distribution (OOD)\nsample is helpful to alert users or reject such unreliable samples. However,\nmodern over-parameterized language models often produce overconfident\npredictions for both in-distribution (ID) and OOD samples. In particular,\nlanguage models suffer from OOD samples with a similar semantic representation\nto ID samples since these OOD samples lie near the ID manifold. A rejection\nnetwork can be trained with ID and diverse outlier samples to detect test OOD\nsamples, but explicitly collecting auxiliary OOD datasets brings an additional\nburden for data collection. In this paper, we propose a simple but effective\nmethod called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD\ndataset by sequentially masking tokens related to ID classes. The surrogate OOD\nsample introduced by POE shows a similar representation to ID data, which is\nmost effective in training a rejection network. Our method does not require any\nexternal OOD data and can be easily implemented within off-the-shelf\nTransformers. A comprehensive comparison with state-of-the-art algorithms\ndemonstrates POE's competitiveness on several text classification benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaeyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyuheon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_D/0/1/0/all/0/1\">Dongbin Na</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Sion Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunbin Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sungchul Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A comparative analysis of SRGAN models. (arXiv:2307.09456v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.09456","description":"<p>In this study, we evaluate the performance of multiple state-of-the-art SRGAN\n(Super Resolution Generative Adversarial Network) models, ESRGAN, Real-ESRGAN\nand EDSR, on a benchmark dataset of real-world images which undergo degradation\nusing a pipeline. Our results show that some models seem to significantly\nincrease the resolution of the input images while preserving their visual\nquality, this is assessed using Tesseract OCR engine. We observe that EDSR-BASE\nmodel from huggingface outperforms the remaining candidate models in terms of\nboth quantitative metrics and subjective visual quality assessments with least\ncompute overhead. Specifically, EDSR generates images with higher peak\nsignal-to-noise ratio (PSNR) and structural similarity index (SSIM) values and\nare seen to return high quality OCR results with Tesseract OCR engine. These\nfindings suggest that EDSR is a robust and effective approach for single-image\nsuper-resolution and may be particularly well-suited for applications where\nhigh-quality visual fidelity is critical and optimized compute.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nikroo_F/0/1/0/all/0/1\">Fatemeh Rezapoor Nikroo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_A/0/1/0/all/0/1\">Ajinkya Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Anantha Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_A/0/1/0/all/0/1\">Adrian Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1\">Kaarthik Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norris_C/0/1/0/all/0/1\">Cleo Norris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dangi_A/0/1/0/all/0/1\">Aditya Dangi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-07-19T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}