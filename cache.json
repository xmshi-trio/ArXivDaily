{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-07-14T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Incomplete Utterance Rewriting as Sequential Greedy Tagging. (arXiv:2307.06337v1 [cs.LG])","link":"http://arxiv.org/abs/2307.06337","description":"<p>The task of incomplete utterance rewriting has recently gotten much\nattention. Previous models struggled to extract information from the dialogue\ncontext, as evidenced by the low restoration scores. To address this issue, we\npropose a novel sequence tagging-based model, which is more adept at extracting\ninformation from context. Meanwhile, we introduce speaker-aware embedding to\nmodel speaker variation. Experiments on multiple public datasets show that our\nmodel achieves optimal results on all nine restoration scores while having\nother metric scores comparable to previous state-of-the-art models.\nFurthermore, benefitting from the model's simplicity, our approach outperforms\nmost previous models on inference speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunshan Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Acquisition of Semantic Relationships between words. (arXiv:2307.06419v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06419","description":"<p>The study of semantic relationships has revealed a close connection between\nthese relationships and the morphological characteristics of a language.\nMorphology, as a subfield of linguistics, investigates the internal structure\nand formation of words. By delving into the relationship between semantic\nrelationships and language morphology, we can gain deeper insights into how the\nunderlying structure of words contributes to the interpretation and\ncomprehension of language. This paper explores the dynamic interplay between\nsemantic relationships and the morphological aspects of different languages, by\nexamining the intricate relationship between language morphology and semantic\nrelationships, valuable insights can be gained regarding how the structure of\nwords influences language comprehension.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naamane_M/0/1/0/all/0/1\">Mohamed Naamane</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06435","description":"<p>Large Language Models (LLMs) have shown excellent generalization capabilities\nthat have led to the development of numerous models. These models propose\nvarious new architectures, tweaking existing architectures with refined\ntraining strategies, increasing context length, using high-quality training\ndata, and increasing training time to outperform baselines. Analyzing new\ndevelopments is crucial for identifying changes that enhance training stability\nand improve generalization in LLMs. This survey paper comprehensively analyses\nthe LLMs architectures and their categorization, training strategies, training\ndatasets, and performance evaluations and discusses future research directions.\nMoreover, the paper also discusses the basic building blocks and concepts\nbehind LLMs, followed by a complete overview of LLMs, including their important\nfeatures and functions. Finally, the paper summarizes significant findings from\nLLM research and consolidates essential architectural and training strategies\nfor developing advanced LLMs. Given the continuous advancements in LLMs, we\nintend to regularly update this paper by incorporating new sections and\nfeaturing the latest LLM models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naveed_H/0/1/0/all/0/1\">Humza Naveed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ullah Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shi Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saqib_M/0/1/0/all/0/1\">Muhammad Saqib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1\">Saeed Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1\">Muhammad Usman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events. (arXiv:2307.06439v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06439","description":"<p>Large language models (LLMs), such as GPT-4, have demonstrated remarkable\ncapabilities across a wide range of tasks, including health applications. In\nthis paper, we study how LLMs can be used to scale biomedical knowledge\ncuration. We find that while LLMs already possess decent competency in\nstructuring biomedical text, by distillation into a task-specific student model\nthrough self-supervised learning, substantial gains can be attained over\nout-of-box LLMs, with additional advantages such as cost, efficiency, and\nwhite-box model access.\n</p>\n<p>We conduct a case study on adverse drug event (ADE) extraction, which is an\nimportant area for improving care. On standard ADE extraction evaluation, a\nGPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised\nstate-of-the-art models without using any labeled data. Despite being over\n1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by\nover 6 absolute points in F1 and GPT-4 by over 5 absolute points.\n</p>\n<p>Ablation studies on distillation model choice (e.g., PubMedBERT vs BioGPT)\nand ADE extraction architecture shed light on best practice for biomedical\nknowledge extraction. Similar gains were attained by distillation for other\nstandard biomedical knowledge extraction tasks such as gene-disease\nassociations and protected health information, further illustrating the promise\nof this approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woldesenbet_Y/0/1/0/all/0/1\">Yonas Woldesenbet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1\">Cliff Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanapathi_P/0/1/0/all/0/1\">Praneeth Sanapathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1\">Mu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valluri_N/0/1/0/all/0/1\">Naveen Valluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strandberg_E/0/1/0/all/0/1\">Erika Strandberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1\">Tristan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])","link":"http://arxiv.org/abs/2307.06440","description":"<p>The computation necessary for training Transformer-based language models has\nskyrocketed in recent years. This trend has motivated research on efficient\ntraining algorithms designed to improve training, validation, and downstream\nperformance faster than standard training. In this work, we revisit three\ncategories of such algorithms: dynamic architectures (layer stacking, layer\ndropping), batch selection (selective backprop, RHO loss), and efficient\noptimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed\ncomputation budget using such methods, we find that their training, validation,\nand downstream gains vanish compared to a baseline with a fully-decayed\nlearning rate. We define an evaluation protocol that enables computation to be\ndone on arbitrary machines by mapping all computation time to a reference\nmachine which we call reference system time. We discuss the limitations of our\nproposed protocol and release our code to encourage rigorous research in\nefficient training procedures: https://github.com/JeanKaddour/NoTrainNoGain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1\">Jean Kaddour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Key_O/0/1/0/all/0/1\">Oscar Key</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nawrot_P/0/1/0/all/0/1\">Piotr Nawrot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1\">Pasquale Minervini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1\">Matt J. Kusner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing the Ability of ChatGPT to Screen Articles for Systematic Reviews. (arXiv:2307.06464v1 [cs.SE])","link":"http://arxiv.org/abs/2307.06464","description":"<p>By organizing knowledge within a research field, Systematic Reviews (SR)\nprovide valuable leads to steer research. Evidence suggests that SRs have\nbecome first-class artifacts in software engineering. However, the tedious\nmanual effort associated with the screening phase of SRs renders these studies\na costly and error-prone endeavor. While screening has traditionally been\nconsidered not amenable to automation, the advent of generative AI-driven\nchatbots, backed with large language models is set to disrupt the field. In\nthis report, we propose an approach to leverage these novel technological\ndevelopments for automating the screening of SRs. We assess the consistency,\nclassification performance, and generalizability of ChatGPT in screening\narticles for SRs and compare these figures with those of traditional\nclassifiers used in SR automation. Our results indicate that ChatGPT is a\nviable option to automate the SR processes, but requires careful considerations\nfrom developers when integrating ChatGPT into their SR tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Syriani_E/0/1/0/all/0/1\">Eugene Syriani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_I/0/1/0/all/0/1\">Istvan David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Gauransh Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v1 [cs.LG])","link":"http://arxiv.org/abs/2307.06483","description":"<p>Automated classifiers (ACs), often built via supervised machine learning\n(SML), can categorize large, statistically powerful samples of data ranging\nfrom text to images and video, and have become widely popular measurement\ndevices in communication science and related fields. Despite this popularity,\neven highly accurate classifiers make errors that cause misclassification bias\nand misleading results in downstream analyses-unless such analyses account for\nthese errors. As we show in a systematic literature review of SML applications,\ncommunication scholars largely ignore misclassification bias. In principle,\nexisting statistical methods can use \"gold standard\" validation data, such as\nthat created by human annotators, to correct misclassification bias and produce\nconsistent estimates. We introduce and test such methods, including a new\nmethod we design and implement in the R package misclassificationmodels, via\nMonte Carlo simulations designed to reveal each method's limitations, which we\nalso release. Based on our results, we recommend our new error correction\nmethod as it is versatile and efficient. In sum, automated classifiers, even\nthose below common accuracy standards or making systematic misclassifications,\ncan be useful for measurement with careful study design and appropriate error\ncorrection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+TeBlunthuis_N/0/1/0/all/0/1\">Nathan TeBlunthuis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hase_V/0/1/0/all/0/1\">Valerie Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chung-Hong Chan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Agreement Tracking for Multi-Issue Negotiation Dialogues. (arXiv:2307.06524v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06524","description":"<p>Automated negotiation support systems aim to help human negotiators reach\nmore favorable outcomes in multi-issue negotiations (e.g., an employer and a\ncandidate negotiating over issues such as salary, hours, and promotions before\na job offer). To be successful, these systems must accurately track agreements\nreached by participants in real-time. Existing approaches either focus on\ntask-oriented dialogues or produce unstructured outputs, rendering them\nunsuitable for this objective. Our work introduces the novel task of agreement\ntracking for two-party multi-issue negotiations, which requires continuous\nmonitoring of agreements within a structured state space. To address the\nscarcity of annotated corpora with realistic multi-issue negotiation dialogues,\nwe use GPT-3 to build GPT-Negochat, a synthesized dataset that we make publicly\navailable. We present a strong initial baseline for our task by\ntransfer-learning a T5 model trained on the MultiWOZ 2.4 corpus. Pre-training\nT5-small and T5-base on MultiWOZ 2.4's DST task enhances results by 21% and 9%\nrespectively over training solely on GPT-Negochat. We validate our method's\nsample-efficiency via smaller training subset experiments. By releasing\nGPT-Negochat and our baseline models, we aim to encourage further research in\nmulti-issue negotiation dialogue agreement tracking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mannekote_A/0/1/0/all/0/1\">Amogh Mannekote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dorr_B/0/1/0/all/0/1\">Bonnie J. Dorr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyer_K/0/1/0/all/0/1\">Kristy Elizabeth Boyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Integration of Large Language Models into Automatic Speech Recognition Systems: An Empirical Study. (arXiv:2307.06530v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06530","description":"<p>This paper explores the integration of Large Language Models (LLMs) into\nAutomatic Speech Recognition (ASR) systems to improve transcription accuracy.\nThe increasing sophistication of LLMs, with their in-context learning\ncapabilities and instruction-following behavior, has drawn significant\nattention in the field of Natural Language Processing (NLP). Our primary focus\nis to investigate the potential of using an LLM's in-context learning\ncapabilities to enhance the performance of ASR systems, which currently face\nchallenges such as ambient noise, speaker accents, and complex linguistic\ncontexts. We designed a study using the Aishell-1 and LibriSpeech datasets,\nwith ChatGPT and GPT-4 serving as benchmarks for LLM capabilities.\nUnfortunately, our initial experiments did not yield promising results,\nindicating the complexity of leveraging LLM's in-context learning for ASR\napplications. Despite further exploration with varied settings and models, the\ncorrected sentences from the LLMs frequently resulted in higher Word Error\nRates (WER), demonstrating the limitations of LLMs in speech applications. This\npaper provides a detailed overview of these experiments, their results, and\nimplications, establishing that using LLMs' in-context learning capabilities to\ncorrect potential errors in speech recognition transcriptions is still a\nchallenging task at the current stage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Min_Z/0/1/0/all/0/1\">Zeping Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinbo Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A Natural Language Processing Approach. (arXiv:2307.06540v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06540","description":"<p>This study addressed the complex task of sentiment analysis on a dataset of\n119,988 original tweets from Weibo using a Convolutional Neural Network (CNN),\noffering a new approach to Natural Language Processing (NLP). The data, sourced\nfrom Baidu's PaddlePaddle AI platform, were meticulously preprocessed,\ntokenized, and categorized based on sentiment labels. A CNN-based model was\nutilized, leveraging word embeddings for feature extraction, and trained to\nperform sentiment classification. The model achieved a macro-average F1-score\nof approximately 0.73 on the test set, showing balanced performance across\npositive, neutral, and negative sentiments. The findings underscore the\neffectiveness of CNNs for sentiment analysis tasks, with implications for\npractical applications in social media analysis, market research, and policy\nstudies. The complete experimental content and code have been made publicly\navailable on the Kaggle data platform for further research and development.\nFuture work may involve exploring different architectures, such as Recurrent\nNeural Networks (RNN) or transformers, or using more complex pre-trained models\nlike BERT, to further improve the model's ability to understand linguistic\nnuances and context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yufei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raga_R/0/1/0/all/0/1\">Rodolfo C. Raga Jr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v1 [cs.IR])","link":"http://arxiv.org/abs/2307.06576","description":"<p>Precisely recommending candidate news articles to users has always been a\ncore challenge for personalized news recommendation systems. Most recent works\nprimarily focus on using advanced natural language processing techniques to\nextract semantic information from rich textual data, employing content-based\nmethods derived from local historical news. However, this approach lacks a\nglobal perspective, failing to account for users' hidden motivations and\nbehaviors beyond semantic information. To address this challenge, we propose a\nnovel model called GLORY (Global-LOcal news Recommendation sYstem), which\ncombines global representations learned from other users with local\nrepresentations to enhance personalized recommendation systems. We accomplish\nthis by constructing a Global-aware Historical News Encoder, which includes a\nglobal news graph and employs gated graph neural networks to enrich news\nrepresentations, thereby fusing historical news representations by a historical\nnews aggregator. Similarly, we extend this approach to a Global Candidate News\nEncoder, utilizing a global entity graph and a candidate news aggregator to\nenhance candidate news representation. Evaluation results on two public news\ndatasets demonstrate that our method outperforms existing approaches.\nFurthermore, our model offers more diverse recommendations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Boming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dairui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzumura_T/0/1/0/all/0/1\">Toyotaro Suzumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Ruihai Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parmesan: mathematical concept extraction for education. (arXiv:2307.06699v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06699","description":"<p>Mathematics is a highly specialized domain with its own unique set of\nchallenges that has seen limited study in natural language processing. However,\nmathematics is used in a wide variety of fields and multidisciplinary research\nin many different domains often relies on an understanding of mathematical\nconcepts. To aid researchers coming from other fields, we develop a prototype\nsystem for searching for and defining mathematical concepts in context,\nfocusing on the field of category theory. This system, Parmesan, depends on\nnatural language processing components including concept extraction, relation\nextraction, definition extraction, and entity linking. In developing this\nsystem, we show that existing techniques cannot be applied directly to the\ncategory theory domain, and suggest hybrid techniques that do perform well,\nthough we expect the system to evolve over time. We also provide two cleaned\nmathematical corpora that power the prototype system, which are based on\njournal articles and wiki pages, respectively. The corpora have been annotated\nwith dependency trees, lemmas, and part-of-speech tags.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Collard_J/0/1/0/all/0/1\">Jacob Collard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paiva_V/0/1/0/all/0/1\">Valeria de Paiva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subrahmanian_E/0/1/0/all/0/1\">Eswaran Subrahmanian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intent-calibrated Self-training for Answer Selection in Open-domain Dialogues. (arXiv:2307.06703v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06703","description":"<p>Answer selection in open-domain dialogues aims to select an accurate answer\nfrom candidates. Recent success of answer selection models hinges on training\nwith large amounts of labeled data. However, collecting large-scale labeled\ndata is labor-intensive and time-consuming. In this paper, we introduce the\npredicted intent labels to calibrate answer labels in a self-training paradigm.\nSpecifically, we propose the intent-calibrated self-training (ICAST) to improve\nthe quality of pseudo answer labels through the intent-calibrated answer\nselection paradigm, in which we employ pseudo intent labels to help improve\npseudo answer labels. We carry out extensive experiments on two benchmark\ndatasets with open-domain dialogues. The experimental results show that ICAST\noutperforms baselines consistently with 1%, 5% and 10% labeled data.\nSpecifically, it improves 2.06% and 1.00% of F1 score on the two datasets,\ncompared with the strongest baseline with only 5% labeled data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Wentao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jiahuan Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhumin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"To share or not to share: What risks would laypeople accept to give sensitive data to differentially-private NLP systems?. (arXiv:2307.06708v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06708","description":"<p>Although the NLP community has adopted central differential privacy as a\ngo-to framework for privacy-preserving model training or data sharing, the\nchoice and interpretation of the key parameter, privacy budget $\\varepsilon$\nthat governs the strength of privacy protection, remains largely arbitrary. We\nargue that determining the $\\varepsilon$ value should not be solely in the\nhands of researchers or system developers, but must also take into account the\nactual people who share their potentially sensitive data. In other words: Would\nyou share your instant messages for $\\varepsilon$ of 10? We address this\nresearch gap by designing, implementing, and conducting a behavioral experiment\n(311 lay participants) to study the behavior of people in uncertain\ndecision-making situations with respect to privacy-threatening situations.\nFraming the risk perception in terms of two realistic NLP scenarios and using a\nvignette behavioral study help us determine what $\\varepsilon$ thresholds would\nlead lay people to be willing to share sensitive textual data - to our\nknowledge, the first study of its kind.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weiss_C/0/1/0/all/0/1\">Christopher Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreuter_F/0/1/0/all/0/1\">Frauke Kreuter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1\">Ivan Habernal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Calibration through Prior Adaptation for Text Classification using Large Language Models. (arXiv:2307.06713v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06713","description":"<p>A wide variety of natural language tasks are currently being addressed with\nlarge-scale language models (LLMs). These models are usually trained with a\nvery large amount of unsupervised text data and adapted to perform a downstream\nnatural language task using methods like fine-tuning, calibration or in-context\nlearning. In this work, we propose an approach to adapt the prior class\ndistribution to perform text classification tasks without the need for labelled\nsamples and only few in-domain sample queries. The proposed approach treats the\nLLM as a black box, adding a stage where the model posteriors are calibrated to\nthe task. Results show that these methods outperform the un-adapted model for\ndifferent number of training shots in the prompt and a previous approach were\ncalibration is performed without using any adaptation data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Estienne_L/0/1/0/all/0/1\">Lautaro Estienne</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why Guided Dialog Policy Learning performs well? Understanding the role of adversarial learning and its alternative. (arXiv:2307.06721v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06721","description":"<p>Dialog policies, which determine a system's action based on the current state\nat each dialog turn, are crucial to the success of the dialog. In recent years,\nreinforcement learning (RL) has emerged as a promising option for dialog policy\nlearning (DPL). In RL-based DPL, dialog policies are updated according to\nrewards. The manual construction of fine-grained rewards, such as\nstate-action-based ones, to effectively guide the dialog policy is challenging\nin multi-domain task-oriented dialog scenarios with numerous state-action pair\ncombinations. One way to estimate rewards from collected data is to train the\nreward estimator and dialog policy simultaneously using adversarial learning\n(AL). Although this method has demonstrated superior performance\nexperimentally, it is fraught with the inherent problems of AL, such as mode\ncollapse. This paper first identifies the role of AL in DPL through detailed\nanalyses of the objective functions of dialog policy and reward estimator.\nNext, based on these analyses, we propose a method that eliminates AL from\nreward estimation and DPL while retaining its advantages. We evaluate our\nmethod using MultiWOZ, a multi-domain task-oriented dialog corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shimoyama_S/0/1/0/all/0/1\">Sho Shimoyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morimura_T/0/1/0/all/0/1\">Tetsuro Morimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abe_K/0/1/0/all/0/1\">Kenshi Abe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takamichi_T/0/1/0/all/0/1\">Toda Takamichi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomomatsu_Y/0/1/0/all/0/1\">Yuta Tomomatsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1\">Masakazu Sugiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hentona_A/0/1/0/all/0/1\">Asahi Hentona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azuma_Y/0/1/0/all/0/1\">Yuuki Azuma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ninomiya_H/0/1/0/all/0/1\">Hirotaka Ninomiya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])","link":"http://arxiv.org/abs/2307.06775","description":"<p>Over the last decade, there has been a vast increase in eating disorder\ndiagnoses and eating disorder-attributed deaths, reaching their zenith during\nthe Covid-19 pandemic. This immense growth derived in part from the stressors\nof the pandemic but also from increased exposure to social media, which is rife\nwith content that promotes eating disorders. Such content can induce eating\ndisorders in viewers. This study aimed to create a multimodal deep learning\nmodel capable of determining whether a given social media post promotes eating\ndisorders based on a combination of visual and textual data. A labeled dataset\nof Tweets was collected from Twitter, upon which twelve deep learning models\nwere trained and tested. Based on model performance, the most effective deep\nlearning model was the multimodal fusion of the RoBERTa natural language\nprocessing model and the MaxViT image classification model, attaining accuracy\nand F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion\nmodel, deployed to classify an unlabeled dataset of posts from the social media\nsites Tumblr and Reddit, generated similar classifications as previous research\nstudies that did not employ artificial intelligence, showing that artificial\nintelligence can develop insights congruent to those of researchers.\nAdditionally, the model was used to conduct a time-series analysis of yet\nunseen Tweets from eight Twitter hashtags, uncovering that the relative\nabundance of pro-eating disorder content has decreased drastically. However,\nsince approximately 2018, pro-eating disorder content has either stopped its\ndecline or risen once more in ampleness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feldman_J/0/1/0/all/0/1\">Jonathan Feldman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Negated Complementary Commonsense using Large Language Models. (arXiv:2307.06794v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06794","description":"<p>Larger language models, such as GPT-3, have shown to be excellent in many\ntasks. However, we demonstrate that out-of-ordinary questions can throw the\nmodel off guard. This work focuses on finding answers to negated complementary\nquestions in commonsense scenarios. We illustrate how such questions adversely\naffect the model responses. We propose a model-agnostic methodology to improve\nthe performance in negated complementary scenarios. Our method outperforms\nfew-shot generation from GPT-3 (by more than 11 points) and, more importantly,\nhighlights the significance of studying the response of large language models\nin negated complementary questions. The code, data, and experiments are\navailable under: https://github.com/navidre/negated_complementary_commonsense.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_N/0/1/0/all/0/1\">Navid Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reformat_M/0/1/0/all/0/1\">Marek Z. Reformat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personalization for BERT-based Discriminative Speech Recognition Rescoring. (arXiv:2307.06832v1 [eess.AS])","link":"http://arxiv.org/abs/2307.06832","description":"<p>Recognition of personalized content remains a challenge in end-to-end speech\nrecognition. We explore three novel approaches that use personalized content in\na neural rescoring step to improve recognition: gazetteers, prompting, and a\ncross-attention based encoder-decoder model. We use internal de-identified\nen-US data from interactions with a virtual voice assistant supplemented with\npersonalized named entities to compare these approaches. On a test set with\npersonalized named entities, we show that each of these approaches improves\nword error rate by over 10%, against a neural rescoring baseline. We also show\nthat on this test set, natural language prompts can improve word error rate by\n7% without any training and with a marginal loss in generalization. Overall,\ngazetteers were found to perform the best with a 10% improvement in word error\nrate (WER), while also improving WER on a general test set by 1%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Kolehmainen_J/0/1/0/all/0/1\">Jari Kolehmainen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gu_Y/0/1/0/all/0/1\">Yile Gu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gourav_A/0/1/0/all/0/1\">Aditya Gourav</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shivakumar_P/0/1/0/all/0/1\">Prashanth Gurunath Shivakumar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Gandhe_A/0/1/0/all/0/1\">Ankur Gandhe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rastrow_A/0/1/0/all/0/1\">Ariya Rastrow</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bulyko_I/0/1/0/all/0/1\">Ivan Bulyko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Garbage in, garbage out: Zero-shot detection of crime using Large Language Models. (arXiv:2307.06844v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06844","description":"<p>This paper proposes exploiting the common sense knowledge learned by large\nlanguage models to perform zero-shot reasoning about crimes given textual\ndescriptions of surveillance videos. We show that when video is (manually)\nconverted to high quality textual descriptions, large language models are\ncapable of detecting and classifying crimes with state-of-the-art performance\nusing only zero-shot reasoning. However, existing automated video-to-text\napproaches are unable to generate video descriptions of sufficient quality to\nsupport reasoning (garbage video descriptions into the large language model,\ngarbage out).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Simmons_A/0/1/0/all/0/1\">Anj Simmons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasa_R/0/1/0/all/0/1\">Rajesh Vasa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-consistency for open-ended generations. (arXiv:2307.06857v1 [cs.AI])","link":"http://arxiv.org/abs/2307.06857","description":"<p>In this paper, we present a novel approach for improving the quality and\nconsistency of generated outputs from large-scale pre-trained language models\n(LLMs). Self-consistency has emerged as an effective approach for prompts with\nfixed answers, selecting the answer with the highest number of votes. In this\npaper, we introduce a generalized framework for self-consistency that extends\nits applicability beyond problems that have fixed-answer answers. Through\nextensive simulations, we demonstrate that our approach consistently recovers\nthe optimal or near-optimal generation from a set of candidates. We also\npropose lightweight parameter-free similarity functions that show significant\nand consistent improvements across code generation, autoformalization, and\nsummarization tasks, even without access to token log probabilities. Our method\nincurs minimal computational overhead, requiring no auxiliary reranker models\nor modifications to the existing model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Siddhartha Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaofei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deoras_A/0/1/0/all/0/1\">Anoop Deoras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompts Should not be Seen as Secrets: Systematically Measuring Prompt Extraction Attack Success. (arXiv:2307.06865v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06865","description":"<p>The generations of large language models are commonly controlled through\nprompting techniques, where a user's query to the model is prefixed with a\nprompt that aims to guide the model's behaviour on the query. The prompts used\nby companies to guide their models are often treated as secrets, to be hidden\nfrom the user making the query. They have even been treated as commodities to\nbe bought and sold. However, there has been anecdotal evidence showing that the\nprompts can be extracted by a user even when they are kept secret. In this\npaper, we present a framework for systematically measuring the success of\nprompt extraction attacks. In experiments with multiple sources of prompts and\nmultiple underlying language models, we find that simple text-based attacks can\nin fact reveal prompts with high probability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ippolito_D/0/1/0/all/0/1\">Daphne Ippolito</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DecompEval: Evaluating Generated Texts as Unsupervised Decomposed Question Answering. (arXiv:2307.06869v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06869","description":"<p>Existing evaluation metrics for natural language generation (NLG) tasks face\nthe challenges on generalization ability and interpretability. Specifically,\nmost of the well-performed metrics are required to train on evaluation datasets\nof specific NLG tasks and evaluation dimensions, which may cause over-fitting\nto task-specific datasets. Furthermore, existing metrics only provide an\nevaluation score for each dimension without revealing the evidence to interpret\nhow this score is obtained. To deal with these challenges, we propose a simple\nyet effective metric called DecompEval. This metric formulates NLG evaluation\nas an instruction-style question answering task and utilizes instruction-tuned\npre-trained language models (PLMs) without training on evaluation datasets,\naiming to enhance the generalization ability. To make the evaluation process\nmore interpretable, we decompose our devised instruction-style question about\nthe quality of generated texts into the subquestions that measure the quality\nof each sentence. The subquestions with their answers generated by PLMs are\nthen recomposed as evidence to obtain the evaluation result. Experimental\nresults show that DecompEval achieves state-of-the-art performance in untrained\nmetrics for evaluating text summarization and dialogue generation, which also\nexhibits strong dimension-level / task-level generalization ability and\ninterpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ke_P/0/1/0/all/0/1\">Pei Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Benchmarks for Factuality Evaluation of Language Models. (arXiv:2307.06908v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06908","description":"<p>Before deploying a language model (LM) within a given domain, it is important\nto measure its tendency to generate factually incorrect information in that\ndomain. Existing factual generation evaluation methods focus on facts sampled\nfrom the LM itself, and thus do not control the set of evaluated facts and\nmight under-represent rare and unlikely facts. We propose FACTOR: Factual\nAssessment via Corpus TransfORmation, a scalable approach for evaluating LM\nfactuality. FACTOR automatically transforms a factual corpus of interest into a\nbenchmark evaluating an LM's propensity to generate true facts from the corpus\nvs. similar but incorrect statements. We use our framework to create two\nbenchmarks: Wiki-FACTOR and News-FACTOR. We show that: (i) our benchmark scores\nincrease with model size and improve when the LM is augmented with retrieval;\n(ii) benchmark score correlates with perplexity, but the two metrics do not\nalways agree on model ranking; and (iii) when perplexity and benchmark score\ndisagree, the latter better reflects factuality in open-ended generation, as\nmeasured by human annotators. We make our data and code publicly available in\nhttps://github.com/AI21Labs/factor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muhlgay_D/0/1/0/all/0/1\">Dor Muhlgay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1\">Ori Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magar_I/0/1/0/all/0/1\">Inbal Magar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_Y/0/1/0/all/0/1\">Yoav Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratner_N/0/1/0/all/0/1\">Nir Ratner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leyton_Brown_K/0/1/0/all/0/1\">Kevin Leyton-Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1\">Amnon Shashua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoham_Y/0/1/0/all/0/1\">Yoav Shoham</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT. (arXiv:2307.06917v1 [cs.AI])","link":"http://arxiv.org/abs/2307.06917","description":"<p>Knowledge Graphs (KG) provide us with a structured, flexible, transparent,\ncross-system, and collaborative way of organizing our knowledge and data across\nvarious domains in society and industrial as well as scientific disciplines.\nKGs surpass any other form of representation in terms of effectiveness.\nHowever, Knowledge Graph Engineering (KGE) requires in-depth experiences of\ngraph structures, web technologies, existing models and vocabularies, rule\nsets, logic, as well as best practices. It also demands a significant amount of\nwork. Considering the advancements in large language models (LLMs) and their\ninterfaces and applications in recent years, we have conducted comprehensive\nexperiments with ChatGPT to explore its potential in supporting KGE. In this\npaper, we present a selection of these experiments and their results to\ndemonstrate how ChatGPT can assist us in the development and management of KGs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meyer_L/0/1/0/all/0/1\">Lars-Peter Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stadler_C/0/1/0/all/0/1\">Claus Stadler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frey_J/0/1/0/all/0/1\">Johannes Frey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radtke_N/0/1/0/all/0/1\">Norman Radtke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junghanns_K/0/1/0/all/0/1\">Kurt Junghanns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meissner_R/0/1/0/all/0/1\">Roy Meissner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziwis_G/0/1/0/all/0/1\">Gordian Dziwis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulert_K/0/1/0/all/0/1\">Kirill Bulert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_M/0/1/0/all/0/1\">Michael Martin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding. (arXiv:2307.06924v1 [cs.RO])","link":"http://arxiv.org/abs/2307.06924","description":"<p>Persons with visual impairments (PwVI) have difficulties understanding and\nnavigating spaces around them. Current wayfinding technologies either focus\nsolely on navigation or provide limited communication about the environment.\nMotivated by recent advances in visual-language grounding and semantic\nnavigation, we propose DRAGON, a guiding robot powered by a dialogue system and\nthe ability to associate the environment with natural language. By\nunderstanding the commands from the user, DRAGON is able to guide the user to\nthe desired landmarks on the map, describe the environment, and answer\nquestions from visual observations. Through effective utilization of dialogue,\nthe robot can ground the user's free-form descriptions to landmarks in the\nenvironment, and give the user semantic information through spoken language. We\nconduct a user study with blindfolded participants in an everyday indoor\nenvironment. Our results demonstrate that DRAGON is able to communicate with\nthe user smoothly, provide a good guiding experience, and connect users with\ntheir surrounding environment in an intuitive manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuijing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1\">Aamir Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1\">Kaiwen Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Runxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1\">Peixin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizrachi_Z/0/1/0/all/0/1\">Zachary Mizrachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Justin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McPherson_D/0/1/0/all/0/1\">D. Livingston McPherson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_W/0/1/0/all/0/1\">Wendy A. Rogers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1\">Katherine Driggs-Campbell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs. (arXiv:2307.06930v1 [cs.CV])","link":"http://arxiv.org/abs/2307.06930","description":"<p>Modular vision-language models (Vision-LLMs) align pretrained image encoders\nwith (pretrained) large language models (LLMs), representing a computationally\nmuch more efficient alternative to end-to-end training of large vision-language\nmodels from scratch, which is prohibitively expensive for most. Vision-LLMs\ninstead post-hoc condition LLMs to `understand' the output of an image encoder.\nWith the abundance of readily available high-quality English image-text data as\nwell as monolingual English LLMs, the research focus has been on English-only\nVision-LLMs. Multilingual vision-language models are still predominantly\nobtained via expensive end-to-end pretraining, resulting in comparatively\nsmaller models, trained on limited multilingual image data supplemented with\ntext-only multilingual corpora. In this work, we present mBLIP, the first\nmultilingual Vision-LLM, which we obtain in a computationally efficient manner\n-- on consumer hardware using only a few million training examples -- by\nleveraging a pretrained multilingual LLM. To this end, we \\textit{re-align} an\nimage encoder previously tuned to an English LLM to a new, multilingual LLM --\nfor this, we leverage multilingual data from a mix of vision-and-language\ntasks, which we obtain by machine-translating high-quality English data to 95\nlanguages. On the IGLUE benchmark, mBLIP yields results competitive with\nstate-of-the-art models. Moreover, in image captioning on XM3600, mBLIP\n(zero-shot) even outperforms PaLI-X (a model with 55B parameters). Compared to\nthese very large multilingual vision-language models trained from scratch, we\nobtain mBLIP by training orders of magnitude fewer parameters on magnitudes\nless data. We release our model and code at\n\\url{https://github.com/gregor-ge/mBLIP}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geigle_G/0/1/0/all/0/1\">Gregor Geigle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Abhay Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1\">Radu Timofte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1\">Goran Glava&#x161;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v1 [cs.CL])","link":"http://arxiv.org/abs/2307.06945","description":"<p>We propose the In-context Autoencoder (ICAE) for context compression in a\nlarge language model (LLM). The ICAE has two modules: a learnable encoder\nadapted with LoRA from an LLM for compressing a long context into a limited\nnumber of memory slots, and a fixed decoder which is the target LLM that can\ncondition on the memory slots for various purposes. We first pretrain the ICAE\nusing both autoencoding and language modeling objectives on massive text data,\nenabling it to generate memory slots that accurately and comprehensively\nrepresent the original context. Then, we fine-tune the pretrained ICAE on a\nsmall amount of instruct data to enhance its interaction with various prompts\nfor producing desirable responses. Our experimental results demonstrate that\nthe ICAE learned with our proposed pretraining and fine-tuning paradigm can\neffectively produce memory slots with $4\\times$ context compression, which can\nbe well conditioned on by the target LLM to respond to various prompts. The\npromising results demonstrate significant implications of the ICAE for its\nnovel approach to the long context problem and its potential to reduce\ncomputation and memory overheads for LLM inference in practice, suggesting\nfurther research effort in context management for an LLM. Our code and data\nwill be released shortly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Perturbation-based QE: An Explainable, Unsupervised Word-level Quality Estimation Method for Blackbox Machine Translation. (arXiv:2305.07457v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07457","description":"<p>Quality Estimation (QE) is the task of predicting the quality of Machine\nTranslation (MT) system output, without using any gold-standard translation\nreferences. State-of-the-art QE models are supervised: they require\nhuman-labeled quality of some MT system output on some datasets for training,\nmaking them domain-dependent and MT-system-dependent. There has been research\non unsupervised QE, which requires glass-box access to the MT systems, or\nparallel MT data to generate synthetic errors for training QE models. In this\npaper, we present Perturbation-based QE - a word-level Quality Estimation\napproach that works simply by analyzing MT system output on perturbed input\nsource sentences. Our approach is unsupervised, explainable, and can evaluate\nany type of blackbox MT systems, including the currently prominent large\nlanguage models (LLMs) with opaque internal processes. For language directions\nwith no labeled QE data, our approach has similar or better performance than\nthe zero-shot supervised approach on the WMT21 shared task. Our approach is\nbetter at detecting gender bias and word-sense-disambiguation errors in\ntranslation than supervised QE, indicating its robustness to out-of-domain\nusage. The performance gap is larger when detecting errors on a nontraditional\ntranslation-prompting LLM, indicating that our approach is more generalizable\nto different MT systems. We give examples demonstrating our approach's\nexplainability power, where it shows which input source words have influence on\na certain MT output word.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1\">Tu Anh Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1\">Jan Niehues</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Small Language Models on PubMedQA via Generative Data Augmentation. (arXiv:2305.07804v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07804","description":"<p>Large Language Models (LLMs) have made remarkable advancements in the field\nof natural language processing. However, their increasing size poses challenges\nin terms of computational cost. On the other hand, Small Language Models (SLMs)\nare known for their efficiency, but they often struggle with limited capacity\nand training data, especially in specific domains. In this paper, we introduce\na novel method aimed at improving SLMs in the medical domain using LLM-based\ngenerative data augmentation. The objective of our approach is to develop more\nefficient and capable models that are specifically tailored for specialized\napplications. Through experiments conducted on the PubMedQA dataset, we\ndemonstrate the effectiveness of LLMs in refining and diversifying existing\nquestion-answer pairs. This refinement process leads to improved performance in\na significantly smaller model after fine-tuning. Notably, our best SLM, with\nunder 1.6 billion parameters, outperforms the few-shot GPT-4 on the PubMedQA\ndataset. Our code and generated data are publicly available to facilitate\nfurther explorations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1\">Shangdi Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10400","description":"<p>Automatically determining whether a text and a corresponding image are\nsemantically aligned is a significant challenge for vision-language models,\nwith applications in generative text-to-image and image-to-text tasks. In this\nwork, we study methods for automatic text-image alignment evaluation. We first\nintroduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets\nfrom both text-to-image and image-to-text generation tasks, with human\njudgements for whether a given text-image pair is semantically aligned. We then\ndescribe two automatic methods to determine alignment: the first involving a\npipeline based on question generation and visual question answering models, and\nthe second employing an end-to-end classification approach by finetuning\nmultimodal pretrained models. Both methods surpass prior approaches in various\ntext-image alignment tasks, with significant improvements in challenging cases\nthat involve complex composition or unnatural images. Finally, we demonstrate\nhow our approaches can localize specific misalignments between an image and a\ngiven text, and how they can be used to automatically re-rank candidates in\ntext-to-image generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yarom_M/0/1/0/all/0/1\">Michal Yarom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_O/0/1/0/all/0/1\">Oran Lang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ofek_E/0/1/0/all/0/1\">Eran Ofek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Speech Emotion Recognition. (arXiv:2306.07848v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.07848","description":"<p>Contrastive learning based pretraining methods have recently exhibited\nimpressive success in diverse fields. In this paper, we propose GEmo-CLAP, a\nkind of efficient gender-attribute-enhanced contrastive language-audio\npretraining (CLAP) model for speech emotion recognition. To be specific, we\nfirst build an effective emotion CLAP model Emo-CLAP for emotion recognition,\nutilizing various self-supervised learning based pre-trained models. Then,\nconsidering the importance of the gender attribute in speech emotion modeling,\ntwo GEmo-CLAP approaches are further proposed to integrate the emotion and\ngender information of speech signals, forming more reasonable objectives.\nExtensive experiments on the IEMOCAP corpus demonstrate that our proposed two\nGEmo-CLAP approaches consistently outperform the baseline Emo-CLAP with\ndifferent pre-trained models, while also achieving superior recognition\nperformance compared with other state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yanni Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuguang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jixun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_W/0/1/0/all/0/1\">Wen Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Heng Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Kosmos-2: Grounding Multimodal Large Language Models to the World. (arXiv:2306.14824v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.14824","description":"<p>We introduce Kosmos-2, a Multimodal Large Language Model (MLLM), enabling new\ncapabilities of perceiving object descriptions (e.g., bounding boxes) and\ngrounding text to the visual world. Specifically, we represent refer\nexpressions as links in Markdown, i.e., ``[text span](bounding boxes)'', where\nobject descriptions are sequences of location tokens. Together with multimodal\ncorpora, we construct large-scale data of grounded image-text pairs (called\nGrIT) to train the model. In addition to the existing capabilities of MLLMs\n(e.g., perceiving general modalities, following instructions, and performing\nin-context learning), Kosmos-2 integrates the grounding capability into\ndownstream applications. We evaluate Kosmos-2 on a wide range of tasks,\nincluding (i) multimodal grounding, such as referring expression comprehension,\nand phrase grounding, (ii) multimodal referring, such as referring expression\ngeneration, (iii) perception-language tasks, and (iv) language understanding\nand generation. This work lays out the foundation for the development of\nEmbodiment AI and sheds light on the big convergence of language, multimodal\nperception, action, and world modeling, which is a key step toward artificial\ngeneral intelligence. Code and pretrained models are available at\nhttps://aka.ms/kosmos-2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiliang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yaru Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00470","description":"<p>Large language models(LLMS) have shown excellent text generation\ncapabilities,capable of generating fluent responses for many downstream tasks.\nHowever,applying large language models to real-world critical tasks remains\nchallenging due to their susceptibility to hallucinations and inability to\ndirectly use external knowledge. To address the above challenges,this paper\nproposes PatternGPT, a pattern-driven text generation framework for large\nlanguage models. First,the framework utilizes the extraction capabilities of\nlarge language models to generate rich and diverse patterns and later draws on\nthe idea of federated learning. Using multiple agents to achieve sharing to\nobtain more diverse patterns. Finally, it searches for high-quality patterns\nusing judgment criteria and optimization algorithms and uses the searched\npatterns to guide the model for generation. This framework has the advantages\nof generating diversified patterns, protecting data privacy,combining external\nknowledge, and improving the quality of generation, which provides an effective\nmethod to optimize the text generation capability of large language models,and\nmake it better applied to the field of intelligent dialogue and content\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Le Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_X/0/1/0/all/0/1\">Xin Shan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03109","description":"<p>Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yupeng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.03875","description":"<p>Supply chain operations traditionally involve a variety of complex decision\nmaking problems. Over the last few decades, supply chains greatly benefited\nfrom advances in computation, which allowed the transition from manual\nprocessing to automation and cost-effective optimization. Nonetheless, business\noperators still need to spend substantial efforts in explaining and\ninterpreting the optimization outcomes to stakeholders. Motivated by the recent\nadvances in Large Language Models (LLMs), we study how this disruptive\ntechnology can help bridge the gap between supply chain automation and human\ncomprehension and trust thereof. We design OptiGuide -- a framework that\naccepts as input queries in plain text, and outputs insights about the\nunderlying optimization outcomes. Our framework does not forgo the\nstate-of-the-art combinatorial optimization technology, but rather leverages it\nto quantitatively answer what-if scenarios (e.g., how would the cost change if\nwe used supplier B instead of supplier A for a given demand?). Importantly, our\ndesign does not require sending proprietary data over to LLMs, which can be a\nprivacy concern in some circumstances. We demonstrate the effectiveness of our\nframework on a real server placement scenario within Microsoft's cloud supply\nchain. Along the way, we develop a general evaluation benchmark, which can be\nused to evaluate the accuracy of the LLM output in other scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Beibin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mellou_K/0/1/0/all/0/1\">Konstantina Mellou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathuri_J/0/1/0/all/0/1\">Jeevan Pathuri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menache_I/0/1/0/all/0/1\">Ishai Menache</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-07-13T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}