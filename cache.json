{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-03-07T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Exploring Data Augmentation Methods on Social Media Corpora. (arXiv:2303.02198v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02198","description":"<p>Data augmentation has proven widely effective in computer vision. In Natural\nLanguage Processing (NLP) data augmentation remains an area of active research.\nThere is no widely accepted augmentation technique that works well across tasks\nand model architectures. In this paper we explore data augmentation techniques\nin the context of text classification using two social media datasets. We\nexplore popular varieties of data augmentation, starting with oversampling,\nEasy Data Augmentation (Wei and Zou, 2019) and Back-Translation (Sennrich et\nal., 2015). We also consider Greyscaling, a relatively unexplored data\naugmentation technique that seeks to mitigate the intensity of adjectives in\nexamples. Finally, we consider a few-shot learning approach: Pattern-Exploiting\nTraining (PET) (Schick et al., 2020). For the experiments we use a BERT\ntransformer architecture. Results show that augmentation techniques provide\nonly minimal and inconsistent improvements. Synonym replacement provided\nevidence of some performance improvement and adjective scales with Grayscaling\nis an area where further exploration would be valuable. Few-shot learning\nexperiments show consistent improvement over supervised training, and seem very\npromising when classes are easily separable but further exploration would be\nvaluable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pietri_I/0/1/0/all/0/1\">Isabel Garcia Pietri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1\">Kineret Stanley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Answering Questions Over Knowledge Graphs Using Logic Programming Along with Language Models. (arXiv:2303.02206v1 [cs.LG])","link":"http://arxiv.org/abs/2303.02206","description":"<p>Question Answering over Knowledge Graphs (KGQA) is the task of answering\nnatural language questions over a knowledge graph (KG). This task requires a\nmodel to reason over multiple edges of the KG to reach the right answer. In\nthis work, we present a method to equip large language models (LLMs) with\nclassic logical programming languages to provide an explainable solution to the\nproblem. Our goal is to extract the representation of the question in the form\nof a Prolog query, which can then be used to answer the query programmatically.\nTo demonstrate the effectiveness of this approach, we use the MetaQA dataset\nand show that our method finds the correct answer entities for all the\nquestions in the test dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madani_N/0/1/0/all/0/1\">Navid Madani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_K/0/1/0/all/0/1\">Kenneth Joseph</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrojText: Test-time Invisible Textual Trojan Insertion. (arXiv:2303.02242v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02242","description":"<p>In Natural Language Processing (NLP), intelligent neuron models can be\nsusceptible to textual Trojan attacks. Such attacks occur when Trojan models\nbehave normally for standard inputs but generate malicious output for inputs\nthat contain a specific trigger. Syntactic-structure triggers, which are\ninvisible, are becoming more popular for Trojan attacks because they are\ndifficult to detect and defend against. However, these types of attacks require\na large corpus of training data to generate poisoned samples with the necessary\nsyntactic structures for Trojan insertion. Obtaining such data can be difficult\nfor attackers, and the process of generating syntactic poisoned triggers and\ninserting Trojans can be time-consuming. This paper proposes a solution called\nTrojText, which aims to determine whether invisible textual Trojan attacks can\nbe performed more efficiently and cost-effectively without training data. The\nproposed approach, called the Representation-Logit Trojan Insertion (RLI)\nalgorithm, uses smaller sampled test data instead of large training data to\nachieve the desired attack. The paper also introduces two additional\ntechniques, namely the accumulated gradient ranking (AGR) and Trojan Weights\nPruning (TWP), to reduce the number of tuned parameters and the attack\noverhead. The TrojText approach was evaluated on three datasets (AG's News,\nSST-2, and OLID) using three NLP models (BERT, XLNet, and DeBERTa). The\nexperiments demonstrated that the TrojText approach achieved a 98.35\\%\nclassification accuracy for test sentences in the target class on the BERT\nmodel for the AG's News dataset. The source code for TrojText is available at\nhttps://github.com/UCF-ML-Research/TrojText.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yepeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1\">Bo Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Q/0/1/0/all/0/1\">Qian Lou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to reason over visual objects. (arXiv:2303.02260v1 [cs.CV])","link":"http://arxiv.org/abs/2303.02260","description":"<p>A core component of human intelligence is the ability to identify abstract\npatterns inherent in complex, high-dimensional perceptual data, as exemplified\nby visual reasoning tasks such as Raven's Progressive Matrices (RPM). Motivated\nby the goal of designing AI systems with this capacity, recent work has focused\non evaluating whether neural networks can learn to solve RPM-like problems.\nPrevious work has generally found that strong performance on these problems\nrequires the incorporation of inductive biases that are specific to the RPM\nproblem format, raising the question of whether such models might be more\nbroadly useful. Here, we investigated the extent to which a general-purpose\nmechanism for processing visual scenes in terms of objects might help promote\nabstract visual reasoning. We found that a simple model, consisting only of an\nobject-centric encoder and a transformer reasoning module, achieved\nstate-of-the-art results on both of two challenging RPM-like benchmarks (PGM\nand I-RAVEN), as well as a novel benchmark with greater visual complexity\n(CLEVR-Matrices). These results suggest that an inductive bias for\nobject-centric processing may be a key component of abstract visual reasoning,\nobviating the need for problem-specific inductive biases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mondal_S/0/1/0/all/0/1\">Shanka Subhra Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webb_T/0/1/0/all/0/1\">Taylor Webb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1\">Jonathan D. Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiTTO: A Feature Representation Imitation Approach for Improving Cross-Lingual Transfer. (arXiv:2303.02357v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02357","description":"<p>Zero-shot cross-lingual transfer is promising, however has been shown to be\nsub-optimal, with inferior transfer performance across low-resource languages.\nIn this work, we envision languages as domains for improving zero-shot transfer\nby jointly reducing the feature incongruity between the source and the target\nlanguage and increasing the generalization capabilities of pre-trained\nmultilingual transformers. We show that our approach, DiTTO, significantly\noutperforms the standard zero-shot fine-tuning method on multiple datasets\nacross all languages using solely unlabeled instances in the target language.\nEmpirical results show that jointly reducing feature incongruity for multiple\ntarget languages is vital for successful cross-lingual transfer. Moreover, our\nmodel enables better cross-lingual transfer than standard fine-tuning methods,\neven in the few-shot setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shanu Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soujanya_A/0/1/0/all/0/1\">Abbaraju Soujanya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dandapat_S/0/1/0/all/0/1\">Sandipan Dandapat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitaram_S/0/1/0/all/0/1\">Sunayana Sitaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RweetMiner: Automatic identification and categorization of help requests on twitter during disasters. (arXiv:2303.02399v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02399","description":"<p>Catastrophic events create uncertain situations for humanitarian\norganizations locating and providing aid to affected people. Many people turn\nto social media during disasters for requesting help and/or providing relief to\nothers. However, the majority of social media posts seeking help could not\nproperly be detected and remained concealed because often they are noisy and\nill-formed. Existing systems lack in planning an effective strategy for tweet\npreprocessing and grasping the contexts of tweets. This research, first of all,\nformally defines request tweets in the context of social networking sites,\nhereafter rweets, along with their different primary types and sub-types. Our\nmain contributions are the identification and categorization of rweets. For\nrweet identification, we employ two approaches, namely a rule-based and\nlogistic regression, and show their high precision and F1 scores. The rweets\nclassification into sub-types such as medical, food, and shelter, using\nlogistic regression shows promising results and outperforms existing works.\nFinally, we introduce an architecture to store intermediate data to accelerate\nthe development process of the machine learning classifiers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ullah_I/0/1/0/all/0/1\">Irfan Ullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sharifullah Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1\">Muhammad Imran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Young-Koo Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges. (arXiv:2303.02411v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02411","description":"<p>Recent advancements in visiolinguistic (VL) learning have allowed the\ndevelopment of multiple models and techniques that offer several impressive\nimplementations, able to currently resolve a variety of tasks that require the\ncollaboration of vision and language. Current datasets used for VL pre-training\nonly contain a limited amount of visual and linguistic knowledge, thus\nsignificantly limiting the generalization capabilities of many VL models.\nExternal knowledge sources such as knowledge graphs (KGs) and Large Language\nModels (LLMs) are able to cover such generalization gaps by filling in missing\nknowledge, resulting in the emergence of hybrid architectures. In the current\nsurvey, we analyze tasks that have benefited from such hybrid approaches.\nMoreover, we categorize existing knowledge sources and types, proceeding to\ndiscussion regarding the KG vs LLM dilemma and its potential impact to future\nhybrid approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lymperaiou_M/0/1/0/all/0/1\">Maria Lymperaiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamou_G/0/1/0/all/0/1\">Giorgos Stamou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-tuning hyper-parameters for unsupervised cross-lingual tokenization. (arXiv:2303.02427v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02427","description":"<p>We explore the possibility of meta-learning for the language-independent\nunsupervised tokenization problem for English, Russian, and Chinese. We\nimplement the meta-learning approach for automatic determination of\nhyper-parameters of the unsupervised tokenization model proposed in earlier\nworks, relying on various human-independent fitness functions such as\nnormalised anti-entropy, compression factor and cross-split F 1 score, as well\nas additive and multiplicative composite combinations of the three metrics,\ntesting them against the conventional F1 tokenization score. We find a fairly\ngood correlation between the latter and the additive combination of the former\nthree metrics for English and Russian. In case of Chinese, we find a\nsignificant correlation between the F 1 score and the compression factor. Our\nresults suggest the possibility of robust unsupervised tokenization of\nlow-resource and dead languages and allow us to think about human languages in\nterms of the evolution of efficient symbolic communication codes with different\nstructural optimisation schemes that have evolved in different human cultures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kolonin_A/0/1/0/all/0/1\">Anton Kolonin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lon-e{\\aa} at SemEval-2023 Task 11: A Comparison of\\\\Activation Functions for Soft and Hard Label Prediction. (arXiv:2303.02468v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02468","description":"<p>We study the influence of different activation functions in the output layer\nof deep neural network models for soft and hard label prediction in the\nlearning with disagreement task. In this task, the goal is to quantify the\namount of disagreement via predicting soft labels. To predict the soft labels,\nwe use BERT-based preprocessors and encoders and vary the activation function\nused in the output layer, while keeping other parameters constant. The soft\nlabels are then used for the hard label prediction. The activation functions\nconsidered are sigmoid as well as a step-function that is added to the model\npost-training and a sinusoidal activation function, which is introduced for the\nfirst time in this paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_P/0/1/0/all/0/1\">Peyman Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mehran Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Azzawi_S/0/1/0/all/0/1\">Sana Sabah Al-Azzawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_I/0/1/0/all/0/1\">Ignacio Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Variational Quantum Classifiers for Natural-Language Text. (arXiv:2303.02469v1 [cs.CL])","link":"http://arxiv.org/abs/2303.02469","description":"<p>As part of the recent research effort on quantum natural language processing\n(QNLP), variational quantum sentence classifiers (VQSCs) have been implemented\nand supported in lambeq / DisCoPy, based on the DisCoCat model of sentence\nmeaning. We discuss in some detail VQSCs, including category theory, DisCoCat\nfor modeling sentence as string diagram, and DisCoPy for encoding string\ndiagram as parameterized quantum circuit. Many NLP tasks, however, require the\nhandling of text consisting of multiple sentences, which is not supported in\nlambeq / DisCoPy. A good example is sentiment classification of customer\nfeedback or product review. We discuss three potential approaches to\nvariational quantum text classifiers (VQTCs), in line with VQSCs. The first is\na weighted bag-of-sentences approach which treats text as a group of\nindependent sentences with task-specific sentence weighting. The second is a\ncoreference resolution approach which treats text as a consolidation of its\nmember sentences with coreferences among them resolved. Both approaches are\nbased on the DisCoCat model and should be implementable in lambeq / DisCoCat.\nThe third approach, on the other hand, is based on the DisCoCirc model which\nconsiders both ordering of sentences and interaction of words in composing text\nmeaning from word and sentence meanings. DisCoCirc makes fundamental\nmodification of DisCoCat since a sentence in DisCoCirc updates meanings of\nwords, whereas all meanings are static in DisCoCat. It is not clear if\nDisCoCirc can be implemented in lambeq / DisCoCat without breaking DisCoCat.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1\">Daniel T. Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESD: Expected Squared Difference as a Tuning-Free Trainable Calibration Measure. (arXiv:2303.02472v1 [cs.LG])","link":"http://arxiv.org/abs/2303.02472","description":"<p>Studies have shown that modern neural networks tend to be poorly calibrated\ndue to over-confident predictions. Traditionally, post-processing methods have\nbeen used to calibrate the model after training. In recent years, various\ntrainable calibration measures have been proposed to incorporate them directly\ninto the training process. However, these methods all incorporate internal\nhyperparameters, and the performance of these calibration objectives relies on\ntuning these hyperparameters, incurring more computational costs as the size of\nneural networks and datasets become larger. As such, we present Expected\nSquared Difference (ESD), a tuning-free (i.e., hyperparameter-free) trainable\ncalibration objective loss, where we view the calibration error from the\nperspective of the squared difference between the two expectations. With\nextensive experiments on several architectures (CNNs, Transformers) and\ndatasets, we demonstrate that (1) incorporating ESD into the training improves\nmodel calibration in various batch size settings without the need for internal\nhyperparameter tuning, (2) ESD yields the best-calibrated results compared with\nprevious approaches, and (3) ESD drastically improves the computational costs\nrequired for calibration during training due to the absence of internal\nhyperparameter. The code is publicly accessible at\nhttps://github.com/hee-suk-yoon/ESD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_H/0/1/0/all/0/1\">Hee Suk Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tee_J/0/1/0/all/0/1\">Joshua Tian Jin Tee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_E/0/1/0/all/0/1\">Eunseop Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sunjae Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gwangsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Token-Level Supervised Contrastive Learning for Punctuation Restoration. (arXiv:2107.09099v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.09099","description":"<p>Punctuation is critical in understanding natural language text. Currently,\nmost automatic speech recognition (ASR) systems do not generate punctuation,\nwhich affects the performance of downstream tasks, such as intent detection and\nslot filling. This gives rise to the need for punctuation restoration. Recent\nwork in punctuation restoration heavily utilizes pre-trained language models\nwithout considering data imbalance when predicting punctuation classes. In this\nwork, we address this problem by proposing a token-level supervised contrastive\nlearning method that aims at maximizing the distance of representation of\ndifferent punctuation marks in the embedding space. The result shows that\ntraining with token-level supervised contrastive learning obtains up to 3.2%\nabsolute F1 improvement on the test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qiushi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_T/0/1/0/all/0/1\">Tom Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">H Lilian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xubo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bo Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logic Traps in Evaluating Attribution Scores. (arXiv:2109.05463v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2109.05463","description":"<p>Modern deep learning models are notoriously opaque, which has motivated the\ndevelopment of methods for interpreting how deep models predict. This goal is\nusually approached with attribution method, which assesses the influence of\nfeatures on model predictions. As an explanation method, the evaluation\ncriteria of attribution methods is how accurately it re-reflects the actual\nreasoning process of the model (faithfulness). Meanwhile, since the reasoning\nprocess of deep models is inaccessible, researchers design various evaluation\nmethods to demonstrate their arguments. However, some crucial logic traps in\nthese evaluation methods are ignored in most works, causing inaccurate\nevaluation and unfair comparison. This paper systematically reviews existing\nmethods for evaluating attribution scores and summarizes the logic traps in\nthese methods. We further conduct experiments to demonstrate the existence of\neach logic trap. Through both the theoretical and experimental analysis, we\nhope to increase attention on the inaccurate evaluation of attribution scores.\nMoreover, with this paper, we suggest stopping focusing on improving\nperformance under unreliable evaluation systems and starting efforts on\nreducing the impact of proposed logic traps\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ju_Y/0/1/0/all/0/1\">Yiming Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhongtao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TraVLR: Now You See It, Now You Don't! A Bimodal Dataset for Evaluating Visio-Linguisic Reasoning. (arXiv:2111.10756v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2111.10756","description":"<p>Numerous visio-linguistic (V+L) representation learning methods have been\ndeveloped, yet existing datasets do not adequately evaluate the extent to which\nthey represent visual and linguistic concepts in a unified space. We propose\nseveral novel evaluation settings for V+L models, including cross-modal\ntransfer. Furthermore, existing V+L benchmarks often report global accuracy\nscores on the entire dataset, making it difficult to pinpoint the specific\nreasoning tasks that models fail and succeed at. We present TraVLR, a synthetic\ndataset comprising four V+L reasoning tasks. TraVLR's synthetic nature allows\nus to constrain its training and testing distributions along task-relevant\ndimensions, enabling the evaluation of out-of-distribution generalisation. Each\nexample in TraVLR redundantly encodes the scene in two modalities, allowing\neither to be dropped or added during training or testing without losing\nrelevant information. We compare the performance of four state-of-the-art V+L\nmodels, finding that while they perform well on test examples from the same\nmodality, they all fail at cross-modal transfer and have limited success\naccommodating the addition or deletion of one modality. We release TraVLR as an\nopen challenge for the research community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chow_K/0/1/0/all/0/1\">Keng Ji Chow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantifying Memorization Across Neural Language Models. (arXiv:2202.07646v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2202.07646","description":"<p>Large language models (LMs) have been shown to memorize parts of their\ntraining data, and when prompted appropriately, they will emit the memorized\ntraining data verbatim. This is undesirable because memorization violates\nprivacy (exposing user data), degrades utility (repeated easy-to-memorize text\nis often low quality), and hurts fairness (some texts are memorized over\nothers).\n</p>\n<p>We describe three log-linear relationships that quantify the degree to which\nLMs emit memorized training data. Memorization significantly grows as we\nincrease (1) the capacity of a model, (2) the number of times an example has\nbeen duplicated, and (3) the number of tokens of context used to prompt the\nmodel. Surprisingly, we find the situation becomes more complicated when\ngeneralizing these results across model families. On the whole, we find that\nmemorization in LMs is more prevalent than previously believed and will likely\nget worse as models continues to scale, at least without active mitigations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ippolito_D/0/1/0/all/0/1\">Daphne Ippolito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagielski_M/0/1/0/all/0/1\">Matthew Jagielski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chiyuan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter-Free Attentive Scoring for Speaker Verification. (arXiv:2203.05642v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2203.05642","description":"<p>This paper presents a novel study of parameter-free attentive scoring for\nspeaker verification. Parameter-free scoring provides the flexibility of\ncomparing speaker representations without the need of an accompanying\nparametric scoring model. Inspired by the attention component in Transformer\nneural networks, we propose a variant of the scaled dot product attention\nmechanism to compare enrollment and test segment representations. In addition,\nthis work explores the effect on performance of (i) different types of\nnormalization, (ii) independent versus tied query/key estimation, (iii) varying\nthe number of key-value pairs and (iv) pooling multiple enrollment utterance\nstatistics. Experimental results for a 4 task average show that a simple\nparameter-free attentive scoring mechanism can improve the average EER by 10%\nover the best cosine similarity baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pelecanos_J/0/1/0/all/0/1\">Jason Pelecanos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yiling Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreno_I/0/1/0/all/0/1\">Ignacio Lopez Moreno</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Testing the limits of natural language models for predicting human language judgments. (arXiv:2204.03592v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.03592","description":"<p>Neural network language models can serve as computational hypotheses about\nhow humans process language. We compared the model-human consistency of diverse\nlanguage models using a novel experimental approach: controversial sentence\npairs. For each controversial sentence pair, two language models disagree about\nwhich sentence is more likely to occur in natural text. Considering nine\nlanguage models (including n-gram, recurrent neural networks, and transformer\nmodels), we created hundreds of such controversial sentence pairs by either\nselecting sentences from a corpus or synthetically optimizing sentence pairs to\nbe highly controversial. Human subjects then provided judgments indicating for\neach pair which of the two sentences is more likely. Controversial sentence\npairs proved highly effective at revealing model failures and identifying\nmodels that aligned most closely with human judgments. The most\nhuman-consistent model tested was GPT-2, although experiments also revealed\nsignificant shortcomings of its alignment with human perception.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Golan_T/0/1/0/all/0/1\">Tal Golan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siegelman_M/0/1/0/all/0/1\">Matthew Siegelman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kriegeskorte_N/0/1/0/all/0/1\">Nikolaus Kriegeskorte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldassano_C/0/1/0/all/0/1\">Christopher Baldassano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeepStruct: Pretraining of Language Models for Structure Prediction. (arXiv:2205.10475v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.10475","description":"<p>We introduce a method for improving the structural understanding abilities of\nlanguage models. Unlike previous approaches that finetune the models with\ntask-specific augmentation, we pretrain language models on a collection of\ntask-agnostic corpora to generate structures from text. Our structure\npretraining enables zero-shot transfer of the learned knowledge that models\nhave about the structure tasks. We study the performance of this approach on 28\ndatasets, spanning 10 structure prediction tasks including open information\nextraction, joint entity and relation extraction, named entity recognition,\nrelation classification, semantic role labeling, event extraction, coreference\nresolution, factual probe, intent detection, and dialogue state tracking. We\nfurther enhance the pretraining with the task-specific training sets. We show\nthat a 10B parameter language model transfers non-trivially to most tasks and\nobtains state-of-the-art performance on 21 of 28 datasets that we evaluate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1\">Haoyun Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TalkToModel: Explaining Machine Learning Models with Interactive Natural Language Conversations. (arXiv:2207.04154v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2207.04154","description":"<p>Machine Learning (ML) models are increasingly used to make critical decisions\nin real-world applications, yet they have become more complex, making them\nharder to understand. To this end, researchers have proposed several techniques\nto explain model predictions. However, practitioners struggle to use these\nexplainability techniques because they often do not know which one to choose\nand how to interpret the results of the explanations. In this work, we address\nthese challenges by introducing TalkToModel: an interactive dialogue system for\nexplaining machine learning models through conversations. Specifically,\nTalkToModel comprises of three key components: 1) a natural language interface\nfor engaging in conversations, making ML model explainability highly\naccessible, 2) a dialogue engine that adapts to any tabular model and dataset,\ninterprets natural language, maps it to appropriate explanations, and generates\ntext responses, and 3) an execution component that constructs the explanations.\nWe carried out extensive quantitative and human subject evaluations of\nTalkToModel. Overall, we found the conversational system understands user\ninputs on novel datasets and models with high accuracy, demonstrating the\nsystem's capacity to generalize to new situations. In real-world evaluations\nwith humans, 73% of healthcare workers (e.g., doctors and nurses) agreed they\nwould use TalkToModel over baseline point-and-click systems for explainability\nin a disease prediction task, and 85% of ML professionals agreed TalkToModel\nwas easier to use for computing explanations. Our findings demonstrate that\nTalkToModel is more effective for model explainability than existing systems,\nintroducing a new category of explainability tools for practitioners. Code &amp;\ndemo released here: https://github.com/dylan-slack/TalkToModel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Looking for a Needle in a Haystack: A Comprehensive Study of Hallucinations in Neural Machine Translation. (arXiv:2208.05309v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.05309","description":"<p>Although the problem of hallucinations in neural machine translation (NMT)\nhas received some attention, research on this highly pathological phenomenon\nlacks solid ground. Previous work has been limited in several ways: it often\nresorts to artificial settings where the problem is amplified, it disregards\nsome (common) types of hallucinations, and it does not validate adequacy of\ndetection heuristics. In this paper, we set foundations for the study of NMT\nhallucinations. First, we work in a natural setting, i.e., in-domain data\nwithout artificial noise neither in training nor in inference. Next, we\nannotate a dataset of over 3.4k sentences indicating different kinds of\ncritical errors and hallucinations. Then, we turn to detection methods and both\nrevisit methods used previously and propose using glass-box uncertainty-based\ndetectors. Overall, we show that for preventive settings, (i) previously used\nmethods are largely inadequate, (ii) sequence log-probability works best and\nperforms on par with reference-based methods. Finally, we propose\nDeHallucinator, a simple method for alleviating hallucinations at test time\nthat significantly reduces the hallucinatory rate. To ease future research, we\nrelease our annotated dataset for WMT18 German-English data, along with the\nmodel, training data, and code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guerreiro_N/0/1/0/all/0/1\">Nuno M. Guerreiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voita_E/0/1/0/all/0/1\">Elena Voita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F.T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AudioGen: Textually Guided Audio Generation. (arXiv:2209.15352v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2209.15352","description":"<p>We tackle the problem of generating audio samples conditioned on descriptive\ntext captions. In this work, we propose AaudioGen, an auto-regressive\ngenerative model that generates audio samples conditioned on text inputs.\nAudioGen operates on a learnt discrete audio representation. The task of\ntext-to-audio generation poses multiple challenges. Due to the way audio\ntravels through a medium, differentiating ``objects'' can be a difficult task\n(e.g., separating multiple people simultaneously speaking). This is further\ncomplicated by real-world recording conditions (e.g., background noise,\nreverberation, etc.). Scarce text annotations impose another constraint,\nlimiting the ability to scale models. Finally, modeling high-fidelity audio\nrequires encoding audio at high sampling rate, leading to extremely long\nsequences. To alleviate the aforementioned challenges we propose an\naugmentation technique that mixes different audio samples, driving the model to\ninternally learn to separate multiple sources. We curated 10 datasets\ncontaining different types of audio and text annotations to handle the scarcity\nof text-audio data points. For faster inference, we explore the use of\nmulti-stream modeling, allowing the use of shorter sequences while maintaining\na similar bitrate and perceptual quality. We apply classifier-free guidance to\nimprove adherence to text. Comparing to the evaluated baselines, AudioGen\noutperforms over both objective and subjective metrics. Finally, we explore the\nability of the proposed method to generate audio continuation conditionally and\nunconditionally. Samples: https://felixkreuk.github.io/audiogen\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kreuk_F/0/1/0/all/0/1\">Felix Kreuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polyak_A/0/1/0/all/0/1\">Adam Polyak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singer_U/0/1/0/all/0/1\">Uriel Singer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Defossez_A/0/1/0/all/0/1\">Alexandre D&#xe9;fossez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1\">Jade Copet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1\">Devi Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taigman_Y/0/1/0/all/0/1\">Yaniv Taigman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transparency Helps Reveal When Language Models Learn Meaning. (arXiv:2210.07468v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07468","description":"<p>Many current NLP systems are built from language models trained to optimize\nunsupervised objectives on large amounts of raw text. Under what conditions\nmight such a procedure acquire meaning? Our systematic experiments with\nsynthetic data reveal that, with languages where all expressions have\ncontext-independent denotations (i.e., languages with strong transparency),\nboth autoregressive and masked language models successfully learn to emulate\nsemantic relations between expressions. However, when denotations are changed\nto be context-dependent with the language otherwise unmodified, this ability\ndegrades. Turning to natural language, our experiments with a specific\nphenomenon -- referential opacity -- add to the growing body of evidence that\ncurrent language models do not represent natural language semantics well. We\nshow this failure relates to the context-dependent nature of natural language\nform-meaning mappings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaofeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Neural Network Model for Readability Assessment with Feature Projection and Length-Balanced Loss. (arXiv:2210.10305v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10305","description":"<p>For readability assessment, traditional methods mainly employ machine\nlearning classifiers with hundreds of linguistic features. Although the deep\nlearning model has become the prominent approach for almost all NLP tasks, it\nis less explored for readability assessment. In this paper, we propose a\nBERT-based model with feature projection and length-balanced loss (BERT-FP-LBL)\nfor readability assessment. Specially, we present a new difficulty knowledge\nguided semi-supervised method to extract topic features to complement the\ntraditional linguistic features. From the linguistic features, we employ\nprojection filtering to extract orthogonal features to supplement BERT\nrepresentations. Furthermore, we design a new length-balanced loss to handle\nthe greatly varying length distribution of data. Our model achieves\nstate-of-the-art performances on two English benchmark datasets and one dataset\nof Chinese textbooks, and also achieves the near-perfect accuracy of 99\\% on\none English dataset. Moreover, our proposed model obtains comparable results\nwith human experts in consistency test.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yunfang Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"E2E Segmentation in a Two-Pass Cascaded Encoder ASR Model. (arXiv:2211.15432v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.15432","description":"<p>We explore unifying a neural segmenter with two-pass cascaded encoder ASR\ninto a single model. A key challenge is allowing the segmenter (which runs in\nreal-time, synchronously with the decoder) to finalize the 2nd pass (which runs\n900 ms behind real-time) without introducing user-perceived latency or deletion\nerrors during inference. We propose a design where the neural segmenter is\nintegrated with the causal 1st pass decoder to emit a end-of-segment (EOS)\nsignal in real-time. The EOS signal is then used to finalize the non-causal 2nd\npass. We experiment with different ways to finalize the 2nd pass, and find that\na novel dummy frame injection strategy allows for simultaneous high quality 2nd\npass results and low finalization latency. On a real-world long-form captioning\ntask (YouTube), we achieve 2.4% relative WER and 140 ms EOS latency gains over\na baseline VAD-based segmenter with the same cascaded encoder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">W. Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shuo-Yiin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yanzhang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rybach_D/0/1/0/all/0/1\">David Rybach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_R/0/1/0/all/0/1\">Robert David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1\">Rohit Prabhavalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allauzen_C/0/1/0/all/0/1\">Cyril Allauzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyser_C/0/1/0/all/0/1\">Cal Peyser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor D. Strohman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain of Hindsight Aligns Language Models with Feedback. (arXiv:2302.02676v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.02676","description":"<p>Learning from human preferences is important for language models to be\nhelpful and useful for humans, and to align with human and social values. Prior\nwork have achieved remarkable successes by learning from human feedback to\nunderstand and follow instructions. Nonetheless, these methods are either\nfounded on hand-picked model generations that are favored by human annotators,\nrendering them ineffective in terms of data utilization and challenging to\napply in general, or they depend on reward functions and reinforcement\nlearning, which are prone to imperfect reward function and extremely\nchallenging to optimize. In this work, we propose a novel technique, Chain of\nHindsight, that is easy to optimize and can learn from any form of feedback,\nregardless of its polarity. Our idea is inspired by how humans learn from\nextensive feedback presented in the form of languages. We convert all types of\nfeedback into sentences, which are then used to fine-tune the model, allowing\nus to take advantage of the language comprehension capabilities of language\nmodels. We condition the model on a sequence of model generations paired with\nfeedback. By doing so, models are trained to generate outputs based on\nfeedback, and models can learn to identify and correct negative attributes or\nerrors. Applying our method to large language models, we observed that Chain of\nHindsight significantly surpasses previous methods in aligning language models\nwith human preferences. We observed significant improvements on summarization\nand dialogue tasks and our approach is markedly preferred in human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sferrazza_C/0/1/0/all/0/1\">Carmelo Sferrazza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Categorical Archive of ChatGPT Failures. (arXiv:2302.03494v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03494","description":"<p>Large language models have been demonstrated to be valuable in different\nfields. ChatGPT, developed by OpenAI, has been trained using massive amounts of\ndata and simulates human conversation by comprehending context and generating\nappropriate responses. It has garnered significant attention due to its ability\nto effectively answer a broad range of human inquiries, with fluent and\ncomprehensive answers surpassing prior public chatbots in both security and\nusefulness. However, a comprehensive analysis of ChatGPT's failures is lacking,\nwhich is the focus of this study. Eleven categories of failures, including\nreasoning, factual errors, math, coding, and bias, are presented and discussed.\nThe risks, limitations, and societal implications of ChatGPT are also\nhighlighted. The goal of this study is to assist researchers and developers in\nenhancing future language models and chatbots.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Borji_A/0/1/0/all/0/1\">Ali Borji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Compositional Exemplars for In-context Learning. (arXiv:2302.05698v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.05698","description":"<p>Large pretrained language models (LMs) have shown impressive In-Context\nLearning (ICL) ability, where the model learns to do an unseen task via a\nprompt consisting of input-output examples as the demonstration, without any\nparameter updates. The performance of ICL is highly dominated by the quality of\nthe selected in-context examples. However, previous selection methods are\nmostly based on simple heuristics, leading to sub-optimal performance. In this\nwork, we formulate in-context example selection as a subset selection problem.\nWe propose CEIL (Compositional Exemplars for In-context Learning), which is\ninstantiated by Determinantal Point Processes (DPPs) to model the interaction\nbetween the given input and in-context examples, and optimized through a\ncarefully-designed contrastive learning objective to obtain preference from\nLMs. We validate CEIL on 12 classification and generation datasets from 7\ndistinct NLP tasks, including sentiment analysis, paraphrase detection, natural\nlanguage inference, commonsense reasoning, open-domain question answering, code\ngeneration, and semantic parsing. Extensive experiments demonstrate not only\nthe state-of-the-art performance but also the transferability and\ncompositionality of CEIL, shedding new light on effective and efficient\nin-context learning. Our code is released at\nhttps://github.com/HKUNLP/icl-ceil.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiacheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Sidecar Separator Can Convert a Single-Talker Speech Recognition System to a Multi-Talker One. (arXiv:2302.09908v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2302.09908","description":"<p>Although automatic speech recognition (ASR) can perform well in common\nnon-overlapping environments, sustaining performance in multi-talker\noverlapping speech recognition remains challenging. Recent research revealed\nthat ASR model's encoder captures different levels of information with\ndifferent layers -- the lower layers tend to have more acoustic information,\nand the upper layers more linguistic. This inspires us to develop a Sidecar\nseparator to empower a well-trained ASR model for multi-talker scenarios by\nseparating the mixed speech embedding between two suitable layers. We\nexperimented with a wav2vec 2.0-based ASR model with a Sidecar mounted. By\nfreezing the parameters of the original model and training only the Sidecar\n(8.7 M, 8.4% of all parameters), the proposed approach outperforms the previous\nstate-of-the-art by a large margin for the 2-speaker mixed LibriMix dataset,\nreaching a word error rate (WER) of 10.36%; and obtains comparable results\n(7.56%) for LibriSpeechMix dataset when limited training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Lingwei Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jiawen Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1\">Mingyu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuejiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xixin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Deep Semantics for Test Completion. (arXiv:2302.10166v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2302.10166","description":"<p>Writing tests is a time-consuming yet essential task during software\ndevelopment. We propose to leverage recent advances in deep learning for text\nand code generation to assist developers in writing tests. We formalize the\nnovel task of test completion to automatically complete the next statement in a\ntest method based on the context of prior statements and the code under test.\nWe develop TeCo -- a deep learning model using code semantics for test\ncompletion. The key insight underlying TeCo is that predicting the next\nstatement in a test method requires reasoning about code execution, which is\nhard to do with only syntax-level data that existing code completion models\nuse. TeCo extracts and uses six kinds of code semantics data, including the\nexecution result of prior statements and the execution context of the test\nmethod. To provide a testbed for this new task, as well as to evaluate TeCo, we\ncollect a corpus of 130,934 test methods from 1,270 open-source Java projects.\nOur results show that TeCo achieves an exact-match accuracy of 18, which is 29%\nhigher than the best baseline using syntax-level data only. When measuring\nfunctional correctness of generated next statement, TeCo can generate runnable\ncode in 29% of the cases compared to 18% obtained by the best baseline.\nMoreover, TeCo is significantly better than prior work on test oracle\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nie_P/0/1/0/all/0/1\">Pengyu Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_R/0/1/0/all/0/1\">Rahul Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond J. Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gligoric_M/0/1/0/all/0/1\">Milos Gligoric</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hyena Hierarchy: Towards Larger Convolutional Language Models. (arXiv:2302.10866v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.10866","description":"<p>Recent advances in deep learning have relied heavily on the use of large\nTransformers due to their ability to learn at scale. However, the core building\nblock of Transformers, the attention operator, exhibits quadratic cost in\nsequence length, limiting the amount of context accessible. Existing\nsubquadratic methods based on low-rank and sparse approximations need to be\ncombined with dense attention layers to match Transformers, indicating a gap in\ncapability. In this work, we propose Hyena, a subquadratic drop-in replacement\nfor attention constructed by interleaving implicitly parametrized long\nconvolutions and data-controlled gating. In recall and reasoning tasks on\nsequences of thousands to hundreds of thousands of tokens, Hyena improves\naccuracy by more than 50 points over operators relying on state-spaces and\nother implicit and explicit methods, matching attention-based models. We set a\nnew state-of-the-art for dense-attention-free architectures on language\nmodeling in standard datasets (WikiText103 and The Pile), reaching Transformer\nquality with a 20% reduction in training compute required at sequence length\n2K. Hyena operators are twice as fast as highly optimized attention at sequence\nlength 8K, and 100x faster at sequence length 64K.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Poli_M/0/1/0/all/0/1\">Michael Poli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massaroli_S/0/1/0/all/0/1\">Stefano Massaroli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_E/0/1/0/all/0/1\">Eric Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daniel Y. Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dao_T/0/1/0/all/0/1\">Tri Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baccus_S/0/1/0/all/0/1\">Stephen Baccus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancements in Federated Learning: Models, Methods, and Privacy. (arXiv:2302.11466v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2302.11466","description":"<p>Federated learning (FL) is a promising technique for addressing the rising\nprivacy and security issues. Its main ingredient is to cooperatively learn the\nmodel among the distributed clients without uploading any sensitive data. In\nthis paper, we conducted a thorough review of the related works, following the\ndevelopment context and deeply mining the key technologies behind FL from both\ntheoretical and practical perspectives. Specifically, we first classify the\nexisting works in FL architecture based on the network topology of FL systems\nwith detailed analysis and summarization. Next, we abstract the current\napplication problems, summarize the general techniques and frame the\napplication problems into the general paradigm of FL base models. Moreover, we\nprovide our proposed solutions for model training via FL. We have summarized\nand analyzed the existing FedOpt algorithms, and deeply revealed the\nalgorithmic development principles of many first-order algorithms in depth,\nproposing a more generalized algorithm design framework. Based on these\nframeworks, we have instantiated FedOpt algorithms. As privacy and security is\nthe fundamental requirement in FL, we provide the existing attack scenarios and\nthe defense methods. To the best of our knowledge, we are among the first tier\nto review the theoretical methodology and propose our strategies since there\nare very few works surveying the theoretical approaches. Our survey targets\nmotivating the development of high-performance, privacy-preserving, and secure\nmethods to integrate FL into real-world applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huiming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huandong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Q/0/1/0/all/0/1\">Qingyue Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Depeng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ancient Chinese Word Segmentation and Part-of-Speech Tagging Using Distant Supervision. (arXiv:2303.01912v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.01912","description":"<p>Ancient Chinese word segmentation (WSG) and part-of-speech tagging (POS) are\nimportant to study ancient Chinese, but the amount of ancient Chinese WSG and\nPOS tagging data is still rare. In this paper, we propose a novel augmentation\nmethod of ancient Chinese WSG and POS tagging data using distant supervision\nover parallel corpus. However, there are still mislabeled and unlabeled ancient\nChinese words inevitably in distant supervision. To address this problem, we\ntake advantage of the memorization effects of deep neural networks and a small\namount of annotated data to get a model with much knowledge and a little noise,\nand then we use this model to relabel the ancient Chinese sentences in parallel\ncorpus. Experiments show that the model trained over the relabeled data\noutperforms the model trained over the data generated from distant supervision\nand the annotated data. Our code is available at\nhttps://github.com/farlit/ACDS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shuo Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Piji Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-03-06T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}