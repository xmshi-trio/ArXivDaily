{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-02-17T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Meeting the Needs of Low-Resource Languages: The Value of Automatic Alignments via Pretrained Models. (arXiv:2302.07912v1 [cs.CL])","link":"http://arxiv.org/abs/2302.07912","description":"<p>Large multilingual models have inspired a new class of word alignment\nmethods, which work well for the model's pretraining languages. However, the\nlanguages most in need of automatic alignment are low-resource and, thus, not\ntypically included in the pretraining data. In this work, we ask: How do modern\naligners perform on unseen languages, and are they better than traditional\nmethods? We contribute gold-standard alignments for Bribri--Spanish,\nGuarani--Spanish, Quechua--Spanish, and Shipibo-Konibo--Spanish. With these, we\nevaluate state-of-the-art aligners with and without model adaptation to the\ntarget language. Finally, we also evaluate the resulting alignments\nextrinsically through two downstream tasks: named entity recognition and\npart-of-speech tagging. We find that although transformer-based methods\ngenerally outperform traditional models, the two classes of approach remain\ncompetitive with each other.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_A/0/1/0/all/0/1\">Abteen Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCarthy_A/0/1/0/all/0/1\">Arya D. McCarthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oncevay_A/0/1/0/all/0/1\">Arturo Oncevay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiruzzo_L/0/1/0/all/0/1\">Luis Chiruzzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortega_J/0/1/0/all/0/1\">John E. Ortega</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimenez_Lugo_G/0/1/0/all/0/1\">Gustavo A. Gim&#xe9;nez-Lugo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coto_Solano_R/0/1/0/all/0/1\">Rolando Coto-Solano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Commonsense Reasoning for Conversational AI: A Survey of the State of the Art. (arXiv:2302.07926v1 [cs.CL])","link":"http://arxiv.org/abs/2302.07926","description":"<p>Large, transformer-based pretrained language models like BERT, GPT, and T5\nhave demonstrated a deep understanding of contextual semantics and language\nsyntax. Their success has enabled significant advances in conversational AI,\nincluding the development of open-dialogue systems capable of coherent, salient\nconversations which can answer questions, chat casually, and complete tasks.\nHowever, state-of-the-art models still struggle with tasks that involve higher\nlevels of reasoning - including commonsense reasoning that humans find trivial.\nThis paper presents a survey of recent conversational AI research focused on\ncommonsense reasoning. The paper lists relevant training datasets and describes\nthe primary approaches to include commonsense in conversational AI. The paper\nalso discusses benchmarks used for evaluating commonsense in conversational AI\nproblems. Finally, the paper presents preliminary observations of the limited\ncommonsense capabilities of two state-of-the-art open dialogue models,\nBlenderBot3 and LaMDA, and its negative effect on natural interactions. These\nobservations further motivate research on commonsense reasoning in\nconversational AI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Richardson_C/0/1/0/all/0/1\">Christopher Richardson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heck_L/0/1/0/all/0/1\">Larry Heck</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tree-Based Representation and Generation of Natural and Mathematical Language. (arXiv:2302.07974v1 [cs.CL])","link":"http://arxiv.org/abs/2302.07974","description":"<p>Mathematical language in scientific communications and educational scenarios\nis important yet relatively understudied compared to natural languages. Recent\nworks on mathematical language focus either on representing stand-alone\nmathematical expressions, especially in their natural tree format, or\nmathematical reasoning in pre-trained natural language models. Existing works\non jointly modeling and generating natural and mathematical languages simply\ntreat mathematical expressions as text, without accounting for the rigid\nstructural properties of mathematical expressions. In this paper, we propose a\nseries of modifications to existing language models to jointly represent and\ngenerate text and math: representing mathematical expressions as sequences of\nnode tokens in their operator tree format, using math symbol and tree position\nembeddings to preserve the semantic and structural properties of mathematical\nexpressions, and using a constrained decoding method to generate mathematically\nvalid expressions. We ground our modifications in GPT-2, resulting in a model\nMathGPT, and demonstrate that it outperforms baselines on mathematical\nexpression generation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scarlatos_A/0/1/0/all/0/1\">Alexander Scarlatos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_A/0/1/0/all/0/1\">Andrew Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\\`A-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable Prompting. (arXiv:2302.07994v1 [cs.LG])","link":"http://arxiv.org/abs/2302.07994","description":"<p>We introduce \\`A-la-carte Prompt Tuning (APT), a transformer-based scheme to\ntune prompts on distinct data so that they can be arbitrarily composed at\ninference time. The individual prompts can be trained in isolation, possibly on\ndifferent devices, at different times, and on different distributions or\ndomains. Furthermore each prompt only contains information about the subset of\ndata it was exposed to during training. During inference, models can be\nassembled based on arbitrary selections of data sources, which we call\n\"\\`a-la-carte learning\". \\`A-la-carte learning enables constructing bespoke\nmodels specific to each user's individual access rights and preferences. We can\nadd or remove information from the model by simply adding or removing the\ncorresponding prompts without retraining from scratch. We demonstrate that\n\\`a-la-carte built models achieve accuracy within $5\\%$ of models trained on\nthe union of the respective sources, with comparable cost in terms of training\nand inference time. For the continual learning benchmarks Split CIFAR-100 and\nCORe50, we achieve state-of-the-art performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bowman_B/0/1/0/all/0/1\">Benjamin Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_A/0/1/0/all/0/1\">Alessandro Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zancato_L/0/1/0/all/0/1\">Luca Zancato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trager_M/0/1/0/all/0/1\">Matthew Trager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perera_P/0/1/0/all/0/1\">Pramuditha Perera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paolini_G/0/1/0/all/0/1\">Giovanni Paolini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1\">Stefano Soatto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks. (arXiv:2302.08043v1 [cs.LG])","link":"http://arxiv.org/abs/2302.08043","description":"<p>Graphs can model complex relationships between objects, enabling a myriad of\nWeb applications such as online page/article classification and social\nrecommendation. While graph neural networks(GNNs) have emerged as a powerful\ntool for graph representation learning, in an end-to-end supervised setting,\ntheir performance heavily rely on a large amount of task-specific supervision.\nTo reduce labeling requirement, the \"pre-train, fine-tune\" and \"pre-train,\nprompt\" paradigms have become increasingly common. In particular, prompting is\na popular alternative to fine-tuning in natural language processing, which is\ndesigned to narrow the gap between pre-training and downstream objectives in a\ntask-specific manner. However, existing study of prompting on graphs is still\nlimited, lacking a universal treatment to appeal to different downstream tasks.\nIn this paper, we propose GraphPrompt, a novel pre-training and prompting\nframework on graphs. GraphPrompt not only unifies pre-training and downstream\ntasks into a common task template, but also employs a learnable prompt to\nassist a downstream task in locating the most relevant knowledge from the\npre-train model in a task-specific manner. Finally, we conduct extensive\nexperiments on five public datasets to evaluate and analyze GraphPrompt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zemin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xingtong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinming Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LabelPrompt: Effective Prompt-based Learning for Relation Classification. (arXiv:2302.08068v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08068","description":"<p>Recently, prompt-based learning has become a very popular solution in many\nNatural Language Processing (NLP) tasks by inserting a template into model\ninput, which converts the task into a cloze-style one to smoothing out\ndifferences between the Pre-trained Language Model (PLM) and the current task.\nBut in the case of relation classification, it is difficult to map the masked\noutput to the relation labels because of its abundant semantic information,\ne.g. org:founded_by''. Therefore, a pre-trained model still needs enough\nlabelled data to fit the relations. To mitigate this challenge, in this paper,\nwe present a novel prompt-based learning method, namely LabelPrompt, for the\nrelation classification task. It is an extraordinary intuitive approach by a\nmotivation: ``GIVE MODEL CHOICES!''. First, we define some additional tokens to\nrepresent the relation labels, which regards these tokens as the verbalizer\nwith semantic initialisation and constructs them with a prompt template method.\nThen we revisit the inconsistency of the predicted relation and the given\nentities, an entity-aware module with the thought of contrastive learning is\ndesigned to mitigate the problem. At last, we apply an attention query strategy\nto self-attention layers to resolve two types of tokens, prompt tokens and\nsequence tokens. The proposed strategy effectively improves the adaptation\ncapability of prompt-based learning in the relation classification task when\nonly a small labelled data is available. Extensive experimental results\nobtained on several bench-marking datasets demonstrate the superiority of the\nproposed LabelPrompt method, particularly in the few-shot scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaoning Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhenhua Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tianyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaojun Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document Flattening: Beyond Concatenating Context for Document-Level Neural Machine Translation. (arXiv:2302.08079v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08079","description":"<p>Existing work in document-level neural machine translation commonly\nconcatenates several consecutive sentences as a pseudo-document, and then\nlearns inter-sentential dependencies. This strategy limits the model's ability\nto leverage information from distant context. We overcome this limitation with\na novel Document Flattening (DocFlat) technique that integrates Flat-Batch\nAttention (FBA) and Neural Context Gate (NCG) into Transformer model to utilize\ninformation beyond the pseudo-document boundaries. FBA allows the model to\nattend to all the positions in the batch and learns the relationships between\npositions explicitly and NCG identifies the useful information from the distant\ncontext. We conduct comprehensive experiments and analyses on three benchmark\ndatasets for English-German translation, and validate the effectiveness of two\nvariants of DocFlat. Empirical results show that our approach outperforms\nstrong baselines with statistical significance on BLEU, COMET and accuracy on\nthe contrastive test set. The analyses highlight that DocFlat is highly\neffective in capturing the long-range information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Minghao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_G/0/1/0/all/0/1\">George Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lizhen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Limits of ChatGPT for Query or Aspect-based Text Summarization. (arXiv:2302.08081v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08081","description":"<p>Text summarization has been a crucial problem in natural language processing\n(NLP) for several decades. It aims to condense lengthy documents into shorter\nversions while retaining the most critical information. Various methods have\nbeen proposed for text summarization, including extractive and abstractive\nsummarization. The emergence of large language models (LLMs) like GPT3 and\nChatGPT has recently created significant interest in using these models for\ntext summarization tasks. Recent studies \\cite{goyal2022news,\nzhang2023benchmarking} have shown that LLMs-generated news summaries are\nalready on par with humans. However, the performance of LLMs for more practical\napplications like aspect or query-based summaries is underexplored. To fill\nthis gap, we conducted an evaluation of ChatGPT's performance on four widely\nused benchmark datasets, encompassing diverse summaries from Reddit posts, news\narticles, dialogue meetings, and stories. Our experiments reveal that ChatGPT's\nperformance is comparable to traditional fine-tuning methods in terms of Rouge\nscores. Moreover, we highlight some unique differences between\nChatGPT-generated summaries and human references, providing valuable insights\ninto the superpower of ChatGPT for diverse text summarization tasks. Our\nfindings call for new directions in this area, and we plan to conduct further\nresearch to systematically examine the characteristics of ChatGPT-generated\nsummaries through extensive human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinlu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Multi-Object Positional Relationships via Emergent Communication. (arXiv:2302.08084v1 [cs.LG])","link":"http://arxiv.org/abs/2302.08084","description":"<p>The study of emergent communication has been dedicated to interactive\nartificial intelligence. While existing work focuses on communication about\nsingle objects or complex image scenes, we argue that communicating\nrelationships between multiple objects is important in more realistic tasks,\nbut understudied. In this paper, we try to fill this gap and focus on emergent\ncommunication about positional relationships between two objects. We train\nagents in the referential game where observations contain two objects, and find\nthat generalization is the major problem when the positional relationship is\ninvolved. The key factor affecting the generalization ability of the emergent\nlanguage is the input variation between Speaker and Listener, which is realized\nby a random image generator in our work. Further, we find that the learned\nlanguage can generalize well in a new multi-step MDP task where the positional\nrelationship describes the goal, and performs better than raw-pixel images as\nwell as pre-trained image features, verifying the strong generalization ability\nof discrete sequences. We also show that language transfer from the referential\ngame performs better in the new task than learning language directly in this\ntask, implying the potential benefits of pre-training in referential games. All\nin all, our experiments demonstrate the viability and merit of having agents\nlearn to communicate positional relationships between multiple objects through\nemergent communication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yicheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Boshi An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zongqing Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement. (arXiv:2302.08088v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08088","description":"<p>Speech enhancement models have greatly progressed in recent years, but still\nshow limits in perceptual quality of their speech outputs. We propose an\nobjective for perceptual quality based on temporal acoustic parameters. These\nare fundamental speech features that play an essential role in various\napplications, including speaker recognition and paralinguistic analysis. We\nprovide a differentiable estimator for four categories of low-level acoustic\ndescriptors involving: frequency-related parameters, energy or\namplitude-related parameters, spectral balance parameters, and temporal\nfeatures. Unlike prior work that looks at aggregated acoustic parameters or a\nfew categories of acoustic parameters, our temporal acoustic parameter (TAP)\nloss enables auxiliary optimization and improvement of many fine-grain speech\ncharacteristics in enhancement workflows. We show that adding TAPLoss as an\nauxiliary objective in speech enhancement produces speech with improved\nperceptual quality and intelligibility. We use data from the Deep Noise\nSuppression 2020 Challenge to demonstrate that both time-domain models and\ntime-frequency domain models can benefit from our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yunyang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konan_J/0/1/0/all/0/1\">Joseph Konan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shuo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bick_D/0/1/0/all/0/1\">David Bick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anurag Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do We Still Need Clinical Language Models?. (arXiv:2302.08091v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08091","description":"<p>Although recent advances in scaling large language models (LLMs) have\nresulted in improvements on many NLP tasks, it remains unclear whether these\nmodels trained primarily with general web text are the right tool in highly\nspecialized, safety critical domains such as clinical text. Recent results have\nsuggested that LLMs encode a surprising amount of medical knowledge. This\nraises an important question regarding the utility of smaller domain-specific\nlanguage models. With the success of general-domain LLMs, is there still a need\nfor specialized clinical models? To investigate this question, we conduct an\nextensive empirical analysis of 12 language models, ranging from 220M to 175B\nparameters, measuring their performance on 3 different clinical tasks that test\ntheir ability to parse and reason over electronic health records. As part of\nour experiments, we train T5-Base and T5-Large models from scratch on clinical\nnotes from MIMIC III and IV to directly investigate the efficiency of clinical\ntokens. We show that relatively small specialized clinical models substantially\noutperform all in-context learning approaches, even when finetuned on limited\nannotated data. Further, we find that pretraining on clinical tokens allows for\nsmaller, more parameter-efficient models that either match or outperform much\nlarger language models trained on general text. We release the code and the\nmodels used under the PhysioNet Credentialed Health Data license and data use\nagreement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lehman_E/0/1/0/all/0/1\">Eric Lehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_E/0/1/0/all/0/1\">Evan Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1\">Diwakar Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1\">Jonas Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Micah J. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziegler_Z/0/1/0/all/0/1\">Zachary Ziegler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadler_D/0/1/0/all/0/1\">Daniel Nadler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szolovits_P/0/1/0/all/0/1\">Peter Szolovits</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_A/0/1/0/all/0/1\">Alistair Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alsentzer_E/0/1/0/all/0/1\">Emily Alsentzer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Product Question Answering in E-Commerce: A Survey. (arXiv:2302.08092v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08092","description":"<p>Product question answering (PQA), aiming to automatically provide instant\nresponses to customer's questions in E-Commerce platforms, has drawn increasing\nattention in recent years. Compared with typical QA problems, PQA exhibits\nunique challenges such as the subjectivity and reliability of user-generated\ncontents in E-commerce platforms. Therefore, various problem settings and novel\nmethods have been proposed to capture these special characteristics. In this\npaper, we aim to systematically review existing research efforts on PQA.\nSpecifically, we categorize PQA studies into four problem settings in terms of\nthe form of provided answers. We analyze the pros and cons, as well as present\nexisting datasets and evaluation protocols for each setting. We further\nsummarize the most significant challenges that characterize PQA from general QA\napplications and discuss their corresponding solutions. Finally, we conclude\nthis paper by providing the prospect on several future directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PAAPLoss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement. (arXiv:2302.08095v1 [cs.SD])","link":"http://arxiv.org/abs/2302.08095","description":"<p>Despite rapid advancement in recent years, current speech enhancement models\noften produce speech that differs in perceptual quality from real clean speech.\nWe propose a learning objective that formalizes differences in perceptual\nquality, by using domain knowledge of acoustic-phonetics. We identify temporal\nacoustic parameters -- such as spectral tilt, spectral flux, shimmer, etc. --\nthat are non-differentiable, and we develop a neural network estimator that can\naccurately predict their time-series values across an utterance. We also model\nphoneme-specific weights for each feature, as the acoustic parameters are known\nto show different behavior in different phonemes. We can add this criterion as\nan auxiliary loss to any model that produces speech, to optimize speech outputs\nto match the values of clean speech in these features. Experimentally we show\nthat it improves speech enhancement workflows in both time-domain and\ntime-frequency domain, as measured by standard evaluation metrics. We also\nprovide an analysis of phoneme-dependent improvement on acoustic parameters,\ndemonstrating the additional interpretability that our method provides. This\nanalysis can suggest which features are currently the bottleneck for\nimprovement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konan_J/0/1/0/all/0/1\">Joseph Konan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bick_D/0/1/0/all/0/1\">David Bick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yunyang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shuo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anurag Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt Tuning of Deep Neural Networks for Speaker-adaptive Visual Speech Recognition. (arXiv:2302.08102v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08102","description":"<p>Visual Speech Recognition (VSR) aims to infer speech into text depending on\nlip movements alone. As it focuses on visual information to model the speech,\nits performance is inherently sensitive to personal lip appearances and\nmovements, and this makes the VSR models show degraded performance when they\nare applied to unseen speakers. In this paper, to remedy the performance\ndegradation of the VSR model on unseen speakers, we propose prompt tuning\nmethods of Deep Neural Networks (DNNs) for speaker-adaptive VSR. Specifically,\nmotivated by recent advances in Natural Language Processing (NLP), we finetune\nprompts on adaptation data of target speakers instead of modifying the\npre-trained model parameters. Different from the previous prompt tuning methods\nmainly limited to Transformer variant architecture, we explore different types\nof prompts, the addition, the padding, and the concatenation form prompts that\ncan be applied to the VSR model which is composed of CNN and Transformer in\ngeneral. With the proposed prompt tuning, we show that the performance of the\npre-trained VSR model on unseen speakers can be largely improved by using a\nsmall amount of adaptation data (e.g., less than 5 minutes), even if the\npre-trained model is already developed with large speaker variations. Moreover,\nby analyzing the performance and parameters of different types of prompts, we\ninvestigate when the prompt tuning is preferred over the finetuning methods.\nThe effectiveness of the proposed method is evaluated on both word- and\nsentence-level VSR databases, LRW-ID and GRID.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyung-Il Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ro_Y/0/1/0/all/0/1\">Yong Man Ro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?. (arXiv:2302.08143v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08143","description":"<p>Prompt tuning (PT) which only tunes the embeddings of an additional sequence\nof tokens per task, keeping the pre-trained language model (PLM) frozen, has\nshown remarkable performance in few-shot learning. Despite this, PT has been\nshown to rely heavily on good initialization of the prompt embeddings. In this\nwork, we study meta prompt tuning (MPT) to systematically explore how\nmeta-learning can help improve (if it can) cross-task generalization in PT\nthrough learning to initialize the prompt embeddings from other relevant tasks.\nWe empirically analyze a representative set of meta learning algorithms in a\nwide range of adaptation settings with different source/target task\nconfigurations on a large set of few-shot tasks. With extensive experiments and\nanalysis, we demonstrate the effectiveness of MPT. We find the improvement to\nbe significant particularly on classification tasks. For other kinds of tasks\nsuch as question answering, we observe that while MPT can outperform PT in most\ncases, it does not always outperform multi-task learning. We further provide an\nin-depth analysis from the perspective of task similarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruochen Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CluCDD:Contrastive Dialogue Disentanglement via Clustering. (arXiv:2302.08146v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08146","description":"<p>A huge number of multi-participant dialogues happen online every day, which\nleads to difficulty in understanding the nature of dialogue dynamics for both\nhumans and machines. Dialogue disentanglement aims at separating an entangled\ndialogue into detached sessions, thus increasing the readability of long\ndisordered dialogue. Previous studies mainly focus on message-pair\nclassification and clustering in two-step methods, which cannot guarantee the\nwhole clustering performance in a dialogue. To address this challenge, we\npropose a simple yet effective model named CluCDD, which aggregates utterances\nby contrastive learning. More specifically, our model pulls utterances in the\nsame session together and pushes away utterances in different ones. Then a\nclustering method is adopted to generate predicted clustering labels.\nComprehensive experiments conducted on the Movie Dialogue dataset and IRC\ndataset demonstrate that our model achieves a new state-of-the-art result.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jingsheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zeyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_S/0/1/0/all/0/1\">Suncheng Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yuzhuo Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empirical Investigation of Neural Symbolic Reasoning Strategies. (arXiv:2302.08148v1 [cs.AI])","link":"http://arxiv.org/abs/2302.08148","description":"<p>Neural reasoning accuracy improves when generating intermediate reasoning\nsteps. However, the source of this improvement is yet unclear. Here, we\ninvestigate and factorize the benefit of generating intermediate steps for\nsymbolic reasoning. Specifically, we decompose the reasoning strategy w.r.t.\nstep granularity and chaining strategy. With a purely symbolic numerical\nreasoning dataset (e.g., A=1, B=3, C=A+3, C?), we found that the choice of\nreasoning strategies significantly affects the performance, with the gap\nbecoming even larger as the extrapolation length becomes longer. Surprisingly,\nwe also found that certain configurations lead to nearly perfect performance,\neven in the case of length extrapolation. Our results indicate the importance\nof further exploring effective strategies for neural reasoning models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aoki_Y/0/1/0/all/0/1\">Yoichi Aoki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kudo_K/0/1/0/all/0/1\">Keito Kudo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuribayashi_T/0/1/0/all/0/1\">Tatsuki Kuribayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brassard_A/0/1/0/all/0/1\">Ana Brassard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshikawa_M/0/1/0/all/0/1\">Masashi Yoshikawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaguchi_K/0/1/0/all/0/1\">Keisuke Sakaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1\">Kentaro Inui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reanalyzing L2 Preposition Learning with Bayesian Mixed Effects and a Large Language Model. (arXiv:2302.08150v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08150","description":"<p>We use both Bayesian and neural models to dissect a data set of Chinese\nlearners' pre- and post-interventional responses to two tests measuring their\nunderstanding of English prepositions. The results mostly replicate previous\nfindings from frequentist analyses and newly reveal crucial interactions\nbetween student ability, task type, and stimulus sentence. Given the sparsity\nof the data as well as high diversity among learners, the Bayesian method\nproves most useful; but we also see potential in using language model\nprobabilities as predictors of grammaticality and learnability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prange_J/0/1/0/all/0/1\">Jakob Prange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_M/0/1/0/all/0/1\">Man Ho Ivy Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Un mod{\\`e}le de base de connaissances terminologiques. (arXiv:2302.08198v1 [cs.AI])","link":"http://arxiv.org/abs/2302.08198","description":"<p>In the present paper, we argue that Terminological Knowledge Bases (TKB) are\nall the more useful for addressing various needs as they do not fulfill formal\ncriteria. Moreover, they intend to clarify the terminology of a given domain by\nillustrating term uses in various contexts. Thus we designed a TKB structure\nincluding 3 linked features: terms, concepts and texts, that present the\npeculiar use of each term in the domain. Note that concepts are represented\ninto frames whose non-formal description is standardized. Associated with this\nstructure, we defined modeling criteria at the conceptual level. Finaly, we\ndiscuss the situation of TKB with regard to ontologies, and the use of TKB for\nthe development of AI systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seguela_P/0/1/0/all/0/1\">Patrick S&#xe9;gu&#xe9;la</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aussenac_Gilles_N/0/1/0/all/0/1\">Nathalie Aussenac-Gilles</a> (IRIT-MELODI, CNRS)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Language Models with Preferences through f-divergence Minimization. (arXiv:2302.08215v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08215","description":"<p>Aligning language models with preferences can be posed as approximating a\ntarget distribution representing some desired behavior. Existing approaches\ndiffer both in the functional form of the target distribution and the algorithm\nused to approximate it. For instance, Reinforcement Learning from Human\nFeedback (RLHF) corresponds to minimizing a reverse KL from an implicit target\ndistribution arising from a KL penalty in the objective. On the other hand,\nGenerative Distributional Control (GDC) has an explicit target distribution and\nminimizes a forward KL from it using the Distributional Policy Gradient (DPG)\nalgorithm. In this paper, we propose a new approach, f-DPG, which allows the\nuse of any f-divergence to approximate any target distribution. f-DPG unifies\nboth frameworks (RLHF, GDC) and the approximation methods (DPG, RL with KL\npenalties). We show the practical benefits of various choices of divergence\nobjectives and demonstrate that there is no universally optimal objective but\nthat different divergences are good for approximating different targets. For\ninstance, we discover that for GDC, the Jensen-Shannon divergence frequently\noutperforms forward KL divergence by a wide margin, leading to significant\nimprovements over prior work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Go_D/0/1/0/all/0/1\">Dongyoung Go</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1\">Germ&#xe1;n Kruszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozen_J/0/1/0/all/0/1\">Jos Rozen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryu_N/0/1/0/all/0/1\">Nahyeon Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1\">Marc Dymetman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue State Distillation Network with Inter-Slot Contrastive Learning for Dialogue State Tracking. (arXiv:2302.08220v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08220","description":"<p>In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to\nextract users' intentions from the dialogue history. Currently, most existing\napproaches suffer from error propagation and are unable to dynamically select\nrelevant information when utilizing previous dialogue states. Moreover, the\nrelations between the updates of different slots provide vital clues for DST.\nHowever, the existing approaches rely only on predefined graphs to indirectly\ncapture the relations. In this paper, we propose a Dialogue State Distillation\nNetwork (DSDN) to utilize relevant information of previous dialogue states and\nmigrate the gap of utilization between training and testing. Thus, it can\ndynamically exploit previous dialogue states and avoid introducing error\npropagation simultaneously. Further, we propose an inter-slot contrastive\nlearning loss to effectively capture the slot co-update relations from dialogue\ncontext. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ\n2.1 datasets. The experimental results show that our proposed model achieves\nthe state-of-the-art performance for DST.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dandan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_S/0/1/0/all/0/1\">Siu Cheung Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Q/0/1/0/all/0/1\">Qiang Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaonan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jian Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Spoken Language Identification with Map-Mix. (arXiv:2302.08229v1 [cs.LG])","link":"http://arxiv.org/abs/2302.08229","description":"<p>The pre-trained multi-lingual XLSR model generalizes well for language\nidentification after fine-tuning on unseen languages. However, the performance\nsignificantly degrades when the languages are not very distinct from each\nother, for example, in the case of dialects. Low resource dialect\nclassification remains a challenging problem to solve. We present a new data\naugmentation method that leverages model training dynamics of individual data\npoints to improve sampling for latent mixup. The method works well in\nlow-resource settings where generalization is paramount. Our datamaps-based\nmixup technique, which we call Map-Mix improves weighted F1 scores by 2%\ncompared to the random mixup baseline and results in a significantly\nwell-calibrated model. The code for our method is open sourced on\nhttps://github.com/skit-ai/Map-Mix.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rajaa_S/0/1/0/all/0/1\">Shangeth Rajaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandan_K/0/1/0/all/0/1\">Kriti Anandan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1\">Swaraj Dalmia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_T/0/1/0/all/0/1\">Tarun Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chng_E/0/1/0/all/0/1\">Eng Siong Chng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tragic and Comical Networks. Clustering Dramatic Genres According to Structural Properties. (arXiv:2302.08258v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08258","description":"<p>There is a growing tradition in the joint field of network studies and drama\nhistory that produces interpretations from the character networks of the\nplays.The potential of such an interpretation is that the diagrams provide a\ndifferent representation of the relationships between characters as compared to\nreading the text or watching the performance. Our aim is to create a method\nthat is able to cluster texts with similar structures on the basis of the\nplay's well-interpretable and simple properties, independent from the number of\ncharacters in the drama, or in other words, the size of the network. Finding\nthese features is the most important part of our research, as well as\nestablishing the appropriate statistical procedure to calculate the\nsimilarities between the texts. Our data was downloaded from the DraCor\ndatabase and analyzed in R (we use the GerDracor and the ShakeDraCor\nsub-collection). We want to propose a robust method based on the distribution\nof words among characters; distribution of characters in scenes, average length\nof speech acts, or character-specific and macro-level network properties such\nas clusterization coefficient and network density. Based on these metrics a\nsupervised classification procedure is applied to the sub-collections to\nclassify comedies and tragedies using the Support Vector Machine (SVM) method.\nOur research shows that this approach can also produce reliable results on a\nsmall sample size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Botond_S/0/1/0/all/0/1\">Szemes Botond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bence_V/0/1/0/all/0/1\">Vida Bence</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-augmented Image Captioning. (arXiv:2302.08268v1 [cs.CV])","link":"http://arxiv.org/abs/2302.08268","description":"<p>Inspired by retrieval-augmented language generation and pretrained Vision and\nLanguage (V&amp;L) encoders, we present a new approach to image captioning that\ngenerates sentences given the input image and a set of captions retrieved from\na datastore, as opposed to the image alone. The encoder in our model jointly\nprocesses the image and retrieved captions using a pretrained V&amp;L BERT, while\nthe decoder attends to the multimodal encoder representations, benefiting from\nthe extra textual evidence from the retrieved captions. Experimental results on\nthe COCO dataset show that image captioning can be effectively formulated from\nthis new perspective. Our model, named EXTRA, benefits from using captions\nretrieved from the training dataset, and it can also benefit from using an\nexternal dataset without the need for retraining. Ablation studies show that\nretrieving a sufficient number of captions (e.g., k=5) can improve captioning\nquality. Our work contributes towards using pretrained V&amp;L encoders for\ngenerative tasks, instead of standard classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramos_R/0/1/0/all/0/1\">Rita Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_B/0/1/0/all/0/1\">Bruno Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NUAA-QMUL-AIIT at Memotion 3: Multi-modal Fusion with Squeeze-and-Excitation for Internet Meme Emotion Analysis. (arXiv:2302.08326v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08326","description":"<p>This paper describes the participation of our NUAA-QMUL-AIIT team in the\nMemotion 3 shared task on meme emotion analysis. We propose a novel multi-modal\nfusion method, Squeeze-and-Excitation Fusion (SEFusion), and embed it into our\nsystem for emotion classification in memes. SEFusion is a simple fusion method\nthat employs fully connected layers, reshaping, and matrix multiplication.\nSEFusion learns a weight for each modality and then applies it to its own\nmodality feature. We evaluate the performance of our system on the three\nMemotion 3 sub-tasks. Among all participating systems in this Memotion 3 shared\ntask, our system ranked first on task A, fifth on task B, and second on task C.\nOur proposed SEFusion provides the flexibility to fuse any features from\ndifferent modalities. The source code for our method is published on\nhttps://github.com/xxxxxxxxy/memotion3-SEFusion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaoyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cluster-based Deep Ensemble Learning for Emotion Classification in Internet Memes. (arXiv:2302.08343v1 [cs.CV])","link":"http://arxiv.org/abs/2302.08343","description":"<p>Memes have gained popularity as a means to share visual ideas through the\nInternet and social media by mixing text, images and videos, often for humorous\npurposes. Research enabling automated analysis of memes has gained attention in\nrecent years, including among others the task of classifying the emotion\nexpressed in memes. In this paper, we propose a novel model, cluster-based deep\nensemble learning (CDEL), for emotion classification in memes. CDEL is a hybrid\nmodel that leverages the benefits of a deep learning model in combination with\na clustering algorithm, which enhances the model with additional information\nafter clustering memes with similar facial features. We evaluate the\nperformance of CDEL on a benchmark dataset for emotion classification, proving\nits effectiveness by outperforming a wide range of baseline models and\nachieving state-of-the-art performance. Further evaluation through ablated\nmodels demonstrates the effectiveness of the different components of CDEL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaoyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Event-based News Narrative Extraction. (arXiv:2302.08351v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08351","description":"<p>Narratives are fundamental to our understanding of the world, providing us\nwith a natural structure for knowledge representation over time. Computational\nnarrative extraction is a subfield of artificial intelligence that makes heavy\nuse of information retrieval and natural language processing techniques.\nDespite the importance of computational narrative extraction, relatively little\nscholarly work exists on synthesizing previous research and strategizing future\nresearch in the area. In particular, this article focuses on extracting news\nnarratives from an event-centric perspective. Extracting narratives from news\ndata has multiple applications in understanding the evolving information\nlandscape. This survey presents an extensive study of research in the area of\nevent-based news narrative extraction. In particular, we screened over 900\narticles that yielded 54 relevant articles. These articles are synthesized and\norganized by representation model, extraction criteria, and evaluation\napproaches. Based on the reviewed studies, we identify recent trends, open\nchallenges, and potential research lines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Norambuena_B/0/1/0/all/0/1\">Brian Keith Norambuena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_T/0/1/0/all/0/1\">Tanushree Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+North_C/0/1/0/all/0/1\">Chris North</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversation Style Transfer using Few-Shot Learning. (arXiv:2302.08362v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08362","description":"<p>Conventional text style transfer approaches for natural language focus on\nsentence-level style transfer without considering contextual information, and\nthe style is described with attributes (e.g., formality). When applying style\ntransfer on conversations such as task-oriented dialogues, existing approaches\nsuffer from these limitations as context can play an important role and the\nstyle attributes are often difficult to define in conversations. In this paper,\nwe introduce conversation style transfer as a few-shot learning problem, where\nthe model learns to perform style transfer by observing only the target-style\ndialogue examples. We propose a novel in-context learning approach to solve the\ntask with style-free dialogues as a pivot. Human evaluation shows that by\nincorporating multi-turn context, the model is able to match the target style\nwhile having better appropriateness and semantic correctness compared to\nutterance-level style transfer. Additionally, we show that conversation style\ntransfer can also benefit downstream tasks. Results on multi-domain intent\nclassification tasks show improvement in F1 scores after transferring the style\nof training data to match the style of test data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Shamik Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_R/0/1/0/all/0/1\">Raphael Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_N/0/1/0/all/0/1\">Nikolaos Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansimov_E/0/1/0/all/0/1\">Elman Mansimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1\">Saab Mansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficiency 360: Efficient Vision Transformers. (arXiv:2302.08374v1 [cs.CV])","link":"http://arxiv.org/abs/2302.08374","description":"<p>Transformers are widely used for solving tasks in natural language\nprocessing, computer vision, speech, and music domains. In this paper, we talk\nabout the efficiency of transformers in terms of memory (the number of\nparameters), computation cost (number of floating points operations), and\nperformance of models, including accuracy, the robustness of the model, and\nfair \\&amp; bias-free features. We mainly discuss the vision transformer for the\nimage classification task. Our contribution is to introduce an efficient 360\nframework, which includes various aspects of the vision transformer, to make it\nmore efficient for industrial applications. By considering those applications,\nwe categorize them into multiple dimensions such as privacy, robustness,\ntransparency, fairness, inclusiveness, continual learning, probabilistic\nmodels, approximation, computational complexity, and spectral complexity. We\ncompare various vision transformer models based on their performance, the\nnumber of parameters, and the number of floating point operations (FLOPs) on\nmultiple datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1\">Badri N. Patro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agneeswaran_V/0/1/0/all/0/1\">Vijay Agneeswaran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEALLA: Learning Lightweight Language-agnostic Sentence Embeddings with Knowledge Distillation. (arXiv:2302.08387v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08387","description":"<p>Large-scale language-agnostic sentence embedding models such as LaBSE (Feng\net al., 2022) obtain state-of-the-art performance for parallel sentence\nalignment. However, these large-scale models can suffer from inference speed\nand computation overhead. This study systematically explores learning\nlanguage-agnostic sentence embeddings with lightweight models. We demonstrate\nthat a thin-deep encoder can construct robust low-dimensional sentence\nembeddings for 109 languages. With our proposed distillation methods, we\nachieve further improvements by incorporating knowledge from a teacher model.\nEmpirical results on Tatoeba, United Nations, and BUCC show the effectiveness\nof our lightweight models. We release our lightweight language-agnostic\nsentence embedding models LEALLA on TensorFlow Hub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhuoyuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakagawa_T/0/1/0/all/0/1\">Tetsuji Nakagawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. (arXiv:2302.08399v1 [cs.AI])","link":"http://arxiv.org/abs/2302.08399","description":"<p>Intuitive psychology is a pillar of common-sense reasoning. The replication\nof this reasoning in machine intelligence is an important stepping-stone on the\nway to human-like artificial intelligence. Several recent tasks and benchmarks\nfor examining this reasoning in Large-Large Models have focused in particular\non belief attribution in Theory-of-Mind tasks. These tasks have shown both\nsuccesses and failures. We consider in particular a recent purported success\ncase, and show that small variations that maintain the principles of ToM turn\nthe results on their head. We argue that in general, the zero-hypothesis for\nmodel evaluation in intuitive psychology should be skeptical, and that outlying\nfailure cases should outweigh average success rates. We also consider what\npossible future successes on Theory-of-Mind tasks by more powerful LLMs would\nmean for ToM tasks with people.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1\">Tomer Ullman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating and Improving the Coreference Capabilities of Machine Translation Models. (arXiv:2302.08464v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08464","description":"<p>Machine translation (MT) requires a wide range of linguistic capabilities,\nwhich current end-to-end models are expected to learn implicitly by observing\naligned sentences in bilingual corpora. In this work, we ask: \\emph{How well do\nMT models learn coreference resolution from implicit signal?} To answer this\nquestion, we develop an evaluation methodology that derives coreference\nclusters from MT output and evaluates them without requiring annotations in the\ntarget language. We further evaluate several prominent open-source and\ncommercial MT systems, translating from English to six target languages, and\ncompare them to state-of-the-art coreference resolvers on three challenging\nbenchmarks. Our results show that the monolingual resolvers greatly outperform\nMT models. Motivated by this result, we experiment with different methods for\nincorporating the output of coreference resolution models in MT, showing\nimprovement over strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yehudai_A/0/1/0/all/0/1\">Asaf Yehudai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1\">Arie Cattan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1\">Gabriel Stanovsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEVER: Learning to Verify Language-to-Code Generation with Execution. (arXiv:2302.08468v1 [cs.LG])","link":"http://arxiv.org/abs/2302.08468","description":"<p>The advent of pre-trained code language models (CodeLMs) has lead to\nsignificant progress in language-to-code generation. State-of-the-art\napproaches in this area combine CodeLM decoding with sample pruning and\nreranking using test cases or heuristics based on the execution results.\nHowever, it is challenging to obtain test cases for many real-world\nlanguage-to-code applications, and heuristics cannot well capture the semantic\nfeatures of the execution results, such as data type and value range, which\noften indicates the correctness of the program. In this work, we propose LEVER,\na simple approach to improve language-to-code generation by learning to verify\nthe generated programs with their execution results. Specifically, we train\nverifiers to determine whether a program sampled from the CodeLM is correct or\nnot based on the natural language input, the program itself and its execution\nresults. The sampled programs are reranked by combining the verification score\nwith the CodeLM generation probability, and marginalizing over programs with\nthe same execution results. On four datasets across the domains of table QA,\nmath QA and basic Python programming, LEVER consistently improves over the base\nCodeLMs (4.6% to 10.9% with code-davinci-002) and achieves new state-of-the-art\nresults on all of them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ni_A/0/1/0/all/0/1\">Ansong Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_S/0/1/0/all/0/1\">Srini Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Ves Stoyanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sida I. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Auditing large language models: a three-layered approach. (arXiv:2302.08500v1 [cs.CL])","link":"http://arxiv.org/abs/2302.08500","description":"<p>The emergence of large language models (LLMs) represents a major advance in\nartificial intelligence (AI) research. However, the widespread use of LLMs is\nalso coupled with significant ethical and social challenges. Previous research\nhas pointed towards auditing as a promising governance mechanism to help ensure\nthat AI systems are designed and deployed in ways that are ethical, legal, and\ntechnically robust. However, existing auditing procedures fail to address the\ngovernance challenges posed by LLMs, which are adaptable to a wide range of\ndownstream tasks. To help bridge that gap, we offer three contributions in this\narticle. First, we establish the need to develop new auditing procedures that\ncapture the risks posed by LLMs by analysing the affordances and constraints of\nexisting auditing procedures. Second, we outline a blueprint to audit LLMs in\nfeasible and effective ways by drawing on best practices from IT governance and\nsystem engineering. Specifically, we propose a three-layered approach, whereby\ngovernance audits, model audits, and application audits complement and inform\neach other. Finally, we discuss the limitations not only of our three-layered\napproach but also of the prospect of auditing LLMs at all. Ultimately, this\narticle seeks to expand the methodological toolkit available to technology\nproviders and policymakers who wish to analyse and evaluate LLMs from\ntechnical, ethical, and legal perspectives.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mokander_J/0/1/0/all/0/1\">Jakob M&#xf6;kander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuett_J/0/1/0/all/0/1\">Jonas Schuett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Floridi_L/0/1/0/all/0/1\">Luciano Floridi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pairwise Representation Learning for Event Coreference. (arXiv:2010.12808v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2010.12808","description":"<p>Natural Language Processing tasks such as resolving the coreference of events\nrequire understanding the relations between two text snippets. These tasks are\ntypically formulated as (binary) classification problems over independently\ninduced representations of the text snippets. In this work, we develop a\nPairwise Representation Learning (PairwiseRL) scheme for the event mention\npairs, in which we jointly encode a pair of text snippets so that the\nrepresentation of each mention in the pair is induced in the context of the\nother one. Furthermore, our representation supports a finer, structured\nrepresentation of the text snippet to facilitate encoding events and their\narguments. We show that PairwiseRL, despite its simplicity, outperforms the\nprior state-of-the-art event coreference systems on both cross-document and\nwithin-document event coreference benchmarks. We also conduct in-depth analysis\nin terms of the improvement and the limitation of pairwise representation so as\nto provide insights for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predictions For Pre-training Language Models. (arXiv:2011.09031v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2011.09031","description":"<p>Language model pre-training has proven to be useful in many language\nunderstanding tasks. In this paper, we investigate whether it is still helpful\nto add the self-training method in the pre-training step and the fine-tuning\nstep. Towards this goal, we propose a learning framework that making best use\nof the unlabel data on the low-resource and high-resource labeled dataset. In\nindustry NLP applications, we have large amounts of data produced by users or\ncustomers. Our learning framework is based on this large amounts of unlabel\ndata. First, We use the model fine-tuned on manually labeled dataset to predict\npseudo labels for the user-generated unlabeled data. Then we use the pseudo\nlabels to supervise the task-specific training on the large amounts of\nuser-generated data. We consider this task-specific training step on pseudo\nlabels as a pre-training step for the next fine-tuning step. At last, we\nfine-tune on the manually labeled dataset upon the pre-trained model. In this\nwork, we first empirically show that our method is able to solidly improve the\nperformance by 3.6%, when the manually labeled fine-tuning dataset is\nrelatively small. Then we also show that our method still is able to improve\nthe performance further by 0.2%, when the manually labeled fine-tuning dataset\nis relatively large enough. We argue that our method make the best use of the\nunlabel data, which is superior to either pre-training or self-training alone.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Event Linking: Grounding Event Mentions to Wikipedia. (arXiv:2112.07888v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.07888","description":"<p>Comprehending an article requires understanding its constituent events.\nHowever, the context where an event is mentioned often lacks the details of\nthis event. A question arises: how can the reader obtain more knowledge about\nthis particular event in addition to what is provided by the local context in\nthe article?\n</p>\n<p>This work defines Event Linking, a new natural language understanding task at\nthe event level. Event linking tries to link an event mention appearing in an\narticle to the most appropriate Wikipedia page. This page is expected to\nprovide rich knowledge about what the event mention refers to. To standardize\nthe research in this new direction, we contribute in four-fold. First, this is\nthe first work in the community that formally defines Event Linking task.\nSecond, we collect a dataset for this new task. Specifically, we automatically\ngather training set from Wikipedia, and then create two evaluation sets: one\nfrom the Wikipedia domain, reporting the in-domain performance, and a second\nfrom the real-world news domain, to evaluate out-of-domain performance. Third,\nwe retrain and evaluate two state-of-the-art (SOTA) entity linking models,\nshowing the challenges of event linking, and we propose an event-specific\nlinking system EVELINK to set a competitive result for the new task. Fourth, we\nconduct a detailed and insightful analysis to help understand the task and the\nlimitation of the current model. Overall, as our analysis shows, Event Linking\nis a considerably challenging and essential task requiring more effort from the\ncommunity. Data and code are available here:\nhttps://github.com/CogComp/event-linking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nitish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BITE: Textual Backdoor Attacks with Iterative Trigger Injection. (arXiv:2205.12700v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12700","description":"<p>Backdoor attacks have become an emerging threat to NLP systems. By providing\npoisoned training data, the adversary can embed a ``backdoor'' into the victim\nmodel, which allows input instances satisfying certain textual patterns (e.g.,\ncontaining a keyword) to be predicted as a target label of the adversary's\nchoice. In this paper, we demonstrate that it's possible to design a backdoor\nattack that is both stealthy (i.e., hard to notice) and effective (i.e., has a\nhigh attack success rate). We propose BITE, a backdoor attack that poisons the\ntraining data to establish strong correlations between the target label and\nsome ``trigger words'', by iteratively injecting them into target-label\ninstances through natural word-level perturbations. The poisoned training data\ninstruct the victim model to predict the target label on inputs containing\ntrigger words, forming the backdoor. Experiments on four medium-sized text\nclassification datasets show that BITE is significantly more effective than\nbaselines while maintaining decent stealthiness, raising alarm on the usage of\nuntrusted training data. We further propose a defense method named DeBITE based\non potential trigger word removal, which outperforms existing methods on\ndefending BITE and generalizes well to defending other backdoor attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vansh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neuro-Symbolic Procedural Planning with Commonsense Prompting. (arXiv:2206.02928v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.02928","description":"<p>Procedural planning aims to implement complex high-level goals by\ndecomposition into sequential simpler low-level steps. Although procedural\nplanning is a basic skill set for humans in daily life, it remains a challenge\nfor large language models (LLMs) that lack a deep understanding of the\ncause-effect relations in procedures. Previous methods require manual exemplars\nto acquire procedural planning knowledge from LLMs in the zero-shot setting.\nHowever, such elicited pre-trained knowledge in LLMs induces spurious\ncorrelations between goals and steps, which impair the model generalization to\nunseen tasks. In contrast, this paper proposes a neuro-symbolic procedural\nPLANner (PLAN) that elicits procedural planning knowledge from the LLMs with\ncommonsense-infused prompting. To mitigate spurious goal-step correlations, we\nuse symbolic program executors on the latent procedural representations to\nformalize prompts from commonsense knowledge bases as a causal intervention\ntoward the Structural Causal Model. Both automatic and human evaluations on\nWikiHow and RobotHow show the superiority of PLAN on procedural planning\nwithout further training or manual exemplars.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Weixi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wenda Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eckstein_M/0/1/0/all/0/1\">Miguel Eckstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BigVGAN: A Universal Neural Vocoder with Large-Scale Training. (arXiv:2206.04658v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2206.04658","description":"<p>Despite recent progress in generative adversarial network (GAN)-based\nvocoders, where the model generates raw waveform conditioned on acoustic\nfeatures, it is challenging to synthesize high-fidelity audio for numerous\nspeakers across various recording environments. In this work, we present\nBigVGAN, a universal vocoder that generalizes well for various\nout-of-distribution scenarios without fine-tuning. We introduce periodic\nactivation function and anti-aliased representation into the GAN generator,\nwhich brings the desired inductive bias for audio synthesis and significantly\nimproves audio quality. In addition, we train our GAN vocoder at the largest\nscale up to 112M parameters, which is unprecedented in the literature. We\nidentify and address the failure modes in large-scale GAN training for audio,\nwhile maintaining high-fidelity output without over-regularization. Our\nBigVGAN, trained only on clean speech (LibriTTS), achieves the state-of-the-art\nperformance for various zero-shot (out-of-distribution) conditions, including\nunseen speakers, languages, recording environments, singing voices, music, and\ninstrumental audio. We release our code and model at:\nhttps://github.com/NVIDIA/BigVGAN\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-gil Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Sungroh Yoon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Write and Paint: Generative Vision-Language Models are Unified Modal Learners. (arXiv:2206.07699v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2206.07699","description":"<p>Recent advances in vision-language pre-training have pushed the\nstate-of-the-art on various vision-language tasks, making machines more capable\nof multi-modal writing (image-to-text generation) and painting (text-to-image\ngeneration). However, few studies investigate if these two essential\ncapabilities can be learned together and boost each other, making a versatile\nand powerful multi-modal foundation model. In this work, we disclose the\npotential of symmetric generative vision-language pre-training in learning to\nwrite and paint concurrently, and propose a new unified modal model, named\nDaVinci, trained with prefix language modeling and prefix image modeling, a\nsimple generative self-supervised objective on image-text pairs. Thanks to the\nproposed prefix multi-modal modeling framework, DaVinci is simple to train,\nscalable to huge data, adaptable to both writing and painting tasks, and also\nstrong on other vision, text, and multi-modal understanding tasks. DaVinci\nachieves competitive performance on a wide range of 27 generation/understanding\ntasks and demonstrates the superiority of combining vision/language generative\npre-training. Furthermore, we carefully benchmark the performance of different\nvision-language pre-training objectives on different scales of pre-training\ndatasets on a heterogeneous and broad distribution coverage. Our results\ndemonstrate the potential of exploiting self-supervision in both language and\nvision inputs, and establish new, stronger baselines for future comparisons at\ndifferent data scales. The code and pre-trained models are available at\nhttps://github.com/shizhediao/DaVinci.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Diao_S/0/1/0/all/0/1\">Shizhe Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinsong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiawei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recitation-Augmented Language Models. (arXiv:2210.01296v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.01296","description":"<p>We propose a new paradigm to help Large Language Models (LLMs) generate more\naccurate factual knowledge without retrieving from an external corpus, called\nRECITation-augmented gEneration (RECITE). Different from retrieval-augmented\nlanguage models that retrieve relevant documents before generating the outputs,\ngiven an input, RECITE first recites one or several relevant passages from\nLLMs' own memory via sampling, and then produces the final answers. We show\nthat RECITE is a powerful paradigm for knowledge-intensive NLP tasks.\nSpecifically, we show that by utilizing recitation as the intermediate step, a\nrecite-and-answer scheme can achieve new state-of-the-art performance in\nvarious closed-book question answering (CBQA) tasks. In experiments, we verify\nthe effectiveness of \\method~on four pre-trained models (PaLM, UL2, OPT, and\nCodex) and three CBQA tasks (Natural Questions, TriviaQA, and HotpotQA). Our\ncode is available at \"https://github.com/Edward-Sun/RECITE\".\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhiqing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yiming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Disentangled Representations for Natural Language Definitions. (arXiv:2210.02898v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.02898","description":"<p>Disentangling the encodings of neural models is a fundamental aspect for\nimproving interpretability, semantic control and downstream task performance in\nNatural Language Processing. Currently, most disentanglement methods are\nunsupervised or rely on synthetic datasets with known generative factors. We\nargue that recurrent syntactic and semantic regularities in textual data can be\nused to provide the models with both structural biases and generative factors.\nWe leverage the semantic structures present in a representative and\nsemantically dense category of sentence types, definitional sentences, for\ntraining a Variational Autoencoder to learn disentangled representations. Our\nexperimental results show that the proposed model outperforms unsupervised\nbaselines on several qualitative and quantitative benchmarks for\ndisentanglement, and it also improves the results in the downstream task of\ndefinition modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Carvalho_D/0/1/0/all/0/1\">Danilo S. Carvalho</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Mercatali_G/0/1/0/all/0/1\">Giangiacomo Mercatali</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yingji Zhang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andre Freitas</a> (1 and 2) ((1) Department of Computer Science, University of Manchester, United Kingdom, (2) Idiap Research Institute, Switzerland)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SODAPOP: Open-Ended Discovery of Social Biases in Social Commonsense Reasoning Models. (arXiv:2210.07269v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07269","description":"<p>A common limitation of diagnostic tests for detecting social biases in NLP\nmodels is that they may only detect stereotypic associations that are\npre-specified by the designer of the test. Since enumerating all possible\nproblematic associations is infeasible, it is likely these tests fail to detect\nbiases that are present in a model but not pre-specified by the designer. To\naddress this limitation, we propose SODAPOP (SOcial bias Discovery from Answers\nabout PeOPle) in social commonsense question-answering. Our pipeline generates\nmodified instances from the Social IQa dataset (Sap et al., 2019) by (1)\nsubstituting names associated with different demographic groups, and (2)\ngenerating many distractor answers from a masked language model. By using a\nsocial commonsense model to score the generated distractors, we are able to\nuncover the model's stereotypic associations between demographic groups and an\nopen set of words. We also test SODAPOP on debiased models and show the\nlimitations of multiple state-of-the-art debiasing algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_H/0/1/0/all/0/1\">Haozhe An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongxia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudinger_R/0/1/0/all/0/1\">Rachel Rudinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods. (arXiv:2210.07321v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07321","description":"<p>Machine generated text is increasingly difficult to distinguish from human\nauthored text. Powerful open-source models are freely available, and\nuser-friendly tools that democratize access to generative models are\nproliferating. ChatGPT, which was released shortly after the first preprint of\nthis survey, epitomizes these trends. The great potential of state-of-the-art\nnatural language generation (NLG) systems is tempered by the multitude of\navenues for abuse. Detection of machine generated text is a key countermeasure\nfor reducing abuse of NLG models, with significant technical challenges and\nnumerous open problems. We provide a survey that includes both 1) an extensive\nanalysis of threat models posed by contemporary NLG systems, and 2) the most\ncomplete review of machine generated text detection methods to date. This\nsurvey places machine generated text within its cybersecurity and social\ncontext, and provides strong guidance for future work addressing the most\ncritical threat models, and ensuring detection systems themselves demonstrate\ntrustworthiness through fairness, robustness, and accountability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Crothers_E/0/1/0/all/0/1\">Evan Crothers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1\">Nathalie Japkowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viktor_H/0/1/0/all/0/1\">Herna Viktor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can language models handle recursively nested grammatical structures? A case study on comparing models and humans. (arXiv:2210.15303v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.15303","description":"<p>How should we compare the capabilities of language models (LMs) and humans? I\ndraw inspiration from comparative psychology to highlight some challenges. In\nparticular, I consider a case study: processing of recursively nested\ngrammatical structures. Prior work suggests that LMs cannot handle these\nstructures as reliably as humans can. However, the humans were provided with\ninstructions and training, while the LMs were evaluated zero-shot. I therefore\nmatch the evaluation more closely. Providing large LMs with a simple prompt --\nsubstantially less content than the human training -- allows the LMs to\nconsistently outperform the human results, and even to extrapolate to more\ndeeply nested conditions than were tested with humans. Further, reanalyzing the\nprior human data suggests that the humans may not perform above chance at the\ndifficult structures initially. Thus, large LMs may indeed process recursively\nnested grammatical structures as reliably as humans. This case study highlights\nhow discrepancies in the evaluation can confound comparisons of language models\nand humans. I therefore reflect on the broader challenge of comparing human and\nmodel capabilities, and highlight an important difference between evaluating\ncognitive models and foundation models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lampinen_A/0/1/0/all/0/1\">Andrew Kyle Lampinen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WR-ONE2SET: Towards Well-Calibrated Keyphrase Generation. (arXiv:2211.06862v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.06862","description":"<p>Keyphrase generation aims to automatically generate short phrases summarizing\nan input document. The recently emerged ONE2SET paradigm (Ye et al., 2021)\ngenerates keyphrases as a set and has achieved competitive performance.\nNevertheless, we observe serious calibration errors outputted by ONE2SET,\nespecially in the over-estimation of $\\varnothing$ token (means \"no\ncorresponding keyphrase\"). In this paper, we deeply analyze this limitation and\nidentify two main reasons behind: 1) the parallel generation has to introduce\nexcessive $\\varnothing$ as padding tokens into training instances; and 2) the\ntraining mechanism assigning target to each slot is unstable and further\naggravates the $\\varnothing$ token over-estimation. To make the model\nwell-calibrated, we propose WR-ONE2SET which extends ONE2SET with an adaptive\ninstance-level cost Weighting strategy and a target Re-assignment mechanism.\nThe former dynamically penalizes the over-estimated slots for different\ninstances thus smoothing the uneven training distribution. The latter refines\nthe original inappropriate assignment and reduces the supervisory signals of\nover-estimated slots. Experimental results on commonly-used datasets\ndemonstrate the effectiveness and generality of our proposed paradigm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1\">Binbin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiangpeng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Huan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Easy to Decide, Hard to Agree: Reducing Disagreements Between Saliency Methods. (arXiv:2211.08369v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08369","description":"<p>A popular approach to unveiling the black box of neural NLP models is to\nleverage saliency methods, which assign scalar importance scores to each input\ncomponent. A common practice for evaluating whether an interpretability method\nis faithful and plausible has been to use evaluation-by-agreement -- multiple\nmethods agreeing on an explanation increases its credibility. However, recent\nwork has found that even saliency methods have weak rank correlations and\nadvocated for the use of alternative diagnostic methods. In our work, we\ndemonstrate that rank correlation is not a good fit for evaluating agreement\nand argue that Pearson-$r$ is a better suited alternative. We show that\nregularization techniques that increase faithfulness of attention explanations\nalso increase agreement between saliency methods. Through connecting our\nfindings to instance categories based on training dynamics we show that,\nsurprisingly, easy-to-learn instances exhibit low agreement in saliency method\nexplanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jukic_J/0/1/0/all/0/1\">Josip Juki&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutek_M/0/1/0/all/0/1\">Martin Tutek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reward Gaming in Conditional Text Generation. (arXiv:2211.08714v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08714","description":"<p>To align conditional text generation model outputs with desired behaviors,\nthere has been an increasing focus on training the model using reinforcement\nlearning (RL) with reward functions learned from human annotations. Under this\nframework, we identify three common cases where high rewards are incorrectly\nassigned to undesirable patterns: noise-induced spurious correlation, naturally\noccurring spurious correlation, and covariate shift. We show that even though\nlearned metrics achieve high performance on the distribution of the data used\nto train the reward function, the undesirable patterns may be amplified during\nRL training of the text generation model. While there has been discussion about\nreward gaming in the RL or safety community, in this discussion piece, we would\nlike to highlight reward gaming in the natural language generation (NLG)\ncommunity using concrete conditional text generation examples and discuss\npotential fixes and areas for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_V/0/1/0/all/0/1\">Vishakh Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sellam_T/0/1/0/all/0/1\">Thibault Sellam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parikh_A/0/1/0/all/0/1\">Ankur P. Parikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Surrogate Gradient Spiking Neural Networks as Encoders for Large Vocabulary Continuous Speech Recognition. (arXiv:2212.01187v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.01187","description":"<p>Compared to conventional artificial neurons that produce dense and\nreal-valued responses, biologically-inspired spiking neurons transmit sparse\nand binary information, which can also lead to energy-efficient\nimplementations. Recent research has shown that spiking neural networks can be\ntrained like standard recurrent neural networks using the surrogate gradient\nmethod. They have shown promising results on speech command recognition tasks.\nUsing the same technique, we show that they are scalable to large vocabulary\ncontinuous speech recognition, where they are capable of replacing LSTMs in the\nencoder with only minor loss of performance. This suggests that they may be\napplicable to more involved sequence-to-sequence tasks. Moreover, in contrast\nto their recurrent non-spiking counterparts, they show robustness to exploding\ngradient problems without the need to use gates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bittar_A/0/1/0/all/0/1\">Alexandre Bittar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garner_P/0/1/0/all/0/1\">Philip N. Garner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Talking About Large Language Models. (arXiv:2212.03551v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.03551","description":"<p>Thanks to rapid progress in artificial intelligence, we have entered an era\nwhen technology and philosophy intersect in interesting ways. Sitting squarely\nat the centre of this intersection are large language models (LLMs). The more\nadept LLMs become at mimicking human language, the more vulnerable we become to\nanthropomorphism, to seeing the systems in which they are embedded as more\nhuman-like than they really are. This trend is amplified by the natural\ntendency to use philosophically loaded terms, such as \"knows\", \"believes\", and\n\"thinks\", when describing these systems. To mitigate this trend, this paper\nadvocates the practice of repeatedly stepping back to remind ourselves of how\nLLMs, and the systems of which they form a part, actually work. The hope is\nthat increased scientific precision will encourage more philosophical nuance in\nthe discourse around artificial intelligence, both within the field and in the\npublic sphere.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1\">Murray Shanahan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Choosing the Number of Topics in LDA Models -- A Monte Carlo Comparison of Selection Criteria. (arXiv:2212.14074v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.14074","description":"<p>Selecting the number of topics in LDA models is considered to be a difficult\ntask, for which alternative approaches have been proposed. The performance of\nthe recently developed singular Bayesian information criterion (sBIC) is\nevaluated and compared to the performance of alternative model selection\ncriteria. The sBIC is a generalization of the standard BIC that can be\nimplemented to singular statistical models. The comparison is based on Monte\nCarlo simulations and carried out for several alternative settings, varying\nwith respect to the number of topics, the number of documents and the size of\ndocuments in the corpora. Performance is measured using different criteria\nwhich take into account the correct number of topics, but also whether the\nrelevant topics from the DGPs are identified. Practical recommendations for LDA\nmodel selection in applications are derived.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bystrov_V/0/1/0/all/0/1\">Victor Bystrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naboka_V/0/1/0/all/0/1\">Viktoriia Naboka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staszewska_Bystrova_A/0/1/0/all/0/1\">Anna Staszewska-Bystrova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winker_P/0/1/0/all/0/1\">Peter Winker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neighborhood-Regularized Self-Training for Learning with Few Labels. (arXiv:2301.03726v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.03726","description":"<p>Training deep neural networks (DNNs) with limited supervision has been a\npopular research topic as it can significantly alleviate the annotation burden.\nSelf-training has been successfully applied in semi-supervised learning tasks,\nbut one drawback of self-training is that it is vulnerable to the label noise\nfrom incorrect pseudo labels. Inspired by the fact that samples with similar\nlabels tend to share similar representations, we develop a neighborhood-based\nsample selection approach to tackle the issue of noisy pseudo labels. We\nfurther stabilize self-training via aggregating the predictions from different\nrounds during sample selection. Experiments on eight tasks show that our\nproposed method outperforms the strongest self-training baseline with 1.83% and\n2.51% performance gain for text and graph datasets on average. Our further\nanalysis demonstrates that our proposed data selection strategy reduces the\nnoise of pseudo labels by 36.8% and saves 57.3% of the time when compared with\nthe best baseline. Our code and appendices will be uploaded to\nhttps://github.com/ritaranx/NeST.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1\">Hejie Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_X/0/1/0/all/0/1\">Xuan Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1\">Joyce Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Carl Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Learning Models to Study Sentence Comprehension in the Human Brain. (arXiv:2301.06340v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.06340","description":"<p>Recent artificial neural networks that process natural language achieve\nunprecedented performance in tasks requiring sentence-level understanding. As\nsuch, they could be interesting models of the integration of linguistic\ninformation in the human brain. We review works that compare these artificial\nlanguage models with human brain activity and we assess the extent to which\nthis approach has improved our understanding of the neural processes involved\nin natural language comprehension. Two main results emerge. First, the neural\nrepresentation of word meaning aligns with the context-dependent, dense word\nvectors used by the artificial neural networks. Second, the processing\nhierarchy that emerges within artificial neural networks broadly matches the\nbrain, but is surprisingly inconsistent across studies. We discuss current\nchallenges in establishing artificial neural networks as process models of\nnatural language comprehension. We suggest exploiting the highly structured\nrepresentational geometry of artificial neural networks when mapping\nrepresentations to brain data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arana_S/0/1/0/all/0/1\">Sophie Arana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerousseau_J/0/1/0/all/0/1\">Jacques Pesnot Lerousseau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hagoort_P/0/1/0/all/0/1\">Peter Hagoort</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal Reasoning of Entities and Events in Procedural Texts. (arXiv:2301.10896v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10896","description":"<p>Entities and events are crucial to natural language reasoning and common in\nprocedural texts. Existing work has focused either exclusively on entity state\ntracking (e.g., whether a pan is hot) or on event reasoning (e.g., whether one\nwould burn themselves by touching the pan), while these two tasks are often\ncausally related. We propose CREPE, the first benchmark on causal reasoning of\nevent plausibility and entity states. We show that most language models,\nincluding GPT-3, perform close to chance at .35 F1, lagging far behind human at\n.87 F1. We boost model performance to .59 F1 by creatively representing events\nas programming languages while prompting language models pretrained on code. By\ninjecting the causal relations between entities and events as intermediate\nreasoning steps in our representation, we further boost the performance to .67\nF1. Our findings indicate not only the challenge that CREPE brings for language\nmodels, but also the efficacy of code-like prompting combined with\nchain-of-thought prompting for multihop event reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hainiu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_W/0/1/0/all/0/1\">Weiqiu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_M/0/1/0/all/0/1\">Manni Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Chain-of-Thought Reasoning in Language Models. (arXiv:2302.00923v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.00923","description":"<p>Large language models (LLMs) have shown impressive performance on complex\nreasoning by leveraging chain-of-thought (CoT) prompting to generate\nintermediate reasoning chains as the rationale to infer the answer. However,\nexisting CoT studies have focused on the language modality. We propose\nMultimodal-CoT that incorporates language (text) and vision (images) modalities\ninto a two-stage framework that separates rationale generation and answer\ninference. In this way, answer inference can leverage better generated\nrationales that are based on multimodal information. With Multimodal-CoT, our\nmodel under 1 billion parameters outperforms the previous state-of-the-art LLM\n(GPT-3.5) by 16% (75.17%-&gt;91.68%) on the ScienceQA benchmark and even surpasses\nhuman performance. Code is publicly available available at\nhttps://github.com/amazon-science/mm-cot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">George Karypis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1\">Alex Smola</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UDApter -- Efficient Domain Adaptation Using Adapters. (arXiv:2302.03194v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03194","description":"<p>We propose two methods to make unsupervised domain adaptation (UDA) more\nparameter efficient using adapters, small bottleneck layers interspersed with\nevery layer of the large-scale pre-trained language model (PLM). The first\nmethod deconstructs UDA into a two-step process: first by adding a domain\nadapter to learn domain-invariant information and then by adding a task adapter\nthat uses domain-invariant information to learn task representations in the\nsource domain. The second method jointly learns a supervised classifier while\nreducing the divergence measure. Compared to strong baselines, our simple\nmethods perform well in natural language inference (MNLI) and the cross-domain\nsentiment classification task. We even outperform unsupervised domain\nadaptation methods such as DANN and DSN in sentiment classification, and we are\nwithin 0.85% F1 for natural language inference task, by fine-tuning only a\nfraction of the full model parameters. We release our code at\nhttps://github.com/declare-lab/domadapter\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malik_B/0/1/0/all/0/1\">Bhavitvya Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashyap_A/0/1/0/all/0/1\">Abhinav Ramesh Kashyap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.04054","description":"<p>Reliability of machine learning evaluation -- the consistency of observed\nevaluation scores across replicated model training runs -- is affected by\nseveral sources of nondeterminism which can be regarded as measurement noise.\nCurrent tendencies to remove noise in order to enforce reproducibility of\nresearch results neglect inherent nondeterminism at the implementation level\nand disregard crucial interaction effects between algorithmic noise factors and\ndata properties. This limits the scope of conclusions that can be drawn from\nsuch experiments. Instead of removing noise, we propose to incorporate several\nsources of variance, including their interaction with data properties, into an\nanalysis of significance and reliability of machine learning evaluation, with\nthe aim to draw inferences beyond particular instances of trained models. We\nshow how to use linear mixed effects models (LMEMs) to analyze performance\nevaluation scores, and to conduct statistical inference with a generalized\nlikelihood ratio test (GLRT). This allows us to incorporate arbitrary sources\nof noise like meta-parameter variations into statistical significance testing,\nand to assess performance differences conditional on data properties.\nFurthermore, a variance component analysis (VCA) enables the analysis of the\ncontribution of noise sources to overall variance and the computation of a\nreliability coefficient by the ratio of substantial to total variance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hagmann_M/0/1/0/all/0/1\">Michael Hagmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1\">Stefan Riezler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLIAM: Literature-based Data Synthesis for Synergistic Drug Combination Prediction. (arXiv:2302.06860v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06860","description":"<p>Language models pre-trained on scientific literature corpora have\nsubstantially advanced scientific discovery by offering high-quality feature\nrepresentations for downstream applications. However, these features are often\nnot interpretable, and thus can reveal limited insights to domain experts.\nInstead of obtaining features from language models, we propose BLIAM, a\nliterature-based data synthesis approach to directly generate training data\npoints that are interpretable and model-agnostic to downstream applications.\nThe key idea of BLIAM is to create prompts using existing training data and\nthen use these prompts to synthesize new data points. BLIAM performs these two\nsteps iteratively as new data points will define more informative prompts and\nnew prompts will in turn synthesize more accurate data points. Notably,\nliterature-based data augmentation might introduce data leakage since labels of\ntest data points in downstream applications might have already been mentioned\nin the language model corpus. To prevent such leakage, we introduce GDSC-combo,\na large-scale drug combination discovery dataset that was published after the\nbiomedical language model was trained. We found that BLIAM substantially\noutperforms a non-augmented approach and manual prompting in this rigorous data\nsplit setting. BLIAM can be further used to synthesize data points for novel\ndrugs and cell lines that were not even measured in biomedical experiments. In\naddition to the promising prediction performance, the data points synthesized\nby BLIAM are interpretable and model-agnostic, enabling in silico augmentation\nfor in vitro experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woicik_A/0/1/0/all/0/1\">Addie Woicik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Artificial intelligence in psychology research. (arXiv:2302.07267v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2302.07267","description":"<p>Large Language Models have vastly grown in capabilities. One potential\napplication of such AI systems is to support data collection in the social\nsciences, where perfect experimental control is currently unfeasible and the\ncollection of large, representative datasets is generally expensive. In this\npaper, we re-replicate 14 studies from the Many Labs 2 replication project\n(Klein et al., 2018) with OpenAI's text-davinci-003 model, colloquially known\nas GPT3.5. For the 10 studies that we could analyse, we collected a total of\n10,136 responses, each of which was obtained by running GPT3.5 with the\ncorresponding study's survey inputted as text. We find that our GPT3.5-based\nsample replicates 30% of the original results as well as 30% of the Many Labs 2\nresults, although there is heterogeneity in both these numbers (as we replicate\nsome original findings that Many Labs 2 did not and vice versa). We also find\nthat unlike the corresponding human subjects, GPT3.5 answered some survey\nquestions with extreme homogeneity$\\unicode{x2013}$with zero variation in\ndifferent runs' responses$\\unicode{x2013}$raising concerns that a hypothetical\nAI-led future may in certain ways be subject to a diminished diversity of\nthought. Overall, while our results suggest that Large Language Model\npsychology studies are feasible, their findings should not be assumed to\nstraightforwardly generalise to the human case. Nevertheless, AI-based data\ncollection may eventually become a viable and economically relevant method in\nthe empirical social sciences, making the understanding of its capabilities and\napplications central.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_P/0/1/0/all/0/1\">Peter S. Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoenegger_P/0/1/0/all/0/1\">Philipp Schoenegger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chongyang Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer models: an introduction and catalog. (arXiv:2302.07730v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07730","description":"<p>In the past few years we have seen the meteoric appearance of dozens of\nmodels of the Transformer family, all of which have funny, but not\nself-explanatory, names. The goal of this paper is to offer a somewhat\ncomprehensive but simple catalog and classification of the most popular\nTransformer models. The paper also includes an introduction to the most\nimportant aspects and innovation in Transformer models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amatriain_X/0/1/0/all/0/1\">Xavier Amatriain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-02-16T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}