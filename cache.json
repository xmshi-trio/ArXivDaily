{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-06-26T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"A Reference-less Quality Metric for Automatic Speech Recognition via Contrastive-Learning of a Multi-Language Model with Self-Supervision. (arXiv:2306.13114v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13114","description":"<p>The common standard for quality evaluation of automatic speech recognition\n(ASR) systems is reference-based metrics such as the Word Error Rate (WER),\ncomputed using manual ground-truth transcriptions that are time-consuming and\nexpensive to obtain. This work proposes a multi-language referenceless quality\nmetric, which allows comparing the performance of different ASR models on a\nspeech dataset without ground truth transcriptions. To estimate the quality of\nASR hypotheses, a pre-trained language model (LM) is fine-tuned with\ncontrastive learning in a self-supervised learning manner. In experiments\nconducted on several unseen test datasets consisting of outputs from top\ncommercial ASR engines in various languages, the proposed referenceless metric\nobtains a much higher correlation with WER scores and their ranks than the\nperplexity metric from the state-of-art multi-lingual LM in all experiments,\nand also reduces WER by more than $7\\%$ when used for ensembling hypotheses.\nThe fine-tuned model and experiments are made available for the\nreproducibility: https://github.com/aixplain/NoRefER\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuksel_K/0/1/0/all/0/1\">Kamer Ali Yuksel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_T/0/1/0/all/0/1\">Thiago Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunduz_A/0/1/0/all/0/1\">Ahmet Gunduz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Badrashiny_M/0/1/0/all/0/1\">Mohamed Al-Badrashiny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Javadi_G/0/1/0/all/0/1\">Golara Javadi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt to GPT-3: Step-by-Step Thinking Instructions for Humor Generation. (arXiv:2306.13195v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13195","description":"<p>Artificial intelligence has made significant progress in natural language\nprocessing, with models like GPT-3 demonstrating impressive capabilities.\nHowever, these models still have limitations when it comes to complex tasks\nthat require an understanding of the user, such as mastering human comedy\nwriting strategies. This paper explores humor generation using GPT-3 by\nmodeling human comedy writing theory and leveraging step-by-step thinking\ninstructions. In addition, we explore the role of cognitive distance in\ncreating humor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuetian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_M/0/1/0/all/0/1\">Mei Si</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Adversarial Examples Jailbreak Large Language Models. (arXiv:2306.13213v1 [cs.CR])","link":"http://arxiv.org/abs/2306.13213","description":"<p>Recently, there has been a surge of interest in introducing vision into Large\nLanguage Models (LLMs). The proliferation of large Visual Language Models\n(VLMs), such as Flamingo, BLIP-2, and GPT-4, signifies an exciting convergence\nof advancements in both visual and language foundation models. Yet, the risks\nassociated with this integrative approach are largely unexamined. In this\npaper, we shed light on the security and safety implications of this trend.\nFirst, we underscore that the continuous and high-dimensional nature of the\nadditional visual input space intrinsically makes it a fertile ground for\nadversarial attacks. This unavoidably expands the attack surfaces of LLMs.\nSecond, we highlight that the broad functionality of LLMs also presents visual\nattackers with a wider array of achievable adversarial objectives, extending\nthe implications of security failures beyond mere misclassification. To\nelucidate these risks, we study adversarial examples in the visual input space\nof a VLM. Specifically, against MiniGPT-4, which incorporates safety mechanisms\nthat can refuse harmful instructions, we present visual adversarial examples\nthat can circumvent the safety mechanisms and provoke harmful behaviors of the\nmodel. Remarkably, we discover that adversarial examples, even if optimized on\na narrow, manually curated derogatory corpus against specific social groups,\ncan universally jailbreak the model's safety mechanisms. A single such\nadversarial example can generally undermine MiniGPT-4's safety, enabling it to\nheed a wide range of harmful instructions and produce harmful content far\nbeyond simply imitating the derogatory corpus used in optimization. Unveiling\nthese risks, we accentuate the urgent need for comprehensive risk assessments,\nrobust defense strategies, and the implementation of responsible practices for\nthe secure and safe utilization of VLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1\">Xiangyu Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_A/0/1/0/all/0/1\">Ashwinee Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengdi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1\">Prateek Mittal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiversiGATE: A Comprehensive Framework for Reliable Large Language Models. (arXiv:2306.13230v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13230","description":"<p>In this paper, we introduce DiversiGATE, a unified framework that\nconsolidates diverse methodologies for LLM verification. The proposed framework\ncomprises two main components: Diversification and Aggregation which provide a\nholistic perspective on existing verification approaches, such as\nSelf-Consistency, Math Prompter and WebGPT. Furthermore, we propose a novel\n`SelfLearner' model that conforms to the DiversiGATE framework which can learn\nfrom its own outputs and refine its performance over time, leading to improved\naccuracy. To evaluate the effectiveness of SelfLearner, we conducted a rigorous\nseries of experiments, including tests on synthetic data as well as on popular\narithmetic reasoning benchmarks such as GSM8K. Our results demonstrate that our\napproach outperforms traditional LLMs, achieving a considerable 54.8% -&gt; 61.8%\nimprovement on the GSM8K benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Imani_S/0/1/0/all/0/1\">Shima Imani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beyram_A/0/1/0/all/0/1\">Ali Beyram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_H/0/1/0/all/0/1\">Harsh Shrivastava</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolQA: A Dataset for LLM Question Answering with External Tools. (arXiv:2306.13304v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13304","description":"<p>Large Language Models (LLMs) have demonstrated impressive performance in\nvarious NLP tasks, but they still suffer from challenges such as hallucination\nand weak numerical reasoning. To overcome these challenges, external tools can\nbe used to enhance LLMs' question-answering abilities. However, current\nevaluation methods do not distinguish between questions that can be answered\nusing LLMs' internal knowledge and those that require external information\nthrough tool use. To address this issue, we introduce a new dataset called\nToolQA, which is designed to faithfully evaluate LLMs' ability to use external\ntools for question answering. Our development of ToolQA involved a scalable,\nautomated process for dataset curation, along with 13 specialized tools\ndesigned for interaction with external knowledge in order to answer questions.\nImportantly, we strive to minimize the overlap between our benchmark data and\nLLMs' pre-training data, enabling a more precise evaluation of LLMs' tool-use\nreasoning abilities. We conducted an in-depth diagnosis of existing tool-use\nLLMs to highlight their strengths, weaknesses, and potential improvements. Our\nfindings set a new benchmark for evaluating LLMs and suggest new directions for\nfuture advancements. Our data and code are freely available to the broader\nscientific community on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yuchen Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haotian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Effective and Compact Contextual Representation for Conformer Transducer Speech Recognition Systems. (arXiv:2306.13307v1 [eess.AS])","link":"http://arxiv.org/abs/2306.13307","description":"<p>Current ASR systems are mainly trained and evaluated at the utterance level.\nLong range cross utterance context can be incorporated. A key task is to derive\na suitable compact representation of the most relevant history contexts. In\ncontrast to previous researches based on either LSTM-RNN encoded histories that\nattenuate the information from longer range contexts, or frame level\nconcatenation of transformer context embeddings, in this paper compact\nlow-dimensional cross utterance contextual features are learned in the\nConformer-Transducer Encoder using specially designed attention pooling layers\nthat are applied over efficiently cached preceding utterances history vectors.\nExperiments on the 1000-hr Gigaspeech corpus demonstrate that the proposed\ncontextualized streaming Conformer-Transducers outperform the baseline using\nutterance internal context only with statistically significant WER reductions\nof 0.7% to 0.5% absolute (4.3% to 3.1% relative) on the dev and test data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Cui_M/0/1/0/all/0/1\">Mingyu Cui</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kang_J/0/1/0/all/0/1\">Jiawen Kang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Deng_J/0/1/0/all/0/1\">Jiajun Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yin_X/0/1/0/all/0/1\">Xi Yin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xie_Y/0/1/0/all/0/1\">Yutao Xie</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1\">Xunying Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mutually Guided Few-shot Learning for Relational Triple Extraction. (arXiv:2306.13310v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13310","description":"<p>Knowledge graphs (KGs), containing many entity-relation-entity triples,\nprovide rich information for downstream applications. Although extracting\ntriples from unstructured texts has been widely explored, most of them require\na large number of labeled instances. The performance will drop dramatically\nwhen only few labeled data are available. To tackle this problem, we propose\nthe Mutually Guided Few-shot learning framework for Relational Triple\nExtraction (MG-FTE). Specifically, our method consists of an entity-guided\nrelation proto-decoder to classify the relations firstly and a relation-guided\nentity proto-decoder to extract entities based on the classified relations. To\ndraw the connection between entity and relation, we design a proto-level fusion\nmodule to boost the performance of both entity extraction and relation\nclassification. Moreover, a new cross-domain few-shot triple extraction task is\nintroduced. Extensive experiments show that our method outperforms many\nstate-of-the-art methods by 12.6 F1 score on FewRel 1.0 (single-domain) and\n20.5 F1 score on FewRel 2.0 (cross-domain).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chengmei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shuai Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Bowei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chen Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lianghua He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Abstractive Text Summarization for Resumes With Cutting Edge NLP Transformers and LSTM. (arXiv:2306.13315v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13315","description":"<p>Text summarization is a fundamental task in natural language processing that\naims to condense large amounts of textual information into concise and coherent\nsummaries. With the exponential growth of content and the need to extract key\ninformation efficiently, text summarization has gained significant attention in\nrecent years. In this study, LSTM and pre-trained T5, Pegasus, BART and\nBART-Large model performances were evaluated on the open source dataset (Xsum,\nCNN/Daily Mail, Amazon Fine Food Review and News Summary) and the prepared\nresume dataset. This resume dataset consists of many information such as\nlanguage, education, experience, personal information, skills, and this data\nincludes 75 resumes. The primary objective of this research was to classify\nresume text. Various techniques such as LSTM, pre-trained models, and\nfine-tuned models were assessed using a dataset of resumes. The BART-Large\nmodel fine-tuned with the resume dataset gave the best performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mercan_O/0/1/0/all/0/1\">&#xd6;yk&#xfc; Berfin Mercan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavsak_S/0/1/0/all/0/1\">Sena Nur Cavsak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deliahmetoglu_A/0/1/0/all/0/1\">Aysu Deliahmetoglu</a> (Intern), <a href=\"http://arxiv.org/find/cs/1/au:+Tanberk_S/0/1/0/all/0/1\">Senem Tanberk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stress Testing BERT Anaphora Resolution Models for Reaction Extraction in Chemical Patents. (arXiv:2306.13379v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13379","description":"<p>The high volume of published chemical patents and the importance of a timely\nacquisition of their information gives rise to automating information\nextraction from chemical patents. Anaphora resolution is an important component\nof comprehensive information extraction, and is critical for extracting\nreactions. In chemical patents, there are five anaphoric relations of interest:\nco-reference, transformed, reaction associated, work up, and contained. Our\ngoal is to investigate how the performance of anaphora resolution models for\nreaction texts in chemical patents differs in a noise-free and noisy\nenvironment and to what extent we can improve the robustness against noise of\nthe model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yueh_C/0/1/0/all/0/1\">Chieling Yueh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1\">Evangelos Kanoulas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_B/0/1/0/all/0/1\">Bruno Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_C/0/1/0/all/0/1\">Camilo Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhondi_S/0/1/0/all/0/1\">Saber Akhondi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Long-range Language Modeling with Self-retrieval. (arXiv:2306.13421v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13421","description":"<p>Retrieval-augmented language models (LMs) have received much attention\nrecently. However, typically the retriever is not trained jointly as a native\ncomponent of the LM, but added to an already-pretrained LM, which limits the\nability of the LM and the retriever to adapt to one another. In this work, we\npropose the Retrieval-Pretrained Transformer (RPT), an architecture and\ntraining procedure for jointly training a retrieval-augmented LM from scratch\nfor the task of modeling long texts. Given a recently generated text chunk in a\nlong document, the LM computes query representations, which are then used to\nretrieve earlier chunks in the document, located potentially tens of thousands\nof tokens before. Information from retrieved chunks is fused into the LM\nrepresentations to predict the next target chunk. We train the retriever\ncomponent with a semantic objective, where the goal is to retrieve chunks that\nincrease the probability of the next chunk, according to a reference LM. We\nevaluate RPT on four long-range language modeling tasks, spanning books, code,\nand mathematical writing, and demonstrate that RPT improves retrieval quality\nand subsequently perplexity across the board compared to strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rubin_O/0/1/0/all/0/1\">Ohad Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Descriptive Image Captioning via Semipermeable Maximum Likelihood Estimation. (arXiv:2306.13460v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13460","description":"<p>Image captioning aims to describe visual content in natural language. As 'a\npicture is worth a thousand words', there could be various correct descriptions\nfor an image. However, with maximum likelihood estimation as the training\nobjective, the captioning model is penalized whenever its prediction mismatches\nwith the label. For instance, when the model predicts a word expressing richer\nsemantics than the label, it will be penalized and optimized to prefer more\nconcise expressions, referred to as conciseness optimization. In contrast,\npredictions that are more concise than labels lead to richness optimization.\nSuch conflicting optimization directions could eventually result in the model\ngenerating general descriptions. In this work, we introduce Semipermeable\nMaxImum Likelihood Estimation (SMILE), which allows richness optimization while\nblocking conciseness optimization, thus encouraging the model to generate\nlonger captions with more details. Extensive experiments on two mainstream\nimage captioning datasets MSCOCO and Flickr30K demonstrate that SMILE\nsignificantly enhances the descriptiveness of generated captions. We further\nprovide in-depth investigations to facilitate a better understanding of how\nSMILE works.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1\">Zihao Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1\">Anwen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qin Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Incorporating Graph Information in Transformer-based AMR Parsing. (arXiv:2306.13467v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13467","description":"<p>Abstract Meaning Representation (AMR) is a Semantic Parsing formalism that\naims at providing a semantic graph abstraction representing a given text.\nCurrent approaches are based on autoregressive language models such as BART or\nT5, fine-tuned through Teacher Forcing to obtain a linearized version of the\nAMR graph from a sentence. In this paper, we present LeakDistill, a model and\nmethod that explores a modification to the Transformer architecture, using\nstructural adapters to explicitly incorporate graph information into the\nlearned representations and improve AMR parsing performance. Our experiments\nshow how, by employing word-to-node alignment to embed graph structural\ninformation into the encoder at training time, we can obtain state-of-the-art\nAMR parsing through self-knowledge distillation, even without the use of\nadditional data. We release the code at\n\\url{<a href=\"http://www.github.com/sapienzanlp/LeakDistill\">this http URL</a>}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vasylenko_P/0/1/0/all/0/1\">Pavlo Vasylenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cabot_P/0/1/0/all/0/1\">Pere-Llu&#xed;s Huguet Cabot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorenzo_A/0/1/0/all/0/1\">Abelardo Carlos Mart&#xed;nez Lorenzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navigli_R/0/1/0/all/0/1\">Roberto Navigli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-Infused Self Attention Transformers. (arXiv:2306.13501v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13501","description":"<p>Transformer-based language models have achieved impressive success in various\nnatural language processing tasks due to their ability to capture complex\ndependencies and contextual information using self-attention mechanisms.\nHowever, they are not without limitations. These limitations include\nhallucinations, where they produce incorrect outputs with high confidence, and\nalignment issues, where they generate unhelpful and unsafe outputs for human\nusers. These limitations stem from the absence of implicit and missing context\nin the data alone. To address this, researchers have explored augmenting these\nmodels with external knowledge from knowledge graphs to provide the necessary\nadditional context. However, the ad-hoc nature of existing methods makes it\ndifficult to properly analyze the effects of knowledge infusion on the many\nmoving parts or components of a transformer. This paper introduces a systematic\nmethod for infusing knowledge into different components of a transformer-based\nmodel. A modular framework is proposed to identify specific components within\nthe transformer architecture, such as the self-attention mechanism, encoder\nlayers, or the input embedding layer, where knowledge infusion can be applied.\nAdditionally, extensive experiments are conducted on the General Language\nUnderstanding Evaluation (GLUE) benchmark tasks, and the findings are reported.\nThis systematic approach aims to facilitate more principled approaches to\nincorporating knowledge into language model architectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1\">Kaushik Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zi_Y/0/1/0/all/0/1\">Yuxin Zi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_V/0/1/0/all/0/1\">Vignesh Narayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_M/0/1/0/all/0/1\">Manas Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Multimodal Large Language Models. (arXiv:2306.13549v1 [cs.CV])","link":"http://arxiv.org/abs/2306.13549","description":"<p>Multimodal Large Language Model (MLLM) recently has been a new rising\nresearch hotspot, which uses powerful Large Language Models (LLMs) as a brain\nto perform multimodal tasks. The surprising emergent capabilities of MLLM, such\nas writing stories based on images and OCR-free math reasoning, are rare in\ntraditional methods, suggesting a potential path to artificial general\nintelligence. In this paper, we aim to trace and summarize the recent progress\nof MLLM. First of all, we present the formulation of MLLM and delineate its\nrelated concepts. Then, we discuss the key techniques and applications,\nincluding Multimodal Instruction Tuning (M-IT), Multimodal In-Context Learning\n(M-ICL), Multimodal Chain of Thought (M-CoT), and LLM-Aided Visual Reasoning\n(LAVR). Finally, we discuss existing challenges and point out promising\nresearch directions. In light of the fact that the era of MLLM has only just\nbegun, we will keep updating this survey and hope it can inspire more research.\nAn associated GitHub link collecting the latest papers is available at\nhttps://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_S/0/1/0/all/0/1\">Shukang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chaoyou Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sirui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"System-Level Natural Language Feedback. (arXiv:2306.13588v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13588","description":"<p>Natural language (NL) feedback contains rich information about the user\nexperience. Existing studies focus on an instance-level approach, where\nfeedback is used to refine specific examples, disregarding its system-wide\napplication. This paper proposes a general framework for unlocking the\nsystem-level use of NL feedback. We show how to use feedback to formalize\nsystem-level design decisions in a human-in-the-loop-process -- in order to\nproduce better models. In particular this is done through: (i) metric design\nfor tasks; and (ii) language model prompt design for refining model responses.\nWe conduct two case studies of this approach for improving search query\ngeneration and dialog response generation, demonstrating the effectiveness of\nthe use of system-level feedback. We show the combination of system-level\nfeedback and instance-level feedback brings further gains, and that human\nwritten instance-level feedback results in more grounded refinements than\nGPT-3.5 written ones, underlying the importance of human feedback for building\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Weizhe Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Margin Maximization in Attention Mechanism. (arXiv:2306.13596v1 [cs.LG])","link":"http://arxiv.org/abs/2306.13596","description":"<p>Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where,\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are tunable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as a token separation mechanism. Remarkably, our results\nare applicable to general data and precisely characterize $\\textit{optimality}$\nof tokens in terms of the value embeddings $\\boldsymbol{Xv}$ and problem\ngeometry. We also provide a broader regularization path analysis that\nestablishes the margin maximizing nature of attention even for nonlinear\nprediction heads. When optimizing $\\boldsymbol{v}$ and $\\boldsymbol{p}$\nsimultaneously with logistic loss, we identify conditions under which the\nregularization paths directionally converge to their respective hard-margin SVM\nsolutions where $\\boldsymbol{v}$ separates the input features based on their\nlabels. Interestingly, the SVM formulation of $\\boldsymbol{p}$ is influenced by\nthe support vector geometry of $\\boldsymbol{v}$. Finally, we verify our\ntheoretical findings via numerical experiments and provide insights.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuechen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GKD: Generalized Knowledge Distillation for Auto-regressive Sequence Models. (arXiv:2306.13649v1 [cs.LG])","link":"http://arxiv.org/abs/2306.13649","description":"<p>Knowledge distillation is commonly used for compressing neural networks to\nreduce their inference cost and memory footprint. However, current distillation\nmethods for auto-regressive models, such as generative language models (LMs),\nsuffer from two key issues: (1) distribution mismatch between output sequences\nduring training and the sequences generated by the student during its\ndeployment, and (2) model under-specification, where the student model may not\nbe expressive enough to fit the teacher's distribution. To address these\nissues, we propose Generalized Knowledge Distillation (GKD). GKD mitigates\ndistribution mismatch by sampling output sequences from the student during\ntraining. Furthermore, GKD handles model under-specification by optimizing\nalternative divergences, such as reverse KL, that focus on generating samples\nfrom the student that are likely under the teacher's distribution. We\ndemonstrate that GKD outperforms commonly-used approaches for distilling LLMs\non summarization, machine translation, and arithmetic reasoning tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1\">Rishabh Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1\">Nino Vieillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanczyk_P/0/1/0/all/0/1\">Piotr Stanczyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_S/0/1/0/all/0/1\">Sabela Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1\">Matthieu Geist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachem_O/0/1/0/all/0/1\">Olivier Bachem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bring Your Own Data! Self-Supervised Evaluation for Large Language Models. (arXiv:2306.13651v1 [cs.CL])","link":"http://arxiv.org/abs/2306.13651","description":"<p>With the rise of Large Language Models (LLMs) and their ubiquitous deployment\nin diverse domains, measuring language model behavior on realistic data is\nimperative. For example, a company deploying a client-facing chatbot must\nensure that the model will not respond to client requests with profanity.\nCurrent evaluations approach this problem using small, domain-specific datasets\nwith human-curated labels. These evaluation sets are often sampled from a\nnarrow and simplified distribution, and data sources can unknowingly be leaked\ninto the training set which can lead to misleading evaluations. To bypass these\ndrawbacks, we propose a framework for self-supervised evaluation of LLMs by\nanalyzing their sensitivity or invariance to transformations on the input text.\nSelf-supervised evaluation can directly monitor LLM behavior on datasets\ncollected in the wild or streamed during live model deployment. We demonstrate\nself-supervised evaluation strategies for measuring closed-book knowledge,\ntoxicity, and long-range context dependence, in addition to sensitivity to\ngrammatical structure and tokenization errors. When comparisons to similar\nhuman-labeled benchmarks are available, we find strong correlations between\nself-supervised and human-supervised evaluations. The self-supervised paradigm\ncomplements current evaluation strategies that rely on labeled data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Neel Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1\">Khalid Saifullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchenbauer_J/0/1/0/all/0/1\">John Kirchenbauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_M/0/1/0/all/0/1\">Manli Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aniruddha Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1\">Jonas Geiping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Determinantal Beam Search. (arXiv:2106.07400v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.07400","description":"<p>Beam search is a go-to strategy for decoding neural sequence models. The\nalgorithm can naturally be viewed as a subset optimization problem, albeit one\nwhere the corresponding set function does not reflect interactions between\ncandidates. Empirically, this leads to sets often exhibiting high overlap,\ne.g., strings may differ by only a single word. Yet in use-cases that call for\nmultiple solutions, a diverse or representative set is often desired. To\naddress this issue, we propose a reformulation of beam search, which we call\ndeterminantal beam search. Determinantal beam search has a natural relationship\nto determinantal point processes (DPPs), models over sets that inherently\nencode intra-set interactions. By posing iterations in beam search as a series\nof subdeterminant maximization problems, we can turn the algorithm into a\ndiverse subset selection process. In a case study, we use the string\nsubsequence kernel to explicitly encourage n-gram coverage in text generated\nfrom a sequence model. We observe that our algorithm offers competitive\nperformance against other diverse set generation strategies in the context of\nlanguage generation, while providing a more general approach to optimizing for\ndiversity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forster_M/0/1/0/all/0/1\">Martina Forster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Gender Fairness of Pre-Trained Language Models without Catastrophic Forgetting. (arXiv:2110.05367v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.05367","description":"<p>Existing studies addressing gender bias of pre-trained language models,\nusually build a small gender-neutral data set and conduct a second phase\npre-training on the model with such data. However, given the limited size and\nconcentrated focus of the gender-neutral data, catastrophic forgetting would\noccur during second-phase pre-training. Forgetting information in the original\ntraining data may damage the model's downstream performance by a large margin.\nIn this work, we empirically show that catastrophic forgetting occurs in such\nmethods by evaluating them with general NLP tasks in GLUE. Then, we propose a\nnew method, GEnder Equality Prompt (GEEP), to improve gender fairness of\npre-trained models with less forgetting. GEEP freezes the pre-trained model and\nlearns gender-related prompts with gender-neutral data. Empirical results show\nthat GEEP not only achieves SOTA performances on gender fairness tasks, but\nalso forgets less and performs better on GLUE by a large margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fatemi_Z/0/1/0/all/0/1\">Zahra Fatemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"INSCIT: Information-Seeking Conversations with Mixed-Initiative Interactions. (arXiv:2207.00746v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.00746","description":"<p>In an information-seeking conversation, a user may ask questions that are\nunder-specified or unanswerable. An ideal agent would interact by initiating\ndifferent response types according to the available knowledge sources. However,\nmost current studies either fail to or artificially incorporate such agent-side\ninitiative. This work presents InSCIt, a dataset for Information-Seeking\nConversations with mixed-initiative Interactions. It contains 4.7K user-agent\nturns from 805 human-human conversations where the agent searches over\nWikipedia and either directly answers, asks for clarification, or provides\nrelevant information to address user queries. The data supports two subtasks,\nevidence passage identification and response generation, as well as a human\nevaluation protocol to assess model performance. We report results of two\nsystems based on state-of-the-art models of conversational knowledge\nidentification and open-domain question answering. Both systems significantly\nunderperform humans, suggesting ample room for improvement in future studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zeqiu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parish_R/0/1/0/all/0/1\">Ryu Parish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ammanabrolu_P/0/1/0/all/0/1\">Prithviraj Ammanabrolu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Natural Bias for Language Generation Models. (arXiv:2212.09686v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09686","description":"<p>After just a few hundred training updates, a standard probabilistic model for\nlanguage generation has likely not yet learnt many semantic or syntactic rules\nof natural language, making it difficult to estimate the probability\ndistribution over next tokens. Yet around this point, these models have\nidentified a simple, loss-minimising behaviour: to output the unigram\ndistribution of the target training corpus. The use of such a heuristic raises\nthe question: Can we initialise our models with this behaviour and save\nprecious compute resources and model capacity? Here we show that we can\neffectively endow standard neural language generation models with a separate\nmodule that reflects unigram frequency statistics as prior knowledge, simply by\ninitialising the bias term in a model's final linear layer with the log-unigram\ndistribution. We use neural machine translation as a test bed for this simple\ntechnique and observe that it: (i) improves learning efficiency; (ii) achieves\nbetter overall performance; and perhaps most importantly (iii) appears to\ndisentangle strong frequency effects by encouraging the model to specialise in\nnon-frequency-related aspects of language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stokowiec_W/0/1/0/all/0/1\">Wojciech Stokowiec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rimell_L/0/1/0/all/0/1\">Laura Rimell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuncoro_A/0/1/0/all/0/1\">Adhiguna Kuncoro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions. (arXiv:2212.10509v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10509","description":"<p>Prompting-based large language models (LLMs) are surprisingly powerful at\ngenerating natural language reasoning steps or Chains-of-Thoughts (CoT) for\nmulti-step question answering (QA). They struggle, however, when the necessary\nknowledge is either unavailable to the LLM or not up-to-date within its\nparameters. While using the question to retrieve relevant text from an external\nknowledge source helps LLMs, we observe that this one-step retrieve-and-read\napproach is insufficient for multi-step QA. Here, \\textit{what to retrieve}\ndepends on \\textit{what has already been derived}, which in turn may depend on\n\\textit{what was previously retrieved}. To address this, we propose IRCoT, a\nnew approach for multi-step QA that interleaves retrieval with steps\n(sentences) in a CoT, guiding the retrieval with CoT and in turn using\nretrieved results to improve CoT. Using IRCoT with GPT3 substantially improves\nretrieval (up to 21 points) as well as downstream QA (up to 15 points) on four\ndatasets: HotpotQA, 2WikiMultihopQA, MuSiQue, and IIRC. We observe similar\nsubstantial gains in out-of-distribution (OOD) settings as well as with much\nsmaller models such as Flan-T5-large without additional training. IRCoT reduces\nmodel hallucination, resulting in factually more accurate CoT reasoning. Code,\ndata, and prompts are available at \\url{https://github.com/stonybrooknlp/ircot}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1\">Harsh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Summarize the Past to Predict the Future: Natural Language Descriptions of Context Boost Multimodal Object Interaction. (arXiv:2301.09209v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2301.09209","description":"<p>We study object interaction anticipation in egocentric videos. This task\nrequires an understanding of the spatiotemporal context formed by past actions\non objects, coined action context. We propose TransFusion, a multimodal\ntransformer-based architecture. It exploits the representational power of\nlanguage by summarising the action context. TransFusion leverages pre-trained\nimage captioning and vision-language models to extract the action context from\npast video frames. This action context together with the next video frame is\nprocessed by the multimodal fusion module to forecast the next object\ninteraction. Our model enables more efficient end-to-end learning. The large\npre-trained language models add common sense and a generalisation capability.\nExperiments on Ego4D and EPIC-KITCHENS-100 show the effectiveness of our\nmultimodal fusion model. They also highlight the benefits of using\nlanguage-based context summaries in a task where vision seems to suffice. Our\nmethod outperforms state-of-the-art approaches by 40.4% in relative terms in\noverall mAP on the Ego4D test set. We validate the effectiveness of TransFusion\nvia experiments on EPIC-KITCHENS-100. Video and code are available at\nhttps://eth-ait.github.io/transfusion-proj/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pasca_R/0/1/0/all/0/1\">Razvan-George Pasca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavryushin_A/0/1/0/all/0/1\">Alexey Gavryushin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_Y/0/1/0/all/0/1\">Yen-Ling Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1\">Luc Van Gool</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilliges_O/0/1/0/all/0/1\">Otmar Hilliges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xi Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extending the Pre-Training of BLOOM for Improved Support of Traditional Chinese: Models, Methods and Results. (arXiv:2303.04715v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.04715","description":"<p>In this paper we present the multilingual language model BLOOM-zh that\nfeatures enhanced support for Traditional Chinese. BLOOM-zh has its origins in\nthe open-source BLOOM models presented by BigScience in 2022. Starting from\nreleased models, we extended the pre-training of BLOOM by additional 7.4\nbillion tokens in Traditional Chinese and English covering a variety of domains\nsuch as news articles, books, encyclopedias, educational materials as well as\nspoken language. In order to show the properties of BLOOM-zh, both existing and\nnewly created benchmark scenarios are used for evaluating the performance.\nBLOOM-zh outperforms its predecessor on most Traditional Chinese benchmarks\nwhile maintaining its English capability. We release all our models to the\nresearch community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ennen_P/0/1/0/all/0/1\">Philipp Ennen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_P/0/1/0/all/0/1\">Po-Chun Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang-Le Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yen-Chen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yin-Hsiang Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chin-Tung Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-Shan Shiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wei-Yun Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Automated Prompting: Are We Actually Doing Better?. (arXiv:2304.03609v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03609","description":"<p>Current literature demonstrates that Large Language Models (LLMs) are great\nfew-shot learners, and prompting significantly increases their performance on a\nrange of downstream tasks in a few-shot learning setting. An attempt to\nautomate human-led prompting followed, with some progress achieved. In\nparticular, subsequent work demonstrates automation can outperform fine-tuning\nin certain K-shot learning scenarios.\n</p>\n<p>In this paper, we revisit techniques for automated prompting on six different\ndownstream tasks and a larger range of K-shot learning settings. We find that\nautomated prompting does not consistently outperform simple manual prompts. Our\nwork suggests that, in addition to fine-tuning, manual prompts should be used\nas a baseline in this line of research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yulin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiren Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1\">Ilia Shumailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullins_R/0/1/0/all/0/1\">Robert Mullins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1\">Yarin Gal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Supplementary Features of BiLSTM for Enhanced Sequence Labeling. (arXiv:2305.19928v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19928","description":"<p>Sequence labeling tasks require the computation of sentence representations\nfor each word within a given sentence. A prevalent method incorporates a\nBi-directional Long Short-Term Memory (BiLSTM) layer to enhance the sequence\nstructure information. However, empirical evidence Li (2020) suggests that the\ncapacity of BiLSTM to produce sentence representations for sequence labeling\ntasks is inherently limited. This limitation primarily results from the\nintegration of fragments from past and future sentence representations to\nformulate a complete sentence representation. In this study, we observed that\nthe entire sentence representation, found in both the first and last cells of\nBiLSTM, can supplement each the individual sentence representation of each\ncell. Accordingly, we devised a global context mechanism to integrate entire\nfuture and past sentence representations into each cell's sentence\nrepresentation within the BiLSTM framework. By incorporating the BERT model\nwithin BiLSTM as a demonstration, and conducting exhaustive experiments on nine\ndatasets for sequence labeling tasks, including named entity recognition (NER),\npart of speech (POS) tagging, and End-to-End Aspect-Based sentiment analysis\n(E2E-ABSA). We noted significant improvements in F1 scores and accuracy across\nall examined datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Conglei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_K/0/1/0/all/0/1\">Kun Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongguang Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEACE: Perfect linear concept erasure in closed form. (arXiv:2306.03819v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.03819","description":"<p>Concept erasure aims to remove specified features from a representation. It\ncan improve fairness (e.g. preventing a classifier from using gender or race)\nand interpretability (e.g. removing a concept to observe changes in model\nbehavior). We introduce LEAst-squares Concept Erasure (LEACE), a closed-form\nmethod which provably prevents all linear classifiers from detecting a concept\nwhile changing the representation as little as possible, as measured by a broad\nclass of norms. We apply LEACE to large language models with a novel procedure\ncalled \"concept scrubbing,\" which erases target concept information from every\nlayer in the network. We demonstrate our method on two tasks: measuring the\nreliance of language models on part-of-speech information, and reducing gender\nbias in BERT embeddings. Code is available at\nhttps://github.com/EleutherAI/concept-erasure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belrose_N/0/1/0/all/0/1\">Nora Belrose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_Joseph_D/0/1/0/all/0/1\">David Schneider-Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visually-Grounded Descriptions Improve Zero-Shot Image Classification. (arXiv:2306.06077v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2306.06077","description":"<p>Language-vision models like CLIP have made significant progress in zero-shot\nvision tasks, such as zero-shot image classification (ZSIC). However,\ngenerating specific and expressive class descriptions remains a major\nchallenge. Existing approaches suffer from granularity and label ambiguity\nissues. To tackle these challenges, we propose V-GLOSS: Visual Glosses, a novel\nmethod leveraging modern language models and semantic knowledge bases to\nproduce visually-grounded class descriptions. We demonstrate V-GLOSS's\neffectiveness by achieving state-of-the-art results on benchmark ZSIC datasets\nincluding ImageNet and STL-10. In addition, we introduce a silver dataset with\nclass descriptions generated by V-GLOSS, and show its usefulness for vision\ntasks. We make available our code and dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ogezi_M/0/1/0/all/0/1\">Michael Ogezi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-in-the-Loop through Chain-of-Thought. (arXiv:2306.07932v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.07932","description":"<p>While the emergence of powerful language models along with Chain-of-thought\nprompting has made automation more and more omnipresent, it sometimes\ndemonstrates its weakness in long-term or multi-step logical reasoning. For\nexample, users don't always get desirable answers for complex mathematical\nproblems without human involvement. Against this background, we present the\nManual Correction System (MCS) -- a human-in-the-loop system enhanced by\nChain-of-Thought prompting, which explores how manual correction of sub-logics\nin rationales can improve LLM's reasoning performance. Moving one step forward,\nconsidering a system with human-in-the-loop involves more than having humans\nimprove performance but also controlling the cost. Therefore, we post a\nCost-utility Analysis Model for Human-in-the-Loop systems (CAMLOP) based on\nclassical economics theory to analyze, quantify and balance the utility and the\ncorresponding cost. We conduct experiments of MCS and CAMLOP with twelve\ndatasets. A significant advantage w.r.t cost and utility proves its superiority\nover strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zefan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenjuan Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Word Models to World Models: Translating from Natural Language to the Probabilistic Language of Thought. (arXiv:2306.12672v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.12672","description":"<p>How does language inform our downstream thinking? In particular, how do\nhumans make meaning from language--and how can we leverage a theory of\nlinguistic meaning to build machines that think in more human-like ways? In\nthis paper, we propose rational meaning construction, a computational framework\nfor language-informed thinking that combines neural language models with\nprobabilistic models for rational inference. We frame linguistic meaning as a\ncontext-sensitive mapping from natural language into a probabilistic language\nof thought (PLoT)--a general-purpose symbolic substrate for generative world\nmodeling. Our architecture integrates two computational tools that have not\npreviously come together: we model thinking with probabilistic programs, an\nexpressive representation for commonsense reasoning; and we model meaning\nconstruction with large language models (LLMs), which support broad-coverage\ntranslation from natural language utterances to code expressions in a\nprobabilistic programming language. We illustrate our framework through\nexamples covering four core domains from cognitive science: probabilistic\nreasoning, logical and relational reasoning, visual and physical reasoning, and\nsocial reasoning. In each, we show that LLMs can generate context-sensitive\ntranslations that capture pragmatically-appropriate linguistic meanings, while\nBayesian inference with the generated programs supports coherent and robust\ncommonsense reasoning. We extend our framework to integrate\ncognitively-motivated symbolic modules (physics simulators, graphics engines,\nand planning algorithms) to provide a unified commonsense thinking interface\nfrom language. Finally, we explore how language can drive the construction of\nworld models themselves. We hope this work will provide a roadmap towards\ncognitive models and AI systems that synthesize the insights of both modern and\nclassical computational perspectives.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wong_L/0/1/0/all/0/1\">Lionel Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grand_G/0/1/0/all/0/1\">Gabriel Grand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lew_A/0/1/0/all/0/1\">Alexander K. Lew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansinghka_V/0/1/0/all/0/1\">Vikash K. Mansinghka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning. (arXiv:2306.13089v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.13089","description":"<p>Molecule property prediction has gained significant attention in recent\nyears. The main bottleneck is the label insufficiency caused by expensive lab\nexperiments. In order to alleviate this issue and to better leverage textual\nknowledge for tasks, this study investigates the feasibility of employing\nnatural language instructions to accomplish molecule-related tasks in a\nzero-shot setting. We discover that existing molecule-text models perform\npoorly in this setting due to inadequate treatment of instructions and limited\ncapacity for graphs. To overcome these issues, we propose GIMLET, which unifies\nlanguage models for both graph and text data. By adopting generalized position\nembedding, our model is extended to encode both graph structures and\ninstruction text without additional graph encoding modules. GIMLET also\ndecouples encoding of the graph from tasks instructions in the attention\nmechanism, enhancing the generalization of graph features across novel tasks.\nWe construct a dataset consisting of more than two thousand molecule tasks with\ncorresponding instructions derived from task descriptions. We pretrain GIMLET\non the molecule tasks along with instructions, enabling the model to transfer\neffectively to a broad range of tasks. Experimental results demonstrate that\nGIMLET significantly outperforms molecule-text baselines in instruction-based\nzero-shot learning, even achieving closed results to supervised GNN models on\ntasks such as toxcast and muv.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiteng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengchao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hannan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhi-Hong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MarioGPT: Open-Ended Text2Level Generation through Large Language Models. (arXiv:2302.05981v2 [cs.AI] CROSS LISTED)","link":"http://arxiv.org/abs/2302.05981","description":"<p>Procedural Content Generation (PCG) algorithms provide a technique to\ngenerate complex and diverse environments in an automated way. However, while\ngenerating content with PCG methods is often straightforward, generating\nmeaningful content that reflects specific intentions and constraints remains\nchallenging. Furthermore, many PCG algorithms lack the ability to generate\ncontent in an open-ended manner. Recently, Large Language Models (LLMs) have\nshown to be incredibly effective in many diverse domains. These trained LLMs\ncan be fine-tuned, re-using information and accelerating training for new\ntasks. In this work, we introduce MarioGPT, a fine-tuned GPT2 model trained to\ngenerate tile-based game levels, in our case Super Mario Bros levels. We show\nthat MarioGPT can not only generate diverse levels, but can be text-prompted\nfor controllable level generation, addressing one of the key challenges of\ncurrent PCG techniques. As far as we know, MarioGPT is the first text-to-level\nmodel. We also combine MarioGPT with novelty search, enabling it to generate\ndiverse levels with varying play-style dynamics (i.e. player paths). This\ncombination allows for the open-ended generation of an increasingly diverse\nrange of content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1\">Shyam Sudhakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Duque_M/0/1/0/all/0/1\">Miguel Gonz&#xe1;lez-Duque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glanois_C/0/1/0/all/0/1\">Claire Glanois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freiberger_M/0/1/0/all/0/1\">Matthias Freiberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najarro_E/0/1/0/all/0/1\">Elias Najarro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1\">Sebastian Risi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-06-25T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}