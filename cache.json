{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-17T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Understanding AI Cognition: A Neural Module for Inference Inspired by Human Memory Mechanisms. (arXiv:2310.09297v1 [cs.LG])","link":"http://arxiv.org/abs/2310.09297","description":"<p>How humans and machines make sense of current inputs for relation reasoning\nand question-answering while putting the perceived information into context of\nour past memories, has been a challenging conundrum in cognitive science and\nartificial intelligence. Inspired by human brain's memory system and cognitive\narchitectures, we propose a PMI framework that consists of perception, memory\nand inference components. Notably, the memory module comprises working and\nlong-term memory, with the latter endowed with a higher-order structure to\nretain more accumulated knowledge and experiences. Through a differentiable\ncompetitive write access, current perceptions update working memory, which is\nlater merged with long-term memory via outer product associations, averting\nmemory overflow and minimizing information conflicts. In the inference module,\nrelevant information is retrieved from two separate memory origins and\nassociatively integrated to attain a more comprehensive and precise\ninterpretation of current perceptions. We exploratively apply our PMI to\nimprove prevailing Transformers and CNN models on question-answering tasks like\nbAbI-20k and Sort-of-CLEVR datasets, as well as relation calculation and image\nclassification tasks, and in each case, our PMI enhancements consistently\noutshine their original counterparts significantly. Visualization analyses\nreveal that memory consolidation, along with the interaction and integration of\ninformation from diverse memory sources, substantially contributes to the model\neffectiveness on inference tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xiangyu Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1\">Piao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ruizheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhicheng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ranking LLM-Generated Loop Invariants for Program Verification. (arXiv:2310.09342v1 [cs.PL])","link":"http://arxiv.org/abs/2310.09342","description":"<p>Synthesizing inductive loop invariants is fundamental to automating program\nverification. In this work, we observe that Large Language Models (such as\ngpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of\nprograms in a 0-shot setting, yet require several samples to generate the\ncorrect invariants. This can lead to a large number of calls to a program\nverifier to establish an invariant. To address this issue, we propose a {\\it\nre-ranking} approach for the generated results of LLMs. We have designed a\nranker that can distinguish between correct inductive invariants and incorrect\nattempts based on the problem definition. The ranker is optimized as a\ncontrastive ranker. Experimental results demonstrate that this re-ranking\nmechanism significantly improves the ranking of correct invariants among the\ngenerated candidates, leading to a notable reduction in the number of calls to\na verifier.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_S/0/1/0/all/0/1\">Shuvendu K. Lahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhoury_S/0/1/0/all/0/1\">Sarah Fakhoury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musuvathi_M/0/1/0/all/0/1\">Madanlal Musuvathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_A/0/1/0/all/0/1\">Akash Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1\">Aseem Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senthilnathan_A/0/1/0/all/0/1\">Aditya Senthilnathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Rahul Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swamy_N/0/1/0/all/0/1\">Nikhil Swamy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents. (arXiv:2310.09343v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09343","description":"<p>Human-like chatbots necessitate the use of commonsense reasoning in order to\neffectively comprehend and respond to implicit information present within\nconversations. Achieving such coherence and informativeness in responses,\nhowever, is a non-trivial task. Even for large language models (LLMs), the task\nof identifying and aggregating key evidence within a single hop presents a\nsubstantial challenge. This complexity arises because such evidence is\nscattered across multiple turns in a conversation, thus necessitating\nintegration over multiple hops. Hence, our focus is to facilitate such\nmulti-hop reasoning over a dialogue context, namely dialogue chain-of-thought\n(CoT) reasoning. To this end, we propose a knowledge distillation framework\nthat leverages LLMs as unreliable teachers and selectively distills consistent\nand helpful rationales via alignment filters. We further present DOCTOR, a\nDialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for\nresponse generation. We conduct extensive experiments to show that enhancing\ndialogue agents with high-quality rationales from DOCTOR significantly improves\nthe quality of their responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chae_H/0/1/0/all/0/1\">Hyungjoo Chae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yongho Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_K/0/1/0/all/0/1\">Kai Tzu-iunn Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taeyoon Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minjin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongha Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_J/0/1/0/all/0/1\">Jinyoung Yeo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Domain Adaption for Neural Information Retrieval. (arXiv:2310.09350v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09350","description":"<p>Neural information retrieval requires costly annotated data for each target\ndomain to be competitive. Synthetic annotation by query generation using Large\nLanguage Models or rule-based string manipulation has been proposed as an\nalternative, but their relative merits have not been analysed. In this paper,\nwe compare both methods head-to-head using the same neural IR architecture. We\nfocus on the BEIR benchmark, which includes test datasets from several domains\nwith no training data, and explore two scenarios: zero-shot, where the\nsupervised system is trained in a large out-of-domain dataset (MS-MARCO); and\nunsupervised domain adaptation, where, in addition to MS-MARCO, the system is\nfine-tuned in synthetic data from the target domain. Our results indicate that\nLarge Language Models outperform rule-based methods in all scenarios by a large\nmargin, and, more importantly, that unsupervised domain adaptation is effective\ncompared to applying a supervised IR system in a zero-shot fashion. In addition\nwe explore several sizes of open Large Language Models to generate synthetic\ndata and find that a medium-sized model suffices. Code and models are publicly\navailable for reproducibility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dominguez_C/0/1/0/all/0/1\">Carlos Dominguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campos_J/0/1/0/all/0/1\">Jon Ander Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azkune_G/0/1/0/all/0/1\">Gorka Azkune</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Computational Approach to Style in American Poetry. (arXiv:2310.09357v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09357","description":"<p>We develop a quantitative method to assess the style of American poems and to\nvisualize a collection of poems in relation to one another. Qualitative poetry\ncriticism helped guide our development of metrics that analyze various\northographic, syntactic, and phonemic features. These features are used to\ndiscover comprehensive stylistic information from a poem's multi-layered latent\nstructure, and to compute distances between poems in this space. Visualizations\nprovide ready access to the analytical components. We demonstrate our method on\nseveral collections of poetry, showing that it better delineates poetry style\nthan the traditional word-occurrence features that are used in typical text\nanalysis algorithms. Our method has potential applications to academic research\nof texts, to research of the intuitive personal response to poetry, and to\nmaking recommendations to readers based on their favorite poems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaplan_D/0/1/0/all/0/1\">David M. Kaplan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1\">David M. Blei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Surveying the Landscape of Text Summarization with Deep Learning: A Comprehensive Review. (arXiv:2310.09411v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09411","description":"<p>In recent years, deep learning has revolutionized natural language processing\n(NLP) by enabling the development of models that can learn complex\nrepresentations of language data, leading to significant improvements in\nperformance across a wide range of NLP tasks. Deep learning models for NLP\ntypically use large amounts of data to train deep neural networks, allowing\nthem to learn the patterns and relationships in language data. This is in\ncontrast to traditional NLP approaches, which rely on hand-engineered features\nand rules to perform NLP tasks. The ability of deep neural networks to learn\nhierarchical representations of language data, handle variable-length input\nsequences, and perform well on large datasets makes them well-suited for NLP\napplications. Driven by the exponential growth of textual data and the\nincreasing demand for condensed, coherent, and informative summaries, text\nsummarization has been a critical research area in the field of NLP. Applying\ndeep learning to text summarization refers to the use of deep neural networks\nto perform text summarization tasks. In this survey, we begin with a review of\nfashionable text summarization tasks in recent years, including extractive,\nabstractive, multi-document, and so on. Next, we discuss most deep\nlearning-based models and their experimental results on these tasks. The paper\nalso covers datasets and data representation for summarization tasks. Finally,\nwe delve into the opportunities and challenges associated with summarization\ntasks and their corresponding methodologies, aiming to inspire future research\nefforts to advance the field further. A goal of our survey is to explain how\nthese methods differ in their requirements as understanding them is essential\nfor choosing a technique suited for a specific setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guanghua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Weili Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SALM: Speech-augmented Language Model with In-context Learning for Speech Recognition and Translation. (arXiv:2310.09424v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09424","description":"<p>We present a novel Speech Augmented Language Model (SALM) with {\\em\nmultitask} and {\\em in-context} learning capabilities. SALM comprises a frozen\ntext LLM, a audio encoder, a modality adapter module, and LoRA layers to\naccommodate speech input and associated task instructions. The unified SALM not\nonly achieves performance on par with task-specific Conformer baselines for\nAutomatic Speech Recognition (ASR) and Speech Translation (AST), but also\nexhibits zero-shot in-context learning capabilities, demonstrated through\nkeyword-boosting task for ASR and AST. Moreover, {\\em speech supervised\nin-context training} is proposed to bridge the gap between LLM training and\ndownstream speech tasks, which further boosts the in-context learning ability\nof speech-to-text models. Proposed model is open-sourced via NeMo toolkit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhehuai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">He Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrusenko_A/0/1/0/all/0/1\">Andrei Andrusenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hrinchuk_O/0/1/0/all/0/1\">Oleksii Hrinchuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puvvada_K/0/1/0/all/0/1\">Krishna C. Puvvada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jason Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Subhankar Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balam_J/0/1/0/all/0/1\">Jagadeesh Balam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09430","description":"<p>Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly\nadvanced the performance of artificial systems on various natural language\nprocessing tasks to human-like levels. However, their generalisation and\nrobustness to perform logical reasoning remain under-evaluated. To probe this\nability, we propose three new logical reasoning datasets named \"ReClor-plus\",\n\"LogiQA-plus\" and \"LogiQAv2-plus\", each featuring three subsets: the first with\nrandomly shuffled options, the second with the correct choices replaced by\n\"none of the other options are correct\", and a combination of the previous two\nsubsets. We carry out experiments on these datasets with both discriminative\nand generative LLMs and show that these simple tricks greatly hinder the\nperformance of the language models. Despite their superior performance on the\noriginal publicly available datasets, we find that all models struggle to\nanswer our newly constructed datasets. We show that introducing task variations\nby perturbing a sizable training set can markedly improve the model's\ngeneralisation and robustness in logical reasoning tasks. Moreover, applying\nlogic-driven data augmentation for fine-tuning, combined with prompting can\nenhance the generalisation performance of both discriminative large language\nmodels and generative large language models. These results offer insights into\nassessing and improving the generalisation and robustness of large language\nmodels for logical reasoning tasks. We make our source code and data publicly\navailable\n\\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1\">Gael Gendron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1\">Alex Yuxuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_N/0/1/0/all/0/1\">Neset Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiamou Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing BERT-Based Visual Question Answering through Keyword-Driven Sentence Selection. (arXiv:2310.09432v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09432","description":"<p>The Document-based Visual Question Answering competition addresses the\nautomatic detection of parent-child relationships between elements in\nmulti-page documents. The goal is to identify the document elements that answer\na specific question posed in natural language. This paper describes the\nPoliTo's approach to addressing this task, in particular, our best solution\nexplores a text-only approach, leveraging an ad hoc sampling strategy.\nSpecifically, our approach leverages the Masked Language Modeling technique to\nfine-tune a BERT model, focusing on sentences containing sensitive keywords\nthat also occur in the questions, such as references to tables or images.\nThanks to the effectiveness of this approach, we are able to achieve high\nperformance compared to baselines, demonstrating how our solution contributes\npositively to this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Napolitano_D/0/1/0/all/0/1\">Davide Napolitano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaiani_L/0/1/0/all/0/1\">Lorenzo Vaiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cagliero_L/0/1/0/all/0/1\">Luca Cagliero</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sub-network Discovery and Soft-masking for Continual Learning of Mixed Tasks. (arXiv:2310.09436v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09436","description":"<p>Continual learning (CL) has two main objectives: preventing catastrophic\nforgetting (CF) and encouraging knowledge transfer (KT). The existing\nliterature mainly focused on overcoming CF. Some work has also been done on KT\nwhen the tasks are similar. To our knowledge, only one method has been proposed\nto learn a sequence of mixed tasks. However, these techniques still suffer from\nCF and/or limited KT. This paper proposes a new CL method to achieve both. It\novercomes CF by isolating the knowledge of each task via discovering a\nsubnetwork for it. A soft-masking mechanism is also proposed to preserve the\nprevious knowledge and to enable the new task to leverage the past knowledge to\nachieve KT. Experiments using classification, generation, information\nextraction, and their mixture (i.e., heterogeneous tasks) show that the\nproposed method consistently outperforms strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ke_Z/0/1/0/all/0/1\">Zixuan Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Computational analyses of linguistic features with schizophrenic and autistic traits along with formal thought disorders. (arXiv:2310.09494v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09494","description":"<p>[See full abstract in the pdf] Formal Thought Disorder (FTD), which is a\ngroup of symptoms in cognition that affects language and thought, can be\nobserved through language. FTD is seen across such developmental or psychiatric\ndisorders as Autism Spectrum Disorder (ASD) or Schizophrenia, and its related\nSchizotypal Personality Disorder (SPD). This paper collected a Japanese\naudio-report dataset with score labels related to ASD and SPD through a\ncrowd-sourcing service from the general population. We measured language\ncharacteristics with the 2nd edition of the Social Responsiveness Scale (SRS2)\nand the Schizotypal Personality Questionnaire (SPQ), including an odd speech\nsubscale from SPQ to quantify the FTD symptoms. We investigated the following\nfour research questions through machine-learning-based score predictions: (RQ1)\nHow are schizotypal and autistic measures correlated? (RQ2) What is the most\nsuitable task to elicit FTD symptoms? (RQ3) Does the length of speech affect\nthe elicitation of FTD symptoms? (RQ4) Which features are critical for\ncapturing FTD symptoms? We confirmed that an FTD-related subscale, odd speech,\nwas significantly correlated with both the total SPQ and SRS scores, although\nthey themselves were not correlated significantly. Our regression analysis\nindicated that longer speech about a negative memory elicited more FTD\nsymptoms. The ablation study confirmed the importance of function words and\nboth the abstract and temporal features for FTD-related odd speech estimation.\nIn contrast, content words were effective only in the SRS predictions, and\ncontent words were effective only in the SPQ predictions, a result that implies\nthe differences between SPD-like and ASD-like symptoms. Data and programs used\nin this paper can be found here:\nhttps://sites.google.com/view/sagatake/resource.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saga_T/0/1/0/all/0/1\">Takeshi Saga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hiroki Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1\">Satoshi Nakamura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language Models. (arXiv:2310.09499v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09499","description":"<p>Various Large Language Models(LLMs) from the Generative Pretrained\nTransformer~(GPT) family have achieved outstanding performances in a wide range\nof text generation tasks. However, the enormous model sizes have hindered their\npractical use in real-world applications due to high inference latency.\nTherefore, improving the efficiencies of LLMs through quantization, pruning,\nand other means has been a key issue in LLM studies. In this work, we propose a\nmethod based on Hessian sensitivity-aware mixed sparsity pruning to prune LLMs\nto at least 50\\% sparsity without the need of any retraining. It allocates\nsparsity adaptively based on sensitivity, allowing us to reduce pruning-induced\nerror while maintaining the overall sparsity level. The advantages of the\nproposed method exhibit even more when the sparsity is extremely high.\nFurthermore, our method is compatible with quantization, enabling further\ncompression of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1\">Hang Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yanmin Qian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DepNeCTI: Dependency-based Nested Compound Type Identification for Sanskrit. (arXiv:2310.09501v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09501","description":"<p>Multi-component compounding is a prevalent phenomenon in Sanskrit, and\nunderstanding the implicit structure of a compound's components is crucial for\ndeciphering its meaning. Earlier approaches in Sanskrit have focused on binary\ncompounds and neglected the multi-component compound setting. This work\nintroduces the novel task of nested compound type identification (NeCTI), which\naims to identify nested spans of a multi-component compound and decode the\nimplicit semantic relations between them. To the best of our knowledge, this is\nthe first attempt in the field of lexical semantics to propose this task.\n</p>\n<p>We present 2 newly annotated datasets including an out-of-domain dataset for\nthis task. We also benchmark these datasets by exploring the efficacy of the\nstandard problem formulations such as nested named entity recognition,\nconstituency parsing and seq2seq, etc. We present a novel framework named\nDepNeCTI: Dependency-based Nested Compound Type Identifier that surpasses the\nperformance of the best baseline with an average absolute improvement of 13.1\npoints F1-score in terms of Labeled Span Score (LSS) and a 5-fold enhancement\nin inference efficiency. In line with the previous findings in the binary\nSanskrit compound identification task, context provides benefits for the NeCTI\ntask. The codebase and datasets are publicly available at:\nhttps://github.com/yaswanth-iitkgp/DepNeCTI\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sandhan_J/0/1/0/all/0/1\">Jivnesh Sandhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narsupalli_Y/0/1/0/all/0/1\">Yaswanth Narsupalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muppirala_S/0/1/0/all/0/1\">Sreevatsa Muppirala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_S/0/1/0/all/0/1\">Sriram Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satuluri_P/0/1/0/all/0/1\">Pavankumar Satuluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Amba Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attentive Multi-Layer Perceptron for Non-autoregressive Generation. (arXiv:2310.09512v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09512","description":"<p>Autoregressive~(AR) generation almost dominates sequence generation for its\nefficacy. Recently, non-autoregressive~(NAR) generation gains increasing\npopularity for its efficiency and growing efficacy. However, its efficiency is\nstill bottlenecked by quadratic complexity in sequence lengths, which is\nprohibitive for scaling to long sequence generation and few works have been\ndone to mitigate this problem. In this paper, we propose a novel MLP variant,\n\\textbf{A}ttentive \\textbf{M}ulti-\\textbf{L}ayer \\textbf{P}erceptron~(AMLP), to\nproduce a generation model with linear time and space complexity. Different\nfrom classic MLP with static and learnable projection matrices, AMLP leverages\nadaptive projections computed from inputs in an attentive mode. The\nsample-aware adaptive projections enable communications among tokens in a\nsequence, and model the measurement between the query and key space.\nFurthermore, we marry AMLP with popular NAR models, deriving a highly efficient\nNAR-AMLP architecture with linear time and space complexity. Empirical results\nshow that such marriage architecture surpasses competitive efficient NAR\nmodels, by a significant margin on text-to-speech synthesis and machine\ntranslation. We also test AMLP's self- and cross-attention ability separately\nwith extensive ablation experiments, and find them comparable or even superior\nto the other efficient models. The efficiency analysis further shows that AMLP\nextremely reduces the memory cost against vanilla non-autoregressive models for\nlong sequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shuyang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instruction Tuning with Human Curriculum. (arXiv:2310.09518v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09518","description":"<p>The dominant paradigm for instruction tuning is the random-shuffled training\nof maximally diverse instruction-response pairs. This paper explores the\npotential benefits of applying a structured cognitive learning approach to\ninstruction tuning in contemporary large language models like ChatGPT and\nGPT-4. Unlike the previous conventional randomized instruction dataset, we\npropose a highly structured synthetic dataset that mimics the progressive and\norganized nature of human education. We curate our dataset by aligning it with\neducational frameworks, incorporating meta information including its topic and\ncognitive rigor level for each sample. Our dataset covers comprehensive\nfine-grained topics spanning diverse educational stages (from middle school to\ngraduate school) with various questions for each topic to enhance conceptual\ndepth using Bloom's taxonomy-a classification framework distinguishing various\nlevels of human cognition for each concept. The results demonstrate that this\ncognitive rigorous training approach yields significant performance\nenhancements - +3.06 on the MMLU benchmark and an additional +1.28 on AI2\nReasoning Challenge (hard set) - compared to conventional randomized training,\nall while avoiding additional computational costs. This research highlights the\npotential of leveraging human learning principles to enhance the capabilities\nof language models in comprehending and responding to complex instructions and\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Bruce W. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyunsoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_K/0/1/0/all/0/1\">Kang Min Yoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentiment Analysis Using Averaged Weighted Word Vector Features. (arXiv:2002.05606v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2002.05606","description":"<p>People use the world wide web heavily to share their experience with entities\nsuch as products, services, or travel destinations. Texts that provide online\nfeedback in the form of reviews and comments are essential to make consumer\ndecisions. These comments create a valuable source that may be used to measure\nsatisfaction related to products or services. Sentiment analysis is the task of\nidentifying opinions expressed in such text fragments. In this work, we develop\ntwo methods that combine different types of word vectors to learn and estimate\npolarity of reviews. We develop average review vectors from word vectors and\nadd weights to this review vectors using word frequencies in positive and\nnegative sensitivity-tagged reviews. We applied the methods to several datasets\nfrom different domains that are used as standard benchmarks for sentiment\nanalysis. We ensemble the techniques with each other and existing methods, and\nwe make a comparison with the approaches in the literature. The results show\nthat the performances of our approaches outperform the state-of-the-art success\nrates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Erkan_A/0/1/0/all/0/1\">Ali Erkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gungor_T/0/1/0/all/0/1\">Tunga Gungor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Temporal Convolutional Attention-based Network For Sequence Modeling. (arXiv:2002.12530v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2002.12530","description":"<p>With the development of feed-forward models, the default model for sequence\nmodeling has gradually evolved to replace recurrent networks. Many powerful\nfeed-forward models based on convolutional networks and attention mechanism\nwere proposed and show more potential to handle sequence modeling tasks. We\nwonder that is there an architecture that can not only achieve an approximate\nsubstitution of recurrent network, but also absorb the advantages of\nfeed-forward models. So we propose an exploratory architecture referred to\nTemporal Convolutional Attention-based Network (TCAN) which combines temporal\nconvolutional network and attention mechanism. TCAN includes two parts, one is\nTemporal Attention (TA) which captures relevant features inside the sequence,\nthe other is Enhanced Residual (ER) which extracts shallow layer's important\ninformation and transfers to deep layers. We improve the state-of-the-art\nresults of bpc/perplexity to 30.28 on word-level PTB, 1.092 on character-level\nPTB, and 9.20 on WikiText-2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_H/0/1/0/all/0/1\">Hongyan Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1\">Siqiao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yudi Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_F/0/1/0/all/0/1\">Furao Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graphmax for Text Generation. (arXiv:2101.00153v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.00153","description":"<p>In text generation, a large language model (LM) makes a choice of each new\nword based only on the former selection of its context using the softmax\nfunction. Nevertheless, the link statistics information of concurrent words\nbased on a scene-specific corpus is valuable in choosing the next word, which\ncan help to ensure the topic of the generated text to be aligned with the\ncurrent task. To fully explore the co-occurrence information,we propose a\ngraphmax function for task-specific text generation. Using the graph-based\nregularization, graphmax enables the final word choice to be determined by both\nthe global knowledge from the LM and the local knowledge from the\nscene-specific corpus. The traditional softmax function is regularized with a\ngraph total variation (GTV) term, which incorporates the local knowledge into\nthe LM and encourages the model to consider the statistical relationships\nbetween words in a scene-specific corpus. The proposed graphmax is versatile\nand can be readily plugged into any large pre-trained LM for text generation\nand machine translation. Through extensive experiments, we demonstrate that the\nnew GTV-based regularization can improve performances in various natural\nlanguage processing tasks in comparison with existing methods. Moreover,\nthrough human experiments, we observe that participants can easily distinguish\nthe text generated by graphmax or softmax.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bin_L/0/1/0/all/0/1\">Liu Bin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guosheng_Y/0/1/0/all/0/1\">Yin Guosheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counterfactual Memorization in Neural Language Models. (arXiv:2112.12938v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.12938","description":"<p>Modern neural language models that are widely used in various NLP tasks risk\nmemorizing sensitive information from their training data. Understanding this\nmemorization is important in real world applications and also from a\nlearning-theoretical perspective. An open question in previous studies of\nlanguage model memorization is how to filter out \"common\" memorization. In\nfact, most memorization criteria strongly correlate with the number of\noccurrences in the training set, capturing memorized familiar phrases, public\nknowledge, templated texts, or other repeated data. We formulate a notion of\ncounterfactual memorization which characterizes how a model's predictions\nchange if a particular document is omitted during training. We identify and\nstudy counterfactually-memorized training examples in standard text datasets.\nWe estimate the influence of each memorized training example on the validation\nset and on generated texts, showing how this can provide direct evidence of the\nsource of memorization at test time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ippolito_D/0/1/0/all/0/1\">Daphne Ippolito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Katherine Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jagielski_M/0/1/0/all/0/1\">Matthew Jagielski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1\">Florian Tram&#xe8;r</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1\">Nicholas Carlini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speculative Decoding: Lossless Speedup of Autoregressive Translation. (arXiv:2203.16487v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.16487","description":"<p>Different from some previous work accelerating autoregressive translation\n(AT) at the sacrifice of quality, we propose Speculative Decoding (SpecDec) --\na novel decoding paradigm inspired by speculative execution in computer\narchitecture, which combines respective advantages of AT and non-autoregressive\ntranslation (NAT) for lossless speedup of translation. At each decoding step,\nSpecDec first speculatively drafts (i.e. decodes) next $k$ tokens with an NAT\nmodel and then verifies them with an AT model, where only the drafted tokens\npassing the verification are accepted as decoded tokens for guaranteeing its\ntranslation result is exactly the same as AT. The collaboration of NAT drafting\nand AT verification leads to a much higher decoding speed without quality loss\ndue to parallel computing enabled by speculative decoding.\n</p>\n<p>We conduct experiments in 4 standard WMT translation benchmarks and confirm\nthe vanilla SpecDec yields exactly the same results as AT greedy decoding with\nan around $3\\times$ speedup, and that its variant (SpecDec++) with an advanced\nverification strategy not only outperforms AT greedy decoding, but also further\nimproves the decoding speed, resulting in an around $5\\times$ speedup over AT.\nMoreover, SpecDec can be easily generalized for speeding up other seq2seq tasks\nlike Abstractive Summarization, and benefit more from stronger computing\ndevices, demonstrating its potential to become a \\textit{de facto} decoding\nstandard in the future for efficient and lossless seq2seq generation. We will\nrelease all our codes and checkpoints to facilitate reproducing our results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Heming Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Labeling Programs with Non-Programmers Indirectly via Active Examples: A Case Study with Text-to-SQL. (arXiv:2205.12422v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12422","description":"<p>Can non-programmers annotate natural language utterances with complex\nprograms that represent their meaning? We introduce APEL, a framework in which\nnon-programmers select among candidate programs generated by a seed semantic\nparser (e.g., Codex). Since they cannot understand the candidate programs, we\nask them to select indirectly by examining the programs' input-ouput examples.\nFor each utterance, APEL actively searches for a simple input on which the\ncandidate programs tend to produce different outputs. It then asks the\nnon-programmers only to choose the appropriate output, thus allowing us to\ninfer which program is correct and could be used to fine-tune the parser. As a\nfirst case study, we recruited human non-programmers to use APEL to re-annotate\nSPIDER, a text-to-SQL dataset. Our approach achieved the same annotation\naccuracy as the original expert annotators (75%) and exposed many subtle errors\nin the original annotations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snell_C/0/1/0/all/0/1\">Charlie Snell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1\">Jason Eisner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"5q032e@SMM4H'22: Transformer-based classification of premise in tweets related to COVID-19. (arXiv:2209.03851v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.03851","description":"<p>Automation of social network data assessment is one of the classic challenges\nof natural language processing. During the COVID-19 pandemic, mining people's\nstances from public messages have become crucial regarding understanding\nattitudes towards health orders. In this paper, the authors propose the\npredictive model based on transformer architecture to classify the presence of\npremise in Twitter texts. This work is completed as part of the Social Media\nMining for Health (SMM4H) Workshop 2022. We explored modern transformer-based\nclassifiers in order to construct the pipeline efficiently capturing tweets\nsemantics. Our experiments on a Twitter dataset showed that RoBERTa is superior\nto the other transformer models in the case of the premise prediction task. The\nmodel achieved competitive performance with respect to ROC AUC value 0.807, and\n0.7648 for the F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Porvatov_V/0/1/0/all/0/1\">Vadim Porvatov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semenova_N/0/1/0/all/0/1\">Natalia Semenova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt. (arXiv:2210.03029v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03029","description":"<p>Enhancing the zero-shot performance of instruction-following models requires\nheavy computation, either by scaling the total number of training datasets or\nthe model size. In this work, we explore how retrieval of soft prompts obtained\nthrough prompt tuning can efficiently assist hard prompts in zero-shot task\ngeneralization. Specifically, we train soft prompt embeddings for each prompt\nthrough prompt tuning, store the samples of the training instances mapped with\nthe prompt embeddings, and retrieve the corresponding prompt embedding of the\ntraining instance closest to the query instance during inference. While only\nadding 0.007% additional parameters, retrieval of soft prompt enhances the\nperformance of T0 on unseen tasks by outperforming it on 10 out of 11 datasets\nas well as improving the mean accuracy of T0 on BIG-bench benchmark by 2.39%\npoints. Also, we report an interesting finding that retrieving source\nembeddings trained on similar answer choice formats is more important than\nthose on similar task types.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Seonghyeon Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Joel Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yongrae Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind the Labels: Describing Relations in Knowledge Graphs With Pretrained Models. (arXiv:2210.07373v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07373","description":"<p>Pretrained language models (PLMs) for data-to-text (D2T) generation can use\nhuman-readable data labels such as column headings, keys, or relation names to\ngeneralize to out-of-domain examples. However, the models are well-known in\nproducing semantically inaccurate outputs if these labels are ambiguous or\nincomplete, which is often the case in D2T datasets. In this paper, we expose\nthis issue on the task of descibing a relation between two entities. For our\nexperiments, we collect a novel dataset for verbalizing a diverse set of 1,522\nunique relations from three large-scale knowledge graphs (Wikidata, DBPedia,\nYAGO). We find that although PLMs for D2T generation expectedly fail on unclear\ncases, models trained with a large variety of relation labels are surprisingly\nrobust in verbalizing novel, unseen relations. We argue that using data with a\ndiverse set of clear and meaningful labels is key to training D2T generation\nsystems capable of generalizing to novel domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kasner_Z/0/1/0/all/0/1\">Zden&#x11b;k Kasner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstas_I/0/1/0/all/0/1\">Ioannis Konstas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1\">Ond&#x159;ej Du&#x161;ek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces. (arXiv:2211.03536v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2211.03536","description":"<p>Knowledge graph embedding (KGE) is an increasingly popular technique that\naims to represent entities and relations of knowledge graphs into\nlow-dimensional semantic spaces for a wide spectrum of applications such as\nlink prediction, knowledge reasoning and knowledge completion. In this paper,\nwe provide a systematic review of existing KGE techniques based on\nrepresentation spaces. Particularly, we build a fine-grained classification to\ncategorise the models based on three mathematical perspectives of the\nrepresentation spaces: (1) Algebraic perspective, (2) Geometric perspective,\nand (3) Analytical perspective. We introduce the rigorous definitions of\nfundamental mathematical spaces before diving into KGE models and their\nmathematical properties. We further discuss different KGE methods over the\nthree categories, as well as summarise how spatial advantages work over\ndifferent embedding needs. By collating the experimental results from\ndownstream tasks, we also explore the advantages of mathematical space in\ndifferent scenarios and the reasons behind them. We further state some\npromising research directions from a representation space perspective, with\nwhich we hope to inspire researchers to design their KGE models as well as\ntheir related applications with more consideration of their mathematical space\nproperties.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Jiahang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1\">Jinyuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zaiqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shangsong Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bidirectional Representations for Low Resource Spoken Language Understanding. (arXiv:2211.14320v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.14320","description":"<p>Most spoken language understanding systems use a pipeline approach composed\nof an automatic speech recognition interface and a natural language\nunderstanding module. This approach forces hard decisions when converting\ncontinuous inputs into discrete language symbols. Instead, we propose a\nrepresentation model to encode speech in rich bidirectional encodings that can\nbe used for downstream tasks such as intent prediction. The approach uses a\nmasked language modelling objective to learn the representations, and thus\nbenefits from both the left and right contexts. We show that the performance of\nthe resulting encodings before fine-tuning is better than comparable models on\nmultiple datasets, and that fine-tuning the top layers of the representation\nmodel improves the current state of the art on the Fluent Speech Command\ndataset, also in a low-data regime, when a limited amount of labelled data is\nused for training. Furthermore, we propose class attention as a spoken language\nunderstanding module, efficient both in terms of speed and number of\nparameters. Class attention can be used to visually explain the predictions of\nour model, which goes a long way in understanding how the model makes\npredictions. We perform experiments in English and in Dutch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meeus_Q/0/1/0/all/0/1\">Quentin Meeus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1\">Hugo Van hamme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Cloze to Comprehension: Retrofitting Pre-trained Masked Language Model to Pre-trained Machine Reader. (arXiv:2212.04755v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.04755","description":"<p>We present Pre-trained Machine Reader (PMR), a novel method for retrofitting\npre-trained masked language models (MLMs) to pre-trained machine reading\ncomprehension (MRC) models without acquiring labeled data. PMR can resolve the\ndiscrepancy between model pre-training and downstream fine-tuning of existing\nMLMs. To build the proposed PMR, we constructed a large volume of\ngeneral-purpose and high-quality MRC-style training data by using Wikipedia\nhyperlinks and designed a Wiki Anchor Extraction task to guide the MRC-style\npre-training. Apart from its simplicity, PMR effectively solves extraction\ntasks, such as Extractive Question Answering and Named Entity Recognition. PMR\nshows tremendous improvements over existing approaches, especially in\nlow-resource scenarios. When applied to the sequence classification task in the\nMRC formulation, PMR enables the extraction of high-quality rationales to\nexplain the classification process, thereby providing greater prediction\nexplainability. PMR also has the potential to serve as a unified model for\ntackling various extraction and classification tasks in the MRC formulation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weiwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Meng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extending TrOCR for Text Localization-Free OCR of Full-Page Scanned Receipt Images. (arXiv:2212.05525v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.05525","description":"<p>Digitization of scanned receipts aims to extract text from receipt images and\nsave it into structured documents. This is usually split into two sub-tasks:\ntext localization and optical character recognition (OCR). Most existing OCR\nmodels only focus on the cropped text instance images, which require the\nbounding box information provided by a text region detection model. Introducing\nan additional detector to identify the text instance images in advance adds\ncomplexity, however instance-level OCR models have very low accuracy when\nprocessing the whole image for the document-level OCR, such as receipt images\ncontaining multiple text lines arranged in various layouts. To this end, we\npropose a localization-free document-level OCR model for transcribing all the\ncharacters in a receipt image into an ordered sequence end-to-end.\nSpecifically, we finetune the pretrained instance-level model TrOCR with\nrandomly cropped image chunks, and gradually increase the image chunk size to\ngeneralize the recognition ability from instance images to full-page images. In\nour experiments on the SROIE receipt OCR dataset, the model finetuned with our\nstrategy achieved 64.4 F1-score and a 22.8% character error rate (CER),\nrespectively, which outperforms the baseline results with 48.5 F1-score and\n50.6% CER. The best model, which splits the full image into 15 equally sized\nchunks, gives 87.8 F1-score and 4.98% CER with minimal additional pre or\npost-processing of the output. Moreover, the characters in the generated\ndocument-level sequences are arranged in the reading order, which is practical\nfor real-world applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongkuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whittaker_E/0/1/0/all/0/1\">Edward Whittaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kitagishi_I/0/1/0/all/0/1\">Ikuo Kitagishi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Momentum Contrastive Pre-training for Question Answering. (arXiv:2212.05762v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.05762","description":"<p>Existing pre-training methods for extractive Question Answering (QA) generate\ncloze-like queries different from natural questions in syntax structure, which\ncould overfit pre-trained models to simple keyword matching. In order to\naddress this problem, we propose a novel Momentum Contrastive pRe-training fOr\nqueStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS\nintroduces a momentum contrastive learning framework to align the answer\nprobability between cloze-like and natural query-passage sample pairs. Hence,\nthe pre-trained models can better transfer the knowledge learned in cloze-like\nsamples to answering natural questions. Experimental results on three\nbenchmarking QA datasets show that our method achieves noticeable improvement\ncompared with all baselines in both supervised and zero-shot scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Minda Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Muzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Improving Summarization Factual Consistency from Natural Language Feedback. (arXiv:2212.09968v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09968","description":"<p>Despite the recent progress in language generation models, their outputs may\nnot always meet user expectations. In this work, we study whether informational\nfeedback in natural language can be leveraged to improve generation quality and\nuser preference alignment. To this end, we consider factual consistency in\nsummarization, the quality that the summary should only contain information\nsupported by the input documents, as the user-expected preference. We collect a\nhigh-quality dataset, DeFacto, containing human demonstrations and\ninformational natural language feedback consisting of corrective instructions,\nedited summaries, and explanations with respect to the factual consistency of\nthe summary. Using our dataset, we study three natural language generation\ntasks: (1) editing a summary by following the human feedback, (2) generating\nhuman feedback for editing the original summary, and (3) revising the initial\nsummary to correct factual errors by generating both the human feedback and\nedited summary. We show that DeFacto can provide factually consistent\nhuman-edited summaries and further insights into summarization factual\nconsistency thanks to its informational natural language feedback. We further\ndemonstrate that fine-tuned language models can leverage our dataset to improve\nthe summary factual consistency, while large language models lack the zero-shot\nlearning ability in our proposed tasks that require controllable text\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1\">Budhaditya Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teruel_M/0/1/0/all/0/1\">Milagro Teruel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halfaker_A/0/1/0/all/0/1\">Aaron Halfaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed H. Awadallah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models. (arXiv:2301.04213v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.04213","description":"<p>Language models learn a great quantity of factual information during\npretraining, and recent work localizes this information to specific model\nweights like mid-layer MLP weights. In this paper, we find that we can change\nhow a fact is stored in a model by editing weights that are in a different\nlocation than where existing methods suggest that the fact is stored. This is\nsurprising because we would expect that localizing facts to specific model\nparameters would tell us where to manipulate knowledge in models, and this\nassumption has motivated past work on model editing methods. Specifically, we\nshow that localization conclusions from representation denoising (also known as\nCausal Tracing) do not provide any insight into which model MLP layer would be\nbest to edit in order to override an existing stored fact with a new one. This\nfinding raises questions about how past work relies on Causal Tracing to select\nwhich model layers to edit. Next, we consider several variants of the editing\nproblem, including erasing and amplifying facts. For one of our editing\nproblems, editing performance does relate to localization results from\nrepresentation denoising, but we find that which layer we edit is a far better\npredictor of performance. Our results suggest, counterintuitively, that better\nmechanistic understanding of how pretrained language models work may not always\ntranslate to insights about how to best change their behavior. Our code is\navailable at https://github.com/google/belief-localization\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1\">Peter Hase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Been Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandeharioun_A/0/1/0/all/0/1\">Asma Ghandeharioun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked Language Models. (arXiv:2301.10472v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10472","description":"<p>Large multilingual language models typically rely on a single vocabulary\nshared across 100+ languages. As these models have increased in parameter count\nand depth, vocabulary size has remained largely unchanged. This\n\\textit{vocabulary bottleneck} limits the representational capabilities of\nmultilingual models like XLM-R. In this paper, we introduce a new approach for\nscaling to very large multilingual vocabularies by de-emphasizing token sharing\nbetween languages with little lexical overlap and assigning vocabulary capacity\nto achieve sufficient coverage for each individual language. Tokenizations\nusing our vocabulary are typically more semantically meaningful and shorter\ncompared to XLM-R. Leveraging this improved vocabulary, we train XLM-V, a\nmultilingual language model with a one million token vocabulary. XLM-V\noutperforms XLM-R on every task we tested on ranging from natural language\ninference (XNLI), question answering (MLQA, XQuAD, TyDiQA), to named entity\nrecognition (WikiAnn). XLM-V is particularly effective on low-resource language\ntasks and outperforms XLM-R by 11.2% and 5.8% absolute on MasakhaNER and\nAmericas NLI, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Davis Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonen_H/0/1/0/all/0/1\">Hila Gonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Naman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghazvininejad_M/0/1/0/all/0/1\">Marjan Ghazvininejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Type-Aware Decomposed Framework for Few-Shot Named Entity Recognition. (arXiv:2302.06397v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06397","description":"<p>Despite the recent success achieved by several two-stage prototypical\nnetworks in few-shot named entity recognition (NER) task, the overdetected\nfalse spans at the span detection stage and the inaccurate and unstable\nprototypes at the type classification stage remain to be challenging problems.\nIn this paper, we propose a novel Type-Aware Decomposed framework, namely\nTadNER, to solve these problems. We first present a type-aware span filtering\nstrategy to filter out false spans by removing those semantically far away from\ntype names. We then present a type-aware contrastive learning strategy to\nconstruct more accurate and stable prototypes by jointly exploiting support\nsamples and type names as references. Extensive experiments on various\nbenchmarks prove that our proposed TadNER framework yields a new\nstate-of-the-art performance. Our code and data will be available at\nhttps://github.com/NLPWM-WHU/TadNER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_T/0/1/0/all/0/1\">Tieyun Qian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FinXABSA: Explainable Finance through Aspect-Based Sentiment Analysis. (arXiv:2303.02563v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.02563","description":"<p>This paper presents a novel approach for explainability in financial analysis\nby deriving financially-explainable statistical relationships through\naspect-based sentiment analysis, Pearson correlation, Granger causality &amp;\nuncertainty coefficient. The proposed methodology involves constructing an\naspect list from financial literature and applying aspect-based sentiment\nanalysis on social media text to compute sentiment scores for each aspect.\nPearson correlation is then applied to uncover financially explainable\nrelationships between aspect sentiment scores and stock prices. Findings for\nderived relationships are made robust by applying Granger causality to\ndetermine the forecasting ability of each aspect sentiment score for stock\nprices. Finally, an added layer of interpretability is added by evaluating\nuncertainty coefficient scores between aspect sentiment scores and stock\nprices. This allows us to determine the aspects whose sentiment scores are most\nstatistically significant for stock prices. Relative to other methods, our\napproach provides a more informative and accurate understanding of the\nrelationship between sentiment analysis and stock prices. Specifically, this\nmethodology enables an interpretation of the statistical relationship between\naspect-based sentiment scores and stock prices, which offers explainability to\nAI-driven financial decision-making.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ong_K/0/1/0/all/0/1\">Keane Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heever_W/0/1/0/all/0/1\">Wihan van der Heever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satapathy_R/0/1/0/all/0/1\">Ranjan Satapathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mengaldo_G/0/1/0/all/0/1\">Gianmarco Mengaldo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Transformers Parse while Predicting the Masked Word?. (arXiv:2303.08117v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.08117","description":"<p>Pre-trained language models have been shown to encode linguistic structures,\ne.g. dependency and constituency parse trees, in their embeddings while being\ntrained on unsupervised loss functions like masked language modeling. Some\ndoubts have been raised whether the models actually are doing parsing or only\nsome computation weakly correlated with it. We study questions: (a) Is it\npossible to explicitly describe transformers with realistic embedding\ndimension, number of heads, etc. that are capable of doing parsing -- or even\napproximate parsing? (b) Why do pre-trained models capture parsing structure?\nThis paper takes a step toward answering these questions in the context of\ngenerative modeling with PCFGs. We show that masked language models like BERT\nor RoBERTa of moderate sizes can approximately execute the Inside-Outside\nalgorithm for the English PCFG [Marcus et al, 1993]. We also show that the\nInside-Outside algorithm is optimal for masked language modeling loss on the\nPCFG-generated data. We also give a construction of transformers with $50$\nlayers, $15$ attention heads, and $1275$ dimensional embeddings in average such\nthat using its embeddings it is possible to do constituency parsing with\n$&gt;70\\%$ F1 score on PTB dataset. We conduct probing experiments on models\npre-trained on PCFG-generated data to show that this not only allows recovery\nof approximate parse tree, but also recovers marginal span probabilities\ncomputed by the Inside-Outside algorithm, which suggests an implicit bias of\nmasked language modeling towards this algorithm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haoyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panigrahi_A/0/1/0/all/0/1\">Abhishek Panigrahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sanjeev Arora</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Scope of In-Context Learning for the Extraction of Medical Temporal Constraints. (arXiv:2303.09366v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09366","description":"<p>Medications often impose temporal constraints on everyday patient activity.\nViolations of such medical temporal constraints (MTCs) lead to a lack of\ntreatment adherence, in addition to poor health outcomes and increased\nhealthcare expenses. These MTCs are found in drug usage guidelines (DUGs) in\nboth patient education materials and clinical texts. Computationally\nrepresenting MTCs in DUGs will advance patient-centric healthcare applications\nby helping to define safe patient activity patterns. We define a novel taxonomy\nof MTCs found in DUGs and develop a novel context-free grammar (CFG) based\nmodel to computationally represent MTCs from unstructured DUGs. Additionally,\nwe release three new datasets with a combined total of N = 836 DUGs labeled\nwith normalized MTCs. We develop an in-context learning (ICL) solution for\nautomatically extracting and normalizing MTCs found in DUGs, achieving an\naverage F1 score of 0.62 across all datasets. Finally, we rigorously\ninvestigate ICL model performance against a baseline model, across datasets and\nMTC types, and through in-depth error analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seegmiller_P/0/1/0/all/0/1\">Parker Seegmiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatto_J/0/1/0/all/0/1\">Joseph Gatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basak_M/0/1/0/all/0/1\">Madhusudan Basak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cook_D/0/1/0/all/0/1\">Diane Cook</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghasemzadeh_H/0/1/0/all/0/1\">Hassan Ghasemzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stankovic_J/0/1/0/all/0/1\">John Stankovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preum_S/0/1/0/all/0/1\">Sarah Preum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural Architecture Search for Effective Teacher-Student Knowledge Transfer in Language Models. (arXiv:2303.09639v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09639","description":"<p>Large pretrained language models have achieved state-of-the-art results on a\nvariety of downstream tasks. Knowledge Distillation (KD) into a smaller student\nmodel addresses their inefficiency, allowing for deployment in\nresource-constrained environments. However, KD can be ineffective when the\nstudent is manually selected from a set of existing options, since it can be a\nsub-optimal choice within the space of all possible student architectures. We\ndevelop multilingual KD-NAS, the use of Neural Architecture Search (NAS) guided\nby KD to find the optimal student architecture for task agnostic distillation\nfrom a multilingual teacher. In each episode of the search process, a NAS\ncontroller predicts a reward based on the distillation loss and latency of\ninference. The top candidate architectures are then distilled from the teacher\non a small proxy set. Finally the architecture(s) with the highest reward is\nselected, and distilled on the full training corpus. KD-NAS can automatically\ntrade off efficiency and effectiveness, and recommends architectures suitable\nto various latency budgets. Using our multi-layer hidden state distillation\nprocess, our KD-NAS student model achieves a 7x speedup on CPU inference (2x on\nGPU) compared to a XLM-Roberta Base Teacher, while maintaining 90% performance,\nand has been deployed in 3 software offerings requiring large throughput, low\nlatency and deployment on CPU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Aashka Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Udagawa_T/0/1/0/all/0/1\">Takuma Udagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merler_M/0/1/0/all/0/1\">Michele Merler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1\">Rameswar Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Kurdi_Y/0/1/0/all/0/1\">Yousef El-Kurdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_B/0/1/0/all/0/1\">Bishwaranjan Bhattacharjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Making the Most of ChatGPT for Machine Translation. (arXiv:2303.13780v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13780","description":"<p>ChatGPT shows remarkable capabilities for machine translation (MT). Several\nprior studies have shown that it achieves comparable results to commercial\nsystems for high-resource languages, but lags behind in complex tasks, e.g.,\nlow-resource and distant-language-pairs translation. However, they usually\nadopt simple prompts which can not fully elicit the capability of ChatGPT. In\nthis paper, we aim to further mine ChatGPT's translation ability by revisiting\nseveral aspects: temperature, task information, and domain information, and\ncorrespondingly propose an optimal temperature setting and two (simple but\neffective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts\n(DSP). We show that: 1) The performance of ChatGPT depends largely on\ntemperature, and a lower temperature usually can achieve better performance; 2)\nEmphasizing the task information can further improve ChatGPT's performance,\nparticularly in complex MT tasks; 3) Introducing domain information can elicit\nChatGPT's generalization ability and improve its performance in the specific\ndomain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT\ntasks, which can be partially addressed by our proposed prompts but still need\nto be highlighted for the MT/NLP community. We also explore the effects of\nadvanced in-context learning strategies and find a (negative but interesting)\nobservation: the powerful chain-of-thought prompt leads to word-by-word\ntranslation behavior, thus bringing significant translation degradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Keqin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Yuanxin Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Manifold Learning for Reading Comprehension and Logical Reasoning Tasks with Polytuplet Loss. (arXiv:2304.01046v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01046","description":"<p>The current trend in developing machine learning models for reading\ncomprehension and logical reasoning tasks is focused on improving the models'\nabilities to understand and utilize logical rules. This work focuses on\nproviding a novel loss function and accompanying model architecture that has\nmore interpretable components than some other models by representing a common\nstrategy employed by humans when given reading comprehension and logical\nreasoning tasks. Our strategy involves emphasizing relative accuracy over\nabsolute accuracy and can theoretically produce the correct answer with\nincomplete knowledge. We examine the effectiveness of this strategy to solve\nreading comprehension and logical reasoning questions. The models were\nevaluated on the ReClor dataset, a challenging reading comprehension and\nlogical reasoning benchmark. We propose the polytuplet loss function, which\nforces prioritization of learning the relative correctness of answer choices\nover learning the true accuracy of each choice. Our results indicate that\nmodels employing polytuplet loss outperform existing baseline models, though\nfurther research is required to quantify the benefits it may present.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jeffrey Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_I/0/1/0/all/0/1\">Ivan Rodriguez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Contrastive Transfer Framework with Propagation Structure for Boosting Low-Resource Rumor Detection. (arXiv:2304.01492v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01492","description":"<p>The truth is significantly hampered by massive rumors that spread along with\nbreaking news or popular topics. Since there is sufficient corpus gathered from\nthe same domain for model training, existing rumor detection algorithms show\npromising performance on yesterday's news. However, due to a lack of\nsubstantial training data and prior expert knowledge, they are poor at spotting\nrumors concerning unforeseen events, especially those propagated in different\nlanguages (i.e., low-resource regimes). In this paper, we propose a unified\ncontrastive transfer framework to detect rumors by adapting the features\nlearned from well-resourced rumor data to that of the low-resourced with only\nfew-shot annotations. More specifically, we first represent rumor circulated on\nsocial media as an undirected topology for enhancing the interaction of user\nopinions, and then train a Multi-scale Graph Convolutional Network via a\nunified contrastive paradigm to mine effective clues simultaneously from post\nsemantics and propagation structure. Our model explicitly breaks the barriers\nof the domain and/or language issues, via language alignment and a novel\ndomain-adaptive contrastive learning mechanism. To well-generalize the\nrepresentation learning using a small set of annotated target events, we reveal\nthat rumor-indicative signal is closely correlated with the uniformity of the\ndistribution of these events. We design a target-wise contrastive training\nmechanism with three event-level data augmentation strategies, capable of\nunifying the representations by distinguishing target events. Extensive\nexperiments conducted on four low-resource datasets collected from real-world\nmicroblog platforms demonstrate that our framework achieves much better\nperformance than state-of-the-art methods and exhibits a superior capacity for\ndetecting rumors at early stages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mingfei Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Discrete and Backpropagation: Straight-Through and Beyond. (arXiv:2304.08612v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2304.08612","description":"<p>Backpropagation, the cornerstone of deep learning, is limited to computing\ngradients for continuous variables. This limitation poses challenges for\nproblems involving discrete latent variables. To address this issue, we propose\na novel approach to approximate the gradient of parameters involved in\ngenerating discrete latent variables. First, we examine the widely used\nStraight-Through (ST) heuristic and demonstrate that it works as a first-order\napproximation of the gradient. Guided by our findings, we propose ReinMax,\nwhich achieves second-order accuracy by integrating Heun's method, a\nsecond-order numerical method for solving ODEs. ReinMax does not require\nHessian or other second-order derivatives, thus having negligible computation\noverheads. Extensive experimental results on various tasks demonstrate the\nsuperiority of ReinMax over the state of the art. Implementations are released\nat https://github.com/microsoft/ReinMax.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dissecting Recall of Factual Associations in Auto-Regressive Language Models. (arXiv:2304.14767v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.14767","description":"<p>Transformer-based language models (LMs) are known to capture factual\nknowledge in their parameters. While previous work looked into where factual\nassociations are stored, only little is known about how they are retrieved\ninternally during inference. We investigate this question through the lens of\ninformation flow. Given a subject-relation query, we study how the model\naggregates information about the subject and relation to predict the correct\nattribute. With interventions on attention edges, we first identify two\ncritical points where information propagates to the prediction: one from the\nrelation positions followed by another from the subject positions. Next, by\nanalyzing the information at these points, we unveil a three-step internal\nmechanism for attribute extraction. First, the representation at the\nlast-subject position goes through an enrichment process, driven by the early\nMLP sublayers, to encode many subject-related attributes. Second, information\nfrom the relation propagates to the prediction. Third, the prediction\nrepresentation \"queries\" the enriched subject to extract the attribute. Perhaps\nsurprisingly, this extraction is typically done via attention heads, which\noften encode subject-attribute mappings in their parameters. Overall, our\nfindings introduce a comprehensive view of how factual associations are stored\nand extracted internally in LMs, facilitating future research on knowledge\nlocalization and editing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bastings_J/0/1/0/all/0/1\">Jasmijn Bastings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippova_K/0/1/0/all/0/1\">Katja Filippova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Previously Fact-Checked Claim Retrieval. (arXiv:2305.07991v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07991","description":"<p>Fact-checkers are often hampered by the sheer amount of online content that\nneeds to be fact-checked. NLP can help them by retrieving already existing\nfact-checks relevant to the content being investigated. This paper introduces a\nnew multilingual dataset -- MultiClaim -- for previously fact-checked claim\nretrieval. We collected 28k posts in 27 languages from social media, 206k\nfact-checks in 39 languages written by professional fact-checkers, as well as\n31k connections between these two groups. This is the most extensive and the\nmost linguistically diverse dataset of this kind to date. We evaluated how\ndifferent unsupervised methods fare on this dataset and its various dimensions.\nWe show that evaluating such a diverse dataset has its complexities and proper\ncare needs to be taken before interpreting the results. We also evaluated a\nsupervised fine-tuning approach, improving upon the unsupervised method\nsignificantly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pikuliak_M/0/1/0/all/0/1\">Mat&#xfa;&#x161; Pikuliak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srba_I/0/1/0/all/0/1\">Ivan Srba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_R/0/1/0/all/0/1\">Robert Moro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hromadka_T/0/1/0/all/0/1\">Timo Hromadka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smolen_T/0/1/0/all/0/1\">Timotej Smolen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melisek_M/0/1/0/all/0/1\">Martin Melisek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vykopal_I/0/1/0/all/0/1\">Ivan Vykopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simko_J/0/1/0/all/0/1\">Jakub Simko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Podrouzek_J/0/1/0/all/0/1\">Juraj Podrouzek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bielikova_M/0/1/0/all/0/1\">Maria Bielikova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation. (arXiv:2305.08371v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08371","description":"<p>Dialogue segmentation is a crucial task for dialogue systems allowing a\nbetter understanding of conversational texts. Despite recent progress in\nunsupervised dialogue segmentation methods, their performances are limited by\nthe lack of explicit supervised signals for training. Furthermore, the precise\ndefinition of segmentation points in conversations still remains as a\nchallenging problem, increasing the difficulty of collecting manual\nannotations. In this paper, we provide a feasible definition of dialogue\nsegmentation points with the help of document-grounded dialogues and release a\nlarge-scale supervised dataset called SuperDialseg, containing 9,478 dialogues\nbased on two prevalent document-grounded dialogue corpora, and also inherit\ntheir useful dialogue-related annotations. Moreover, we provide a benchmark\nincluding 18 models across five categories for the dialogue segmentation task\nwith several proper evaluation metrics. Empirical studies show that supervised\nlearning is extremely effective in in-domain datasets and models trained on\nSuperDialseg can achieve good generalization ability on out-of-domain data.\nAdditionally, we also conducted human verification on the test set and the\nKappa score confirmed the quality of our automatically constructed dataset. We\nbelieve our work is an important step forward in the field of dialogue\nsegmentation. Our codes and data can be found from:\nhttps://github.com/Coldog2333/SuperDialseg.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Junfeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengzhang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1\">Akiko Aizawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Memorization for Good: Encryption with Autoregressive Language Models. (arXiv:2305.10445v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10445","description":"<p>Over-parameterized neural language models (LMs) can memorize and recite long\nsequences of training data. While such memorization is normally associated with\nundesired properties such as overfitting and information leaking, our work\ncasts memorization as an unexplored capability of LMs. We propose the first\nsymmetric encryption algorithm with autoregressive language models (SELM). We\nshow that autoregressive LMs can encode arbitrary data into a compact\nreal-valued vector (i.e., encryption) and then losslessly decode the vector to\nthe original message (i.e., decryption) via random subspace optimization and\ngreedy decoding. While SELM is not amenable to conventional cryptanalysis, we\ninvestigate its security through a novel empirical variant of the classic\nIND-CPA (indistinguishability under chosen-plaintext attack) game and show\npromising results on security. Our code and datasets are available at\nhttps://github.com/OSU-NLP-Group/SELM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1\">Samuel Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding. (arXiv:2305.10563v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2305.10563","description":"<p>We consider a contrastive learning approach to knowledge graph embedding\n(KGE) via InfoNCE. For KGE, efficient learning relies on augmenting the\ntraining data with negative triples. However, most KGE works overlook the bias\nfrom generating the negative triples-false negative triples (factual triples\nmissing from the knowledge graph). We argue that the generation of high-quality\n(i.e., hard) negative triples might lead to an increase in false negative\ntriples. To mitigate the impact of false negative triples during the generation\nof hard negative triples, we propose the Hardness and Structure-aware\n(\\textbf{HaSa}) contrastive KGE method, which alleviates the effect of false\nnegative triples while generating the hard negative triples. Experiments show\nthat HaSa improves the performance of InfoNCE-based KGE approaches and achieves\nstate-of-the-art results in several metrics for WN18RR datasets and competitive\nresults for FB15k-237 datasets compared to both classic and pre-trained\nLM-based KGE methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Honggen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">June Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molybog_I/0/1/0/all/0/1\">Igor Molybog</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation. (arXiv:2305.11490v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.11490","description":"<p>Following the impressive development of LLMs, vision-language alignment in\nLLMs is actively being researched to enable multimodal reasoning and visual IO.\nThis direction of research is particularly relevant to medical imaging because\nmedical image analysis and generation consist of reasoning based on a\ncombination of visual features and prior knowledge. Many recent works have\nfocused on training adapter networks that serve as an information bridge\nbetween image processing networks and LLMs; but presumably, in order to achieve\nmaximum reasoning potential of LLMs on visual information as well, visual and\nlanguage features should be allowed to interact more freely. This is especially\nimportant in the medical domain because understanding and generating medical\nimages such as chest X-rays (CXR) require not only accurate visual and\nlanguage-based reasoning but also a more intimate mapping between the two\nmodalities. Thus, taking inspiration from previous work on the transformer and\nVQ-GAN combination for bidirectional image and text generation, we build upon\nthis approach and develop a method for instruction-tuning an LLM pre-trained\nonly on text to gain vision-language capabilities for medical images.\nSpecifically, we leverage a pretrained LLM's existing question-answering and\ninstruction-following abilities to teach it to understand visual inputs by\ninstructing it to answer questions about image inputs and, symmetrically,\noutput both text and image responses appropriate to a given query by tuning the\nLLM with diverse tasks that encompass image-based text-generation and\ntext-based image-generation. We show that our model, LLM-CXR, trained in this\napproach shows better image-text alignment in both CXR understanding and\ngeneration tasks while being smaller in size compared to previously developed\nmodels that perform a narrower range of tasks. The code is at\nhttps://github.com/hyn2028/llm-cxr.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Suhyeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Won Jun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empower Large Language Model to Perform Better on Industrial Domain-Specific Question Answering. (arXiv:2305.11541v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11541","description":"<p>Large Language Model (LLM) has gained popularity and achieved remarkable\nresults in open-domain tasks, but its performance in real industrial\ndomain-specific scenarios is average due to its lack of specific domain\nknowledge. This issue has attracted widespread attention, but there are few\nrelevant benchmarks available. In this paper, we provide a benchmark Question\nAnswering (QA) dataset named MSQA, centered around Microsoft products and IT\ntechnical problems encountered by customers. This dataset contains industry\ncloud-specific QA knowledge, an area not extensively covered in general LLMs,\nmaking it well-suited for evaluating methods aiming to enhance LLMs'\ndomain-specific capabilities. In addition, we propose a new model interaction\nparadigm that can empower LLM to achieve better performance on domain-specific\ntasks where it is not proficient. Extensive experiments demonstrate that the\napproach following our method outperforms the commonly used LLM with retrieval\nmethods. We make our source code and sample data available at:\nhttps://aka.ms/Microsoft_QA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fangkai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zezhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1\">Mohit Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1\">Qingwei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1\">Saravan Rajmohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue Questions with LLMs. (arXiv:2305.11792v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11792","description":"<p>Large Language Models (LLMs), such as \\texttt{ChatGPT}, greatly empower\ndialogue systems with strong language understanding and generation\ncapabilities. However, most of the previous works prompt the LLMs to directly\ngenerate a response based on the dialogue context, overlooking the underlying\nlinguistic cues about the user status exhibited in the context. Such in-depth\ndialogue scenarios are challenging for existing LLMs to figure out the user's\nhidden needs and respond satisfactorily through a single-step inference. To\nthis end, we propose a novel linguistic cue-based chain-of-thoughts\n(\\textit{Cue}-CoT), which enhances the LLMs inference with an intermediate\nreasoning step to find cues exhibited in the dialogue, aiming to provide a more\npersonalized and engaging response. To evaluate the approach, we build a\nbenchmark with in-depth dialogue questions, consisting of 6 datasets in both\nChinese and English, targeting 3 major linguistic cues during the conversation:\n\\textit{personality}, \\textit{emotion}, and \\textit{psychology}. We conduct\nextensive experiments on the proposed benchmark with 5 LLMs under both\nzero-shot and one-shot settings. Empirical results demonstrate our proposed\n\\textit{Cue}-CoT method outperforms standard prompting methods in terms of both\n\\textit{helpfulness} and \\textit{acceptability} on all datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zezhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1\">Bin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining. (arXiv:2305.12074v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12074","description":"<p>Many text mining models are constructed by fine-tuning a large deep\npre-trained language model (PLM) in downstream tasks. However, a significant\nchallenge nowadays is maintaining performance when we use a lightweight model\nwith limited labelled samples. We present DisCo, a semi-supervised learning\n(SSL) framework for fine-tuning a cohort of small student models generated from\na large PLM using knowledge distillation. Our key insight is to share\ncomplementary knowledge among distilled student cohorts to promote their SSL\neffectiveness. DisCo employs a novel co-training technique to optimize a cohort\nof multiple small student models by promoting knowledge sharing among students\nunder diversified views: model views produced by different distillation\nstrategies and data views produced by various input augmentations. We evaluate\nDisCo on both semi-supervised text classification and extractive summarization\ntasks. Experimental results show that DisCo can produce student models that are\n7.6 times smaller and 4.8 times faster in inference than the baseline PLMs\nwhile maintaining comparable performance. We also show that DisCo-generated\nstudent models outperform the similar-sized models elaborately tuned in\ndistinct tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weifeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qianren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_T/0/1/0/all/0/1\">Ting Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Your Explanations Reliable? Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack. (arXiv:2305.12351v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.12351","description":"<p>LIME has emerged as one of the most commonly referenced tools in explainable\nAI (XAI) frameworks that is integrated into critical machine learning\napplications--e.g., healthcare and finance. However, its stability remains\nlittle explored, especially in the context of text data, due to the unique\ntext-space constraints. To address these challenges, in this paper, we first\nevaluate the inherent instability of LIME on text data to establish a baseline,\nand then propose a novel algorithm XAIFooler to perturb text inputs and\nmanipulate explanations that casts investigation on the stability of LIME as a\ntext perturbation optimization problem. XAIFooler conforms to the constraints\nto preserve text semantics and original prediction with small perturbations,\nand introduces Rank-biased Overlap (RBO) as a key part to guide the\noptimization of XAIFooler that satisfies all the requirements for explanation\nsimilarity measure. Extensive experiments on real-world text datasets\ndemonstrate that XAIFooler significantly outperforms all baselines by large\nmargins in its ability to manipulate LIME's explanations with high semantic\npreservability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burger_C/0/1/0/all/0/1\">Christopher Burger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lingwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Thai Le</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation. (arXiv:2305.12599v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12599","description":"<p>Combining large language models with logical reasoning enhance their capacity\nto address problems in a robust and reliable manner. Nevertheless, the\nintricate nature of logical reasoning poses challenges to gathering reliable\ndata from web for building comprehensive training datasets, subsequently\naffecting the performance on downstream tasks. To address this, we introduce a\nnovel logic-driven data augmentation approach, AMR-LDA. AMR-LDA converts the\noriginal text into an Abstract Meaning Representation (AMR) graph, a structured\nsemantic representation that encapsulates the logic structure of the sentence,\nupon which operations are performed to generate logically modified AMR graphs.\nThe modified AMR graphs are subsequently converted back into texts to create\naugmented data. Notably, our methodology is architecture-agnostic and enhances\ngenerative large language models, such as GPT-3.5 and GPT-4, through prompt\naugmentation, and fine-tuning discriminative large language models through\ncontrastive learning with logic-driven data augmentation. Empirical evidence\nunderscores the efficacy of our proposed method with improvement in performance\nacross seven downstream tasks, such as logical reasoning reading comprehension,\ntextual entailment, and natural language inference. Furthermore, our method\nranked first on the ReClor leaderboard\n\\url{https://eval.ai/web/challenges/challenge-page/503/leaderboard/1347}. The\nsource code and data are publicly available\n\\url{https://github.com/Strong-AI-Lab/Logical-Equivalence-driven-AMR-Data-Augmentation-for-Representation-Learning}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1\">Alex Yuxuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhenyun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1\">Gael Gendron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pistotti_T/0/1/0/all/0/1\">Timothy Pistotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_N/0/1/0/all/0/1\">Neset Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_N/0/1/0/all/0/1\">Nathan Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yonghua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1\">Paul Denny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiamou Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling for Many-to-Many Multimodal Summarization. (arXiv:2305.12767v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.12767","description":"<p>Many-to-many multimodal summarization (M$^3$S) task aims to generate\nsummaries in any language with document inputs in any language and the\ncorresponding image sequence, which essentially comprises multimodal\nmonolingual summarization (MMS) and multimodal cross-lingual summarization\n(MXLS) tasks. Although much work has been devoted to either MMS or MXLS and has\nobtained increasing attention in recent years, little research pays attention\nto the M$^3$S task. Besides, existing studies mainly focus on 1) utilizing MMS\nto enhance MXLS via knowledge distillation without considering the performance\nof MMS or 2) improving MMS models by filtering summary-unrelated visual\nfeatures with implicit learning or explicitly complex training objectives. In\nthis paper, we first introduce a general and practical task, i.e., M$^3$S.\nFurther, we propose a dual knowledge distillation and target-oriented vision\nmodeling framework for the M$^3$S task. Specifically, the dual knowledge\ndistillation method guarantees that the knowledge of MMS and MXLS can be\ntransferred to each other and thus mutually prompt both of them. To offer\ntarget-oriented visual features, a simple yet effective target-oriented\ncontrastive objective is designed and responsible for discarding needless\nvisual information. Extensive experiments on the many-to-many setting show the\neffectiveness of the proposed approach. Additionally, we will contribute a\nmany-to-many multimodal summarization (M$^3$Sum) dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yunlong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lion: Adversarial Distillation of Proprietary Large Language Models. (arXiv:2305.12870v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12870","description":"<p>The practice of transferring knowledge from a sophisticated, proprietary\nlarge language model (LLM) to a compact, open-source LLM has garnered\nconsiderable attention. Previous works have focused on a unidirectional\nknowledge distillation way by aligning the responses of the student model with\nthose of the teacher model to a set of instructions. Nevertheless, they\noverlooked the possibility of incorporating any reciprocal\n\"feedback\"--identifying challenging instructions where the student model's\nperformance falls short--to boost the student model's proficiency iteratively.\nTo this end, we propose a novel adversarial distillation framework for a more\nefficient knowledge transfer. Leveraging the versatile role adaptability of\nLLMs, we prompt the teacher model to identify \"hard\" instructions and generate\nnew \"hard\" instructions for the student model, creating a three-stage\nadversarial loop of imitation, discrimination, and generation. By applying this\nadversarial framework, we successfully transfer knowledge from ChatGPT to a\nstudent model (named Lion), using a mere 70k training data. Our results show\nthat Lion-13B not only achieves comparable open-ended generation capabilities\nto ChatGPT but surpasses conventional state-of-the-art (SOTA) instruction-tuned\nmodels like Vicuna-13B by 55.4% in challenging zero-shot reasoning benchmarks\nsuch as BIG-Bench Hard (BBH) and 16.7% on AGIEval. Code and model can be found\nat https://github.com/YJiangcm/Lion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chunkit Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefixes. (arXiv:2305.13499v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13499","description":"<p>Many real-world applications require making multiple predictions from the\nsame text. Fine-tuning a large pre-trained language model for each downstream\ntask causes computational burdens in the inference time due to several times of\nforward passes. To amortize the computational cost, freezing the language model\nand building lightweight models for downstream tasks based on fixed text\nrepresentations are common solutions. Accordingly, how to learn fixed but\ngeneral text representations that can generalize well to unseen downstream\ntasks becomes a challenge. Previous works have shown that the generalizability\nof representations can be improved by fine-tuning the pre-trained language\nmodel with some source tasks in a multi-tasking way. In this work, we propose a\nprefix-based method to learn the fixed text representations with source tasks.\nWe learn a task-specific prefix for each source task independently and combine\nthem to get the final representations. Our experimental results show that\nprefix-based training performs better than multi-tasking training and can\nupdate the text representations at a smaller computational cost than\nmulti-tasking training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Liang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1\">Amjad Almahairi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinott_R/0/1/0/all/0/1\">Ruty Rinott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration. (arXiv:2305.13626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13626","description":"<p>Conversational systems based on Large Language Models (LLMs), such as\nChatGPT, show exceptional proficiency in context understanding and response\ngeneration. However, despite their impressive capabilities, they still possess\nlimitations, such as providing randomly-guessed answers to ambiguous queries or\nfailing to refuse users' requests, both of which are considered aspects of a\nconversational agent's proactivity. This raises the question of whether\nLLM-based conversational systems are equipped to handle proactive dialogue\nproblems. In this work, we conduct a comprehensive analysis of LLM-based\nconversational systems, specifically focusing on three aspects of proactive\ndialogue systems: clarification, target-guided, and non-collaborative\ndialogues. To trigger the proactivity of LLMs, we propose the Proactive\nChain-of-Thought prompting scheme, which augments LLMs with the goal planning\ncapability over descriptive reasoning chains. Empirical findings are discussed\nto promote future studies on LLM-based proactive dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1\">Lizi Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenqiang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Prompt Optimization for Large Language Models Against Distribution Shifts. (arXiv:2305.13954v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13954","description":"<p>Large Language Model (LLM) has demonstrated significant ability in various\nNatural Language Processing tasks. However, their effectiveness is highly\ndependent on the phrasing of the task prompt, leading to research on automatic\nprompt optimization using labeled task data. We reveal that these prompt\noptimization techniques are vulnerable to distribution shifts such as\nsubpopulation shifts, which are common for LLMs in real-world scenarios such as\ncustomer reviews analysis. In this light, we propose a new problem of robust\nprompt optimization for LLMs against distribution shifts, which requires the\nprompt optimized over the labeled source group can simultaneously generalize to\nan unlabeled target group. To solve this problem, we propose Generalized Prompt\nOptimization framework, which incorporates the unlabeled data from the target\ngroup into prompt optimization. Extensive experimental results demonstrate the\neffectiveness of the proposed framework with significant performance\nimprovement on the target group and comparable performance on the source group.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Moxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jizhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning. (arXiv:2305.14045v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14045","description":"<p>Language models (LMs) with less than 100B parameters are known to perform\npoorly on chain-of-thought (CoT) reasoning in contrast to large LMs when\nsolving unseen tasks. In this work, we aim to equip smaller LMs with the\nstep-by-step reasoning capability by instruction tuning with CoT rationales. In\norder to achieve this goal, we first introduce a new instruction-tuning dataset\ncalled the CoT Collection, which augments the existing Flan Collection\n(including only 9 CoT tasks) with additional 1.84 million rationales across\n1,060 tasks. We show that CoT fine-tuning Flan-T5 (3B &amp; 11B) with CoT\nCollection enables smaller LMs to have better CoT capabilities on unseen tasks.\nOn the BIG-Bench-Hard (BBH) benchmark, we report an average improvement of\n+4.34% (Flan-T5 3B) and +2.60% (Flan-T5 11B), in terms of zero-shot task\naccuracy. Furthermore, we show that instruction tuning with CoT Collection\nallows LMs to possess stronger few-shot learning capabilities on 4\ndomain-specific tasks, resulting in an improvement of +2.24% (Flan-T5 3B) and\n+2.37% (Flan-T5 11B), even outperforming ChatGPT utilizing demonstrations until\nthe max length by a +13.98% margin. Our code, the CoT Collection data, and\nmodel checkpoints are publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungone Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joo_S/0/1/0/all/0/1\">Se June Joo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Joel Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Seonghyeon Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14196","description":"<p>We introduce ZeroSCROLLS, a zero-shot benchmark for natural language\nunderstanding over long texts, which contains only test and small validation\nsets, without training data. We adapt six tasks from the SCROLLS benchmark, and\nadd four new datasets, including two novel information fusing tasks, such as\naggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a\ncomprehensive evaluation of both open-source and closed large language models,\nfinding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest\naverage score. However, there is still room for improvement on multiple open\nchallenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to\npass the naive baseline. As the state of the art is a moving target, we invite\nresearchers to evaluate their ideas on the live ZeroSCROLLS leaderboard.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shaham_U/0/1/0/all/0/1\">Uri Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivgi_M/0/1/0/all/0/1\">Maor Ivgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Efrat_A/0/1/0/all/0/1\">Avia Efrat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1\">Omer Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Finding the Pillars of Strength for Multi-Head Attention. (arXiv:2305.14380v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.14380","description":"<p>Recent studies have revealed some issues of Multi-Head Attention (MHA), e.g.,\nredundancy and over-parameterization. Specifically, the heads of MHA were\noriginally designed to attend to information from different representation\nsubspaces, whereas prior studies found that some attention heads likely learn\nsimilar features and can be pruned without harming performance. Inspired by the\nminimum-redundancy feature selection, we assume that focusing on the most\nrepresentative and distinctive features with minimum resources can mitigate the\nabove issues and lead to more effective and efficient MHAs. In particular, we\npropose Grouped Head Attention, trained with a self-supervised group constraint\nthat group attention heads, where each group focuses on an essential but\ndistinctive feature subset. We additionally propose a Voting-to-Stay procedure\nto remove redundant heads, thus achieving a transformer with lighter weights.\nMoreover, our method achieves significant performance gains on three\nwell-established tasks while considerably compressing parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jinjie Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_R/0/1/0/all/0/1\">Rui Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zonglin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_H/0/1/0/all/0/1\">Han Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BAND: Biomedical Alert News Dataset. (arXiv:2305.14480v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14480","description":"<p>Infectious disease outbreaks continue to pose a significant threat to human\nhealth and well-being. To improve disease surveillance and understanding of\ndisease spread, several surveillance systems have been developed to monitor\ndaily news alerts and social media. However, existing systems lack thorough\nepidemiological analysis in relation to corresponding alerts or news, largely\ndue to the scarcity of well-annotated reports data. To address this gap, we\nintroduce the Biomedical Alert News Dataset (BAND), which includes 1,508\nsamples from existing reported news articles, open emails, and alerts, as well\nas 30 epidemiology-related questions. These questions necessitate the model's\nexpert reasoning abilities, thereby offering valuable insights into the\noutbreak of the disease. The BAND dataset brings new challenges to the NLP\nworld, requiring better disguise capability of the content and the ability to\ninfer important information. We provide several benchmark tasks, including\nNamed Entity Recognition (NER), Question Answering (QA), and Event Extraction\n(EE), to show how existing models are capable of handling these tasks in the\nepidemiology domain. To the best of our knowledge, the BAND corpus is the\nlargest corpus of well-annotated biomedical outbreak alert news with\nelaborately designed questions, making it a valuable resource for\nepidemiologists and NLP researchers alike.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zihao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meiru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zaiqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yannan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buckeridge_D/0/1/0/all/0/1\">David Buckeridge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text Translation. (arXiv:2305.14838v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14838","description":"<p>Joint speech-language training is challenging due to the large demand for\ntraining data and GPU consumption, as well as the modality gap between speech\nand language. We present ComSL, a speech-language model built atop a composite\narchitecture of public pretrained speech-only and language-only models and\noptimized data-efficiently for spoken language tasks. Particularly, we propose\nto incorporate cross-modality learning into transfer learning and conduct them\nsimultaneously for downstream tasks in a multi-task learning manner. Our\napproach has demonstrated effectiveness in end-to-end speech-to-text\ntranslation tasks, achieving a new state-of-the-art average BLEU score of 31.5\non the multilingual speech to English text translation task for 21 languages,\nas measured on the public CoVoST2 evaluation set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_C/0/1/0/all/0/1\">Chenyang Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yanmin Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Words to Wires: Generating Functioning Electronic Devices from Natural Language Descriptions. (arXiv:2305.14874v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14874","description":"<p>In this work, we show that contemporary language models have a previously\nunknown skill -- the capacity for electronic circuit design from high-level\ntextual descriptions, akin to code generation. We introduce two benchmarks:\nPins100, assessing model knowledge of electrical components, and Micro25,\nevaluating a model's capability to design common microcontroller circuits and\ncode in the Arduino ecosystem that involve input, output, sensors, motors,\nprotocols, and logic -- with models such as GPT-4 and Claude-V1 achieving\nbetween 60% to 96% Pass@1 on generating full devices. We include six case\nstudies of using language models as a design assistant for moderately complex\ndevices, such as a radiation-powered random number generator, an emoji\nkeyboard, a visible spectrometer, and several assistive devices, while offering\na qualitative analysis performance, outlining evaluation challenges, and\nsuggesting areas of development to improve complex circuit design and practical\nutility. With this work, we aim to spur research at the juncture of natural\nlanguage processing and electronic design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jansen_P/0/1/0/all/0/1\">Peter Jansen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adversarial Demonstration Attacks on Large Language Models. (arXiv:2305.14950v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14950","description":"<p>With the emergence of more powerful large language models (LLMs), such as\nChatGPT and GPT-4, in-context learning (ICL) has gained significant prominence\nin leveraging these models for specific tasks by utilizing data-label pairs as\nprecondition prompts. While incorporating demonstrations can greatly enhance\nthe performance of LLMs across various tasks, it may introduce a new security\nconcern: attackers can manipulate only the demonstrations without changing the\ninput to perform an attack. In this paper, we investigate the security concern\nof ICL from an adversarial perspective, focusing on the impact of\ndemonstrations. We propose a novel attack method named advICL, which aims to\nmanipulate only the demonstration without changing the input to mislead the\nmodels. Our results demonstrate that as the number of demonstrations increases,\nthe robustness of in-context learning would decrease. Additionally, we also\nidentify the intrinsic property of the demonstrations is that they can be used\n(prepended) with different inputs. As a result, it introduces a more practical\nthreat model in which an attacker can attack the test input example even\nwithout knowing and manipulating it. To achieve it, we propose the transferable\nversion of advICL, named Transferable-advICL. Our experiment shows that the\nadversarial demonstration generated by Transferable-advICL can successfully\nattack the unseen test input examples. We hope that our study reveals the\ncritical security risks associated with ICL and underscores the need for\nextensive research on the robustness of ICL, particularly given its increasing\nsignificance in the advancement of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiongxiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zichen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Keun Hee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhuojun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhaoheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhuofeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lawyer LLaMA Technical Report. (arXiv:2305.15062v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15062","description":"<p>Large Language Models (LLMs), like LLaMA, have exhibited remarkable\nperformance across various tasks. Nevertheless, when deployed to specific\ndomains such as law or medicine, the models still confront the challenge of a\ndeficiency in domain-specific knowledge and an inadequate capability to\nleverage that knowledge to resolve domain-related problems. In this paper, we\npropose a new framework to adapt LLMs to specific domains and build Lawyer\nLLaMA, a legal domain LLM, based on this framework. Specifically, we inject\ndomain knowledge during the continual training stage and teach the model to\nlearn professional skills using properly designed supervised fine-tuning tasks.\nMoreover, to alleviate the hallucination problem during the model's generation,\nwe add a retrieval module and extract relevant legal articles before the model\nanswers any queries. When learning domain-specific skills, we find that\nexperts' experience is much more useful than experiences distilled from\nChatGPT, where hundreds of expert-written data outperform tens of thousands of\nChatGPT-generated ones. We will release our model and data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Quzhe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_M/0/1/0/all/0/1\">Mingxu Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1\">Zhenwei An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Cong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhibin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zirui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yansong Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. (arXiv:2306.05685v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05685","description":"<p>Evaluating large language model (LLM) based chat assistants is challenging\ndue to their broad capabilities and the inadequacy of existing benchmarks in\nmeasuring human preferences. To address this, we explore using strong LLMs as\njudges to evaluate these models on more open-ended questions. We examine the\nusage and limitations of LLM-as-a-judge, including position, verbosity, and\nself-enhancement biases, as well as limited reasoning ability, and propose\nsolutions to mitigate some of them. We then verify the agreement between LLM\njudges and human preferences by introducing two benchmarks: MT-bench, a\nmulti-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our\nresults reveal that strong LLM judges like GPT-4 can match both controlled and\ncrowdsourced human preferences well, achieving over 80% agreement, the same\nlevel of agreement between humans. Hence, LLM-as-a-judge is a scalable and\nexplainable way to approximate human preferences, which are otherwise very\nexpensive to obtain. Additionally, we show our benchmark and traditional\nbenchmarks complement each other by evaluating several variants of LLaMA and\nVicuna. The MT-bench questions, 3K expert votes, and 30K conversations with\nhuman preferences are publicly available at\nhttps://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lianmin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_W/0/1/0/all/0/1\">Wei-Lin Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Y/0/1/0/all/0/1\">Ying Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_S/0/1/0/all/0/1\">Siyuan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhanghao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yonghao Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuohan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dacheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric. P Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1\">Joseph E. Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1\">Ion Stoica</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clickbait Detection via Large Language Models. (arXiv:2306.09597v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09597","description":"<p>Clickbait, which aims to induce users with some surprising and even thrilling\nheadlines for increasing click-through rates, permeates almost all online\ncontent publishers, such as news portals and social media. Recently, Large\nLanguage Models (LLMs) have emerged as a powerful instrument and achieved\ntremendous success in a serious of NLP downstream tasks. However, it is not yet\nknown whether LLMs can be served as a high-quality clickbait detection system.\nIn this paper, we analyze the performance of LLMs in the few-shot scenarios on\na number of English and Chinese benchmark datasets. Experimental results show\nthat LLMs cannot achieve the best results compared to the state-of-the-art deep\nand fine-tuning PLMs methods. Different from the human intuition, the\nexperiments demonstrated that LLMs cannot make satisfied clickbait detection\njust by the headlines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Han Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yunhao Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_J/0/1/0/all/0/1\">Jipeng Qiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analysis of the Cambridge Multiple-Choice Questions Reading Dataset with a Focus on Candidate Response Distribution. (arXiv:2306.13047v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.13047","description":"<p>Multiple choice exams are widely used to assess candidates across a diverse\nrange of domains and tasks. To moderate question quality, newly proposed\nquestions often pass through pre-test evaluation stages before being deployed\ninto real-world exams. Currently, this evaluation process is manually\nintensive, which can lead to time lags in the question development cycle.\nStreamlining this process via automation can significantly enhance efficiency,\nhowever, there's a current lack of datasets with adequate pre-test analysis\ninformation. In this paper we analyse a subset of the public Cambridge\nMultiple-Choice Questions Reading Database released by Cambridge University\nPress &amp; Assessment; a multiple-choice comprehension dataset of questions at\ndifferent target levels, with corresponding candidate selection distributions.\nWe introduce the task of candidate distribution matching, propose several\nevaluation metrics for the task, and demonstrate that automatic systems trained\non RACE++ can be leveraged as baselines for our task. We further demonstrate\nthat these automatic systems can be used for practical pre-test evaluation\ntasks such as detecting underperforming distractors, where our detection\nsystems can automatically identify poor distractors that few candidates select.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vatsal Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullooly_A/0/1/0/all/0/1\">Andrew Mullooly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knill_K/0/1/0/all/0/1\">Kate Knill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J. F. Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.15343","description":"<p>This research paper focuses on the challenges posed by hallucinations in\nlarge language models (LLMs), particularly in the context of the medical\ndomain. Hallucination, wherein these models generate plausible yet unverified\nor incorrect information, can have serious consequences in healthcare\napplications. We propose a new benchmark and dataset, Med-HALT (Medical Domain\nHallucination Test), designed specifically to evaluate and reduce\nhallucinations. Med-HALT provides a diverse multinational dataset derived from\nmedical examinations across various countries and includes multiple innovative\ntesting modalities. Med-HALT includes two categories of tests reasoning and\nmemory-based hallucination tests, designed to assess LLMs's problem-solving and\ninformation retrieval abilities.\n</p>\n<p>Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2,\nMPT, and Falcon, revealing significant differences in their performance. The\npaper provides detailed insights into the dataset, promoting transparency and\nreproducibility. Through this work, we aim to contribute to the development of\nsafer and more reliable language models in healthcare. Our benchmark can be\nfound at medhalt.github.io\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1\">Ankit Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umapathi_L/0/1/0/all/0/1\">Logesh Kumar Umapathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankarasubbu_M/0/1/0/all/0/1\">Malaikannan Sankarasubbu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Science and engineering for what? A large-scale analysis of students' projects in science fairs. (arXiv:2308.02962v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.02962","description":"<p>Science and Engineering fairs offer K-12 students opportunities to engage\nwith authentic STEM practices. Particularly, students are given the chance to\nexperience authentic and open inquiry processes, by defining which themes,\nquestions and approaches will guide their scientific endeavors. In this study,\nwe analyzed data from over 5,000 projects presented at a nationwide science\nfair in Brazil over the past 20 years using topic modeling to identify the main\ntopics that have driven students' inquiry and design. Our analysis identified a\nbroad range of topics being explored, with significant variations over time,\nregion, and school setting. We argue those results and proposed methodology can\nnot only support further research in the context of science fairs, but also\ninform instruction and design of contexts-specific resources to support\nstudents in open inquiry experiences in different settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eloy_A/0/1/0/all/0/1\">Adelmo Eloy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferraz_T/0/1/0/all/0/1\">Thomas Palmeira Ferraz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_F/0/1/0/all/0/1\">Fellip Silva Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopes_R/0/1/0/all/0/1\">Roseli de Deus Lopes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SynJax: Structured Probability Distributions for JAX. (arXiv:2308.03291v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.03291","description":"<p>The development of deep learning software libraries enabled significant\nprogress in the field by allowing users to focus on modeling, while letting the\nlibrary to take care of the tedious and time-consuming task of optimizing\nexecution for modern hardware accelerators. However, this has benefited only\nparticular types of deep learning models, such as Transformers, whose\nprimitives map easily to the vectorized computation. The models that explicitly\naccount for structured objects, such as trees and segmentations, did not\nbenefit equally because they require custom algorithms that are difficult to\nimplement in a vectorized form.\n</p>\n<p>SynJax directly addresses this problem by providing an efficient vectorized\nimplementation of inference algorithms for structured distributions covering\nalignment, tagging, segmentation, constituency trees and spanning trees. This\nis done by exploiting the connection between algorithms for automatic\ndifferentiation and probabilistic inference. With SynJax we can build\nlarge-scale differentiable models that explicitly model structure in the data.\nThe code is available at https://github.com/google-deepmind/synjax\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stanojevic_M/0/1/0/all/0/1\">Milo&#x161; Stanojevi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sartran_L/0/1/0/all/0/1\">Laurent Sartran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLEVA: Chinese Language Models EVAluation Platform. (arXiv:2308.04813v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04813","description":"<p>With the continuous emergence of Chinese Large Language Models (LLMs), how to\nevaluate a model's capabilities has become an increasingly significant issue.\nThe absence of a comprehensive Chinese benchmark that thoroughly assesses a\nmodel's performance, the unstandardized and incomparable prompting procedure,\nand the prevalent risk of contamination pose major challenges in the current\nevaluation of Chinese LLMs. We present CLEVA, a user-friendly platform crafted\nto holistically evaluate Chinese LLMs. Our platform employs a standardized\nworkflow to assess LLMs' performance across various dimensions, regularly\nupdating a competitive leaderboard. To alleviate contamination, CLEVA curates a\nsignificant proportion of new data and develops a sampling strategy that\nguarantees a unique subset for each leaderboard round. Empowered by an\neasy-to-use interface that requires just a few mouse clicks and a model API,\nusers can conduct a thorough evaluation with minimal coding. Large-scale\nexperiments featuring 23 Chinese LLMs have validated CLEVA's efficacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jianqiao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1\">Duo Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zi-Yuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiaohui Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongfeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shijia Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Thresh: A Unified, Customizable and Deployable Platform for Fine-Grained Text Evaluation. (arXiv:2308.06953v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.06953","description":"<p>Fine-grained, span-level human evaluation has emerged as a reliable and\nrobust method for evaluating text generation tasks such as summarization,\nsimplification, machine translation and news generation, and the derived\nannotations have been useful for training automatic metrics and improving\nlanguage models. However, existing annotation tools implemented for these\nevaluation frameworks lack the adaptability to be extended to different domains\nor languages, or modify annotation settings according to user needs; and, the\nabsence of a unified annotated data format inhibits the research in multi-task\nlearning. In this paper, we introduce Thresh, a unified, customizable and\ndeployable platform for fine-grained evaluation. With a single YAML\nconfiguration file, users can build and test an annotation interface for any\nframework within minutes -- all in one web browser window. To facilitate\ncollaboration and sharing, Thresh provides a community hub that hosts a\ncollection of fine-grained frameworks and corresponding annotations made and\ncollected by the community, covering a wide range of NLP tasks. For deployment,\nThresh offers multiple options for any scale of annotation projects from small\nmanual inspections to large crowdsourcing ones. Additionally, we introduce a\nPython library to streamline the entire process from typology design and\ndeployment to annotation processing. Thresh is publicly accessible at\nhttps://thresh.tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Heineman_D/0/1/0/all/0/1\">David Heineman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1\">Yao Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SummHelper: Collaborative Human-Computer Summarization. (arXiv:2308.08363v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.08363","description":"<p>Current approaches for text summarization are predominantly automatic, with\nrather limited space for human intervention and control over the process. In\nthis paper, we introduce SummHelper, a 2-phase summarization assistant designed\nto foster human-machine collaboration. The initial phase involves content\nselection, where the system recommends potential content, allowing users to\naccept, modify, or introduce additional selections. The subsequent phase,\ncontent consolidation, involves SummHelper generating a coherent summary from\nthese selections, which users can then refine using visual mappings between the\nsummary and the source text. Small-scale user studies reveal the effectiveness\nof our application, with participants being especially appreciative of the\nbalance between automated guidance and opportunities for personal input.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Slobodkin_A/0/1/0/all/0/1\">Aviv Slobodkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nachum_N/0/1/0/all/0/1\">Niv Nachum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amar_S/0/1/0/all/0/1\">Shmuel Amar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapira_O/0/1/0/all/0/1\">Ori Shapira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10335","description":"<p>Recently, the large language models (LLMs) have shown extraordinary ability\nin understanding natural language and generating programming code. It has been\na common practice of software engineers to consult LLMs when encountering\ncoding questions. Although efforts have been made to avoid syntax errors and\nalign the code with the intended semantics, the reliability and robustness of\nthe code generationfrom LLMs have not yet been thoroughly studied. The\nexecutable code is not equivalent to the reliable and robust code, especially\nin the context of real-world software development. The misuse of APIs in the\ngenerated code could lead to severe problem, such as resource leaks, program\ncrashes. To make things worse, the users of LLM code generation services are\nactually the developers that are most vulnerable to these code that seems right\n-- They are always novice developers that are not familiar with the APIs that\nLLMs generate code for them. Therefore, they could hardly tell the misuse in\nthe code generated by LLMs, which further facilitates the incorrect code\napplied in real-world software. Existing code evaluation benchmark and datasets\nfocus on crafting small tasks such as programming questions in coding\ninterviews, which however deviates from the problem that developers would ask\nLLM for real-world coding help. To fill the missing piece, in this work, we\npropose a dataset RobustAPI for evaluating the reliability and robustness of\ncode generated by LLMs. We collect 1208 coding questions from StackOverflow on\n24 representative Java APIs. We summarize thecommon misuse patterns of these\nAPIs and evaluate them oncurrent popular LLMs. The evaluation results show that\nevenfor GPT-4, 62% of the generated code contains API misuses,which would cause\nunexpected consequences if the code isintroduced into real-world software.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1\">Li Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RaLLe: A Framework for Developing and Evaluating Retrieval-Augmented Large Language Models. (arXiv:2308.10633v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10633","description":"<p>Retrieval-augmented large language models (R-LLMs) combine pre-trained large\nlanguage models (LLMs) with information retrieval systems to improve the\naccuracy of factual question-answering. However, current libraries for building\nR-LLMs provide high-level abstractions without sufficient transparency for\nevaluating and optimizing prompts within specific inference processes such as\nretrieval and generation. To address this gap, we present RaLLe, an open-source\nframework designed to facilitate the development, evaluation, and optimization\nof R-LLMs for knowledge-intensive tasks. With RaLLe, developers can easily\ndevelop and evaluate R-LLMs, improving hand-crafted prompts, assessing\nindividual inference processes, and objectively measuring overall system\nperformance quantitatively. By leveraging these features, developers can\nenhance the performance and accuracy of their R-LLMs in knowledge-intensive\ngeneration tasks. We open-source our code at https://github.com/yhoshi3/RaLLe.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hoshi_Y/0/1/0/all/0/1\">Yasuto Hoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyashita_D/0/1/0/all/0/1\">Daisuke Miyashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_Y/0/1/0/all/0/1\">Youyang Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tatsuno_K/0/1/0/all/0/1\">Kento Tatsuno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morioka_Y/0/1/0/all/0/1\">Yasuhiro Morioka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torii_O/0/1/0/all/0/1\">Osamu Torii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deguchi_J/0/1/0/all/0/1\">Jun Deguchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LMSanitator: Defending Prompt-Tuning Against Task-Agnostic Backdoors. (arXiv:2308.13904v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.13904","description":"<p>Prompt-tuning has emerged as an attractive paradigm for deploying large-scale\nlanguage models due to its strong downstream task performance and efficient\nmultitask serving ability. Despite its wide adoption, we empirically show that\nprompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside\nin the pretrained models and can affect arbitrary downstream tasks. The\nstate-of-the-art backdoor detection approaches cannot defend against\ntask-agnostic backdoors since they hardly converge in reversing the backdoor\ntriggers. To address this issue, we propose LMSanitator, a novel approach for\ndetecting and removing task-agnostic backdoors on Transformer models. Instead\nof directly inverting the triggers, LMSanitator aims to invert the predefined\nattack vectors (pretrained models' output when the input is embedded with\ntriggers) of the task-agnostic backdoors, which achieves much better\nconvergence performance and backdoor detection accuracy. LMSanitator further\nleverages prompt-tuning's property of freezing the pretrained model to perform\naccurate and fast output monitoring and input purging during the inference\nphase. Extensive experiments on multiple language models and NLP tasks\nillustrate the effectiveness of LMSanitator. For instance, LMSanitator achieves\n92.8% backdoor detection accuracy on 960 models and decreases the attack\nsuccess rate to less than 1% in most scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chengkun Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_W/0/1/0/all/0/1\">Wenlong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhikun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Minghu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_W/0/1/0/all/0/1\">Wenjing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zihui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenzhi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Code Generation by Dynamic Temperature Sampling. (arXiv:2309.02772v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2309.02772","description":"<p>Recently, Large Language Models (LLMs) have shown impressive results in code\ngeneration. However, existing decoding strategies are designed for Natural\nLanguage (NL) generation, overlooking the differences between NL and\nprogramming languages (PL). Due to this oversight, a better decoding strategy\nfor code generation remains an open question. In this paper, we conduct the\nfirst systematic study to explore a decoding strategy specialized in code\ngeneration. With an analysis of loss distributions of code tokens, we find that\ncode tokens can be divided into two categories: challenging tokens that are\ndifficult to predict and confident tokens that can be easily inferred. Among\nthem, the challenging tokens mainly appear at the beginning of a code block.\nInspired by the above findings, we propose a simple yet effective method:\nAdaptive Temperature (AdapT) sampling, which dynamically adjusts the\ntemperature coefficient when decoding different tokens. We apply a larger\ntemperature when sampling for challenging tokens, allowing LLMs to explore\ndiverse choices. We employ a smaller temperature for confident tokens avoiding\nthe influence of tail randomness noises. We apply AdapT sampling to LLMs with\ndifferent sizes and conduct evaluations on two popular datasets. Results show\nthat AdapT sampling significantly outperforms state-of-the-art decoding\nstrategy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuqi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">YunFei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1\">Hong Mei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing?. (arXiv:2309.08636v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08636","description":"<p>Historical emphasis on writing mastery has shifted with advances in\ngenerative AI, especially in scientific writing. This study analysed six AI\nchatbots for scholarly writing in humanities and archaeology. Using methods\nthat assessed factual correctness and scientific contribution, ChatGPT-4 showed\nthe highest quantitative accuracy, closely followed by ChatGPT-3.5, Bing, and\nBard. However, Claude 2 and Aria scored considerably lower. Qualitatively, all\nAIs exhibited proficiency in merging existing knowledge, but none produced\noriginal scientific content. Inter-estingly, our findings suggest ChatGPT-4\nmight represent a plateau in large language model size. This research\nemphasizes the unique, intricate nature of human research, suggesting that AI's\nemulation of human originality in scientific writing is challenging. As of\n2023, while AI has transformed content generation, it struggles with original\ncontributions in humanities. This may change as AI chatbots continue to evolve\ninto LLM-powered software.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lozic_E/0/1/0/all/0/1\">Edisa Lozi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stular_B/0/1/0/all/0/1\">Benjamin &#x160;tular</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models. (arXiv:2309.13567v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.13567","description":"<p>With the development of web technology, social media texts are becoming a\nrich source for automatic mental health analysis. As traditional discriminative\nmethods bear the problem of low interpretability, the recent large language\nmodels have been explored for interpretable mental health analysis on social\nmedia, which aims to provide detailed explanations along with predictions. The\nresults show that ChatGPT can generate approaching-human explanations for its\ncorrect classifications. However, LLMs still achieve unsatisfactory\nclassification performance in a zero-shot/few-shot manner. Domain-specific\nfinetuning is an effective solution, but faces 2 challenges: 1) lack of\nhigh-quality training data. 2) no open-source LLMs for interpretable mental\nhealth analysis were released to lower the finetuning cost. To alleviate these\nproblems, we build the first multi-task and multi-source interpretable mental\nhealth instruction (IMHI) dataset on social media, with 105K data samples. The\nraw social media data are collected from 10 existing sources covering 8 mental\nhealth analysis tasks. We use expert-written few-shot prompts and collected\nlabels to prompt ChatGPT and obtain explanations from its responses. To ensure\nthe reliability of the explanations, we perform strict automatic and human\nevaluations on the correctness, consistency, and quality of generated data.\nBased on the IMHI dataset and LLaMA2 foundation models, we train MentalLLaMA,\nthe first open-source LLM series for interpretable mental health analysis with\ninstruction-following capability. We also evaluate the performance of\nMentalLLaMA on the IMHI evaluation benchmark with 10 test sets, where their\ncorrectness for making predictions and the quality of explanations are\nexamined. The results show that MentalLLaMA approaches state-of-the-art\ndiscriminative methods in correctness and generates high-quality explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kailai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianlin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1\">Ziyan Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1\">Sophia Ananiadou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jimin Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Legal Question-Answering in the Indian Context: Efficacy, Challenges, and Potential of Modern AI Models. (arXiv:2309.14735v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.14735","description":"<p>Legal QA platforms bear the promise to metamorphose the manner in which legal\nexperts engage with jurisprudential documents. In this exposition, we embark on\na comparative exploration of contemporary AI frameworks, gauging their\nadeptness in catering to the unique demands of the Indian legal milieu, with a\nkeen emphasis on Indian Legal Question Answering (AILQA). Our discourse zeroes\nin on an array of retrieval and QA mechanisms, positioning the OpenAI GPT model\nas a reference point. The findings underscore the proficiency of prevailing\nAILQA paradigms in decoding natural language prompts and churning out precise\nresponses. The ambit of this study is tethered to the Indian criminal legal\nlandscape, distinguished by its intricate nature and associated logistical\nconstraints. To ensure a holistic evaluation, we juxtapose empirical metrics\nwith insights garnered from seasoned legal practitioners, thereby painting a\ncomprehensive picture of AI's potential and challenges within the realm of\nIndian legal QA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nigam_S/0/1/0/all/0/1\">Shubham Kumar Nigam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Shubham Kumar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Ayush Kumar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shallum_N/0/1/0/all/0/1\">Noel Shallum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Chain of Thought Reasoning: Advances, Frontiers and Future. (arXiv:2309.15402v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.15402","description":"<p>Chain-of-thought reasoning, a cognitive process fundamental to human\nintelligence, has garnered significant attention in the realm of artificial\nintelligence and natural language processing. However, there still remains a\nlack of a comprehensive survey for this arena. To this end, we take the first\nstep and present a thorough survey of this research field carefully and widely.\nWe use X-of-Thought to refer to Chain-of-Thought in a broad sense. In detail,\nwe systematically organize the current research according to the taxonomies of\nmethods, including XoT construction, XoT structure variants, and enhanced XoT.\nAdditionally, we describe XoT with frontier applications, covering planning,\ntool use, and distillation. Furthermore, we address challenges and discuss some\nfuture directions, including faithfulness, multi-modal, and theory. We hope\nthis survey serves as a valuable resource for researchers seeking to innovate\nwithin the domain of chain-of-thought reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1\">Zheng Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jingchang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qianglong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Weijiang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Weihua Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HyPoradise: An Open Baseline for Generative Speech Recognition with Large Language Models. (arXiv:2309.15701v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.15701","description":"<p>Advancements in deep neural networks have allowed automatic speech\nrecognition (ASR) systems to attain human parity on several publicly available\nclean speech datasets. However, even state-of-the-art ASR systems experience\nperformance degradation when confronted with adverse conditions, as a\nwell-trained acoustic model is sensitive to variations in the speech domain,\ne.g., background noise. Intuitively, humans address this issue by relying on\ntheir linguistic knowledge: the meaning of ambiguous spoken terms is usually\ninferred from contextual cues thereby reducing the dependency on the auditory\nsystem. Inspired by this observation, we introduce the first open-source\nbenchmark to utilize external large language models (LLMs) for ASR error\ncorrection, where N-best decoding hypotheses provide informative elements for\ntrue transcription prediction. This approach is a paradigm shift from the\ntraditional language model rescoring strategy that can only select one\ncandidate hypothesis as the output transcription. The proposed benchmark\ncontains a novel dataset, HyPoradise (HP), encompassing more than 334,000 pairs\nof N-best hypotheses and corresponding accurate transcriptions across prevalent\nspeech domains. Given this dataset, we examine three types of error correction\ntechniques based on LLMs with varying amounts of labeled\nhypotheses-transcription pairs, which gains a significant word error rate (WER)\nreduction. Experimental evidence demonstrates the proposed technique achieves a\nbreakthrough by surpassing the upper bound of traditional re-ranking based\nmethods. More surprisingly, LLM with reasonable prompt and its generative\ncapability can even correct those tokens that are missing in N-best list. We\nmake our results publicly accessible for reproducible pipelines with released\npre-trained models, thus providing a new evaluation paradigm for ASR error\ncorrection with LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuchen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1\">Sabato Macro Siniscalchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chng_E/0/1/0/all/0/1\">Eng Siong Chng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unlocking Bias Detection: Leveraging Transformer-Based Models for Content Analysis. (arXiv:2310.00347v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00347","description":"<p>Bias detection in text is imperative due to its role in reinforcing negative\nstereotypes, disseminating misinformation, and influencing decisions. Current\nlanguage models often fall short in generalizing beyond their training sets. In\nresponse, we introduce the Contextualized Bi-Directional Dual Transformer\n(CBDT) Classifier. This novel architecture utilizes two synergistic transformer\nnetworks: the Context Transformer and the Entity Transformer, aiming for\nenhanced bias detection. Our dataset preparation follows the FAIR principles,\nensuring ethical data usage. Through rigorous testing on various datasets, CBDT\nshowcases its ability in distinguishing biased from neutral statements, while\nalso pinpointing exact biased lexemes. Our approach outperforms existing\nmethods, achieving a 2-4\\% increase over benchmark performances. This opens\navenues for adapting the CBDT model across diverse linguistic and cultural\nlandscapes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamgbose_O/0/1/0/all/0/1\">Oluwanifemi Bamgbose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatrath_V/0/1/0/all/0/1\">Veronica Chatrath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghuge_S/0/1/0/all/0/1\">Shardul Ghuge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidyakin_Y/0/1/0/all/0/1\">Yan Sidyakin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muaad_A/0/1/0/all/0/1\">Abdullah Y Muaad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"(Dynamic) Prompting might be all you need to repair Compressed LLMs. (arXiv:2310.00867v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00867","description":"<p>Large language models (LLMs), while transformative for NLP, come with\nsignificant computational demands, underlining the need for efficient,\ntraining-free compression. Notably, despite the marked improvement in\ntraining-free compression for the largest of LLMs, our tests using LLaMA-7B and\nOPT-6.7b highlight a significant performance drop in several realistic\ndownstream tasks. Investigation into the trade-off between resource-intensive\npost-compression re-training highlights the prospect of prompt-driven recovery\nas a lightweight adaption tool. However, existing studies, confined mainly to\nperplexity evaluations and simple tasks, fail to offer unequivocal confidence\nin the scalability and generalizability of prompting. We tackle this\nuncertainty in two key ways. First, we uncover the vulnerability of naive\nprompts in LLM compression as an over-reliance on a singular prompt per input.\nIn response, we propose inference-time dynamic prompting (IDP), a mechanism\nthat autonomously chooses from a set of curated prompts based on the context of\neach individual input. Second, we delve into a scientific understanding of why\n\"prompting might be all you need post-LLM compression.\" Our findings suggest\nthat compression does not irretrievably erase LLM model knowledge but displace\nit, necessitating a new inference path. IDP effectively redirects this path,\nenabling the model to tap into its inherent yet displaced knowledge and thereby\nrecover performance. Empirical tests affirm the value of IDP, demonstrating an\naverage performance improvement of 1.24% across nine varied tasks spanning\nmultiple knowledge domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1\">Duc N.M Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1\">Minsik Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merth_T/0/1/0/all/0/1\">Thomas Merth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastegari_M/0/1/0/all/0/1\">Mohammad Rastegari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Driving with LLMs: Fusing Object-Level Vector Modality for Explainable Autonomous Driving. (arXiv:2310.01957v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2310.01957","description":"<p>Large Language Models (LLMs) have shown promise in the autonomous driving\nsector, particularly in generalization and interpretability. We introduce a\nunique object-level multimodal LLM architecture that merges vectorized numeric\nmodalities with a pre-trained LLM to improve context understanding in driving\nsituations. We also present a new dataset of 160k QA pairs derived from 10k\ndriving scenarios, paired with high quality control commands collected with RL\nagent and question answer pairs generated by teacher LLM (GPT-3.5). A distinct\npretraining strategy is devised to align numeric vector modalities with static\nLLM representations using vector captioning language data. We also introduce an\nevaluation metric for Driving QA and demonstrate our LLM-driver's proficiency\nin interpreting driving scenarios, answering questions, and decision-making.\nOur findings highlight the potential of LLM-based driving action generation in\ncomparison to traditional behavioral cloning. We make our benchmark, datasets,\nand model available for further exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Long Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinavski_O/0/1/0/all/0/1\">Oleg Sinavski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hunermann_J/0/1/0/all/0/1\">Jan H&#xfc;nermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnsund_A/0/1/0/all/0/1\">Alice Karnsund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willmott_A/0/1/0/all/0/1\">Andrew James Willmott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_D/0/1/0/all/0/1\">Danny Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maund_D/0/1/0/all/0/1\">Daniel Maund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shotton_J/0/1/0/all/0/1\">Jamie Shotton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond. (arXiv:2310.02071v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.02071","description":"<p>In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zefan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuchi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instances and Labels: Hierarchy-aware Joint Supervised Contrastive Learning for Hierarchical Multi-Label Text Classification. (arXiv:2310.05128v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05128","description":"<p>Hierarchical multi-label text classification (HMTC) aims at utilizing a label\nhierarchy in multi-label classification. Recent approaches to HMTC deal with\nthe problem of imposing an over-constrained premise on the output space by\nusing contrastive learning on generated samples in a semi-supervised manner to\nbring text and label embeddings closer. However, the generation of samples\ntends to introduce noise as it ignores the correlation between similar samples\nin the same batch. One solution to this issue is supervised contrastive\nlearning, but it remains an underexplored topic in HMTC due to its complex\nstructured labels. To overcome this challenge, we propose $\\textbf{HJCL}$, a\n$\\textbf{H}$ierarchy-aware $\\textbf{J}$oint Supervised $\\textbf{C}$ontrastive\n$\\textbf{L}$earning method that bridges the gap between supervised contrastive\nlearning and HMTC. Specifically, we employ both instance-wise and label-wise\ncontrastive learning techniques and carefully construct batches to fulfill the\ncontrastive learning objective. Extensive experiments on four multi-path HMTC\ndatasets demonstrate that HJCL achieves promising results and the effectiveness\nof Contrastive Learning on HMTC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+U_S/0/1/0/all/0/1\">Simon Chi Lok U</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_Basulto_V/0/1/0/all/0/1\">V&#xed;ctor Guti&#xe9;rrez-Basulto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jeff Z. Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Long-form Text Generation in Mental Health with Task-adaptive Tokenization. (arXiv:2310.05317v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05317","description":"<p>We propose task-adaptive tokenization as a way to adapt the generation\npipeline to the specifics of a downstream task and enhance long-form generation\nin mental health. Inspired by insights from cognitive science, our\ntask-adaptive tokenizer samples variable segmentations from multiple outcomes,\nwith sampling probabilities optimized based on task-specific data. We introduce\na strategy for building a specialized vocabulary and introduce a vocabulary\nmerging protocol that allows for the integration of task-specific tokens into\nthe pre-trained model's tokenization step. Through extensive experiments on\npsychological question-answering tasks in both Chinese and English, we find\nthat our task-adaptive tokenization approach brings a significant improvement\nin generation performance while using up to 60% fewer tokens. Preliminary\nexperiments point to promising results when using our tokenization approach\nwith very large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_N/0/1/0/all/0/1\">Naihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabour_S/0/1/0/all/0/1\">Sahand Sabour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yilin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Resolving the Imbalance Issue in Hierarchical Disciplinary Topic Inference via LLM-based Data Augmentation. (arXiv:2310.05318v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05318","description":"<p>In addressing the imbalanced issue of data within the realm of Natural\nLanguage Processing, text data augmentation methods have emerged as pivotal\nsolutions. This data imbalance is prevalent in the research proposals submitted\nduring the funding application process. Such imbalances, resulting from the\nvarying popularity of disciplines or the emergence of interdisciplinary\nstudies, significantly impede the precision of downstream topic models that\ndeduce the affiliated disciplines of these proposals. At the data level,\nproposals penned by experts and scientists are inherently complex technological\ntexts, replete with intricate terminologies, which augmenting such specialized\ntext data poses unique challenges. At the system level, this, in turn,\ncompromises the fairness of AI-assisted reviewer assignment systems, which\nraises a spotlight on solving this issue. This study leverages large language\nmodels (Llama V1) as data generators to augment research proposals categorized\nwithin intricate disciplinary hierarchies, aiming to rectify data imbalances\nand enhance the equity of expert assignments. We first sample within the\nhierarchical structure to find the under-represented class. Then we designed a\nprompt for keyword-based research proposal generation. Our experiments attests\nto the efficacy of the generated data, demonstrating that research proposals\nproduced using the prompts can effectively address the aforementioned issues\nand generate high quality scientific text data, thus help the model overcome\nthe imbalanced issue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xunxin Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_M/0/1/0/all/0/1\">Meng Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1\">Zhiyuan Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuanchun Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis. (arXiv:2310.05374v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05374","description":"<p>Training a high performance end-to-end speech (E2E) processing model requires\nan enormous amount of labeled speech data, especially in the era of\ndata-centric artificial intelligence. However, labeled speech data are usually\nscarcer and more expensive for collection, compared to textual data. We propose\nLatent Synthesis (LaSyn), an efficient textual data utilization framework for\nE2E speech processing models. We train a latent synthesizer to convert textual\ndata into an intermediate latent representation of a pre-trained speech model.\nThese pseudo acoustic representations of textual data augment acoustic data for\nmodel training. We evaluate LaSyn on low-resource automatic speech recognition\n(ASR) and spoken language understanding (SLU) tasks. For ASR, LaSyn improves an\nE2E baseline trained on LibriSpeech train-clean-100, with relative word error\nrate reductions over 22.3% on different test sets. For SLU, LaSyn improves our\nE2E baseline by absolute 4.1% for intent classification accuracy and 3.8% for\nslot filling SLU-F1 on SLURP, and absolute 4.49% and 2.25% for exact match (EM)\nand EM-Tree accuracies on STOP respectively. With fewer parameters, the results\nof LaSyn are competitive to published state-of-the-art works. The results\ndemonstrate the quality of the augmented training data. The source code will be\navailable to the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianqiao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1\">Nianzu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_Y/0/1/0/all/0/1\">Yu Ting Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiffuSeq-v2: Bridging Discrete and Continuous Text Spaces for Accelerated Seq2Seq Diffusion Models. (arXiv:2310.05793v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.05793","description":"<p>Diffusion models have gained prominence in generating high-quality sequences\nof text. Nevertheless, current approaches predominantly represent discrete text\nwithin a continuous diffusion space, which incurs substantial computational\noverhead during training and results in slower sampling speeds. In this paper,\nwe introduce a soft absorbing state that facilitates the diffusion model in\nlearning to reconstruct discrete mutations based on the underlying Gaussian\nspace, thereby enhancing its capacity to recover conditional signals. During\nthe sampling phase, we employ state-of-the-art ODE solvers within the\ncontinuous space to expedite the sampling process. Comprehensive experimental\nevaluations reveal that our proposed method effectively accelerates the\ntraining convergence by 4x and generates samples of similar quality 800x\nfaster, rendering it significantly closer to practical application.\n\\footnote{The code is released at \\url{https://github.com/Shark-NLP/DiffuSeq}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shansan Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mukai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction. (arXiv:2310.07284v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2310.07284","description":"<p>Humans possess an extraordinary ability to selectively focus on the sound\nsource of interest amidst complex acoustic environments, commonly referred to\nas cocktail party scenarios. In an attempt to replicate this remarkable\nauditory attention capability in machines, target speaker extraction (TSE)\nmodels have been developed. These models leverage the pre-registered cues of\nthe target speaker to extract the sound source of interest. However, the\neffectiveness of these models is hindered in real-world scenarios due to the\nunreliable or even absence of pre-registered cues. To address this limitation,\nthis study investigates the integration of natural language description to\nenhance the feasibility, controllability, and performance of existing TSE\nmodels. Specifically, we propose a model named LLM-TSE, wherein a large\nlanguage model (LLM) extracts useful semantic cues from the user's typed text\ninput. These cues can serve as independent extraction cues, task selectors to\ncontrol the TSE process or complement the pre-registered cues. Our experimental\nresults demonstrate competitive performance when only text-based cues are\npresented, the effectiveness of using input text as a task selector, and a new\nstate-of-the-art when combining text-based cues with pre-registered cues. To\nour knowledge, this is the first study to successfully incorporate LLMs to\nguide target speaker extraction, which can be a cornerstone for cocktail party\nproblem research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Hao_X/0/1/0/all/0/1\">Xiang Hao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Jibin Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_J/0/1/0/all/0/1\">Jianwei Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1\">Chenglin Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_K/0/1/0/all/0/1\">Kay Chen Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM4Vis: Explainable Visualization Recommendation using ChatGPT. (arXiv:2310.07652v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2310.07652","description":"<p>Data visualization is a powerful tool for exploring and communicating\ninsights in various domains. To automate visualization choice for datasets, a\ntask known as visualization recommendation has been proposed. Various\nmachine-learning-based approaches have been developed for this purpose, but\nthey often require a large corpus of dataset-visualization pairs for training\nand lack natural explanations for their results. To address this research gap,\nwe propose LLM4Vis, a novel ChatGPT-based prompting approach to perform\nvisualization recommendation and return human-like explanations using very few\ndemonstration examples. Our approach involves feature description,\ndemonstration example selection, explanation generation, demonstration example\nconstruction, and inference steps. To obtain demonstration examples with\nhigh-quality explanations, we propose a new explanation generation\nbootstrapping to iteratively refine generated explanations by considering the\nprevious generation and template-based hint. Evaluations on the VizML dataset\nshow that LLM4Vis outperforms or performs similarly to supervised learning\nmodels like Random Forest, Decision Tree, and MLP in both few-shot and\nzero-shot settings. The qualitative evaluation also shows the effectiveness of\nexplanations generated by LLM4Vis. We make our code publicly available at\n\\href{https://github.com/demoleiwang/LLM4Vis}{https://github.com/demoleiwang/LLM4Vis}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Ee-Peng Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models. (arXiv:2310.07818v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07818","description":"<p>Identifying analogies plays a pivotal role in human cognition and language\nproficiency. In the last decade, there has been extensive research on word\nanalogies in the form of ``A is to B as C is to D.'' However, there is a\ngrowing interest in analogies that involve longer text, such as sentences and\ncollections of sentences, which convey analogous meanings. While the current\nNLP research community evaluates the ability of Large Language Models (LLMs) to\nidentify such analogies, the underlying reasons behind these abilities warrant\ndeeper investigation. Furthermore, the capability of LLMs to encode both\nsyntactic and semantic structures of language within their embeddings has\ngarnered significant attention with the surge in their utilization. In this\nwork, we examine the relationship between the abilities of multiple LLMs to\nidentify sentence analogies, and their capacity to encode syntactic and\nsemantic structures. Through our analysis, we find that analogy identification\nability of LLMs is positively correlated with their ability to encode syntactic\nand semantic structures of sentences. Specifically, we find that the LLMs which\ncapture syntactic structures better, also have higher abilities in identifying\nsentence analogies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wijesiriwardene_T/0/1/0/all/0/1\">Thilini Wijesiriwardene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wickramarachchi_R/0/1/0/all/0/1\">Ruwan Wickramarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reganti_A/0/1/0/all/0/1\">Aishwarya Naresh Reganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.07923","description":"<p>Recent theoretical work has identified surprisingly simple reasoning\nproblems, such as checking if two nodes in a graph are connected or simulating\nfinite-state machines, that are provably unsolvable by standard transformers\nthat answer immediately after reading their input. However, in practice,\ntransformers' reasoning can be improved by allowing them to use a \"chain of\nthought\" or \"scratchpad\", i.e., generate and condition on a sequence of\nintermediate tokens before answering. Motivated by this, we ask: Does such\nintermediate generation fundamentally extend the computational power of a\ndecoder-only transformer? We show that the answer is yes, but the amount of\nincrease depends crucially on the amount of intermediate generation. For\ninstance, we find that transformer decoders with a logarithmic number of\ndecoding steps (w.r.t. the input length) push the limits of standard\ntransformers only slightly, while a linear number of decoding steps adds a\nclear new ability (under standard complexity conjectures): recognizing all\nregular languages. Our results also imply that linear steps keep transformer\ndecoders within context-sensitive languages, and polynomial steps make them\nrecognize exactly the class of polynomial-time solvable problems -- the first\nexact characterization of a type of transformers in terms of standard\ncomplexity classes. Together, our results provide a nuanced framework for\nunderstanding how the length of a transformer's chain of thought or scratchpad\nimpacts its reasoning power.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques. (arXiv:2310.08101v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08101","description":"<p>Text entry is an essential task in our day-to-day digital interactions.\nNumerous intelligent features have been developed to streamline this process,\nmaking text entry more effective, efficient, and fluid. These improvements\ninclude sentence prediction and user personalization. However, as deep\nlearning-based language models become the norm for these advanced features, the\nnecessity for data collection and model fine-tuning increases. These challenges\ncan be mitigated by harnessing the in-context learning capability of large\nlanguage models such as GPT-3.5. This unique feature allows the language model\nto acquire new skills through prompts, eliminating the need for data collection\nand fine-tuning. Consequently, large language models can learn various text\nprediction techniques. We initially showed that, for a sentence prediction\ntask, merely prompting GPT-3.5 surpassed a GPT-2 backed system and is\ncomparable with a fine-tuned GPT-3.5 model, with the latter two methods\nrequiring costly data collection, fine-tuning and post-processing. However, the\ntask of prompting large language models to specialize in specific text\nprediction tasks can be challenging, particularly for designers without\nexpertise in prompt engineering. To address this, we introduce Promptor, a\nconversational prompt generation agent designed to engage proactively with\ndesigners. Promptor can automatically generate complex prompts tailored to meet\nspecific needs, thus offering a solution to this challenge. We conducted a user\nstudy involving 24 participants creating prompts for three intelligent text\nentry tasks, half of the participants used Promptor while the other half\ndesigned prompts themselves. The results show that Promptor-designed prompts\nresult in a 35% increase in similarity and 22% in coherence over those by\ndesigners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junxiao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudley_J/0/1/0/all/0/1\">John J. Dudley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jingyao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byrne_B/0/1/0/all/0/1\">Bill Byrne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kristensson_P/0/1/0/all/0/1\">Per Ola Kristensson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context Compression for Auto-regressive Transformers with Sentinel Tokens. (arXiv:2310.08152v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08152","description":"<p>The quadratic complexity of the attention module makes it gradually become\nthe bulk of compute in Transformer-based LLMs during generation. Moreover, the\nexcessive key-value cache that arises when dealing with long inputs also brings\nsevere issues on memory footprint and inference latency. In this work, we\npropose a plug-and-play approach that is able to incrementally compress the\nintermediate activation of a specified span of tokens into compact ones,\nthereby reducing both memory and computational cost when processing subsequent\ncontext. Experiments on both in-domain language modeling and zero-shot\nopen-ended document generation demonstrate the advantage of our approach over\nsparse attention baselines in terms of fluency, n-gram matching, and semantic\nsimilarity. At last, we comprehensively profile the benefit of context\ncompression on improving the system throughout. Code is available at\nhttps://github.com/DRSY/KV_Compression.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Siyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Q/0/1/0/all/0/1\">Qi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Factual Consistency for Knowledge-Grounded Dialogue Systems via Knowledge Enhancement and Alignment. (arXiv:2310.08372v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08372","description":"<p>Pretrained language models (PLMs) based knowledge-grounded dialogue systems\nare prone to generate responses that are factually inconsistent with the\nprovided knowledge source. In such inconsistent responses, the dialogue models\nfail to accurately express the external knowledge they rely upon. Inspired by\nprevious work which identified that feed-forward networks (FFNs) within\nTransformers are responsible for factual knowledge expressions, we investigate\ntwo methods to efficiently improve the factual expression capability {of FFNs}\nby knowledge enhancement and alignment respectively. We first propose\n\\textsc{K-Dial}, which {explicitly} introduces {extended FFNs in Transformers\nto enhance factual knowledge expressions} given the specific patterns of\nknowledge-grounded dialogue inputs. Additionally, we apply the reinforcement\nlearning for factual consistency (RLFC) method to implicitly adjust FFNs'\nexpressions in responses by aligning with gold knowledge for the factual\nconsistency preference. To comprehensively assess the factual consistency and\ndialogue quality of responses, we employ extensive automatic measures and human\nevaluations including sophisticated fine-grained NLI-based metrics.\nExperimental results on WoW and CMU\\_DoG datasets demonstrate that our methods\nefficiently enhance the ability of the FFN module to convey factual knowledge,\nvalidating the efficacy of improving factual consistency for knowledge-grounded\ndialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Boyang Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weichao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1\">Lifeng Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Data-Type Understanding does not emerge from Scaling Vision-Language Models. (arXiv:2310.08577v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.08577","description":"<p>Recent advances in the development of vision-language models (VLMs) are\nyielding remarkable success in recognizing visual semantic content, including\nimpressive instances of compositional image understanding. Here, we introduce\nthe novel task of Visual Data-Type Identification, a basic perceptual skill\nwith implications for data curation (e.g., noisy data-removal from large\ndatasets, domain-specific retrieval) and autonomous vision (e.g.,\ndistinguishing changing weather conditions from camera lens staining). We\ndevelop two datasets consisting of animal images altered across a diverse set\nof 27 visual data-types, spanning four broad categories. An extensive zero-shot\nevaluation of 39 VLMs, ranging from 100M to 80B parameters, shows a nuanced\nperformance landscape. While VLMs are reasonably good at identifying certain\nstylistic \\textit{data-types}, such as cartoons and sketches, they struggle\nwith simpler data-types arising from basic manipulations like image rotations\nor additive noise. Our findings reveal that (i) model scaling alone yields\nmarginal gains for contrastively-trained models like CLIP, and (ii) there is a\npronounced drop in performance for the largest auto-regressively trained VLMs\nlike OpenFlamingo. This finding points to a blind spot in current frontier\nVLMs: they excel in recognizing semantic content but fail to acquire an\nunderstanding of visual data-types through scaling. By analyzing the\npre-training distributions of these models and incorporating data-type\ninformation into the captions during fine-tuning, we achieve a significant\nenhancement in performance. By exploring this previously uncharted task, we aim\nto set the stage for further advancing VLMs to equip them with visual data-type\nunderstanding. Code and datasets are released at\nhttps://github.com/bethgelab/DataTypeIdentification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Udandarao_V/0/1/0/all/0/1\">Vishaal Udandarao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burg_M/0/1/0/all/0/1\">Max F. Burg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1\">Samuel Albanie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1\">Matthias Bethge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Out-of-Distribution Detection by Leveraging Between-Layer Transformation Smoothness. (arXiv:2310.02832v1 [cs.LG] CROSS LISTED)","link":"http://arxiv.org/abs/2310.02832","description":"<p>Effective OOD detection is crucial for reliable machine learning models, yet\nmost current methods are limited in practical use due to requirements like\naccess to training data or intervention in training. We present a novel method\nfor detecting OOD data in deep neural networks based on transformation\nsmoothness between intermediate layers of a network (BLOOD), which is\napplicable to pre-trained models without access to training data. BLOOD\nutilizes the tendency of between-layer representation transformations of\nin-distribution (ID) data to be smoother than the corresponding transformations\nof OOD data, a property that we also demonstrate empirically for Transformer\nnetworks. We evaluate BLOOD on several text classification tasks with\nTransformer networks and demonstrate that it outperforms methods with\ncomparable resource requirements. Our analysis also suggests that when learning\nsimpler tasks, OOD data transformations maintain their original sharpness,\nwhereas sharpness increases with more complex tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jelenic_F/0/1/0/all/0/1\">Fran Jeleni&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jukic_J/0/1/0/all/0/1\">Josip Juki&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutek_M/0/1/0/all/0/1\">Martin Tutek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puljiz_M/0/1/0/all/0/1\">Mate Puljiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-16T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}