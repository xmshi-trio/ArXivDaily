{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-08-30T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"VoiceBank-2023: A Multi-Speaker Mandarin Speech Corpus for Constructing Personalized TTS Systems for the Speech Impaired. (arXiv:2308.14763v1 [eess.AS])","link":"http://arxiv.org/abs/2308.14763","description":"<p>Services of personalized TTS systems for the Mandarin-speaking speech\nimpaired are rarely mentioned. Taiwan started the VoiceBanking project in 2020,\naiming to build a complete set of services to deliver personalized Mandarin TTS\nsystems to amyotrophic lateral sclerosis patients. This paper reports the\ncorpus design, corpus recording, data purging and correction for the corpus,\nand evaluations of the developed personalized TTS systems, for the VoiceBanking\nproject. The developed corpus is named after the VoiceBank-2023 speech corpus\nbecause of its release year. The corpus contains 29.78 hours of utterances with\nprompts of short paragraphs and common phrases spoken by 111 native Mandarin\nspeakers. The corpus is labeled with information about gender, degree of speech\nimpairment, types of users, transcription, SNRs, and speaking rates. The\nVoiceBank-2023 is available by request for non-commercial use and welcomes all\nparties to join the VoiceBanking project to improve the services for the speech\nimpaired.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Su_J/0/1/0/all/0/1\">Jia-Jyu Su</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liao_P/0/1/0/all/0/1\">Pang-Chen Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_Y/0/1/0/all/0/1\">Yen-Ting Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1\">Wu-Hao Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liou_G/0/1/0/all/0/1\">Guan-Ting Liou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kao_C/0/1/0/all/0/1\">Cheng-Che Kao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Cheng Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chiang_J/0/1/0/all/0/1\">Jen-Chieh Chiang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_W/0/1/0/all/0/1\">Wen-Yang Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_P/0/1/0/all/0/1\">Pin-Han Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chiang_C/0/1/0/all/0/1\">Chen-Yu Chiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attention Visualizer Package: Revealing Word Importance for Deeper Insight into Encoder-Only Transformer Models. (arXiv:2308.14850v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14850","description":"<p>This report introduces the Attention Visualizer package, which is crafted to\nvisually illustrate the significance of individual words in encoder-only\ntransformer-based models. In contrast to other methods that center on tokens\nand self-attention scores, our approach will examine the words and their impact\non the final embedding representation. Libraries like this play a crucial role\nin enhancing the interpretability and explainability of neural networks. They\noffer the opportunity to illuminate their internal mechanisms, providing a\nbetter understanding of how they operate and can be enhanced. You can access\nthe code and review examples on the following GitHub repository:\nhttps://github.com/AlaFalaki/AttentionVisualizer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Falaki_A/0/1/0/all/0/1\">Ala Alam Falaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gras_R/0/1/0/all/0/1\">Robin Gras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CommunityFish: A Poisson-based Document Scaling With Hierarchical Clustering. (arXiv:2308.14873v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14873","description":"<p>Document scaling has been a key component in text-as-data applications for\nsocial scientists and a major field of interest for political researchers, who\naim at uncovering differences between speakers or parties with the help of\ndifferent probabilistic and non-probabilistic approaches. Yet, most of these\ntechniques are either built upon the agnostically bag-of-word hypothesis or use\nprior information borrowed from external sources that might embed the results\nwith a significant bias. If the corpus has long been considered as a collection\nof documents, it can also be seen as a dense network of connected words whose\nstructure could be clustered to differentiate independent groups of words,\nbased on their co-occurrences in documents, known as communities. This paper\nintroduces CommunityFish as an augmented version of Wordfish based on a\nhierarchical clustering, namely the Louvain algorithm, on the word space to\nyield communities as semantic and independent n-grams emerging from the corpus\nand use them as an input to Wordfish method, instead of considering the word\nspace. This strategy emphasizes the interpretability of the results, since\ncommunities have a non-overlapping structure, hence a crucial informative power\nin discriminating parties or speakers, in addition to allowing a faster\nexecution of the Poisson scaling model. Aside from yielding communities,\nassumed to be subtopic proxies, the application of this technique outperforms\nthe classic Wordfish model by highlighting historical developments in the U.S.\nState of the Union addresses and was found to replicate the prevailing\npolitical stance in Germany when using the corpus of parties' legislative\nmanifestos.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Diaf_S/0/1/0/all/0/1\">Sami Diaf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiscale Contextual Learning for Speech Emotion Recognition in Emergency Call Center Conversations. (arXiv:2308.14894v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14894","description":"<p>Emotion recognition in conversations is essential for ensuring advanced\nhuman-machine interactions. However, creating robust and accurate emotion\nrecognition systems in real life is challenging, mainly due to the scarcity of\nemotion datasets collected in the wild and the inability to take into account\nthe dialogue context. The CEMO dataset, composed of conversations between\nagents and patients during emergency calls to a French call center, fills this\ngap. The nature of these interactions highlights the role of the emotional flow\nof the conversation in predicting patient emotions, as context can often make a\ndifference in understanding actual feelings. This paper presents a multi-scale\nconversational context learning approach for speech emotion recognition, which\ntakes advantage of this hypothesis. We investigated this approach on both\nspeech transcriptions and acoustic segments. Experimentally, our method uses\nthe previous or next information of the targeted segment. In the text domain,\nwe tested the context window using a wide range of tokens (from 10 to 100) and\nat the speech turns level, considering inputs from both the same and opposing\nspeakers. According to our tests, the context derived from previous tokens has\na more significant influence on accurate prediction than the following tokens.\nFurthermore, taking the last speech turn of the same speaker in the\nconversation seems useful. In the acoustic domain, we conducted an in-depth\nanalysis of the impact of the surrounding emotions on the prediction. While\nmulti-scale conversational context learning using Transformers can enhance\nperformance in the textual modality for emergency call recordings,\nincorporating acoustic context is more challenging.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deschamps_Berger_T/0/1/0/all/0/1\">Th&#xe9;o Deschamps-Berger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamel_L/0/1/0/all/0/1\">Lori Lamel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devillers_L/0/1/0/all/0/1\">Laurence Devillers</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEMORY-VQ: Compression for Tractable Internet-Scale Memory. (arXiv:2308.14903v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14903","description":"<p>Retrieval augmentation is a powerful but expensive method to make language\nmodels more knowledgeable about the world. Memory-based methods like LUMEN\npre-compute token representations for retrieved passages to drastically speed\nup inference. However, memory also leads to much greater storage requirements\nfrom storing pre-computed representations.\n</p>\n<p>We propose MEMORY-VQ, a new method to reduce storage requirements of\nmemory-augmented models without sacrificing performance. Our method uses a\nvector quantization variational autoencoder (VQ-VAE) to compress token\nrepresentations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a\nmemory model that achieves a 16x compression rate with comparable performance\non the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even\nfor extremely large retrieval corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zemlyanskiy_Y/0/1/0/all/0/1\">Yury Zemlyanskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vilnis_L/0/1/0/all/0/1\">Luke Vilnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1\">Santiago Onta&#xf1;&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghai_S/0/1/0/all/0/1\">Sumit Sanghai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural approaches to spoken content embedding. (arXiv:2308.14905v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14905","description":"<p>Comparing spoken segments is a central operation to speech processing.\nTraditional approaches in this area have favored frame-level dynamic\nprogramming algorithms, such as dynamic time warping, because they require no\nsupervision, but they are limited in performance and efficiency. As an\nalternative, acoustic word embeddings -- fixed-dimensional vector\nrepresentations of variable-length spoken word segments -- have begun to be\nconsidered for such tasks as well. However, the current space of such\ndiscriminative embedding models, training approaches, and their application to\nreal-world downstream tasks is limited. We start by considering ``single-view\"\ntraining losses where the goal is to learn an acoustic word embedding model\nthat separates same-word and different-word spoken segment pairs. Then, we\nconsider ``multi-view\" contrastive losses. In this setting, acoustic word\nembeddings are learned jointly with embeddings of character sequences to\ngenerate acoustically grounded embeddings of written words, or acoustically\ngrounded word embeddings.\n</p>\n<p>In this thesis, we contribute new discriminative acoustic word embedding\n(AWE) and acoustically grounded word embedding (AGWE) approaches based on\nrecurrent neural networks (RNNs). We improve model training in terms of both\nefficiency and performance. We take these developments beyond English to\nseveral low-resource languages and show that multilingual training improves\nperformance when labeled data is limited. We apply our embedding models, both\nmonolingual and multilingual, to the downstream tasks of query-by-example\nspeech search and automatic speech recognition. Finally, we show how our\nembedding approaches compare with and complement more recent self-supervised\nspeech models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Settle_S/0/1/0/all/0/1\">Shane Settle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gender bias and stereotypes in Large Language Models. (arXiv:2308.14921v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14921","description":"<p>Large Language Models (LLMs) have made substantial progress in the past\nseveral months, shattering state-of-the-art benchmarks in many domains. This\npaper investigates LLMs' behavior with respect to gender stereotypes, a known\nissue for prior models. We use a simple paradigm to test the presence of gender\nbias, building on but differing from WinoBias, a commonly used gender bias\ndataset, which is likely to be included in the training data of current LLMs.\nWe test four recently published LLMs and demonstrate that they express biased\nassumptions about men and women's occupations. Our contributions in this paper\nare as follows: (a) LLMs are 3-6 times more likely to choose an occupation that\nstereotypically aligns with a person's gender; (b) these choices align with\npeople's perceptions better than with the ground truth as reflected in official\njob statistics; (c) LLMs in fact amplify the bias beyond what is reflected in\nperceptions or the ground truth; (d) LLMs ignore crucial ambiguities in\nsentence structure 95% of the time in our study items, but when explicitly\nprompted, they recognize the ambiguity; (e) LLMs provide explanations for their\nchoices that are factually inaccurate and likely obscure the true reason behind\ntheir predictions. That is, they provide rationalizations of their biased\nbehavior. This highlights a key property of these models: LLMs are trained on\nimbalanced datasets; as such, even with the recent successes of reinforcement\nlearning with human feedback, they tend to reflect those imbalances back at us.\nAs with other types of societal biases, we suggest that LLMs must be carefully\ntested to ensure that they treat minoritized individuals and communities\nequitably.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kotek_H/0/1/0/all/0/1\">Hadas Kotek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dockum_R/0/1/0/all/0/1\">Rikker Dockum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1\">David Q. Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Open-Set Spoken Language Identification and the CU MultiLang Dataset. (arXiv:2308.14951v1 [cs.CL])","link":"http://arxiv.org/abs/2308.14951","description":"<p>Most state-of-the-art spoken language identification models are closed-set;\nin other words, they can only output a language label from the set of classes\nthey were trained on. Open-set spoken language identification systems, however,\ngain the ability to detect when an input exhibits none of the original\nlanguages. In this paper, we implement a novel approach to open-set spoken\nlanguage identification that uses MFCC and pitch features, a TDNN model to\nextract meaningful feature embeddings, confidence thresholding on softmax\noutputs, and LDA and pLDA for learning to classify new unknown languages. We\npresent a spoken language identification system that achieves 91.76% accuracy\non trained languages and has the capability to adapt to unknown languages on\nthe fly. To that end, we also built the CU MultiLang Dataset, a large and\ndiverse multilingual speech corpus which was used to train and evaluate our\nsystem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eyceoz_M/0/1/0/all/0/1\">Mustafa Eyceoz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Justin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pittie_S/0/1/0/all/0/1\">Siddharth Pittie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beigi_H/0/1/0/all/0/1\">Homayoon Beigi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TransPrompt v2: A Transferable Prompting Framework for Cross-task Text Classification. (arXiv:2308.15010v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15010","description":"<p>Text classification is one of the most imperative tasks in natural language\nprocessing (NLP). Recent advances with pre-trained language models (PLMs) have\nshown remarkable success on this task. However, the satisfying results obtained\nby PLMs heavily depend on the large amounts of task-specific labeled data,\nwhich may not be feasible in many application scenarios due to data access and\nprivacy constraints. The recently-proposed prompt-based fine-tuning paradigm\nimproves the performance of PLMs for few-shot text classification with\ntask-specific templates. Yet, it is unclear how the prompting knowledge can be\ntransferred across tasks, for the purpose of mutual reinforcement. We propose\nTransPrompt v2, a novel transferable prompting framework for few-shot learning\nacross similar or distant text classification tasks. For learning across\nsimilar tasks, we employ a multi-task meta-knowledge acquisition (MMA)\nprocedure to train a meta-learner that captures the cross-task transferable\nknowledge. For learning across distant tasks, we further inject the task type\ndescriptions into the prompt, and capture the intra-type and inter-type prompt\nembeddings among multiple distant tasks. Additionally, two de-biasing\ntechniques are further designed to make the trained meta-learner more\ntask-agnostic and unbiased towards any tasks. After that, the meta-learner can\nbe adapted to each specific task with better parameters initialization.\nExtensive experiments show that TransPrompt v2 outperforms single-task and\ncross-task strong baselines over multiple NLP tasks and datasets. We further\nshow that the meta-learner can effectively improve the performance of PLMs on\npreviously unseen tasks. In addition, TransPrompt v2 also outperforms strong\nfine-tuning baselines when learning with full training sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Ming Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Aoying Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recursively Summarizing Enables Long-Term Dialogue Memory in Large Language Models. (arXiv:2308.15022v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15022","description":"<p>Most open-domain dialogue systems suffer from forgetting important\ninformation, especially in a long-term conversation. Existing works usually\ntrain the specific retriever or summarizer to obtain key information from the\npast, which is time-consuming and highly depends on the quality of labeled\ndata. To alleviate this problem, we propose to recursively generate summaries/\nmemory using large language models (LLMs) to enhance long-term memory ability.\nSpecifically, our method first stimulates LLMs to memorize small dialogue\ncontexts and then recursively produce new memory using previous memory and\nfollowing contexts. Finally, the LLM can easily generate a highly consistent\nresponse with the help of the latest memory. We evaluate our method using\nChatGPT and text-davinci-003, and the experiments on the widely-used public\ndataset show that our method can generate more consistent responses in a\nlong-context conversation. Notably, our method is a potential solution to\nenable the LLM to model the extremely long context. Code and scripts will be\nreleased later.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Li Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Neural Ranking Models with Traditional IR Methods. (arXiv:2308.15027v1 [cs.IR])","link":"http://arxiv.org/abs/2308.15027","description":"<p>Neural ranking methods based on large transformer models have recently gained\nsignificant attention in the information retrieval community, and have been\nadopted by major commercial solutions. Nevertheless, they are computationally\nexpensive to create, and require a great deal of labeled data for specialized\ncorpora. In this paper, we explore a low resource alternative which is a\nbag-of-embedding model for document retrieval and find that it is competitive\nwith large transformer models fine tuned on information retrieval tasks. Our\nresults show that a simple combination of TF-IDF, a traditional keyword\nmatching method, with a shallow embedding model provides a low cost path to\ncompete well with the performance of complex neural ranking models on 3\ndatasets. Furthermore, adding TF-IDF measures improves the performance of\nlarge-scale fine tuned models on these tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Anik Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassanzadeh_O/0/1/0/all/0/1\">Oktie Hassanzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gittens_A/0/1/0/all/0/1\">Alex Gittens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jian Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_K/0/1/0/all/0/1\">Kavitha Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yener_B/0/1/0/all/0/1\">Bulent Yener</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large language models converge toward human-like concept organization. (arXiv:2308.15047v1 [cs.LG])","link":"http://arxiv.org/abs/2308.15047","description":"<p>Large language models show human-like performance in knowledge extraction,\nreasoning and dialogue, but it remains controversial whether this performance\nis best explained by memorization and pattern matching, or whether it reflects\nhuman-like inferential semantics and world knowledge. Knowledge bases such as\nWikiData provide large-scale, high-quality representations of inferential\nsemantics and world knowledge. We show that large language models learn to\norganize concepts in ways that are strikingly similar to how concepts are\norganized in such knowledge bases. Knowledge bases model collective,\ninstitutional knowledge, and large language models seem to induce such\nknowledge from raw text. We show that bigger and better models exhibit more\nhuman-like concept organization, across four families of language models and\nthree knowledge graph embeddings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gammelgaard_M/0/1/0/all/0/1\">Mathias Lykke Gammelgaard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christiansen_J/0/1/0/all/0/1\">Jonathan Gabel Christiansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting text-based dialogue state tracker for spoken dialogues. (arXiv:2308.15053v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15053","description":"<p>Although there have been remarkable advances in dialogue systems through the\ndialogue systems technology competition (DSTC), it remains one of the key\nchallenges to building a robust task-oriented dialogue system with a speech\ninterface. Most of the progress has been made for text-based dialogue systems\nsince there are abundant datasets with written corpora while those with spoken\ndialogues are very scarce. However, as can be seen from voice assistant systems\nsuch as Siri and Alexa, it is of practical importance to transfer the success\nto spoken dialogues. In this paper, we describe our engineering effort in\nbuilding a highly successful model that participated in the speech-aware\ndialogue systems technology challenge track in DSTC11. Our model consists of\nthree major modules: (1) automatic speech recognition error correction to\nbridge the gap between the spoken and the text utterances, (2) text-based\ndialogue system (D3ST) for estimating the slots and values using slot\ndescriptions, and (3) post-processing for recovering the error of the estimated\nslot value. Our experiments show that it is important to use an explicit\nautomatic speech recognition error correction module, post-processing, and data\naugmentation to adapt a text-based dialogue state tracker for spoken dialogue\ncorpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaeseok Yoon</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Seunghyun Hwang</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1\">Ran Han</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Bang_J/0/1/0/all/0/1\">Jeonguk Bang</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kee-Eung Kim</a> (1 and 3) ((1) Kim Jaechul Graduate School of AI, KAIST, Seoul, Republic of Korea, (2) Electronics Telecommunications Research Institute (ETRI), Daejeon, Republic of Korea, (3) School of Computing, KAIST, Daejeon, Republic of Korea)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Taxonomic Loss for Morphological Glossing of Low-Resource Languages. (arXiv:2308.15055v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15055","description":"<p>Morpheme glossing is a critical task in automated language documentation and\ncan benefit other downstream applications greatly. While state-of-the-art\nglossing systems perform very well for languages with large amounts of existing\ndata, it is more difficult to create useful models for low-resource languages.\nIn this paper, we propose the use of a taxonomic loss function that exploits\nmorphological information to make morphological glossing more performant when\ndata is scarce. We find that while the use of this loss function does not\noutperform a standard loss function with regards to single-label prediction\naccuracy, it produces better predictions when considering the top-n predicted\nlabels. We suggest this property makes the taxonomic loss function useful in a\nhuman-in-the-loop annotation setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ginn_M/0/1/0/all/0/1\">Michael Ginn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_A/0/1/0/all/0/1\">Alexis Palmer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Killing two birds with one stone: Can an audio captioning system also be used for audio-text retrieval?. (arXiv:2308.15090v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15090","description":"<p>Automated Audio Captioning (AAC) aims to develop systems capable of\ndescribing an audio recording using a textual sentence. In contrast, Audio-Text\nRetrieval (ATR) systems seek to find the best matching audio recording(s) for a\ngiven textual query (Text-to-Audio) or vice versa (Audio-to-Text). These tasks\nrequire different types of systems: AAC employs a sequence-to-sequence model,\nwhile ATR utilizes a ranking model that compares audio and text representations\nwithin a shared projection subspace. However, this work investigates the\nrelationship between AAC and ATR by exploring the ATR capabilities of an\nunmodified AAC system, without fine-tuning for the new task. Our AAC system\nconsists of an audio encoder (ConvNeXt-Tiny) trained on AudioSet for audio\ntagging, and a transformer decoder responsible for generating sentences. For\nAAC, it achieves a high SPIDEr-FL score of 0.298 on Clotho and 0.472 on\nAudioCaps on average. For ATR, we propose using the standard Cross-Entropy loss\nvalues obtained for any audio/caption pair. Experimental results on the Clotho\nand AudioCaps datasets demonstrate decent recall values using this simple\napproach. For instance, we obtained a Text-to-Audio R@1 value of 0.382 for\nAu-dioCaps, which is above the current state-of-the-art method without external\ndata. Interestingly, we observe that normalizing the loss values was necessary\nfor Audio-to-Text retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Labbe_E/0/1/0/all/0/1\">Etienne Labb&#xe9;</a> (IRIT-SAMoVA), <a href=\"http://arxiv.org/find/cs/1/au:+Pellegrini_T/0/1/0/all/0/1\">Thomas Pellegrini</a> (IRIT-SAMoVA), <a href=\"http://arxiv.org/find/cs/1/au:+Pinquier_J/0/1/0/all/0/1\">Julien Pinquier</a> (IRIT-SAMoVA)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sequential annotations for naturally-occurring HRI: first insights. (arXiv:2308.15097v1 [cs.AI])","link":"http://arxiv.org/abs/2308.15097","description":"<p>We explain the methodology we developed for improving the interactions\naccomplished by an embedded conversational agent, drawing from Conversation\nAnalytic sequential and multimodal analysis. The use case is a Pepper robot\nthat is expected to inform and orient users in a library. In order to propose\nand learn better interactive schema, we are creating a corpus of\nnaturally-occurring interactions that will be made available to the community.\nTo do so, we propose an annotation practice based on some theoretical\nunderpinnings about the use of language and multimodal resources in human-robot\ninteraction. CCS CONCEPTS $\\bullet$ Computing methodologies $\\rightarrow$\nDiscourse, dialogue and pragmatics; $\\bullet$ Human-centered computing\n$\\rightarrow$ Text input; HCI theory, concepts and models; Field studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tisserand_L/0/1/0/all/0/1\">Lucien Tisserand</a> (ICAR), <a href=\"http://arxiv.org/find/cs/1/au:+Armetta_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric Armetta</a> (SyCoSMA, LIRIS), <a href=\"http://arxiv.org/find/cs/1/au:+Baldauf_Quilliatre_H/0/1/0/all/0/1\">Heike Baldauf-Quilliatre</a> (ICAR), <a href=\"http://arxiv.org/find/cs/1/au:+Bouquin_A/0/1/0/all/0/1\">Antoine Bouquin</a> (SyCoSMA, LIRIS), <a href=\"http://arxiv.org/find/cs/1/au:+Hassas_S/0/1/0/all/0/1\">Salima Hassas</a> (SyCoSMA, LIRIS), <a href=\"http://arxiv.org/find/cs/1/au:+Lefort_M/0/1/0/all/0/1\">Mathieu Lefort</a> (LIRIS, SyCoSMA)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models on the Chessboard: A Study on ChatGPT's Formal Language Comprehension and Complex Reasoning Skills. (arXiv:2308.15118v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15118","description":"<p>While large language models have made strides in natural language processing,\ntheir proficiency in complex reasoning tasks requiring formal language\ncomprehension, such as chess, remains less investigated. This paper probes the\nperformance of ChatGPT, a sophisticated language model by OpenAI in tackling\nsuch complex reasoning tasks, using chess as a case study. Through robust\nmetrics examining both the legality and quality of moves, we assess ChatGPT's\nunderstanding of the chessboard, adherence to chess rules, and strategic\ndecision-making abilities. Our evaluation identifies limitations within\nChatGPT's attention mechanism that affect its formal language comprehension and\nuncovers the model's underdeveloped self-regulation abilities. Our study also\nreveals ChatGPT's propensity for a coherent strategy in its gameplay and a\nnoticeable uptick in decision-making assertiveness when the model is presented\nwith a greater volume of natural language or possesses a more lucid\nunderstanding of the state of the chessboard. These findings contribute to the\ngrowing exploration of language models' abilities beyond natural language\nprocessing, providing valuable information for future research towards models\ndemonstrating human-like cognitive abilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kuo_M/0/1/0/all/0/1\">Mu-Tien Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsueh_C/0/1/0/all/0/1\">Chih-Chung Hsueh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_R/0/1/0/all/0/1\">Richard Tzong-Han Tsai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpikeBERT: A Language Spikformer Trained with Two-Stage Knowledge Distillation from BERT. (arXiv:2308.15122v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15122","description":"<p>Spiking neural networks (SNNs) offer a promising avenue to implement deep\nneural networks in a more energy-efficient way. However, the network\narchitectures of existing SNNs for language tasks are too simplistic, and deep\narchitectures have not been fully explored, resulting in a significant\nperformance gap compared to mainstream transformer-based networks such as BERT.\nTo this end, we improve a recently-proposed spiking transformer (i.e.,\nSpikformer) to make it possible to process language tasks and propose a\ntwo-stage knowledge distillation method for training it, which combines\npre-training by distilling knowledge from BERT with a large collection of\nunlabelled texts and fine-tuning with task-specific instances via knowledge\ndistillation again from the BERT fine-tuned on the same training examples.\nThrough extensive experimentation, we show that the models trained with our\nmethod, named SpikeBERT, outperform state-of-the-art SNNs and even achieve\ncomparable results to BERTs on text classification tasks for both English and\nChinese with much less energy consumption.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Changze Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_C/0/1/0/all/0/1\">Chenxi Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zixuan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cenyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation and Analysis of Hallucination in Large Vision-Language Models. (arXiv:2308.15126v1 [cs.LG])","link":"http://arxiv.org/abs/2308.15126","description":"<p>Large Vision-Language Models (LVLMs) have recently achieved remarkable\nsuccess. However, LVLMs are still plagued by the hallucination problem, which\nlimits the practicality in many scenarios. Hallucination refers to the\ninformation of LVLMs' responses that does not exist in the visual input, which\nposes potential risks of substantial consequences. There has been limited work\nstudying hallucination evaluation in LVLMs. In this paper, we propose\nHallucination Evaluation based on Large Language Models (HaELM), an LLM-based\nhallucination evaluation framework. HaELM achieves an approximate 95%\nperformance comparable to ChatGPT and has additional advantages including low\ncost, reproducibility, privacy preservation and local deployment. Leveraging\nthe HaELM, we evaluate the hallucination in current LVLMs. Furthermore, we\nanalyze the factors contributing to hallucination in LVLMs and offer helpful\nsuggestions to mitigate the hallucination problem. Our training data and human\nannotation hallucination data will be made public soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yiyang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guohai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_P/0/1/0/all/0/1\">Pengcheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenlin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinghao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jihua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jitao Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haoyu Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Anatomy of Conspirators: Unveiling Traits using a Comprehensive Twitter Dataset. (arXiv:2308.15154v1 [cs.SI])","link":"http://arxiv.org/abs/2308.15154","description":"<p>The discourse around conspiracy theories is currently thriving amidst the\nrampant misinformation prevalent in online environments. Research in this field\nhas been focused on detecting conspiracy theories on social media, often\nrelying on limited datasets. In this study, we present a novel methodology for\nconstructing a Twitter dataset that encompasses accounts engaged in\nconspiracy-related activities throughout the year 2022. Our approach centers on\ndata collection that is independent of specific conspiracy theories and\ninformation operations. Additionally, our dataset includes a control group\ncomprising randomly selected users who can be fairly compared to the\nindividuals involved in conspiracy activities. This comprehensive collection\neffort yielded a total of 15K accounts and 37M tweets extracted from their\ntimelines. We conduct a comparative analysis of the two groups across three\ndimensions: topics, profiles, and behavioral characteristics. The results\nindicate that conspiracy and control users exhibit similarity in terms of their\nprofile metadata characteristics. However, they diverge significantly in terms\nof behavior and activity, particularly regarding the discussed topics, the\nterminology used, and their stance on trending subjects. Interestingly, there\nis no significant disparity in the presence of bot users between the two\ngroups, suggesting that conspiracy and automation are orthogonal concepts.\nFinally, we develop a classifier to identify conspiracy users using 93\nfeatures, some of which are commonly employed in literature for troll\nidentification. The results demonstrate a high accuracy level (with an average\nF1 score of 0.98%), enabling us to uncover the most discriminative features\nassociated with conspiracy-related accounts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gambini_M/0/1/0/all/0/1\">Margherita Gambini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tardelli_S/0/1/0/all/0/1\">Serena Tardelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tesconi_M/0/1/0/all/0/1\">Maurizio Tesconi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Psychological Counseling with Large Language Model: A Multifaceted Decision-Support System for Non-Professionals. (arXiv:2308.15192v1 [cs.AI])","link":"http://arxiv.org/abs/2308.15192","description":"<p>In the contemporary landscape of social media, an alarming number of users\nexpress negative emotions, some of which manifest as strong suicidal\nintentions. This situation underscores a profound need for trained\npsychological counselors who can enact effective mental interventions. However,\nthe development of these professionals is often an imperative but\ntime-consuming task. Consequently, the mobilization of non-professionals or\nvolunteers in this capacity emerges as a pressing concern. Leveraging the\ncapabilities of artificial intelligence, and in particular, the recent advances\nin large language models, offers a viable solution to this challenge. This\npaper introduces a novel model constructed on the foundation of large language\nmodels to fully assist non-professionals in providing psychological\ninterventions on online user discourses. This framework makes it plausible to\nharness the power of non-professional counselors in a meaningful way. A\ncomprehensive study was conducted involving ten professional psychological\ncounselors of varying expertise, evaluating the system across five critical\ndimensions. The findings affirm that our system is capable of analyzing\npatients' issues with relative accuracy and proffering professional-level\nstrategies recommendations, thereby enhancing support for non-professionals.\nThis research serves as a compelling validation of the application of large\nlanguage models in the field of psychology and lays the groundwork for a new\nparadigm of community-based mental health support.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1\">Guanghui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1\">Dan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Changwei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1\">Wei Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lijuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Juan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bing Xiang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking the Generation of Fact Checking Explanations. (arXiv:2308.15202v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15202","description":"<p>Fighting misinformation is a challenging, yet crucial, task. Despite the\ngrowing number of experts being involved in manual fact-checking, this activity\nis time-consuming and cannot keep up with the ever-increasing amount of Fake\nNews produced daily. Hence, automating this process is necessary to help curb\nmisinformation. Thus far, researchers have mainly focused on claim veracity\nclassification. In this paper, instead, we address the generation of\njustifications (textual explanation of why a claim is classified as either true\nor false) and benchmark it with novel datasets and advanced baselines. In\nparticular, we focus on summarization approaches over unstructured knowledge\n(i.e. news articles) and we experiment with several extractive and abstractive\nstrategies. We employed two datasets with different styles and structures, in\norder to assess the generalizability of our findings. Results show that in\njustification production summarization benefits from the claim information,\nand, in particular, that a claim-driven extractive step improves abstractive\nsummarization performances. Finally, we show that although cross-dataset\nexperiments suffer from performance degradation, a unique model trained on a\ncombination of the two datasets is able to retain style information in an\nefficient manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Russo_D/0/1/0/all/0/1\">Daniel Russo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tekiroglu_S/0/1/0/all/0/1\">Serra Sinem Tekiroglu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerini_M/0/1/0/all/0/1\">Marco Guerini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shared Lexical Items as Triggers of Code Switching. (arXiv:2308.15209v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15209","description":"<p>Why do bilingual speakers code-switch (mix their two languages)? Among the\nseveral theories that attempt to explain this natural and ubiquitous\nphenomenon, the Triggering Hypothesis relates code-switching to the presence of\nlexical triggers, specifically cognates and proper names, adjacent to the\nswitch point. We provide a fuller, more nuanced and refined exploration of the\ntriggering hypothesis, based on five large datasets in three language pairs,\nreflecting both spoken and written bilingual interactions. Our results show\nthat words that are assumed to reside in a mental lexicon shared by both\nlanguages indeed trigger code-switching; that the tendency to switch depends on\nthe distance of the trigger from the switch point; and on whether the trigger\nprecedes or succeeds the switch; but not on the etymology of the trigger words.\nWe thus provide strong, robust, evidence-based confirmation to several\nhypotheses on the relationships between lexical triggers and code-switching.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wintner_S/0/1/0/all/0/1\">Shuly Wintner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shehadi_S/0/1/0/all/0/1\">Safaa Shehadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeira_Y/0/1/0/all/0/1\">Yuli Zeira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osmelak_D/0/1/0/all/0/1\">Doreen Osmelak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nov_Y/0/1/0/all/0/1\">Yuval Nov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions. (arXiv:2308.15214v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15214","description":"<p>We demonstrate an embodied conversational agent that can function as a\nreceptionist and generate a mixture of open and closed-domain dialogue along\nwith facial expressions, by using a large language model (LLM) to develop an\nengaging conversation. We deployed the system onto a Furhat robot, which is\nhighly expressive and capable of using both verbal and nonverbal cues during\ninteraction. The system was designed specifically for the National Robotarium\nto interact with visitors through natural conversations, providing them with\ninformation about the facilities, research, news, upcoming events, etc. The\nsystem utilises the state-of-the-art GPT-3.5 model to generate such information\nalong with domain-general conversations and facial expressions based on prompt\nengineering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cherakara_N/0/1/0/all/0/1\">Neeraj Cherakara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varghese_F/0/1/0/all/0/1\">Finny Varghese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shabana_S/0/1/0/all/0/1\">Sheena Shabana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nelson_N/0/1/0/all/0/1\">Nivan Nelson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karukayil_A/0/1/0/all/0/1\">Abhiram Karukayil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulothungan_R/0/1/0/all/0/1\">Rohith Kulothungan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhan_M/0/1/0/all/0/1\">Mohammed Afil Farhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nesset_B/0/1/0/all/0/1\">Birthe Nesset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moujahid_M/0/1/0/all/0/1\">Meriam Moujahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinkar_T/0/1/0/all/0/1\">Tanvi Dinkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1\">Verena Rieser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemon_O/0/1/0/all/0/1\">Oliver Lemon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for Multimodal Machine Translation. (arXiv:2308.15226v1 [cs.CV])","link":"http://arxiv.org/abs/2308.15226","description":"<p>There has been a growing interest in developing multimodal machine\ntranslation (MMT) systems that enhance neural machine translation (NMT) with\nvisual knowledge. This problem setup involves using images as auxiliary\ninformation during training, and more recently, eliminating their use during\ninference. Towards this end, previous works face a challenge in training\npowerful MMT models from scratch due to the scarcity of annotated multilingual\nvision-language data, especially for low-resource languages. Simultaneously,\nthere has been an influx of multilingual pre-trained models for NMT and\nmultimodal pre-trained models for vision-language tasks, primarily in English,\nwhich have shown exceptional generalisation ability. However, these are not\ndirectly applicable to MMT since they do not provide aligned multimodal\nmultilingual features for generative tasks. To alleviate this issue, instead of\ndesigning complex modules for MMT, we propose CLIPTrans, which simply adapts\nthe independently pre-trained multimodal M-CLIP and the multilingual mBART. In\norder to align their embedding spaces, mBART is conditioned on the M-CLIP\nfeatures by a prefix sequence generated through a lightweight mapping network.\nWe train this in a two-stage pipeline which warms up the model with image\ncaptioning before the actual translation task. Through experiments, we\ndemonstrate the merits of this framework and consequently push forward the\nstate-of-the-art across standard benchmarks by an average of +2.67 BLEU. The\ncode can be found at www.github.com/devaansh100/CLIPTrans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1\">Devaansh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kharbanda_S/0/1/0/all/0/1\">Siddhant Kharbanda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jiawei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wanhua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1\">Hanspeter Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1\">Donglai Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-party Goal Tracking with LLMs: Comparing Pre-training, Fine-tuning, and Prompt Engineering. (arXiv:2308.15231v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15231","description":"<p>This paper evaluates the extent to which current Large Language Models (LLMs)\ncan capture task-oriented multi-party conversations (MPCs). We have recorded\nand transcribed 29 MPCs between patients, their companions, and a social robot\nin a hospital. We then annotated this corpus for multi-party goal-tracking and\nintent-slot recognition. People share goals, answer each other's goals, and\nprovide other people's goals in MPCs - none of which occur in dyadic\ninteractions. To understand user goals in MPCs, we compared three methods in\nzero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks\nto train DialogLM using LED, and employed prompt engineering techniques with\nGPT-3.5-turbo, to determine which approach can complete this novel task with\nlimited data. GPT-3.5-turbo significantly outperformed the others in a few-shot\nsetting. The `reasoning' style prompt, when given 7% of the corpus as example\nannotated conversations, was the best performing method. It correctly annotated\n62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition\nMPCs. A `story' style prompt increased model hallucination, which could be\ndetrimental if deployed in safety-critical settings. We conclude that\nmulti-party conversations still challenge state-of-the-art LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Addlesee_A/0/1/0/all/0/1\">Angus Addlesee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sieinska_W/0/1/0/all/0/1\">Weronika Siei&#x144;ska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunson_N/0/1/0/all/0/1\">Nancie Gunson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_D/0/1/0/all/0/1\">Daniel Hern&#xe1;ndez Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dondrup_C/0/1/0/all/0/1\">Christian Dondrup</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemon_O/0/1/0/all/0/1\">Oliver Lemon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Classification-Aware Neural Topic Model Combined With Interpretable Analysis -- For Conflict Classification. (arXiv:2308.15232v1 [cs.LG])","link":"http://arxiv.org/abs/2308.15232","description":"<p>A large number of conflict events are affecting the world all the time. In\norder to analyse such conflict events effectively, this paper presents a\nClassification-Aware Neural Topic Model (CANTM-IA) for Conflict Information\nClassification and Topic Discovery. The model provides a reliable\ninterpretation of classification results and discovered topics by introducing\ninterpretability analysis. At the same time, interpretation is introduced into\nthe model architecture to improve the classification performance of the model\nand to allow interpretation to focus further on the details of the data.\nFinally, the model architecture is optimised to reduce the complexity of the\nmodel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1\">Tianyu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yida Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Soonho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuate_D/0/1/0/all/0/1\">Darline Larissa Kengne Kuate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_J/0/1/0/all/0/1\">Julie Lang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vos_R/0/1/0/all/0/1\">Rob Vos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences. (arXiv:2308.15235v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15235","description":"<p>Flip through any book or listen to any song lyrics, and you will come across\npronouns that, in certain cases, can hinder meaning comprehension, especially\nfor machines. As the role of having cognitive machines becomes pervasive in our\nlives, numerous systems have been developed to resolve pronouns under various\nchallenges. Commensurate with this, it is believed that having systems able to\ndisambiguate pronouns in sentences will help towards the endowment of machines\nwith commonsense and reasoning abilities like those found in humans. However,\none problem these systems face with modern English is the lack of gender\npronouns, where people try to alternate by using masculine, feminine, or plural\nto avoid the whole issue. Since humanity aims to the building of systems in the\nfull-bodied sense we usually reserve for people, what happens when pronouns in\nwritten text, like plural or epicene ones, refer to unspecified entities whose\ngender is not necessarily known? Wouldn't that put extra barriers to existing\ncoreference resolution systems? Towards answering those questions, through the\nimplementation of a neural-symbolic system that utilizes the best of both\nworlds, we are employing PronounFlow, a system that reads any English sentence\nwith pronouns and entities, identifies which of them are not tied to each\nother, and makes suggestions on which to use to avoid biases. Undertaken\nexperiments show that PronounFlow not only alternates pronouns in sentences\nbased on the collective human knowledge around us but also considerably helps\ncoreference resolution systems with the pronoun disambiguation process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Isaak_N/0/1/0/all/0/1\">Nicos Isaak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Classification-Guided Approach for Adversarial Attacks against Neural Machine Translation. (arXiv:2308.15246v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15246","description":"<p>Neural Machine Translation (NMT) models have been shown to be vulnerable to\nadversarial attacks, wherein carefully crafted perturbations of the input can\nmislead the target model. In this paper, we introduce ACT, a novel adversarial\nattack framework against NMT systems guided by a classifier. In our attack, the\nadversary aims to craft meaning-preserving adversarial examples whose\ntranslations by the NMT model belong to a different class than the original\ntranslations in the target language. Unlike previous attacks, our new approach\nhas a more substantial effect on the translation by altering the overall\nmeaning, which leads to a different class determined by a classifier. To\nevaluate the robustness of NMT models to this attack, we propose enhancements\nto existing black-box word-replacement-based attacks by incorporating output\ntranslations of the target NMT model and the output logits of a classifier\nwithin the attack process. Extensive experiments in various settings, including\na comparison with existing untargeted attacks, demonstrate that the proposed\nattack is considerably more successful in altering the class of the output\ntranslation and has more effect on the translation. This new paradigm can show\nthe vulnerabilities of NMT systems by focusing on the class of translation\nrather than the mere translation quality as studied traditionally.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sadrizadeh_S/0/1/0/all/0/1\">Sahar Sadrizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolamic_L/0/1/0/all/0/1\">Ljiljana Dolamic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1\">Pascal Frossard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing OCR Performance through Post-OCR Models: Adopting Glyph Embedding for Improved Correction. (arXiv:2308.15262v1 [cs.CV])","link":"http://arxiv.org/abs/2308.15262","description":"<p>The study investigates the potential of post-OCR models to overcome\nlimitations in OCR models and explores the impact of incorporating glyph\nembedding on post-OCR correction performance. In this study, we have developed\nour own post-OCR correction model. The novelty of our approach lies in\nembedding the OCR output using CharBERT and our unique embedding technique,\ncapturing the visual characteristics of characters. Our findings show that\npost-OCR correction effectively addresses deficiencies in inferior OCR models,\nand glyph embedding enables the model to achieve superior results, including\nthe ability to correct individual words.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yung-Hsin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuli Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KGConv, a Conversational Corpus grounded in Wikidata. (arXiv:2308.15298v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15298","description":"<p>We present KGConv, a large, conversational corpus of 71k conversations where\neach question-answer pair is grounded in a Wikidata fact. Conversations contain\non average 8.6 questions and for each Wikidata fact, we provide multiple\nvariants (12 on average) of the corresponding question using templates, human\nannotations, hand-crafted rules and a question rewriting neural model. We\nprovide baselines for the task of Knowledge-Based, Conversational Question\nGeneration. KGConv can further be used for other generation and analysis tasks\nsuch as single-turn question generation from Wikidata triples, question\nrewriting, question answering from conversation or from knowledge graphs and\nquiz generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brabant_Q/0/1/0/all/0/1\">Quentin Brabant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lecorve_G/0/1/0/all/0/1\">Gwenole Lecorve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rojas_Barahona_L/0/1/0/all/0/1\">Lina M. Rojas-Barahona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardent_C/0/1/0/all/0/1\">Claire Gardent</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TaskLAMA: Probing the Complex Task Understanding of Language Models. (arXiv:2308.15299v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15299","description":"<p>Structured Complex Task Decomposition (SCTD) is the problem of breaking down\na complex real-world task (such as planning a wedding) into a directed acyclic\ngraph over individual steps that contribute to achieving the task, with edges\nspecifying temporal dependencies between them. SCTD is an important component\nof assistive planning tools, and a challenge for commonsense reasoning systems.\nWe probe how accurately SCTD can be done with the knowledge extracted from\nLarge Language Models (LLMs). We introduce a high-quality human-annotated\ndataset for this problem and novel metrics to fairly assess performance of LLMs\nagainst several baselines. Our experiments reveal that LLMs are able to\ndecompose complex tasks into individual steps effectively, with a relative\nimprovement of 15% to 280% over the best baseline. We also propose a number of\napproaches to further improve their performance, with a relative improvement of\n7% to 37% over the base model. However, we find that LLMs still struggle to\npredict pairwise temporal dependencies, which reveals a gap in their\nunderstanding of complex tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1\">Quan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1\">Mehran Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noble_I/0/1/0/all/0/1\">Isaac Noble</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imbrasaite_V/0/1/0/all/0/1\">Vaiva Imbrasaite</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_D/0/1/0/all/0/1\">Deepak Ramachandran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Framework for Responsible Development of Automated Student Feedback with Generative AI. (arXiv:2308.15334v1 [cs.CY])","link":"http://arxiv.org/abs/2308.15334","description":"<p>Providing rich feedback to students is essential for supporting student\nlearning. Recent advances in generative AI, particularly within large language\nmodelling (LLM), provide the opportunity to deliver repeatable, scalable and\ninstant automatically generated feedback to students, making abundant a\npreviously scarce and expensive learning resource. Such an approach is feasible\nfrom a technical perspective due to these recent advances in Artificial\nIntelligence (AI) and Natural Language Processing (NLP); while the potential\nupside is a strong motivator, doing so introduces a range of potential ethical\nissues that must be considered as we apply these technologies. The\nattractiveness of AI systems is that they can effectively automate the most\nmundane tasks; but this risks introducing a \"tyranny of the majority\", where\nthe needs of minorities in the long tail are overlooked because they are\ndifficult to automate.\n</p>\n<p>Developing machine learning models that can generate valuable and authentic\nfeedback requires the input of human domain experts. The choices we make in\ncapturing this expertise -- whose, which, when, and how -- will have\nsignificant consequences for the nature of the resulting feedback. How we\nmaintain our models will affect how that feedback remains relevant given\ntemporal changes in context, theory, and prior learning profiles of student\ncohorts. These questions are important from an ethical perspective; but they\nare also important from an operational perspective. Unless they can be\nanswered, our AI generated systems will lack the trust necessary for them to be\nuseful features in the contemporary learning environment.\n</p>\n<p>This article will outline the frontiers of automated feedback, identify the\nethical issues involved in the provision of automated feedback and present a\nframework to assist academics to develop such systems responsibly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lindsay_E/0/1/0/all/0/1\">Euan D Lindsay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johri_A/0/1/0/all/0/1\">Aditya Johri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bjerva_J/0/1/0/all/0/1\">Johannes Bjerva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Historical patterns of rice farming explain modern-day language use in China and Japan more than modernization and urbanization. (arXiv:2308.15352v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15352","description":"<p>We used natural language processing to analyze a billion words to study\ncultural differences on Weibo, one of China's largest social media platforms.\nWe compared predictions from two common explanations about cultural differences\nin China (economic development and urban-rural differences) against the\nless-obvious legacy of rice versus wheat farming. Rice farmers had to\ncoordinate shared irrigation networks and exchange labor to cope with higher\nlabor requirements. In contrast, wheat relied on rainfall and required half as\nmuch labor. We test whether this legacy made southern China more\ninterdependent. Across all word categories, rice explained twice as much\nvariance as economic development and urbanization. Rice areas used more words\nreflecting tight social ties, holistic thought, and a cautious, prevention\norientation. We then used Twitter data comparing prefectures in Japan, which\nlargely replicated the results from China. This provides crucial evidence of\nthe rice theory in a different nation, language, and platform.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guntuku_S/0/1/0/all/0/1\">Sharath Chandra Guntuku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talhelm_T/0/1/0/all/0/1\">Thomas Talhelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sherman_G/0/1/0/all/0/1\">Garrick Sherman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Angel Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_S/0/1/0/all/0/1\">Salvatore Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Liuqing Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1\">Lyle H. Ungar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-to-SQL Empowered by Large Language Models: A Benchmark Evaluation. (arXiv:2308.15363v1 [cs.DB])","link":"http://arxiv.org/abs/2308.15363","description":"<p>Large language models (LLMs) have emerged as a new paradigm for Text-to-SQL\ntask. However, the absence of a systematical benchmark inhibits the development\nof designing effective, efficient and economic LLM-based Text-to-SQL solutions.\nTo address this challenge, in this paper, we first conduct a systematical and\nextensive comparison over existing prompt engineering methods, including\nquestion representation, example selection and example organization, and with\nthese experimental results, we elaborates their pros and cons. Based on these\nfindings, we propose a new integrated solution, named DAIL-SQL, which refreshes\nthe Spider leaderboard with 86.6% execution accuracy and sets a new bar.\nTowards an efficient and economic LLM-based Text-to-SQL solution, we emphasize\nthe token efficiency in prompt engineering and compare the prior studies under\nthis metric. Additionally, we investigate open-source LLMs in in-context\nlearning, and further enhance their performance with task-specific supervised\nfine-tuning. Our explorations highlight open-source LLMs' potential in\nText-to-SQL, as well as the advantages and disadvantages of the task-specific\nsupervised fine-tuning. We hope that our work provides a deeper understanding\nof Text-to-SQL with LLMs, and inspire further investigations and broad\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dawei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haibin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiuyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yichen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bolin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Machine Ethics -- Can LLMs Perform Moral Reasoning through the Lens of Moral Theories?. (arXiv:2308.15399v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15399","description":"<p>Making moral judgments is an essential step toward developing ethical AI\nsystems. Prevalent approaches are mostly implemented in a bottom-up manner,\nwhich uses a large set of annotated data to train models based on crowd-sourced\nopinions about morality. These approaches have been criticized for potentially\novergeneralizing a limited group of annotators' moral stances and lacking\nexplainability. In contrast, top-down approaches make moral judgments grounded\nin a set of principles. However, it remains conceptual due to the incapability\nof previous language models and the unsolved debate among moral principles. In\nthis study, we propose a flexible framework to steer Large Language Models\n(LLMs) to perform moral reasoning with well-established moral theories from\ninterdisciplinary research. The theory-guided top-down framework can\nincorporate various moral theories. Our experiments demonstrate the\neffectiveness of the proposed framework on datasets derived from moral\ntheories. Furthermore, we show the alignment between different moral theories\nand existing morality datasets. Our analysis exhibits the potentials and flaws\nin existing resources (models and datasets) in developing explainable moral\njudgment-making systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Minda Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xixin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability. (arXiv:2308.15419v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15419","description":"<p>How do language models learn to make predictions during pre-training? To\nstudy this question, we extract learning curves from five autoregressive\nEnglish language model pre-training runs, for 1M tokens in context. We observe\nthat the language models generate short repetitive phrases before learning to\ngenerate longer and more coherent text. We quantify the final surprisal,\nwithin-run variability, age of acquisition, forgettability, and cross-run\nvariability of learning curves for individual tokens in context. More frequent\ntokens reach lower final surprisals, exhibit less variability within and across\npre-training runs, are learned earlier, and are less likely to be \"forgotten\"\nduring pre-training. Higher n-gram probabilities further accentuate these\neffects. Independent of the target token, shorter and more frequent contexts\ncorrelate with marginally more stable and quickly acquired predictions. Effects\nof part-of-speech are also small, although nouns tend to be acquired later and\nless stably than verbs, adverbs, and adjectives. Our work contributes to a\nbetter understanding of language model pre-training dynamics and informs the\ndeployment of stable language models in practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Tyler A. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin K. Bergen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vulgar Remarks Detection in Chittagonian Dialect of Bangla. (arXiv:2308.15448v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15448","description":"<p>The negative effects of online bullying and harassment are increasing with\nInternet popularity, especially in social media. One solution is using natural\nlanguage processing (NLP) and machine learning (ML) methods for the automatic\ndetection of harmful remarks, but these methods are limited in low-resource\nlanguages like the Chittagonian dialect of Bangla.This study focuses on\ndetecting vulgar remarks in social media using supervised ML and deep learning\nalgorithms.Logistic Regression achieved promising accuracy (0.91) while simple\nRNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the\nissue that NN algorithms require more data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_T/0/1/0/all/0/1\">Tanjim Mahmud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ptaszynski_M/0/1/0/all/0/1\">Michal Ptaszynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masui_F/0/1/0/all/0/1\">Fumito Masui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15452","description":"<p>The reasoning capabilities of Large Language Models (LLMs) play a pivotal\nrole in the realm of embodied artificial intelligence. Although there are\neffective methods like program-of-thought prompting for LLMs which uses\nprogramming language to tackle complex reasoning tasks, the specific impact of\ncode data on the improvement of reasoning capabilities remains under-explored.\nTo address this gap, we propose complexity-impacted reasoning score (CIRS),\nwhich combines structural and logical attributes, to measure the correlation\nbetween code and reasoning abilities. Specifically, we use the abstract syntax\ntree to encode the structural information and calculate logical complexity by\nconsidering the difficulty and the cyclomatic complexity. Through an empirical\nanalysis, we find not all code data of complexity can be learned or understood\nby LLMs. Optimal level of complexity is critical to the improvement of\nreasoning abilities by program-aided prompting. Then we design an\nauto-synthesizing and stratifying algorithm, and apply it to instruction\ngeneration for mathematical reasoning and code data filtering for code\ngeneration tasks. Extensive results demonstrates the effectiveness of our\nproposed approach. Code will be integrated into the EasyInstruct framework at\nhttps://github.com/zjunlp/EasyInstruct.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yinuo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer. (arXiv:2308.15459v1 [cs.CL])","link":"http://arxiv.org/abs/2308.15459","description":"<p>Textual style transfer is the task of transforming stylistic properties of\ntext while preserving meaning. Target \"styles\" can be defined in numerous ways,\nranging from single attributes (e.g, formality) to authorship (e.g,\nShakespeare). Previous unsupervised style-transfer approaches generally rely on\nsignificant amounts of labeled data for only a fixed set of styles or require\nlarge language models. In contrast, we introduce a novel diffusion-based\nframework for general-purpose style transfer that can be flexibly adapted to\narbitrary target styles at inference time. Our parameter-efficient approach,\nParaGuide, leverages paraphrase-conditioned diffusion models alongside\ngradient-based guidance from both off-the-shelf classifiers and strong existing\nstyle embedders to transform the style of text while preserving semantic\ninformation. We validate the method on the Enron Email Corpus, with both human\nand automatic evaluations, and find that it outperforms strong baselines on\nformality, sentiment, and even authorship style transfer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_Z/0/1/0/all/0/1\">Zachary Horvitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1\">Ajay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Investigation of the Role of Pre-training in Lifelong Learning. (arXiv:2112.09153v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2112.09153","description":"<p>The lifelong learning paradigm in machine learning is an attractive\nalternative to the more prominent isolated learning scheme not only due to its\nresemblance to biological learning but also its potential to reduce energy\nwaste by obviating excessive model re-training. A key challenge to this\nparadigm is the phenomenon of catastrophic forgetting. With the increasing\npopularity and success of pre-trained models in machine learning, we pose the\nquestion: What role does pre-training play in lifelong learning, specifically\nwith respect to catastrophic forgetting? We investigate existing methods in the\ncontext of large, pre-trained models and evaluate their performance on a\nvariety of text and image classification tasks, including a large-scale study\nusing a novel data set of 15 diverse NLP tasks. Across all settings, we observe\nthat generic pre-training implicitly alleviates the effects of catastrophic\nforgetting when learning multiple tasks sequentially compared to randomly\ninitialized models. We then further investigate why pre-training alleviates\nforgetting in this setting. We study this phenomenon by analyzing the loss\nlandscape, finding that pre-trained weights appear to ease forgetting by\nleading to wider minima. Based on this insight, we propose jointly optimizing\nfor current task loss and loss basin sharpness to explicitly encourage wider\nbasins during sequential fine-tuning. We show that this optimization approach\noutperforms several state-of-the-art task-sequential continual learning\nalgorithms across multiple settings, occasionally even without retaining a\nmemory that scales in size with the number of tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1\">Sanket Vaibhav Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_D/0/1/0/all/0/1\">Darshan Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Deep Convolutional Neural Networks Based Multi-Task Ensemble Model for Aspect and Polarity Classification in Persian Reviews. (arXiv:2201.06313v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.06313","description":"<p>Aspect-based sentiment analysis is of great importance and application\nbecause of its ability to identify all aspects discussed in the text. However,\naspect-based sentiment analysis will be most effective when, in addition to\nidentifying all the aspects discussed in the text, it can also identify their\npolarity. Most previous methods use the pipeline approach, that is, they first\nidentify the aspects and then identify the polarities. Such methods are\nunsuitable for practical applications since they can lead to model errors.\nTherefore, in this study, we propose a multi-task learning model based on\nConvolutional Neural Networks (CNNs), which can simultaneously detect aspect\ncategory and detect aspect category polarity. creating a model alone may not\nprovide the best predictions and lead to errors such as bias and high variance.\nTo reduce these errors and improve the efficiency of model predictions,\ncombining several models known as ensemble learning may provide better results.\nTherefore, the main purpose of this article is to create a model based on an\nensemble of multi-task deep convolutional neural networks to enhance sentiment\nanalysis in Persian reviews. We evaluated the proposed method using a Persian\nlanguage dataset in the movie domain. Jacquard index and Hamming loss measures\nwere used to evaluate the performance of the developed models. The results\nindicate that this new approach increases the efficiency of the sentiment\nanalysis model in the Persian language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vazan_M/0/1/0/all/0/1\">Milad Vazan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masoumi_F/0/1/0/all/0/1\">Fatemeh Sadat Masoumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majd_S/0/1/0/all/0/1\">Sepideh Saeedi Majd</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Theory of Mind Might Have Spontaneously Emerged in Large Language Models. (arXiv:2302.02083v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.02083","description":"<p>We explore the intriguing possibility that theory of mind (ToM), or the\nuniquely human ability to impute unobservable mental states to others, might\nhave spontaneously emerged in large language models (LLMs). We designed 40\nfalse-belief tasks, considered a gold standard in testing ToM in humans, and\nadministered them to several LLMs. Each task included a false-belief scenario,\nthree closely matched true-belief controls, and the reversed versions of all\nfour. Smaller and older models solved no tasks; GPT-3-davinci-001 (from May\n2020) and GPT-3-davinci-002 (from January 2022) solved 10%; and\nGPT-3-davinci-003 (from November 2022) and ChatGPT-3.5-turbo (from March 2023)\nsolved 35% of the tasks, mirroring the performance of three-year-old children.\nChatGPT-4 (from June 2023) solved 90% of the tasks, matching the performance of\nseven-year-old children. These findings suggest the intriguing possibility that\nToM, previously considered exclusive to humans, may have spontaneously emerged\nas a byproduct of LLMs' improving language skills.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kosinski_M/0/1/0/all/0/1\">Michal Kosinski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. (arXiv:2302.12095v5 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2302.12095","description":"<p>ChatGPT is a recent chatbot service released by OpenAI and is receiving\nincreasing attention over the past few months. While evaluations of various\naspects of ChatGPT have been done, its robustness, i.e., the performance to\nunexpected inputs, is still unclear to the public. Robustness is of particular\nconcern in responsible AI, especially for safety-critical applications. In this\npaper, we conduct a thorough evaluation of the robustness of ChatGPT from the\nadversarial and out-of-distribution (OOD) perspective. To do so, we employ the\nAdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart\nreview and DDXPlus medical diagnosis datasets for OOD evaluation. We select\nseveral popular foundation models as baselines. Results show that ChatGPT shows\nconsistent advantages on most adversarial and OOD classification and\ntranslation tasks. However, the absolute performance is far from perfection,\nwhich suggests that adversarial and OOD robustness remains a significant threat\nto foundation models. Moreover, ChatGPT shows astounding performance in\nunderstanding dialogue-related texts and we find that it tends to provide\ninformal suggestions for medical tasks instead of definitive answers. Finally,\nwe present in-depth discussions of possible research directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xixu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Runkai Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haojun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiubo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_B/0/1/0/all/0/1\">Binxin Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OLISIA: a Cascade System for Spoken Dialogue State Tracking. (arXiv:2304.11073v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2304.11073","description":"<p>Though Dialogue State Tracking (DST) is a core component of spoken dialogue\nsystems, recent work on this task mostly deals with chat corpora, disregarding\nthe discrepancies between spoken and written language.In this paper, we propose\nOLISIA, a cascade system which integrates an Automatic Speech Recognition (ASR)\nmodel and a DST model. We introduce several adaptations in the ASR and DST\nmodules to improve integration and robustness to spoken conversations.With\nthese adaptations, our system ranked first in DSTC11 Track 3, a benchmark to\nevaluate spoken DST. We conduct an in-depth analysis of the results and find\nthat normalizing the ASR outputs and adapting the DST inputs through data\naugmentation, along with increasing the pre-trained models size all play an\nimportant role in reducing the performance discrepancy between written and\nspoken conversations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Jacqmin_L/0/1/0/all/0/1\">L&#xe9;o Jacqmin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Druart_L/0/1/0/all/0/1\">Lucas Druart</a> (LIA), <a href=\"http://arxiv.org/find/eess/1/au:+Esteve_Y/0/1/0/all/0/1\">Yannick Est&#xe8;ve</a> (LIA), <a href=\"http://arxiv.org/find/eess/1/au:+Favre_B/0/1/0/all/0/1\">Beno&#xee;t Favre</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rojas_Barahona_L/0/1/0/all/0/1\">Lina Maria Rojas-Barahona</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vielzeuf_V/0/1/0/all/0/1\">Valentin Vielzeuf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Asymmetric feature interaction for interpreting model predictions. (arXiv:2305.07224v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07224","description":"<p>In natural language processing (NLP), deep neural networks (DNNs) could model\ncomplex interactions between context and have achieved impressive results on a\nrange of NLP tasks. Prior works on feature interaction attribution mainly focus\non studying symmetric interaction that only explains the additional influence\nof a set of words in combination, which fails to capture asymmetric influence\nthat contributes to model prediction. In this work, we propose an asymmetric\nfeature interaction attribution explanation model that aims to explore\nasymmetric higher-order feature interactions in the inference of deep neural\nNLP models. By representing our explanation with an directed interaction graph,\nwe experimentally demonstrate interpretability of the graph to discover\nasymmetric feature interactions. Experimental results on two sentiment\nclassification datasets show the superiority of our model against the\nstate-of-the-art feature interaction attribution methods in identifying\ninfluential features for model predictions. Our code is available at\nhttps://github.com/StillLu/ASIV.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaolei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianghong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haode Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"a unified front-end framework for english text-to-speech synthesis. (arXiv:2305.10666v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10666","description":"<p>The front-end is a critical component of English text-to-speech (TTS)\nsystems, responsible for extracting linguistic features that are essential for\na text-to-speech model to synthesize speech, such as prosodies and phonemes.\nThe English TTS front-end typically consists of a text normalization (TN)\nmodule, a prosody word prosody phrase (PWPP) module, and a grapheme-to-phoneme\n(G2P) module. However, current research on the English TTS front-end focuses\nsolely on individual modules, neglecting the interdependence between them and\nresulting in sub-optimal performance for each module. Therefore, this paper\nproposes a unified front-end framework that captures the dependencies among the\nEnglish TTS front-end modules. Extensive experiments have demonstrated that the\nproposed method achieves state-of-the-art (SOTA) performance in all modules.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ying_Z/0/1/0/all/0/1\">Zelin Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_Q/0/1/0/all/0/1\">Qiuqiang Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qiao Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuanyuan Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Trip Towards Fairness: Bias and De-Biasing in Large Language Models. (arXiv:2305.13862v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13862","description":"<p>Cheap-to-Build Very Large-Language Models (CtB-LLMs) with affordable training\nare emerging as the next big revolution in natural language processing and\nunderstanding. These CtB-LLMs are democratizing access to trainable Very\nLarge-Language Models (VLLMs) and, thus, may represent the building blocks of\nmany NLP systems solving downstream tasks. Hence, a little or a large bias in\nCtB-LLMs may cause huge harm. In this paper, we performed a large investigation\nof the bias of three families of CtB-LLMs, and we showed that debiasing\ntechniques are effective and usable. Indeed, according to current tests, the\nLLaMA and the OPT families have an important bias in gender, race, religion,\nand profession. In contrast to the analysis for other LLMs, we discovered that\nbias depends not on the number of parameters but on the perplexity. Finally,\nthe debiasing of OPT using LoRA reduces bias up to 4.12 points in the\nnormalized stereotype score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ranaldi_L/0/1/0/all/0/1\">Leonardo Ranaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruzzetti_E/0/1/0/all/0/1\">Elena Sofia Ruzzetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venditti_D/0/1/0/all/0/1\">Davide Venditti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onorati_D/0/1/0/all/0/1\">Dario Onorati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanzotto_F/0/1/0/all/0/1\">Fabio Massimo Zanzotto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time. (arXiv:2305.17118v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.17118","description":"<p>Large language models(LLMs) have sparked a new wave of exciting AI\napplications. Hosting these models at scale requires significant memory\nresources. One crucial memory bottleneck for the deployment stems from the\ncontext window. It is commonly recognized that model weights are memory hungry;\nhowever, the size of key-value embedding stored during the generation process\n(KV cache) can easily surpass the model size. The enormous size of the KV cache\nputs constraints on the inference batch size, which is crucial for high\nthroughput inference workload. Inspired by an interesting observation of the\nattention scores, we hypothesize the persistence of importance: only pivotal\ntokens, which had a substantial influence at one step, will significantly\ninfluence future generations. Based on our empirical verification and\ntheoretical analysis around this hypothesis, we propose Scissorhands, a system\nthat maintains the memory usage of the KV cache at a fixed budget without\nfinetuning the model. In essence, Scissorhands manages the KV cache by storing\nthe pivotal tokens with a higher probability. We validate that Scissorhands\nreduces the inference memory usage of the KV cache by up to 5X without\ncompromising model quality. We further demonstrate that Scissorhands can be\ncombined with 4-bit quantization, traditionally used to compress model weights,\nto achieve up to 20X compression.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zichang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desai_A/0/1/0/all/0/1\">Aditya Desai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_F/0/1/0/all/0/1\">Fangshuo Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weitao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_V/0/1/0/all/0/1\">Victor Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhaozhuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blockwise Parallel Transformer for Large Context Models. (arXiv:2305.19370v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19370","description":"<p>Transformers have emerged as the cornerstone of state-of-the-art natural\nlanguage processing models, showcasing exceptional performance across a wide\nrange of AI applications. However, the memory demands posed by the\nself-attention mechanism and the large feedforward network in Transformers\nlimit their ability to handle long sequences, thereby creating challenges for\ntasks involving multiple long sequences or long-term dependencies. We present a\ndistinct approach, Blockwise Parallel Transformer (BPT), that leverages\nblockwise computation of self-attention and feedforward network fusion to\nminimize memory costs. By processing longer input sequences while maintaining\nmemory efficiency, BPT enables training sequences 32 times longer than vanilla\nTransformers and up to 4 times longer than previous memory-efficient methods.\nExtensive experiments on language modeling and reinforcement learning tasks\ndemonstrate the effectiveness of BPT in reducing memory requirements and\nimproving performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Do Annotator Demographics Matter? Measuring the Influence of Annotator Demographics with the POPQUORN Dataset. (arXiv:2306.06826v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.06826","description":"<p>Annotators are not fungible. Their demographics, life experiences, and\nbackgrounds all contribute to how they label data. However, NLP has only\nrecently considered how annotator identity might influence their decisions.\nHere, we present POPQUORN (the POtato-Prolific dataset for QUestion-Answering,\nOffensiveness, text Rewriting, and politeness rating with demographic Nuance).\nPOPQUORN contains 45,000 annotations from 1,484 annotators, drawn from a\nrepresentative sample regarding sex, age, and race as the US population.\nThrough a series of analyses, we show that annotators' background plays a\nsignificant role in their judgments. Further, our work shows that backgrounds\nnot previously considered in NLP (e.g., education), are meaningful and should\nbe considered. Our study suggests that understanding the background of\nannotators and collecting labels from a demographically balanced pool of crowd\nworkers is important to reduce the bias of datasets. The dataset, annotator\nbackground, and annotation interface are available at\nhttps://github.com/Jiaxin-Pei/potato-prolific-dataset .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1\">Jiaxin Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurgens_D/0/1/0/all/0/1\">David Jurgens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mol-Instructions: A Large-Scale Biomolecular Instruction Dataset for Large Language Models. (arXiv:2306.08018v2 [q-bio.QM] UPDATED)","link":"http://arxiv.org/abs/2306.08018","description":"<p>Large Language Models (LLMs), with their remarkable task-handling\ncapabilities and innovative outputs, have catalyzed significant advancements\nacross a spectrum of fields. However, their proficiency within specialized\ndomains such as biomolecular studies remains limited. To address this\nchallenge, we introduce Mol-Instructions, a meticulously curated, comprehensive\ninstruction dataset expressly designed for the biomolecular realm.\nMol-Instructions is composed of three pivotal components: molecule-oriented\ninstructions, protein-oriented instructions, and biomolecular text\ninstructions, each curated to enhance the understanding and prediction\ncapabilities of LLMs concerning biomolecular features and behaviors. Through\nextensive instruction tuning experiments on the representative LLM, we\nunderscore the potency of Mol-Instructions to enhance the adaptability and\ncognitive acuity of large models within the complex sphere of biomolecular\nstudies, thereby promoting advancements in the biomolecular research community.\nMol-Instructions is made publicly accessible for future research endeavors and\nwill be subjected to continual updates for enhanced applicability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Fang_Y/0/1/0/all/0/1\">Yin Fang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Liu_K/0/1/0/all/0/1\">Kangwei Liu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Huang_R/0/1/0/all/0/1\">Rui Huang</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuo Chen</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Fan_X/0/1/0/all/0/1\">Xiaohui Fan</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Block-State Transformer. (arXiv:2306.09539v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09539","description":"<p>State space models (SSMs) have shown impressive results on tasks that require\nmodeling long-range dependencies and efficiently scale to long sequences owing\nto their subquadratic runtime complexity. Originally designed for continuous\nsignals, SSMs have shown superior performance on a plethora of tasks, in vision\nand audio; however, SSMs still lag Transformer performance in Language Modeling\ntasks. In this work, we propose a hybrid layer named Block-State Transformer\n(BST), that internally combines an SSM sublayer for long-range\ncontextualization, and a Block Transformer sublayer for short-term\nrepresentation of sequences. We study three different, and completely\nparallelizable, variants that integrate SSMs and block-wise attention. We show\nthat our model outperforms similar Transformer-based architectures on language\nmodeling perplexity and generalizes to longer sequences. In addition, the\nBlock-State Transformer demonstrates more than tenfold increase in speed at the\nlayer level compared to the Block-Recurrent Transformer when model\nparallelization is employed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fathi_M/0/1/0/all/0/1\">Mahan Fathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pilault_J/0/1/0/all/0/1\">Jonathan Pilault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bacon_P/0/1/0/all/0/1\">Pierre-Luc Bacon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firat_O/0/1/0/all/0/1\">Orhan Firat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goroshin_R/0/1/0/all/0/1\">Ross Goroshin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Fixated by Red Herrings: Exploring Creative Problem Solving and Einstellung Effect using the Only Connect Wall Dataset. (arXiv:2306.11167v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.11167","description":"<p>The quest for human imitative AI has been an enduring topic in AI research\nsince its inception. The technical evolution and emerging capabilities of the\nlatest cohort of large language models (LLMs) have reinvigorated the subject\nbeyond academia to the cultural zeitgeist. While recent NLP evaluation\nbenchmark tasks test some aspects of human-imitative behaviour (e.g.,\nBIG-bench's 'human-like behavior' tasks), few, if not none, examine creative\nproblem solving abilities. Creative problem solving in humans is a well-studied\ntopic in cognitive neuroscience with standardized tests that predominantly use\nthe ability to associate (heterogeneous) connections among clue words as a\nmetric for creativity. Exposure to misleading stimuli - distractors dubbed red\nherrings - impede human performance in such tasks via the fixation effect and\nEinstellung paradigm. In cognitive neuroscience studies, such fixations are\nexperimentally induced by pre-exposing participants to orthographically similar\nincorrect words to subsequent word-fragments or clues. The popular British quiz\nshow Only Connect's Connecting Wall segment essentially mimics Mednick's Remote\nAssociates Test (RAT) formulation with built-in, deliberate red herrings, which\nmakes it an ideal proxy dataset to explore and study fixation effect and\nEinstellung paradigm from cognitive neuroscience in LLMs. In this paper we\npresent the novel Only Connect Wall (OCW) dataset and report results from our\nevaluation of selected pre-trained language models and LLMs on creative problem\nsolving tasks like grouping clue words by heterogeneous connections, and\nidentifying correct open knowledge domain connections in respective groups. We\nsynthetically generate two additional datasets: OCW-Randomized, OCW-WordNet to\nfurther analyze our red-herrings hypothesis in language models. The code and\nlink to the dataset are available at https://github.com/TaatiTeam/OCW.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naeini_S/0/1/0/all/0/1\">Saeid Naeini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saqur_R/0/1/0/all/0/1\">Raeid Saqur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saeidi_M/0/1/0/all/0/1\">Mozhgan Saeidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_J/0/1/0/all/0/1\">John Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taati_B/0/1/0/all/0/1\">Babak Taati</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model. (arXiv:2307.07740v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.07740","description":"<p>Sentiment analysis is the process of identifying and categorizing people's\nemotions or opinions regarding various topics. The analysis of Twitter\nsentiment has become an increasingly popular topic in recent years. In this\npaper, we present several machine learning and a deep learning model to\nanalysis sentiment of Persian political tweets. Our analysis was conducted\nusing Bag of Words and ParsBERT for word representation. We applied Gaussian\nNaive Bayes, Gradient Boosting, Logistic Regression, Decision Trees, Random\nForests, as well as a combination of CNN and LSTM to classify the polarities of\ntweets. The results of this study indicate that deep learning with ParsBERT\nembedding performs better than machine learning. The CNN-LSTM model had the\nhighest classification accuracy with 89 percent on the first dataset and 71\npercent on the second dataset. Due to the complexity of Persian, it was a\ndifficult task to achieve this level of efficiency. The main objective of our\nresearch was to reduce the training time while maintaining the model's\nperformance. As a result, several adjustments were made to the model\narchitecture and parameters. In addition to achieving the objective, the\nperformance was slightly improved as well.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mohammad Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdanparast_Z/0/1/0/all/0/1\">Zahra Yazdanparast</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications. (arXiv:2307.09162v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09162","description":"<p>Gender bias in artificial intelligence (AI) and natural language processing\nhas garnered significant attention due to its potential impact on societal\nperceptions and biases. This research paper aims to analyze gender bias in\nLarge Language Models (LLMs) with a focus on multiple comparisons between GPT-2\nand GPT-3.5, some prominent language models, to better understand its\nimplications. Through a comprehensive literature review, the study examines\nexisting research on gender bias in AI language models and identifies gaps in\nthe current knowledge. The methodology involves collecting and preprocessing\ndata from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis\ntechniques to evaluate gender bias in the generated text. The findings shed\nlight on gendered word associations, language usage, and biased narratives\npresent in the outputs of these Large Language Models. The discussion explores\nthe ethical implications of gender bias and its potential consequences on\nsocial perceptions and marginalized communities. Additionally, the paper\npresents strategies for reducing gender bias in LLMs, including algorithmic\napproaches and data augmentation techniques. The research highlights the\nimportance of interdisciplinary collaborations and the role of sociological\nstudies in mitigating gender bias in AI models. By addressing these issues, we\ncan pave the way for more inclusive and unbiased AI systems that have a\npositive impact on society.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_V/0/1/0/all/0/1\">Vishesh Thakur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NBIAS: A Natural Language Processing Framework for Bias Identification in Text. (arXiv:2308.01681v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01681","description":"<p>Bias in textual data can lead to skewed interpretations and outcomes when the\ndata is used. These biases could perpetuate stereotypes, discrimination, or\nother forms of unfair treatment. An algorithm trained on biased data may end up\nmaking decisions that disproportionately impact a certain group of people.\nTherefore, it is crucial to detect and remove these biases to ensure the fair\nand ethical use of data. To this end, we develop a comprehensive and robust\nframework NBIAS that consists of four main layers: data, corpus construction,\nmodel development and an evaluation layer. The dataset is constructed by\ncollecting diverse data from various domains, including social media,\nhealthcare, and job hiring portals. As such, we applied a transformer-based\ntoken classification model that is able to identify bias words/ phrases through\na unique named entity BIAS. In the evaluation procedure, we incorporate a blend\nof quantitative and qualitative measures to gauge the effectiveness of our\nmodels. We achieve accuracy improvements ranging from 1% to 8% compared to\nbaselines. We are also able to generate a robust understanding of the model\nfunctioning. The proposed approach is applicable to a variety of biases and\ncontributes to the fair and ethical use of textual data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1\">Muskan Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reji_D/0/1/0/all/0/1\">Deepak John Reji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bashir_S/0/1/0/all/0/1\">Syed Raza Bashir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chen Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach. (arXiv:2308.04645v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04645","description":"<p>Constituency parsing plays a fundamental role in advancing natural language\nprocessing (NLP) tasks. However, training an automatic syntactic analysis\nsystem for ancient languages solely relying on annotated parse data is a\nformidable task due to the inherent challenges in building treebanks for such\nlanguages. It demands extensive linguistic expertise, leading to a scarcity of\navailable resources. To overcome this hurdle, cross-lingual transfer techniques\nwhich require minimal or even no annotated data for low-resource target\nlanguages offer a promising solution. In this study, we focus on building a\nconstituency parser for $\\mathbf{M}$iddle $\\mathbf{H}$igh $\\mathbf{G}$erman\n($\\mathbf{MHG}$) under realistic conditions, where no annotated MHG treebank is\navailable for training. In our approach, we leverage the linguistic continuity\nand structural similarity between MHG and $\\mathbf{M}$odern $\\mathbf{G}$erman\n($\\mathbf{MG}$), along with the abundance of MG treebank resources.\nSpecifically, by employing the $\\mathit{delexicalization}$ method, we train a\nconstituency parser on MG parse datasets and perform cross-lingual transfer to\nMHG parsing. Our delexicalized constituency parser demonstrates remarkable\nperformance on the MHG test set, achieving an F1-score of 67.3%. It outperforms\nthe best zero-shot cross-lingual baseline by a margin of 28.6% points. These\nencouraging results underscore the practicality and potential for automatic\nsyntactic analysis in other ancient languages that face similar challenges as\nMHG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nie_E/0/1/0/all/0/1\">Ercong Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_H/0/1/0/all/0/1\">Helmut Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Document Page Classification: Design, Datasets, and Challenges. (arXiv:2308.12896v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.12896","description":"<p>This paper highlights the need to bring document classification benchmarking\ncloser to real-world applications, both in the nature of data tested ($X$:\nmulti-channel, multi-paged, multi-industry; $Y$: class distributions and label\nset variety) and in classification tasks considered ($f$: multi-page document,\npage stream, and document bundle classification, ...). We identify the lack of\npublic multi-page document classification datasets, formalize different\nclassification tasks arising in application scenarios, and motivate the value\nof targeting efficient multi-page document representations. An experimental\nstudy on proposed multi-page document classification datasets demonstrates that\ncurrent benchmarks have become irrelevant and need to be updated to evaluate\ncomplete documents, as they naturally occur in practice. This reality check\nalso calls for more mature evaluation methodologies, covering calibration\nevaluation, inference complexity (time-memory), and a range of realistic\ndistribution shifts (e.g., born-digital vs. scanning noise, shifting page\norder). Our study ends on a hopeful note by recommending concrete avenues for\nfuture improvements.}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Landeghem_J/0/1/0/all/0/1\">Jordy Van Landeghem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sanket Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1\">Matthew B. Blaschko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies. (arXiv:2308.14120v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.14120","description":"<p>A knowledge gap persists between Machine Learning (ML) developers (e.g., data\nscientists) and practitioners (e.g., clinicians), hampering the full\nutilization of ML for clinical data analysis. We investigated the potential of\nthe chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this\ngap and perform ML analyses efficiently. Real-world clinical datasets and study\ndetails from large trials across various medical specialties were presented to\nchatGPT ADA without specific guidance. ChatGPT ADA autonomously developed\nstate-of-the-art ML models based on the original study's training data to\npredict clinical outcomes such as cancer development, cancer progression,\ndisease complications, or biomarkers such as pathogenic gene sequences.\nStrikingly, these ML models matched or outperformed their published\ncounterparts. We conclude that chatGPT ADA offers a promising avenue to\ndemocratize ML in medicine, making advanced analytics accessible to non-ML\nexperts and promoting broader applications in medical research and practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arasteh_S/0/1/0/all/0/1\">Soroosh Tayebi Arasteh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tianyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotfinia_M/0/1/0/all/0/1\">Mahshad Lotfinia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhl_C/0/1/0/all/0/1\">Christiane Kuhl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kather_J/0/1/0/all/0/1\">Jakob Nikolas Kather</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truhn_D/0/1/0/all/0/1\">Daniel Truhn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nebelung_S/0/1/0/all/0/1\">Sven Nebelung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenges of GPT-3-based Conversational Agents for Healthcare. (arXiv:2308.14641v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.14641","description":"<p>The potential to provide patients with faster information access while\nallowing medical specialists to concentrate on critical tasks makes medical\ndomain dialog agents appealing. However, the integration of large-language\nmodels (LLMs) into these agents presents certain limitations that may result in\nserious consequences. This paper investigates the challenges and risks of using\nGPT-3-based models for medical question-answering (MedQA). We perform several\nevaluations contextualized in terms of standard medical principles. We provide\na procedure for manually designing patient queries to stress-test high-risk\nlimitations of LLMs in MedQA systems. Our analysis reveals that LLMs fail to\nrespond adequately to these queries, generating erroneous medical information,\nunsafe recommendations, and content that may be considered offensive.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lechner_F/0/1/0/all/0/1\">Fabian Lechner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahnala_A/0/1/0/all/0/1\">Allison Lahnala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welch_C/0/1/0/all/0/1\">Charles Welch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flek_L/0/1/0/all/0/1\">Lucie Flek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-08-29T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}