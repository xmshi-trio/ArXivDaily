{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-01T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Deep Learning-based Sentiment Classification: A Comparative Survey. (arXiv:2312.17253v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17253","description":"<p>Recently, Deep Learning (DL) approaches have been applied to solve the\nSentiment Classification (SC) problem, which is a core task in reviews mining\nor Sentiment Analysis (SA). The performances of these approaches are affected\nby different factors. This paper addresses these factors and classifies them\ninto three categories: data preparation based factors, feature representation\nbased factors and the classification techniques based factors. The paper is a\ncomprehensive literature-based survey that compares the performance of more\nthan 100 DL-based SC approaches by using 21 public datasets of reviews given by\ncustomers within three specific application domains (products, movies and\nrestaurants). These 21 datasets have different characteristics\n(balanced/imbalanced, size, etc.) to give a global vision for our study. The\ncomparison explains how the proposed factors quantitatively affect the\nperformance of the studied DL-based SC approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kayed_M/0/1/0/all/0/1\">Mohamed Kayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diaz_Redondo_R/0/1/0/all/0/1\">Rebeca P. D&#xed;az-Redondo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mabrouk_A/0/1/0/all/0/1\">Alhassan Mabrouk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Faithful Model Evaluation for Model-Based Metrics. (arXiv:2312.17254v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17254","description":"<p>Statistical significance testing is used in natural language processing (NLP)\nto determine whether the results of a study or experiment are likely to be due\nto chance or if they reflect a genuine relationship. A key step in significance\ntesting is the estimation of confidence interval which is a function of sample\nvariance. Sample variance calculation is straightforward when evaluating\nagainst ground truth. However, in many cases, a metric model is often used for\nevaluation. For example, to compare toxicity of two large language models, a\ntoxicity classifier is used for evaluation. Existing works usually do not\nconsider the variance change due to metric model errors, which can lead to\nwrong conclusions. In this work, we establish the mathematical foundation of\nsignificance testing for model-based metrics. With experiments on public\nbenchmark datasets and a production system, we show that considering metric\nmodel errors to calculate sample variances for model-based metrics changes the\nconclusions in certain experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Palash Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rahul Gupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Bytes to Biases: Investigating the Cultural Self-Perception of Large Language Models. (arXiv:2312.17256v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17256","description":"<p>Large language models (LLMs) are able to engage in natural-sounding\nconversations with humans, showcasing unprecedented capabilities for\ninformation retrieval and automated decision support. They have disrupted\nhuman-technology interaction and the way businesses operate. However,\ntechnologies based on generative artificial intelligence (GenAI) are known to\nhallucinate, misinform, and display biases introduced by the massive datasets\non which they are trained. Existing research indicates that humans may\nunconsciously internalize these biases, which can persist even after they stop\nusing the programs. This study explores the cultural self-perception of LLMs by\nprompting ChatGPT (OpenAI) and Bard (Google) with value questions derived from\nthe GLOBE project. The findings reveal that their cultural self-perception is\nmost closely aligned with the values of English-speaking countries and\ncountries characterized by sustained economic competitiveness. Recognizing the\ncultural biases of LLMs and understanding how they work is crucial for all\nmembers of society because one does not want the black box of artificial\nintelligence to perpetuate bias in humans, who might, in turn, inadvertently\ncreate and train even more biased algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Messner_W/0/1/0/all/0/1\">Wolfgang Messner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greene_T/0/1/0/all/0/1\">Tatum Greene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matalone_J/0/1/0/all/0/1\">Josephine Matalone</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evolving Large Language Model Assistant with Long-Term Conditional Memory. (arXiv:2312.17257v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17257","description":"<p>With the rapid development of large language models, AI assistants like\nChatGPT have widely entered people's works and lives. In this paper, we present\nan evolving large language model assistant that utilizes verbal long-term\nmemory. It focuses on preserving the knowledge and experience from the history\ndialogue between the user and AI assistant, which can be applied to future\ndialogue for generating a better response. The model generates a set of records\nfor each finished dialogue and stores them in the memory. In later usage, given\na new user input, the model uses it to retrieve its related memory to improve\nthe quality of the response. To find the best form of memory, we explore\ndifferent ways of constructing the memory and propose a new memorizing\nmechanism called conditional memory to solve the problems in previous methods.\nWe also investigate the retrieval and usage of memory in the generation\nprocess. The assistant uses GPT-4 as the backbone and we evaluate it on three\nconstructed test datasets focusing on different abilities required by an AI\nassistant with long-term memory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Ruifeng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zili Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Ziqiang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empowering Working Memory for Large Language Model Agents. (arXiv:2312.17259v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17259","description":"<p>Large language models (LLMs) have achieved impressive linguistic\ncapabilities. However, a key limitation persists in their lack of human-like\nmemory faculties. LLMs exhibit constrained memory retention across sequential\ninteractions, hindering complex reasoning. This paper explores the potential of\napplying cognitive psychology's working memory frameworks, to enhance LLM\narchitecture. The limitations of traditional LLM memory designs are analyzed,\nincluding their isolation of distinct dialog episodes and lack of persistent\nmemory links. To address this, an innovative model is proposed incorporating a\ncentralized Working Memory Hub and Episodic Buffer access to retain memories\nacross episodes. This architecture aims to provide greater continuity for\nnuanced contextual reasoning during intricate tasks and collaborative\nscenarios. While promising, further research is required into optimizing\nepisodic memory encoding, storage, prioritization, retrieval, and security.\nOverall, this paper provides a strategic blueprint for developing LLM agents\nwith more sophisticated, human-like memory capabilities, highlighting memory\nmechanisms as a vital frontier in artificial general intelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Nan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jianchuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiqiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yuzhen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Si Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Ming Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Classification of Teaching Activities from University Lecture Recordings. (arXiv:2312.17262v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17262","description":"<p>The way of understanding online higher education has greatly changed due to\nthe worldwide pandemic situation. Teaching is undertaken remotely, and the\nfaculty incorporate lecture audio recordings as part of the teaching material.\nThis new online teaching-learning setting has largely impacted university\nclasses. While online teaching technology that enriches virtual classrooms has\nbeen abundant over the past two years, the same has not occurred in supporting\nstudents during online learning. {To overcome this limitation, our aim is to\nwork toward enabling students to easily access the piece of the lesson\nrecording in which the teacher explains a theoretical concept, solves an\nexercise, or comments on organizational issues of the course. To that end, we\npresent a multimodal classification algorithm that identifies the type of\nactivity that is being carried out at any time of the lesson by using a\ntransformer-based language model that exploits features from the audio file and\nfrom the automated lecture transcription. The experimental results will show\nthat some academic activities are more easily identifiable with the audio\nsignal while resorting to the text transcription is needed to identify others.\nAll in all, our contribution aims to recognize the academic activities of a\nteacher during a lesson.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sapena_O/0/1/0/all/0/1\">Oscar Sapena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onaindia_E/0/1/0/all/0/1\">Eva Onaindia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TACIT: A Target-Agnostic Feature Disentanglement Framework for Cross-Domain Text Classification. (arXiv:2312.17263v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17263","description":"<p>Cross-domain text classification aims to transfer models from label-rich\nsource domains to label-poor target domains, giving it a wide range of\npractical applications. Many approaches promote cross-domain generalization by\ncapturing domain-invariant features. However, these methods rely on unlabeled\nsamples provided by the target domains, which renders the model ineffective\nwhen the target domain is agnostic. Furthermore, the models are easily\ndisturbed by shortcut learning in the source domain, which also hinders the\nimprovement of domain generalization ability. To solve the aforementioned\nissues, this paper proposes TACIT, a target domain agnostic feature\ndisentanglement framework which adaptively decouples robust and unrobust\nfeatures by Variational Auto-Encoders. Additionally, to encourage the\nseparation of unrobust features from robust features, we design a feature\ndistillation task that compels unrobust features to approximate the output of\nthe teacher. The teacher model is trained with a few easy samples that are easy\nto carry potential unknown shortcuts. Experimental results verify that our\nframework achieves comparable results to state-of-the-art baselines while\nutilizing only source domain data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1\">Rui Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1\">Fausto Giunchiglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingji Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_M/0/1/0/all/0/1\">Mingjie Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hao Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESGReveal: An LLM-based approach for extracting structured data from ESG reports. (arXiv:2312.17264v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17264","description":"<p>ESGReveal is an innovative method proposed for efficiently extracting and\nanalyzing Environmental, Social, and Governance (ESG) data from corporate\nreports, catering to the critical need for reliable ESG information retrieval.\nThis approach utilizes Large Language Models (LLM) enhanced with Retrieval\nAugmented Generation (RAG) techniques. The ESGReveal system includes an ESG\nmetadata module for targeted queries, a preprocessing module for assembling\ndatabases, and an LLM agent for data extraction. Its efficacy was appraised\nusing ESG reports from 166 companies across various sectors listed on the Hong\nKong Stock Exchange in 2022, ensuring comprehensive industry and market\ncapitalization representation. Utilizing ESGReveal unearthed significant\ninsights into ESG reporting with GPT-4, demonstrating an accuracy of 76.9% in\ndata extraction and 83.7% in disclosure analysis, which is an improvement over\nbaseline models. This highlights the framework's capacity to refine ESG data\nanalysis precision. Moreover, it revealed a demand for reinforced ESG\ndisclosures, with environmental and social data disclosures standing at 69.5%\nand 57.2%, respectively, suggesting a pursuit for more corporate transparency.\nWhile current iterations of ESGReveal do not process pictorial information, a\nfunctionality intended for future enhancement, the study calls for continued\nresearch to further develop and compare the analytical capabilities of various\nLLMs. In summary, ESGReveal is a stride forward in ESG data processing,\noffering stakeholders a sophisticated tool to better evaluate and advance\ncorporate sustainability efforts. Its evolution is promising in promoting\ntransparency in corporate reporting and aligning with broader sustainable\ndevelopment aims.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yi Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1\">Mengying Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhongjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhu Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1\">ZongXiong Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zihan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shiming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">HongXiang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Lei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenwen Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17267","description":"<p>Recently, prompt-tuning with pre-trained language models (PLMs) has\ndemonstrated the significantly enhancing ability of relation extraction (RE)\ntasks. However, in low-resource scenarios, where the available training data is\nscarce, previous prompt-based methods may still perform poorly for prompt-based\nrepresentation learning due to a superficial understanding of the relation. To\nthis end, we highlight the importance of learning high-quality relation\nrepresentation in low-resource scenarios for RE, and propose a novel\nprompt-based relation representation method, named MVRE\n(\\underline{M}ulti-\\underline{V}iew \\underline{R}elation\n\\underline{E}xtraction), to better leverage the capacity of PLMs to improve the\nperformance of RE within the low-resource prompt-tuning paradigm. Specifically,\nMVRE decouples each relation into different perspectives to encompass\nmulti-view relation representations for maximizing the likelihood during\nrelation inference. Furthermore, we also design a Global-Local loss and a\nDynamic-Initialization method for better alignment of the multi-view\nrelation-representing virtual words, containing the semantics of relation\nlabels during the optimization learning process and initialization. Extensive\nexperiments on three benchmark datasets show that our method can achieve\nstate-of-the-art in low-resource settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chenghao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1\">Xiaoye Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhenyi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Wenfeng Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Dangyang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Question Answering with Reformulations over Knowledge Graph. (arXiv:2312.17269v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17269","description":"<p>conversational question answering (convQA) over knowledge graphs (KGs)\ninvolves answering multi-turn natural language questions about information\ncontained in a KG. State-of-the-art methods of ConvQA often struggle with\ninexplicit question-answer pairs. These inputs are easy for human beings to\nunderstand given a conversation history, but hard for a machine to interpret,\nwhich can degrade ConvQA performance. To address this problem, we propose a\nreinforcement learning (RL) based model, CornNet, which utilizes question\nreformulations generated by large language models (LLMs) to improve ConvQA\nperformance. CornNet adopts a teacher-student architecture where a teacher\nmodel learns question representations using human writing reformulations, and a\nstudent model to mimic the teacher model's output via reformulations generated\nby LLMs. The learned question representation is then used by an RL model to\nlocate the correct answer in a KG. Extensive experimental results show that\nCornNet outperforms state-of-the-art convQA models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lihui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_B/0/1/0/all/0/1\">Blaine Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Boxin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_H/0/1/0/all/0/1\">Hanghang Tong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PanGu-$\\pi$: Enhancing Language Model Architectures via Nonlinearity Compensation. (arXiv:2312.17276v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17276","description":"<p>The recent trend of large language models (LLMs) is to increase the scale of\nboth model size (\\aka the number of parameters) and dataset to achieve better\ngenerative ability, which is definitely proved by a lot of work such as the\nfamous GPT and Llama. However, large models often involve massive computational\ncosts, and practical applications cannot afford such high prices. However, the\nmethod of constructing a strong model architecture for LLMs is rarely\ndiscussed. We first analyze the state-of-the-art language model architectures\nand observe the feature collapse problem. Based on the theoretical analysis, we\npropose that the nonlinearity is also very important for language models, which\nis usually studied in convolutional neural networks for vision tasks. The\nseries informed activation function is then introduced with tiny calculations\nthat can be ignored, and an augmented shortcut is further used to enhance the\nmodel nonlinearity. We then demonstrate that the proposed approach is\nsignificantly effective for enhancing the model nonlinearity through carefully\ndesigned ablations; thus, we present a new efficient model architecture for\nestablishing modern, namely, PanGu-$\\pi$. Experiments are then conducted using\nthe same dataset and training strategy to compare PanGu-$\\pi$ with\nstate-of-the-art LLMs. The results show that PanGu-$\\pi$-7B can achieve a\ncomparable performance to that of benchmarks with about 10\\% inference\nspeed-up, and PanGu-$\\pi$-1B can achieve state-of-the-art performance in terms\nof accuracy and efficiency. In addition, we have deployed PanGu-$\\pi$-7B in the\nhigh-value domains of finance and law, developing an LLM named YunShan for\npractical application. The results show that YunShan can surpass other models\nwith similar scales on benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yehui Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tianyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kai Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Ying Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xutao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hailin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Z/0/1/0/all/0/1\">Zheyuan Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fangcheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jianyuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Sinan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yinchen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qinghua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Conducting Advanced Text Analytics Information Systems Research. (arXiv:2312.17278v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17278","description":"<p>The exponential growth of digital content has generated massive textual\ndatasets, necessitating advanced analytical approaches. Large Language Models\n(LLMs) have emerged as tools capable of processing and extracting insights from\nmassive unstructured textual datasets. However, how to leverage LLMs for\ntext-based Information Systems (IS) research is currently unclear. To assist IS\nresearch in understanding how to operationalize LLMs, we propose a Text\nAnalytics for Information Systems Research (TAISR) framework. Our proposed\nframework provides detailed recommendations grounded in IS and LLM literature\non how to conduct meaningful text-based IS research. We conducted three case\nstudies in business intelligence using our TAISR framework to demonstrate its\napplication across several IS research contexts. We also outline potential\nchallenges and limitations in adopting LLMs for IS. By offering a systematic\napproach and evidence of its utility, our TAISR framework contributes to future\nIS research streams looking to incorporate powerful LLMs for text analytics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ampel_B/0/1/0/all/0/1\">Benjamin M. Ampel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chi-Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">James Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hsinchun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stateful FastConformer with Cache-based Inference for Streaming Automatic Speech Recognition. (arXiv:2312.17279v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17279","description":"<p>In this paper, we propose an efficient and accurate streaming speech\nrecognition model based on the FastConformer architecture. We adapted the\nFastConformer architecture for streaming applications through: (1) constraining\nboth the look-ahead and past contexts in the encoder, and (2) introducing an\nactivation caching mechanism to enable the non-autoregressive encoder to\noperate autoregressively during inference. The proposed model is thoughtfully\ndesigned in a way to eliminate the accuracy disparity between the train and\ninference time which is common for many streaming models. Furthermore, our\nproposed encoder works with various decoder configurations including\nConnectionist Temporal Classification (CTC) and RNN-Transducer (RNNT) decoders.\nAdditionally, we introduced a hybrid CTC/RNNT architecture which utilizes a\nshared encoder with both a CTC and RNNT decoder to boost the accuracy and save\ncomputation. We evaluate the proposed model on LibriSpeech dataset and a\nmulti-domain large scale dataset and demonstrate that it can achieve better\naccuracy with lower latency and inference time compared to a conventional\nbuffered streaming model baseline. We also showed that training a model with\nmultiple latencies can achieve better accuracy than single latency models while\nit enables us to support multiple latencies with a single model. Our\nexperiments also showed the hybrid architecture would not only speedup the\nconvergence of the CTC decoder but also improves the accuracy of streaming\nmodels compared to single decoder models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noroozi_V/0/1/0/all/0/1\">Vahid Noroozi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Somshubra Majumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ankur Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balam_J/0/1/0/all/0/1\">Jagadeesh Balam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AI Content Self-Detection for Transformer-based Large Language Models. (arXiv:2312.17289v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17289","description":"<p>$ $The usage of generative artificial intelligence (AI) tools based on large\nlanguage models, including ChatGPT, Bard, and Claude, for text generation has\nmany exciting applications with the potential for phenomenal productivity\ngains. One issue is authorship attribution when using AI tools. This is\nespecially important in an academic setting where the inappropriate use of\ngenerative AI tools may hinder student learning or stifle research by creating\na large amount of automatically generated derivative work. Existing plagiarism\ndetection systems can trace the source of submitted text but are not yet\nequipped with methods to accurately detect AI-generated text. This paper\nintroduces the idea of direct origin detection and evaluates whether generative\nAI systems can recognize their output and distinguish it from human-written\ntexts. We argue why current transformer-based models may be able to self-detect\ntheir own generated text and perform a small empirical study using zero-shot\nlearning to investigate if that is the case. Results reveal varying\ncapabilities of AI systems to identify their generated text. Google's Bard\nmodel exhibits the largest capability of self-detection with an accuracy of\n94\\%, followed by OpenAI's ChatGPT with 83\\%. On the other hand, Anthropic's\nClaude model seems to be not able to self-detect.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Caiado_A/0/1/0/all/0/1\">Ant&#xf4;nio Junior Alves Caiado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahsler_M/0/1/0/all/0/1\">Michael Hahsler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effect of dimensionality change on the bias of word embeddings. (arXiv:2312.17292v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17292","description":"<p>Word embedding methods (WEMs) are extensively used for representing text\ndata. The dimensionality of these embeddings varies across various tasks and\nimplementations. The effect of dimensionality change on the accuracy of the\ndownstream task is a well-explored question. However, how the dimensionality\nchange affects the bias of word embeddings needs to be investigated. Using the\nEnglish Wikipedia corpus, we study this effect for two static (Word2Vec and\nfastText) and two context-sensitive (ElMo and BERT) WEMs. We have two\nobservations. First, there is a significant variation in the bias of word\nembeddings with the dimensionality change. Second, there is no uniformity in\nhow the dimensionality change affects the bias of word embeddings. These\nfactors should be considered while selecting the dimensionality of word\nembeddings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rai_R/0/1/0/all/0/1\">Rohit Raj Rai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awekar_A/0/1/0/all/0/1\">Amit Awekar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing watermarks for large language models. (arXiv:2312.17295v1 [cs.CR])","link":"http://arxiv.org/abs/2312.17295","description":"<p>With the rise of large language models (LLMs) and concerns about potential\nmisuse, watermarks for generative LLMs have recently attracted much attention.\nAn important aspect of such watermarks is the trade-off between their\nidentifiability and their impact on the quality of the generated text. This\npaper introduces a systematic approach to this trade-off in terms of a\nmulti-objective optimization problem. For a large class of robust, efficient\nwatermarks, the associated Pareto optimal solutions are identified and shown to\noutperform the currently default watermark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wouters_B/0/1/0/all/0/1\">Bram Wouters</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structured Packing in LLM Training Improves Long Context Utilization. (arXiv:2312.17296v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17296","description":"<p>Recent advances in long-context Large Language Models (LCLMs) have generated\nsignificant interest, especially in applications such as querying scientific\nresearch papers. However, their potential is often limited by inadequate\ncontext utilization. We identify the absence of long-range semantic\ndependencies in typical training data as a primary hindrance. To address this,\nwe delve into the benefits of frequently incorporating related documents into\ntraining inputs. Using the inherent directory structure of code data as a\nsource of training examples, we demonstrate improvements in perplexity, even\nfor tasks unrelated to coding. Building on these findings, but with a broader\nfocus, we introduce Structured Packing for Long Context (SPLiCe). SPLiCe is an\ninnovative method for creating training examples by using a retrieval method to\ncollate the most mutually relevant documents into a single training context.\nOur results indicate that \\method{} enhances model performance and can be used\nto train large models to utilize long contexts better. We validate our results\nby training a large $3$B model, showing both perplexity improvements and better\nlong-context performance on downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Staniszewski_K/0/1/0/all/0/1\">Konrad Staniszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tworkowski_S/0/1/0/all/0/1\">Szymon Tworkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaszczur_S/0/1/0/all/0/1\">Sebastian Jaszczur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1\">Henryk Michalewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kucinski_L/0/1/0/all/0/1\">&#x141;ukasz Kuci&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milos_P/0/1/0/all/0/1\">Piotr Mi&#x142;o&#x15b;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Nature: Datasets and Models for Analyzing Nature-Related Disclosures. (arXiv:2312.17337v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17337","description":"<p>Nature is an amorphous concept. Yet, it is essential for the planet's\nwell-being to understand how the economy interacts with it. To address the\ngrowing demand for information on corporate nature disclosure, we provide\ndatasets and classifiers to detect nature communication by companies. We ground\nour approach in the guidelines of the Taskforce on Nature-related Financial\nDisclosures (TNFD). Particularly, we focus on the specific dimensions of water,\nforest, and biodiversity. For each dimension, we create an expert-annotated\ndataset with 2,200 text samples and train classifier models. Furthermore, we\nshow that nature communication is more prevalent in hotspot areas and directly\neffected industries like agriculture and utilities. Our approach is the first\nto respond to calls to assess corporate nature communication on a large scale.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schimanski_T/0/1/0/all/0/1\">Tobias Schimanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senni_C/0/1/0/all/0/1\">Chiara Colesanti Senni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gostlow_G/0/1/0/all/0/1\">Glen Gostlow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jingwei Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tingyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leippold_M/0/1/0/all/0/1\">Markus Leippold</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SentinelLMs: Encrypted Input Adaptation and Fine-tuning of Language Models for Private and Secure Inference. (arXiv:2312.17342v1 [cs.CR])","link":"http://arxiv.org/abs/2312.17342","description":"<p>This paper addresses the privacy and security concerns associated with deep\nneural language models, which serve as crucial components in various modern\nAI-based applications. These models are often used after being pre-trained and\nfine-tuned for specific tasks, with deployment on servers accessed through the\ninternet. However, this introduces two fundamental risks: (a) the transmission\nof user inputs to the server via the network gives rise to interception\nvulnerabilities, and (b) privacy concerns emerge as organizations that deploy\nsuch models store user data with restricted context. To address this, we\npropose a novel method to adapt and fine-tune transformer-based language models\non passkey-encrypted user-specific text. The original pre-trained language\nmodel first undergoes a quick adaptation (without any further pre-training)\nwith a series of irreversible transformations applied to the tokenizer and\ntoken embeddings. This enables the model to perform inference on encrypted\ninputs while preventing reverse engineering of text from model parameters and\nintermediate outputs. After adaptation, models are fine-tuned on encrypted\nversions of existing training datasets. Experimental evaluation employing\nadapted versions of renowned models (e.g., BERT, RoBERTa) across established\nbenchmark English and multilingual datasets for text classification and\nsequence labeling shows that encrypted models achieve performance parity with\ntheir original counterparts. This serves to safeguard performance, privacy, and\nsecurity cohesively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Abhijit Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingda Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deo_S/0/1/0/all/0/1\">Soham Deo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AQUALLM: Audio Question Answering Data Generation Using Large Language Models. (arXiv:2312.17343v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17343","description":"<p>Audio Question Answering (AQA) constitutes a pivotal task in which machines\nanalyze both audio signals and natural language questions to produce precise\nnatural language answers. The significance of possessing high-quality, diverse,\nand extensive AQA datasets cannot be overstated when aiming for the precision\nof an AQA system. While there has been notable focus on developing accurate and\nefficient AQA models, the creation of high-quality, diverse, and extensive\ndatasets for the specific task at hand has not garnered considerable attention.\nTo address this challenge, this work makes several contributions. We introduce\na scalable AQA data generation pipeline, denoted as the AQUALLM framework,\nwhich relies on Large Language Models (LLMs). This framework utilizes existing\naudio-caption annotations and incorporates state-of-the-art LLMs to generate\nexpansive, high-quality AQA datasets. Additionally, we present three extensive\nand high-quality benchmark datasets for AQA, contributing significantly to the\nprogression of AQA research. AQA models trained on the proposed datasets set\nsuperior benchmarks compared to the existing state-of-the-art. Moreover, models\ntrained on our datasets demonstrate enhanced generalizability when compared to\nmodels trained using human-annotated AQA data. Code and datasets will be\naccessible on GitHub~\\footnote{\\url{https://github.com/swarupbehera/AQUALLM}}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Behera_S/0/1/0/all/0/1\">Swarup Ranjan Behera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Injeti_K/0/1/0/all/0/1\">Krishna Mohan Injeti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patibandla_J/0/1/0/all/0/1\">Jaya Sai Kiran Patibandla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pokala_P/0/1/0/all/0/1\">Praveen Kumar Pokala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pailla_B/0/1/0/all/0/1\">Balakrishna Reddy Pailla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Model as an Annotator: Unsupervised Context-aware Quality Phrase Generation. (arXiv:2312.17349v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17349","description":"<p>Phrase mining is a fundamental text mining task that aims to identify quality\nphrases from context. Nevertheless, the scarcity of extensive gold labels\ndatasets, demanding substantial annotation efforts from experts, renders this\ntask exceptionally challenging. Furthermore, the emerging, infrequent, and\ndomain-specific nature of quality phrases presents further challenges in\ndealing with this task. In this paper, we propose LMPhrase, a novel\nunsupervised context-aware quality phrase mining framework built upon large\npre-trained language models (LMs). Specifically, we first mine quality phrases\nas silver labels by employing a parameter-free probing technique called\nPerturbed Masking on the pre-trained language model BERT (coined as Annotator).\nIn contrast to typical statistic-based or distantly-supervised methods, our\nsilver labels, derived from large pre-trained language models, take into\naccount rich contextual information contained in the LMs. As a result, they\nbring distinct advantages in preserving informativeness, concordance, and\ncompleteness of quality phrases. Secondly, training a discriminative span\nprediction model heavily relies on massive annotated data and is likely to face\nthe risk of overfitting silver labels. Alternatively, we formalize phrase\ntagging task as the sequence generation problem by directly fine-tuning on the\nSequence-to-Sequence pre-trained language model BART with silver labels (coined\nas Generator). Finally, we merge the quality phrases from both the Annotator\nand Generator as the final predictions, considering their complementary nature\nand distinct characteristics. Extensive experiments show that our LMPhrase\nconsistently outperforms all the existing competitors across two different\ngranularity phrase mining tasks, where each task is tested on two different\ndomain datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_Y/0/1/0/all/0/1\">Yuan Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junjie Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Commonsense for Zero-Shot Natural Language Video Localization. (arXiv:2312.17429v1 [cs.CV])","link":"http://arxiv.org/abs/2312.17429","description":"<p>Zero-shot Natural Language-Video Localization (NLVL) methods have exhibited\npromising results in training NLVL models exclusively with raw video data by\ndynamically generating video segments and pseudo-query annotations. However,\nexisting pseudo-queries often lack grounding in the source video, resulting in\nunstructured and disjointed content. In this paper, we investigate the\neffectiveness of commonsense reasoning in zero-shot NLVL. Specifically, we\npresent CORONET, a zero-shot NLVL framework that leverages commonsense to\nbridge the gap between videos and generated pseudo-queries via a commonsense\nenhancement module. CORONET employs Graph Convolution Networks (GCN) to encode\ncommonsense information extracted from a knowledge graph, conditioned on the\nvideo, and cross-attention mechanisms to enhance the encoded video and\npseudo-query representations prior to localization. Through empirical\nevaluations on two benchmark datasets, we demonstrate that CORONET surpasses\nboth zero-shot and weakly supervised baselines, achieving improvements up to\n32.13% across various recall thresholds and up to 6.33% in mIoU. These results\nunderscore the significance of leveraging commonsense reasoning for zero-shot\nNLVL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holla_M/0/1/0/all/0/1\">Meghana Holla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lourentzou_I/0/1/0/all/0/1\">Ismini Lourentzou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Video Understanding with Large Language Models: A Survey. (arXiv:2312.17432v1 [cs.CV])","link":"http://arxiv.org/abs/2312.17432","description":"<p>With the burgeoning growth of online video platforms and the escalating\nvolume of video content, the demand for proficient video understanding tools\nhas intensified markedly. With Large Language Models (LLMs) showcasing\nremarkable capabilities in key language tasks, this survey provides a detailed\noverview of the recent advancements in video understanding harnessing the power\nof LLMs (Vid-LLMs). The emergent capabilities of Vid-LLMs are surprisingly\nadvanced, particularly their ability for open-ended spatial-temporal reasoning\ncombined with commonsense knowledge, suggesting a promising path for future\nvideo understanding. We examine the unique characteristics and capabilities of\nVid-LLMs, categorizing the approaches into four main types: LLM-based Video\nAgents, Vid-LLMs Pretraining, Vid-LLMs Instruction Tuning, and Hybrid Methods.\nFurthermore, this survey also presents a comprehensive study of the tasks and\ndatasets for Vid-LLMs, along with the methodologies employed for evaluation.\nAdditionally, the survey explores the expansive applications of Vid-LLMs across\nvarious domains, thereby showcasing their remarkable scalability and\nversatility in addressing challenges in real-world video understanding.\nFinally, the survey summarizes the limitations of existing Vid-LLMs and the\ndirections for future research. For more information, we recommend readers\nvisit the repository at\nhttps://github.com/yunlong10/Awesome-LLMs-for-Video-Understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yunlong Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_J/0/1/0/all/0/1\">Jing Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Siting Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Luchuan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Susan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Teng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Daoan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_J/0/1/0/all/0/1\">Jie An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jingyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rongyi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vosoughi_A/0/1/0/all/0/1\">Ali Vosoughi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1\">Feng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiebo Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chenliang Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EHR Interaction Between Patients and AI: NoteAid EHR Interaction. (arXiv:2312.17475v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17475","description":"<p>With the rapid advancement of Large Language Models (LLMs) and their\noutstanding performance in semantic and contextual comprehension, the potential\nof LLMs in specialized domains warrants exploration. This paper introduces the\nNoteAid EHR Interaction Pipeline, an innovative approach developed using\ngenerative LLMs to assist in patient education, a task stemming from the need\nto aid patients in understanding Electronic Health Records (EHRs). Building\nupon the NoteAid work, we designed two novel tasks from the patient's\nperspective: providing explanations for EHR content that patients may not\nunderstand and answering questions posed by patients after reading their EHRs.\nWe extracted datasets containing 10,000 instances from MIMIC Discharge\nSummaries and 876 instances from the MADE medical notes collection,\nrespectively, executing the two tasks through the NoteAid EHR Interaction\nPipeline with these data. Performance data of LLMs on these tasks were\ncollected and constructed as the corresponding NoteAid EHR Interaction Dataset.\nThrough a comprehensive evaluation of the entire dataset using LLM assessment\nand a rigorous manual evaluation of 64 instances, we showcase the potential of\nLLMs in patient education. Besides, the results provide valuable data support\nfor future exploration and applications in this domain while also supplying\nhigh-quality synthetic datasets for in-house system training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaocheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variation and Hyperparameters. (arXiv:2312.17476v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17476","description":"<p>The advancement of Large Language Models (LLMs) has led to their widespread\nuse across a broad spectrum of tasks including decision making. Prior studies\nhave compared the decision making abilities of LLMs with those of humans from a\npsychological perspective. However, these studies have not always properly\naccounted for the sensitivity of LLMs' behavior to hyperparameters and\nvariations in the prompt. In this study, we examine LLMs' performance on the\nHorizon decision making task studied by Binz and Schulz (2023) analyzing how\nLLMs respond to variations in prompts and hyperparameters. By experimenting on\nthree OpenAI language models possessing different capabilities, we observe that\nthe decision making abilities fluctuate based on the input prompts and\ntemperature settings. Contrary to previous findings language models display a\nhuman-like exploration exploitation tradeoff after simple adjustments to the\nprompt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loya_M/0/1/0/all/0/1\">Manikanta Loya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_D/0/1/0/all/0/1\">Divya Anand Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futrell_R/0/1/0/all/0/1\">Richard Futrell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MosaicBERT: A Bidirectional Encoder Optimized for Fast Pretraining. (arXiv:2312.17482v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17482","description":"<p>Although BERT-style encoder models are heavily used in NLP research, many\nresearchers do not pretrain their own BERTs from scratch due to the high cost\nof training. In the past half-decade since BERT first rose to prominence, many\nadvances have been made with other transformer architectures and training\nconfigurations that have yet to be systematically incorporated into BERT. Here,\nwe introduce MosaicBERT, a BERT-style encoder architecture and training recipe\nthat is empirically optimized for fast pretraining. This efficient architecture\nincorporates FlashAttention, Attention with Linear Biases (ALiBi), Gated Linear\nUnits (GLU), a module to dynamically remove padded tokens, and low precision\nLayerNorm into the classic transformer encoder block. The training recipe\nincludes a 30% masking ratio for the Masked Language Modeling (MLM) objective,\nbfloat16 precision, and vocabulary size optimized for GPU throughput, in\naddition to best-practices from RoBERTa and other encoder models. When\npretrained from scratch on the C4 dataset, this base model achieves a\ndownstream average GLUE (dev) score of 79.6 in 1.13 hours on 8 A100 80 GB GPUs\nat a cost of roughly $20. We plot extensive accuracy vs. pretraining speed\nPareto curves and show that MosaicBERT base and large are consistently Pareto\noptimal when compared to a competitive BERT base and large. This empirical\nspeed up in pretraining enables researchers and engineers to pretrain custom\nBERT-style models at low cost instead of finetune on existing generic models.\nWe open source our model weights and code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Portes_J/0/1/0/all/0/1\">Jacob Portes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trott_A/0/1/0/all/0/1\">Alex Trott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havens_S/0/1/0/all/0/1\">Sam Havens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_D/0/1/0/all/0/1\">Daniel King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venigalla_A/0/1/0/all/0/1\">Abhinav Venigalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadeem_M/0/1/0/all/0/1\">Moin Nadeem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sardana_N/0/1/0/all/0/1\">Nikhil Sardana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khudia_D/0/1/0/all/0/1\">Daya Khudia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1\">Jonathan Frankle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Truth Forest: Toward Multi-Scale Truthfulness in Large Language Models through Intervention without Tuning. (arXiv:2312.17484v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17484","description":"<p>Despite the great success of large language models (LLMs) in various tasks,\nthey suffer from generating hallucinations. We introduce Truth Forest, a method\nthat enhances truthfulness in LLMs by uncovering hidden truth representations\nusing multi-dimensional orthogonal probes. Specifically, it creates multiple\northogonal bases for modeling truth by incorporating orthogonal constraints\ninto the probes. Moreover, we introduce Random Peek, a systematic technique\nconsidering an extended range of positions within the sequence, reducing the\ngap between discerning and generating truth features in LLMs. By employing this\napproach, we improved the truthfulness of Llama-2-7B from 40.8\\% to 74.5\\% on\nTruthfulQA. Likewise, significant improvements are observed in fine-tuned\nmodels. We conducted a thorough analysis of truth features using probes. Our\nvisualization results show that orthogonal probes capture complementary\ntruth-related features, forming well-defined clusters that reveal the inherent\nstructure of the dataset. Code: \\url{https://github.com/jongjyh/trfr}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhongzhi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xingwu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_X/0/1/0/all/0/1\">Xianfeng Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_F/0/1/0/all/0/1\">Fengzong Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Z/0/1/0/all/0/1\">Zhanhui Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Cheng-Zhong Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Open-Vocabulary Diffusion to Camouflaged Instance Segmentation. (arXiv:2312.17505v1 [cs.CV])","link":"http://arxiv.org/abs/2312.17505","description":"<p>Text-to-image diffusion techniques have shown exceptional capability of\nproducing high-quality images from text descriptions. This indicates that there\nexists a strong correlation between the visual and textual domains. In\naddition, text-image discriminative models such as CLIP excel in image\nlabelling from text prompts, thanks to the rich and diverse information\navailable from open concepts. In this paper, we leverage these technical\nadvances to solve a challenging problem in computer vision: camouflaged\ninstance segmentation. Specifically, we propose a method built upon a\nstate-of-the-art diffusion model, empowered by open-vocabulary to learn\nmulti-scale textual-visual features for camouflaged object representations.\nSuch cross-domain representations are desirable in segmenting camouflaged\nobjects where visual cues are subtle to distinguish the objects from the\nbackground, especially in segmenting novel objects which are not seen in\ntraining. We also develop technically supportive components to effectively fuse\ncross-domain features and engage relevant features towards respective\nforeground objects. We validate our method and compare it with existing ones on\nseveral benchmark datasets of camouflaged instance segmentation and generic\nopen-vocabulary instance segmentation. Experimental results confirm the\nadvances of our method over existing ones. We will publish our code and\npre-trained models to support future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Tuan-Anh Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Duc Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_B/0/1/0/all/0/1\">Binh-Son Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_N/0/1/0/all/0/1\">Nhat Minh Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor W. Tsang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1\">Sai-Kit Yeung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in the Avalon Game. (arXiv:2312.17515v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17515","description":"<p>Multi-agent collaboration with Large Language Models (LLMs) demonstrates\nproficiency in basic tasks, yet its efficiency in more complex scenarios\nremains unexplored. In gaming environments, these agents often face situations\nwithout established coordination protocols, requiring them to make intelligent\ninferences about teammates from limited data. This problem motivates the area\nof ad hoc teamwork, in which an agent may potentially cooperate with a variety\nof teammates to achieve a shared goal. Our study focuses on the ad hoc teamwork\nproblem where the agent operates in an environment driven by natural language.\nOur findings reveal the potential of LLM agents in team collaboration,\nhighlighting issues related to hallucinations in communication. To address this\nissue, we develop CodeAct, a general agent that equips LLM with enhanced memory\nand code-driven reasoning, enabling the repurposing of partial information for\nrapid adaptation to new teammates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zijing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shunfeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shilong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yali Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overview of the PromptCBLUE Shared Task in CHIP2023. (arXiv:2312.17522v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17522","description":"<p>This paper presents an overview of the PromptCBLUE shared task\n(<a href=\"http://cips-chip.org.cn/2023/eval1\">this http URL</a>) held in the CHIP-2023 Conference. This\nshared task reformualtes the CBLUE benchmark, and provide a good testbed for\nChinese open-domain or medical-domain large language models (LLMs) in general\nmedical natural language processing. Two different tracks are held: (a) prompt\ntuning track, investigating the multitask prompt tuning of LLMs, (b) probing\nthe in-context learning capabilities of open-sourced LLMs. Many teams from both\nthe industry and academia participated in the shared tasks, and the top teams\nachieved amazing test results. This paper describes the tasks, the datasets,\nevaluation metrics, and the top systems for both tasks. Finally, the paper\nsummarizes the techniques and results of the evaluation of the various\napproaches explored by the participating teams.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mosha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Buzhou Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Quantitative Reasoning Skills of Large Language Models through Dimension Perception. (arXiv:2312.17532v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17532","description":"<p>Quantities are distinct and critical components of texts that characterize\nthe magnitude properties of entities, providing a precise perspective for the\nunderstanding of natural language, especially for reasoning tasks. In recent\nyears, there has been a flurry of research on reasoning tasks based on large\nlanguage models (LLMs), most of which solely focus on numerical values,\nneglecting the dimensional concept of quantities with units despite its\nimportance. We argue that the concept of dimension is essential for precisely\nunderstanding quantities and of great significance for LLMs to perform\nquantitative reasoning. However, the lack of dimension knowledge and\nquantity-related benchmarks has resulted in low performance of LLMs. Hence, we\npresent a framework to enhance the quantitative reasoning ability of language\nmodels based on dimension perception. We first construct a dimensional unit\nknowledge base (DimUnitKB) to address the knowledge gap in this area. We\npropose a benchmark DimEval consisting of seven tasks of three categories to\nprobe and enhance the dimension perception skills of LLMs. To evaluate the\neffectiveness of our methods, we propose a quantitative reasoning task and\nconduct experiments. The experimental results show that our dimension\nperception method dramatically improves accuracy (43.55%-&gt;50.67%) on\nquantitative reasoning tasks compared to GPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuncheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Sihang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunwen Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of LLMs. (arXiv:2312.17535v1 [cs.AI])","link":"http://arxiv.org/abs/2312.17535","description":"<p>CoT (Chain-of-Thought) is a way to solve reasoning problems for LLMs .\nRecently, many researches appear for improving the CoT capability of LLMs. In\nthis work, we also proposed Olapa-MCoT, which is a LLMs based on llama2-13B PLM\nfor finetuning and alignment learning. During the alignment training, we\nproposed the SimRRHF algorithm and Incorrect Data Relearning and mainly focused\non optimizing the Chinese mathematical reasoning ability of Olapa-MCoT. The\nexperiment achieved significant results, with the accuracy of Chinese\nmathematical reasoning up to 50%, 36% rise compared to llama2-13B. In addition,\nthe accuracy of English reasoning ability also increased by nearly 4%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shaojie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaobin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_C/0/1/0/all/0/1\">Chengxiang Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Bo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Building Efficient Universal Classifiers with Natural Language Inference. (arXiv:2312.17543v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17543","description":"<p>Generative Large Language Models (LLMs) have become the mainstream choice for\nfewshot and zeroshot learning thanks to the universality of text generation.\nMany users, however, do not need the broad capabilities of generative LLMs when\nthey only want to automate a classification task. Smaller BERT-like models can\nalso learn universal tasks, which allow them to do any text classification task\nwithout requiring fine-tuning (zeroshot classification) or to learn new tasks\nwith only a few examples (fewshot), while being significantly more efficient\nthan generative LLMs. This paper (1) explains how Natural Language Inference\n(NLI) can be used as a universal classification task that follows similar\nprinciples as instruction fine-tuning of generative LLMs, (2) provides a\nstep-by-step guide with reusable Jupyter notebooks for building a universal\nclassifier, and (3) shares the resulting universal classifier that is trained\non 33 datasets with 389 diverse classes. Parts of the code we share has been\nused to train our older zeroshot classifiers that have been downloaded more\nthan 55 million times via the Hugging Face Hub as of December 2023. Our new\nclassifier improves zeroshot performance by 9.4%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Laurer_M/0/1/0/all/0/1\">Moritz Laurer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atteveldt_W/0/1/0/all/0/1\">Wouter van Atteveldt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casas_A/0/1/0/all/0/1\">Andreu Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welbers_K/0/1/0/all/0/1\">Kasper Welbers</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Action-Item-Driven Summarization of Long Meeting Transcripts. (arXiv:2312.17581v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17581","description":"<p>The increased prevalence of online meetings has significantly enhanced the\npracticality of a model that can automatically generate the summary of a given\nmeeting. This paper introduces a novel and effective approach to automate the\ngeneration of meeting summaries. Current approaches to this problem generate\ngeneral and basic summaries, considering the meeting simply as a long dialogue.\nHowever, our novel algorithms can generate abstractive meeting summaries that\nare driven by the action items contained in the meeting transcript. This is\ndone by recursively generating summaries and employing our action-item\nextraction algorithm for each section of the meeting in parallel. All of these\nsectional summaries are then combined and summarized together to create a\ncoherent and action-item-driven summary. In addition, this paper introduces\nthree novel methods for dividing up long transcripts into topic-based sections\nto improve the time efficiency of our algorithm, as well as to resolve the\nissue of large language models (LLMs) forgetting long-term dependencies. Our\npipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an\napproximately 4.98% increase from the current state-of-the-art result produced\nby a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Golia_L/0/1/0/all/0/1\">Logan Golia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Faithful Explanations for Text Classification with Robustness Improvement and Explanation Guided Training. (arXiv:2312.17591v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17591","description":"<p>Feature attribution methods highlight the important input tokens as\nexplanations to model predictions, which have been widely applied to deep\nneural networks towards trustworthy AI. However, recent works show that\nexplanations provided by these methods face challenges of being faithful and\nrobust. In this paper, we propose a method with Robustness improvement and\nExplanation Guided training towards more faithful EXplanations (REGEX) for text\nclassification. First, we improve model robustness by input gradient\nregularization technique and virtual adversarial training. Secondly, we use\nsalient ranking to mask noisy tokens and maximize the similarity between model\nattention and feature attribution, which can be seen as a self-training\nprocedure without importing other external information. We conduct extensive\nexperiments on six datasets with five attribution methods, and also evaluate\nthe faithfulness in the out-of-domain setting. The results show that REGEX\nimproves fidelity metrics of explanations in all settings and further achieves\nconsistent gains based on two randomization tests. Moreover, we show that using\nhighlight explanations produced by REGEX to train select-then-predict models\nresults in comparable task performance to the end-to-end method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongfang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Generative Information Extraction: A Survey. (arXiv:2312.17617v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17617","description":"<p>Information extraction (IE) aims to extract structural knowledge (such as\nentities, relations, and events) from plain natural language texts. Recently,\ngenerative Large Language Models (LLMs) have demonstrated remarkable\ncapabilities in text understanding and generation, allowing for generalization\nacross various domains and tasks. As a result, numerous works have been\nproposed to harness abilities of LLMs and offer viable solutions for IE tasks\nbased on a generative paradigm. To conduct a comprehensive systematic review\nand exploration of LLM efforts for IE tasks, in this study, we survey the most\nrecent advancements in this field. We first present an extensive overview by\ncategorizing these works in terms of various IE subtasks and learning\nparadigms, then we empirically analyze the most advanced methods and discover\nthe emerging trend of IE tasks with LLMs. Based on thorough review conducted,\nwe identify several insights in technique and promising research directions\nthat deserve further exploration in future studies. We maintain a public\nrepository and consistently update related resources at:\n\\url{https://github.com/quqxui/Awesome-LLM4IE-Papers}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Derong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wenjun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1\">Enhong Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Research on the Laws of Multimodal Perception and Cognition from a Cross-cultural Perspective -- Taking Overseas Chinese Gardens as an Example. (arXiv:2312.17642v1 [cs.AI])","link":"http://arxiv.org/abs/2312.17642","description":"<p>This study aims to explore the complex relationship between perceptual and\ncognitive interactions in multimodal data analysis,with a specific emphasis on\nspatial experience design in overseas Chinese gardens. It is found that\nevaluation content and images on social media can reflect individuals' concerns\nand sentiment responses, providing a rich data base for cognitive research that\ncontains both sentimental and image-based cognitive information. Leveraging\ndeep learning techniques, we analyze textual and visual data from social media,\nthereby unveiling the relationship between people's perceptions and sentiment\ncognition within the context of overseas Chinese gardens. In addition, our\nstudy introduces a multi-agent system (MAS)alongside AI agents. Each agent\nexplores the laws of aesthetic cognition through chat scene simulation combined\nwith web search. This study goes beyond the traditional approach of translating\nperceptions into sentiment scores, allowing for an extension of the research\nmethodology in terms of directly analyzing texts and digging deeper into\nopinion data. This study provides new perspectives for understanding aesthetic\nexperience and its impact on architecture and landscape design across diverse\ncultural contexts, which is an essential contribution to the field of cultural\ncommunication and aesthetic understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1\">Ran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1\">Xueqi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yijun Mao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Normalization of Lithuanian Text Using Regular Expressions. (arXiv:2312.17660v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17660","description":"<p>Text Normalization is an integral part of any text-to-speech synthesis\nsystem. In a natural language text, there are elements such as numbers, dates,\nabbreviations, etc. that belong to other semiotic classes. They are called\nnon-standard words (NSW) and need to be expanded into ordinary words. For this\npurpose, it is necessary to identify the semiotic class of each NSW. The\ntaxonomy of semiotic classes adapted to the Lithuanian language is presented in\nthe work. Sets of rules are created for detecting and expanding NSWs based on\nregular expressions. Experiments with three completely different data sets were\nperformed and the accuracy was assessed. Causes of errors are explained and\nrecommendations are given for the development of text normalization rules.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kasparaitis_P/0/1/0/all/0/1\">Pijus Kasparaitis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gemini in Reasoning: Unveiling Commonsense in Multimodal Large Language Models. (arXiv:2312.17661v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17661","description":"<p>The burgeoning interest in Multimodal Large Language Models (MLLMs), such as\nOpenAI's GPT-4V(ision), has significantly impacted both academic and industrial\nrealms. These models enhance Large Language Models (LLMs) with advanced visual\nunderstanding capabilities, facilitating their application in a variety of\nmultimodal tasks. Recently, Google introduced Gemini, a cutting-edge MLLM\ndesigned specifically for multimodal integration. Despite its advancements,\npreliminary benchmarks indicate that Gemini lags behind GPT models in\ncommonsense reasoning tasks. However, this assessment, based on a limited\ndataset (i.e., HellaSWAG), does not fully capture Gemini's authentic\ncommonsense reasoning potential. To address this gap, our study undertakes a\nthorough evaluation of Gemini's performance in complex reasoning tasks that\nnecessitate the integration of commonsense knowledge across modalities. We\ncarry out a comprehensive analysis of 12 commonsense reasoning datasets,\nranging from general to domain-specific tasks. This includes 11 datasets\nfocused solely on language, as well as one that incorporates multimodal\nelements. Our experiments across four LLMs and two MLLMs demonstrate Gemini's\ncompetitive commonsense reasoning capabilities. Additionally, we identify\ncommon challenges faced by current LLMs and MLLMs in addressing commonsense\nproblems, underscoring the need for further advancements in enhancing the\ncommonsense reasoning abilities of these models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jatmo: Prompt Injection Defense by Task-Specific Finetuning. (arXiv:2312.17673v1 [cs.CR])","link":"http://arxiv.org/abs/2312.17673","description":"<p>Large Language Models (LLMs) are attracting significant research attention\ndue to their instruction-following abilities, allowing users and developers to\nleverage LLMs for a variety of tasks. However, LLMs are vulnerable to\nprompt-injection attacks: a class of attacks that hijack the model's\ninstruction-following abilities, changing responses to prompts to undesired,\npossibly malicious ones. In this work, we introduce Jatmo, a method for\ngenerating task-specific models resilient to prompt-injection attacks. Jatmo\nleverages the fact that LLMs can only follow instructions once they have\nundergone instruction tuning. It harnesses a teacher instruction-tuned model to\ngenerate a task-specific dataset, which is then used to fine-tune a base model\n(i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a\ndataset of inputs for the task: it uses the teacher model to generate outputs.\nFor situations with no pre-existing datasets, Jatmo can use a single example,\nor in some cases none at all, to produce a fully synthetic dataset. Our\nexperiments on six tasks show that Jatmo models provide the same quality of\noutputs on their specific task as standard LLMs, while being resilient to\nprompt injections. The best attacks succeeded in less than 0.5% of cases\nagainst our models, versus over 90% success rate against GPT-3.5-Turbo. We\nrelease Jatmo at https://github.com/wagner-group/prompt-injection-defense.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Piet_J/0/1/0/all/0/1\">Julien Piet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alrashed_M/0/1/0/all/0/1\">Maha Alrashed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitawarin_C/0/1/0/all/0/1\">Chawin Sitawarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sizhe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zeming Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1\">Elizabeth Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alomair_B/0/1/0/all/0/1\">Basel Alomair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1\">David Wagner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TuPy-E: detecting hate speech in Brazilian Portuguese social media with a novel dataset and comprehensive analysis of models. (arXiv:2312.17704v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17704","description":"<p>Social media has become integral to human interaction, providing a platform\nfor communication and expression. However, the rise of hate speech on these\nplatforms poses significant risks to individuals and communities. Detecting and\naddressing hate speech is particularly challenging in languages like Portuguese\ndue to its rich vocabulary, complex grammar, and regional variations. To\naddress this, we introduce TuPy-E, the largest annotated Portuguese corpus for\nhate speech detection. TuPy-E leverages an open-source approach, fostering\ncollaboration within the research community. We conduct a detailed analysis\nusing advanced techniques like BERT models, contributing to both academic\nunderstanding and practical applications\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_F/0/1/0/all/0/1\">Felipe Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_V/0/1/0/all/0/1\">Victoria Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebecken_N/0/1/0/all/0/1\">Nelson Ebecken</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Principled Gradient-based Markov Chain Monte Carlo for Text Generation. (arXiv:2312.17710v1 [cs.CL])","link":"http://arxiv.org/abs/2312.17710","description":"<p>Recent papers have demonstrated the possibility of energy-based text\ngeneration by adapting gradient-based sampling algorithms, a paradigm of MCMC\nalgorithms that promises fast convergence. However, as we show in this paper,\nprevious attempts on this approach to text generation all fail to sample\ncorrectly from the target language model distributions. To address this\nlimitation, we consider the problem of designing text samplers that are\nfaithful, meaning that they have the target text distribution as its limiting\ndistribution. We propose several faithful gradient-based sampling algorithms to\nsample from the target energy-based text distribution correctly, and study\ntheir theoretical properties. Through experiments on various forms of text\ngeneration, we demonstrate that faithful samplers are able to generate more\nfluent text while adhering to the control objectives better.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Afra Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennigen_L/0/1/0/all/0/1\">Lucas Torroba Hennigen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinyan Velocity Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1\">Jason Eisner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Holden Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Translating Hanja Historical Documents to Contemporary Korean and English. (arXiv:2205.10019v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.10019","description":"<p>The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of\nJoseon, the 500-year kingdom preceding the modern nation of Korea. The Annals\nwere originally written in an archaic Korean writing system, `Hanja', and were\ntranslated into Korean from 1968 to 1993. The resulting translation was however\ntoo literal and contained many archaic Korean words; thus, a new expert\ntranslation effort began in 2012. Since then, the records of only one king have\nbeen completed in a decade. In parallel, expert translators are working on\nEnglish translation, also at a slow pace and produced only one king's records\nin English so far. Thus, we propose H2KE, a neural machine translation model,\nthat translates historical documents in Hanja to more easily understandable\nKorean and to English. Built on top of multilingual neural machine translation,\nH2KE learns to translate a historical document written in Hanja, from both a\nfull dataset of outdated Korean translation and a small dataset of more\nrecently translated contemporary Korean and English. We compare our method\nagainst two baselines: a recent model that simultaneously learns to restore and\ntranslate Hanja historical document and a Transformer based model trained only\non newly translated corpora. The experiments reveal that our method\nsignificantly outperforms the baselines in terms of BLEU scores for both\ncontemporary Korean and English translations. We further conduct extensive\nhuman evaluation which shows that our translation is preferred over the\noriginal expert translations by both experts and non-expert Korean speakers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Juhee Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jiho Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_H/0/1/0/all/0/1\">Haneul Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bak_J/0/1/0/all/0/1\">JinYeong Bak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-lingual Lifelong Learning. (arXiv:2205.11152v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11152","description":"<p>The longstanding goal of multi-lingual learning has been to develop a\nuniversal cross-lingual model that can withstand the changes in multi-lingual\ndata distributions. There has been a large amount of work to adapt such\nmulti-lingual models to unseen target languages. However, the majority of work\nin this direction focuses on the standard one-hop transfer learning pipeline\nfrom source to target languages, whereas in realistic scenarios, new languages\ncan be incorporated at any time in a sequential manner. In this paper, we\npresent a principled Cross-lingual Continual Learning (CCL) evaluation\nparadigm, where we analyze different categories of approaches used to\ncontinually adapt to emerging data from different languages. We provide\ninsights into what makes multilingual sequential learning particularly\nchallenging. To surmount such challenges, we benchmark a representative set of\ncross-lingual continual learning algorithms and analyze their knowledge\npreservation, accumulation, and generalization capabilities compared to\nbaselines on carefully curated datastreams. The implications of this analysis\ninclude a recipe for how to measure and balance different cross-lingual\ncontinual learning desiderata, which go beyond conventional transfer learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mhamdi_M/0/1/0/all/0/1\">Meryem M&#x27;hamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Solving Math Word Problems via Cooperative Reasoning induced Language Models. (arXiv:2210.16257v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.16257","description":"<p>Large-scale pre-trained language models (PLMs) bring new opportunities to\nchallenging problems, especially those that need high-level intelligence, such\nas the math word problem (MWPs). However, directly applying existing PLMs to\nMWPs can fail as the generation process lacks sufficient supervision and thus\nlacks fast adaptivity as humans. We notice that human reasoning has a dual\nreasoning framework that consists of an immediate reaction system (system 1)\nand a delicate reasoning system (system 2), where the entire reasoning is\ndetermined by their interaction. This inspires us to develop a cooperative\nreasoning-induced PLM for solving MWPs, called Cooperative Reasoning (CoRe),\nresulting in a human-like reasoning architecture with system 1 as the generator\nand system 2 as the verifier. In our approach, the generator is responsible for\ngenerating reasoning paths, and the verifiers are used to supervise the\nevaluation in order to obtain reliable feedback for the generator. We evaluate\nour CoRe framework on several mathematical reasoning datasets and achieve\ndecent improvement over state-of-the-art methods, up to 9.6% increase over best\nbaselines. Our codes are available at https://github.com/TianHongZXY/CoRe\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xinyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing Prompts for Text-to-Image Generation. (arXiv:2212.09611v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09611","description":"<p>Well-designed prompts can guide text-to-image models to generate amazing\nimages. However, the performant prompts are often model-specific and misaligned\nwith user input. Instead of laborious human engineering, we propose prompt\nadaptation, a general framework that automatically adapts original user input\nto model-preferred prompts. Specifically, we first perform supervised\nfine-tuning with a pretrained language model on a small collection of manually\nengineered prompts. Then we use reinforcement learning to explore better\nprompts. We define a reward function that encourages the policy to generate\nmore aesthetically pleasing images while preserving the original user\nintentions. Experimental results on Stable Diffusion show that our method\noutperforms manual prompt engineering in terms of both automatic metrics and\nhuman preference ratings. Moreover, reinforcement learning further boosts\nperformance, especially on out-of-domain prompts. The pretrained checkpoints\nare available at https://aka.ms/promptist. The demo can be found at\nhttps://aka.ms/promptist-demo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yaru Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_Z/0/1/0/all/0/1\">Zewen Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v9 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03109","description":"<p>Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yupeng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graph Neural Prompting with Large Language Models. (arXiv:2309.15427v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.15427","description":"<p>Large language models (LLMs) have shown remarkable generalization capability\nwith exceptional performance in various language modeling tasks. However, they\nstill exhibit inherent limitations in precisely capturing and returning\ngrounded knowledge. While existing work has explored utilizing knowledge graphs\n(KGs) to enhance language modeling via joint training and customized model\narchitectures, applying this to LLMs is problematic owing to their large number\nof parameters and high computational cost. Therefore, how to enhance\npre-trained LLMs using grounded knowledge, e.g., retrieval-augmented\ngeneration, remains an open question. In this work, we propose Graph Neural\nPrompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in\nlearning beneficial knowledge from KGs. GNP encompasses various designs,\nincluding a standard graph neural network encoder, a cross-modality pooling\nmodule, a domain projector, and a self-supervised link prediction objective.\nExtensive experiments on multiple datasets demonstrate the superiority of GNP\non both commonsense and biomedical reasoning tasks across different LLM sizes\nand settings. Code is available at https://github.com/meettyj/GNP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yijun Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Huan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Ziqing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1\">Nitesh V. Chawla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Panpan Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes. (arXiv:2310.15959v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15959","description":"<p>We introduce NoteChat, a novel cooperative multi-agent framework leveraging\nLarge Language Models (LLMs) to generate patient-physician dialogues. NoteChat\nembodies the principle that an ensemble of role-specific LLMs, through\nstructured role-play and strategic prompting, can perform their assigned roles\nmore effectively. The synergy among these role-playing LLMs results in a\ncohesive and efficient dialogue generation. Evaluation on MTS-dialogue, a\nbenchmark dataset for patient-physician dialogues-note pairs, shows that models\ntrained with the augmented synthetic patient-physician dialogues by NoteChat\noutperforms other state-of-the-art models for generating clinical notes. Our\ncomprehensive automatic and human evaluation demonstrates that NoteChat\nsubstantially surpasses state-of-the-art models like ChatGPT and GPT-4 up to\n22.78% by domain experts in generating superior synthetic patient-physician\ndialogues based on clinical notes. NoteChat has the potential to engage\npatients directly and help clinical documentation, a leading cause of physician\nburnout.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junda Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huixue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Rumeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yucheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PhayaThaiBERT: Enhancing a Pretrained Thai Language Model with Unassimilated Loanwords. (arXiv:2311.12475v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.12475","description":"<p>While WangchanBERTa has become the de facto standard in transformer-based\nThai language modeling, it still has shortcomings in regard to the\nunderstanding of foreign words, most notably English words, which are often\nborrowed without orthographic assimilation into Thai in many contexts. We\nidentify the lack of foreign vocabulary in WangchanBERTa's tokenizer as the\nmain source of these shortcomings. We then expand WangchanBERTa's vocabulary\nvia vocabulary transfer from XLM-R's pretrained tokenizer and pretrain a new\nmodel using the expanded tokenizer, starting from WangchanBERTa's checkpoint,\non a new dataset that is larger than the one used to train WangchanBERTa. Our\nresults show that our new pretrained model, PhayaThaiBERT, outperforms\nWangchanBERTa in many downstream tasks and datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sriwirote_P/0/1/0/all/0/1\">Panyut Sriwirote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapiang_J/0/1/0/all/0/1\">Jalinee Thapiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timtong_V/0/1/0/all/0/1\">Vasan Timtong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutherford_A/0/1/0/all/0/1\">Attapol T. Rutherford</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph Construction. (arXiv:2312.03022v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2312.03022","description":"<p>Knowledge graph construction (KGC) is a multifaceted undertaking involving\nthe extraction of entities, relations, and events. Traditionally, large\nlanguage models (LLMs) have been viewed as solitary task-solving agents in this\ncomplex landscape. However, this paper challenges this paradigm by introducing\na novel framework, CooperKGC. Departing from the conventional approach,\nCooperKGC establishes a collaborative processing network, assembling a KGC\ncollaboration team capable of concurrently addressing entity, relation, and\nevent extraction tasks. Our experiments unequivocally demonstrate that\nfostering collaboration and information interaction among diverse agents within\nCooperKGC yields superior results compared to individual cognitive processes\noperating in isolation. Importantly, our findings reveal that the collaboration\nfacilitated by CooperKGC enhances knowledge selection, correction, and\naggregation capabilities across multiple rounds of interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hongbin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_H/0/1/0/all/0/1\">Honghao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wei Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1\">Weiqiang Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decoupling SQL Query Hardness Parsing for Text-to-SQL. (arXiv:2312.06172v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.06172","description":"<p>The fundamental goal of the Text-to-SQL task is to translate natural language\nquestion into SQL query. Current research primarily emphasizes the information\ncoupling between natural language questions and schemas, and significant\nprogress has been made in this area. The natural language questions as the\nprimary task requirements source determines the hardness of correspond SQL\nqueries, the correlation between the two always be ignored. However, when the\ncorrelation between questions and queries was decoupled, it may simplify the\ntask. In this paper, we introduce an innovative framework for Text-to-SQL based\non decoupling SQL query hardness parsing. This framework decouples the\nText-to-SQL task based on query hardness by analyzing questions and schemas,\nsimplifying the multi-hardness task into a single-hardness challenge. This\ngreatly reduces the parsing pressure on the language model. We evaluate our\nproposed framework and achieve a new state-of-the-art performance of\nfine-turning methods on Spider dev.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jiawen Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guo Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation. (arXiv:2312.09085v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.09085","description":"<p>Large Language Models (LLMs) encapsulate vast amounts of knowledge but still\nremain vulnerable to external misinformation. Existing research mainly studied\nthis susceptibility behavior in a single-turn setting. However, belief can\nchange during a multi-turn conversation, especially a persuasive one.\nTherefore, in this study, we delve into LLMs' susceptibility to persuasive\nconversations, particularly on factual questions that they can answer\ncorrectly. We first curate the Farm (i.e., Fact to Misinform) dataset, which\ncontains factual questions paired with systematically generated persuasive\nmisinformation. Then, we develop a testing framework to track LLMs' belief\nchanges in a persuasive dialogue. Through extensive experiments, we find that\nLLMs' correct beliefs on factual knowledge can be easily manipulated by various\npersuasive strategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Rongwu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Brian S. Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shujian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1\">Zhixuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Han Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Augmented Generation for Large Language Models: A Survey. (arXiv:2312.10997v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.10997","description":"<p>Large Language Models (LLMs) demonstrate significant capabilities but face\nchallenges such as hallucination, outdated knowledge, and non-transparent,\nuntraceable reasoning processes. Augmented Generation (RAG) has emerged as a\npromising solution to these issues by incorporating real-time data from\nexternal databases into LLM responses. This enhances the accuracy and\ncredibility of the models, particularly for knowledge-intensive tasks, and\nallows for continuous knowledge updates and integration of domain-specific\ninformation. RAG synergistically merges LLMs' intrinsic knowledge with the\nvast, dynamic repositories of external databases. This survey paper provides an\nin-depth analysis of the evolution of RAG, focusing on three key paradigms:\nNaive RAG, Advanced RAG, and Modular RAG. It methodically examines the three\nfundamental components of RAG systems: the retriever, the generator, and the\naugmentation methods, underscoring the cutting-edge technologies within each\ncomponenet. Additionally, the paper introduces novel metrics and capabilities\nfor evaluating RAG models, as well as the most recent evaluation framework.\nFinally, the paper outlines future research directions from three perspectives:\nfuture challenges,modality extension,and the development of the RAG technical\nstack and ecosystem\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunfan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1\">Kangxiang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jinliu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_Y/0/1/0/all/0/1\">Yuxi Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiawei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qianyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haofen Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model (LLM) Bias Index -- LLMBI. (arXiv:2312.14769v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.14769","description":"<p>The Large Language Model Bias Index (LLMBI) is a pioneering approach designed\nto quantify and address biases inherent in large language models (LLMs), such\nas GPT-4. We recognise the increasing prevalence and impact of LLMs across\ndiverse sectors. This research introduces a novel metric, LLMBI, to\nsystematically measure and mitigate biases potentially skewing model responses.\nWe formulated LLMBI using a composite scoring system incorporating multiple\ndimensions of bias, including but not limited to age, gender, and racial\nbiases. To operationalise this metric, we engaged in a multi-step process\ninvolving collecting and annotating LLM responses, applying sophisticated\nNatural Language Processing (NLP) techniques for bias detection, and computing\nthe LLMBI score through a specially crafted mathematical formula. The formula\nintegrates weighted averages of various bias dimensions, a penalty for dataset\ndiversity deficiencies, and a correction for sentiment biases. Our empirical\nanalysis, conducted using responses from OpenAI's API, employs advanced\nsentiment analysis as a representative method for bias detection. The research\nreveals LLMs, whilst demonstrating impressive capabilities in text generation,\nexhibit varying degrees of bias across different dimensions. LLMBI provides a\nquantifiable measure to compare biases across models and over time, offering a\nvital tool for systems engineers, researchers and regulators in enhancing the\nfairness and reliability of LLMs. It highlights the potential of LLMs in\nmimicking unbiased human-like responses. Additionally, it underscores the\nnecessity of continuously monitoring and recalibrating such models to align\nwith evolving societal norms and ethical standards.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oketunji_A/0/1/0/all/0/1\">Abiodun Finbarrs Oketunji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anas_M/0/1/0/all/0/1\">Muhammad Anas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saina_D/0/1/0/all/0/1\">Deepthi Saina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SOLAR 10.7B: Scaling Large Language Models with Simple yet Effective Depth Up-Scaling. (arXiv:2312.15166v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.15166","description":"<p>We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion\nparameters, demonstrating superior performance in various natural language\nprocessing (NLP) tasks. Inspired by recent efforts to efficiently up-scale\nLLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which\nencompasses depthwise scaling and continued pretraining. In contrast to other\nLLM up-scaling methods that use mixture-of-experts, DUS does not require\ncomplex changes to train and inference efficiently. We show experimentally that\nDUS is simple yet effective in scaling up high-performance LLMs from small\nones. Building on the DUS model, we additionally present SOLAR 10.7B-Instruct,\na variant fine-tuned for instruction-following capabilities, surpassing\nMixtral-8x7B-Instruct. SOLAR 10.7B is publicly available under the Apache 2.0\nlicense, promoting broad access and application in the LLM field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dahyun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chanjun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sanghoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1\">Wonsung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wonho Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyeonwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yungi Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hyeonju Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jihoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_C/0/1/0/all/0/1\">Changbae Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Seonghoon Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sukyung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Hyunbyung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gim_G/0/1/0/all/0/1\">Gyoungjin Gim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1\">Mikyoung Cha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwalsuk Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sunghun Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM Factoscope: Uncovering LLMs' Factual Discernment through Inner States Analysis. (arXiv:2312.16374v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.16374","description":"<p>Large Language Models (LLMs) have revolutionized various domains with\nextensive knowledge and creative capabilities. However, a critical issue with\nLLMs is their tendency to produce outputs that diverge from factual reality.\nThis phenomenon is particularly concerning in sensitive applications such as\nmedical consultation and legal advice, where accuracy is paramount. In this\npaper, we introduce the LLM factoscope, a novel Siamese network-based model\nthat leverages the inner states of LLMs for factual detection. Our\ninvestigation reveals distinguishable patterns in LLMs' inner states when\ngenerating factual versus non-factual content. We demonstrate the LLM\nfactoscope's effectiveness across various architectures, achieving over 96%\naccuracy in factual detection. Our work opens a new avenue for utilizing LLMs'\ninner states for factual detection and encourages further exploration into\nLLMs' inner workings for enhanced reliability and transparency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jinwen He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yujia Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zijin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chengan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yue Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experiential Co-Learning of Software-Developing Agents. (arXiv:2312.17025v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17025","description":"<p>Recent advancements in large language models (LLMs) have brought significant\nchanges to various domains, especially through LLM-driven autonomous agents.\nThese agents are now capable of collaborating seamlessly, splitting tasks and\nenhancing accuracy, thus minimizing the need for human involvement. However,\nthese agents often approach a diverse range of tasks in isolation, without\nbenefiting from past experiences. This isolation can lead to repeated mistakes\nand inefficient trials in task solving. To this end, this paper introduces\nExperiential Co-Learning, a novel framework in which instructor and assistant\nagents gather shortcut-oriented experiences from their historical trajectories\nand use these past experiences for mutual reasoning. This paradigm, enriched\nwith previous experiences, equips agents to more effectively address unseen\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_Y/0/1/0/all/0/1\">Yufan Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiahao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Length Extrapolation of Transformers: A Survey from the Perspective of Position Encoding. (arXiv:2312.17044v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17044","description":"<p>Transformer has taken the natural language processing (NLP) field by storm\nsince birth, owing to its superior ability to model complex dependencies in\nsequences. Despite the great success of pretrained language models (PLMs) based\non Transformer across almost all NLP tasks, they all suffer from a preset\nlength limit and thus can hardly extend this success to longer sequences beyond\nseen data, namely the length extrapolation problem. Length extrapolation has\naroused great interest among researchers, as it is the core feature of human\nlanguage capacity. To enhance length extrapolation of Transformers, a plethora\nof methods have been proposed, mostly focusing on extrapolatable position\nencodings. In this article, we provide an organized and systematical review of\nthese research efforts in a unified notation from a position encoding\nperspective, aiming to enable the reader to gain a deep understanding of\nexisting methods and provide stimuli for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaocheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiachong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-12-31T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}