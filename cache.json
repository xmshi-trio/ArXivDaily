{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-05T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"End-to-End Continuous Speech Emotion Recognition in Real-life Customer Service Call Center Conversations. (arXiv:2310.02281v1 [eess.AS])","link":"http://arxiv.org/abs/2310.02281","description":"<p>Speech Emotion recognition (SER) in call center conversations has emerged as\na valuable tool for assessing the quality of interactions between clients and\nagents. In contrast to controlled laboratory environments, real-life\nconversations take place under uncontrolled conditions and are subject to\ncontextual factors that influence the expression of emotions. In this paper, we\npresent our approach to constructing a large-scale reallife dataset (CusEmo)\nfor continuous SER in customer service call center conversations. We adopted\nthe dimensional emotion annotation approach to capture the subtlety,\ncomplexity, and continuity of emotions in real-life call center conversations,\nwhile annotating contextual information. The study also addresses the\nchallenges encountered during the application of the End-to-End (E2E) SER\nsystem to the dataset, including determining the appropriate label sampling\nrate and input segment length, as well as integrating contextual information\n(interlocutor's gender and empathy level) with different weights using\nmultitask learning. The result shows that incorporating the empathy level\ninformation improved the model's performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Feng_Y/0/1/0/all/0/1\">Yajing Feng</a> (CNRS-LISN), <a href=\"http://arxiv.org/find/eess/1/au:+Devillers_L/0/1/0/all/0/1\">Laurence Devillers</a> (CNRS-LISN, SU)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation. (arXiv:2310.02304v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02304","description":"<p>Several recent advances in AI systems (e.g., Tree-of-Thoughts and\nProgram-Aided Language Models) solve problems by providing a \"scaffolding\"\nprogram that structures multiple calls to language models to generate better\noutputs. A scaffolding program is written in a programming language such as\nPython. In this work, we use a language-model-infused scaffolding program to\nimprove itself. We start with a seed \"improver\" that improves an input program\naccording to a given utility function by querying a language model several\ntimes and returning the best solution. We then run this seed improver to\nimprove itself. Across a small set of downstream tasks, the resulting improved\nimprover generates programs with significantly better performance than its seed\nimprover. Afterward, we analyze the variety of self-improvement strategies\nproposed by the language model, including beam search, genetic algorithms, and\nsimulated annealing. Since the language models themselves are not altered, this\nis not full recursive self-improvement. Nonetheless, it demonstrates that a\nmodern language model, GPT-4 in our proof-of-concept experiments, is capable of\nwriting code that can call itself to improve itself. We critically consider\nconcerns around the development of self-improving technologies and evaluate the\nfrequency with which the generated code bypasses a sandbox.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zelikman_E/0/1/0/all/0/1\">Eric Zelikman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lorch_E/0/1/0/all/0/1\">Eliana Lorch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the definition of toxicity in NLP. (arXiv:2310.02357v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02357","description":"<p>The fundamental problem in toxicity detection task lies in the fact that the\ntoxicity is ill-defined. Jigsaw, a unit within Google and one of the leaders in\nthe field, uses a definition of toxicity given by Dixon et al. - 'rude,\ndisrespectful, or unreasonable language that is likely to make someone leave a\ndiscussion'. One can instantly see the issue with this definition, as it gives\nno quantitative measure of the toxicity and operates with highly subjective\ncultural terms. Despite all vagueness and flaws, this definition is de-facto\nwidely used by many researchers. In this work we suggest quantative\nstress-based defenition for the toxicity that overcomes existing shortcomings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1\">Sergey Berezin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahbakhsh_R/0/1/0/all/0/1\">Reza Farahbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_N/0/1/0/all/0/1\">Noel Crespi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ProtoNER: Few shot Incremental Learning for Named Entity Recognition using Prototypical Networks. (arXiv:2310.02372v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02372","description":"<p>Key value pair (KVP) extraction or Named Entity Recognition(NER) from\nvisually rich documents has been an active area of research in document\nunderstanding and data extraction domain. Several transformer based models such\nas LayoutLMv2, LayoutLMv3, and LiLT have emerged achieving state of the art\nresults. However, addition of even a single new class to the existing model\nrequires (a) re-annotation of entire training dataset to include this new class\nand (b) retraining the model again. Both of these issues really slow down the\ndeployment of updated model. \\\\ We present \\textbf{ProtoNER}: Prototypical\nNetwork based end-to-end KVP extraction model that allows addition of new\nclasses to an existing model while requiring minimal number of newly annotated\ntraining samples. The key contributions of our model are: (1) No dependency on\ndataset used for initial training of the model, which alleviates the need to\nretain original training dataset for longer duration as well as data\nre-annotation which is very time consuming task, (2) No intermediate synthetic\ndata generation which tends to add noise and results in model's performance\ndegradation, and (3) Hybrid loss function which allows model to retain\nknowledge about older classes as well as learn about newly added classes.\\\\\nExperimental results show that ProtoNER finetuned with just 30 samples is able\nto achieve similar results for the newly added classes as that of regular model\nfinetuned with 2600 samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Ritesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1\">Saurabh Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1\">Ashish Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isahagian_V/0/1/0/all/0/1\">Vatche Isahagian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Health Agents: A Personalized LLM-Powered Agent Framework. (arXiv:2310.02374v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02374","description":"<p>Conversational Health Agents (CHAs) are interactive systems designed to\nenhance personal healthcare services by engaging in empathetic conversations\nand processing multimodal data. While current CHAs, especially those utilizing\nLarge Language Models (LLMs), primarily focus on conversation, they often lack\ncomprehensive agent capabilities. This includes the ability to access personal\nuser health data from wearables, 24/7 data collection sources, and electronic\nhealth records, as well as integrating the latest published health insights and\nconnecting with established multimodal data analysis tools. We are developing a\nframework to empower CHAs by equipping them with critical thinking, knowledge\nacquisition, and problem-solving abilities. Our CHA platform, powered by LLMs,\nseamlessly integrates healthcare tools, enables multilingual and multimodal\nconversations, and interfaces with a variety of user data analysis tools. We\nillustrate its proficiency in handling complex healthcare tasks, such as stress\nlevel estimation, showcasing the agent's cognitive and operational\ncapabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abbasian_M/0/1/0/all/0/1\">Mahyar Abbasian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azimi_I/0/1/0/all/0/1\">Iman Azimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1\">Amir M. Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Ramesh Jain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Speech Recognition with N-Skipgram and Positional Unigram Matching. (arXiv:2310.02382v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02382","description":"<p>Training unsupervised speech recognition systems presents challenges due to\nGAN-associated instability, misalignment between speech and text, and\nsignificant memory demands. To tackle these challenges, we introduce a novel\nASR system, ESPUM. This system harnesses the power of lower-order N-skipgrams\n(up to N=3) combined with positional unigram statistics gathered from a small\nbatch of samples. Evaluated on the TIMIT benchmark, our model showcases\ncompetitive performance in ASR and phoneme segmentation tasks. Access our\npublicly available code at https://github.com/lwang114/GraphUnsupASR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasegawa_Johnson_M/0/1/0/all/0/1\">Mark Hasegawa-Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_C/0/1/0/all/0/1\">Chang D. Yoo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindTheDApp: A Toolchain for Complex Network-Driven Structural Analysis of Ethereum-based Decentralised Applications. (arXiv:2310.02408v1 [cs.IT])","link":"http://arxiv.org/abs/2310.02408","description":"<p>This paper presents MindTheDApp, a toolchain designed specifically for the\nstructural analysis of Ethereum-based Decentralized Applications (DApps), with\na distinct focus on a complex network-driven approach. Unlike existing tools,\nour toolchain combines the power of ANTLR4 and Abstract Syntax Tree (AST)\ntraversal techniques to transform the architecture and interactions within\nsmart contracts into a specialized bipartite graph. This enables advanced\nnetwork analytics to highlight operational efficiencies within the DApp's\narchitecture.\n</p>\n<p>The bipartite graph generated by the proposed tool comprises two sets of\nnodes: one representing smart contracts, interfaces, and libraries, and the\nother including functions, events, and modifiers. Edges in the graph connect\nfunctions to smart contracts they interact with, offering a granular view of\ninterdependencies and execution flow within the DApp. This network-centric\napproach allows researchers and practitioners to apply complex network theory\nin understanding the robustness, adaptability, and intricacies of decentralized\nsystems.\n</p>\n<p>Our work contributes to the enhancement of security in smart contracts by\nallowing the visualisation of the network, and it provides a deep understanding\nof the architecture and operational logic within DApps. Given the growing\nimportance of smart contracts in the blockchain ecosystem and the emerging\napplication of complex network theory in technology, our toolchain offers a\ntimely contribution to both academic research and practical applications in the\nfield of blockchain technology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ibba_G/0/1/0/all/0/1\">Giacomo Ibba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aufiero_S/0/1/0/all/0/1\">Sabrina Aufiero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartolucci_S/0/1/0/all/0/1\">Silvia Bartolucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neykova_R/0/1/0/all/0/1\">Rumyana Neykova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortu_M/0/1/0/all/0/1\">Marco Ortu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonelli_R/0/1/0/all/0/1\">Roberto Tonelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Destefanis_G/0/1/0/all/0/1\">Giuseppe Destefanis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nugget 2D: Dynamic Contextual Compression for Scaling Decoder-only Language Models. (arXiv:2310.02409v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02409","description":"<p>Standard Transformer-based language models (LMs) scale poorly to long\ncontexts. We propose a solution based on dynamic contextual compression, which\nextends the Nugget approach of Qin &amp; Van Durme (2023) from BERT-like frameworks\nto decoder-only LMs. Our method models history as compressed \"nuggets\" which\nare trained to allow for reconstruction, and it can be initialized with\noff-the-shelf models such as LLaMA. We demonstrate through experiments in\nlanguage modeling, question answering, and summarization that Nugget2D retains\ncapabilities in these tasks, while drastically reducing the overhead during\ndecoding in terms of time and space. For example, in the experiments of\nautoencoding, Nugget2D can shrink context at a 20x compression ratio with a\nBLEU score of 98% for reconstruction, achieving nearly lossless encoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_G/0/1/0/all/0/1\">Guanghui Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosset_C/0/1/0/all/0/1\">Corby Rosset</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_E/0/1/0/all/0/1\">Ethan C. Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_N/0/1/0/all/0/1\">Nikhil Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mixture of Quantized Experts (MoQE): Complementary Effect of Low-bit Quantization and Robustness. (arXiv:2310.02410v1 [cs.LG])","link":"http://arxiv.org/abs/2310.02410","description":"<p>Large Mixture of Experts (MoE) models could achieve state-of-the-art quality\non various language tasks, including machine translation task, thanks to the\nefficient model scaling capability with expert parallelism. However, it has\nbrought a fundamental issue of larger memory consumption and increased memory\nbandwidth bottleneck at deployment time. In this paper, we propose Mixture of\nQuantized Experts (MoQE) which is a simple weight-only quantization method\napplying ultra low-bit down to 2-bit quantizations only to expert weights for\nmitigating the increased memory and latency issues of MoE models. We show that\nlow-bit quantization together with the MoE architecture delivers a reliable\nmodel performance while reducing the memory size significantly even without any\nadditional training in most cases. In particular, expert layers in MoE models\nare much more robust to the quantization than conventional feedforward networks\n(FFN) layers. In our comprehensive analysis, we show that MoE models with 2-bit\nexpert weights can deliver better model performance than the dense model\ntrained on the same dataset. As a result of low-bit quantization, we show the\nmodel size can be reduced by 79.6% of the original half precision floating\npoint (fp16) MoE model. Combined with an optimized GPU runtime implementation,\nit also achieves 1.24X speed-up on A100 GPUs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fahim_R/0/1/0/all/0/1\">Raffy Fahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadalla_H/0/1/0/all/0/1\">Hany Hassan Awadalla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can a student Large Language Model perform as well as it's teacher?. (arXiv:2310.02421v1 [cs.LG])","link":"http://arxiv.org/abs/2310.02421","description":"<p>The burgeoning complexity of contemporary deep learning models, while\nachieving unparalleled accuracy, has inadvertently introduced deployment\nchallenges in resource-constrained environments. Knowledge distillation, a\ntechnique aiming to transfer knowledge from a high-capacity \"teacher\" model to\na streamlined \"student\" model, emerges as a promising solution to this dilemma.\nThis paper provides a comprehensive overview of the knowledge distillation\nparadigm, emphasizing its foundational principles such as the utility of soft\nlabels and the significance of temperature scaling. Through meticulous\nexamination, we elucidate the critical determinants of successful distillation,\nincluding the architecture of the student model, the caliber of the teacher,\nand the delicate balance of hyperparameters. While acknowledging its profound\nadvantages, we also delve into the complexities and challenges inherent in the\nprocess. Our exploration underscores knowledge distillation's potential as a\npivotal technique in optimizing the trade-off between model performance and\ndeployment efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gholami_S/0/1/0/all/0/1\">Sia Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omar_M/0/1/0/all/0/1\">Marwan Omar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Provide Security & Privacy Advice? Measuring the Ability of LLMs to Refute Misconceptions. (arXiv:2310.02431v1 [cs.HC])","link":"http://arxiv.org/abs/2310.02431","description":"<p>Users seek security &amp; privacy (S&amp;P) advice from online resources, including\ntrusted websites and content-sharing platforms. These resources help users\nunderstand S&amp;P technologies and tools and suggest actionable strategies. Large\nLanguage Models (LLMs) have recently emerged as trusted information sources.\nHowever, their accuracy and correctness have been called into question. Prior\nresearch has outlined the shortcomings of LLMs in answering multiple-choice\nquestions and user ability to inadvertently circumvent model restrictions\n(e.g., to produce toxic content). Yet, the ability of LLMs to provide reliable\nS&amp;P advice is not well-explored. In this paper, we measure their ability to\nrefute popular S&amp;P misconceptions that the general public holds. We first study\nrecent academic literature to curate a dataset of over a hundred S&amp;P-related\nmisconceptions across six different topics. We then query two popular LLMs\n(Bard and ChatGPT) and develop a labeling guide to evaluate their responses to\nthese misconceptions. To comprehensively evaluate their responses, we further\napply three strategies: query each misconception multiple times, generate and\nquery their paraphrases, and solicit source URLs of the responses. Both models\ndemonstrate, on average, a 21.3% non-negligible error rate, incorrectly\nsupporting popular S&amp;P misconceptions. The error rate increases to 32.6% when\nwe repeatedly query LLMs with the same or paraphrased misconceptions. We also\nexpose that models may partially support a misconception or remain\nnoncommittal, refusing a firm stance on misconceptions. Our exploration of\ninformation sources for responses revealed that LLMs are susceptible to\nproviding invalid URLs (21.2% for Bard and 67.7% for ChatGPT) or point to\nunrelated sources (44.2% returned by Bard and 18.3% by ChatGPT).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arunasalam_A/0/1/0/all/0/1\">Arjun Arunasalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celik_Z/0/1/0/all/0/1\">Z. Berkay Celik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of Large Language Models with Misconceptions. (arXiv:2310.02439v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02439","description":"<p>We propose novel evaluations for mathematical reasoning capabilities of Large\nLanguage Models (LLMs) based on mathematical misconceptions. Our primary\napproach is to simulate LLMs as a novice learner and an expert tutor, aiming to\nidentify the incorrect answer to math question resulted from a specific\nmisconception and to recognize the misconception(s) behind an incorrect answer,\nrespectively. Contrary to traditional LLMs-based mathematical evaluations that\nfocus on answering math questions correctly, our approach takes inspirations\nfrom principles in educational learning sciences. We explicitly ask LLMs to\nmimic a novice learner by answering questions in a specific incorrect manner\nbased on incomplete knowledge; and to mimic an expert tutor by identifying\nmisconception(s) corresponding to an incorrect answer to a question. Using\nsimple grade-school math problems, our experiments reveal that, while LLMs can\neasily answer these questions correctly, they struggle to identify 1) the\nincorrect answer corresponding to specific incomplete knowledge\n(misconceptions); 2) the misconceptions that explain particular incorrect\nanswers. Our study indicates new opportunities for enhancing LLMs' math\nreasoning capabilities, especially on developing robust student simulation and\nexpert tutoring models in the educational applications such as intelligent\ntutoring systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Naiming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonkar_S/0/1/0/all/0/1\">Shashank Sonkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woodhead_S/0/1/0/all/0/1\">Simon Woodhead</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Low-Resource Languages Jailbreak GPT-4. (arXiv:2310.02446v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02446","description":"<p>AI safety training and red-teaming of large language models (LLMs) are\nmeasures to mitigate the generation of unsafe content. Our work exposes the\ninherent cross-lingual vulnerability of these safety mechanisms, resulting from\nthe linguistic inequality of safety training data, by successfully\ncircumventing GPT-4's safeguard through translating unsafe English inputs into\nlow-resource languages. On the AdvBenchmark, GPT-4 engages with the unsafe\ntranslated inputs and provides actionable items that can get the users towards\ntheir harmful goals 79% of the time, which is on par with or even surpassing\nstate-of-the-art jailbreaking attacks. Other high-/mid-resource languages have\nsignificantly lower attack success rate, which suggests that the cross-lingual\nvulnerability mainly applies to low-resource languages. Previously, limited\ntraining on low-resource languages primarily affects speakers of those\nlanguages, causing technological disparities. However, our work highlights a\ncrucial shift: this deficiency now poses a risk to all LLMs users. Publicly\navailable translation APIs enable anyone to exploit LLMs' safety\nvulnerabilities. Therefore, our work calls for a more holistic red-teaming\nefforts to develop robust multilingual safeguards with wide language coverage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng-Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menghini_C/0/1/0/all/0/1\">Cristina Menghini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Backdoor Adjustment of Confounding by Provenance for Robust Text Classification of Multi-institutional Clinical Notes. (arXiv:2310.02451v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02451","description":"<p>Natural Language Processing (NLP) methods have been broadly applied to\nclinical tasks. Machine learning and deep learning approaches have been used to\nimprove the performance of clinical NLP. However, these approaches require\nsufficiently large datasets for training, and trained models have been shown to\ntransfer poorly across sites. These issues have led to the promotion of data\ncollection and integration across different institutions for accurate and\nportable models. However, this can introduce a form of bias called confounding\nby provenance. When source-specific data distributions differ at deployment,\nthis may harm model performance. To address this issue, we evaluate the utility\nof backdoor adjustment for text classification in a multi-site dataset of\nclinical notes annotated for mentions of substance abuse. Using an evaluation\nframework devised to measure robustness to distributional shifts, we assess the\nutility of backdoor adjustment. Our results indicate that backdoor adjustment\ncan effectively mitigate for confounding shift.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiruo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1\">Zhecheng Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1\">Meliha Yeti&#x15f;gen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pakhomov_S/0/1/0/all/0/1\">Serguei Pakhomov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1\">Trevor Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Empty Signifier Problem: Towards Clearer Paradigms for Operationalising \"Alignment\" in Large Language Models. (arXiv:2310.02457v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02457","description":"<p>In this paper, we address the concept of \"alignment\" in large language models\n(LLMs) through the lens of post-structuralist socio-political theory,\nspecifically examining its parallels to empty signifiers. To establish a shared\nvocabulary around how abstract concepts of alignment are operationalised in\nempirical datasets, we propose a framework that demarcates: 1) which dimensions\nof model behaviour are considered important, then 2) how meanings and\ndefinitions are ascribed to these dimensions, and by whom. We situate existing\nempirical literature and provide guidance on deciding which paradigm to follow.\nThrough this framework, we aim to foster a culture of transparency and critical\nevaluation, aiding the community in navigating the complexities of aligning\nLLMs with human populations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1\">Paul R&#xf6;ttger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Can Be Good Privacy Protection Learners. (arXiv:2310.02469v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02469","description":"<p>The proliferation of Large Language Models (LLMs) has driven considerable\ninterest in fine-tuning them with domain-specific data to create specialized\nlanguage models. Nevertheless, such domain-specific fine-tuning data often\ncontains sensitive personally identifiable information (PII). Direct\nfine-tuning LLMs on this data without privacy protection poses a risk of\nleakage. To address this challenge, we introduce Privacy Protection Language\nModels (PPLM), a novel paradigm for fine-tuning LLMs that effectively injects\ndomain-specific knowledge while safeguarding data privacy. Our work offers a\ntheoretical analysis for model design and delves into various techniques such\nas corpus curation, penalty-based unlikelihood in training loss, and\ninstruction-based tuning, etc. Extensive experiments across diverse datasets\nand scenarios demonstrate the effectiveness of our approaches. In particular,\ninstruction tuning with both positive and negative examples, stands out as a\npromising method, effectively protecting private data while enhancing the\nmodel's knowledge. Our work underscores the potential for Large Language Models\nas robust privacy protection learners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yijia Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yiqiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yushi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenchao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xujiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ResidualTransformer: Residual Low-rank Learning with Weight-sharing for Transformer Layers. (arXiv:2310.02489v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02489","description":"<p>Memory constraint of always-on devices is one of the major concerns when\ndeploying speech processing models on these devices. While larger models\ntrained with sufficiently large amount of data generally perform better, making\nthem fit in the device memory is a demanding challenge. In this paper, we aim\nto reduce model size by reparameterizing model weights across Transformer\nencoder layers and assuming a special weight composition and structure. More\nspecifically, inspired by ResNet and the more recent LoRA work, we propose an\napproach named ResidualTransformer, where each weight matrix in a Transformer\nlayer comprises 1) a shared full-rank component with its adjacent layers, and\n2) a unique low-rank component to itself. The low-rank matrices only account\nfor a small amount of model size increase. In addition, we add diagonal weight\nmatrices to improve modeling capacity of the low-rank matrices. Experiments of\nour 10k-hour speech recognition and speech translation tasks show that the\nTransformer encoder size can be reduced by ~3X with very slight performance\ndegradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CITING: Large Language Models Create Curriculum for Instruction Tuning. (arXiv:2310.02527v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02527","description":"<p>The recent advancement of large language models (LLMs) has been achieved\nthrough a combo of instruction tuning and human alignment. However, building\nmanually crafted instruction datasets and performing human alignment become the\nbottleneck for scaling the development of LLMs. In this paper, we exploit the\nidea of leveraging AI models in lieu of humans as the teacher to train student\nLLMs. Our method is inspired by how human students refine their writing skills\nby following the rubrics and learning from the revisions offered by their\ntutors. Specifically, we employ a teacher LLM to create a curriculum for\ninstruction tuning of the student LLM, namely Curriculum Instruction TunING\n(CITING). It encompasses two main steps: (1) the teacher LLM crafts the rubrics\nfor evaluating the answers corresponding to various types of questions, and (2)\nthe student LLM learns to follow the rubrics and perform self-correction from\nthe revision made by the teacher. We further iteratively carry out it to embody\nthe procedure of CITING. We compare CITING to a series of state-of-the-art\nbaselines on four datasets. Our method demonstrates strong improvement in terms\nof articulate, in-depth, and comprehensive by GPT-4 evaluation. Specifically,\nit achieves an average winning rate of 79.4% over SFT, 73.4% over RLHF, 78.1%\nover RRHF, and 76.3% over RAFT, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_T/0/1/0/all/0/1\">Tao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NOLA: Networks as Linear Combination of Low Rank Random Basis. (arXiv:2310.02556v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02556","description":"<p>Large Language Models (LLMs) have recently gained popularity due to their\nimpressive few-shot performance across various downstream tasks. However,\nfine-tuning all parameters and storing a unique model for each downstream task\nor domain becomes impractical because of the massive size of checkpoints (e.g.,\n350GB in GPT-3). Current literature, such as LoRA, showcases the potential of\nlow-rank modifications to the original weights of an LLM, enabling efficient\nadaptation and storage for task-specific models. These methods can reduce the\nnumber of parameters needed to fine-tune an LLM by several orders of magnitude.\nYet, these methods face two primary limitations: 1) the parameter reduction is\nlower-bounded by the rank one decomposition, and 2) the extent of reduction is\nheavily influenced by both the model architecture and the chosen rank. For\ninstance, in larger models, even a rank one decomposition might exceed the\nnumber of parameters truly needed for adaptation. In this paper, we introduce\nNOLA, which overcomes the rank one lower bound present in LoRA. It achieves\nthis by re-parameterizing the low-rank matrices in LoRA using linear\ncombinations of randomly generated matrices (basis) and optimizing the linear\nmixture coefficients only. This approach allows us to decouple the number of\ntrainable parameters from both the choice of rank and the network architecture.\nWe present adaptation results using GPT-2 and ViT in natural language and\ncomputer vision tasks. NOLA performs as well as, or better than models with\nequivalent parameter counts. Furthermore, we demonstrate that we can halve the\nparameters in larger models compared to LoRA with rank one, without sacrificing\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koohpayegani_S/0/1/0/all/0/1\">Soroush Abbasi Koohpayegani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navaneet_K/0/1/0/all/0/1\">KL Navaneet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nooralinejad_P/0/1/0/all/0/1\">Parsa Nooralinejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolouri_S/0/1/0/all/0/1\">Soheil Kolouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirsiavash_H/0/1/0/all/0/1\">Hamed Pirsiavash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Automatic VQA Evaluation Using Large Language Models. (arXiv:2310.02567v1 [cs.CV])","link":"http://arxiv.org/abs/2310.02567","description":"<p>8 years after the visual question answering (VQA) task was proposed, accuracy\nremains the primary metric for automatic evaluation. VQA Accuracy has been\neffective so far in the IID evaluation setting. However, our community is\nundergoing a shift towards open-ended generative models and OOD evaluation. In\nthis new paradigm, the existing VQA Accuracy metric is overly stringent and\nunderestimates the performance of VQA systems. Thus, there is a need to develop\nmore robust automatic VQA metrics that serve as a proxy for human judgment. In\nthis work, we propose to leverage the in-context learning capabilities of\ninstruction-tuned large language models (LLMs) to build a better VQA metric. We\nformulate VQA evaluation as an answer-rating task where the LLM is instructed\nto score the accuracy of a candidate answer given a set of reference answers.\nWe demonstrate the proposed metric better correlates with human judgment\ncompared to existing metrics across several VQA models and benchmarks. We hope\nwide adoption of our metric will contribute to better estimating the research\nprogress on the VQA task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manas_O/0/1/0/all/0/1\">Oscar Ma&#xf1;as</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krojer_B/0/1/0/all/0/1\">Benno Krojer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Aishwarya Agrawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"I$^2$KD-SLU: An Intra-Inter Knowledge Distillation Framework for Zero-Shot Cross-Lingual Spoken Language Understanding. (arXiv:2310.02594v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02594","description":"<p>Spoken language understanding (SLU) typically includes two subtasks: intent\ndetection and slot filling. Currently, it has achieved great success in\nhigh-resource languages, but it still remains challenging in low-resource\nlanguages due to the scarcity of labeled training data. Hence, there is a\ngrowing interest in zero-shot cross-lingual SLU. Despite of the success of\nexisting zero-shot cross-lingual SLU models, most of them neglect to achieve\nthe mutual guidance between intent and slots. To address this issue, we propose\nan Intra-Inter Knowledge Distillation framework for zero-shot cross-lingual\nSpoken Language Understanding (I$^2$KD-SLU) to model the mutual guidance.\nSpecifically, we not only apply intra-knowledge distillation between intent\npredictions or slot predictions of the same utterance in different languages,\nbut also apply inter-knowledge distillation between intent predictions and slot\npredictions of the same utterance. Our experimental results demonstrate that\nour proposed framework significantly improves the performance compared with the\nstrong baselines and achieves the new state-of-the-art performance on the\nMultiATIS++ dataset, obtaining a significant improvement over the previous best\nmodel in overall accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_T/0/1/0/all/0/1\">Tianjun Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenghong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AGIR: Automating Cyber Threat Intelligence Reporting with Natural Language Generation. (arXiv:2310.02655v1 [cs.CR])","link":"http://arxiv.org/abs/2310.02655","description":"<p>Cyber Threat Intelligence (CTI) reporting is pivotal in contemporary risk\nmanagement strategies. As the volume of CTI reports continues to surge, the\ndemand for automated tools to streamline report generation becomes increasingly\napparent. While Natural Language Processing techniques have shown potential in\nhandling text data, they often struggle to address the complexity of diverse\ndata sources and their intricate interrelationships. Moreover, established\nparadigms like STIX have emerged as de facto standards within the CTI\ncommunity, emphasizing the formal categorization of entities and relations to\nfacilitate consistent data sharing. In this paper, we introduce AGIR (Automatic\nGeneration of Intelligence Reports), a transformative Natural Language\nGeneration tool specifically designed to address the pressing challenges in the\nrealm of CTI reporting. AGIR's primary objective is to empower security\nanalysts by automating the labor-intensive task of generating comprehensive\nintelligence reports from formal representations of entity graphs. AGIR\nutilizes a two-stage pipeline by combining the advantages of template-based\napproaches and the capabilities of Large Language Models such as ChatGPT. We\nevaluate AGIR's report generation capabilities both quantitatively and\nqualitatively. The generated reports accurately convey information expressed\nthrough formal language, achieving a high recall value (0.99) without\nintroducing hallucination. Furthermore, we compare the fluency and utility of\nthe reports with state-of-the-art approaches, showing how AGIR achieves higher\nscores in terms of Syntactic Log-Odds Ratio (SLOR) and through questionnaires.\nBy using our tool, we estimate that the report writing time is reduced by more\nthan 40%, therefore streamlining the CTI production of any organization and\ncontributing to the automation of several CTI tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perrina_F/0/1/0/all/0/1\">Filippo Perrina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marchiori_F/0/1/0/all/0/1\">Francesco Marchiori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1\">Mauro Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verde_N/0/1/0/all/0/1\">Nino Vincenzo Verde</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LC-Score: Reference-less estimation of Text Comprehension Difficulty. (arXiv:2310.02754v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02754","description":"<p>Being able to read and understand written text is critical in a digital era.\nHowever, studies shows that a large fraction of the population experiences\ncomprehension issues. In this context, further initiatives in accessibility are\nrequired to improve the audience text comprehension. However, writers are\nhardly assisted nor encouraged to produce easy-to-understand content. Moreover,\nAutomatic Text Simplification (ATS) model development suffers from the lack of\nmetric to accurately estimate comprehension difficulty We present\n\\textsc{LC-Score}, a simple approach for training text comprehension metric for\nany French text without reference \\ie predicting how easy to understand a given\ntext is on a $[0, 100]$ scale. Our objective with this scale is to\nquantitatively capture the extend to which a text suits to the \\textit{Langage\nClair} (LC, \\textit{Clear Language}) guidelines, a French initiative closely\nrelated to English Plain Language. We explore two approaches: (i) using\nlinguistically motivated indicators used to train statistical models, and (ii)\nneural learning directly from text leveraging pre-trained language models. We\nintroduce a simple proxy task for comprehension difficulty training as a\nclassification task. To evaluate our models, we run two distinct human\nannotation experiments, and find that both approaches (indicator based and\nneural) outperforms commonly used readability and comprehension metrics such as\nFKGL and SAMSA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tardy_P/0/1/0/all/0/1\">Paul Tardy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roze_C/0/1/0/all/0/1\">Charlotte Roze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poupet_P/0/1/0/all/0/1\">Paul Poupet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Study and Framework for Automated Summariser Evaluation: LangChain and Hybrid Algorithms. (arXiv:2310.02759v1 [cs.LG])","link":"http://arxiv.org/abs/2310.02759","description":"<p>Automated Essay Score (AES) is proven to be one of the cutting-edge\ntechnologies. Scoring techniques are used for various purposes. Reliable scores\nare calculated based on influential variables. Such variables can be computed\nby different methods based on the domain. The research is concentrated on the\nuser's understanding of a given topic. The analysis is based on a scoring index\nby using Large Language Models. The user can then compare and contrast the\nunderstanding of a topic that they recently learned. The results are then\ncontributed towards learning analytics and progression is made for enhancing\nthe learning ability. In this research, the focus is on summarizing a PDF\ndocument and gauging a user's understanding of its content. The process\ninvolves utilizing a Langchain tool to summarize the PDF and extract the\nessential information. By employing this technique, the research aims to\ndetermine how well the user comprehends the summarized content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+S_B/0/1/0/all/0/1\">Bagiya Lakshmi S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_S/0/1/0/all/0/1\">Sanjjushri Varshini R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadevan_R/0/1/0/all/0/1\">Rohith Mahadevan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_R/0/1/0/all/0/1\">Raja CSP Raman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Role of Linguistic Priors in Measuring Compositional Generalization of Vision-Language Models. (arXiv:2310.02777v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02777","description":"<p>Compositionality is a common property in many modalities including natural\nlanguages and images, but the compositional generalization of multi-modal\nmodels is not well-understood. In this paper, we identify two sources of\nvisual-linguistic compositionality: linguistic priors and the interplay between\nimages and texts. We show that current attempts to improve compositional\ngeneralization rely on linguistic priors rather than on information in the\nimage. We also propose a new metric for compositionality without such\nlinguistic priors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Li Erran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1\">Stefano Ermon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffner_P/0/1/0/all/0/1\">Patrick Haffner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1\">Rong Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zaiwei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A UMLS-Augmented Framework for Improving Factuality in Large Language Models within Healthcare. (arXiv:2310.02778v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02778","description":"<p>Large language models (LLMs) have demonstrated powerful text generation\ncapabilities, bringing unprecedented innovation to the healthcare field. While\nLLMs hold immense promise for applications in healthcare, applying them to real\nclinical scenarios presents significant challenges, as these models may\ngenerate content that deviates from established medical facts and even exhibit\npotential biases. In our research, we develop an augmented LLM framework based\non the Unified Medical Language System (UMLS), aiming to better serve the\nhealthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our\nbenchmark models, and conduct automatic evaluations using the ROUGE Score and\nBERTScore on 104 questions from the LiveQA test set. Additionally, we establish\ncriteria for physician-evaluation based on four dimensions: Factuality,\nCompleteness, Readability and Relevancy. ChatGPT-3.5 is used for physician\nevaluation with 20 questions on the LiveQA test set. Multiple resident\nphysicians conducted blind reviews to evaluate the generated content, and the\nresults indicate that this framework effectively enhances the factuality,\ncompleteness, and relevance of generated content. Our research demonstrates the\neffectiveness of using UMLS-augmented LLMs and highlights the potential\napplication value of LLMs in in medical question-answering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Rui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marrese_Taylor_E/0/1/0/all/0/1\">Edison Marrese-Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_Y/0/1/0/all/0/1\">Yuhe Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lechao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Low Resource Summarization using Pre-trained Language Models. (arXiv:2310.02790v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02790","description":"<p>With the advent of Deep Learning based Artificial Neural Networks models,\nNatural Language Processing (NLP) has witnessed significant improvements in\ntextual data processing in terms of its efficiency and accuracy. However, the\nresearch is mostly restricted to high-resource languages such as English and\nlow-resource languages still suffer from a lack of available resources in terms\nof training datasets as well as models with even baseline evaluation results.\nConsidering the limited availability of resources for low-resource languages,\nwe propose a methodology for adapting self-attentive transformer-based\narchitecture models (mBERT, mT5) for low-resource summarization, supplemented\nby the construction of a new baseline dataset (76.5k article, summary pairs) in\na low-resource language Urdu. Choosing news (a publicly available source) as\nthe application domain has the potential to make the proposed methodology\nuseful for reproducing in other languages with limited resources. Our adapted\nsummarization model \\textit{urT5} with up to 44.78\\% reduction in size as\ncompared to \\textit{mT5} can capture contextual information of low resource\nlanguage effectively with evaluation score (up to 46.35 ROUGE-1, 77 BERTScore)\nat par with state-of-the-art models in high resource language English\n\\textit{(PEGASUS: 47.21, BART: 45.14 on XSUM Dataset)}. The proposed method\nprovided a baseline approach towards extractive as well as abstractive\nsummarization with competitive evaluation results in a limited resource setup.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Munaf_M/0/1/0/all/0/1\">Mubashir Munaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afzal_H/0/1/0/all/0/1\">Hammad Afzal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iltaf_N/0/1/0/all/0/1\">Naima Iltaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1\">Khawir Mahmood</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DOMINO: A Dual-System for Multi-step Visual Language Reasoning. (arXiv:2310.02804v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02804","description":"<p>Visual language reasoning requires a system to extract text or numbers from\ninformation-dense images like charts or plots and perform logical or arithmetic\nreasoning to arrive at an answer. To tackle this task, existing work relies on\neither (1) an end-to-end vision-language model trained on a large amount of\ndata, or (2) a two-stage pipeline where a captioning model converts the image\ninto text that is further read by another large language model to deduce the\nanswer. However, the former approach forces the model to answer a complex\nquestion with one single step, and the latter approach is prone to inaccurate\nor distracting information in the converted text that can confuse the language\nmodel. In this work, we propose a dual-system for multi-step multimodal\nreasoning, which consists of a \"System-1\" step for visual information\nextraction and a \"System-2\" step for deliberate reasoning. Given an input,\nSystem-2 breaks down the question into atomic sub-steps, each guiding System-1\nto extract the information required for reasoning from the image. Experiments\non chart and plot datasets show that our method with a pre-trained System-2\nmodule performs competitively compared to prior work on in- and\nout-of-distribution data. By fine-tuning the System-2 module (LLaMA-2 70B) on\nonly a small amount of data on multi-step reasoning, the accuracy of our method\nis further improved and surpasses the best fully-supervised end-to-end approach\nby 5.7% and a pipeline approach with FlanPaLM (540B) by 7.5% on a challenging\ndataset with human-authored questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peifang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golovneva_O/0/1/0/all/0/1\">Olga Golovneva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_Zarandi_M/0/1/0/all/0/1\">Maryam Fazel-Zarandi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02842","description":"<p>Large Language Models (LLMs) have the ability to solve a variety of tasks,\nsuch as text summarization and mathematical questions, just out of the box, but\nthey are often trained with a single task in mind. Due to high computational\ncosts, the current trend is to use prompt instruction tuning to better adjust\nmonolithic, pretrained LLMs for new -- but often individual -- downstream\ntasks. Thus, how one would expand prompt tuning to handle -- concomitantly --\nheterogeneous tasks and data distributions is a widely open question. To\naddress this gap, we suggest the use of \\emph{Mixture of Prompts}, or MoPs,\nassociated with smart gating functionality: the latter -- whose design is one\nof the contributions of this paper -- can identify relevant skills embedded in\ndifferent groups of prompts and dynamically assign combined experts (i.e.,\ncollection of prompts), based on the target task. Additionally, MoPs are\nempirically agnostic to any model compression technique applied -- for\nefficiency reasons -- as well as instruction data source and task composition.\nIn practice, MoPs can simultaneously mitigate prompt training \"interference\" in\nmulti-task, multi-source scenarios (e.g., task and data heterogeneity across\nsources), as well as possible implications from model approximations. As a\nhighlight, MoPs manage to decrease final perplexity from $\\sim20\\%$ up to\n$\\sim70\\%$, as compared to baselines, in the federated scenario, and from $\\sim\n3\\%$ up to $\\sim30\\%$ in the centralized scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_M/0/1/0/all/0/1\">Mirian Del Carmen Hipolito Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hate Speech Detection in Limited Data Contexts using Synthetic Data Generation. (arXiv:2310.02876v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02876","description":"<p>A growing body of work has focused on text classification methods for\ndetecting the increasing amount of hate speech posted online. This progress has\nbeen limited to only a select number of highly-resourced languages causing\ndetection systems to either under-perform or not exist in limited data\ncontexts. This is majorly caused by a lack of training data which is expensive\nto collect and curate in these settings. In this work, we propose a data\naugmentation approach that addresses the problem of lack of data for online\nhate speech detection in limited data contexts using synthetic data generation\ntechniques. Given a handful of hate speech examples in a high-resource language\nsuch as English, we present three methods to synthesize new examples of hate\nspeech data in a target language that retains the hate sentiment in the\noriginal examples but transfers the hate targets. We apply our approach to\ngenerate training data for hate speech classification tasks in Hindi and\nVietnamese. Our findings show that a model trained on synthetic data performs\ncomparably to, and in some cases outperforms, a model trained only on the\nsamples available in the target domain. This method can be adopted to bootstrap\nhate speech detection models from scratch in limited data contexts. As the\ngrowth of social media within these contexts continues to outstrip response\nefforts, this work furthers our capacities for detection, understanding, and\nresponse to hate speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khullar_A/0/1/0/all/0/1\">Aman Khullar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nkemelu_D/0/1/0/all/0/1\">Daniel Nkemelu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cuong V. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Best_M/0/1/0/all/0/1\">Michael L. Best</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Use Your INSTINCT: INSTruction optimization usIng Neural bandits Coupled with Transformers. (arXiv:2310.02905v1 [cs.LG])","link":"http://arxiv.org/abs/2310.02905","description":"<p>Large language models (LLMs) have shown remarkable instruction-following\ncapabilities and achieved impressive performances in various applications.\nHowever, the performances of LLMs depend heavily on the instructions given to\nthem, which are typically manually tuned with substantial human efforts. Recent\nwork has used the query-efficient Bayesian optimization (BO) algorithm to\nautomatically optimize the instructions given to black-box LLMs. However, BO\nusually falls short when optimizing highly sophisticated (e.g.,\nhigh-dimensional) objective functions, such as the functions mapping an\ninstruction to the performance of an LLM. This is mainly due to the limited\nexpressive power of the Gaussian process (GP) model which is used by BO as a\nsurrogate to model the objective function. Meanwhile, it has been repeatedly\nshown that neural networks (NNs), especially pre-trained transformers, possess\nstrong expressive power and can model highly complex functions. So, we adopt a\nneural bandit algorithm which replaces the GP in BO by an NN surrogate to\noptimize instructions for black-box LLMs. More importantly, the neural bandit\nalgorithm allows us to naturally couple the NN surrogate with the hidden\nrepresentation learned by a pre-trained transformer (i.e., an open-source LLM),\nwhich significantly boosts its performance. These motivate us to propose our\nINSTruction optimization usIng Neural bandits Coupled with Transformers}\n(INSTINCT) algorithm. We perform instruction optimization for ChatGPT and use\nextensive experiments to show that our INSTINCT consistently outperforms the\nexisting methods in different tasks, such as in various instruction induction\ntasks and the task of improving the zero-shot chain-of-thought instruction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xiaoqiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaoxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zhongxiang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenyang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yao Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_S/0/1/0/all/0/1\">See-Kiong Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaillet_P/0/1/0/all/0/1\">Patrick Jaillet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Low_B/0/1/0/all/0/1\">Bryan Kian Hsiang Low</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing Large Language Models on Climate Information. (arXiv:2310.02932v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02932","description":"<p>Understanding how climate change affects us and learning about available\nsolutions are key steps toward empowering individuals and communities to\nmitigate and adapt to it. As Large Language Models (LLMs) rise in popularity,\nit is necessary to assess their capability in this domain. In this study, we\npresent a comprehensive evaluation framework, grounded in science communication\nprinciples, to analyze LLM responses to climate change topics. Our framework\nemphasizes both the presentational and epistemological adequacy of answers,\noffering a fine-grained analysis of LLM generations. Spanning 8 dimensions, our\nframework discerns up to 30 distinct issues in model outputs. The task is a\nreal-world example of a growing number of challenging problems where AI can\ncomplement and lift human performance. We introduce a novel and practical\nprotocol for scalable oversight that uses AI Assistance and relies on raters\nwith relevant educational backgrounds. We evaluate several recent LLMs and\nconduct a comprehensive analysis of the results, shedding light on both the\npotential and the limitations of LLMs in the realm of climate communication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bulian_J/0/1/0/all/0/1\">Jannis Bulian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schafer_M/0/1/0/all/0/1\">Mike S. Sch&#xe4;fer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Afra Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_H/0/1/0/all/0/1\">Heidi Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ciaramita_M/0/1/0/all/0/1\">Massimiliano Ciaramita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaiarin_B/0/1/0/all/0/1\">Ben Gaiarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huebscher_M/0/1/0/all/0/1\">Michelle Chen Huebscher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buck_C/0/1/0/all/0/1\">Christian Buck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mede_N/0/1/0/all/0/1\">Niels Mede</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leippold_M/0/1/0/all/0/1\">Markus Leippold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strauss_N/0/1/0/all/0/1\">Nadine Strauss</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LibriSpeech-PC: Benchmark for Evaluation of Punctuation and Capitalization Capabilities of end-to-end ASR Models. (arXiv:2310.02943v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02943","description":"<p>Traditional automatic speech recognition (ASR) models output lower-cased\nwords without punctuation marks, which reduces readability and necessitates a\nsubsequent text processing model to convert ASR transcripts into a proper\nformat. Simultaneously, the development of end-to-end ASR models capable of\npredicting punctuation and capitalization presents several challenges,\nprimarily due to limited data availability and shortcomings in the existing\nevaluation methods, such as inadequate assessment of punctuation prediction. In\nthis paper, we introduce a LibriSpeech-PC benchmark designed to assess the\npunctuation and capitalization prediction capabilities of end-to-end ASR\nmodels. The benchmark includes a LibriSpeech-PC dataset with restored\npunctuation and capitalization, a novel evaluation metric called Punctuation\nError Rate (PER) that focuses on punctuation marks, and initial baseline\nmodels. All code, data, and models are publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meister_A/0/1/0/all/0/1\">Aleksandr Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novikov_M/0/1/0/all/0/1\">Matvei Novikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karpov_N/0/1/0/all/0/1\">Nikolay Karpov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakhturina_E/0/1/0/all/0/1\">Evelina Bakhturina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavrukhin_V/0/1/0/all/0/1\">Vitaly Lavrukhin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shadow Alignment: The Ease of Subverting Safely-Aligned Language Models. (arXiv:2310.02949v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02949","description":"<p>Warning: This paper contains examples of harmful language, and reader\ndiscretion is recommended. The increasing open release of powerful large\nlanguage models (LLMs) has facilitated the development of downstream\napplications by reducing the essential cost of data annotation and computation.\nTo ensure AI safety, extensive safety-alignment measures have been conducted to\narmor these models against malicious use (primarily hard prompt attack).\nHowever, beneath the seemingly resilient facade of the armor, there might lurk\na shadow. By simply tuning on 100 malicious examples with 1 GPU hour, these\nsafely aligned LLMs can be easily subverted to generate harmful content.\nFormally, we term a new attack as Shadow Alignment: utilizing a tiny amount of\ndata can elicit safely-aligned models to adapt to harmful tasks without\nsacrificing model helpfulness. Remarkably, the subverted models retain their\ncapability to respond appropriately to regular inquiries. Experiments across 8\nmodels released by 5 different organizations (LLaMa-2, Falcon, InternLM,\nBaiChuan2, Vicuna) demonstrate the effectiveness of shadow alignment attack.\nBesides, the single-turn English-only attack successfully transfers to\nmulti-turn dialogue and other languages. This study serves as a clarion call\nfor a collective effort to overhaul and fortify the safety of open-source LLMs\nagainst malicious attackers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petzold_L/0/1/0/all/0/1\">Linda Petzold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"JsonTuning: Towards Generalizable, Robust, and Controllable Instruction Tuning. (arXiv:2310.02953v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02953","description":"<p>Instruction tuning has emerged as a crucial process for harnessing the\ncapabilities of large language models (LLMs) by providing explicit task\ninstructions, leading to improved performance in various tasks. However,\nprevalent text-to-text instruction tuning (TextTuning) methods suffer from\nlimitations in generalization, robustness, and controllability due to the\nambiguity and lack of explicit structure in tasks. In this paper, we propose\nJsonTuning, a novel structure-to-structure approach for instruction tuning. By\nleveraging the versatility and structured nature of JSON to represent tasks,\nJsonTuning enhances generalization by helping the model understand essential\ntask elements and their relations, improves robustness by minimizing ambiguity,\nand increases controllability by providing explicit control over the output. We\nconduct a comprehensive comparative study with diverse language models and\nevaluation benchmarks. Experimental results show that JsonTuning outperforms\nTextTuning in various applications, showcasing improved performance,\nadaptability, robustness, and controllability. By overcoming the limitations of\nTextTuning, JsonTuning demonstrates significant potential for more effective\nand reliable LLMs capable of handling diverse scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guizhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning. (arXiv:2310.02954v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02954","description":"<p>Recent advances in natural language processing, primarily propelled by Large\nLanguage Models (LLMs), have showcased their remarkable capabilities grounded\nin in-context learning. A promising avenue for guiding LLMs in intricate\nreasoning tasks involves the utilization of intermediate reasoning steps within\nthe Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies\nin the effective selection of exemplars for facilitating in-context learning.\nIn this study, we introduce a framework that leverages Dual Queries and\nLow-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars\nfor in-context learning. Dual Queries first query LLM to obtain LLM-generated\nknowledge such as CoT, then query the retriever to obtain the final exemplars\nvia both question and the knowledge. Moreover, for the second query, LoRe\nemploys dimensionality reduction techniques to refine exemplar selection,\nensuring close alignment with the input question's knowledge. Through extensive\nexperiments, we demonstrate that DQ-LoRe significantly outperforms prior\nstate-of-the-art methods in the automatic selection of exemplars for GPT-4,\nenhancing performance from 92.5\\% to 94.2\\%. Our comprehensive analysis further\nreveals that DQ-LoRe consistently outperforms retrieval-based approaches in\nterms of both performance and adaptability, especially in scenarios\ncharacterized by distribution shifts. DQ-LoRe pushes the boundaries of\nin-context learning and opens up new avenues for addressing complex reasoning\nchallenges. We will release the code soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jiong Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chuanyang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yichun Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhicheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingxing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiongwei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jing Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech Model. (arXiv:2310.02971v1 [eess.AS])","link":"http://arxiv.org/abs/2310.02971","description":"<p>Prompting and adapter tuning have emerged as efficient alternatives to\nfine-tuning (FT) methods. However, existing studies on speech prompting focused\non classification tasks and failed on more complex sequence generation tasks.\nBesides, adapter tuning is primarily applied with a focus on encoder-only\nself-supervised models. Our experiments show that prompting on Wav2Seq, a\nself-supervised encoder-decoder model, surpasses previous works in sequence\ngeneration tasks. It achieves a remarkable 53% relative improvement in word\nerror rate for ASR and a 27% in F1 score for slot filling. Additionally,\nprompting competes with the FT method in the low-resource scenario. Moreover,\nwe show the transferability of prompting and adapter tuning on Wav2Seq in\ncross-lingual ASR. When limited trainable parameters are involved, prompting\nand adapter tuning consistently outperform conventional FT across 7 languages.\nNotably, in the low-resource scenario, prompting consistently outperforms\nadapter tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Ming-Hsin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_Y/0/1/0/all/0/1\">Yun-Ping Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_J/0/1/0/all/0/1\">Jing Neng Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1\">Paul Kuo-Ming Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1\">Chien-yu Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network. (arXiv:2310.02973v1 [cs.CL])","link":"http://arxiv.org/abs/2310.02973","description":"<p>Recent studies have demonstrated promising outcomes by employing large\nlanguage models with multi-tasking capabilities. They utilize prompts to guide\nthe model's behavior and surpass performance of task-specific models. Motivated\nby this, we ask: can we build a single model that jointly perform various\nspoken language understanding (SLU) tasks? To address this, we utilize\npre-trained automatic speech recognition (ASR) models and employ various task\nand dataset specifiers as discrete prompts. We demonstrate efficacy of our\nsingle multi-task learning (MTL) model \"UniverSLU\" for 12 different speech\nclassification and sequence generation tasks across 17 datasets and 9\nlanguages. Results show that UniverSLU achieves competitive performance and\neven surpasses task-specific models. We also conduct preliminary investigations\ninto enabling human-interpretable natural phrases instead of task specifiers as\ndiscrete prompts and test the model's generalization capabilities to new\nparaphrases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Siddhant Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futami_H/0/1/0/all/0/1\">Hayato Futami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jee-weon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Roshan Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashiwagi_Y/0/1/0/all/0/1\">Yosuke Kashiwagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsunoo_E/0/1/0/all/0/1\">Emiru Tsunoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation. (arXiv:2310.02977v1 [cs.CV])","link":"http://arxiv.org/abs/2310.02977","description":"<p>Recent methods in text-to-3D leverage powerful pretrained diffusion models to\noptimize NeRF. Notably, these methods are able to produce high-quality 3D\nscenes without training on 3D data. Due to the open-ended nature of the task,\nmost studies evaluate their results with subjective case studies and user\nexperiments, thereby presenting a challenge in quantitatively addressing the\nquestion: How has current progress in Text-to-3D gone so far? In this paper, we\nintroduce T$^3$Bench, the first comprehensive text-to-3D benchmark containing\ndiverse text prompts of three increasing complexity levels that are specially\ndesigned for 3D generation. To assess both the subjective quality and the text\nalignment, we propose two automatic metrics based on multi-view images produced\nby the 3D contents. The quality metric combines multi-view text-image scores\nand regional convolution to detect quality and view inconsistency. The\nalignment metric uses multi-view captioning and Large Language Model (LLM)\nevaluation to measure text-3D consistency. Both metrics closely correlate with\ndifferent dimensions of human judgments, providing a paradigm for efficiently\nevaluating text-to-3D models. The benchmarking results, shown in Fig. 1, reveal\nperformance differences among six prevalent text-to-3D methods. Our analysis\nfurther highlights the common struggles for current methods on generating\nsurroundings and multi-object scenes, as well as the bottleneck of leveraging\n2D guidance for 3D generation. Our project page is available at:\nhttps://t3bench.com.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuze He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yushi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Matthieu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yubin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_J/0/1/0/all/0/1\">Jenny Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_R/0/1/0/all/0/1\">Ran Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong-Jin Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors. (arXiv:2310.02980v1 [cs.LG])","link":"http://arxiv.org/abs/2310.02980","description":"<p>Modeling long-range dependencies across sequences is a longstanding goal in\nmachine learning and has led to architectures, such as state space models, that\ndramatically outperform Transformers on long sequences. However, these\nimpressive empirical gains have been by and large demonstrated on benchmarks\n(e.g. Long Range Arena), where models are randomly initialized and trained to\npredict a target label from an input sequence. In this work, we show that\nrandom initialization leads to gross overestimation of the differences between\narchitectures and that pretraining with standard denoising objectives, using\n$\\textit{only the downstream task data}$, leads to dramatic gains across\nmultiple architectures and to very small gaps between Transformers and state\nspace models (SSMs). In stark contrast to prior works, we find vanilla\nTransformers to match the performance of S4 on Long Range Arena when properly\npretrained, and we improve the best reported results of SSMs on the PathX-256\ntask by 20 absolute points. Subsequently, we analyze the utility of\npreviously-proposed structured parameterizations for SSMs and show they become\nmostly redundant in the presence of data-driven initialization obtained through\npretraining. Our work shows that, when evaluating different architectures on\nsupervised tasks, incorporation of data-driven priors via pretraining is\nessential for reliable performance estimation, and can be done efficiently.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amos_I/0/1/0/all/0/1\">Ido Amos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankit Gupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Laws for Associative Memories. (arXiv:2310.02984v1 [stat.ML])","link":"http://arxiv.org/abs/2310.02984","description":"<p>Learning arguably involves the discovery and memorization of abstract rules.\nThe aim of this paper is to study associative memory mechanisms. Our model is\nbased on high-dimensional matrices consisting of outer products of embeddings,\nwhich relates to the inner layers of transformer language models. We derive\nprecise scaling laws with respect to sample size and parameter size, and\ndiscuss the statistical efficiency of different estimators, including\noptimization-based algorithms. We provide extensive numerical experiments to\nvalidate and interpret theoretical results, including fine-grained\nvisualizations of the stored memory associations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1\">Vivien Cabannes</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Dohmatob_E/0/1/0/all/0/1\">Elvis Dohmatob</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"xVal: A Continuous Number Encoding for Large Language Models. (arXiv:2310.02989v1 [stat.ML])","link":"http://arxiv.org/abs/2310.02989","description":"<p>Large Language Models have not yet been broadly adapted for the analysis of\nscientific datasets due in part to the unique difficulties of tokenizing\nnumbers. We propose xVal, a numerical encoding scheme that represents any real\nnumber using just a single token. xVal represents a given real number by\nscaling a dedicated embedding vector by the number value. Combined with a\nmodified number-inference approach, this strategy renders the model end-to-end\ncontinuous when considered as a map from the numbers of the input string to\nthose of the output string. This leads to an inductive bias that is generally\nmore suitable for applications in scientific domains. We empirically evaluate\nour proposal on a number of synthetic and real-world datasets. Compared with\nexisting number encoding schemes, we find that xVal is more token-efficient and\ndemonstrates improved generalization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Golkar_S/0/1/0/all/0/1\">Siavash Golkar</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Pettee_M/0/1/0/all/0/1\">Mariel Pettee</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eickenberg_M/0/1/0/all/0/1\">Michael Eickenberg</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1\">Alberto Bietti</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cranmer_M/0/1/0/all/0/1\">Miles Cranmer</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Krawezik_G/0/1/0/all/0/1\">Geraud Krawezik</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Lanusse_F/0/1/0/all/0/1\">Francois Lanusse</a>, <a href=\"http://arxiv.org/find/stat/1/au:+McCabe_M/0/1/0/all/0/1\">Michael McCabe</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ohana_R/0/1/0/all/0/1\">Ruben Ohana</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Parker_L/0/1/0/all/0/1\">Liam Parker</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Blancard_B/0/1/0/all/0/1\">Bruno R&#xe9;galdo-Saint Blancard</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Tesileanu_T/0/1/0/all/0/1\">Tiberiu Tesileanu</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ho_S/0/1/0/all/0/1\">Shirley Ho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Kosmos-G: Generating Images in Context with Multimodal Large Language Models. (arXiv:2310.02992v1 [cs.CV])","link":"http://arxiv.org/abs/2310.02992","description":"<p>Recent advancements in text-to-image (T2I) and vision-language-to-image\n(VL2I) generation have made significant strides. However, the generation from\ngeneralized vision-language inputs, especially involving multiple images,\nremains under-explored. This paper presents Kosmos-G, a model that leverages\nthe advanced perception capabilities of Multimodal Large Language Models\n(MLLMs) to tackle the aforementioned challenge. Our approach aligns the output\nspace of MLLM with CLIP using the textual modality as an anchor and performs\ncompositional instruction tuning on curated data. Kosmos-G demonstrates a\nunique capability of zero-shot multi-entity subject-driven generation. Notably,\nthe score distillation instruction tuning requires no modifications to the\nimage decoder. This allows for a seamless substitution of CLIP and effortless\nintegration with a myriad of U-Net techniques ranging from fine-grained\ncontrols to personalized image decoder variants. We posit Kosmos-G as an\ninitial attempt towards the goal of \"image as a foreign language in image\ngeneration.\"\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xichen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1\">Zhiliang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language Models. (arXiv:2310.02998v1 [cs.CV])","link":"http://arxiv.org/abs/2310.02998","description":"<p>Large Vision-Language Models (LVLMs) can understand the world comprehensively\nby integrating rich information from different modalities, achieving remarkable\nperformance improvements on various multimodal downstream tasks. However,\ndeploying LVLMs is often problematic due to their massive computational/energy\ncosts and carbon consumption. Such issues make it infeasible to adopt\nconventional iterative global pruning, which is costly due to computing the\nHessian matrix of the entire large model for sparsification. Alternatively,\nseveral studies have recently proposed layer-wise pruning approaches to avoid\nthe expensive computation of global pruning and efficiently compress model\nweights according to their importance within a layer. However, these methods\noften suffer from suboptimal model compression due to their lack of a global\nperspective. To address this limitation in recent efficient pruning methods for\nlarge models, we propose Efficient Coarse-to-Fine Layer-Wise Pruning (ECoFLaP),\na two-stage coarse-to-fine weight pruning approach for LVLMs. We first\ndetermine the sparsity ratios of different layers or blocks by leveraging the\nglobal importance score, which is efficiently computed based on the\nzeroth-order approximation of the global model gradients. Then, the multimodal\nmodel performs local layer-wise unstructured weight pruning based on\nglobally-informed sparsity ratios. We validate our proposed method across\nvarious multimodal and unimodal models and datasets, demonstrating significant\nperformance improvements over prevalent pruning techniques in the high-sparsity\nregime.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yi-Lin Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Jaehong Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Words to Watts: Benchmarking the Energy Costs of Large Language Model Inference. (arXiv:2310.03003v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03003","description":"<p>Large language models (LLMs) have exploded in popularity due to their new\ngenerative capabilities that go far beyond prior state-of-the-art. These\ntechnologies are increasingly being leveraged in various domains such as law,\nfinance, and medicine. However, these models carry significant computational\nchallenges, especially the compute and energy costs required for inference.\nInference energy costs already receive less attention than the energy costs of\ntraining LLMs -- despite how often these large models are called on to conduct\ninference in reality (e.g., ChatGPT). As these state-of-the-art LLMs see\nincreasing usage and deployment in various domains, a better understanding of\ntheir resource utilization is crucial for cost-savings, scaling performance,\nefficient hardware usage, and optimal inference strategies.\n</p>\n<p>In this paper, we describe experiments conducted to study the computational\nand energy utilization of inference with LLMs. We benchmark and conduct a\npreliminary analysis of the inference performance and inference energy costs of\ndifferent sizes of LLaMA -- a recent state-of-the-art LLM -- developed by Meta\nAI on two generations of popular GPUs (NVIDIA V100 \\&amp; A100) and two datasets\n(Alpaca and GSM8K) to reflect the diverse set of tasks/benchmarks for LLMs in\nresearch and practice. We present the results of multi-node, multi-GPU\ninference using model sharding across up to 32 GPUs. To our knowledge, our work\nis the one of the first to study LLM inference performance from the perspective\nof computational and energy resources at this scale.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Samsi_S/0/1/0/all/0/1\">Siddharth Samsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDonald_J/0/1/0/all/0/1\">Joseph McDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baolin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaleas_A/0/1/0/all/0/1\">Adam Michaleas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Michael Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergeron_W/0/1/0/all/0/1\">William Bergeron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kepner_J/0/1/0/all/0/1\">Jeremy Kepner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_D/0/1/0/all/0/1\">Devesh Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadepally_V/0/1/0/all/0/1\">Vijay Gadepally</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions. (arXiv:2310.03016v1 [cs.LG])","link":"http://arxiv.org/abs/2310.03016","description":"<p>In order to understand the in-context learning phenomenon, recent works have\nadopted a stylized experimental framework and demonstrated that Transformers\ncan learn gradient-based learning algorithms for various classes of real-valued\nfunctions. However, the limitations of Transformers in implementing learning\nalgorithms, and their ability to learn other forms of algorithms are not well\nunderstood. Additionally, the degree to which these capabilities are confined\nto attention-based models is unclear. Furthermore, it remains to be seen\nwhether the insights derived from these stylized settings can be extrapolated\nto pretrained Large Language Models (LLMs). In this work, we take a step\ntowards answering these questions by demonstrating the following: (a) On a\ntest-bed with a variety of Boolean function classes, we find that Transformers\ncan nearly match the optimal learning algorithm for 'simpler' tasks, while\ntheir performance deteriorates on more 'complex' tasks. Additionally, we find\nthat certain attention-free models perform (almost) identically to Transformers\non a range of tasks. (b) When provided a teaching sequence, i.e. a set of\nexamples that uniquely identifies a function in a class, we show that\nTransformers learn more sample-efficiently. Interestingly, our results show\nthat Transformers can learn to implement two distinct algorithms to solve a\nsingle task, and can adaptively select the more sample-efficient algorithm\ndepending on the sequence of in-context examples. (c) Lastly, we show that\nextant LLMs, e.g. LLaMA-2, GPT-4, can compete with nearest-neighbor baselines\non prediction tasks that are guaranteed to not be in their training set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattamishra_S/0/1/0/all/0/1\">Satwik Bhattamishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1\">Arkil Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1\">Phil Blunsom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanade_V/0/1/0/all/0/1\">Varun Kanade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Question Answering for Unified Information Extraction. (arXiv:2310.03017v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03017","description":"<p>Multimodal information extraction (MIE) aims to extract structured\ninformation from unstructured multimedia content. Due to the diversity of tasks\nand settings, most current MIE models are task-specific and data-intensive,\nwhich limits their generalization to real-world scenarios with diverse task\nrequirements and limited labeled data. To address these issues, we propose a\nnovel multimodal question answering (MQA) framework to unify three MIE tasks by\nreformulating them into a unified span extraction and multi-choice QA pipeline.\nExtensive experiments on six datasets show that: 1) Our MQA framework\nconsistently and significantly improves the performances of various\noff-the-shelf large multimodal models (LMM) on MIE tasks, compared to vanilla\nprompting. 2) In the zero-shot setting, MQA outperforms previous\nstate-of-the-art baselines by a large margin. In addition, the effectiveness of\nour framework can successfully transfer to the few-shot setting, enhancing LMMs\non a scale of 10B parameters to be competitive or outperform much larger\nlanguage models such as ChatGPT and GPT-4. Our MQA framework can serve as a\ngeneral principle of utilizing LMMs to better solve MIE and potentially other\ndownstream multimodal tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yuxuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero Resource Code-switched Speech Benchmark Using Speech Utterance Pairs For Multiple Spoken Languages. (arXiv:2310.03018v1 [eess.AS])","link":"http://arxiv.org/abs/2310.03018","description":"<p>We introduce a new zero resource code-switched speech benchmark designed to\ndirectly assess the code-switching capabilities of self-supervised speech\nencoders. We showcase a baseline system of language modeling on discrete units\nto demonstrate how the code-switching abilities of speech encoders can be\nassessed in a zero-resource manner. Our experiments encompass a variety of\nwell-known speech encoders, including Wav2vec 2.0, HuBERT, XLSR, etc. We\nexamine the impact of pre-training languages and model size on benchmark\nperformance. Notably, though our results demonstrate that speech encoders with\nmultilingual pre-training, exemplified by XLSR, outperform monolingual variants\n(Wav2vec 2.0, HuBERT) in code-switching scenarios, there is still substantial\nroom for improvement in their code-switching linguistic abilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Po Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1\">Chih-Kai Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fu_Y/0/1/0/all/0/1\">Yu-Kuan Fu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Dunbar_E/0/1/0/all/0/1\">Ewan Dunbar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Sense per Translation. (arXiv:2106.06082v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.06082","description":"<p>Word sense disambiguation (WSD) is the task of determining the sense of a\nword in context. Translations have been used in WSD as a source of knowledge,\nand even as a means of delimiting word senses. In this paper, we define three\ntheoretical properties of the relationship between senses and translations, and\nargue that they constitute necessary conditions for using translations as sense\ninventories. The key property of One Sense per Translation (OSPT) provides a\nfoundation for a translation-based WSD method. The results of an intrinsic\nevaluation experiment indicate that our method achieves a precision of\napproximately 93% compared to manual corpus annotations. Our extrinsic\nevaluation experiments demonstrate WSD improvements of up to 4.6% F1-score on\ndifficult WSD datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Clipping: Differentially Private Deep Learning Made Easier and Stronger. (arXiv:2206.07136v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2206.07136","description":"<p>Per-example gradient clipping is a key algorithmic step that enables\npractical differential private (DP) training for deep learning models. The\nchoice of clipping threshold R, however, is vital for achieving high accuracy\nunder DP. We propose an easy-to-use replacement, called automatic clipping,\nthat eliminates the need to tune R for any DP optimizers, including DP-SGD,\nDP-Adam, DP-LAMB and many others. The automatic variants are as private and\ncomputationally efficient as existing DP optimizers, but require no DP-specific\nhyperparameters and thus make DP training as amenable as the standard\nnon-private training. We give a rigorous convergence analysis of automatic\nDP-SGD in the non-convex setting, showing that it can enjoy an asymptotic\nconvergence rate that matches the standard SGD, under a symmetric gradient\nnoise assumption of the per-sample gradients (commonly used in the non-DP\nliterature). We demonstrate on various language and vision tasks that automatic\nclipping outperforms or matches the state-of-the-art, and can be easily\nemployed with minimal changes to existing codebases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bu_Z/0/1/0/all/0/1\">Zhiqi Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_S/0/1/0/all/0/1\">Sheng Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">George Karypis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A comprehensive review of automatic text summarization techniques: method, data, evaluation and coding. (arXiv:2301.03403v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.03403","description":"<p>We provide a literature review about Automatic Text Summarization (ATS)\nsystems. We consider a citation-based approach. We start with some popular and\nwell-known papers that we have in hand about each topic we want to cover and we\nhave tracked the \"backward citations\" (papers that are cited by the set of\npapers we knew beforehand) and the \"forward citations\" (newer papers that cite\nthe set of papers we knew beforehand). In order to organize the different\nmethods, we present the diverse approaches to ATS guided by the mechanisms they\nuse to generate a summary. Besides presenting the methods, we also present an\nextensive review of the datasets available for summarization tasks and the\nmethods used to evaluate the quality of the summaries. Finally, we present an\nempirical exploration of these methods using the CNN Corpus dataset that\nprovides golden summaries for extractive and abstractive methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cajueiro_D/0/1/0/all/0/1\">Daniel O. Cajueiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nery_A/0/1/0/all/0/1\">Arthur G. Nery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavares_I/0/1/0/all/0/1\">Igor Tavares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_M/0/1/0/all/0/1\">Ma&#xed;sa K. De Melo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_S/0/1/0/all/0/1\">Silvia A. dos Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weigang_L/0/1/0/all/0/1\">Li Weigang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celestino_V/0/1/0/all/0/1\">Victor R. R. Celestino</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alternating Updates for Efficient Transformers. (arXiv:2301.13310v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.13310","description":"<p>It has been well established that increasing scale in deep transformer\nnetworks leads to improved quality and performance. However, this increase in\nscale often comes with prohibitive increases in compute cost and inference\nlatency. We introduce Alternating Updates (AltUp), a simple-to-implement method\nto increase a model's capacity without the computational burden. AltUp enables\nthe widening of the learned representation, i.e., the token embedding, while\nonly incurring a negligible increase in latency. AltUp achieves this by working\non a subblock of the widened representation at each layer and using a\npredict-and-correct mechanism to update the inactivated blocks. We present\nextensions of AltUp, such as its applicability to the sequence dimension, and\ndemonstrate how AltUp can be synergistically combined with existing approaches,\nsuch as Sparse Mixture-of-Experts models, to obtain efficient models with even\nhigher capacity. Our experiments on benchmark transformer models and language\ntasks demonstrate the consistent effectiveness of AltUp on a diverse set of\nscenarios. Notably, on SuperGLUE and SQuAD benchmarks, AltUp enables up to\n$87\\%$ speedup relative to the dense baselines at the same accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baykal_C/0/1/0/all/0/1\">Cenk Baykal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cutler_D/0/1/0/all/0/1\">Dylan Cutler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dikkala_N/0/1/0/all/0/1\">Nishanth Dikkala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_N/0/1/0/all/0/1\">Nikhil Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panigrahy_R/0/1/0/all/0/1\">Rina Panigrahy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Double Equivariance for Inductive Link Prediction for Both New Nodes and New Relation Types. (arXiv:2302.01313v6 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.01313","description":"<p>The task of inductive link prediction in discrete attributed multigraphs\n(e.g., knowledge graphs, multilayer networks, heterogeneous networks, etc.)\ngenerally focuses on test predictions with solely new nodes but not both new\nnodes and new relation types. In this work, we formally define the task of\npredicting (completely) new nodes and new relation types in test as a doubly\ninductive link prediction task and introduce a theoretical framework for the\nsolution. We start by defining the concept of double permutation-equivariant\nrepresentations that are equivariant to permutations of both node identities\nand edge relation types. We then propose a general blueprint to design neural\narchitectures that impose a structural representation of relations that can\ninductively generalize from training nodes and relations to arbitrarily new\ntest nodes and relations without the need for adaptation, side information, or\nretraining. We also introduce the concept of distributionally double\nequivariant positional embeddings designed to perform the same task. Finally,\nwe empirically demonstrate the capability of the two proposed models on a set\nof novel real-world benchmarks, showcasing average relative performance gains\nof $39.65\\%$ on predicting new relations types compared to baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jincheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Large-Scale Analysis of Persian Tweets Regarding Covid-19 Vaccination. (arXiv:2302.04511v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.04511","description":"<p>The Covid-19 pandemic had an enormous effect on our lives, especially on\npeople's interactions. By introducing Covid-19 vaccines, both positive and\nnegative opinions were raised over the subject of taking vaccines or not. In\nthis paper, using data gathered from Twitter, including tweets and user\nprofiles, we offer a comprehensive analysis of public opinion in Iran about the\nCoronavirus vaccines. For this purpose, we applied a search query technique\ncombined with a topic modeling approach to extract vaccine-related tweets. We\nutilized transformer-based models to classify the content of the tweets and\nextract themes revolving around vaccination. We also conducted an emotion\nanalysis to evaluate the public happiness and anger around this topic. Our\nresults demonstrate that Covid-19 vaccination has attracted considerable\nattention from different angles, such as governmental issues, safety or\nhesitancy, and side effects. Moreover, Coronavirus-relevant phenomena like\npublic vaccination and the rate of infection deeply impacted public emotional\nstatus and users' interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ShabaniMirzaei_T/0/1/0/all/0/1\">Taha ShabaniMirzaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chamani_H/0/1/0/all/0/1\">Houmaan Chamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abaskohi_A/0/1/0/all/0/1\">Amirhossein Abaskohi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zadeh_Z/0/1/0/all/0/1\">Zhivar Sourati Hassan Zadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahrak_B/0/1/0/all/0/1\">Behnam Bahrak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Technical report: Graph Neural Networks go Grammatical. (arXiv:2303.01590v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.01590","description":"<p>This paper introduces a framework for formally establishing a connection\nbetween a portion of an algebraic language and a Graph Neural Network (GNN).\nThe framework leverages Context-Free Grammars (CFG) to organize algebraic\noperations into generative rules that can be translated into a GNN layer model.\nAs CFGs derived directly from a language tend to contain redundancies in their\nrules and variables, we present a grammar reduction scheme. By applying this\nstrategy, we define a CFG that conforms to the third-order Weisfeiler-Lehman\n(3-WL) test using MATLANG. From this 3-WL CFG, we derive a GNN model, named\nG$^2$N$^2$, which is provably 3-WL compliant. Through various experiments, we\ndemonstrate the superior efficiency of G$^2$N$^2$ compared to other 3-WL GNNs\nacross numerous downstream tasks. Specifically, one experiment highlights the\nbenefits of grammar reduction within our framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Piquenot_J/0/1/0/all/0/1\">Jason Piquenot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moscatelli_A/0/1/0/all/0/1\">Aldo Moscatelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berar_M/0/1/0/all/0/1\">Maxime B&#xe9;rar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heroux_P/0/1/0/all/0/1\">Pierre H&#xe9;roux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+raveaux_R/0/1/0/all/0/1\">Romain raveaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramel_J/0/1/0/all/0/1\">Jean-Yves Ramel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adam_S/0/1/0/all/0/1\">S&#xe9;bastien Adam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personalize Segment Anything Model with One Shot. (arXiv:2305.03048v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.03048","description":"<p>Driven by large-data pre-training, Segment Anything Model (SAM) has been\ndemonstrated as a powerful and promptable framework, revolutionizing the\nsegmentation models. Despite the generality, customizing SAM for specific\nvisual concepts without man-powered prompting is under explored, e.g.,\nautomatically segmenting your pet dog in different images. In this paper, we\npropose a training-free Personalization approach for SAM, termed as PerSAM.\nGiven only a single image with a reference mask, PerSAM first localizes the\ntarget concept by a location prior, and segments it within other images or\nvideos via three techniques: target-guided attention, target-semantic\nprompting, and cascaded post-refinement. In this way, we effectively adapt SAM\nfor private use without any training. To further alleviate the mask ambiguity,\nwe present an efficient one-shot fine-tuning variant, PerSAM-F. Freezing the\nentire SAM, we introduce two learnable weights for multi-scale masks, only\ntraining 2 parameters within 10 seconds for improved performance. To\ndemonstrate our efficacy, we construct a new segmentation dataset, PerSeg, for\npersonalized evaluation, and test our methods on video object segmentation with\ncompetitive performance. Besides, our approach can also enhance DreamBooth to\npersonalize Stable Diffusion for text-to-image generation, which discards the\nbackground disturbance for better target appearance learning. Code is released\nat https://github.com/ZrrSkywalker/Personalize-SAM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Renrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengkai Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Ziyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shilin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junting Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xianzheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-supervised Neural Factor Analysis for Disentangling Utterance-level Speech Representations. (arXiv:2305.08099v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2305.08099","description":"<p>Self-supervised learning (SSL) speech models such as wav2vec and HuBERT have\ndemonstrated state-of-the-art performance on automatic speech recognition (ASR)\nand proved to be extremely useful in low label-resource settings. However, the\nsuccess of SSL models has yet to transfer to utterance-level tasks such as\nspeaker, emotion, and language recognition, which still require supervised\nfine-tuning of the SSL models to obtain good performance. We argue that the\nproblem is caused by the lack of disentangled representations and an\nutterance-level learning objective for these tasks. Inspired by how HuBERT uses\nclustering to discover hidden acoustic units, we formulate a factor analysis\n(FA) model that uses the discovered hidden acoustic units to align the SSL\nfeatures. The underlying utterance-level representations are disentangled from\nthe content of speech using probabilistic inference on the aligned features.\nFurthermore, the variational lower bound derived from the FA model provides an\nutterance-level objective, allowing error gradients to be backpropagated to the\nTransformer layers to learn highly discriminative acoustic units. When used in\nconjunction with HuBERT's masked prediction training, our models outperform the\ncurrent best model, WavLM, on all utterance-level non-semantic tasks on the\nSUPERB benchmark with only 20% of labeled data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weiwei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1\">Chenhang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mak_M/0/1/0/all/0/1\">Man-Wai Mak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Y/0/1/0/all/0/1\">Youzhi Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10276","description":"<p>In this paper, we take the initiative to investigate the performance of LLMs\non complex planning tasks that require LLMs to understand a virtual spatial\nenvironment simulated via natural language and act correspondingly in text. We\npropose a benchmark named Natural Language Planning and Action (Natala)\ncomposed of a set of novel tasks: Brick World, NLVR-based Manipulations, and\nNatural Language Navigation. We found that current popular LLMs such as ChatGPT\nstill lack abilities in complex planning. This arises a question -- do the LLMs\nhave a good understanding of the environments described in natural language, or\nmaybe other alternatives such as symbolic representations are neater and hence\nbetter to be understood by LLMs? To this end, we propose a novel method called\nCoS (Chain-of-Symbol Prompting) that represents the complex environments with\ncondensed symbolic spatial representations during the chained intermediate\nthinking steps. CoS is easy to use and does not need additional training on\nLLMs. Extensive experiments indicate that CoS clearly surpasses the performance\nof the Chain-of-Thought (CoT) Prompting in all three planning tasks with even\nfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.\nThe performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)\non Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt\nobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate\nsteps from demonstrations on Brick World. Code and data available at:\nhttps://github.com/hanxuhu/chain-of-symbol-planning\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanxu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huajian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yun-Ze Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Parameter-Efficient Learning Approach to Arabic Dialect Identification with Pre-Trained General-Purpose Speech Model. (arXiv:2305.11244v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11244","description":"<p>In this work, we explore Parameter-Efficient-Learning (PEL) techniques to\nrepurpose a General-Purpose-Speech (GSM) model for Arabic dialect\nidentification (ADI). Specifically, we investigate different setups to\nincorporate trainable features into a multi-layer encoder-decoder GSM\nformulation under frozen pre-trained settings. Our architecture includes\nresidual adapter and model reprogramming (input-prompting). We design a\ntoken-level label mapping to condition the GSM for Arabic Dialect\nIdentification (ADI). This is challenging due to the high variation in\nvocabulary and pronunciation among the numerous regional dialects. We achieve\nnew state-of-the-art accuracy on the ADI-17 dataset by vanilla fine-tuning. We\nfurther reduce the training budgets with the PEL method, which performs within\n1.86% accuracy to fine-tuning using only 2.5% of (extra) network trainable\nparameters. Our study demonstrates how to identify Arabic dialects using a\nsmall dataset and limited computation with open source code and pre-trained\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1\">Srijith Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sumeer Ahmad Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiani_N/0/1/0/all/0/1\">Narsis A. Kiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Cabrero_D/0/1/0/all/0/1\">David Gomez-Cabrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1\">Jesper N. Tegner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alt-Text with Context: Improving Accessibility for Images on Twitter. (arXiv:2305.14779v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.14779","description":"<p>In this work we present an approach for generating alternative text (or\nalt-text) descriptions for images shared on social media, specifically Twitter.\nMore than just a special case of image captioning, alt-text is both more\nliterally descriptive and context-specific. Also critically, images posted to\nTwitter are often accompanied by user-written text that despite not necessarily\ndescribing the image may provide useful context that if properly leveraged can\nbe informative. We address this task with a multimodal model that conditions on\nboth textual information from the associated social media post as well as\nvisual signal from the image, and demonstrate that the utility of these two\ninformation sources stacks. We put forward a new dataset of 371k images paired\nwith alt-text and tweets scraped from Twitter and evaluate on it across a\nvariety of automated metrics as well as human evaluation. We show that our\napproach of conditioning on both tweet text and visual information\nsignificantly outperforms prior work, by more than 2x on BLEU@4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srivatsan_N/0/1/0/all/0/1\">Nikita Srivatsan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samaniego_S/0/1/0/all/0/1\">Sofia Samaniego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florez_O/0/1/0/all/0/1\">Omar Florez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1\">Taylor Berg-Kirkpatrick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of GPT-Generated Text. (arXiv:2305.17359v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17359","description":"<p>Large language models (LLMs) have notably enhanced the fluency and diversity\nof machine-generated text. However, this progress also presents a significant\nchallenge in detecting the origin of a given text, and current research on\ndetection methods lags behind the rapid evolution of LLMs. Conventional\ntraining-based methods have limitations in flexibility, particularly when\nadapting to new domains, and they often lack explanatory power. To address this\ngap, we propose a novel training-free detection strategy called Divergent\nN-Gram Analysis (DNA-GPT). Given a text, we first truncate it in the middle and\nthen use only the preceding portion as input to the LLMs to regenerate the new\nremaining parts. By analyzing the differences between the original and new\nremaining parts through N-gram analysis in black-box or probability divergence\nin white-box, we unveil significant discrepancies between the distribution of\nmachine-generated text and the distribution of human-written text. We conducted\nextensive experiments on the most advanced LLMs from OpenAI, including\ntext-davinci-003, GPT-3.5-turbo, and GPT-4, as well as open-source models such\nas GPT-NeoX-20B and LLaMa-13B. Results show that our zero-shot approach\nexhibits state-of-the-art performance in distinguishing between human and\nGPT-generated text on four English and one German dataset, outperforming\nOpenAI's own classifier, which is trained on millions of text. Additionally,\nour methods provide reasonable explanations and evidence to support our claim,\nwhich is a unique feature of explainable detection. Our method is also robust\nunder the revised text attack and can additionally solve model sourcing. Codes\nare available at https://github.com/Xianjun-Yang/DNA-GPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petzold_L/0/1/0/all/0/1\">Linda Petzold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AWQ: Activation-aware Weight Quantization for LLM Compression and Acceleration. (arXiv:2306.00978v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00978","description":"<p>Large language models (LLMs) have shown excellent performance on various\ntasks, but the astronomical model size raises the hardware barrier for serving\n(memory size) and slows down token generation (memory bandwidth). In this\npaper, we propose Activation-aware Weight Quantization (AWQ), a\nhardware-friendly approach for LLM low-bit weight-only quantization. Our method\nis based on the observation that weights are not equally important: protecting\nonly 1% of salient weights can greatly reduce quantization error. We then\npropose to search for the optimal per-channel scaling that protects the salient\nweights by observing the activation, not weights. AWQ does not rely on any\nbackpropagation or reconstruction, so it can well preserve LLMs' generalization\nability on different domains and modalities, without overfitting to the\ncalibration set. AWQ outperforms existing work on various language modeling and\ndomain-specific benchmarks. Thanks to better generalization, it achieves\nexcellent quantization performance for instruction-tuned LMs and, for the first\ntime, multi-modal LMs. Alongside AWQ, we implement an efficient and flexible\ninference framework tailored for LLMs on the edge, offering more than 3x\nspeedup over the Huggingface FP16 implementation on both desktop and mobile\nGPUs. It also democratizes the deployment of the 70B Llama-2 model on mobile\nGPU (NVIDIA Jetson Orin 64GB).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Ji Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiaming Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haotian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_X/0/1/0/all/0/1\">Xingyu Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Song Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization. (arXiv:2306.01102v6 [cs.NE] UPDATED)","link":"http://arxiv.org/abs/2306.01102","description":"<p>Large Language Models (LLMs) have emerged as powerful tools capable of\naccomplishing a broad spectrum of tasks. Their abilities span numerous areas,\nand one area where they have made a significant impact is in the domain of code\ngeneration. In this context, we view LLMs as mutation and crossover tools.\nMeanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and\nrobust solutions. By merging the code-generating abilities of LLMs with the\ndiversity and robustness of QD solutions, we introduce LLMatic, a Neural\nArchitecture Search (NAS) algorithm. While LLMs struggle to conduct NAS\ndirectly through prompts, LLMatic uses a procedural approach, leveraging QD for\nprompts and network architecture to create diverse and highly performant\nnetworks. We test LLMatic on the CIFAR-10 image classification benchmark,\ndemonstrating that it can produce competitive networks with just $2,000$\nsearches, even without prior knowledge of the benchmark domain or exposure to\nany previous top-performing models for the benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nasir_M/0/1/0/all/0/1\">Muhammad U. Nasir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Earle_S/0/1/0/all/0/1\">Sam Earle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Steven James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cleghorn_C/0/1/0/all/0/1\">Christopher Cleghorn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems. (arXiv:2306.03091v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03091","description":"<p>Large Language Models (LLMs) have greatly advanced code auto-completion\nsystems, with a potential for substantial productivity enhancements for\ndevelopers. However, current benchmarks mainly focus on single-file tasks,\nleaving an assessment gap for more complex, real-world, multi-file programming\nscenarios. To fill this gap, we introduce RepoBench, a new benchmark\nspecifically designed for evaluating repository-level code auto-completion\nsystems. RepoBench supports both Python and Java and consists of three\ninterconnected evaluation tasks: RepoBench-R (Retrieval), RepoBench-C (Code\nCompletion), and RepoBench-P (Pipeline). Each task respectively measures the\nsystem's ability to retrieve the most relevant code snippets from other files\nas cross-file context, predict the next line of code with cross-file and\nin-file context, and handle complex tasks that require a combination of both\nretrieval and next-line prediction. RepoBench aims to facilitate a more\ncomplete comparison of performance and encouraging continuous improvement in\nauto-completion systems. RepoBench is publicly available at\nhttps://github.com/Leolty/repobench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deductive Verification of Chain-of-Thought Reasoning. (arXiv:2306.03872v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03872","description":"<p>Large Language Models (LLMs) significantly benefit from Chain-of-Thought\n(CoT) prompting in performing various reasoning tasks. While CoT allows models\nto produce more comprehensive reasoning processes, its emphasis on intermediate\nreasoning steps can inadvertently introduce hallucinations and accumulated\nerrors, thereby limiting models' ability to solve complex reasoning tasks.\nInspired by how humans engage in careful and meticulous deductive logical\nreasoning processes to solve tasks, we seek to enable language models to\nperform explicit and rigorous deductive reasoning, and also ensure the\ntrustworthiness of their reasoning process through self-verification. However,\ndirectly verifying the validity of an entire deductive reasoning process is\nchallenging, even with advanced models like ChatGPT. In light of this, we\npropose to decompose a reasoning verification process into a series of\nstep-by-step subprocesses, each only receiving their necessary context and\npremises. To facilitate this procedure, we propose Natural Program, a natural\nlanguage-based deductive reasoning format. Our approach enables models to\ngenerate precise reasoning steps where subsequent steps are more rigorously\ngrounded on prior steps. It also empowers language models to carry out\nreasoning self-verification in a step-by-step manner. By integrating this\nverification process into each deductive reasoning stage, we significantly\nenhance the rigor and trustfulness of generated reasoning steps. Along this\nprocess, we also improve the answer correctness on complex reasoning tasks.\nCode will be released at https://github.com/lz1oceani/verify_cot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yunhao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mingu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Memisevic_R/0/1/0/all/0/1\">Roland Memisevic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedCPT: Contrastive Pre-trained Transformers with Large-scale PubMed Search Logs for Zero-shot Biomedical Information Retrieval. (arXiv:2307.00589v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2307.00589","description":"<p>Information retrieval (IR) is essential in biomedical knowledge acquisition\nand clinical decision support. While recent progress has shown that language\nmodel encoders perform better semantic retrieval, training such models requires\nabundant query-article annotations that are difficult to obtain in biomedicine.\nAs a result, most biomedical IR systems only conduct lexical matching. In\nresponse, we introduce MedCPT, a first-of-its-kind Contrastively Pre-trained\nTransformer model for zero-shot semantic IR in biomedicine. To train MedCPT, we\ncollected an unprecedented scale of 255 million user click logs from PubMed.\nWith such data, we use contrastive learning to train a pair of\nclosely-integrated retriever and re-ranker. Experimental results show that\nMedCPT sets new state-of-the-art performance on six biomedical IR tasks,\noutperforming various baselines including much larger models such as\nGPT-3-sized cpt-text-XL. In addition, MedCPT also generates better biomedical\narticle and sentence representations for semantic evaluations. As such, MedCPT\ncan be readily applied to various real-world biomedical IR tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Won Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Comeau_D/0/1/0/all/0/1\">Donald C. Comeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeganova_L/0/1/0/all/0/1\">Lana Yeganova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilbur_W/0/1/0/all/0/1\">W. John Wilbur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ValiTex -- a unified validation framework for computational text-based measures of social science constructs. (arXiv:2307.02863v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.02863","description":"<p>Guidance on how to validate computational text-based measures of social\nscience constructs is fragmented. While scholars generally acknowledge the\nimportance of validating their text-based measures, they often lack common\nterminology and a unified framework to do so. This paper introduces ValiTex, a\nnew validation framework designed to assist scholars in validly measuring\nsocial science constructs based on textual data. ValiTex prescribes researchers\nto demonstrate three types of validity evidence: substantive evidence\n(outlining the theoretical underpinning of the measure), structural evidence\n(examining the properties of the text model and its output), and external\nevidence (testing for how the measure relates to independent information). In\naddition to the framework, ValiTex offers valuable practical guidance through a\nchecklist that is adaptable for different use cases. The checklist clearly\ndefines and outlines specific validation steps while also offering a\nknowledgeable evaluation of the importance of each validation step to establish\nvalidity. We demonstrate the utility of the framework by applying it to a use\ncase of detecting sexism from social media data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Birkenmaier_L/0/1/0/all/0/1\">Lukas Birkenmaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1\">Claudia Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lechner_C/0/1/0/all/0/1\">Clemens Lechner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets. (arXiv:2307.10928v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.10928","description":"<p>Evaluation of Large Language Models (LLMs) is challenging because\ninstruction-following necessitates alignment with human values and the required\nset of skills varies depending on the instruction. However, previous studies\nhave mainly focused on coarse-grained evaluation (i.e. overall preference-based\nevaluation), which limits interpretability since it does not consider the\nnature of user instructions that require instance-wise skill composition. In\nthis paper, we introduce FLASK (Fine-grained Language Model Evaluation based on\nAlignment Skill Sets), a fine-grained evaluation protocol for both human-based\nand model-based evaluation which decomposes coarse-level scoring to a skill\nset-level scoring for each instruction. We experimentally observe that the\nfine-graininess of evaluation is crucial for attaining a holistic view of model\nperformance and increasing the reliability of the evaluation. Using FLASK, we\ncompare multiple open-source and proprietary LLMs and observe a high\ncorrelation between model-based and human-based evaluations. We publicly\nrelease the evaluation data and code implementation at\nhttps://github.com/kaistAI/FLASK.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Seonghyeon Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1\">Hyeonbin Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungone Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yongrae Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Juho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L-Eval: Instituting Standardized Evaluation for Long Context Language Models. (arXiv:2307.11088v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11088","description":"<p>Recently, there has been growing interest in extending the context length of\nlarge language models (LLMs), aiming to effectively process long inputs of one\nturn or conversations with more extensive histories. While proprietary models\nsuch as GPT-4 and Claude can largely preserve the reasoning ability in an\nextended context, open-source models are still progressing through the early\nstages of development. To bridge this gap, we propose L-Eval to institute a\nmore standardized evaluation for long context language models (LCLMs)\naddressing two key aspects: dataset construction and evaluation metrics. On the\none hand, we build a new evaluation suite containing 20 sub-tasks, 508 long\ndocuments, and over 2,000 human-labeled query-response pairs encompassing\ndiverse question styles, domains, and input length (3k$\\sim$200k tokens). On\nthe other hand, we investigate the effectiveness in evalution metrics for\nLCLMs. Results show that popular n-gram matching metrics generally can not\ncorrelate well with human judgment, and thus we strongly advocate for\nlength-instruction-enhanced (LIE) evaluation and employing LLM judges. We\nconducted a comprehensive study of 4 popular commercial LLMs and 12 open-source\ncounterparts using the L-Eval benchmark. Our empirical findings offer useful\ninsights into the study of LCLMs and lay the groundwork for the development of\nmore principled evaluation of these models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_C/0/1/0/all/0/1\">Chenxin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shansan Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1\">Ming Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingjian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mukai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation. (arXiv:2308.08155v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.08155","description":"<p>AutoGen is an open-source framework that allows developers to build LLM\napplications via multiple agents that can converse with each other to\naccomplish tasks. AutoGen agents are customizable, conversable, and can operate\nin various modes that employ combinations of LLMs, human inputs, and tools.\nUsing AutoGen, developers can also flexibly define agent interaction behaviors.\nBoth natural language and computer code can be used to program flexible\nconversation patterns for different applications. AutoGen serves as a generic\ninfrastructure to build diverse applications of various complexities and LLM\ncapacities. Empirical studies demonstrate the effectiveness of the framework in\nmany example applications, with domains ranging from mathematics, coding,\nquestion answering, operations research, online decision-making, entertainment,\netc.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_G/0/1/0/all/0/1\">Gagan Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yiran Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Beibin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_E/0/1/0/all/0/1\">Erkang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Li Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoyun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaokun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiale Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_R/0/1/0/all/0/1\">Ryen W White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burger_D/0/1/0/all/0/1\">Doug Burger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chi Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instruction Tuning for Large Language Models: A Survey. (arXiv:2308.10792v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10792","description":"<p>This paper surveys research works in the quickly advancing field of\ninstruction tuning (IT), a crucial technique to enhance the capabilities and\ncontrollability of large language models (LLMs). Instruction tuning refers to\nthe process of further training LLMs on a dataset consisting of\n\\textsc{(instruction, output)} pairs in a supervised fashion, which bridges the\ngap between the next-word prediction objective of LLMs and the users' objective\nof having LLMs adhere to human instructions. In this work, we make a systematic\nreview of the literature, including the general methodology of IT, the\nconstruction of IT datasets, the training of IT models, and applications to\ndifferent modalities, domains and applications, along with an analysis on\naspects that influence the outcome of IT (e.g., generation of instruction\noutputs, size of the instruction dataset, etc). We also review the potential\npitfalls of IT along with criticism against it, along with efforts pointing out\ncurrent deficiencies of existing strategies and suggest some avenues for\nfruitful research. Project page: github.com/xiaoya-li/Instruction-Tuning-Survey\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Linfeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Runyi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantifying Uncertainty in Answers from any Language Model and Enhancing their Trustworthiness. (arXiv:2308.16175v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16175","description":"<p>We introduce BSDetector, a method for detecting bad and speculative answers\nfrom a pretrained Large Language Model by estimating a numeric confidence score\nfor any output it generated. Our uncertainty quantification technique works for\nany LLM accessible only via a black-box API, whose training data remains\nunknown. By expending a bit of extra computation, users of any LLM API can now\nget the same response as they would ordinarily, as well as a confidence\nestimate that cautions when not to trust this response. Experiments on both\nclosed and open-form Question-Answer benchmarks reveal that BSDetector more\naccurately identifies incorrect LLM responses than alternative uncertainty\nestimation procedures (for both GPT-3 and ChatGPT). By sampling multiple\nresponses from the LLM and considering the one with the highest confidence\nscore, we can additionally obtain more accurate responses from the same LLM,\nwithout any extra training steps. In applications involving automated\nevaluation with LLMs, accounting for our confidence scores leads to more\nreliable evaluation in both human-in-the-loop and fully-automated settings\n(across both GPT 3.5 and 4).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiuhai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_J/0/1/0/all/0/1\">Jonas Mueller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sparse Autoencoders Find Highly Interpretable Features in Language Models. (arXiv:2309.08600v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.08600","description":"<p>One of the roadblocks to a better understanding of neural networks' internals\nis \\textit{polysemanticity}, where neurons appear to activate in multiple,\nsemantically distinct contexts. Polysemanticity prevents us from identifying\nconcise, human-understandable explanations for what neural networks are doing\ninternally. One hypothesised cause of polysemanticity is\n\\textit{superposition}, where neural networks represent more features than they\nhave neurons by assigning features to an overcomplete set of directions in\nactivation space, rather than to individual neurons. Here, we attempt to\nidentify those directions, using sparse autoencoders to reconstruct the\ninternal activations of a language model. These autoencoders learn sets of\nsparsely activating features that are more interpretable and monosemantic than\ndirections identified by alternative approaches, where interpretability is\nmeasured by automated methods. Moreover, we show that with our learned set of\nfeatures, we can pinpoint the features that are causally responsible for\ncounterfactual behaviour on the indirect object identification task\n\\citep{wang2022interpretability} to a finer degree than previous\ndecompositions. This work indicates that it is possible to resolve\nsuperposition in language models using a scalable, unsupervised method. Our\nmethod may serve as a foundation for future mechanistic interpretability work,\nwhich we hope will enable greater model transparency and steerability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_H/0/1/0/all/0/1\">Hoagy Cunningham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewart_A/0/1/0/all/0/1\">Aidan Ewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riggs_L/0/1/0/all/0/1\">Logan Riggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huben_R/0/1/0/all/0/1\">Robert Huben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharkey_L/0/1/0/all/0/1\">Lee Sharkey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Catastrophic Forgetting in Multimodal Large Language Models. (arXiv:2309.10313v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.10313","description":"<p>Following the success of GPT4, there has been a surge in interest in\nmultimodal large language model (MLLM) research. This line of research focuses\non developing general-purpose LLMs through fine-tuning pre-trained LLMs and\nvision models. However, catastrophic forgetting, a notorious phenomenon where\nthe fine-tuned model fails to retain similar performance compared to the\npre-trained model, still remains an inherent problem in multimodal LLMs (MLLM).\nIn this paper, we introduce EMT: Evaluating MulTimodality for evaluating the\ncatastrophic forgetting in MLLMs, by treating each MLLM as an image classifier.\nWe first apply EMT to evaluate several open-source fine-tuned MLLMs and we\ndiscover that almost all evaluated MLLMs fail to retain the same performance\nlevels as their vision encoders on standard image classification tasks.\nMoreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess\nperformance throughout the fine-tuning. Interestingly, our results suggest that\nearly-stage fine-tuning on an image dataset improves performance across other\nimage datasets, by enhancing the alignment of text and visual features.\nHowever, as fine-tuning proceeds, the MLLMs begin to hallucinate, resulting in\na significant loss of generalizability, even when the image encoder remains\nfrozen. Our results suggest that MLLMs have yet to demonstrate performance on\npar with their vision models on standard image classification tasks and the\ncurrent MLLM fine-tuning procedure still has room for improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yuexiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shengbang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Mu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Q/0/1/0/all/0/1\">Qing Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yong Jae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yi Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme Long Sequence Transformer Models. (arXiv:2309.14509v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.14509","description":"<p>Computation in a typical Transformer-based large language model (LLM) can be\ncharacterized by batch size, hidden dimension, number of layers, and sequence\nlength. Until now, system works for accelerating LLM training have focused on\nthe first three dimensions: data parallelism for batch size, tensor parallelism\nfor hidden size and pipeline parallelism for model depth or layers. These\nwidely studied forms of parallelism are not targeted or optimized for long\nsequence Transformer models. Given practical application needs for long\nsequence LLM, renewed attentions are being drawn to sequence parallelism.\nHowever, existing works in sequence parallelism are constrained by\nmemory-communication inefficiency, limiting their scalability to long sequence\nlarge models. In this work, we introduce DeepSpeed-Ulysses, a novel, portable\nand effective methodology for enabling highly efficient and scalable LLM\ntraining with extremely long sequence length. DeepSpeed-Ulysses at its core\npartitions input data along the sequence dimension and employs an efficient\nall-to-all collective communication for attention computation. Theoretical\ncommunication analysis shows that whereas other methods incur communication\noverhead as sequence length increases, DeepSpeed-Ulysses maintains constant\ncommunication volume when sequence length and compute devices are increased\nproportionally. Furthermore, experimental evaluations show that\nDeepSpeed-Ulysses trains 2.5x faster with 4x longer sequence length than the\nexisting method SOTA baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacobs_S/0/1/0/all/0/1\">Sam Ade Jacobs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1\">Masahiro Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Minjia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuaiwen Leon Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajbhandari_S/0/1/0/all/0/1\">Samyam Rajbhandari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving. (arXiv:2309.17452v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.17452","description":"<p>Large language models have made significant progress in various language\ntasks, yet they still struggle with complex mathematics. In this paper, we\npropose ToRA a series of Tool-integrated Reasoning Agents designed to solve\nchallenging mathematical problems by seamlessly integrating natural language\nreasoning with the utilization of external tools (e.g., computation libraries\nand symbolic solvers), thereby amalgamating the analytical prowess of language\nand the computational efficiency of tools. To train ToRA, we curate interactive\ntool-use trajectories on mathematical datasets, apply imitation learning on the\nannotations, and propose output space shaping to further refine models'\nreasoning behavior. As a result, ToRA models significantly outperform\nopen-source models on 10 mathematical reasoning datasets across all scales with\n13%-19% absolute improvements on average. Notably, ToRA-7B reaches 44.6% on the\ncompetition-level dataset MATH, surpassing the best open-source model\nWizardMath-70B by 22% absolute. ToRA-Code-34B is also the first open-source\nmodel that achieves an accuracy exceeding 50% on MATH, which significantly\noutperforms GPT-4's CoT result, and is competitive with GPT-4 solving problems\nwith programs. Additionally, we conduct a comprehensive analysis of the\nbenefits and remaining challenges of tool interaction for mathematical\nreasoning, providing valuable insights for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gou_Z/0/1/0/all/0/1\">Zhibin Gou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhihong Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fewer is More: Trojan Attacks on Parameter-Efficient Fine-Tuning. (arXiv:2310.00648v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00648","description":"<p>Parameter-efficient fine-tuning (PEFT) enables efficient adaptation of\npre-trained language models (PLMs) to specific tasks. By tuning only a minimal\nset of (extra) parameters, PEFT achieves performance comparable to full\nfine-tuning. However, despite its prevalent use, the security implications of\nPEFT remain largely unexplored. In this paper, we conduct a pilot study\nrevealing that PEFT exhibits unique vulnerability to trojan attacks.\nSpecifically, we present PETA, a novel attack that accounts for downstream\nadaptation through bilevel optimization: the upper-level objective embeds the\nbackdoor into a PLM while the lower-level objective simulates PEFT to retain\nthe PLM's task-specific performance. With extensive evaluation across a variety\nof downstream tasks and trigger designs, we demonstrate PETA's effectiveness in\nterms of both attack success rate and unaffected clean accuracy, even after the\nvictim user performs PEFT over the backdoored PLM using untainted data.\nMoreover, we empirically provide possible explanations for PETA's efficacy: the\nbilevel optimization inherently 'orthogonalizes' the backdoor and PEFT modules,\nthereby retaining the backdoor throughout PEFT. Based on this insight, we\nexplore a simple defense that omits PEFT in selected layers of the backdoored\nPLM and unfreezes a subset of these layers' parameters, which is shown to\neffectively neutralize PETA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lauren Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Ting Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Entity-Deduction Arena: A playground for probing the conversational reasoning and planning capabilities of LLMs. (arXiv:2310.01468v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01468","description":"<p>Large language models (LLMs) are effective at answering questions that are\nclearly asked. However, when faced with ambiguous queries they can act\nunpredictably and produce incorrect outputs. This underscores the need for the\ndevelopment of intelligent agents capable of asking clarification questions to\nresolve ambiguities effectively. This capability requires complex\nunderstanding, state tracking, reasoning and planning over multiple\nconversational turns. However, directly measuring this can be challenging. In\nthis paper, we offer a surrogate problem which assesses an LLMs's capability to\ndeduce an entity unknown to itself, but revealed to a judge, by asking the\njudge a series of queries. This entity-deducing game can serve as an evaluation\nframework to probe the conversational reasoning and planning capabilities of\nlanguage models. We systematically evaluate various LLMs and discover\nsignificant differences in their performance on this task. We find that strong\nLLMs like GPT-4 outperform human players by a large margin. We further employ\nBehavior Cloning (BC) to examine whether a weaker model is capable of imitating\na stronger model and generalizing to data or domains, using only the\ndemonstrations from a stronger model. We finally propose to use Reinforcement\nLearning to enhance reasoning and planning capacity of Vicuna models through\nepisodes of game playing, which lead to significant performance improvement. We\nhope that this problem offers insights into how autonomous agents could be\ntrained to behave more intelligently in ambiguous circumstances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yizhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiarui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1\">Navdeep Jaitly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples. (arXiv:2310.01469v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01469","description":"<p>Large Language Models (LLMs), including GPT-3.5, LLaMA, and PaLM, seem to be\nknowledgeable and able to adapt to many tasks. However, we still can not\ncompletely trust their answer, since LLMs suffer from\nhallucination--fabricating non-existent facts to cheat users without\nperception. And the reasons for their existence and pervasiveness remain\nunclear. In this paper, we demonstrate that non-sense prompts composed of\nrandom tokens can also elicit the LLMs to respond with hallucinations. This\nphenomenon forces us to revisit that hallucination may be another view of\nadversarial examples, and it shares similar features with conventional\nadversarial examples as the basic feature of LLMs. Therefore, we formalize an\nautomatic hallucination triggering method as the hallucination attack in an\nadversarial way. Finally, we explore basic feature of attacked adversarial\nprompts and propose a simple yet effective defense strategy. Our code is\nreleased on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jia-Yu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_K/0/1/0/all/0/1\">Kun-Peng Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen-Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_M/0/1/0/all/0/1\">Mu-Nan Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Li Yuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Preserving Phonemic Distinctions for Ordinal Regression: A Novel Loss Function for Automatic Pronunciation Assessment. (arXiv:2310.01839v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2310.01839","description":"<p>Automatic pronunciation assessment (APA) manages to quantify the\npronunciation proficiency of a second language (L2) learner in a language.\nPrevailing approaches to APA normally leverage neural models trained with a\nregression loss function, such as the mean-squared error (MSE) loss, for\nproficiency level prediction. Despite most regression models can effectively\ncapture the ordinality of proficiency levels in the feature space, they are\nconfronted with a primary obstacle that different phoneme categories with the\nsame proficiency level are inevitably forced to be close to each other,\nretaining less phoneme-discriminative information. On account of this, we\ndevise a phonemic contrast ordinal (PCO) loss for training regression-based APA\nmodels, which aims to preserve better phonemic distinctions between phoneme\ncategories meanwhile considering ordinal relationships of the regression target\noutput. Specifically, we introduce a phoneme-distinct regularizer into the MSE\nloss, which encourages feature representations of different phoneme categories\nto be far apart while simultaneously pulling closer the representations\nbelonging to the same phoneme category by means of weighted distances. An\nextensive set of experiments carried out on the speechocean762 benchmark\ndataset suggest the feasibility and effectiveness of our model in relation to\nsome existing state-of-the-art models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yan_B/0/1/0/all/0/1\">Bi-Cheng Yan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Wei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yi-Cheng Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jiun-Ting Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_C/0/1/0/all/0/1\">Chi-Han Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_B/0/1/0/all/0/1\">Berlin Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effective and Parameter-Efficient Reusing Fine-Tuned Models. (arXiv:2310.01886v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.01886","description":"<p>Many pre-trained large-scale models provided online have become highly\neffective in transferring to downstream tasks. At the same time, various\ntask-specific models fine-tuned on these pre-trained models are available\nonline for public use. In practice, as collecting task-specific data is\nlabor-intensive and fine-tuning the large pre-trained models is computationally\nexpensive, one can reuse task-specific finetuned models to deal with downstream\ntasks. However, using a model per task causes a heavy burden on storage and\nserving. Recently, many training-free and parameter-efficient methods have been\nproposed for reusing multiple fine-tuned task-specific models into a single\nmulti-task model. However, these methods exhibit a large accuracy gap compared\nwith using a fine-tuned model per task. In this paper, we propose\nParameter-Efficient methods for ReUsing (PERU) fine-tuned models. For reusing\nFully Fine-Tuned (FFT) models, we propose PERU-FFT by injecting a sparse task\nvector into a merged model by magnitude pruning. For reusing LoRA fine-tuned\nmodels, we propose PERU-LoRA use a lower-rank matrix to approximate the LoRA\nmatrix by singular value decomposition. Both PERUFFT and PERU-LoRA are\ntraining-free. Extensive experiments conducted on computer vision and natural\nlanguage process tasks demonstrate the effectiveness and parameter-efficiency\nof the proposed methods. The proposed PERU-FFT and PERU-LoRA outperform\nexisting reusing model methods by a large margin and achieve comparable\nperformance to using a fine-tuned model per task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weisen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baijiong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02031","description":"<p>Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yida Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Daxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Who's Harry Potter? Approximate Unlearning in LLMs. (arXiv:2310.02238v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02238","description":"<p>Large language models (LLMs) are trained on massive internet corpora that\noften contain copyrighted content. This poses legal and ethical challenges for\nthe developers and users of these models, as well as the original authors and\npublishers. In this paper, we propose a novel technique for unlearning a subset\nof the training data from a LLM, without having to retrain it from scratch.\n</p>\n<p>We evaluate our technique on the task of unlearning the Harry Potter books\nfrom the Llama2-7b model (a generative language model recently open-sourced by\nMeta). While the model took over 184K GPU-hours to pretrain, we show that in\nabout 1 GPU hour of finetuning, we effectively erase the model's ability to\ngenerate or recall Harry Potter-related content, while its performance on\ncommon benchmarks (such as Winogrande, Hellaswag, arc, boolq and piqa) remains\nalmost unaffected. We make our fine-tuned model publicly available on\nHuggingFace for community evaluation. To the best of our knowledge, this is the\nfirst paper to present an effective technique for unlearning in generative\nlanguage models.\n</p>\n<p>Our technique consists of three main components: First, we use a reinforced\nmodel that is further trained on the target data to identify the tokens that\nare most related to the unlearning target, by comparing its logits with those\nof a baseline model. Second, we replace idiosyncratic expressions in the target\ndata with generic counterparts, and leverage the model's own predictions to\ngenerate alternative labels for every token. These labels aim to approximate\nthe next-token predictions of a model that has not been trained on the target\ndata. Third, we finetune the model on these alternative labels, which\neffectively erases the original text from the model's memory whenever it is\nprompted with its context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eldan_R/0/1/0/all/0/1\">Ronen Eldan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russinovich_M/0/1/0/all/0/1\">Mark Russinovich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Named Entity Inclusion in Abstractive Text Summarization. (arXiv:2307.02570v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2307.02570","description":"<p>We address the named entity omission - the drawback of many current\nabstractive text summarizers. We suggest a custom pretraining objective to\nenhance the model's attention on the named entities in a text. At first, the\nnamed entity recognition model RoBERTa is trained to determine named entities\nin the text. After that, this model is used to mask named entities in the text\nand the BART model is trained to reconstruct them. Next, the BART model is\nfine-tuned on the summarization task. Our experiments showed that this\npretraining approach improves named entity inclusion precision and recall\nmetrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1\">Sergey Berezin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batura_T/0/1/0/all/0/1\">Tatiana Batura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-04T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/"}}]}]}