{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-04-27T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Pretrain on just structure: Understanding linguistic inductive biases using transfer learning. (arXiv:2304.13060v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13060","description":"<p>Both humans and transformer language models are able to learn language\nwithout explicit structural supervision. What inductive learning biases make\nthis learning possible? In this study, we examine the effect of different\ninductive learning biases by predisposing language models with structural\nbiases through pretraining on artificial structured data, and then evaluating\nby fine-tuning on English. Our experimental setup gives us the ability to\nactively control the inductive bias of language models. With our experiments,\nwe investigate the comparative success of three types of inductive bias: 1) an\ninductive bias for recursive, hierarchical processing 2) an inductive bias for\nunrestricted token-token dependencies that can't be modeled by context-free\ngrammars, and 3) an inductive bias for a Zipfian power-law vocabulary\ndistribution. We show that complex token-token interactions form the best\ninductive biases, and that this is strongest in the non-context-free case. We\nalso show that a Zipfian vocabulary distribution forms a good inductive bias\nindependently from grammatical structure. Our study leverages the capabilities\nof transformer models to run controlled language learning experiments that are\nnot possible to run in humans, and surfaces hypotheses about the structures\nthat facilitate language learning in both humans and machines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_I/0/1/0/all/0/1\">Isabel Papadimitriou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LAST: Scalable Lattice-Based Speech Modelling in JAX. (arXiv:2304.13134v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13134","description":"<p>We introduce LAST, a LAttice-based Speech Transducer library in JAX. With an\nemphasis on flexibility, ease-of-use, and scalability, LAST implements\ndifferentiable weighted finite state automaton (WFSA) algorithms needed for\ntraining \\&amp; inference that scale to a large WFSA such as a recognition lattice\nover the entire utterance. Despite these WFSA algorithms being well-known in\nthe literature, new challenges arise from performance characteristics of modern\narchitectures, and from nuances in automatic differentiation. We describe a\nsuite of generally applicable techniques employed in LAST to address these\nchallenges, and demonstrate their effectiveness with benchmarks on TPUv3 and\nV100 GPU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Ke Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Variani_E/0/1/0/all/0/1\">Ehsan Variani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagby_T/0/1/0/all/0/1\">Tom Bagby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riley_M/0/1/0/all/0/1\">Michael Riley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESimCSE Unsupervised Contrastive Learning Jointly with UDA Semi-Supervised Learning for Large Label System Text Classification Mode. (arXiv:2304.13140v1 [cs.LG])","link":"http://arxiv.org/abs/2304.13140","description":"<p>The challenges faced by text classification with large tag systems in natural\nlanguage processing tasks include multiple tag systems, uneven data\ndistribution, and high noise. To address these problems, the ESimCSE\nunsupervised comparative learning and UDA semi-supervised comparative learning\nmodels are combined through the use of joint training techniques in the\nmodels.The ESimCSE model efficiently learns text vector representations using\nunlabeled data to achieve better classification results, while UDA is trained\nusing unlabeled data through semi-supervised learning methods to improve the\nprediction performance of the models and stability, and further improve the\ngeneralization ability of the model. In addition, adversarial training\ntechniques FGM and PGD are used in the model training process to improve the\nrobustness and reliability of the model. The experimental results show that\nthere is an 8% and 10% accuracy improvement relative to Baseline on the public\ndataset Ruesters as well as on the operational dataset, respectively, and a 15%\nimprovement in manual validation accuracy can be achieved on the operational\ndataset, indicating that the method is effective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Ruan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+HangCheng_Z/0/1/0/all/0/1\">Zhou HangCheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Ran Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+JiaoYu_Q/0/1/0/all/0/1\">Qin JiaoYu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Wei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ChenZi_W/0/1/0/all/0/1\">Wang ChenZi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling Spoken Information Queries for Virtual Assistants: Open Problems, Challenges and Opportunities. (arXiv:2304.13149v1 [cs.IR])","link":"http://arxiv.org/abs/2304.13149","description":"<p>Virtual assistants are becoming increasingly important speech-driven\nInformation Retrieval platforms that assist users with various tasks.\n</p>\n<p>We discuss open problems and challenges with respect to modeling spoken\ninformation queries for virtual assistants, and list opportunities where\nInformation Retrieval methods and research can be applied to improve the\nquality of virtual assistant speech recognition.\n</p>\n<p>We discuss how query domain classification, knowledge graphs and user\ninteraction data, and query personalization can be helpful to improve the\naccurate recognition of spoken information domain queries. Finally, we also\nprovide a brief overview of current problems and challenges in speech\nrecognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gysel_C/0/1/0/all/0/1\">Christophe Van Gysel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sebis at SemEval-2023 Task 7: A Joint System for Natural Language Inference and Evidence Retrieval from Clinical Trial Reports. (arXiv:2304.13180v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13180","description":"<p>With the increasing number of clinical trial reports generated every day, it\nis becoming hard to keep up with novel discoveries that inform evidence-based\nhealthcare recommendations. To help automate this process and assist medical\nexperts, NLP solutions are being developed. This motivated the SemEval-2023\nTask 7, where the goal was to develop an NLP system for two tasks: evidence\nretrieval and natural language inference from clinical trial data. In this\npaper, we describe our two developed systems. The first one is a pipeline\nsystem that models the two tasks separately, while the second one is a joint\nsystem that learns the two tasks simultaneously with a shared representation\nand a multi-task learning approach. The final system combines their outputs in\nan ensemble system. We formalize the models, present their characteristics and\nchallenges, and provide an analysis of achieved results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vladika_J/0/1/0/all/0/1\">Juraj Vladika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TABLET: Learning From Instructions For Tabular Data. (arXiv:2304.13188v1 [cs.LG])","link":"http://arxiv.org/abs/2304.13188","description":"<p>Acquiring high-quality data is often a significant challenge in training\nmachine learning (ML) models for tabular prediction, particularly in\nprivacy-sensitive and costly domains like medicine and finance. Providing\nnatural language instructions to large language models (LLMs) offers an\nalternative solution. However, it is unclear how effectively instructions\nleverage the knowledge in LLMs for solving tabular prediction problems. To\naddress this gap, we introduce TABLET, a benchmark of 20 diverse tabular\ndatasets annotated with instructions that vary in their phrasing, granularity,\nand technicality. Additionally, TABLET includes the instructions' logic and\nstructured modifications to the instructions. We find in-context instructions\nincrease zero-shot F1 performance for Flan-T5 11b by 44% on average and 13% for\nChatGPT on TABLET. Also, we explore the limitations of using LLMs for tabular\nprediction in our benchmark by evaluating instruction faithfulness. We find\nLLMs often ignore instructions and fail to predict specific instances\ncorrectly, even with examples. Our analysis on TABLET shows that, while\ninstructions help LLM performance, learning from instructions for tabular data\nrequires new capabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Explainable and Safe Conversational Agents for Mental Health: A Survey. (arXiv:2304.13191v1 [cs.AI])","link":"http://arxiv.org/abs/2304.13191","description":"<p>Virtual Mental Health Assistants (VMHAs) are seeing continual advancements to\nsupport the overburdened global healthcare system that gets 60 million primary\ncare visits, and 6 million Emergency Room (ER) visits annually. These systems\nare built by clinical psychologists, psychiatrists, and Artificial Intelligence\n(AI) researchers for Cognitive Behavioral Therapy (CBT). At present, the role\nof VMHAs is to provide emotional support through information, focusing less on\ndeveloping a reflective conversation with the patient. A more comprehensive,\nsafe and explainable approach is required to build responsible VMHAs to ask\nfollow-up questions or provide a well-informed response. This survey offers a\nsystematic critical review of the existing conversational agents in mental\nhealth, followed by new insights into the improvements of VMHAs with contextual\nknowledge, datasets, and their emerging role in clinical decision support. We\nalso provide new directions toward enriching the user experience of VMHAs with\nexplainability, safety, and wholesome trustworthiness. Finally, we provide\nevaluation metrics and practical considerations for VMHAs beyond the current\nliterature to build trust between VMHAs and patients in active communications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Surjodeep Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_M/0/1/0/all/0/1\">Manas Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">L. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1\">Muskan Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1\">Biplav Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dongaonkar_B/0/1/0/all/0/1\">Bhaktee Dongaonkar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Curious Case of Code Prompts. (arXiv:2304.13250v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13250","description":"<p>Recent work has shown that prompting language models with code-like\nrepresentations of natural language leads to performance improvements on\nstructured reasoning tasks. However, such tasks comprise only a small subset of\nall natural language tasks. In our work, we seek to answer whether or not\ncode-prompting is the preferred way of interacting with language models in\ngeneral. We compare code and text prompts across three popular GPT models\n(davinci, code-davinci-002, and text-davinci-002) on a broader selection of\ntasks (e.g., QA, sentiment, summarization) and find that with few exceptions,\ncode prompts do not consistently outperform text prompts. Furthermore, we show\nthat the style of code prompt has a large effect on performance for some but\nnot all tasks and that fine-tuning on text instructions leads to better\nrelative performance of code prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dugan_L/0/1/0/all/0/1\">Liam Dugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hainiu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping. (arXiv:2304.13273v1 [cs.CV])","link":"http://arxiv.org/abs/2304.13273","description":"<p>With the development of Vision-Language Pre-training Models (VLPMs)\nrepresented by CLIP and ALIGN, significant breakthroughs have been achieved for\nassociation-based visual tasks such as image classification and image-text\nretrieval by the zero-shot capability of CLIP without fine-tuning. However,\nCLIP is hard to apply to generation-based tasks. This is due to the lack of\ndecoder architecture and pre-training tasks for generation. Although previous\nworks have created generation capacity for CLIP through additional language\nmodels, a modality gap between the CLIP representations of different modalities\nand the inability of CLIP to model the offset of this gap, which fails the\nconcept to transfer across modalities. To solve the problem, we try to map\nimages/videos to the language modality and generate captions from the language\nmodality. In this paper, we propose the K-nearest-neighbor Cross-modality\nMapping (Knight), a zero-shot method from association to generation. With\ntext-only unsupervised training, Knight achieves state-of-the-art performance\nin zero-shot methods for image captioning and video captioning. Our code is\navailable at https://github.com/junyangwang0410/Knight.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Closeness of In-Context Learning and Weight Shifting for Softmax Regression. (arXiv:2304.13276v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13276","description":"<p>Large language models (LLMs) are known for their exceptional performance in\nnatural language processing, making them highly effective in many human\nlife-related or even job-related tasks. The attention mechanism in the\nTransformer architecture is a critical component of LLMs, as it allows the\nmodel to selectively focus on specific input parts. The softmax unit, which is\na key part of the attention mechanism, normalizes the attention scores. Hence,\nthe performance of LLMs in various NLP tasks depends significantly on the\ncrucial role played by the attention mechanism with the softmax unit.\n</p>\n<p>In-context learning, as one of the celebrated abilities of recent LLMs, is an\nimportant concept in querying LLMs such as ChatGPT. Without further parameter\nupdates, Transformers can learn to predict based on few in-context examples.\nHowever, the reason why Transformers becomes in-context learners is not well\nunderstood. Recently, several works [ASA+22,GTLV22,ONR+22] have studied the\nin-context learning from a mathematical perspective based on a linear\nregression formulation $\\min_x\\| Ax - b \\|_2$, which show Transformers'\ncapability of learning linear functions in context.\n</p>\n<p>In this work, we study the in-context learning based on a softmax regression\nformulation $\\min_{x} \\| \\langle \\exp(Ax), {\\bf 1}_n \\rangle^{-1} \\exp(Ax) - b\n\\|_2$ of Transformer's attention mechanism. We show the upper bounds of the\ndata transformations induced by a single self-attention layer and by\ngradient-descent on a $\\ell_2$ regression loss for softmax prediction function,\nwhich imply that when training self-attention-only Transformers for fundamental\nregression tasks, the models learned by gradient-descent and Transformers show\ngreat similarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yu Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Slot and Intent Detection in Low-Resource Languages. (arXiv:2304.13292v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13292","description":"<p>Intent detection and slot filling are critical tasks in spoken and natural\nlanguage understanding for task-oriented dialog systems. In this work we\ndescribe our participation in the slot and intent detection for low-resource\nlanguage varieties (SID4LR; Aepli et al. (2023)). We investigate the slot and\nintent detection (SID) tasks using a wide range of models and settings. Given\nthe recent success of multitask-prompted finetuning of large language models,\nwe also test the generalization capability of the recent encoder-decoder model\nmT0 (Muennighoff et al., 2022) on new tasks (i.e., SID) in languages they have\nnever intentionally seen. We show that our best model outperforms the baseline\nby a large margin (up to +30 F1 points) in both SID tasks\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_S/0/1/0/all/0/1\">Sang Yun Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_G/0/1/0/all/0/1\">Gagan Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inciarte_A/0/1/0/all/0/1\">Alcides Alcoba Inciarte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain Text-to-SQL. (arXiv:2304.13301v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13301","description":"<p>Recent advancements in Large Language Models (LLMs), such as Codex, ChatGPT\nand GPT-4 have significantly impacted the AI community, including Text-to-SQL\ntasks. Some evaluations and analyses on LLMs show their potential to generate\nSQL queries but they point out poorly designed prompts (e.g. simplistic\nconstruction or random sampling) limit LLMs' performance and may cause\nunnecessary or irrelevant outputs. To address these issues, we propose\nCBR-ApSQL, a Case-Based Reasoning (CBR)-based framework combined with GPT-3.5\nfor precise control over case-relevant and case-irrelevant knowledge in\nText-to-SQL tasks. We design adaptive prompts for flexibly adjusting inputs for\nGPT-3.5, which involves (1) adaptively retrieving cases according to the\nquestion intention by de-semantizing the input question, and (2) an adaptive\nfallback mechanism to ensure the informativeness of the prompt, as well as the\nrelevance between cases and the prompt. In the de-semanticization phase, we\ndesigned Semantic Domain Relevance Evaluator(SDRE), combined with Poincar\\'e\ndetector(mining implicit semantics in hyperbolic space), TextAlign(discovering\nexplicit matches), and Positector (part-of-speech detector). SDRE semantically\nand syntactically generates in-context exemplar annotations for the new case.\nOn the three cross-domain datasets, our framework outperforms the\nstate-of-the-art(SOTA) model in execution accuracy by 3.7\\%, 2.5\\%, and 8.2\\%,\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1\">Chunxi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jintao Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pancheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zhihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Ting Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nominal Topology for Data Languages. (arXiv:2304.13337v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13337","description":"<p>We propose a novel topological perspective on data languages recognizable by\norbit-finite nominal monoids. For this purpose, we introduce pro-orbit-finite\nnominal topological spaces. Assuming globally bounded support sizes, they\ncoincide with nominal Stone spaces and are shown to be dually equivalent to a\nsubcategory of nominal boolean algebras. Recognizable data languages are\ncharacterized as topologically clopen sets of pro-orbit-finite words. In\naddition, we explore the expressive power of pro-orbit-finite equations by\nestablishing a nominal version of Reiterman's pseudovariety theorem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Urbat_H/0/1/0/all/0/1\">Henning Urbat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milius_S/0/1/0/all/0/1\">Stefan Milius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birkmann_F/0/1/0/all/0/1\">Fabian Birkmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unleashing Infinite-Length Input Capacity for Large-scale Language Models with Self-Controlled Memory System. (arXiv:2304.13343v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13343","description":"<p>Large-scale Language Models (LLMs) are constrained by their inability to\nprocess lengthy inputs. To address this limitation, we propose the\nSelf-Controlled Memory (SCM) system to unleash infinite-length input capacity\nfor large-scale language models. Our SCM system is composed of three key\nmodules: the language model agent, the memory stream, and the memory\ncontroller. The language model agent iteratively processes ultra-long inputs\nand stores all historical information in the memory stream. The memory\ncontroller provides the agent with both long-term memory (archived memory) and\nshort-term memory (flash memory) to generate precise and coherent responses.\nThe controller determines which memories from archived memory should be\nactivated and how to incorporate them into the model input. Our SCM system can\nbe integrated with any LLMs to enable them to process ultra-long texts without\nany modification or fine-tuning. Experimental results show that our SCM system\nenables LLMs, which are not optimized for multi-turn dialogue, to achieve\nmulti-turn dialogue capabilities that are comparable to ChatGPT, and to\noutperform ChatGPT in scenarios involving ultra-long document summarization or\nlong-term conversations. Additionally, we will supply a test set, which covers\ncommon long-text input scenarios, for evaluating the abilities of LLMs in\nprocessing long documents.~\\footnote{Working in\nprogress.}\\footnote{\\url{https://github.com/wbbeyourself/SCM4LLMs}}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xinnian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1\">Peihao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multidimensional Evaluation for Text Style Transfer Using ChatGPT. (arXiv:2304.13462v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13462","description":"<p>We investigate the potential of ChatGPT as a multidimensional evaluator for\nthe task of \\emph{Text Style Transfer}, alongside, and in comparison to,\nexisting automatic metrics as well as human judgements. We focus on a zero-shot\nsetting, i.e. prompting ChatGPT with specific task instructions, and test its\nperformance on three commonly-used dimensions of text style transfer\nevaluation: style strength, content preservation, and fluency. We perform a\ncomprehensive correlation analysis for two transfer directions (and overall) at\ndifferent levels. Compared to existing automatic metrics, ChatGPT achieves\ncompetitive correlations with human judgments. These preliminary results are\nexpected to provide a first glimpse into the role of large language models in\nthe multidimensional evaluation of stylized text generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_H/0/1/0/all/0/1\">Huiyuan Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toral_A/0/1/0/all/0/1\">Antonio Toral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1\">Malvina Nissim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"I'm\" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets. (arXiv:2304.13557v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13557","description":"<p>As virtual assistants continue to be taken up globally, there is an\never-greater need for these speech-based systems to communicate naturally in a\nvariety of languages. Crowdsourcing initiatives have focused on multilingual\ntranslation of big, open data sets for use in natural language processing\n(NLP). Yet, language translation is often not one-to-one, and biases can\ntrickle in. In this late-breaking work, we focus on the case of pronouns\ntranslated between English and Japanese in the crowdsourced Tatoeba database.\nWe found that masculine pronoun biases were present overall, even though\nplurality in language was accounted for in other ways. Importantly, we detected\nbiases in the translation process that reflect nuanced reactions to the\npresence of feminine, neutral, and/or non-binary pronouns. We raise the issue\nof translation bias for pronouns and offer a practical solution to embed\nplurality in NLP data sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seaborn_K/0/1/0/all/0/1\">Katie Seaborn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yeongdae Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Multi-Modal DBMSs for Seamless Querying of Texts and Tables. (arXiv:2304.13559v1 [cs.DB])","link":"http://arxiv.org/abs/2304.13559","description":"<p>In this paper, we propose Multi-Modal Databases (MMDBs), which is a new class\nof database systems that can seamlessly query text and tables using SQL. To\nenable seamless querying of textual data using SQL in an MMDB, we propose to\nextend relational databases with so-called multi-modal operators (MMOps) which\nare based on the advances of recent large language models such as GPT-3. The\nmain idea of MMOps is that they allow text collections to be treated as tables\nwithout the need to manually transform the data. As we show in our evaluation,\nour MMDB prototype can not only outperform state-of-the-art approaches such as\ntext-to-table in terms of accuracy and performance but it also requires\nsignificantly less training data to fine-tune the model for an unseen text\ncollection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Urban_M/0/1/0/all/0/1\">Matthias Urban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Binnig_C/0/1/0/all/0/1\">Carsten Binnig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Impact of Position Bias on Language Models in Token Classification. (arXiv:2304.13567v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13567","description":"<p>Language Models (LMs) have shown state-of-the-art performance in Natural\nLanguage Processing (NLP) tasks. Downstream tasks such as Named Entity\nRecognition (NER) or Part-of-Speech (POS) tagging are known to suffer from data\nimbalance issues, specifically in terms of the ratio of positive to negative\nexamples, and class imbalance. In this paper, we investigate an additional\nspecific issue for language models, namely the position bias of positive\nexamples in token classification tasks. Therefore, we conduct an in-depth\nevaluation of the impact of position bias on the performance of LMs when\nfine-tuned on Token Classification benchmarks. Our study includes CoNLL03 and\nOntoNote5.0 for NER, English Tree Bank UD_en and TweeBank for POS tagging. We\npropose an evaluation approach to investigate position bias in Transformer\nmodels. We show that encoders like BERT, ERNIE, ELECTRA, and decoders such as\nGPT2 and BLOOM can suffer from this bias with an average drop of 3\\% and 9\\% in\ntheir performance. To mitigate this effect, we propose two methods: Random\nPosition Shifting and Context Perturbation, that we apply on batches during the\ntraining process. The results show an improvement of $\\approx$ 2\\% in the\nperformance of the model on CoNLL03, UD_en, and TweeBank.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amor_M/0/1/0/all/0/1\">Mehdi Ben Amor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granitzer_M/0/1/0/all/0/1\">Michael Granitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitrovic_J/0/1/0/all/0/1\">Jelena Mitrovi&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toxic comments reduce the activity of volunteer editors on Wikipedia. (arXiv:2304.13568v1 [cs.CY])","link":"http://arxiv.org/abs/2304.13568","description":"<p>Wikipedia is one of the most successful collaborative projects in history. It\nis the largest encyclopedia ever created, with millions of users worldwide\nrelying on it as the first source of information as well as for fact-checking\nand in-depth research. As Wikipedia relies solely on the efforts of its\nvolunteer-editors, its success might be particularly affected by toxic speech.\nIn this paper, we analyze all 57 million comments made on user talk pages of\n8.5 million editors across the six most active language editions of Wikipedia\nto study the potential impact of toxicity on editors' behaviour. We find that\ntoxic comments consistently reduce the activity of editors, leading to an\nestimated loss of 0.5-2 active days per user in the short term. This amounts to\nmultiple human-years of lost productivity when considering the number of active\ncontributors to Wikipedia. The effects of toxic comments are even greater in\nthe long term, as they significantly increase the risk of editors leaving the\nproject altogether. Using an agent-based model, we demonstrate that toxicity\nattacks on Wikipedia have the potential to impede the progress of the entire\nproject. Our results underscore the importance of mitigating toxic speech on\ncollaborative platforms such as Wikipedia to ensure their continued success.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Smirnov_I/0/1/0/all/0/1\">Ivan Smirnov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_C/0/1/0/all/0/1\">Camelia Oprea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohmaier_M/0/1/0/all/0/1\">Markus Strohmaier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shades of meaning: Uncovering the geometry of ambiguous word representations through contextualised language models. (arXiv:2304.13597v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13597","description":"<p>Lexical ambiguity presents a profound and enduring challenge to the language\nsciences. Researchers for decades have grappled with the problem of how\nlanguage users learn, represent and process words with more than one meaning.\nOur work offers new insight into psychological understanding of lexical\nambiguity through a series of simulations that capitalise on recent advances in\ncontextual language models. These models have no grounded understanding of the\nmeanings of words at all; they simply learn to predict words based on the\nsurrounding context provided by other words. Yet, our analyses show that their\nrepresentations capture fine-grained meaningful distinctions between\nunambiguous, homonymous, and polysemous words that align with lexicographic\nclassifications and psychological theorising. These findings provide\nquantitative support for modern psychological conceptualisations of lexical\nambiguity and raise new challenges for understanding of the way that contextual\ninformation shapes the meanings of words across different timescales.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cevoli_B/0/1/0/all/0/1\">Benedetta Cevoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_C/0/1/0/all/0/1\">Chris Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastle_K/0/1/0/all/0/1\">Kathleen Rastle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChartSumm: A Comprehensive Benchmark for Automatic Chart Summarization of Long and Short Summaries. (arXiv:2304.13620v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13620","description":"<p>Automatic chart to text summarization is an effective tool for the visually\nimpaired people along with providing precise insights of tabular data in\nnatural language to the user. A large and well-structured dataset is always a\nkey part for data driven models. In this paper, we propose ChartSumm: a\nlarge-scale benchmark dataset consisting of a total of 84,363 charts along with\ntheir metadata and descriptions covering a wide range of topics and chart types\nto generate short and long summaries. Extensive experiments with strong\nbaseline models show that even though these models generate fluent and\ninformative summaries by achieving decent scores in various automatic\nevaluation metrics, they often face issues like suffering from hallucination,\nmissing out important data points, in addition to incorrect explanation of\ncomplex trends in the charts. We also investigated the potential of expanding\nChartSumm to other languages using automated translation tools. These make our\ndataset a challenging benchmark for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_R/0/1/0/all/0/1\">Raian Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_R/0/1/0/all/0/1\">Rizvi Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhad_A/0/1/0/all/0/1\">Abdullah Al Farhad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1\">Md Tahmid Rahman Laskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ashmafee_M/0/1/0/all/0/1\">Md. Hamjajul Ashmafee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_A/0/1/0/all/0/1\">Abu Raihan Mostofa Kamal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HausaNLP at SemEval-2023 Task 12: Leveraging African Low Resource TweetData for Sentiment Analysis. (arXiv:2304.13634v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13634","description":"<p>We present the findings of SemEval-2023 Task 12, a shared task on sentiment\nanalysis for low-resource African languages using Twitter dataset. The task\nfeatured three subtasks; subtask A is monolingual sentiment classification with\n12 tracks which are all monolingual languages, subtask B is multilingual\nsentiment classification using the tracks in subtask A and subtask C is a\nzero-shot sentiment classification. We present the results and findings of\nsubtask A, subtask B and subtask C. We also release the code on github. Our\ngoal is to leverage low-resource tweet data using pre-trained Afro-xlmr-large,\nAfriBERTa-Large, Bert-base-arabic-camelbert-da-sentiment (Arabic-camelbert),\nMultilingual-BERT (mBERT) and BERT models for sentiment analysis of 14 African\nlanguages. The datasets for these subtasks consists of a gold standard\nmulti-class labeled Twitter datasets from these languages. Our results\ndemonstrate that Afro-xlmr-large model performed better compared to the other\nmodels in most of the languages datasets. Similarly, Nigerian languages: Hausa,\nIgbo, and Yoruba achieved better performance compared to other languages and\nthis can be attributed to the higher volume of data present in the languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salahudeen_S/0/1/0/all/0/1\">Saheed Abdullahi Salahudeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawan_F/0/1/0/all/0/1\">Falalu Ibrahim Lawan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wali_A/0/1/0/all/0/1\">Ahmad Mustapha Wali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imam_A/0/1/0/all/0/1\">Amina Abubakar Imam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuaibu_A/0/1/0/all/0/1\">Aliyu Rabiu Shuaibu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yusuf_A/0/1/0/all/0/1\">Aliyu Yusuf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabiu_N/0/1/0/all/0/1\">Nur Bala Rabiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_M/0/1/0/all/0/1\">Musa Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adamu_S/0/1/0/all/0/1\">Shamsuddeen Umaru Adamu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aliyu_S/0/1/0/all/0/1\">Saminu Mohammad Aliyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadanya_M/0/1/0/all/0/1\">Murja Sani Gadanya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muaz_S/0/1/0/all/0/1\">Sanah Abdullahi Muaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_M/0/1/0/all/0/1\">Mahmoud Said Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdullahi_A/0/1/0/all/0/1\">Abdulkadir Abdullahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamoh_A/0/1/0/all/0/1\">Abdulmalik Yusuf Jamoh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Symmetric Dual Encoding Dense Retrieval Framework for Knowledge-Intensive Visual Question Answering. (arXiv:2304.13649v1 [cs.CV])","link":"http://arxiv.org/abs/2304.13649","description":"<p>Knowledge-Intensive Visual Question Answering (KI-VQA) refers to answering a\nquestion about an image whose answer does not lie in the image. This paper\npresents a new pipeline for KI-VQA tasks, consisting of a retriever and a\nreader. First, we introduce DEDR, a symmetric dual encoding dense retrieval\nframework in which documents and queries are encoded into a shared embedding\nspace using uni-modal (textual) and multi-modal encoders. We introduce an\niterative knowledge distillation approach that bridges the gap between the\nrepresentation spaces in these two encoders. Extensive evaluation on two\nwell-established KI-VQA datasets, i.e., OK-VQA and FVQA, suggests that DEDR\noutperforms state-of-the-art baselines by 11.6% and 30.9% on OK-VQA and FVQA,\nrespectively. Utilizing the passages retrieved by DEDR, we further introduce\nMM-FiD, an encoder-decoder multi-modal fusion-in-decoder model, for generating\na textual answer for KI-VQA tasks. MM-FiD encodes the question, the image, and\neach retrieved passage separately and uses all passages jointly in its decoder.\nCompared to competitive baselines in the literature, this approach leads to\n5.5% and 8.5% improvements in terms of question answering accuracy on OK-VQA\nand FVQA, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salemi_A/0/1/0/all/0/1\">Alireza Salemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pizzorno_J/0/1/0/all/0/1\">Juan Altmayer Pizzorno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Implicit Feedback to Improve Question Generation. (arXiv:2304.13664v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13664","description":"<p>Question Generation (QG) is a task of Natural Language Processing (NLP) that\naims at automatically generating questions from text. Many applications can\nbenefit from automatically generated questions, but often it is necessary to\ncurate those questions, either by selecting or editing them. This task is\ninformative on its own, but it is typically done post-generation, and, thus,\nthe effort is wasted. In addition, most existing systems cannot incorporate\nthis feedback back into them easily. In this work, we present a system, GEN,\nthat learns from such (implicit) feedback. Following a pattern-based approach,\nit takes as input a small set of sentence/question pairs and creates patterns\nwhich are then applied to new unseen sentences. Each generated question, after\nbeing corrected by the user, is used as a new seed in the next iteration, so\nmore patterns are created each time. We also take advantage of the corrections\nmade by the user to score the patterns and therefore rank the generated\nquestions. Results show that GEN is able to improve by learning from both\nlevels of implicit feedback when compared to the version with no learning,\nconsidering the top 5, 10, and 20 questions. Improvements go up from 10%,\ndepending on the metric and strategy used.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_H/0/1/0/all/0/1\">Hugo Rodrigues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nyberg_E/0/1/0/all/0/1\">Eric Nyberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coheur_L/0/1/0/all/0/1\">Luisa Coheur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HeySQuAD: A Spoken Question Answering Dataset. (arXiv:2304.13689v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13689","description":"<p>Human-spoken questions are critical to evaluating the performance of spoken\nquestion answering (SQA) systems that serve several real-world use cases\nincluding digital assistants. We present a new large-scale community-shared SQA\ndataset, HeySQuAD that consists of 76k human-spoken questions and 97k\nmachine-generated questions and corresponding textual answers derived from the\nSQuAD QA dataset. The goal of HeySQuAD is to measure the ability of machines to\nunderstand noisy spoken questions and answer the questions accurately. To this\nend, we run extensive benchmarks on the human-spoken and machine-generated\nquestions to quantify the differences in noise from both sources and its\nsubsequent impact on the model and answering accuracy. Importantly, for the\ntask of SQA, where we want to answer human-spoken questions, we observe that\ntraining using the transcribed human-spoken and original SQuAD questions leads\nto significant improvements (12.51%) over training using only the original\nSQuAD textual questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yijing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rallabandi_S/0/1/0/all/0/1\">SaiKrishna Rallabandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasamurthy_R/0/1/0/all/0/1\">Ravisutha Srinivasamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dakle_P/0/1/0/all/0/1\">Parag Pravin Dakle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gon_A/0/1/0/all/0/1\">Alolika Gon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_P/0/1/0/all/0/1\">Preethi Raghavan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond. (arXiv:2304.13712v1 [cs.CL])","link":"http://arxiv.org/abs/2304.13712","description":"<p>This paper presents a comprehensive and practical guide for practitioners and\nend-users working with Large Language Models (LLMs) in their downstream natural\nlanguage processing (NLP) tasks. We provide discussions and insights into the\nusage of LLMs from the perspectives of models, data, and downstream tasks.\nFirstly, we offer an introduction and brief summary of current GPT- and\nBERT-style LLMs. Then, we discuss the influence of pre-training data, training\ndata, and test data. Most importantly, we provide a detailed discussion about\nthe use and non-use cases of large language models for various natural language\nprocessing tasks, such as knowledge-intensive tasks, traditional natural\nlanguage understanding tasks, natural language generation tasks, emergent\nabilities, and considerations for specific tasks.We present various use cases\nand non-use cases to illustrate the practical applications and limitations of\nLLMs in real-world scenarios. We also try to understand the importance of data\nand the specific challenges associated with each NLP task. Furthermore, we\nexplore the impact of spurious biases on LLMs and delve into other essential\nconsiderations, such as efficiency, cost, and latency, to ensure a\ncomprehensive understanding of deploying LLMs in practice. This comprehensive\nguide aims to provide researchers and practitioners with valuable insights and\nbest practices for working with LLMs, thereby enabling the successful\nimplementation of these models in a wide range of NLP tasks. A curated list of\npractical guide resources of LLMs, regularly updated, can be found at\n\\url{https://github.com/Mooler0410/LLMsPracticalGuide}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingfeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hongye Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaotian Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1\">Qizhang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haoming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of GPT-3.5 and GPT-4 for supporting real-world information needs in healthcare delivery. (arXiv:2304.13714v1 [cs.AI])","link":"http://arxiv.org/abs/2304.13714","description":"<p>Despite growing interest in using large language models (LLMs) in healthcare,\ncurrent explorations do not assess the real-world utility and safety of LLMs in\nclinical settings. Our objective was to determine whether two LLMs can serve\ninformation needs submitted by physicians as questions to an informatics\nconsultation service in a safe and concordant manner. Sixty six questions from\nan informatics consult service were submitted to GPT-3.5 and GPT-4 via simple\nprompts. 12 physicians assessed the LLM responses' possibility of patient harm\nand concordance with existing reports from an informatics consultation service.\nPhysician assessments were summarized based on majority vote. For no questions\ndid a majority of physicians deem either LLM response as harmful. For GPT-3.5,\nresponses to 8 questions were concordant with the informatics consult report,\n20 discordant, and 9 were unable to be assessed. There were 29 responses with\nno majority on \"Agree\", \"Disagree\", and \"Unable to assess\". For GPT-4,\nresponses to 13 questions were concordant, 15 discordant, and 3 were unable to\nbe assessed. There were 35 responses with no majority. Responses from both LLMs\nwere largely devoid of overt harm, but less than 20% of the responses agreed\nwith an answer from an informatics consultation service, responses contained\nhallucinated references, and physicians were divided on what constitutes harm.\nThese results suggest that while general purpose LLMs are able to provide safe\nand credible responses, they often do not meet the specific information need of\na given question. A definitive evaluation of the usefulness of LLMs in\nhealthcare settings will likely require additional research on prompt\nengineering, calibration, and custom-tailoring of general purpose models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dash_D/0/1/0/all/0/1\">Debadutta Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapa_R/0/1/0/all/0/1\">Rahul Thapa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banda_J/0/1/0/all/0/1\">Juan M. Banda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1\">Akshay Swaminathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheatham_M/0/1/0/all/0/1\">Morgan Cheatham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashyap_M/0/1/0/all/0/1\">Mehr Kashyap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotecha_N/0/1/0/all/0/1\">Nikesh Kotecha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jonathan H. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gombar_S/0/1/0/all/0/1\">Saurabh Gombar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downing_L/0/1/0/all/0/1\">Lance Downing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedreira_R/0/1/0/all/0/1\">Rachel Pedreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goh_E/0/1/0/all/0/1\">Ethan Goh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnaout_A/0/1/0/all/0/1\">Angel Arnaout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morris_G/0/1/0/all/0/1\">Garret Kenn Morris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magon_H/0/1/0/all/0/1\">Honor Magon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1\">Matthew P Lungren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Nigam H. Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-linguistic differences in gender congruency effects: Evidence from meta-analyses. (arXiv:2109.03490v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.03490","description":"<p>It has been proposed that the order in which words are prepared for\nproduction depends on the speaker's language. When producing the translation\nequivalent of the small cat, speakers of German or Dutch select the\ngender-marked determiner at a relatively early stage of production. Speakers of\nFrench or Italian postpone the encoding of a determiner or adjective until the\nphonological form of the noun is available. Hence, even though the words are\nproduced in the same order (e.g., die kleine Katze in German, le petit chat in\nFrench), they are not planned in the same order and might require different\namounts of advanced planning prior to production onset. This distinction\nbetween early and late selection languages was proposed to account for the\nobservation that speakers of Germanic and Slavic languages, but not of Romance\nlanguages, are slower to name pictures in the context of a distractor word of a\ndifferent gender. Meta-analyses are conducted to provide the first direct test\nof this cross-linguistic difference and to test a prediction of the late\nselection hypothesis. They confirm the existence of the gender congruency\neffect in German/Slavic languages and its absence in Romance languages when\ntarget and distractor words are presented simultaneously. They do not allow\nconfirming the hypothesis that in the latter languages, a similar effect\nemerges when the presentation of the distractor is delayed. Overall, these\nanalyses confirm the cross-linguistic difference but show that the evidence\navailable to date is not sufficient to confirm or reject the late selection\nhypothesis as an explanation of this difference. We highlight specific\ndirections for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burki_A/0/1/0/all/0/1\">Audrey B&#xfc;rki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoven_E/0/1/0/all/0/1\">Emiel van den Hoven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiller_N/0/1/0/all/0/1\">Niels O. Schiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DImitrov_N/0/1/0/all/0/1\">Nikolay DImitrov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detection of sepsis during emergency department triage using machine learning. (arXiv:2204.07657v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2204.07657","description":"<p>Sepsis is a life-threatening condition with organ dysfunction and is a\nleading cause of death and critical illness worldwide. Even a few hours of\ndelay in the treatment of sepsis results in increased mortality. Early\ndetection of sepsis during emergency department triage would allow early\ninitiation of lab analysis, antibiotic administration, and other sepsis\ntreatment protocols. The purpose of this study was to compare sepsis detection\nperformance at ED triage (prior to the use of laboratory diagnostics) of the\nstandard sepsis screening algorithm (SIRS with source of infection) and a\nmachine learning algorithm trained on EHR triage data. A machine learning model\n(KATE Sepsis) was developed using patient encounters with triage data from\n16participating hospitals. KATE Sepsis and standard screening were\nretrospectively evaluated on the adult population of 512,949 medical records.\nKATE Sepsis demonstrates an AUC of 0.9423 (0.9401 - 0.9441) with sensitivity of\n71.09% (70.12% - 71.98%) and specificity of 94.81% (94.75% - 94.87%). Standard\nscreening demonstrates an AUC of 0.6826 (0.6774 - 0.6878) with sensitivity of\n40.8% (39.71% - 41.86%) and specificity of95.72% (95.68% - 95.78%). The KATE\nSepsis model trained to detect sepsis demonstrates 77.67% (75.78% -79.42%)\nsensitivity in detecting severe sepsis and 86.95% (84.2% - 88.81%) sensitivity\nin detecting septic shock. The standard screening protocol demonstrates 43.06%\n(41% - 45.87%) sensitivity in detecting severe sepsis and40% (36.55% - 43.26%)\nsensitivity in detecting septic shock. Future research should focus on the\nprospective impact of KATE Sepsis on administration of antibiotics, readmission\nrate, morbidity and mortality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ivanov_O/0/1/0/all/0/1\">Oleksandr Ivanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molander_K/0/1/0/all/0/1\">Karin Molander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunne_R/0/1/0/all/0/1\">Robert Dunne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Stephen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brecher_D/0/1/0/all/0/1\">Deena Brecher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Masek_K/0/1/0/all/0/1\">Kevin Masek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_E/0/1/0/all/0/1\">Erica Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lisa Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Travers_D/0/1/0/all/0/1\">Debbie Travers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delaney_D/0/1/0/all/0/1\">Deb Delaney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montgomery_K/0/1/0/all/0/1\">Kyla Montgomery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reilly_C/0/1/0/all/0/1\">Christian Reilly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Modelling with Pixels. (arXiv:2207.06991v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.06991","description":"<p>Language models are defined over a finite set of inputs, which creates a\nvocabulary bottleneck when we attempt to scale the number of supported\nlanguages. Tackling this bottleneck results in a trade-off between what can be\nrepresented in the embedding matrix and computational issues in the output\nlayer. This paper introduces PIXEL, the Pixel-based Encoder of Language, which\nsuffers from neither of these issues. PIXEL is a pretrained language model that\nrenders text as images, making it possible to transfer representations across\nlanguages based on orthographic similarity or the co-activation of pixels.\nPIXEL is trained to reconstruct the pixels of masked patches instead of\npredicting a distribution over tokens. We pretrain the 86M parameter PIXEL\nmodel on the same English data as BERT and evaluate on syntactic and semantic\ntasks in typologically diverse languages, including various non-Latin scripts.\nWe find that PIXEL substantially outperforms BERT on syntactic and semantic\nprocessing tasks on scripts that are not found in the pretraining data, but\nPIXEL is slightly weaker than BERT when working with Latin scripts.\nFurthermore, we find that PIXEL is more robust than BERT to orthographic\nattacks and linguistic code-switching, further confirming the benefits of\nmodelling language with pixels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rust_P/0/1/0/all/0/1\">Phillip Rust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lotz_J/0/1/0/all/0/1\">Jonas F. Lotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bugliarello_E/0/1/0/all/0/1\">Emanuele Bugliarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salesky_E/0/1/0/all/0/1\">Elizabeth Salesky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lhoneux_M/0/1/0/all/0/1\">Miryam de Lhoneux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language in a Bottle: Language Model Guided Concept Bottlenecks for Interpretable Image Classification. (arXiv:2211.11158v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.11158","description":"<p>Concept Bottleneck Models (CBM) are inherently interpretable models that\nfactor model decisions into human-readable concepts. They allow people to\neasily understand why a model is failing, a critical feature for high-stakes\napplications. CBMs require manually specified concepts and often under-perform\ntheir black box counterparts, preventing their broad adoption. We address these\nshortcomings and are first to show how to construct high-performance CBMs\nwithout manual specification of similar accuracy to black box models. Our\napproach, Language Guided Bottlenecks (LaBo), leverages a language model,\nGPT-3, to define a large space of possible bottlenecks. Given a problem domain,\nLaBo uses GPT-3 to produce factual sentences about categories to form candidate\nconcepts. LaBo efficiently searches possible bottlenecks through a novel\nsubmodular utility that promotes the selection of discriminative and diverse\ninformation. Ultimately, GPT-3's sentential concepts can be aligned to images\nusing CLIP, to form a bottleneck layer. Experiments demonstrate that LaBo is a\nhighly effective prior for concepts important to visual recognition. In the\nevaluation with 11 diverse datasets, LaBo bottlenecks excel at few-shot\nclassification: they are 11.7% more accurate than black box linear probes at 1\nshot and comparable with more data. Overall, LaBo demonstrates that inherently\ninterpretable models can be widely applied at similar, or better, performance\nthan black box approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panagopoulou_A/0/1/0/all/0/1\">Artemis Panagopoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shenghao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Daniel Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yatskar_M/0/1/0/all/0/1\">Mark Yatskar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting Is Programming: A Query Language for Large Language Models. (arXiv:2212.06094v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.06094","description":"<p>Large language models have demonstrated outstanding performance on a wide\nrange of tasks such as question answering and code generation. On a high level,\ngiven an input, a language model can be used to automatically complete the\nsequence in a statistically-likely way. Based on this, users prompt these\nmodels with language instructions or examples, to implement a variety of\ndownstream tasks. Advanced prompting methods can even imply interaction between\nthe language model, a user, and external tools such as calculators. However, to\nobtain state-of-the-art performance or adapt language models for specific\ntasks, complex task- and model-specific programs have to be implemented, which\nmay still require ad-hoc interaction.\n</p>\n<p>Based on this, we present the novel idea of Language Model Programming (LMP).\nLMP generalizes language model prompting from pure text prompts to an intuitive\ncombination of text prompting and scripting. Additionally, LMP allows\nconstraints to be specified over the language model output. This enables easy\nadaption to many tasks while abstracting language model internals and providing\nhigh-level semantics.\n</p>\n<p>To enable LMP, we implement LMQL(short for Language Model Query Language),\nwhich leverages the constraints and control flow from an LMP prompt to generate\nan efficient inference procedure that minimizes the number of expensive calls\nto the underlying language model.\n</p>\n<p>We show that LMQL can capture a wide range of state-of-the-art prompting\nmethods in an intuitive way, especially facilitating interactive flows that are\nchallenging to implement with existing high-level APIs. Our evaluation shows\nthat we retain or increase the accuracy on several downstream tasks, while also\nsignificantly reducing the required amount of computation or cost in the case\nof pay-to-use APIs (26-85% cost savings).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Beurer_Kellner_L/0/1/0/all/0/1\">Luca Beurer-Kellner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fischer_M/0/1/0/all/0/1\">Marc Fischer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Incorporating Knowledge into Document Summarisation: an Application of Prefix-Tuning on GPT-2. (arXiv:2301.11719v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11719","description":"<p>Despite the great development of document summarisation techniques nowadays,\nfactual inconsistencies between the generated summaries and the original texts\nstill occur from time to time. This study explores the possibility of adopting\nprompts to incorporate factual knowledge into generated summaries. We\nspecifically study prefix-tuning that uses a set of trainable continuous prefix\nprompts together with discrete natural language prompts to aid summary\ngeneration. Experimental results demonstrate that the trainable prefixes can\nhelp the summarisation model extract information from discrete prompts\nprecisely, thus generating knowledge-preserving summaries that are factually\nconsistent with the discrete prompts. The ROUGE improvements of the generated\nsummaries indicate that explicitly adding factual knowledge into the\nsummarisation process could boost the overall performance, showing great\npotential for applying it to other natural language processing tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Emma Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakeri_A/0/1/0/all/0/1\">Alireza Seyed Shakeri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predicting Sentence-Level Factuality of News and Bias of Media Outlets. (arXiv:2301.11850v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11850","description":"<p>Predicting the factuality of news reporting and bias of media outlets is\nsurely relevant for automated news credibility and fact-checking. While prior\nwork has focused on the veracity of news, we propose a fine-grained reliability\nanalysis of the entire media. Specifically, we study the prediction of\nsentence-level factuality of news reporting and bias of media outlets, which\nmay explain more accurately the overall reliability of the entire source. We\nfirst manually produced a large sentence-level dataset, titled \"FactNews\",\ncomposed of 6,191 sentences expertly annotated according to factuality and\nmedia bias definitions from AllSides. As a result, baseline models for\nsentence-level factuality prediction were presented by fine-tuning BERT.\nFinally, due to the severity of fake news and political polarization in Brazil,\nboth dataset and baseline were proposed for Portuguese. However, our approach\nmay be applied to any other language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1\">Francielle Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaidka_K/0/1/0/all/0/1\">Kokil Jaidka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pardo_T/0/1/0/all/0/1\">Thiago A. S. Pardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benevenuto_F/0/1/0/all/0/1\">Fabr&#xed;cio Benevenuto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Risks of Stealing the Decoding Algorithms of Language Models. (arXiv:2303.04729v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.04729","description":"<p>A key component of generating text from modern language models (LM) is the\nselection and tuning of decoding algorithms. These algorithms determine how to\ngenerate text from the internal probability distribution generated by the LM.\nThe process of choosing a decoding algorithm and tuning its hyperparameters\ntakes significant time, manual effort, and computation, and it also requires\nextensive human evaluation. Therefore, the identity and hyperparameters of such\ndecoding algorithms are considered to be extremely valuable to their owners. In\nthis work, we show, for the first time, that an adversary with typical API\naccess to an LM can steal the type and hyperparameters of its decoding\nalgorithms at very low monetary costs. Our attack is effective against popular\nLMs used in text generation APIs, including GPT-2 and GPT-3. We demonstrate the\nfeasibility of stealing such information with only a few dollars, e.g.,\n$\\$0.8$, $\\$1$, $\\$4$, and $\\$40$ for the four versions of GPT-3.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naseh_A/0/1/0/all/0/1\">Ali Naseh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_K/0/1/0/all/0/1\">Kalpesh Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Houmansadr_A/0/1/0/all/0/1\">Amir Houmansadr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learn What Is Possible, Then Choose What Is Best: Disentangling One-To-Many Relations in Language Through Text-based Games. (arXiv:2304.07258v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.07258","description":"<p>Language models pre-trained on large self-supervised corpora, followed by\ntask-specific fine-tuning has become the dominant paradigm in NLP. These\npre-training datasets often have a one-to-many structure--e.g. in dialogue\nthere are many valid responses for a given context. However, only some of these\nresponses will be desirable in our downstream task. This raises the question of\nhow we should train the model such that it can emulate the desirable\nbehaviours, but not the undesirable ones. Current approaches train in a\none-to-one setup--only a single target response is given for a single dialogue\ncontext--leading to models only learning to predict the average response, while\nignoring the full range of possible responses. Using text-based games as a\ntestbed, our approach, PASA, uses discrete latent variables to capture the\nrange of different behaviours represented in our larger pre-training dataset.\nWe then use knowledge distillation to distil the posterior probability\ndistribution into a student model. This probability distribution is far richer\nthan learning from only the hard targets of the dataset, and thus allows the\nstudent model to benefit from the richer range of actions the teacher model has\nlearned. Results show up to 49% empirical improvement over the previous\nstate-of-the-art model on the Jericho Walkthroughs dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Towle_B/0/1/0/all/0/1\">Benjamin Towle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Ke Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The language of sounds unheard: Exploring sensory semantic knowledge in large language models. (arXiv:2304.07830v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.07830","description":"<p>Semantic dimensions of sound have been playing a central role in\nunderstanding the nature of auditory sensory experience as well as the broader\nrelation between perception, language, and meaning. Accordingly, and given the\nrecent proliferation of large language models (LLMs), here we asked whether\nsuch models exhibit an organisation of perceptual semantics similar to those\nobserved in humans. Specifically, we prompted ChatGPT, a chatbot based on a\nstate-of-the-art LLM, to rate musical instrument sounds on a set of 20 semantic\nscales. We elicited multiple responses in separate chats, analogous to having\nmultiple human raters. ChatGPT generated semantic profiles that only partially\ncorrelated with human ratings, yet showed robust agreement along well-known\npsychophysical dimensions of musical sounds such as brightness (bright-dark)\nand pitch height (deep-high). Exploratory factor analysis suggested the same\ndimensionality but different spatial configuration of a latent factor space\nbetween the chatbot and human ratings. Unexpectedly, the chatbot showed degrees\nof internal variability that were comparable in magnitude to that of human\nratings. Our work highlights the potential of LLMs to capture salient\ndimensions of human sensory experience.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Siedenburg_K/0/1/0/all/0/1\">Kai Siedenburg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saitis_C/0/1/0/all/0/1\">Charalampos Saitis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM as A Robotic Brain: Unifying Egocentric Memory and Control. (arXiv:2304.09349v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.09349","description":"<p>Embodied AI focuses on the study and development of intelligent systems that\npossess a physical or virtual embodiment (i.e. robots) and are able to\ndynamically interact with their environment. Memory and control are the two\nessential parts of an embodied system and usually require separate frameworks\nto model each of them. In this paper, we propose a novel and generalizable\nframework called LLM-Brain: using Large-scale Language Model as a robotic brain\nto unify egocentric memory and control. The LLM-Brain framework integrates\nmultiple multimodal language models for robotic tasks, utilizing a zero-shot\nlearning approach. All components within LLM-Brain communicate using natural\nlanguage in closed-loop multi-round dialogues that encompass perception,\nplanning, control, and memory. The core of the system is an embodied LLM to\nmaintain egocentric memory and control the robot. We demonstrate LLM-Brain by\nexamining two downstream tasks: active exploration and embodied question\nanswering. The active exploration tasks require the robot to extensively\nexplore an unknown environment within a limited number of actions. Meanwhile,\nthe embodied question answering tasks necessitate that the robot answers\nquestions based on observations acquired during prior explorations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mai_J/0/1/0/all/0/1\">Jinjie Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_G/0/1/0/all/0/1\">Guocheng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1\">Mohamed Elhoseiny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bernard Ghanem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-NER: Named Entity Recognition via Large Language Models. (arXiv:2304.10428v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.10428","description":"<p>Despite the fact that large-scale Language Models (LLM) have achieved SOTA\nperformances on a variety of NLP tasks, its performance on NER is still\nsignificantly below supervised baselines. This is due to the gap between the\ntwo tasks the NER and LLMs: the former is a sequence labeling task in nature\nwhile the latter is a text-generation model.\n</p>\n<p>In this paper, we propose GPT-NER to resolve this issue. GPT-NER bridges the\ngap by transforming the sequence labeling task to a generation task that can be\neasily adapted by LLMs e.g., the task of finding location entities in the input\ntext \"Columbus is a city\" is transformed to generate the text sequence\n\"@@Columbus## is a city\", where special tokens @@## marks the entity to\nextract. To efficiently address the \"hallucination\" issue of LLMs, where LLMs\nhave a strong inclination to over-confidently label NULL inputs as entities, we\npropose a self-verification strategy by prompting LLMs to ask itself whether\nthe extracted entities belong to a labeled entity tag.\n</p>\n<p>We conduct experiments on five widely adopted NER datasets, and GPT-NER\nachieves comparable performances to fully supervised baselines, which is the\nfirst time as far as we are concerned. More importantly, we find that GPT-NER\nexhibits a greater ability in the low-resource and few-shot setups, when the\namount of training data is extremely scarce, GPT-NER performs significantly\nbetter than supervised models. This demonstrates the capabilities of GPT-NER in\nreal-world NER applications where the number of labeled examples is limited.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_R/0/1/0/all/0/1\">Rongbin Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Theory-of-Mind Performance in Large Language Models via Prompting. (arXiv:2304.11490v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.11490","description":"<p>Large language models (LLMs) excel in many tasks in 2023, but they still face\nchallenges in complex reasoning. Theory-of-mind (ToM) tasks, which require\nunderstanding agents' beliefs, goals, and mental states, are essential for\ncommon-sense reasoning involving humans, making it crucial to enhance LLM\nperformance in this area. This study measures the ToM performance of GPT-4 and\nthree GPT-3.5 variants (Davinci-2, Davinci-3, GPT-3.5-Turbo), and investigates\nthe effectiveness of in-context learning in improving their ToM comprehension.\nWe evaluated prompts featuring two-shot chain of thought reasoning and\nstep-by-step thinking instructions. We found that LLMs trained with\nReinforcement Learning from Human Feedback (RLHF) (all models excluding\nDavinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed\nbest in zero-shot settings, reaching nearly 80% ToM accuracy, but still fell\nshort of the 87% human accuracy on the test set. However, when supplied with\nprompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM\naccuracy, with GPT-4 reaching 100%. These results demonstrate that appropriate\nprompting enhances LLM ToM reasoning, and they underscore the context-dependent\nnature of LLM cognitive capacities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moghaddam_S/0/1/0/all/0/1\">Shima Rahimi Moghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honey_C/0/1/0/all/0/1\">Christopher J. Honey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ThreatCrawl: A BERT-based Focused Crawler for the Cybersecurity Domain. (arXiv:2304.11960v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2304.11960","description":"<p>Publicly available information contains valuable information for Cyber Threat\nIntelligence (CTI). This can be used to prevent attacks that have already taken\nplace on other systems. Ideally, only the initial attack succeeds and all\nsubsequent ones are detected and stopped. But while there are different\nstandards to exchange this information, a lot of it is shared in articles or\nblog posts in non-standardized ways. Manually scanning through multiple online\nportals and news pages to discover new threats and extracting them is a\ntime-consuming task. To automize parts of this scanning process, multiple\npapers propose extractors that use Natural Language Processing (NLP) to extract\nIndicators of Compromise (IOCs) from documents. However, while this already\nsolves the problem of extracting the information out of documents, the search\nfor these documents is rarely considered. In this paper, a new focused crawler\nis proposed called ThreatCrawl, which uses Bidirectional Encoder\nRepresentations from Transformers (BERT)-based models to classify documents and\nadapt its crawling path dynamically. While ThreatCrawl has difficulties to\nclassify the specific type of Open Source Intelligence (OSINT) named in texts,\ne.g., IOC content, it can successfully find relevant documents and modify its\npath accordingly. It yields harvest rates of up to 52%, which are, to the best\nof our knowledge, better than the current state of the art.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kuehn_P/0/1/0/all/0/1\">Philipp Kuehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1\">Mike Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayer_M/0/1/0/all/0/1\">Markus Bayer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuter_C/0/1/0/all/0/1\">Christian Reuter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-04-26T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}