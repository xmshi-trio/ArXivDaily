{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-27T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Divide et Impera: Multi-Transformer Architectures for Complex NLP-Tasks. (arXiv:2310.16897v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16897","description":"<p>The growing capabilities of transformer models pave the way for solving\nincreasingly complex NLP tasks. A key to supporting application-specific\nrequirements is the ability to fine-tune. However, compiling a fine-tuning\ndataset tailored to complex tasks is tedious and results in large datasets,\nlimiting the ability to control transformer output. We present an approach in\nwhich complex tasks are divided into simpler subtasks. Multiple transformer\nmodels are fine-tuned to one subtask each, and lined up to accomplish the\ncomplex task. This simplifies the compilation of fine-tuning datasets and\nincreases overall controllability. Using the example of reducing gender bias as\na complex task, we demonstrate our approach and show that it performs better\nthan using a single model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Helland_S/0/1/0/all/0/1\">Solveig Helland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavagnin_E/0/1/0/all/0/1\">Elena Gavagnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spindler_A/0/1/0/all/0/1\">Alexandre de Spindler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Physician Detection of Clinical Harm in Machine Translation: Quality Estimation Aids in Reliance and Backtranslation Identifies Critical Errors. (arXiv:2310.16924v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16924","description":"<p>A major challenge in the practical use of Machine Translation (MT) is that\nusers lack guidance to make informed decisions about when to rely on outputs.\nProgress in quality estimation research provides techniques to automatically\nassess MT quality, but these techniques have primarily been evaluated in vitro\nby comparison against human judgments outside of a specific context of use.\nThis paper evaluates quality estimation feedback in vivo with a human study\nsimulating decision-making in high-stakes medical settings. Using Emergency\nDepartment discharge instructions, we study how interventions based on quality\nestimation versus backtranslation assist physicians in deciding whether to show\nMT outputs to a patient. We find that quality estimation improves appropriate\nreliance on MT, but backtranslation helps physicians detect more clinically\nharmful errors that QE alone often misses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mehandru_N/0/1/0/all/0/1\">Nikita Mehandru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Sweta Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yimin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khoong_E/0/1/0/all/0/1\">Elaine C Khoong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carpuat_M/0/1/0/all/0/1\">Marine Carpuat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salehi_N/0/1/0/all/0/1\">Niloufar Salehi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CL-MASR: A Continual Learning Benchmark for Multilingual ASR. (arXiv:2310.16931v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16931","description":"<p>Modern multilingual automatic speech recognition (ASR) systems like Whisper\nhave made it possible to transcribe audio in multiple languages with a single\nmodel. However, current state-of-the-art ASR models are typically evaluated on\nindividual languages or in a multi-task setting, overlooking the challenge of\ncontinually learning new languages. There is insufficient research on how to\nadd new languages without losing valuable information from previous data.\nFurthermore, existing continual learning benchmarks focus mostly on vision and\nlanguage tasks, leaving continual learning for multilingual ASR largely\nunexplored. To bridge this gap, we propose CL-MASR, a benchmark designed for\nstudying multilingual ASR in a continual learning setting. CL-MASR provides a\ndiverse set of continual learning methods implemented on top of large-scale\npretrained ASR models, along with common metrics to assess the effectiveness of\nlearning new languages while addressing the issue of catastrophic forgetting.\nTo the best of our knowledge, CL-MASR is the first continual learning benchmark\nfor the multilingual ASR task. The code is available at\nhttps://github.com/speechbrain/benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Libera_L/0/1/0/all/0/1\">Luca Della Libera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousavi_P/0/1/0/all/0/1\">Pooneh Mousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaiem_S/0/1/0/all/0/1\">Salah Zaiem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subakan_C/0/1/0/all/0/1\">Cem Subakan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1\">Mirco Ravanelli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Transfers over Several Programming Languages. (arXiv:2310.16937v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16937","description":"<p>Large language models (LLMs) have recently become remarkably good at\nimproving developer productivity for high-resource programming languages. These\nmodels use two kinds of data: large amounts of unlabeled code samples for\npretraining and relatively smaller amounts of labeled code samples for\nfine-tuning or in-context learning. Unfortunately, many programming languages\nare low-resource, lacking labeled samples for most tasks and often even lacking\nunlabeled samples. Therefore, users of low-resource languages (e.g., legacy or\nnew languages) miss out on the benefits of LLMs. Cross-lingual transfer\nlearning uses data from a source language to improve model performance on a\ntarget language. It has been well-studied for natural languages, but has\nreceived little attention for programming languages. This paper reports\nextensive experiments on four tasks using a transformer-based LLM and 11 to 41\nprogramming languages to explore the following questions. First, how well\ncross-lingual transfer works for a given task across different language pairs.\nSecond, given a task and target language, how to best choose a source language.\nThird, the characteristics of a language pair that are predictive of transfer\nperformance, and fourth, how that depends on the given task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baltaji_R/0/1/0/all/0/1\">Razan Baltaji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujar_S/0/1/0/all/0/1\">Saurabh Pujar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandel_L/0/1/0/all/0/1\">Louis Mandel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirzel_M/0/1/0/all/0/1\">Martin Hirzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buratti_L/0/1/0/all/0/1\">Luca Buratti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_L/0/1/0/all/0/1\">Lav Varshney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zephyr: Direct Distillation of LM Alignment. (arXiv:2310.16944v1 [cs.LG])","link":"http://arxiv.org/abs/2310.16944","description":"<p>We aim to produce a smaller language model that is aligned to user intent.\nPrevious research has shown that applying distilled supervised fine-tuning\n(dSFT) on larger models significantly improves task accuracy; however, these\nmodels are unaligned, i.e. they do not respond well to natural prompts. To\ndistill this property, we experiment with the use of preference data from AI\nFeedback (AIF). Starting from a dataset of outputs ranked by a teacher model,\nwe apply distilled direct preference optimization (dDPO) to learn a chat model\nwith significantly improved intent alignment. The approach requires only a few\nhours of training without any additional sampling during fine-tuning. The final\nresult, Zephyr-7B, sets the state-of-the-art on chat benchmarks for 7B\nparameter models, and requires no human annotation. In particular, results on\nMT-Bench show that Zephyr-7B surpasses Llama2-Chat-70B, the best open-access\nRLHF-based model. Code, models, data, and tutorials for the system are\navailable at https://github.com/huggingface/alignment-handbook.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tunstall_L/0/1/0/all/0/1\">Lewis Tunstall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beeching_E/0/1/0/all/0/1\">Edward Beeching</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambert_N/0/1/0/all/0/1\">Nathan Lambert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajani_N/0/1/0/all/0/1\">Nazneen Rajani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rasul_K/0/1/0/all/0/1\">Kashif Rasul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belkada_Y/0/1/0/all/0/1\">Younes Belkada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shengyi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werra_L/0/1/0/all/0/1\">Leandro von Werra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fourrier_C/0/1/0/all/0/1\">Cl&#xe9;mentine Fourrier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habib_N/0/1/0/all/0/1\">Nathan Habib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarrazin_N/0/1/0/all/0/1\">Nathan Sarrazin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanseviero_O/0/1/0/all/0/1\">Omar Sanseviero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text Generation. (arXiv:2310.16964v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16964","description":"<p>Hallucination of text ungrounded in the input is a well-known problem in\nneural data-to-text generation. Many methods have been proposed to mitigate it,\nbut they typically require altering model architecture or collecting additional\ndata, and thus cannot be easily applied to an existing model. In this paper, we\nexplore a new way to mitigate hallucinations by combining the probabilistic\noutput of a generator language model (LM) with the output of a special \"text\ncritic\" classifier, which guides the generation by assessing the match between\nthe input data and the text generated so far. Our method does not need any\nchanges to the underlying LM's architecture or training procedure and can thus\nbe combined with any model and decoding operating on word probabilities. The\ncritic does not need any additional training data, using the base LM's training\ndata and synthetic negative examples. Our experimental results show that our\nmethod improves over the baseline on the WebNLG and OpenDialKG benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lango_M/0/1/0/all/0/1\">Mateusz Lango</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dusek_O/0/1/0/all/0/1\">Ond&#x159;ej Du&#x161;ek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Social Structures from Contemporary Literary Fiction using Character Interaction Graph -- Half Century Chronology of Influential Bengali Writers. (arXiv:2310.16968v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16968","description":"<p>Social structures and real-world incidents often influence contemporary\nliterary fiction. Existing research in literary fiction analysis explains these\nreal-world phenomena through the manual critical analysis of stories.\nConventional Natural Language Processing (NLP) methodologies, including\nsentiment analysis, narrative summarization, and topic modeling, have\ndemonstrated substantial efficacy in analyzing and identifying similarities\nwithin fictional works. However, the intricate dynamics of character\ninteractions within fiction necessitate a more nuanced approach that\nincorporates visualization techniques. Character interaction graphs (or\nnetworks) emerge as a highly suitable means for visualization and information\nretrieval from the realm of fiction. Therefore, we leverage character\ninteraction graphs with NLP-derived features to explore a diverse spectrum of\nsocietal inquiries about contemporary culture's impact on the landscape of\nliterary fiction. Our study involves constructing character interaction graphs\nfrom fiction, extracting relevant graph features, and exploiting these features\nto resolve various real-life queries. Experimental evaluation of influential\nBengali fiction over half a century demonstrates that character interaction\ngraphs can be highly effective in specific assessments and information\nretrieval from literary fiction. Our data and codebase are available at\nhttps://cutt.ly/fbMgGEM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tripto_N/0/1/0/all/0/1\">Nafis Irtiza Tripto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Mohammed Eunus Ali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"STEER: Semantic Turn Extension-Expansion Recognition for Voice Assistants. (arXiv:2310.16990v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16990","description":"<p>In the context of a voice assistant system, steering refers to the phenomenon\nin which a user issues a follow-up command attempting to direct or clarify a\nprevious turn. We propose STEER, a steering detection model that predicts\nwhether a follow-up turn is a user's attempt to steer the previous command.\nConstructing a training dataset for steering use cases poses challenges due to\nthe cold-start problem. To overcome this, we developed heuristic rules to\nsample opt-in usage data, approximating positive and negative samples without\nany annotation. Our experimental results show promising performance in\nidentifying steering intent, with over 95% accuracy on our sampled data.\nMoreover, STEER, in conjunction with our sampling strategy, aligns effectively\nwith real-world steering scenarios, as evidenced by its strong zero-shot\nperformance on a human-graded evaluation set. In addition to relying solely on\nuser transcripts as input, we introduce STEER+, an enhanced version of the\nmodel. STEER+ utilizes a semantic parse tree to provide more context on\nout-of-vocabulary words, such as named entities that often occur at the\nsentence boundary. This further improves model performance, reducing error rate\nin domains where entities frequently appear, such as messaging. Lastly, we\npresent a data analysis that highlights the improvement in user experience when\nvoice assistants support steering use cases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Leon Liyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiarui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moniz_J/0/1/0/all/0/1\">Joel Ruben Antony Moniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Aditya Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piraviperumal_D/0/1/0/all/0/1\">Dhivya Piraviperumal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Tien Dung Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tzou_N/0/1/0/all/0/1\">Nicholas Tzou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How well can machine-generated texts be identified and can language models be trained to avoid identification?. (arXiv:2310.16992v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16992","description":"<p>With the rise of generative pre-trained transformer models such as GPT-3,\nGPT-NeoX, or OPT, distinguishing human-generated texts from machine-generated\nones has become important. We refined five separate language models to generate\nsynthetic tweets, uncovering that shallow learning classification algorithms,\nlike Naive Bayes, achieve detection accuracy between 0.6 and 0.8.\n</p>\n<p>Shallow learning classifiers differ from human-based detection, especially\nwhen using higher temperature values during text generation, resulting in a\nlower detection rate. Humans prioritize linguistic acceptability, which tends\nto be higher at lower temperature values. In contrast, transformer-based\nclassifiers have an accuracy of 0.9 and above. We found that using a\nreinforcement learning approach to refine our generative models can\nsuccessfully evade BERT-based classifiers with a detection accuracy of 0.15 or\nless.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_S/0/1/0/all/0/1\">Sinclair Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steuber_F/0/1/0/all/0/1\">Florian Steuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Joao A. G. Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodosek_G/0/1/0/all/0/1\">Gabi Dreo Rodosek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quality > Quantity: Synthetic Corpora from Foundation Models for Closed-Domain Extractive Question Answering. (arXiv:2310.16995v1 [cs.CL])","link":"http://arxiv.org/abs/2310.16995","description":"<p>Domain adaptation, the process of training a model in one domain and applying\nit to another, has been extensively explored in machine learning. While\ntraining a domain-specific foundation model (FM) from scratch is an option,\nrecent methods have focused on adapting pre-trained FMs for domain-specific\ntasks. However, our experiments reveal that either approach does not\nconsistently achieve state-of-the-art (SOTA) results in the target domain. In\nthis work, we study extractive question answering within closed domains and\nintroduce the concept of targeted pre-training. This involves determining and\ngenerating relevant data to further pre-train our models, as opposed to the\nconventional philosophy of utilizing domain-specific FMs trained on a wide\nrange of data. Our proposed framework uses Galactica to generate synthetic,\n``targeted'' corpora that align with specific writing styles and topics, such\nas research papers and radiology reports. This process can be viewed as a form\nof knowledge distillation. We apply our method to two biomedical extractive\nquestion answering datasets, COVID-QA and RadQA, achieving a new benchmark on\nthe former and demonstrating overall improvements on the latter. Code available\nat https://github.com/saptarshi059/CDQA-v1-Targetted-PreTraining/tree/main.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Saptarshi Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heaton_C/0/1/0/all/0/1\">Connor Heaton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Shreya Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_P/0/1/0/all/0/1\">Prasenjit Mitra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"This Reads Like That: Deep Learning for Interpretable Natural Language Processing. (arXiv:2310.17010v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17010","description":"<p>Prototype learning, a popular machine learning method designed for inherently\ninterpretable decisions, leverages similarities to learned prototypes for\nclassifying new data. While it is mainly applied in computer vision, in this\nwork, we build upon prior research and further explore the extension of\nprototypical networks to natural language processing. We introduce a learned\nweighted similarity measure that enhances the similarity computation by\nfocusing on informative dimensions of pre-trained sentence embeddings.\nAdditionally, we propose a post-hoc explainability mechanism that extracts\nprediction-relevant words from both the prototype and input sentences. Finally,\nwe empirically demonstrate that our proposed method not only improves\npredictive performance on the AG News and RT Polarity datasets over a previous\nprototype-based approach, but also improves the faithfulness of explanations\ncompared to rationale-based recurrent convolutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fanconi_C/0/1/0/all/0/1\">Claudio Fanconi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandenhirtz_M/0/1/0/all/0/1\">Moritz Vandenhirtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Husmann_S/0/1/0/all/0/1\">Severin Husmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogt_J/0/1/0/all/0/1\">Julia E. Vogt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation for Emotion Detection in Small Imbalanced Text Data. (arXiv:2310.17015v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17015","description":"<p>Emotion recognition in text, the task of identifying emotions such as joy or\nanger, is a challenging problem in NLP with many applications. One of the\nchallenges is the shortage of available datasets that have been annotated with\nemotions. Certain existing datasets are small, follow different emotion\ntaxonomies and display imbalance in their emotion distribution. In this work,\nwe studied the impact of data augmentation techniques precisely when applied to\nsmall imbalanced datasets, for which current state-of-the-art models (such as\nRoBERTa) under-perform. Specifically, we utilized four data augmentation\nmethods (Easy Data Augmentation EDA, static and contextual Embedding-based, and\nProtAugment) on three datasets that come from different sources and vary in\nsize, emotion categories and distributions. Our experimental results show that\nusing the augmented data when training the classifier model leads to\nsignificant improvements. Finally, we conducted two case studies: a) directly\nusing the popular chat-GPT API to paraphrase text using different prompts, and\nb) using external data to augment the training set. Results show the promising\npotential of these methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koufakou_A/0/1/0/all/0/1\">Anna Koufakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grisales_D/0/1/0/all/0/1\">Diego Grisales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+jesus_R/0/1/0/all/0/1\">Ragy Costa de jesus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_O/0/1/0/all/0/1\">Oscar Fox</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Integrative Survey on Mental Health Conversational Agents to Bridge Computer Science and Medical Perspectives. (arXiv:2310.17017v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17017","description":"<p>Mental health conversational agents (a.k.a. chatbots) are widely studied for\ntheir potential to offer accessible support to those experiencing mental health\nchallenges. Previous surveys on the topic primarily consider papers published\nin either computer science or medicine, leading to a divide in understanding\nand hindering the sharing of beneficial knowledge between both domains. To\nbridge this gap, we conduct a comprehensive literature review using the PRISMA\nframework, reviewing 534 papers published in both computer science and\nmedicine. Our systematic review reveals 136 key papers on building mental\nhealth-related conversational agents with diverse characteristics of modeling\nand experimental design techniques. We find that computer science papers focus\non LLM techniques and evaluating response quality using automated metrics with\nlittle attention to the application while medical papers use rule-based\nconversational agents and outcome metrics to measure the health outcomes of\nparticipants. Based on our findings on transparency, ethics, and cultural\nheterogeneity in this review, we provide a few recommendations to help bridge\nthe disciplinary divide and enable the cross-disciplinary development of mental\nhealth conversational agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1\">Young Min Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rai_S/0/1/0/all/0/1\">Sunny Rai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1\">Lyle Ungar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1\">Jo&#xe3;o Sedoc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guntuku_S/0/1/0/all/0/1\">Sharath Chandra Guntuku</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditionally Combining Robot Skills using Large Language Models. (arXiv:2310.17019v1 [cs.LG])","link":"http://arxiv.org/abs/2310.17019","description":"<p>This paper combines two contributions. First, we introduce an extension of\nthe Meta-World benchmark, which we call \"Language-World,\" which allows a large\nlanguage model to operate in a simulated robotic environment using\nsemi-structured natural language queries and scripted skills described using\nnatural language. By using the same set of tasks as Meta-World, Language-World\nresults can be easily compared to Meta-World results, allowing for a point of\ncomparison between recent methods using Large Language Models (LLMs) and those\nusing Deep Reinforcement Learning. Second, we introduce a method we call Plan\nConditioned Behavioral Cloning (PCBC), that allows finetuning the behavior of\nhigh-level plans using end-to-end demonstrations. Using Language-World, we show\nthat PCBC is able to achieve strong performance in a variety of few-shot\nregimes, often achieving task generalization with as little as a single\ndemonstration. We have made Language-World available as open-source software at\nhttps://github.com/krzentner/language-world/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zentner_K/0/1/0/all/0/1\">K.R. Zentner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1\">Brian Ichter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1\">Gaurav S. Sukhatme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlled Decoding from Language Models. (arXiv:2310.17022v1 [cs.LG])","link":"http://arxiv.org/abs/2310.17022","description":"<p>We propose controlled decoding (CD), a novel off-policy reinforcement\nlearning method to control the autoregressive generation from language models\ntowards high reward outcomes. CD solves an off-policy reinforcement learning\nproblem through a value function for the reward, which we call a prefix scorer.\nThe prefix scorer is used at inference time to steer the generation towards\nhigher reward outcomes. We show that the prefix scorer may be trained on\n(possibly) off-policy data to predict the expected reward when decoding is\ncontinued from a partially decoded response. We empirically demonstrate that CD\nis effective as a control mechanism on Reddit conversations corpus. We also\nshow that the modularity of the design of CD makes it possible to control for\nmultiple rewards, effectively solving a multi-objective reinforcement learning\nproblem with no additional complexity. Finally, we show that CD can be applied\nin a novel blockwise fashion at inference-time, again without the need for any\ntraining-time changes, essentially bridging the gap between the popular\nbest-of-$K$ strategy and token-level reinforcement learning. This makes CD a\npromising approach for alignment of language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mudgal_S/0/1/0/all/0/1\">Sidharth Mudgal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganapathy_H/0/1/0/all/0/1\">Harish Ganapathy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">YaGuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Heng-Tze Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_M/0/1/0/all/0/1\">Michael Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1\">Trevor Strohman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1\">Ahmad Beirami</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Follow-on Question Suggestion via Voice Hints for Voice Assistants. (arXiv:2310.17034v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17034","description":"<p>The adoption of voice assistants like Alexa or Siri has grown rapidly,\nallowing users to instantly access information via voice search. Query\nsuggestion is a standard feature of screen-based search experiences, allowing\nusers to explore additional topics. However, this is not trivial to implement\nin voice-based settings. To enable this, we tackle the novel task of suggesting\nquestions with compact and natural voice hints to allow users to ask follow-up\nquestions.\n</p>\n<p>We define the task, ground it in syntactic theory and outline linguistic\ndesiderata for spoken hints. We propose baselines and an approach using\nsequence-to-sequence Transformers to generate spoken hints from a list of\nquestions. Using a new dataset of 6681 input questions and human written hints,\nwe evaluated the models with automatic metrics and human evaluation. Results\nshow that a naive approach of concatenating suggested questions creates poor\nvoice hints. Our approach, which applies a linguistically-motivated pretraining\ntask was strongly preferred by humans for producing the most natural hints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fetahu_B/0/1/0/all/0/1\">Besnik Fetahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faustini_P/0/1/0/all/0/1\">Pedro Faustini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castellucci_G/0/1/0/all/0/1\">Giuseppe Castellucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_A/0/1/0/all/0/1\">Anjie Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokhlenko_O/0/1/0/all/0/1\">Oleg Rokhlenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malmasi_S/0/1/0/all/0/1\">Shervin Malmasi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Surgical Fine-tuning for Language Encoders. (arXiv:2310.17041v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17041","description":"<p>Fine-tuning all the layers of a pre-trained neural language encoder (either\nusing all the parameters or using parameter-efficient methods) is often the\nde-facto way of adapting it to a new task. We show evidence that for different\ndownstream language tasks, fine-tuning only a subset of layers is sufficient to\nobtain performance that is close to and often better than fine-tuning all the\nlayers in the language encoder. We propose an efficient metric based on the\ndiagonal of the Fisher information matrix (FIM score), to select the candidate\nlayers for selective fine-tuning. We show, empirically on GLUE and SuperGLUE\ntasks and across distinct language encoders, that this metric can effectively\nselect layers leading to a strong downstream performance. Our work highlights\nthat task-specific information corresponding to a given downstream task is\noften localized within a few layers, and tuning only those is sufficient for\nstrong performance. Additionally, we demonstrate the robustness of the FIM\nscore to rank layers in a manner that remains constant during the optimization\nprocess.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lodha_A/0/1/0/all/0/1\">Abhilasha Lodha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belapurkar_G/0/1/0/all/0/1\">Gayatri Belapurkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalkapurkar_S/0/1/0/all/0/1\">Saloni Chalkapurkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1\">Yuanming Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Reshmi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Samyadeep Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrov_D/0/1/0/all/0/1\">Dmitrii Petrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Soundararajan Srinivasan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BOOST: Harnessing Black-Box Control to Boost Commonsense in LMs' Generation. (arXiv:2310.17054v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17054","description":"<p>Large language models (LLMs) such as GPT-3 have demonstrated a strong\ncapability to generate coherent and contextually relevant text. However, amidst\ntheir successes, a crucial issue persists: their generated outputs still lack\ncommonsense at times. Moreover, fine-tuning the entire LLM towards more\ncommonsensical outputs is computationally expensive if not infeasible. In this\npaper, we present a computation-efficient framework that steers a frozen\nPre-Trained Language Model (PTLM) towards more commonsensical generation (i.e.,\nproducing a plausible output that incorporates a list of concepts in a\nmeaningful way). Specifically, we first construct a reference-free evaluator\nthat assigns a sentence with a commonsensical score by grounding the sentence\nto a dynamic commonsense knowledge base from four different relational aspects.\nWe then use the scorer as the oracle for commonsense knowledge, and extend the\ncontrollable generation method called NADO to train an auxiliary head that\nguides a fixed PTLM to better satisfy the oracle. We test our framework on a\nseries of GPT-2-, Flan-T5-, and Alpaca-based language models (LMs) on two\nconstrained concept-to-sentence benchmarks. Human evaluation results\ndemonstrate that our method consistently leads to the most commonsensical\noutputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yufei Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Felix Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"math-PVS: A Large Language Model Framework to Map Scientific Publications to PVS Theories. (arXiv:2310.17064v1 [cs.AI])","link":"http://arxiv.org/abs/2310.17064","description":"<p>As artificial intelligence (AI) gains greater adoption in a wide variety of\napplications, it has immense potential to contribute to mathematical discovery,\nby guiding conjecture generation, constructing counterexamples, assisting in\nformalizing mathematics, and discovering connections between different\nmathematical areas, to name a few.\n</p>\n<p>While prior work has leveraged computers for exhaustive mathematical proof\nsearch, recent efforts based on large language models (LLMs) aspire to position\ncomputing platforms as co-contributors in the mathematical research process.\nDespite their current limitations in logic and mathematical tasks, there is\ngrowing interest in melding theorem proving systems with foundation models.\nThis work investigates the applicability of LLMs in formalizing advanced\nmathematical concepts and proposes a framework that can critically review and\ncheck mathematical reasoning in research papers. Given the noted reasoning\nshortcomings of LLMs, our approach synergizes the capabilities of proof\nassistants, specifically PVS, with LLMs, enabling a bridge between textual\ndescriptions in academic papers and formal specifications in PVS. By harnessing\nthe PVS environment, coupled with data ingestion and conversion mechanisms, we\nenvision an automated process, called \\emph{math-PVS}, to extract and formalize\nmathematical theorems from research papers, offering an innovative tool for\nacademic review and discovery.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saidi_H/0/1/0/all/0/1\">Hassen Saidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1\">Susmit Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahai_T/0/1/0/all/0/1\">Tuhin Sahai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers Learn Higher-Order Optimization Methods for In-Context Learning: A Study with Linear Models. (arXiv:2310.17086v1 [cs.LG])","link":"http://arxiv.org/abs/2310.17086","description":"<p>Transformers are remarkably good at in-context learning (ICL) -- learning\nfrom demonstrations without parameter updates -- but how they perform ICL\nremains a mystery. Recent work suggests that Transformers may learn in-context\nby internally running Gradient Descent, a first-order optimization method. In\nthis paper, we instead demonstrate that Transformers learn to implement\nhigher-order optimization methods to perform ICL. Focusing on in-context linear\nregression, we show that Transformers learn to implement an algorithm very\nsimilar to Iterative Newton's Method, a higher-order optimization method,\nrather than Gradient Descent. Empirically, we show that predictions from\nsuccessive Transformer layers closely match different iterations of Newton's\nMethod linearly, with each middle layer roughly computing 3 iterations. In\ncontrast, exponentially more Gradient Descent steps are needed to match an\nadditional Transformers layer; this suggests that Transformers have an\ncomparable rate of convergence with high-order methods such as Iterative\nNewton, which are exponentially faster than Gradient Descent. We also show that\nTransformers can learn in-context on ill-conditioned data, a setting where\nGradient Descent struggles but Iterative Newton succeeds. Finally, we show\ntheoretical results which support our empirical findings and have a close\ncorrespondence with them: we prove that Transformers can implement $k$\niterations of Newton's method with $\\mathcal{O}(k)$ layers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Deqing Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tian-Qi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharan_V/0/1/0/all/0/1\">Vatsal Sharan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FLEEK: Factual Error Detection and Correction with Evidence Retrieved from External Knowledge. (arXiv:2310.17119v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17119","description":"<p>Detecting factual errors in textual information, whether generated by large\nlanguage models (LLM) or curated by humans, is crucial for making informed\ndecisions. LLMs' inability to attribute their claims to external knowledge and\ntheir tendency to hallucinate makes it difficult to rely on their responses.\nHumans, too, are prone to factual errors in their writing. Since manual\ndetection and correction of factual errors is labor-intensive, developing an\nautomatic approach can greatly reduce human effort. We present FLEEK, a\nprototype tool that automatically extracts factual claims from text, gathers\nevidence from external knowledge sources, evaluates the factuality of each\nclaim, and suggests revisions for identified errors using the collected\nevidence. Initial empirical evaluation on fact error detection (77-85\\% F1)\nshows the potential of FLEEK. A video demo of FLEEK can be found at\nhttps://youtu.be/NapJFUlkPdQ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bayat_F/0/1/0/all/0/1\">Farima Fatahi Bayat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1\">Benjamin Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_Y/0/1/0/all/0/1\">Yisi Sang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belyi_A/0/1/0/all/0/1\">Anton Belyi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khorshidi_S/0/1/0/all/0/1\">Samira Khorshidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilyas_I/0/1/0/all/0/1\">Ihab F. Ilyas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunyao Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic Segmentation of Semi-Structured and Unstructured Conversational Datasets using Language Models. (arXiv:2310.17120v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17120","description":"<p>Breaking down a document or a conversation into multiple contiguous segments\nbased on its semantic structure is an important and challenging problem in NLP,\nwhich can assist many downstream tasks. However, current works on topic\nsegmentation often focus on segmentation of structured texts. In this paper, we\ncomprehensively analyze the generalization capabilities of state-of-the-art\ntopic segmentation models on unstructured texts. We find that: (a) Current\nstrategies of pre-training on a large corpus of structured text such as\nWiki-727K do not help in transferability to unstructured conversational data.\n(b) Training from scratch with only a relatively small-sized dataset of the\ntarget unstructured domain improves the segmentation results by a significant\nmargin. We stress-test our proposed Topic Segmentation approach by\nexperimenting with multiple loss functions, in order to mitigate effects of\nimbalance in unstructured conversational datasets. Our empirical evaluation\nindicates that Focal Loss function is a robust alternative to Cross-Entropy and\nre-weighted Cross-Entropy loss function when segmenting unstructured and\nsemi-structured chats.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1\">Reshmi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajal_H/0/1/0/all/0/1\">Harjeet Singh Kajal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamath_S/0/1/0/all/0/1\">Sharanya Kamath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_D/0/1/0/all/0/1\">Dhuri Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Samyadeep Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hansi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Soundararajan Srinivasan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Test-time Augmentation for Factual Probing. (arXiv:2310.17121v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17121","description":"<p>Factual probing is a method that uses prompts to test if a language model\n\"knows\" certain world knowledge facts. A problem in factual probing is that\nsmall changes to the prompt can lead to large changes in model output. Previous\nwork aimed to alleviate this problem by optimizing prompts via text mining or\nfine-tuning. However, such approaches are relation-specific and do not\ngeneralize to unseen relation types. Here, we propose to use test-time\naugmentation (TTA) as a relation-agnostic method for reducing sensitivity to\nprompt variations by automatically augmenting and ensembling prompts at test\ntime. Experiments show improved model calibration, i.e., with TTA, model\nconfidence better reflects prediction accuracy. Improvements in prediction\naccuracy are observed for some models, but for other models, TTA leads to\ndegradation. Error analysis identifies the difficulty of producing high-quality\nprompt variations as the main challenge for TTA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamoda_G/0/1/0/all/0/1\">Go Kamoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinzerling_B/0/1/0/all/0/1\">Benjamin Heinzerling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaguchi_K/0/1/0/all/0/1\">Keisuke Sakaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1\">Kentaro Inui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"M2C: Towards Automatic Multimodal Manga Complement. (arXiv:2310.17130v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17130","description":"<p>Multimodal manga analysis focuses on enhancing manga understanding with\nvisual and textual features, which has attracted considerable attention from\nboth natural language processing and computer vision communities. Currently,\nmost comics are hand-drawn and prone to problems such as missing pages, text\ncontamination, and aging, resulting in missing comic text content and seriously\nhindering human comprehension. In other words, the Multimodal Manga Complement\n(M2C) task has not been investigated, which aims to handle the aforementioned\nissues by providing a shared semantic space for vision and language\nunderstanding. To this end, we first propose the Multimodal Manga Complement\ntask by establishing a new M2C benchmark dataset covering two languages. First,\nwe design a manga argumentation method called MCoT to mine event knowledge in\ncomics with large language models. Then, an effective baseline FVP-M$^{2}$\nusing fine-grained visual prompts is proposed to support manga complement.\nExtensive experimental results show the effectiveness of FVP-M$^{2}$ method for\nMultimodal Mange Complement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1\">Hongcheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jiaqi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Incorporating Probing Signals into Multimodal Machine Translation via Visual Question-Answering Pairs. (arXiv:2310.17133v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17133","description":"<p>This paper presents an in-depth study of multimodal machine translation\n(MMT), examining the prevailing understanding that MMT systems exhibit\ndecreased sensitivity to visual information when text inputs are complete.\nInstead, we attribute this phenomenon to insufficient cross-modal interaction,\nrather than image information redundancy. A novel approach is proposed to\ngenerate parallel Visual Question-Answering (VQA) style pairs from the source\ntext, fostering more robust cross-modal interaction. Using Large Language\nModels (LLMs), we explicitly model the probing signal in MMT to convert it into\nVQA-style data to create the Multi30K-VQA dataset. An MMT-VQA multitask\nlearning framework is introduced to incorporate explicit probing signals from\nthe dataset into the MMT training process. Experimental results on two\nwidely-used benchmarks demonstrate the effectiveness of this novel approach.\nOur code and data would be available at:\n\\url{https://github.com/libeineu/MMT-VQA}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zuo_Y/0/1/0/all/0/1\">Yuxin Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Chuanhao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Symbolic Planning and Code Generation for Grounded Dialogue. (arXiv:2310.17140v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17140","description":"<p>Large language models (LLMs) excel at processing and generating both text and\ncode. However, LLMs have had limited applicability in grounded task-oriented\ndialogue as they are difficult to steer toward task objectives and fail to\nhandle novel grounding. We present a modular and interpretable grounded\ndialogue system that addresses these shortcomings by composing LLMs with a\nsymbolic planner and grounded code execution. Our system consists of a reader\nand planner: the reader leverages an LLM to convert partner utterances into\nexecutable code, calling functions that perform grounding. The translated\ncode's output is stored to track dialogue state, while a symbolic planner\ndetermines the next appropriate response. We evaluate our system's performance\non the demanding OneCommon dialogue task, involving collaborative reference\nresolution on abstract images of scattered dots. Our system substantially\noutperforms the previous state-of-the-art, including improving task success in\nhuman evaluations from 56% to 69% in the most challenging setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chiu_J/0/1/0/all/0/1\">Justin T. Chiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenting Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Derek Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaduguru_S/0/1/0/all/0/1\">Saujas Vaduguru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Supercharging academic writing with generative AI: framework, techniques, and caveats. (arXiv:2310.17143v1 [cs.CY])","link":"http://arxiv.org/abs/2310.17143","description":"<p>Academic writing is an indispensable yet laborious part of the research\nenterprise. This Perspective maps out principles and methods for using\ngenerative artificial intelligence (AI), specifically large language models\n(LLMs), to elevate the quality and efficiency of academic writing. We introduce\na human-AI collaborative framework that delineates the rationale (why), process\n(how), and nature (what) of AI engagement in writing. The framework pinpoints\nboth short-term and long-term reasons for engagement and their underlying\nmechanisms (e.g., cognitive offloading and imaginative stimulation). It reveals\nthe role of AI throughout the writing process, conceptualized through a\ntwo-stage model for human-AI collaborative writing, and the nature of AI\nassistance in writing, represented through a model of writing-assistance types\nand levels. Building on this framework, we describe effective prompting\ntechniques for incorporating AI into the writing routine (outlining, drafting,\nand editing) as well as strategies for maintaining rigorous scholarship,\nadhering to varied journal policies, and avoiding overreliance on AI.\nUltimately, the prudent integration of AI into academic writing can ease the\ncommunication burden, empower authors, accelerate discovery, and promote\ndiversity in science.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhicheng Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity. (arXiv:2310.17166v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17166","description":"<p>Cross-lingual transfer (XLT) is an emergent ability of multilingual language\nmodels that preserves their performance on a task to a significant extent when\nevaluated in languages that were not included in the fine-tuning process. While\nEnglish, due to its widespread usage, is typically regarded as the primary\nlanguage for model adaption in various tasks, recent studies have revealed that\nthe efficacy of XLT can be amplified by selecting the most appropriate source\nlanguages based on specific conditions. In this work, we propose the\nutilization of sub-network similarity between two languages as a proxy for\npredicting the compatibility of the languages in the context of XLT. Our\napproach is model-oriented, better reflecting the inner workings of foundation\nmodels. In addition, it requires only a moderate amount of raw text from\ncandidate languages, distinguishing it from the majority of previous methods\nthat rely on external resources. In experiments, we demonstrate that our method\nis more effective than baselines across diverse tasks. Specifically, it shows\nproficiency in ranking candidates for zero-shot XLT, achieving an improvement\nof 4.6% on average in terms of NDCG@3. We also provide extensive analyses that\nconfirm the utility of sub-networks for XLT prediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Taejun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinhyeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Deokyeong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Seong Hoon Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jihoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taeuk Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How do Language Models Bind Entities in Context?. (arXiv:2310.17191v1 [cs.LG])","link":"http://arxiv.org/abs/2310.17191","description":"<p>To correctly use in-context information, language models (LMs) must bind\nentities to their attributes. For example, given a context describing a \"green\nsquare\" and a \"blue circle\", LMs must bind the shapes to their respective\ncolors. We analyze LM representations and identify the binding ID mechanism: a\ngeneral mechanism for solving the binding problem, which we observe in every\nsufficiently large model from the Pythia and LLaMA families. Using causal\ninterventions, we show that LMs' internal activations represent binding\ninformation by attaching binding ID vectors to corresponding entities and\nattributes. We further show that binding ID vectors form a continuous subspace,\nin which distances between binding ID vectors reflect their discernability.\nOverall, our results uncover interpretable strategies in LMs for representing\nsymbolic knowledge in-context, providing a step towards understanding general\nin-context reasoning in large-scale LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiahai Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Data Fusion using the Tsetlin Machine. (arXiv:2310.17207v1 [cs.AI])","link":"http://arxiv.org/abs/2310.17207","description":"<p>We propose a novel way of assessing and fusing noisy dynamic data using a\nTsetlin Machine. Our approach consists in monitoring how explanations in form\nof logical clauses that a TM learns changes with possible noise in dynamic\ndata. This way TM can recognize the noise by lowering weights of previously\nlearned clauses, or reflect it in the form of new clauses. We also perform a\ncomprehensive experimental study using notably different datasets that\ndemonstrated high performance of the proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1\">Rupsa Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zadorozhny_V/0/1/0/all/0/1\">Vladimir I. Zadorozhny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1\">Ole-Christoffer Granmo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond MLE: Convex Learning for Text Generation. (arXiv:2310.17217v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17217","description":"<p>Maximum likelihood estimation (MLE) is a statistical method used to estimate\nthe parameters of a probability distribution that best explain the observed\ndata. In the context of text generation, MLE is often used to train generative\nlanguage models, which can then be used to generate new text. However, we argue\nthat MLE is not always necessary and optimal, especially for closed-ended text\ngeneration tasks like machine translation. In these tasks, the goal of model is\nto generate the most appropriate response, which does not necessarily require\nit to estimate the entire data distribution with MLE. To this end, we propose a\nnovel class of training objectives based on convex functions, which enables\ntext generation models to focus on highly probable outputs without having to\nestimate the entire data distribution. We investigate the theoretical\nproperties of the optimal predicted distribution when applying convex functions\nto the loss, demonstrating that convex functions can sharpen the optimal\ndistribution, thereby enabling the model to better capture outputs with high\nprobabilities. Experiments on various text generation tasks and models show the\neffectiveness of our approach. It enables autoregressive models to bridge the\ngap between greedy and beam search, and facilitates the learning of\nnon-autoregressive models with a maximum improvement of 9+ BLEU points.\nMoreover, our approach also exhibits significant impact on large language\nmodels (LLMs), substantially enhancing their generative capability on various\ntasks. Source code is available at\n\\url{https://github.com/ictnlp/Convex-Learning}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_C/0/1/0/all/0/1\">Chenze Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhengrui Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TST$^\\mathrm{R}$: Target Similarity Tuning Meets the Real World. (arXiv:2310.17228v1 [cs.AI])","link":"http://arxiv.org/abs/2310.17228","description":"<p>Target similarity tuning (TST) is a method of selecting relevant examples in\nnatural language (NL) to code generation through large language models (LLMs)\nto improve performance. Its goal is to adapt a sentence embedding model to have\nthe similarity between two NL inputs match the similarity between their\nassociated code outputs. In this paper, we propose different methods to apply\nand improve TST in the real world. First, we replace the sentence transformer\nwith embeddings from a larger model, which reduces sensitivity to the language\ndistribution and thus provides more flexibility in synthetic generation of\nexamples, and we train a tiny model that transforms these embeddings to a space\nwhere embedding similarity matches code similarity, which allows the model to\nremain a black box and only requires a few matrix multiplications at inference\ntime. Second, we how to efficiently select a smaller number of training\nexamples to train the TST model. Third, we introduce a ranking-based evaluation\nfor TST that does not require end-to-end code generation experiments, which can\nbe expensive to perform.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khatry_A/0/1/0/all/0/1\">Anirudh Khatry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1\">Sumit Gulwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Priyanshu Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singha_A/0/1/0/all/0/1\">Ananya Singha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mukul Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbruggen_G/0/1/0/all/0/1\">Gust Verbruggen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Codebook Features: Sparse and Discrete Interpretability for Neural Networks. (arXiv:2310.17230v1 [cs.LG])","link":"http://arxiv.org/abs/2310.17230","description":"<p>Understanding neural networks is challenging in part because of the dense,\ncontinuous nature of their hidden states. We explore whether we can train\nneural networks to have hidden states that are sparse, discrete, and more\ninterpretable by quantizing their continuous features into what we call\ncodebook features. Codebook features are produced by finetuning neural networks\nwith vector quantization bottlenecks at each layer, producing a network whose\nhidden features are the sum of a small number of discrete vector codes chosen\nfrom a larger codebook. Surprisingly, we find that neural networks can operate\nunder this extreme bottleneck with only modest degradation in performance. This\nsparse, discrete bottleneck also provides an intuitive way of controlling\nneural network behavior: first, find codes that activate when the desired\nbehavior is present, then activate those same codes during generation to elicit\nthat behavior. We validate our approach by training codebook Transformers on\nseveral different datasets. First, we explore a finite state machine dataset\nwith far more hidden states than neurons. In this setting, our approach\novercomes the superposition problem by assigning states to distinct codes, and\nwe find that we can make the neural network behave as if it is in a different\nstate by activating the code for that state. Second, we train Transformer\nlanguage models with up to 410M parameters on two natural language datasets. We\nidentify codes in these models representing diverse, disentangled concepts\n(ranging from negative emotions to months of the year) and find that we can\nguide the model to generate different topics by activating the appropriate\ncodes during inference. Overall, codebook features appear to be a promising\nunit of analysis and control for neural networks and interpretability. Our\ncodebase and models are open-sourced at\nhttps://github.com/taufeeque9/codebook-features.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tamkin_A/0/1/0/all/0/1\">Alex Tamkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taufeeque_M/0/1/0/all/0/1\">Mohammad Taufeeque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual Representation Learning. (arXiv:2310.17233v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17233","description":"<p>Expressing universal semantics common to all languages is helpful in\nunderstanding the meanings of complex and culture-specific sentences. The\nresearch theme underlying this scenario focuses on learning universal\nrepresentations across languages with the usage of massive parallel corpora.\nHowever, due to the sparsity and scarcity of parallel data, there is still a\nbig challenge in learning authentic ``universals'' for any two languages. In\nthis paper, we propose EMMA-X: an EM-like Multilingual pre-training Algorithm,\nto learn (X)Cross-lingual universals with the aid of excessive multilingual\nnon-parallel data. EMMA-X unifies the cross-lingual representation learning\ntask and an extra semantic relation prediction task within an EM framework.\nBoth the extra semantic classifier and the cross-lingual sentence encoder\napproximate the semantic relation of two sentences, and supervise each other\nuntil convergence. To evaluate EMMA-X, we conduct experiments on XRETE, a newly\nintroduced benchmark containing 12 widely studied cross-lingual tasks that\nfully depend on sentence-level representations. Results reveal that EMMA-X\nachieves state-of-the-art performance. Further geometric analysis of the built\nrepresentation space with three requirements demonstrates the superiority of\nEMMA-X over advanced models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1\">Ping Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiangpeng Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yue Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Baosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jun Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Entity and Relation Extraction with Span Pruning and Hypergraph Neural Networks. (arXiv:2310.17238v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17238","description":"<p>Entity and Relation Extraction (ERE) is an important task in information\nextraction. Recent marker-based pipeline models achieve state-of-the-art\nperformance, but still suffer from the error propagation issue. Also, most of\ncurrent ERE models do not take into account higher-order interactions between\nmultiple entities and relations, while higher-order modeling could be\nbeneficial.In this work, we propose HyperGraph neural network for ERE\n($\\hgnn{}$), which is built upon the PL-marker (a state-of-the-art marker-based\npipleline model). To alleviate error propagation,we use a high-recall pruner\nmechanism to transfer the burden of entity identification and labeling from the\nNER module to the joint module of our model. For higher-order modeling, we\nbuild a hypergraph, where nodes are entities (provided by the span pruner) and\nrelations thereof, and hyperedges encode interactions between two different\nrelations or between a relation and its associated subject and object entities.\nWe then run a hypergraph neural network for higher-order inference by applying\nmessage passing over the built hypergraph. Experiments on three widely used\nbenchmarks (\\acef{}, \\ace{} and \\scierc{}) for ERE task show significant\nimprovements over the previous state-of-the-art PL-marker.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhaohui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Songlin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?. (arXiv:2310.17271v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17271","description":"<p>Understanding how and what pre-trained language models (PLMs) learn about\nlanguage is an open challenge in natural language processing. Previous work has\nfocused on identifying whether they capture semantic and syntactic information,\nand how the data or the pre-training objective affects their performance.\nHowever, to the best of our knowledge, no previous work has specifically\nexamined how information loss in input token characters affects the performance\nof PLMs. In this study, we address this gap by pre-training language models\nusing small subsets of characters from individual tokens. Surprisingly, we find\nthat pre-training even under extreme settings, i.e. using only one character of\neach token, the performance retention in standard NLU benchmarks and probing\ntasks compared to full-token models is high. For instance, a model pre-trained\nonly on single first characters from tokens achieves performance retention of\napproximately $90$\\% and $77$\\% of the full-token model in SuperGLUE and GLUE\ntasks, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alajrami_A/0/1/0/all/0/1\">Ahmed Alajrami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Margatina_K/0/1/0/all/0/1\">Katerina Margatina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Logical Forms improve fidelity in Table-to-Text generation. (arXiv:2310.17279v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17279","description":"<p>Table-to-text systems generate natural language statements from structured\ndata like tables. While end-to-end techniques suffer from low factual\ncorrectness (fidelity), a previous study reported gains when using manual\nlogical forms (LF) that represent the selected content and the semantics of the\ntarget text. Given the manual step, it was not clear whether automatic LFs\nwould be effective, or whether the improvement came from content selection\nalone. We present TlT which, given a table and a selection of the content,\nfirst produces LFs and then the textual statement. We show for the first time\nthat automatic LFs improve quality, with an increase in fidelity of 30 points\nover a comparable system not using LFs. Our experiments allow to quantify the\nremaining challenges for high factual correctness, with automatic selection of\ncontent coming first, followed by better Logic-to-Text generation and, to a\nlesser extent, better Table-to-Logic parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alonso_I/0/1/0/all/0/1\">I&#xf1;igo Alonso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Abstract with Nonparametric Variational Information Bottleneck. (arXiv:2310.17284v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17284","description":"<p>Learned representations at the level of characters, sub-words, words and\nsentences, have each contributed to advances in understanding different NLP\ntasks and linguistic phenomena. However, learning textual embeddings is costly\nas they are tokenization specific and require different models to be trained\nfor each level of abstraction. We introduce a novel language representation\nmodel which can learn to compress to different levels of abstraction at\ndifferent layers of the same model. We apply Nonparametric Variational\nInformation Bottleneck (NVIB) to stacked Transformer self-attention layers in\nthe encoder, which encourages an information-theoretic compression of the\nrepresentations through the model. We find that the layers within the model\ncorrespond to increasing levels of abstraction and that their representations\nare more linguistically informed. Finally, we show that NVIB compression\nresults in a model which is more robust to adversarial perturbations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Behjati_M/0/1/0/all/0/1\">Melika Behjati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fehr_F/0/1/0/all/0/1\">Fabio Fehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparing Photorealistic and Animated Embodied Conversational Agents in Serious Games: An Empirical Study on User Experience. (arXiv:2310.17300v1 [cs.HC])","link":"http://arxiv.org/abs/2310.17300","description":"<p>Embodied conversational agents (ECAs) are paradigms of conversational user\ninterfaces in the form of embodied characters. While ECAs offer various\nmanipulable features, this paper focuses on a study conducted to explore two\ndistinct levels of presentation realism. The two agent versions are\nphotorealistic and animated. The study aims to provide insights and design\nsuggestions for speech-enabled ECAs within serious game environments. A\nwithin-subjects, two-by-two factorial design was employed for this research\nwith a cohort of 36 participants balanced for gender. The results showed that\nboth the photorealistic and the animated versions were perceived as highly\nusable, with overall mean scores of 5.76 and 5.71, respectively. However, 69.4\nper cent of the participants stated they preferred the photorealistic version,\n25 per cent stated they preferred the animated version and 5.6 per cent had no\nstated preference. The photorealistic agents were perceived as more realistic\nand human-like, while the animated characters made the task feel more like a\ngame. Even though the agents' realism had no significant effect on usability,\nit positively influenced participants' perceptions of the agent. This research\naims to lay the groundwork for future studies on ECA realism's impact in\nserious games across diverse contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Korre_D/0/1/0/all/0/1\">Danai Korre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language. (arXiv:2310.17306v1 [cs.AI])","link":"http://arxiv.org/abs/2310.17306","description":"<p>Formatting is an important property in tables for visualization,\npresentation, and analysis. Spreadsheet software allows users to automatically\nformat their tables by writing data-dependent conditional formatting (CF)\nrules. Writing such rules is often challenging for users as it requires them to\nunderstand and implement the underlying logic. We present FormaT5, a\ntransformer-based model that can generate a CF rule given the target table and\na natural language description of the desired formatting logic. We find that\nuser descriptions for these tasks are often under-specified or ambiguous,\nmaking it harder for code generation systems to accurately learn the desired\nrule in a single step. To tackle this problem of under-specification and\nminimise argument errors, FormaT5 learns to predict placeholders though an\nabstention objective. These placeholders can then be filled by a second model\nor, when examples of rows that should be formatted are available, by a\nprogramming-by-example system. To evaluate FormaT5 on diverse and real\nscenarios, we create an extensive benchmark of 1053 CF tasks, containing\nreal-world descriptions collected from four different sources. We release our\nbenchmarks to encourage research in this area. Abstention and filling allow\nFormaT5 to outperform 8 different neural approaches on our benchmarks, both\nwith and without examples. Our results illustrate the value of building\ndomain-specific learning systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mukul Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambronero_J/0/1/0/all/0/1\">Jos&#xe9; Cambronero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1\">Sumit Gulwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negreanu_C/0/1/0/all/0/1\">Carina Negreanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nouri_E/0/1/0/all/0/1\">Elnaz Nouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raza_M/0/1/0/all/0/1\">Mohammad Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbruggen_G/0/1/0/all/0/1\">Gust Verbruggen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Ensemble Method Based on the Combination of Transformers with Convolutional Neural Networks to Detect Artificially Generated Text. (arXiv:2310.17312v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17312","description":"<p>Thanks to the state-of-the-art Large Language Models (LLMs), language\ngeneration has reached outstanding levels. These models are capable of\ngenerating high quality content, thus making it a challenging task to detect\ngenerated text from human-written content. Despite the advantages provided by\nNatural Language Generation, the inability to distinguish automatically\ngenerated text can raise ethical concerns in terms of authenticity.\nConsequently, it is important to design and develop methodologies to detect\nartificial content. In our work, we present some classification models\nconstructed by ensembling transformer models such as Sci-BERT, DeBERTa and\nXLNet, with Convolutional Neural Networks (CNNs). Our experiments demonstrate\nthat the considered ensemble architectures surpass the performance of the\nindividual transformer models for classification. Furthermore, the proposed\nSciBERT-CNN ensemble model produced an F1-score of 98.36% on the ALTA shared\ntask 2023 data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liyanage_V/0/1/0/all/0/1\">Vijini Liyanage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buscaldi_D/0/1/0/all/0/1\">Davide Buscaldi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nabra: Syrian Arabic Dialects with Morphological Annotations. (arXiv:2310.17315v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17315","description":"<p>This paper presents Nabra, a corpora of Syrian Arabic dialects with\nmorphological annotations. A team of Syrian natives collected more than 6K\nsentences containing about 60K words from several sources including social\nmedia posts, scripts of movies and series, lyrics of songs and local proverbs\nto build Nabra. Nabra covers several local Syrian dialects including those of\nAleppo, Damascus, Deir-ezzur, Hama, Homs, Huran, Latakia, Mardin, Raqqah, and\nSuwayda. A team of nine annotators annotated the 60K tokens with full\nmorphological annotations across sentence contexts. We trained the annotators\nto follow methodological annotation guidelines to ensure unique morpheme\nannotations, and normalized the annotations. F1 and kappa agreement scores\nranged between 74% and 98% across features, showing the excellent quality of\nNabra annotations. Our corpora are open-source and publicly available as part\nof the Currasat portal https://sina.birzeit.edu/currasat.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nayouf_A/0/1/0/all/0/1\">Amal Nayouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammouda_T/0/1/0/all/0/1\">Tymaa Hammouda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarrar_M/0/1/0/all/0/1\">Mustafa Jarrar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaraket_F/0/1/0/all/0/1\">Fadi Zaraket</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurdy_M/0/1/0/all/0/1\">Mohamad-Bassam Kurdy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Arabic Fine-Grained Entity Recognition. (arXiv:2310.17333v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17333","description":"<p>Traditional NER systems are typically trained to recognize coarse-grained\nentities, and less attention is given to classifying entities into a hierarchy\nof fine-grained lower-level subtypes. This article aims to advance Arabic NER\nwith fine-grained entities. We chose to extend Wojood (an open-source Nested\nArabic Named Entity Corpus) with subtypes. In particular, four main entity\ntypes in Wojood, geopolitical entity (GPE), location (LOC), organization (ORG),\nand facility (FAC), are extended with 31 subtypes. To do this, we first revised\nWojood's annotations of GPE, LOC, ORG, and FAC to be compatible with the LDC's\nACE guidelines, which yielded 5, 614 changes. Second, all mentions of GPE, LOC,\nORG, and FAC (~44K) in Wojood are manually annotated with the LDC's ACE\nsub-types. We refer to this extended version of Wojood as WojoodF ine. To\nevaluate our annotations, we measured the inter-annotator agreement (IAA) using\nboth Cohen's Kappa and F1 score, resulting in 0.9861 and 0.9889, respectively.\nTo compute the baselines of WojoodF ine, we fine-tune three pre-trained Arabic\nBERT encoders in three settings: flat NER, nested NER and nested NER with\nsubtypes and achieved F1 score of 0.920, 0.866, and 0.885, respectively. Our\ncorpus and models are open-source and available at\nhttps://sina.birzeit.edu/wojood/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liqreina_H/0/1/0/all/0/1\">Haneen Liqreina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jarrar_M/0/1/0/all/0/1\">Mustafa Jarrar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalilia_M/0/1/0/all/0/1\">Mohammed Khalilia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Shangiti_A/0/1/0/all/0/1\">Ahmed Oumar El-Shangiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AbdulMageed_M/0/1/0/all/0/1\">Muhammad AbdulMageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ACT-SQL: In-Context Learning for Text-to-SQL with Automatically-Generated Chain-of-Thought. (arXiv:2310.17342v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17342","description":"<p>Recently Large Language Models (LLMs) have been proven to have strong\nabilities in various domains and tasks. We study the problem of prompt\ndesigning in the text-to-SQL task and attempt to improve the LLMs' reasoning\nability when generating SQL queries. Besides the trivial few-shot in-context\nlearning setting, we design our chain-of-thought (CoT) prompt with a similar\nmethod to schema linking. We provide a method named ACT-SQL to automatically\ngenerate auto-CoT exemplars and thus the whole process doesn't need manual\nlabeling. Our approach is cost-saving since we only use the LLMs' API call once\nwhen generating one SQL query. Furthermore, we extend our in-context learning\nmethod to the multi-turn text-to-SQL task. The experiment results show that the\nLLMs' performance can benefit from our ACT-SQL approach. Our approach achieves\nSOTA performance on the Spider dev set among existing in-context learning\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanchong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hongshen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cultural Adaptation of Recipes. (arXiv:2310.17353v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17353","description":"<p>Building upon the considerable advances in Large Language Models (LLMs), we\nare now equipped to address more sophisticated tasks demanding a nuanced\nunderstanding of cross-cultural contexts. A key example is recipe adaptation,\nwhich goes beyond simple translation to include a grasp of ingredients,\nculinary techniques, and dietary preferences specific to a given culture. We\nintroduce a new task involving the translation and cultural adaptation of\nrecipes between Chinese and English-speaking cuisines. To support this\ninvestigation, we present CulturalRecipes, a unique dataset comprised of\nautomatically paired recipes written in Mandarin Chinese and English. This\ndataset is further enriched with a human-written and curated test set. In this\nintricate task of cross-cultural recipe adaptation, we evaluate the performance\nof various methods, including GPT-4 and other LLMs, traditional machine\ntranslation, and information retrieval techniques. Our comprehensive analysis\nincludes both automatic and human evaluation metrics. While GPT-4 exhibits\nimpressive abilities in adapting Chinese recipes into English, it still lags\nbehind human expertise when translating English recipes into Chinese. This\nunderscores the multifaceted nature of cultural adaptations. We anticipate that\nthese insights will significantly contribute to future research on\nculturally-aware language models and their practical application in culturally\ndiverse contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kementchedjhieva_Y/0/1/0/all/0/1\">Yova Kementchedjhieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1\">Ruixiang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karamolegkou_A/0/1/0/all/0/1\">Antonia Karamolegkou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Li Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dare_M/0/1/0/all/0/1\">Megan Dare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Donatelli_L/0/1/0/all/0/1\">Lucia Donatelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1\">Daniel Hershcovich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers. (arXiv:2310.17369v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17369","description":"<p>Research in psychopathology has shown that, at an aggregate level, the\npatterns of emotional change over time -- emotion dynamics -- are indicators of\none's mental health. One's patterns of emotion change have traditionally been\ndetermined through self-reports of emotions; however, there are known issues\nwith accuracy, bias, and convenience. Recent approaches to determining emotion\ndynamics from one's everyday utterances, addresses many of these concerns, but\nit is not yet known whether these measures of utterance emotion dynamics (UED)\ncorrelate with mental health diagnoses. Here, for the first time, we study the\nrelationship between tweet emotion dynamics and mental health disorders. We\nfind that each of the UED metrics studied varied by the user's self-disclosed\ndiagnosis. For example: average valence was significantly higher (i.e., more\npositive text) in the control group compared to users with ADHD, MDD, and PTSD.\nValence variability was significantly lower in the control group compared to\nADHD, depression, bipolar disorder, MDD, PTSD, and OCD but not PPD. Rise and\nrecovery rates of valence also exhibited significant differences from the\ncontrol. This work provides important early evidence for how linguistic cues\npertaining to emotion dynamics can play a crucial role as biosocial markers for\nmental illnesses and aid in the understanding, diagnosis, and management of\nmental health disorders.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_D/0/1/0/all/0/1\">Daniela Teodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_T/0/1/0/all/0/1\">Tiffany Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fyshe_A/0/1/0/all/0/1\">Alona Fyshe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue-based generation of self-driving simulation scenarios using Large Language Models. (arXiv:2310.17372v1 [cs.AI])","link":"http://arxiv.org/abs/2310.17372","description":"<p>Simulation is an invaluable tool for developing and evaluating controllers\nfor self-driving cars. Current simulation frameworks are driven by\nhighly-specialist domain specific languages, and so a natural language\ninterface would greatly enhance usability. But there is often a gap, consisting\nof tacit assumptions the user is making, between a concise English utterance\nand the executable code that captures the user's intent. In this paper we\ndescribe a system that addresses this issue by supporting an extended\nmultimodal interaction: the user can follow up prior instructions with\nrefinements or revisions, in reaction to the simulations that have been\ngenerated from their utterances so far. We use Large Language Models (LLMs) to\nmap the user's English utterances in this interaction into domain-specific\ncode, and so we explore the extent to which LLMs capture the context\nsensitivity that's necessary for computing the speaker's intended message in\ndiscourse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miceli_Barone_A/0/1/0/all/0/1\">Antonio Valerio Miceli-Barone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lascarides_A/0/1/0/all/0/1\">Alex Lascarides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Innes_C/0/1/0/all/0/1\">Craig Innes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToxicChat: Unveiling Hidden Challenges of Toxicity Detection in Real-World User-AI Conversation. (arXiv:2310.17389v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17389","description":"<p>Despite remarkable advances that large language models have achieved in\nchatbots, maintaining a non-toxic user-AI interactive environment has become\nincreasingly critical nowadays. However, previous efforts in toxicity detection\nhave been mostly based on benchmarks derived from social media content, leaving\nthe unique challenges inherent to real-world user-AI interactions\ninsufficiently explored. In this work, we introduce ToxicChat, a novel\nbenchmark based on real user queries from an open-source chatbot. This\nbenchmark contains the rich, nuanced phenomena that can be tricky for current\ntoxicity detection models to identify, revealing a significant domain\ndifference compared to social media content. Our systematic evaluation of\nmodels trained on existing toxicity datasets has shown their shortcomings when\napplied to this unique domain of ToxicChat. Our work illuminates the\npotentially overlooked challenges of toxicity detection in real-world user-AI\nconversations. In the future, ToxicChat can be a valuable resource to drive\nfurther advancements toward building a safe and healthy environment for user-AI\ninteractions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongqi Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yangkun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuxin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yujia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meaning and understanding in large language models. (arXiv:2310.17407v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17407","description":"<p>Can a machine understand the meanings of natural language? Recent\ndevelopments in the generative large language models (LLMs) of artificial\nintelligence have led to the belief that traditional philosophical assumptions\nabout machine understanding of language need to be revised. This article\ncritically evaluates the prevailing tendency to regard machine language\nperformance as mere syntactic manipulation and the simulation of understanding,\nwhich is only partial and very shallow, without sufficient referential\ngrounding in the world. The aim is to highlight the conditions crucial to\nattributing natural language understanding to state-of-the-art LLMs, where it\ncan be legitimately argued that LLMs not only use syntax but also semantics,\ntheir understanding not being simulated but duplicated; and determine how they\nground the meanings of linguistic expressions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Havlik_V/0/1/0/all/0/1\">Vladim&#xed;r Havl&#xed;k</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tackling the Matrix Multiplication Micro-kernel Generation with Exo. (arXiv:2310.17408v1 [cs.MS])","link":"http://arxiv.org/abs/2310.17408","description":"<p>The optimization of the matrix multiplication (or GEMM) has been a need\nduring the last decades. This operation is considered the flagship of current\nlinear algebra libraries such as BLIS, OpenBLAS, or Intel OneAPI because of its\nwidespread use in a large variety of scientific applications. The GEMM is\nusually implemented following the GotoBLAS philosophy, which tiles the GEMM\noperands and uses a series of nested loops for performance improvement. These\napproaches extract the maximum computational power of the architectures through\nsmall pieces of hardware-oriented, high-performance code called micro-kernel.\nHowever, this approach forces developers to generate, with a non-negligible\neffort, a dedicated micro-kernel for each new hardware.\n</p>\n<p>In this work, we present a step-by-step procedure for generating\nmicro-kernels with the Exo compiler that performs close to (or even better\nthan) manually developed microkernels written with intrinsic functions or\nassembly language. Our solution also improves the portability of the generated\ncode, since a hardware target is fully specified by a concise library-based\ndescription of its instructions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Castello_A/0/1/0/all/0/1\">Adri&#xe1;n Castell&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellavita_J/0/1/0/all/0/1\">Julian Bellavita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_G/0/1/0/all/0/1\">Grace Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ikarashi_Y/0/1/0/all/0/1\">Yuka Ikarashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_H/0/1/0/all/0/1\">H&#xe9;ctor Mart&#xed;nez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing GPT-3.5-turbo for Rhetorical Role Prediction in Legal Cases. (arXiv:2310.17413v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17413","description":"<p>We propose a comprehensive study of one-stage elicitation techniques for\nquerying a large pre-trained generative transformer (GPT-3.5-turbo) in the\nrhetorical role prediction task of legal cases. This task is known as requiring\ntextual context to be addressed. Our study explores strategies such as zero-few\nshots, task specification with definitions and clarification of annotation\nambiguities, textual context and reasoning with general prompts and specific\nquestions. We show that the number of examples, the definition of labels, the\npresentation of the (labelled) textual context and specific questions about\nthis context have a positive influence on the performance of the model. Given\nnon-equivalent test set configurations, we observed that prompting with a few\nlabelled examples from direct context can lead the model to a better\nperformance than a supervised fined-tuned multi-class classifier based on the\nBERT encoder (weighted F1 score of = 72%). But there is still a gap to reach\nthe performance of the best systems = 86%) in the LegalEval 2023 task which, on\nthe other hand, require dedicated resources, architectures and training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belfathi_A/0/1/0/all/0/1\">Anas Belfathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_N/0/1/0/all/0/1\">Nicolas Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monceaux_L/0/1/0/all/0/1\">Laura Monceaux</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PETA: Evaluating the Impact of Protein Transfer Learning with Sub-word Tokenization on Downstream Applications. (arXiv:2310.17415v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17415","description":"<p>Large protein language models are adept at capturing the underlying\nevolutionary information in primary structures, offering significant practical\nvalue for protein engineering. Compared to natural language models, protein\namino acid sequences have a smaller data volume and a limited combinatorial\nspace. Choosing an appropriate vocabulary size to optimize the pre-trained\nmodel is a pivotal issue. Moreover, despite the wealth of benchmarks and\nstudies in the natural language community, there remains a lack of a\ncomprehensive benchmark for systematically evaluating protein language model\nquality. Given these challenges, PETA trained language models with 14 different\nvocabulary sizes under three tokenization methods. It conducted thousands of\ntests on 33 diverse downstream datasets to assess the models' transfer learning\ncapabilities, incorporating two classification heads and three random seeds to\nmitigate potential biases. Extensive experiments indicate that vocabulary sizes\nbetween 50 and 200 optimize the model, whereas sizes exceeding 800\ndetrimentally affect the model's representational performance. Our code, model\nweights and datasets are available at\nhttps://github.com/ginnm/ProteinPretraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1\">Pan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Ziyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Huiqun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_G/0/1/0/all/0/1\">Guisheng Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Liang Hong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"''Fifty Shades of Bias'': Normative Ratings of Gender Bias in GPT Generated English Text. (arXiv:2310.17428v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17428","description":"<p>Language serves as a powerful tool for the manifestation of societal belief\nsystems. In doing so, it also perpetuates the prevalent biases in our society.\nGender bias is one of the most pervasive biases in our society and is seen in\nonline and offline discourses. With LLMs increasingly gaining human-like\nfluency in text generation, gaining a nuanced understanding of the biases these\nsystems can generate is imperative. Prior work often treats gender bias as a\nbinary classification task. However, acknowledging that bias must be perceived\nat a relative scale; we investigate the generation and consequent receptivity\nof manual annotators to bias of varying degrees. Specifically, we create the\nfirst dataset of GPT-generated English text with normative ratings of gender\nbias. Ratings were obtained using Best--Worst Scaling -- an efficient\ncomparative annotation framework. Next, we systematically analyze the variation\nof themes of gender biases in the observed ranking and show that\nidentity-attack is most closely related to gender bias. Finally, we show the\nperformance of existing automated models trained on related concepts on our\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1\">Rishav Hada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seth_A/0/1/0/all/0/1\">Agrima Seth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diddee_H/0/1/0/all/0/1\">Harshita Diddee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_K/0/1/0/all/0/1\">Kalika Bali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialect Adaptation and Data Augmentation for Low-Resource ASR: TalTech Systems for the MADASR 2023 Challenge. (arXiv:2310.17448v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17448","description":"<p>This paper describes Tallinn University of Technology (TalTech) systems\ndeveloped for the ASRU MADASR 2023 Challenge. The challenge focuses on\nautomatic speech recognition of dialect-rich Indian languages with limited\ntraining audio and text data. TalTech participated in two tracks of the\nchallenge: Track 1 that allowed using only the provided training data and Track\n3 which allowed using additional audio data. In both tracks, we relied on\nwav2vec2.0 models. Our methodology diverges from the traditional procedure of\nfinetuning pretrained wav2vec2.0 models in two key points: firstly, through the\nimplementation of the aligned data augmentation technique to enhance the\nlinguistic diversity of the training data, and secondly, via the application of\ndeep prefix tuning for dialect adaptation of wav2vec2.0 models. In both tracks,\nour approach yielded significant improvements over the provided baselines,\nachieving the lowest word error rates across all participating teams.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alumae_T/0/1/0/all/0/1\">Tanel Alum&#xe4;e</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_J/0/1/0/all/0/1\">Jiaming Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robnikov_D/0/1/0/all/0/1\">Daniil Robnikov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LightLM: A Lightweight Deep and Narrow Language Model for Generative Recommendation. (arXiv:2310.17488v1 [cs.IR])","link":"http://arxiv.org/abs/2310.17488","description":"<p>This paper presents LightLM, a lightweight Transformer-based language model\nfor generative recommendation. While Transformer-based generative modeling has\ngained importance in various AI sub-fields such as NLP and vision, generative\nrecommendation is still in its infancy due to its unique demand on personalized\ngenerative modeling. Existing works on generative recommendation often use\nNLP-oriented Transformer architectures such as T5, GPT, LLaMA and M6, which are\nheavy-weight and are not specifically designed for recommendation tasks.\nLightLM tackles the issue by introducing a light-weight deep and narrow\nTransformer architecture, which is specifically tailored for direct generation\nof recommendation items. This structure is especially apt for straightforward\ngenerative recommendation and stems from the observation that language model\ndoes not have to be too wide for this task, as the input predominantly consists\nof short tokens that are well-suited for the model's capacity. We also show\nthat our devised user and item ID indexing methods, i.e., Spectral\nCollaborative Indexing (SCI) and Graph Collaborative Indexing (GCI), enables\nthe deep and narrow Transformer architecture to outperform large-scale language\nmodels for recommendation. Besides, to address the hallucination problem of\ngenerating items as output, we propose the constrained generation process for\ngenerative recommenders. Experiments on real-world datasets show that LightLM\noutperforms various competitive baselines in terms of both recommendation\naccuracy and efficiency. The code can be found at\nhttps://github.com/dongyuanjushi/LightLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mei_K/0/1/0/all/0/1\">Kai Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering. (arXiv:2310.17490v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17490","description":"<p>Large language models (LLMs) enable zero-shot approaches in open-domain\nquestion answering (ODQA), yet with limited advancements as the reader is\ncompared to the retriever. This study aims at the feasibility of a zero-shot\nreader that addresses the challenges of computational cost and the need for\nlabeled data. We find that LLMs are distracted due to irrelevant documents in\nthe retrieved set and the overconfidence of the generated answers when they are\nexploited as zero-shot readers. To tackle these problems, we mitigate the\nimpact of such documents via Distraction-aware Answer Selection (DAS) with a\nnegation-based instruction and score adjustment for proper answer selection.\nExperimental results show that our approach successfully handles distraction\nacross diverse scenarios, enhancing the performance of zero-shot readers.\nFurthermore, unlike supervised readers struggling with unseen data, zero-shot\nreaders demonstrate outstanding transferability without any training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sukmin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jeong yeon Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Soyeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong C. Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The IMS Toucan System for the Blizzard Challenge 2023. (arXiv:2310.17499v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17499","description":"<p>For our contribution to the Blizzard Challenge 2023, we improved on the\nsystem we submitted to the Blizzard Challenge 2021. Our approach entails a\nrule-based text-to-phoneme processing system that includes rule-based\ndisambiguation of homographs in the French language. It then transforms the\nphonemes to spectrograms as intermediate representations using a fast and\nefficient non-autoregressive synthesis architecture based on Conformer and\nGlow. A GAN based neural vocoder that combines recent state-of-the-art\napproaches converts the spectrogram to the final wave. We carefully designed\nthe data processing, training, and inference procedures for the challenge data.\nOur system identifier is G. Open source code and demo are available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lux_F/0/1/0/all/0/1\">Florian Lux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koch_J/0/1/0/all/0/1\">Julia Koch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_S/0/1/0/all/0/1\">Sarina Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bott_T/0/1/0/all/0/1\">Thomas Bott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schauffler_N/0/1/0/all/0/1\">Nadja Schauffler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denisov_P/0/1/0/all/0/1\">Pavel Denisov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schweitzer_A/0/1/0/all/0/1\">Antje Schweitzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CompeteAI: Understanding the Competition Behaviors in Large Language Model-based Agents. (arXiv:2310.17512v1 [cs.AI])","link":"http://arxiv.org/abs/2310.17512","description":"<p>Large language models (LLMs) have been widely used as agents to complete\ndifferent tasks, such as personal assistance or event planning. While most work\nhas focused on cooperation and collaboration between agents, little work\nexplores competition, another important mechanism that fosters the development\nof society and economy. In this paper, we seek to examine the competition\nbehaviors in LLM-based agents. We first propose a general framework to study\nthe competition between agents. Then, we implement a practical competitive\nenvironment using GPT-4 to simulate a virtual town with two types of agents,\nincluding restaurant agents and customer agents. Specifically, restaurant\nagents compete with each other to attract more customers, where the competition\nfosters them to transform, such as cultivating new operating strategies. The\nresults of our experiments reveal several interesting findings ranging from\nsocial learning to Matthew Effect, which aligns well with existing sociological\nand economic theories. We believe that competition between agents deserves\nfurther investigation to help us understand society better. The code will be\nreleased soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qinlin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1\">Yiqiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Expressive Power of Low-Rank Adaptation. (arXiv:2310.17513v1 [cs.LG])","link":"http://arxiv.org/abs/2310.17513","description":"<p>Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method that\nleverages low-rank adaptation of weight matrices, has emerged as a prevalent\ntechnique for fine-tuning pre-trained models such as large language models and\ndiffusion models. Despite its huge success in practice, the theoretical\nunderpinnings of LoRA have largely remained unexplored. This paper takes the\nfirst step to bridge this gap by theoretically analyzing the expressive power\nof LoRA. We prove that, for fully connected neural networks, LoRA can adapt any\nmodel $f$ to accurately represent any smaller target model $\\overline{f}$ if\nLoRA-rank $\\geq(\\text{width of }f) \\times \\frac{\\text{depth of\n}\\overline{f}}{\\text{depth of }f}$. We also quantify the approximation error\nwhen LoRA-rank is lower than the threshold. For Transformer networks, we show\nany model can be adapted to a target model of the same size with\nrank-$(\\frac{\\text{embedding size}}{2})$ LoRA adapters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yuchen Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Validity of Evaluation Results: Assessing Concurrence Across Compositionality Benchmarks. (arXiv:2310.17514v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17514","description":"<p>NLP models have progressed drastically in recent years, according to numerous\ndatasets proposed to evaluate performance. Questions remain, however, about how\nparticular dataset design choices may impact the conclusions we draw about\nmodel capabilities. In this work, we investigate this question in the domain of\ncompositional generalization. We examine the performance of six modeling\napproaches across 4 datasets, split according to 8 compositional splitting\nstrategies, ranking models by 18 compositional generalization splits in total.\nOur results show that: i) the datasets, although all designed to evaluate\ncompositional generalization, rank modeling approaches differently; ii)\ndatasets generated by humans align better with each other than they with\nsynthetic datasets, or than synthetic datasets among themselves; iii)\ngenerally, whether datasets are sampled from the same source is more predictive\nof the resulting model ranking than whether they maintain the same\ninterpretation of compositionality; and iv) which lexical items are used in the\ndata can strongly impact conclusions. Overall, our results demonstrate that\nmuch work remains to be done when it comes to assessing whether popular\nevaluation datasets measure what they intend to measure, and suggest that\nelucidating more rigorous standards for establishing the validity of evaluation\nsets could benefit the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Kaiser Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Adina Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can large language models replace humans in the systematic review process? Evaluating GPT-4's efficacy in screening and extracting data from peer-reviewed and grey literature in multiple languages. (arXiv:2310.17526v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17526","description":"<p>Systematic reviews are vital for guiding practice, research, and policy, yet\nthey are often slow and labour-intensive. Large language models (LLMs) could\noffer a way to speed up and automate systematic reviews, but their performance\nin such tasks has not been comprehensively evaluated against humans, and no\nstudy has tested GPT-4, the biggest LLM so far. This pre-registered study\nevaluates GPT-4's capability in title/abstract screening, full-text review, and\ndata extraction across various literature types and languages using a\n'human-out-of-the-loop' approach. Although GPT-4 had accuracy on par with human\nperformance in most tasks, results were skewed by chance agreement and dataset\nimbalance. After adjusting for these, there was a moderate level of performance\nfor data extraction, and - barring studies that used highly reliable prompts -\nscreening performance levelled at none to moderate for different stages and\nlanguages. When screening full-text literature using highly reliable prompts,\nGPT-4's performance was 'almost perfect.' Penalising GPT-4 for missing key\nstudies using highly reliable prompts improved its performance even more. Our\nfindings indicate that, currently, substantial caution should be used if LLMs\nare being used to conduct systematic reviews, but suggest that, for certain\nsystematic review tasks delivered under reliable prompts, LLMs can rival human\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khraisha_Q/0/1/0/all/0/1\">Qusai Khraisha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Put_S/0/1/0/all/0/1\">Sophie Put</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kappenberg_J/0/1/0/all/0/1\">Johanna Kappenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warraitch_A/0/1/0/all/0/1\">Azza Warraitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_K/0/1/0/all/0/1\">Kristin Hadfield</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Bias and Fairness in Gender-Neutral Pretrained Vision-and-Language Models. (arXiv:2310.17530v1 [cs.CV])","link":"http://arxiv.org/abs/2310.17530","description":"<p>Pretrained machine learning models are known to perpetuate and even amplify\nexisting biases in data, which can result in unfair outcomes that ultimately\nimpact user experience. Therefore, it is crucial to understand the mechanisms\nbehind those prejudicial biases to ensure that model performance does not\nresult in discriminatory behaviour toward certain groups or populations. In\nthis work, we define gender bias as our case study. We quantify bias\namplification in pretraining and after fine-tuning on three families of\nvision-and-language models. We investigate the connection, if any, between the\ntwo learning stages, and evaluate how bias amplification reflects on model\nperformance. Overall, we find that bias amplification in pretraining and after\nfine-tuning are independent. We then examine the effect of continued\npretraining on gender-neutral data, finding that this reduces group\ndisparities, i.e., promotes fairness, on VQAv2 and retrieval tasks without\nsignificantly compromising task performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cabello_L/0/1/0/all/0/1\">Laura Cabello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bugliarello_E/0/1/0/all/0/1\">Emanuele Bugliarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brandl_S/0/1/0/all/0/1\">Stephanie Brandl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unpacking the Ethical Value Alignment in Big Models. (arXiv:2310.17551v1 [cs.CY])","link":"http://arxiv.org/abs/2310.17551","description":"<p>Big models have greatly advanced AI's ability to understand, generate, and\nmanipulate information and content, enabling numerous applications. However, as\nthese models become increasingly integrated into everyday life, their inherent\nethical values and potential biases pose unforeseen risks to society. This\npaper provides an overview of the risks and challenges associated with big\nmodels, surveys existing AI ethics guidelines, and examines the ethical\nimplications arising from the limitations of these models. Taking a normative\nethics perspective, we propose a reassessment of recent normative guidelines,\nhighlighting the importance of collaborative efforts in academia to establish a\nunified and universal AI ethics framework. Furthermore, we investigate the\nmoral inclinations of current mainstream LLMs using the Moral Foundation\ntheory, analyze existing alignment algorithms, and outline the unique\nchallenges encountered in aligning ethical values within them. To address these\nchallenges, we introduce a novel conceptual paradigm for aligning the ethical\nvalues of big models and discuss promising research directions for alignment\ncriteria, evaluation, and method, representing an initial step towards the\ninterdisciplinary construction of the ethically aligned AI\n</p>\n<p>This paper is a modified English version of our Chinese paper\nhttps://crad.ict.ac.cn/cn/article/doi/10.7544/issn1000-1239.202330553, intended\nto help non-Chinese native speakers better understand our work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jing Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiting Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Matching Phones and Speech Representations. (arXiv:2310.17558v1 [cs.CL])","link":"http://arxiv.org/abs/2310.17558","description":"<p>Learning phone types from phone instances has been a long-standing problem,\nwhile still being open. In this work, we revisit this problem in the context of\nself-supervised learning, and pose it as the problem of matching cluster\ncentroids to phone embeddings. We study two key properties that enable\nmatching, namely, whether cluster centroids of self-supervised representations\nreduce the variability of phone instances and respect the relationship among\nphones. We then use the matching result to produce pseudo-labels and introduce\na new loss function for improving self-supervised representations. Our\nexperiments show that the matching result captures the relationship among\nphones. Training the new loss function jointly with the regular self-supervised\nlosses, such as APC and CPC, significantly improves the downstream phone\nclassification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Gene-Ping Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hao Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Antigram Behaviour using Distributional Semantics. (arXiv:1901.05066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1901.05066","description":"<p>The field of computational linguistics constantly presents new challenges and\ntopics for research. Whether it be analyzing word usage changes over time or\nidentifying relationships between pairs of seemingly unrelated words. To this\npoint, we identify Anagrams and Antigrams as words possessing such unique\nproperties. The presented work is an exploration into generating anagrams from\na given word and determining whether there exists antigram (semantically\nopposite anagrams) relationships between the pairs of generated anagrams using\nGloVe embeddings. We propose a rudimentary, yet interpretable, rule-based\nalgorithm for detecting antigrams. On a small dataset of just 12 antigrams, our\napproach yielded an accuracy of 39\\% which shows that there is much work left\nto be done in this space.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1\">Saptarshi Sengupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Classifying Continuous Constraint Satisfaction Problems. (arXiv:2106.02397v5 [cs.CC] UPDATED)","link":"http://arxiv.org/abs/2106.02397","description":"<p>A continuous constraint satisfaction problem (CCSP) is a constraint\nsatisfaction problem (CSP) with an interval domain $U \\subset \\mathbb{R}$. We\nengage in a systematic study to classify CCSPs that are complete of the\nExistential Theory of the Reals, i.e., ER-complete. To define this class, we\nfirst consider the problem ETR, which also stands for Existential Theory of the\nReals. In an instance of this problem we are given some sentence of the form\n$\\exists x_1, \\ldots, x_n \\in \\mathbb{R} : \\Phi(x_1, \\ldots, x_n)$, where\n$\\Phi$ is a well-formed quantifier-free formula consisting of the symbols $\\{0,\n1, +, \\cdot, \\geq, &gt;, \\wedge, \\vee, \\neg\\}$, the goal is to check whether this\nsentence is true. Now the class ER is the family of all problems that admit a\npolynomial-time many-one reduction to ETR. It is known that NP $\\subseteq$ ER\n$\\subseteq$ PSPACE.\n</p>\n<p>We restrict our attention on CCSPs with addition constraints ($x + y = z$)\nand some other mild technical condition. Previously, it was shown that\nmultiplication constraints ($x \\cdot y = z$), squaring constraints ($x^2 = y$),\nor inversion constraints ($x\\cdot y = 1$) are sufficient to establish\nER-completeness. We extend this in the strongest possible sense for equality\nconstraints as follows. We show that CCSPs (with addition constraints and some\nother mild technical condition) that have any one well-behaved curved equality\nconstraint ($f(x,y) = 0$) are ER-complete. We further extend our results to\ninequality constraints. We show that any well-behaved convexly curved and any\nwell-behaved concavely curved inequality constraint ($f(x,y) \\geq 0$ and\n$g(x,y) \\geq 0$) imply ER-completeness on the class of such CCSPs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1\">Tillmann Miltzow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmiermann_R/0/1/0/all/0/1\">Reinier F. Schmiermann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"pysentimiento: A Python Toolkit for Opinion Mining and Social NLP tasks. (arXiv:2106.09462v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.09462","description":"<p>In recent years, the extraction of opinions and information from\nuser-generated text has attracted a lot of interest, largely due to the\nunprecedented volume of content in Social Media. However, social researchers\nface some issues in adopting cutting-edge tools for these tasks, as they are\nusually behind commercial APIs, unavailable for other languages than English,\nor very complex to use for non-experts. To address these issues, we present\npysentimiento, a comprehensive multilingual Python toolkit designed for opinion\nmining and other Social NLP tasks. This open-source library brings\nstate-of-the-art models for Spanish, English, Italian, and Portuguese in an\neasy-to-use Python library, allowing researchers to leverage these techniques.\nWe present a comprehensive assessment of performance for several pre-trained\nlanguage models across a variety of tasks, languages, and datasets, including\nan evaluation of fairness in the results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perez_J/0/1/0/all/0/1\">Juan Manuel P&#xe9;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajngewerc_M/0/1/0/all/0/1\">Mariela Rajngewerc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giudici_J/0/1/0/all/0/1\">Juan Carlos Giudici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furman_D/0/1/0/all/0/1\">Dami&#xe1;n A. Furman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luque_F/0/1/0/all/0/1\">Franco Luque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alemany_L/0/1/0/all/0/1\">Laura Alonso Alemany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_M/0/1/0/all/0/1\">Mar&#xed;a Vanina Mart&#xed;nez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aksharantar: Open Indic-language Transliteration datasets and models for the Next Billion Users. (arXiv:2205.03018v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.03018","description":"<p>Transliteration is very important in the Indian language context due to the\nusage of multiple scripts and the widespread use of romanized inputs. However,\nfew training and evaluation sets are publicly available. We introduce\nAksharantar, the largest publicly available transliteration dataset for Indian\nlanguages created by mining from monolingual and parallel corpora, as well as\ncollecting data from human annotators. The dataset contains 26 million\ntransliteration pairs for 21 Indic languages from 3 language families using 12\nscripts. Aksharantar is 21 times larger than existing datasets and is the first\npublicly available dataset for 7 languages and 1 language family. We also\nintroduce the Aksharantar testset comprising 103k word pairs spanning 19\nlanguages that enables a fine-grained analysis of transliteration models on\nnative origin words, foreign words, frequent words, and rare words. Using the\ntraining set, we trained IndicXlit, a multilingual transliteration model that\nimproves accuracy by 15% on the Dakshina test set, and establishes strong\nbaselines on the Aksharantar testset introduced in this work. The models,\nmining scripts, transliteration guidelines, and datasets are available at\nhttps://github.com/AI4Bharat/IndicXlit under open-source licenses. We hope the\navailability of these large-scale, open resources will spur innovation for\nIndic language transliteration and downstream applications. We hope the\navailability of these large-scale, open resources will spur innovation for\nIndic language transliteration and downstream applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madhani_Y/0/1/0/all/0/1\">Yash Madhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthan_S/0/1/0/all/0/1\">Sushane Parthan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedekar_P/0/1/0/all/0/1\">Priyanka Bedekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+NC_G/0/1/0/all/0/1\">Gokul NC</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_R/0/1/0/all/0/1\">Ruchi Khapra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Event knowledge in large language models: the gap between the impossible and the unlikely. (arXiv:2212.01488v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.01488","description":"<p>Word co-occurrence patterns in language corpora contain a surprising amount\nof conceptual knowledge. Large language models (LLMs), trained to predict words\nin context, leverage these patterns to achieve impressive performance on\ndiverse semantic tasks requiring world knowledge. An important but understudied\nquestion about LLMs' semantic abilities is whether they acquire generalized\nknowledge of common events. Here, we test whether five pre-trained LLMs (from\n2018's BERT to 2023's MPT) assign higher likelihood to plausible descriptions\nof agent-patient interactions than to minimally different implausible versions\nof the same event. Using three curated sets of minimal sentence pairs (total\nn=1,215), we found that pre-trained LLMs possess substantial event knowledge,\noutperforming other distributional language models. In particular, they almost\nalways assign higher likelihood to possible vs. impossible events (The teacher\nbought the laptop vs. The laptop bought the teacher). However, LLMs show less\nconsistent preferences for likely vs. unlikely events (The nanny tutored the\nboy vs. The boy tutored the nanny). In follow-up analyses, we show that (i) LLM\nscores are driven by both plausibility and surface-level sentence features,\n(ii) LLM scores generalize well across syntactic variants (active vs. passive\nconstructions) but less well across semantic variants (synonymous sentences),\n(iii) some LLM errors mirror human judgment ambiguity, and (iv) sentence\nplausibility serves as an organizing dimension in internal LLM representations.\nOverall, our results show that important aspects of event knowledge naturally\nemerge from distributional linguistic patterns, but also highlight a gap\nbetween representations of possible/impossible and likely/unlikely events.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kauf_C/0/1/0/all/0/1\">Carina Kauf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanova_A/0/1/0/all/0/1\">Anna A. Ivanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rambelli_G/0/1/0/all/0/1\">Giulia Rambelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chersoni_E/0/1/0/all/0/1\">Emmanuele Chersoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+She_J/0/1/0/all/0/1\">Jingyuan Selena She</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_Z/0/1/0/all/0/1\">Zawad Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fedorenko_E/0/1/0/all/0/1\">Evelina Fedorenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenci_A/0/1/0/all/0/1\">Alessandro Lenci</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZipLM: Inference-Aware Structured Pruning of Language Models. (arXiv:2302.04089v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.04089","description":"<p>The breakthrough performance of large language models (LLMs) comes with major\ncomputational footprints and high deployment costs. In this paper, we progress\ntowards resolving this problem by proposing a novel structured compression\napproach for LLMs, called ZipLM. ZipLM achieves state-of-the-art\naccuracy-vs-speedup, while matching a set of desired target runtime speedups in\nany given inference environment. Specifically, given a model, a dataset, an\ninference environment, as well as a set of speedup targets, ZipLM iteratively\nidentifies and removes components with the worst loss-runtime trade-off. Unlike\nprior methods that specialize in either the post-training/one-shot or the\ngradual compression setting, and only for specific families of models such as\nBERT (encoder) or GPT (decoder), ZipLM produces state-of-the-art compressed\nmodels across all these settings. Furthermore, ZipLM achieves superior results\nfor a fraction of the computational cost relative to prior distillation and\npruning techniques, making it a cost-effective approach for generating an\nentire family of smaller, faster, and highly accurate models, guaranteed to\nmeet the desired inference specifications. In particular, ZipLM outperforms all\nprior BERT-base distillation and pruning techniques, such as CoFi, MiniLM, and\nTinyBERT. Moreover, it matches the performance of the heavily optimized\nMobileBERT model, obtained via extensive architecture search, by simply pruning\nthe baseline BERT-large model. When compressing GPT2, ZipLM outperforms\nDistilGPT2 while being 60% smaller and 30% faster. Our code is available at:\nhttps://github.com/IST-DASLab/ZipLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1\">Eldar Kurtic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1\">Elias Frantar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals. (arXiv:2302.04449v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.04449","description":"<p>High sample complexity has long been a challenge for RL. On the other hand,\nhumans learn to perform tasks not only from interaction or demonstrations, but\nalso by reading unstructured text documents, e.g., instruction manuals.\nInstruction manuals and wiki pages are among the most abundant data that could\ninform agents of valuable features and policies or task-specific environmental\ndynamics and reward structures. Therefore, we hypothesize that the ability to\nutilize human-written instruction manuals to assist learning policies for\nspecific tasks should lead to a more efficient and better-performing agent. We\npropose the Read and Reward framework. Read and Reward speeds up RL algorithms\non Atari games by reading manuals released by the Atari game developers. Our\nframework consists of a QA Extraction module that extracts and summarizes\nrelevant information from the manual and a Reasoning module that evaluates\nobject-agent interactions based on information from the manual. An auxiliary\nreward is then provided to a standard A2C RL agent, when interaction is\ndetected. Experimentally, various RL algorithms obtain significant improvement\nin performance and training speed when assisted by our design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yewen Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azaria_A/0/1/0/all/0/1\">Amos Azaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1\">Tom M. Mitchell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Describe me an Aucklet: Generating Grounded Perceptual Category Descriptions. (arXiv:2303.04053v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.04053","description":"<p>Human speakers can generate descriptions of perceptual concepts, abstracted\nfrom the instance-level. Moreover, such descriptions can be used by other\nspeakers to learn provisional representations of those concepts. Learning and\nusing abstract perceptual concepts is under-investigated in the\nlanguage-and-vision field. The problem is also highly relevant to the field of\nrepresentation learning in multi-modal NLP. In this paper, we introduce a\nframework for testing category-level perceptual grounding in multi-modal\nlanguage models. In particular, we train separate neural networks to generate\nand interpret descriptions of visual categories. We measure the communicative\nsuccess of the two models with the zero-shot classification performance of the\ninterpretation model, which we argue is an indicator of perceptual grounding.\nUsing this framework, we compare the performance of prototype- and\nexemplar-based representations. Finally, we show that communicative success\nexposes performance issues in the generation model, not captured by traditional\nintrinsic NLG evaluation metrics, and argue that these issues stem from a\nfailure to properly ground language in vision at the category level.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noble_B/0/1/0/all/0/1\">Bill Noble</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilinykh_N/0/1/0/all/0/1\">Nikolai Ilinykh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Offline Speech Translation Models for Streaming with Future-Aware Distillation and Inference. (arXiv:2303.07914v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.07914","description":"<p>A popular approach to streaming speech translation is to employ a single\noffline model with a wait-k policy to support different latency requirements,\nwhich is simpler than training multiple online models with different latency\nconstraints. However, there is a mismatch problem in using a model trained with\ncomplete utterances for streaming inference with partial input. We demonstrate\nthat speech representations extracted at the end of a streaming input are\nsignificantly different from those extracted from a complete utterance. To\naddress this issue, we propose a new approach called Future-Aware Streaming\nTranslation (FAST) that adapts an offline ST model for streaming input. FAST\nincludes a Future-Aware Inference (FAI) strategy that incorporates future\ncontext through a trainable masked embedding, and a Future-Aware Distillation\n(FAD) framework that transfers future context from an approximation of full\nspeech to streaming input. Our experiments on the MuST-C EnDe, EnEs, and EnFr\nbenchmarks show that FAST achieves better trade-offs between translation\nquality and latency than strong baselines. Extensive analyses suggest that our\nmethods effectively alleviate the aforementioned mismatch problem between\noffline training and online inference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1\">Biao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1\">Minpeng Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_K/0/1/0/all/0/1\">Kai Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhongqiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Boxing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yidong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaodong Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is ChatGPT A Good Keyphrase Generator? A Preliminary Study. (arXiv:2303.13001v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13001","description":"<p>The emergence of ChatGPT has recently garnered significant attention from the\ncomputational linguistics community. To demonstrate its capabilities as a\nkeyphrase generator, we conduct a preliminary evaluation of ChatGPT for the\nkeyphrase generation task. We evaluate its performance in various aspects,\nincluding keyphrase generation prompts, keyphrase generation diversity, and\nlong document understanding. Our evaluation is based on six benchmark datasets,\nand we adopt the prompt suggested by OpenAI while extending it to six candidate\nprompts. We find that ChatGPT performs exceptionally well on all six candidate\nprompts, with minor performance differences observed across the datasets. Based\non our findings, we conclude that ChatGPT has great potential for keyphrase\ngeneration. Moreover, we discover that ChatGPT still faces challenges when it\ncomes to generating absent keyphrases. Meanwhile, in the final section, we also\npresent some limitations and future expansions of this report.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Mingyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haiyun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Songfang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shilong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huafeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jing_L/0/1/0/all/0/1\">Liping Jing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Evaluation Guided Beam Search for Reasoning. (arXiv:2305.00633v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.00633","description":"<p>Breaking down a problem into intermediate steps has demonstrated impressive\nperformance in Large Language Model (LLM) reasoning. However, the growth of the\nreasoning chain introduces uncertainty and error accumulation, making it\nchallenging to elicit accurate final results. To tackle this challenge of\nuncertainty in multi-step reasoning, we introduce a stepwise self-evaluation\nmechanism to guide and calibrate the reasoning process of LLMs. We propose a\ndecoding algorithm integrating the self-evaluation guidance via stochastic beam\nsearch. The self-evaluation guidance serves as a better-calibrated automatic\ncriterion, facilitating an efficient search in the reasoning space and\nresulting in superior prediction quality. Stochastic beam search balances\nexploitation and exploration of the search space with temperature-controlled\nrandomness. Our approach surpasses the corresponding Codex-backboned baselines\nin few-shot accuracy by $6.34\\%$, $9.56\\%$, and $5.46\\%$ on the GSM8K, AQuA,\nand StrategyQA benchmarks, respectively. Experiment results with Llama-2 on\narithmetic reasoning demonstrate the efficiency of our method in outperforming\nthe baseline methods with comparable computational budgets. Further analysis in\nmulti-step reasoning finds our self-evaluation guidance pinpoints logic\nfailures and leads to higher consistency and robustness. Our code is publicly\navailable at https://guideddecoding.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qizhe Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can LLMs Capture Intertemporal Preferences?. (arXiv:2305.02531v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02531","description":"<p>We explore the viability of Large Language Models (LLMs), specifically\nOpenAI's GPT-3.5 and GPT-4, in emulating human survey respondents and eliciting\npreferences, with a focus on intertemporal choices. Leveraging the extensive\nliterature on intertemporal discounting for benchmarking, we examine responses\nfrom LLMs across various languages and compare them to human responses,\nexploring preferences between smaller, sooner, and larger, later rewards. Our\nfindings reveal that both GPT models demonstrate less patience than humans,\nwith GPT-3.5 exhibiting a lexicographic preference for earlier rewards, unlike\nhuman decision-makers. Though GPT-4 does not display lexicographic preferences,\nits measured discount rates are still considerably larger than those found in\nhumans. Interestingly, GPT models show greater patience in languages with weak\nfuture tense references, such as German and Mandarin, aligning with existing\nliterature that suggests a correlation between language structure and\nintertemporal preferences. We demonstrate how prompting GPT to explain its\ndecisions, a procedure we term ``chain-of-thought conjoint,\" can mitigate, but\ndoes not eliminate, discrepancies between LLM and human responses. While\ndirectly eliciting preferences using LLMs may yield misleading results,\ncombining chain-of-thought conjoint with topic modeling aids in hypothesis\ngeneration, enabling researchers to explore the underpinnings of preferences.\nChain-of-thought conjoint provides a structured framework for marketers to use\nLLMs to identify potential attributes or factors that can explain preference\nheterogeneity across different customers and contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goli_A/0/1/0/all/0/1\">Ali Goli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amandeep Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports. (arXiv:2305.03598v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03598","description":"<p>How can we interpret and retrieve medical evidence to support clinical\ndecisions? Clinical trial reports (CTR) amassed over the years contain\nindispensable information for the development of personalized medicine.\nHowever, it is practically infeasible to manually inspect over 400,000+\nclinical trial reports in order to find the best evidence for experimental\ntreatments. Natural Language Inference (NLI) offers a potential solution to\nthis problem, by allowing the scalable computation of textual entailment.\nHowever, existing NLI models perform poorly on biomedical corpora, and\npreviously published datasets fail to capture the full complexity of inference\nover CTRs. In this work, we present a novel resource to advance research on NLI\nfor reasoning on CTRs. The resource includes two main tasks. Firstly, to\ndetermine the inference relation between a natural language statement, and a\nCTR. Secondly, to retrieve supporting facts to justify the predicted relation.\nWe provide NLI4CT, a corpus of 2400 statements and CTRs, annotated for these\ntasks. Baselines on this corpus expose the limitations of existing NLI models,\nwith 6 state-of-the-art NLI models achieving a maximum F1 score of 0.627. To\nthe best of our knowledge, we are the first to design a task that covers the\ninterpretation of full CTRs. To encourage further work on this challenging\ndataset, we make the corpus, competition leaderboard, website and code to\nreplicate the baseline experiments available at:\nhttps://github.com/ai-systems/nli4ct\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jullien_M/0/1/0/all/0/1\">Ma&#xeb;l Jullien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1\">Marco Valentino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frost_H/0/1/0/all/0/1\">Hannah Frost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ORegan_P/0/1/0/all/0/1\">Paul O&#x27;Regan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landers_D/0/1/0/all/0/1\">Donal Landers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1\">Andr&#xe9; Freitas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-grained Hypergraph Interest Modeling for Conversational Recommendation. (arXiv:2305.04798v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.04798","description":"<p>Conversational recommender system (CRS) interacts with users through\nmulti-turn dialogues in natural language, which aims to provide high-quality\nrecommendations for user's instant information need. Although great efforts\nhave been made to develop effective CRS, most of them still focus on the\ncontextual information from the current dialogue, usually suffering from the\ndata scarcity issue. Therefore, we consider leveraging historical dialogue data\nto enrich the limited contexts of the current dialogue session.\n</p>\n<p>In this paper, we propose a novel multi-grained hypergraph interest modeling\napproach to capture user interest beneath intricate historical data from\ndifferent perspectives. As the core idea, we employ hypergraph to represent\ncomplicated semantic relations underlying historical dialogues. In our\napproach, we first employ the hypergraph structure to model users' historical\ndialogue sessions and form a session-based hypergraph, which captures\ncoarse-grained, session-level relations. Second, to alleviate the issue of data\nscarcity, we use an external knowledge graph and construct a knowledge-based\nhypergraph considering fine-grained, entity-level semantics. We further conduct\nmulti-grained hypergraph convolution on the two kinds of hypergraphs, and\nutilize the enhanced representations to develop interest-aware CRS. Extensive\nexperiments on two benchmarks ReDial and TG-ReDial validate the effectiveness\nof our approach on both recommendation and conversation tasks. Code is\navailable at: https://github.com/RUCAIBox/MHIM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shang_C/0/1/0/all/0/1\">Chenzhan Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yupeng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jing Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Asymmetric feature interaction for interpreting model predictions. (arXiv:2305.07224v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07224","description":"<p>In natural language processing (NLP), deep neural networks (DNNs) could model\ncomplex interactions between context and have achieved impressive results on a\nrange of NLP tasks. Prior works on feature interaction attribution mainly focus\non studying symmetric interaction that only explains the additional influence\nof a set of words in combination, which fails to capture asymmetric influence\nthat contributes to model prediction. In this work, we propose an asymmetric\nfeature interaction attribution explanation model that aims to explore\nasymmetric higher-order feature interactions in the inference of deep neural\nNLP models. By representing our explanation with an directed interaction graph,\nwe experimentally demonstrate interpretability of the graph to discover\nasymmetric feature interactions. Experimental results on two sentiment\nclassification datasets show the superiority of our model against the\nstate-of-the-art feature interaction attribution methods in identifying\ninfluential features for model predictions. Our code is available at\nhttps://github.com/StillLu/ASIV.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaolei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianghong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haode Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Video Is Worth 4096 Tokens: Verbalize Videos To Understand Them In Zero Shot. (arXiv:2305.09758v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.09758","description":"<p>Multimedia content, such as advertisements and story videos, exhibit a rich\nblend of creativity and multiple modalities. They incorporate elements like\ntext, visuals, audio, and storytelling techniques, employing devices like\nemotions, symbolism, and slogans to convey meaning. There is a dearth of large\nannotated training datasets in the multimedia domain hindering the development\nof supervised learning models with satisfactory performance for real-world\napplications. On the other hand, the rise of large language models (LLMs) has\nwitnessed remarkable zero-shot performance in various natural language\nprocessing (NLP) tasks, such as emotion classification, question-answering, and\ntopic classification. To leverage such advanced techniques to bridge this\nperformance gap in multimedia understanding, we propose verbalizing long videos\nto generate their descriptions in natural language, followed by performing\nvideo-understanding tasks on the generated story as opposed to the original\nvideo. Through extensive experiments on fifteen video-understanding tasks, we\ndemonstrate that our method, despite being zero-shot, achieves significantly\nbetter results than supervised baselines for video understanding. Furthermore,\nto alleviate a lack of story understanding benchmarks, we publicly release the\nfirst dataset on a crucial task in computational social science on persuasion\nstrategy identification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Aanisha Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman K Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Object Hallucination in Large Vision-Language Models. (arXiv:2305.10355v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.10355","description":"<p>Inspired by the superior language abilities of large language models (LLM),\nlarge vision-language models (LVLM) have been recently explored by integrating\npowerful LLMs for improving the performance on complex multimodal tasks.\nDespite the promising progress on LVLMs, we find that LVLMs suffer from the\nhallucination problem, i.e. they tend to generate objects that are inconsistent\nwith the target images in the descriptions. To investigate it, this work\npresents the first systematic study on object hallucination of LVLMs. We\nconduct the evaluation experiments on several representative LVLMs, and show\nthat they mostly suffer from severe object hallucination issue. We further\ndiscuss that the visual instructions may influence the hallucination, and find\nthat: objects that frequently occur in the visual instructions or co-occur with\nthe image objects, are obviously prone to be hallucinated by LVLMs. Besides, we\nfind that existing evaluation methods might be affected by the input\ninstructions and generation styles of LVLMs. Thus, we further design an\nimproved evaluation method for object hallucination by proposing a\npolling-based query method called POPE. Experiment results demonstrate that our\nPOPE can evaluate the object hallucination in a more stable and flexible way.\nOur codes and data are publicly available at https://github.com/RUCAIBox/POPE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yifan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recycle-and-Distill: Universal Compression Strategy for Transformer-based Speech SSL Models with Attention Map Reusing and Masking Distillation. (arXiv:2305.11685v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2305.11685","description":"<p>Transformer-based speech self-supervised learning (SSL) models, such as\nHuBERT, show surprising performance in various speech processing tasks.\nHowever, huge number of parameters in speech SSL models necessitate the\ncompression to a more compact model for wider usage in academia or small\ncompanies. In this study, we suggest to reuse attention maps across the\nTransformer layers, so as to remove key and query parameters while retaining\nthe number of layers. Furthermore, we propose a novel masking distillation\nstrategy to improve the student model's speech representation quality. We\nextend the distillation loss to utilize both masked and unmasked speech frames\nto fully leverage the teacher model's high-quality representation. Our\nuniversal compression strategy yields the student model that achieves phoneme\nerror rate (PER) of 7.72% and word error rate (WER) of 9.96% on the SUPERB\nbenchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Jang_K/0/1/0/all/0/1\">Kangwook Jang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1\">Sungnyun Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_H/0/1/0/all/0/1\">Hoirin Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist Examination. (arXiv:2305.12945v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12945","description":"<p>As ChatGPT and GPT-4 spearhead the development of Large Language Models\n(LLMs), more researchers are investigating their performance across various\ntasks. But more research needs to be done on the interpretability capabilities\nof LLMs, that is, the ability to generate reasons after an answer has been\ngiven. Existing explanation datasets are mostly English-language general\nknowledge questions, which leads to insufficient thematic and linguistic\ndiversity. To address the language bias and lack of medical resources in\ngenerating rationales QA datasets, we present ExplainCPE (over 7k instances), a\nchallenging medical benchmark in Simplified Chinese. We analyzed the errors of\nChatGPT and GPT-4, pointing out the limitations of current LLMs in\nunderstanding text and computational reasoning. During the experiment, we also\nfound that different LLMs have different preferences for in-context learning.\nExplainCPE presents a significant challenge, but its potential for further\ninvestigation is promising, and it can be used to evaluate the ability of a\nmodel to generate explanations. AI safety and trustworthiness need more\nattention, and this work makes the first step to explore the medical\ninterpretability of LLMs.The dataset is available at\nhttps://github.com/HITsz-TMG/ExplainCPE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongfang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jindi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLASS: A Design Framework for building Intelligent Tutoring Systems based on Learning Science principles. (arXiv:2305.13272v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13272","description":"<p>We present a design framework called Conversational Learning with Analytical\nStep-by-Step Strategies (CLASS) for building advanced Intelligent Tutoring\nSystems (ITS) powered by high-performance Large Language Models (LLMs). The\nCLASS framework empowers ITS with two key capabilities. First, through a\ncarefully curated scaffolding dataset, CLASS equips ITS with essential\nproblem-solving strategies, enabling it to provide tutor-like, step-by-step\nguidance to students. Second, by using a dynamic conversational dataset, CLASS\nassists ITS in facilitating natural language interactions, fostering engaging\nstudent-tutor conversations. The CLASS framework also provides valuable\ninsights into ITS' internal decision-making process which allows seamless\nintegration of user feedback, thus enabling continuous refinement and\nimprovement. We also present a proof-of-concept ITS, referred to as SPOCK,\nwhich is trained using the CLASS framework with a focus on introductory\ncollege-level biology content. A carefully constructed protocol was developed\nfor SPOCK's preliminary evaluation, examining aspects such as the factual\naccuracy and relevance of its responses. Experts in the field of biology\noffered favorable remarks, particularly highlighting SPOCK's capability to\nbreak down questions into manageable subproblems and provide encouraging\nresponses to students. Code and models are available at\nhttps://github.com/luffycodes/Tutorbot-Spock.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sonkar_S/0/1/0/all/0/1\">Shashank Sonkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Naiming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallick_D/0/1/0/all/0/1\">Debshila Basu Mallick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Automated Fact-Checking: A Survey. (arXiv:2305.13507v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13507","description":"<p>Misinformation is often conveyed in multiple modalities, e.g. a miscaptioned\nimage. Multimodal misinformation is perceived as more credible by humans, and\nspreads faster than its text-only counterparts. While an increasing body of\nresearch investigates automated fact-checking (AFC), previous surveys mostly\nfocus on text. In this survey, we conceptualise a framework for AFC including\nsubtasks unique to multimodal misinformation. Furthermore, we discuss related\nterms used in different communities and map them to our framework. We focus on\nfour modalities prevalent in real-world fact-checking: text, image, audio, and\nvideo. We survey benchmarks and models, and discuss limitations and promising\ndirections for future research\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Mubashara Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlichtkrull_M/0/1/0/all/0/1\">Michael Schlichtkrull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cocarascu_O/0/1/0/all/0/1\">Oana Cocarascu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simperl_E/0/1/0/all/0/1\">Elena Simperl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting and Mitigating Hallucinations in Multilingual Summarisation. (arXiv:2305.13632v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13632","description":"<p>Hallucinations pose a significant challenge to the reliability of neural\nmodels for abstractive summarisation. While automatically generated summaries\nmay be fluent, they often lack faithfulness to the original document. This\nissue becomes even more pronounced in low-resource settings, such as\ncross-lingual transfer. With the existing faithful metrics focusing on English,\neven measuring the extent of this phenomenon in cross-lingual settings is hard.\nTo address this, we first develop a novel metric, mFACT, evaluating the\nfaithfulness of non-English summaries, leveraging translation-based transfer\nfrom multiple English faithfulness metrics. We then propose a simple but\neffective method to reduce hallucinations with a cross-lingual transfer, which\nweighs the loss of each training example by its faithfulness score. Through\nextensive experiments in multiple languages, we demonstrate that mFACT is the\nmetric that is most suited to detect hallucinations. Moreover, we find that our\nproposed loss weighting method drastically increases both performance and\nfaithfulness according to both automatic and human evaluation when compared to\nstrong baselines for cross-lingual transfer such as MAD-X. Our code and dataset\nare available at https://github.com/yfqiu-nlp/mfact-summ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yifu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziser_Y/0/1/0/all/0/1\">Yftah Ziser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo M. Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document. (arXiv:2305.13850v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13850","description":"<p>Visual Relation Extraction (VRE) is a powerful means of discovering\nrelationships between entities within visually-rich documents. Existing methods\noften focus on manipulating entity features to find pairwise relations, yet\nneglect the more fundamental structural information that links disparate entity\npairs together. The absence of global structure information may make the model\nstruggle to learn long-range relations and easily predict conflicted results.\nTo alleviate such limitations, we propose a \\textbf{G}l\\textbf{O}bal\n\\textbf{S}tructure knowledge-guided relation \\textbf{E}xtraction\n(\\textbf{\\model}) framework. {\\model} initiates by generating preliminary\nrelation predictions on entity pairs extracted from a scanned image of the\ndocument. Subsequently, global structural knowledge is captured from the\npreceding iterative predictions, which are then incorporated into the\nrepresentations of the entities. This ``generate-capture-incorporate'' cycle is\nrepeated multiple times, allowing entity representations and global structure\nknowledge to be mutually reinforced. Extensive experiments validate that\n{\\model} not only outperforms existing methods in the standard fine-tuning\nsetting but also reveals superior cross-lingual learning capabilities; indeed,\neven yields stronger data-efficient performance in the low-resource setting.\nThe code for GOSE will be available at https://github.com/chenxn2020/GOSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangnan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Q/0/1/0/all/0/1\">Qian Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juncheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Duo Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation. (arXiv:2305.14327v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14327","description":"<p>Instruction tuning has emerged to enhance the capabilities of large language\nmodels (LLMs) to comprehend instructions and generate appropriate responses.\nExisting methods either manually annotate or employ LLM (e.g., GPT-series) to\ngenerate data for instruction tuning. However, they often overlook associating\ninstructions with existing annotated datasets. In this paper, we propose\nDynosaur, a dynamic growth paradigm for the automatic curation of\ninstruction-tuning data. Based on the metadata of existing datasets, we use\nLLMs to automatically construct instruction-tuning data by identifying relevant\ndata fields and generating appropriate instructions.\n</p>\n<p>By leveraging the existing annotated datasets, Dynosaur offers several\nadvantages: 1) it reduces the API cost for generating instructions (e.g., it\ncosts less than $12 USD by calling GPT-3.5-turbo for generating 800K\ninstruction tuning samples; 2) it provides high-quality data for instruction\ntuning (e.g., it performs better than Alpaca and Flan on Super-NI and Longform\nwith comparable data sizes); and 3) it supports the continuous improvement of\nmodels by generating instruction-tuning data when a new annotated dataset\nbecomes available. We further investigate a continual learning scheme for\nlearning with the ever-growing instruction-tuning dataset, and demonstrate that\nreplaying tasks with diverse instruction embeddings not only helps mitigate\nforgetting issues but generalizes to unseen tasks better.\n</p>\n<p>Code and data are available at https://github.com/WadeYin9712/Dynosaur.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_F/0/1/0/all/0/1\">Fan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1\">Ming Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1\">Hritik Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Else Do I Need to Know? The Effect of Background Information on Users' Reliance on QA Systems. (arXiv:2305.14331v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14331","description":"<p>NLP systems have shown impressive performance at answering questions by\nretrieving relevant context. However, with the increasingly large models, it is\nimpossible and often undesirable to constrain models' knowledge or reasoning to\nonly the retrieved context. This leads to a mismatch between the information\nthat the models access to derive the answer and the information that is\navailable to the user to assess the model predicted answer. In this work, we\nstudy how users interact with QA systems in the absence of sufficient\ninformation to assess their predictions. Further, we ask whether adding the\nrequisite background helps mitigate users' over-reliance on predictions. Our\nstudy reveals that users rely on model predictions even in the absence of\nsufficient information needed to assess the model's correctness. Providing the\nrelevant background, however, helps users better catch model errors, reducing\nover-reliance on incorrect predictions. On the flip side, background\ninformation also increases users' confidence in their accurate as well as\ninaccurate judgments. Our work highlights that supporting users' verification\nof QA predictions is an important, yet challenging, problem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Navita Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briakou_E/0/1/0/all/0/1\">Eleftheria Briakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Amanda Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baumler_C/0/1/0/all/0/1\">Connor Baumler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bonial_C/0/1/0/all/0/1\">Claire Bonial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micher_J/0/1/0/all/0/1\">Jeffrey Micher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voss_C/0/1/0/all/0/1\">Clare R. Voss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carpuat_M/0/1/0/all/0/1\">Marine Carpuat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daume_H/0/1/0/all/0/1\">Hal Daum&#xe9; III</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DecipherPref: Analyzing Influential Factors in Human Preference Judgments via GPT-4. (arXiv:2305.14702v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14702","description":"<p>Human preference judgments are pivotal in guiding large language models\n(LLMs) to produce outputs that align with human values. Human evaluations are\nalso used in summarization tasks to compare outputs from various systems,\ncomplementing existing automatic metrics. Despite their significance, however,\nthere has been limited research probing these pairwise or $k$-wise comparisons.\nThe collective impact and relative importance of factors such as output length,\ninformativeness, fluency, and factual consistency are still not well\nunderstood. It is also unclear if there are other hidden factors influencing\nhuman judgments. In this paper, we conduct an in-depth examination of a\ncollection of pairwise human judgments released by OpenAI. Utilizing the\nBradley-Terry-Luce (BTL) model, we reveal the inherent preferences embedded in\nthese human judgments. We find that the most favored factors vary across tasks\nand genres, whereas the least favored factors tend to be consistent, e.g.,\noutputs are too brief, contain excessive off-focus content or hallucinated\nfacts. Our findings have implications on the construction of balanced datasets\nin human preference evaluations, which is a crucial step in shaping the\nbehaviors of future LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yebowen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaiqiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sangwoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foroosh_H/0/1/0/all/0/1\">Hassan Foroosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Estimating Large Language Model Capabilities without Labeled Test Data. (arXiv:2305.14802v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14802","description":"<p>Large Language Models (LLMs) have the impressive ability to perform\nin-context learning (ICL) from only a few examples, but the success of ICL\nvaries widely from task to task. Thus, it is important to quickly determine\nwhether ICL is applicable to a new task, but directly evaluating ICL accuracy\ncan be expensive in situations where test data is expensive to annotate -- the\nexact situations where ICL is most appealing. In this paper, we propose the\ntask of ICL accuracy estimation, in which we predict the accuracy of an LLM\nwhen doing in-context learning on a new task given only unlabeled test data for\nthat task. To perform ICL accuracy estimation, we propose a method that trains\na meta-model using LLM confidence scores as features. We compare our method to\nseveral strong accuracy estimation baselines on a new benchmark that covers 4\nLLMs and 3 task collections. The meta-model improves over all baselines across\n8 out of 12 settings and achieves the same estimation performance as directly\nevaluating on 40 collected labeled test examples per task. At the same time, no\nexisting approach provides an accurate and reliable ICL accuracy estimation in\nevery setting, highlighting the need for better ways to measure the uncertainty\nof LLM predictions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Harvey Yiyun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1\">Albert Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coverage-based Example Selection for In-Context Learning. (arXiv:2305.14907v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14907","description":"<p>In-context learning (ICL), the ability of large language models to perform\nnovel tasks by conditioning on a prompt with a few task examples, requires\nthese examples to be informative about the test instance. The standard approach\nof independently ranking and selecting the most similar examples selects\nredundant examples while omitting important information. In this work, we show\nthat BERTScore-Recall (BSR) selects better examples that demonstrate more of\nthe salient aspects, e.g. reasoning patterns, of the test input. We further\nextend BSR and many standard metrics to easily optimizable set-level metrics,\ngiving still better coverage of those salient aspects. On 15 datasets spanning\n6 tasks and with 7 diverse LLMs, we show that (1) BSR is the superior metric\nfor in-context example selection across the board, and (2) for compositional\ntasks, set selection using Set-BSR outperforms independent ranking by up to 17\npoints on average and, despite being training-free, surpasses methods that\nleverage task or LLM-specific training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Shivanshu Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_M/0/1/0/all/0/1\">Matt Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Editing Common Sense in Transformers. (arXiv:2305.14956v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14956","description":"<p>Editing model parameters directly in Transformers makes updating open-source\ntransformer-based models possible without re-training (Meng et al., 2023).\nHowever, these editing methods have only been evaluated on statements about\nencyclopedic knowledge with a single correct answer. Commonsense knowledge with\nmultiple correct answers, e.g., an apple can be green or red but not\ntransparent, has not been studied but is as essential for enhancing\ntransformers' reliability and usefulness. In this paper, we investigate whether\ncommonsense judgments are causally associated with localized, editable\nparameters in Transformers, and we provide an affirmative answer. We find that\ndirectly applying the MEMIT editing algorithm results in sub-par performance\nand improve it for the commonsense domain by varying edit tokens and improving\nthe layer selection strategy, i.e., $MEMIT_{CSK}$. GPT-2 Large and XL models\nedited using $MEMIT_{CSK}$ outperform best-fine-tuned baselines by 10.97% and\n10.73% F1 scores on PEP3k and 20Q datasets. In addition, we propose a novel\nevaluation dataset, PROBE SET, that contains unaffected and affected\nneighborhoods, affected paraphrases, and affected reasoning challenges.\n$MEMIT_{CSK}$ performs well across the metrics while fine-tuning baselines show\nsignificant trade-offs between unaffected and affected metrics. These results\nsuggest a compelling future direction for incorporating feedback about common\nsense into Transformers through direct model editing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Anshita Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1\">Debanjan Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheshadri_A/0/1/0/all/0/1\">Akshay Krishna Sheshadri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenlong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lorraine Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiegreffe_S/0/1/0/all/0/1\">Sarah Wiegreffe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_N/0/1/0/all/0/1\">Niket Tandon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models. (arXiv:2305.15064v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15064","description":"<p>Recent large language models (LLMs) are promising for making decisions in\ngrounded environments. However, LLMs frequently fail in complex decision-making\ntasks due to the misalignment between the pre-trained knowledge in LLMs and the\nactual rules in the environment. Existing methods require either costly\ngradient computation or lengthy in-context demonstrations. In this paper, we\npropose AutoPlan, an approach to guide LLM-based agents to accomplish\ninteractive decision-making tasks. AutoPlan augments the LLM prompt with a\ntask-solving plan and optimizes it through iterative experience collection and\nreflection. Our experiments show that AutoPlan, though using no in-context\ndemonstrations, achieves success rates on par with the baselines using\nhuman-written demonstrations on ALFWorld and even outperforms them by 8% on\nHotpotQA. The code is available at https://github.com/owaski/AutoPlan.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Siqi Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visually-Situated Natural Language Understanding with Contrastive Reading Model and Frozen Large Language Models. (arXiv:2305.15080v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15080","description":"<p>Recent advances in Large Language Models (LLMs) have stimulated a surge of\nresearch aimed at extending their applications to the visual domain. While\nthese models exhibit promise in generating abstract image captions and\nfacilitating natural conversations, their performance on text-rich images still\nrequires improvement. In this paper, we introduce Contrastive Reading Model\n(Cream), a novel neural architecture designed to enhance the language-image\nunderstanding capability of LLMs by capturing intricate details that are often\noverlooked in existing methods. Cream combines vision and auxiliary encoders,\nfortified by a contrastive feature alignment technique, to achieve a more\neffective comprehension of language information in visually situated contexts\nwithin the images. Our approach bridges the gap between vision and language\nunderstanding, paving the way for the development of more sophisticated\nDocument Intelligence Assistants. Through rigorous evaluations across diverse\nvisually-situated language understanding tasks that demand reasoning\ncapabilities, we demonstrate the compelling performance of Cream, positioning\nit as a prominent model in the field of visual document understanding. We\nprovide our codebase and newly-generated datasets at\nhttps://github.com/naver-ai/cream .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Geewook Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hodong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Daehee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Haeji Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sanghee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoonsik Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Sangdoo Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kil_T/0/1/0/all/0/1\">Taeho Kil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Bado Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Seunghyun Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bhasha-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages. (arXiv:2305.15814v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15814","description":"<p>We create publicly available language identification (LID) datasets and\nmodels in all 22 Indian languages listed in the Indian constitution in both\nnative-script and romanized text. First, we create Bhasha-Abhijnaanam, a\nlanguage identification test set for native-script as well as romanized text\nwhich spans all 22 Indic languages. We also train IndicLID, a language\nidentifier for all the above-mentioned languages in both native and romanized\nscript. For native-script text, it has better language coverage than existing\nLIDs and is competitive or better than other LIDs. IndicLID is the first LID\nfor romanized text in Indian languages. Two major challenges for romanized text\nLID are the lack of training data and low-LID performance when languages are\nsimilar. We provide simple and effective solutions to these problems. In\ngeneral, there has been limited work on romanized text in any language, and our\nfindings are relevant to other languages that need romanized language\nidentification. Our models are publicly available at\nhttps://ai4bharat.iitm.ac.in/indiclid under open-source licenses. Our training\nand test sets are also publicly available at\nhttps://ai4bharat.iitm.ac.in/bhasha-abhijnaanam under open-source licenses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madhani_Y/0/1/0/all/0/1\">Yash Madhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Data-Constrained Language Models. (arXiv:2305.16264v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16264","description":"<p>The current trend of scaling language models involves increasing both\nparameter count and training dataset size. Extrapolating this trend suggests\nthat training dataset size may soon be limited by the amount of text data\navailable on the internet. Motivated by this limit, we investigate scaling\nlanguage models in data-constrained regimes. Specifically, we run a large set\nof experiments varying the extent of data repetition and compute budget,\nranging up to 900 billion training tokens and 9 billion parameter models. We\nfind that with constrained data for a fixed compute budget, training with up to\n4 epochs of repeated data yields negligible changes to loss compared to having\nunique data. However, with more repetition, the value of adding compute\neventually decays to zero. We propose and empirically validate a scaling law\nfor compute optimality that accounts for the decreasing value of repeated\ntokens and excess parameters. Finally, we experiment with approaches mitigating\ndata scarcity, including augmenting the training dataset with code data or\nremoving commonly used filters. Models and datasets from our 400 training runs\nare freely available at https://github.com/huggingface/datablations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barak_B/0/1/0/all/0/1\">Boaz Barak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scao_T/0/1/0/all/0/1\">Teven Le Scao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piktus_A/0/1/0/all/0/1\">Aleksandra Piktus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tazi_N/0/1/0/all/0/1\">Nouamane Tazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyysalo_S/0/1/0/all/0/1\">Sampo Pyysalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations. (arXiv:2306.04618v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.04618","description":"<p>This paper reexamines the research on out-of-distribution (OOD) robustness in\nthe field of NLP. We find that the distribution shift settings in previous\nstudies commonly lack adequate challenges, hindering the accurate evaluation of\nOOD robustness. To address these issues, we propose a benchmark construction\nprotocol that ensures clear differentiation and challenging distribution\nshifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution\nrobustneSS evaluation covering 5 tasks and 20 datasets. Based on BOSS, we\nconduct a series of experiments on pre-trained language models for analysis and\nevaluation of OOD robustness. First, for vanilla fine-tuning, we examine the\nrelationship between in-distribution (ID) and OOD performance. We identify\nthree typical types that unveil the inner learning mechanism, which could\npotentially facilitate the forecasting of OOD robustness, correlating with the\nadvancements on ID datasets. Then, we evaluate 5 classic methods on BOSS and\nfind that, despite exhibiting some effectiveness in specific cases, they do not\noffer significant improvement compared to vanilla fine-tuning. Further, we\nevaluate 5 LLMs with various adaptation paradigms and find that when sufficient\nID data is available, fine-tuning domain-specific models outperform LLMs on ID\nexamples significantly. However, in the case of OOD instances, prioritizing\nLLMs with in-context learning yields better results. We identify that both\nfine-tuned small models and LLMs face challenges in effectively addressing\ndownstream tasks. The code is public at\n\\url{https://github.com/lifan-yuan/OOD_NLP}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lifan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_G/0/1/0/all/0/1\">Ganqu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Hongcheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_F/0/1/0/all/0/1\">Fangyuan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xingyi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DocumentNet: Bridging the Data Gap in Document Pre-Training. (arXiv:2306.08937v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.08937","description":"<p>Document understanding tasks, in particular, Visually-rich Document Entity\nRetrieval (VDER), have gained significant attention in recent years thanks to\ntheir broad applications in enterprise AI. However, publicly available data\nhave been scarce for these tasks due to strict privacy constraints and high\nannotation costs. To make things worse, the non-overlapping entity spaces from\ndifferent datasets hinder the knowledge transfer between document types. In\nthis paper, we propose a method to collect massive-scale and weakly labeled\ndata from the web to benefit the training of VDER models. The collected\ndataset, named DocumentNet, does not depend on specific document types or\nentity sets, making it universally applicable to all VDER tasks. The current\nDocumentNet consists of 30M documents spanning nearly 400 document types\norganized in a four-level ontology. Experiments on a set of broadly adopted\nVDER tasks show significant improvements when DocumentNet is incorporated into\nthe pre-training for both classic and few-shot learning settings. With the\nrecent emergence of large language models (LLMs), DocumentNet provides a large\ndata source to extend their multi-modal capabilities for VDER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lijun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_J/0/1/0/all/0/1\">Jin Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiayi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauptmann_A/0/1/0/all/0/1\">Alexander G. Hauptmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hanjun Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity and Infant Care. (arXiv:2307.01458v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.01458","description":"<p>The recent advances in natural language processing (NLP), have led to a new\ntrend of applying large language models (LLMs) to real-world scenarios. While\nthe latest LLMs are astonishingly fluent when interacting with humans, they\nsuffer from the misinformation problem by unintentionally generating factually\nfalse statements. This can lead to harmful consequences, especially when\nproduced within sensitive contexts, such as healthcare. Yet few previous works\nhave focused on evaluating misinformation in the long-form (LF) generation of\nLLMs, especially for knowledge-intensive topics. Moreover, although LLMs have\nbeen shown to perform well in different languages, misinformation evaluation\nhas been mostly conducted in English. To this end, we present a benchmark,\nCARE-MI, for evaluating LLM misinformation in: 1) a sensitive topic,\nspecifically the maternity and infant care domain; and 2) a language other than\nEnglish, namely Chinese. Most importantly, we provide an innovative paradigm\nfor building LF generation evaluation benchmarks that can be transferred to\nother knowledge-intensive domains and low-resourced languages. Our proposed\nbenchmark fills the gap between the extensive usage of LLMs and the lack of\ndatasets for assessing the misinformation generated by these models. It\ncontains 1,612 expert-checked questions, accompanied with human-selected\nreferences. Using our benchmark, we conduct extensive experiments and found\nthat current Chinese LLMs are far from perfect in the topic of maternity and\ninfant care. In an effort to minimize the reliance on human resources for\nperformance evaluation, we offer off-the-shelf judgment models for\nautomatically assessing the LF output of LLMs given benchmark questions.\nMoreover, we compare potential solutions for LF generation evaluation and\nprovide insights for building better automated metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tong Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wangyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_M/0/1/0/all/0/1\">Mingbai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1\">Lu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_N/0/1/0/all/0/1\">Noa Garcia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as General Pattern Machines. (arXiv:2307.04721v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.04721","description":"<p>We observe that pre-trained large language models (LLMs) are capable of\nautoregressively completing complex token sequences -- from arbitrary ones\nprocedurally generated by probabilistic context-free grammars (PCFG), to more\nrich spatial patterns found in the Abstraction and Reasoning Corpus (ARC), a\ngeneral AI benchmark, prompted in the style of ASCII art. Surprisingly, pattern\ncompletion proficiency can be partially retained even when the sequences are\nexpressed using tokens randomly sampled from the vocabulary. These results\nsuggest that without any additional training, LLMs can serve as general\nsequence modelers, driven by in-context learning. In this work, we investigate\nhow these zero-shot capabilities may be applied to problems in robotics -- from\nextrapolating sequences of numbers that represent states over time to complete\nsimple motions, to least-to-most prompting of reward-conditioned trajectories\nthat can discover and represent closed-loop policies (e.g., a stabilizing\ncontroller for CartPole). While difficult to deploy today for real systems due\nto latency, context size limitations, and compute costs, the approach of using\nLLMs to drive low-level control may provide an exciting glimpse into how the\npatterns among words could be transferred to actions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mirchandani_S/0/1/0/all/0/1\">Suvir Mirchandani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1\">Pete Florence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1\">Brian Ichter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driess_D/0/1/0/all/0/1\">Danny Driess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arenas_M/0/1/0/all/0/1\">Montserrat Gonzalez Arenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1\">Kanishka Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1\">Dorsa Sadigh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Andy Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AlpaGasus: Training A Better Alpaca with Fewer Data. (arXiv:2307.08701v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.08701","description":"<p>Large language models~(LLMs) strengthen instruction-following capability\nthrough instruction-finetuning (IFT) on supervised instruction/response data.\nHowever, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly\ncontain many low-quality instances with incorrect or irrelevant responses,\nwhich are misleading and detrimental to IFT. In this paper, we propose a simple\nand effective data selection strategy that automatically identifies and filters\nout low-quality data using a strong LLM (e.g., ChatGPT). To this end, we\nintroduce AlpaGasus, which is finetuned on only 9k high-quality data filtered\nfrom the 52k Alpaca data. AlpaGasus significantly outperforms the original\nAlpaca as evaluated by GPT-4 on multiple test sets and the controlled human\nevaluation. Its 13B variant matches $&gt;90\\%$ performance of its teacher LLM\n(i.e., Text-Davinci-003 generating the 52k data) on test tasks. It also\nprovides 5.7x faster training, reducing the training time for a 7B variant from\n80 minutes (for Alpaca) to 14 minutes. Moreover, the experiments prove the\nefficacy of our method across diverse datasets, base models, and LLM filters.\nOverall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be\ngenerally applied to instruction-tuning data, leading to faster training and\nbetter instruction-following models. Our project page is available at:\n\\url{https://lichang-chen.github.io/AlpaGasus/}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lichang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunaratna_K/0/1/0/all/0/1\">Kalpa Gunaratna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vikas Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1\">Vijay Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hongxia Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction. (arXiv:2307.16200v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.16200","description":"<p>This paper focuses on term-status pair extraction from medical dialogues\n(MD-TSPE), which is essential in diagnosis dialogue systems and the automatic\nscribe of electronic medical records (EMRs). In the past few years, works on\nMD-TSPE have attracted increasing research attention, especially after the\nremarkable progress made by generative methods. However, these generative\nmethods output a whole sequence consisting of term-status pairs in one stage\nand ignore integrating prior knowledge, which demands a deeper understanding to\nmodel the relationship between terms and infer the status of each term. This\npaper presents a knowledge-enhanced two-stage generative framework (KTGF) to\naddress the above challenges. Using task-specific prompts, we employ a single\nmodel to complete the MD-TSPE through two phases in a unified generative form:\nwe generate all terms the first and then generate the status of each generated\nterm. In this way, the relationship between terms can be learned more\neffectively from the sequence containing only terms in the first phase, and our\ndesigned knowledge-enhanced prompt in the second phase can leverage the\ncategory and status candidates of the generated term for status generation.\nFurthermore, our proposed special status \"not mentioned\" makes more terms\navailable and enriches the training data in the second phase, which is critical\nin the low-resource setting. The experiments on the Chunyu and CMDD datasets\nshow that the proposed method achieves superior results compared to the\nstate-of-the-art models in the full training and low-resource settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zefa Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1\">Ziyi Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bo Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lexical Diversity in Kinship Across Languages and Dialects. (arXiv:2308.13056v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.13056","description":"<p>Languages are known to describe the world in diverse ways. Across lexicons,\ndiversity is pervasive, appearing through phenomena such as lexical gaps and\nuntranslatability. However, in computational resources, such as multilingual\nlexical databases, diversity is hardly ever represented. In this paper, we\nintroduce a method to enrich computational lexicons with content relating to\nlinguistic diversity. The method is verified through two large-scale case\nstudies on kinship terminology, a domain known to be diverse across languages\nand cultures: one case study deals with seven Arabic dialects, while the other\none with three Indonesian languages. Our results, made available as browseable\nand downloadable computational resources, extend prior linguistics research on\nkinship terminology, and provide insight into the extent of diversity even\nwithin linguistically and culturally close communities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalilia_H/0/1/0/all/0/1\">Hadi Khalilia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bella_G/0/1/0/all/0/1\">G&#xe1;bor Bella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freihat_A/0/1/0/all/0/1\">Abed Alhakim Freihat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darma_S/0/1/0/all/0/1\">Shandy Darma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giunchiglia_F/0/1/0/all/0/1\">Fausto Giunchiglia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior. (arXiv:2309.00359v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00359","description":"<p>Shannon, in his seminal paper introducing information theory, divided the\ncommunication into three levels: technical, semantic, and effectivenss. While\nthe technical level is concerned with accurate reconstruction of transmitted\nsymbols, the semantic and effectiveness levels deal with the inferred meaning\nand its effect on the receiver. Thanks to telecommunications, the first level\nproblem has produced great advances like the internet. Large Language Models\n(LLMs) make some progress towards the second goal, but the third level still\nremains largely untouched. The third problem deals with predicting and\noptimizing communication for desired receiver behavior. LLMs, while showing\nwide generalization capabilities across a wide range of tasks, are unable to\nsolve for this. One reason for the underperformance could be a lack of\n``behavior tokens'' in LLMs' training corpora. Behavior tokens define receiver\nbehavior over a communication, such as shares, likes, clicks, purchases,\nretweets, etc. While preprocessing data for LLM training, behavior tokens are\noften removed from the corpora as noise. Therefore, in this paper, we make some\ninitial progress towards reintroducing behavior tokens in LLM training. The\ntrained models, other than showing similar performance to LLMs on content\nunderstanding tasks, show generalization capabilities on behavior simulation,\ncontent simulation, behavior understanding, and behavior domain adaptation.\nUsing a wide range of tasks on two corpora, we show results on all these\ncapabilities. We call these models Large Content and Behavior Models (LCBMs).\nFurther, to spur more research on LCBMs, we release our new Content Behavior\nCorpus (CBC), a repository containing communicator, message, and corresponding\nreceiver behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1\">Ashmit Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Aditya Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1\">Aanisha Bhattacharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman K Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Somesh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_U/0/1/0/all/0/1\">Uttaran Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1\">Ishita Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrangeli_S/0/1/0/all/0/1\">Stefano Petrangeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What are Public Concerns about ChatGPT? A Novel Self-Supervised Neural Topic Model Tells You. (arXiv:2309.01522v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.01522","description":"<p>The recently released artificial intelligence conversational agent, ChatGPT,\nhas gained significant attention in academia and real life. A multitude of\nearly ChatGPT users eagerly explore its capabilities and share their opinions\non it via social media. Both user queries and social media posts express public\nconcerns regarding this advanced dialogue system. To mine public concerns about\nChatGPT, a novel Self-Supervised neural Topic Model (SSTM), which formalizes\ntopic modeling as a representation learning procedure, is proposed in this\npaper. Extensive experiments have been conducted on Twitter posts about ChatGPT\nand queries asked by ChatGPT users. And experimental results demonstrate that\nthe proposed approach could extract higher quality public concerns with\nimproved interpretability and diversity, surpassing the performance of\nstate-of-the-art approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haiping Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Natural Language Processing Model for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00100","description":"<p>The impression section of a radiology report summarizes important radiology\nfindings and plays a critical role in communicating these findings to\nphysicians. However, the preparation of these summaries is time-consuming and\nerror-prone for radiologists. Recently, numerous models for radiology report\nsummarization have been developed. Nevertheless, there is currently no model\nthat can summarize these reports in multiple languages. Such a model could\ngreatly improve future research and the development of Deep Learning models\nthat incorporate data from patients with different ethnic backgrounds. In this\nstudy, the generation of radiology impressions in different languages was\nautomated by fine-tuning a model, publicly available, based on a multilingual\ntext-to-text Transformer to summarize findings available in English,\nPortuguese, and German radiology reports. In a blind test, two board-certified\nradiologists indicated that for at least 70% of the system-generated summaries,\nthe quality matched or exceeded the corresponding human-written summaries,\nsuggesting substantial clinical reliability. Furthermore, this study showed\nthat the multilingual model outperformed other models that specialized in\nsummarizing radiology reports in only one language, as well as models that were\nnot specifically designed for summarizing radiology reports, such as ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lindo_M/0/1/0/all/0/1\">Mariana Lindo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1\">Ana Sofia Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_A/0/1/0/all/0/1\">Andr&#xe9; Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luijten_G/0/1/0/all/0/1\">Gijs Luijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Correia_G/0/1/0/all/0/1\">Gustavo Correia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Moon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1\">Jens Kleesiek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1\">Jan Egger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_V/0/1/0/all/0/1\">Victor Alves</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models. (arXiv:2310.02255v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.02255","description":"<p>Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit\nimpressive problem-solving skills in many tasks and domains, but their ability\nin mathematical reasoning in visual contexts has not been systematically\nstudied. To bridge this gap, we present MathVista, a benchmark designed to\ncombine challenges from diverse mathematical and visual tasks. It consists of\n6,141 examples, derived from 28 existing multimodal datasets involving\nmathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and\nPaperQA). Completing these tasks requires fine-grained, deep visual\nunderstanding and compositional reasoning, which all state-of-the-art\nfoundation models find challenging. With MathVista, we have conducted a\ncomprehensive, quantitative evaluation of 12 prominent foundation models. The\nbest-performing GPT-4V model achieves an overall accuracy of 49.9%,\nsubstantially outperforming Bard, the second-best performer, by 15.1%. Our\nin-depth analysis reveals that the superiority of GPT-4V is mainly attributed\nto its enhanced visual perception and mathematical reasoning. However, GPT-4V\nstill falls short of human performance by 10.4%, as it often struggles to\nunderstand complex figures and perform rigorous reasoning. This significant gap\nunderscores the critical role that MathVista will play in the development of\ngeneral-purpose AI agents capable of tackling mathematically intensive and\nvisually rich real-world tasks. We further explore the new ability of\nself-verification, the application of self-consistency, and the interactive\nchatbot capabilities of GPT-4V, highlighting its promising potential for future\nresearch. The project is available at https://mathvista.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1\">Hritik Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1\">Tony Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiacheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding. (arXiv:2310.11191v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11191","description":"<p>Text simplification has emerged as an increasingly useful application of AI\nfor bridging the communication gap in specialized fields such as medicine,\nwhere the lexicon is often dominated by technical jargon and complex\nconstructs. Despite notable progress, methods in medical simplification\nsometimes result in the generated text having lower quality and diversity. In\nthis work, we explore ways to further improve the readability of text\nsimplification in the medical domain. We propose (1) a new unlikelihood loss\nthat encourages generation of simpler terms and (2) a reranked beam search\ndecoding method that optimizes for simplicity, which achieve better performance\non readability metrics on three datasets. This study's findings offer promising\navenues for improving text simplification in the medical field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Flores_L/0/1/0/all/0/1\">Lorenzo Jaime Yu Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kejian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chheang_S/0/1/0/all/0/1\">Sophie Chheang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simultaneous Machine Translation with Tailored Reference. (arXiv:2310.13588v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13588","description":"<p>Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shoutao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Language Models Laugh at YouTube Short-form Videos?. (arXiv:2310.14159v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14159","description":"<p>As short-form funny videos on social networks are gaining popularity, it\nbecomes demanding for AI models to understand them for better communication\nwith humans. Unfortunately, previous video humor datasets target specific\ndomains, such as speeches or sitcoms, and mostly focus on verbal cues. We\ncurate a user-generated dataset of 10K multimodal funny videos from YouTube,\ncalled ExFunTube. Using a video filtering pipeline with GPT-3.5, we verify both\nverbal and visual elements contributing to humor. After filtering, we annotate\neach video with timestamps and text explanations for funny moments. Our\nExFunTube is unique over existing datasets in that our videos cover a wide\nrange of domains with various types of humor that necessitate a multimodal\nunderstanding of the content. Also, we develop a zero-shot video-to-text\nprompting to maximize video humor understanding of large language models\n(LLMs). With three different evaluation methods using automatic scores,\nrationale quality experiments, and human evaluations, we show that our\nprompting significantly improves LLMs' ability for humor explanation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ko_D/0/1/0/all/0/1\">Dayoon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model. (arXiv:2310.15113v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15113","description":"<p>Large language models (LLMs) have recently reached an impressive level of\nlinguistic capability, prompting comparisons with human language skills.\nHowever, there have been relatively few systematic inquiries into the\nlinguistic capabilities of the latest generation of LLMs, and those studies\nthat do exist (i) ignore the remarkable ability of humans to generalize, (ii)\nfocus only on English, and (iii) investigate syntax or semantics and overlook\nother capabilities that lie at the heart of human language, like morphology.\nHere, we close these gaps by conducting the first rigorous analysis of the\nmorphological capabilities of ChatGPT in four typologically varied languages\n(specifically, English, German, Tamil, and Turkish). We apply a version of\nBerko's (1958) wug test to ChatGPT, using novel, uncontaminated datasets for\nthe four examined languages. We find that ChatGPT massively underperforms\npurpose-built systems, particularly in English. Overall, our results -- through\nthe lens of morphology -- cast a new light on the linguistic capabilities of\nChatGPT, suggesting that claims of human-like language skills are premature and\nmisleading.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weissweiler_L/0/1/0/all/0/1\">Leonie Weissweiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hofmann_V/0/1/0/all/0/1\">Valentin Hofmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kantharuban_A/0/1/0/all/0/1\">Anjali Kantharuban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_A/0/1/0/all/0/1\">Anna Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutt_R/0/1/0/all/0/1\">Ritam Dutt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengle_A/0/1/0/all/0/1\">Amey Hengle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabra_A/0/1/0/all/0/1\">Anubha Kabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Atharva Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijayakumar_A/0/1/0/all/0/1\">Abhishek Vijayakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oflazer_K/0/1/0/all/0/1\">Kemal Oflazer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortensen_D/0/1/0/all/0/1\">David R. Mortensen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COPF: Continual Learning Human Preference through Optimal Policy Fitting. (arXiv:2310.15694v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.15694","description":"<p>The technique of Reinforcement Learning from Human Feedback (RLHF) is a\ncommonly employed method to improve pre-trained Language Models (LM), enhancing\ntheir ability to conform to human preferences. Nevertheless, the current\nRLHF-based LMs necessitate full retraining each time novel queries or feedback\nare introduced, which becomes a challenging task because human preferences can\nvary between different domains or tasks. Retraining LMs poses practical\ndifficulties in many real-world situations due to the significant time and\ncomputational resources required, along with concerns related to data privacy.\nTo address this limitation, we propose a new method called Continual Optimal\nPolicy Fitting (COPF), in which we estimate a series of optimal policies using\nthe Monte Carlo method, and then continually fit the policy sequence with the\nfunction regularization. COPF involves a single learning phase and doesn't\nnecessitate complex reinforcement learning. Importantly, it shares the\ncapability with RLHF to learn from unlabeled data, making it flexible for\ncontinual preference learning. Our experimental results show that COPF\noutperforms strong Continuous learning (CL) baselines when it comes to\nconsistently aligning with human preferences on different tasks and domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yuanzhao Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Editing for Large Language Models: A Survey. (arXiv:2310.16218v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16218","description":"<p>Large language models (LLMs) have recently transformed both the academic and\nindustrial landscapes due to their remarkable capacity to understand, analyze,\nand generate texts based on their vast knowledge and reasoning ability.\nNevertheless, one major drawback of LLMs is their substantial computational\ncost for pre-training due to their unprecedented amounts of parameters. The\ndisadvantage is exacerbated when new knowledge frequently needs to be\nintroduced into the pre-trained model. Therefore, it is imperative to develop\neffective and efficient techniques to update pre-trained LLMs. Traditional\nmethods encode new knowledge in pre-trained LLMs through direct fine-tuning.\nHowever, naively re-training LLMs can be computationally intensive and risks\ndegenerating valuable pre-trained knowledge irrelevant to the update in the\nmodel. Recently, Knowledge-based Model Editing (KME) has attracted increasing\nattention, which aims to precisely modify the LLMs to incorporate specific\nknowledge, without negatively influencing other irrelevant knowledge. In this\nsurvey, we aim to provide a comprehensive and in-depth overview of recent\nadvances in the field of KME. We first introduce a general formulation of KME\nto encompass different KME strategies. Afterward, we provide an innovative\ntaxonomy of KME techniques based on how the new knowledge is introduced into\npre-trained LLMs, and investigate existing KME strategies while analyzing key\ninsights, advantages, and limitations of methods from each category. Moreover,\nrepresentative metrics, datasets, and applications of KME are introduced\naccordingly. Finally, we provide an in-depth analysis regarding the\npracticality and remaining challenges of KME and suggest promising research\ndirections for further advancement in this field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Song Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaochen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaiyi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jundong Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unraveling Feature Extraction Mechanisms in Neural Networks. (arXiv:2310.16350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16350","description":"<p>The underlying mechanism of neural networks in capturing precise knowledge\nhas been the subject of consistent research efforts. In this work, we propose a\ntheoretical approach based on Neural Tangent Kernels (NTKs) to investigate such\nmechanisms. Specifically, considering the infinite network width, we\nhypothesize the learning dynamics of target models may intuitively unravel the\nfeatures they acquire from training data, deepening our insights into their\ninternal mechanisms. We apply our approach to several fundamental models and\nreveal how these models leverage statistical features during gradient descent\nand how they are integrated into final decisions. We also discovered that the\nchoice of activation function can affect feature extraction. For instance, the\nuse of the \\textit{ReLU} activation function could potentially introduce a bias\nin features, providing a plausible explanation for its replacement with\nalternative functions in recent pre-trained language models. Additionally, we\nfind that while self-attention and CNN models may exhibit limitations in\nlearning n-grams, multiplication-based models seem to excel in this area. We\nverify these theoretical findings through experiments and find that they can be\napplied to analyze language modeling tasks, which can be regarded as a special\nvariant of classification. Our contributions offer insights into the roles and\ncapacities of fundamental components within large language models, thereby\naiding the broader understanding of these complex systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaobing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models. (arXiv:2310.16436v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.16436","description":"<p>A long-standing goal of AI systems is to perform complex multimodal reasoning\nlike humans. Recently, large language models (LLMs) have made remarkable\nstrides in such multi-step reasoning on the language modality solely by\nleveraging the chain of thought (CoT) to mimic human thinking. However, the\ntransfer of these advancements to multimodal contexts introduces heightened\nchallenges, including but not limited to the impractical need for\nlabor-intensive annotation and the limitations in terms of flexibility,\ngeneralizability, and explainability. To evoke CoT reasoning in multimodality,\nthis work first conducts an in-depth analysis of these challenges posed by\nmultimodality and presents two key insights: \"keeping critical thinking\" and\n\"letting everyone do their jobs\" in multimodal CoT reasoning. Furthermore, this\nstudy proposes a novel DDCoT prompting that maintains a critical attitude\nthrough negative-space prompting and incorporates multimodality into reasoning\nby first dividing the reasoning responsibility of LLMs into reasoning and\nrecognition and then integrating the visual recognition capability of visual\nmodels into the joint reasoning process. The rationales generated by DDCoT not\nonly improve the reasoning abilities of both large and small language models in\nzero-shot prompting and fine-tuning learning, significantly outperforming\nstate-of-the-art methods but also exhibit impressive generalizability and\nexplainability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Ge Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiajin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hong-Yu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sibei Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SkyMath: Technical Report. (arXiv:2310.16713v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16713","description":"<p>Large language models (LLMs) have shown great potential to solve varieties of\nnatural language processing (NLP) tasks, including mathematical reasoning. In\nthis work, we present SkyMath, a large language model for mathematics with 13\nbillion parameters. By applying self-compare fine-tuning, we have enhanced\nmathematical reasoning abilities of Skywork-13B-Base remarkably. On GSM8K,\nSkyMath outperforms all known open-source models of similar size and has\nestablished a new SOTA performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haihua Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wenjun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yifu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lunan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jianfei Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianwen Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Biye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bo Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guoliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xuejie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xilin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1\">Rui Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection. (arXiv:2310.16776v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16776","description":"<p>Recent advances have led to the availability of many pre-trained language\nmodels (PLMs); however, a question that remains is how much data is truly\nneeded to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT,\na data-efficient fine-tuning framework that leverages unsupervised core-set\nselection to minimize the amount of data needed to fine-tune PLMs for\ndownstream tasks. We demonstrate the efficacy of our DEFT framework in the\ncontext of text-editing LMs, and compare to the state-of-the art text-editing\nmodel, CoEDIT. Our quantitative and qualitative results demonstrate that DEFT\nmodels are just as accurate as CoEDIT while being finetuned on ~70% less data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Devleena Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khetan_V/0/1/0/all/0/1\">Vivek Khetan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-26T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}