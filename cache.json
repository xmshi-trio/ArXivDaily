{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-16T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models. (arXiv:2310.08659v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08659","description":"<p>Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves the\ngeneralization in downstream tasks. We evaluate our method on natural language\nunderstanding, question answering, summarization, and natural language\ngeneration tasks. Experiments show that our method is highly effective and\noutperforms existing quantization methods, especially in the challenging 2-bit\nand 2/4-bit mixed precision regimes. We will release our code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karampatziakis_N/0/1/0/all/0/1\">Nikos Karampatziakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4 on mock CFA Exams. (arXiv:2310.08678v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08678","description":"<p>Large Language Models (LLMs) have demonstrated remarkable performance on a\nwide range of Natural Language Processing (NLP) tasks, often matching or even\nbeating state-of-the-art task-specific models. This study aims at assessing the\nfinancial reasoning capabilities of LLMs. We leverage mock exam questions of\nthe Chartered Financial Analyst (CFA) Program to conduct a comprehensive\nevaluation of ChatGPT and GPT-4 in financial analysis, considering Zero-Shot\n(ZS), Chain-of-Thought (CoT), and Few-Shot (FS) scenarios. We present an\nin-depth analysis of the models' performance and limitations, and estimate\nwhether they would have a chance at passing the CFA exams. Finally, we outline\ninsights into potential strategies and improvements to enhance the\napplicability of LLMs in finance. In this perspective, we hope this work paves\nthe way for future studies to continue enhancing LLMs for financial reasoning\nthrough rigorous evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Callanan_E/0/1/0/all/0/1\">Ethan Callanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mbakwe_A/0/1/0/all/0/1\">Amarachi Mbakwe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadimitriou_A/0/1/0/all/0/1\">Antony Papadimitriou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_Y/0/1/0/all/0/1\">Yulong Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sibue_M/0/1/0/all/0/1\">Mathieu Sibue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zhiqiang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaomo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sameena Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Joint Language Modeling for Speech Units and Text. (arXiv:2310.08715v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08715","description":"<p>Speech and text are two major forms of human language. The research community\nhas been focusing on mapping speech to text or vice versa for many years.\nHowever, in the field of language modeling, very little effort has been made to\nmodel them jointly. In light of this, we explore joint language modeling for\nspeech units and text. Specifically, we compare different speech tokenizers to\ntransform continuous speech signals into discrete units and use different\nmethods to construct mixed speech-text data. We introduce automatic metrics to\nevaluate how well the joint LM mixes speech and text. We also fine-tune the LM\non downstream spoken language understanding (SLU) tasks with different\nmodalities (speech or text) and test its performance to assess the model's\nlearning of shared representations. Our results show that by mixing speech\nunits and text with our proposed mixing techniques, the joint LM improves over\na speech-only baseline on SLU tasks and shows zero-shot cross-modal\ntransferability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chou_J/0/1/0/all/0/1\">Ju-Chieh Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_C/0/1/0/all/0/1\">Chung-Ming Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1\">Arun Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conneau_A/0/1/0/all/0/1\">Alexis Conneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Zero-Shot Language Agent for Computer Control with Structured Reflection. (arXiv:2310.08740v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08740","description":"<p>Large language models (LLMs) have shown increasing capacity at planning and\nexecuting a high-level goal in a live computer environment (e.g. MiniWoB++). To\nperform a task, recent works often require a model to learn from trace examples\nof the task via either supervised learning or few/many-shot prompting. Without\nthese trace examples, it remains a challenge how an agent can autonomously\nlearn and improve its control on a computer, which limits the ability of an\nagent to perform a new task. We approach this problem with a zero-shot agent\nthat requires no given expert traces. Our agent plans for executable actions on\na partially observed environment, and iteratively progresses a task by\nidentifying and learning from its mistakes via self-reflection and structured\nthought management. On the easy tasks of MiniWoB++, we show that our zero-shot\nagent often outperforms recent SoTAs, with more efficient reasoning. For tasks\nwith more complexity, our reflective agent performs on par with prior best\nmodels, even though previous works had the advantages of accessing expert\ntraces or additional screen information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhiwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bryan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Circuit Component Reuse Across Tasks in Transformer Language Models. (arXiv:2310.08744v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08744","description":"<p>Recent work in mechanistic interpretability has shown that behaviors in\nlanguage models can be successfully reverse-engineered through circuit\nanalysis. A common criticism, however, is that each circuit is task-specific,\nand thus such analysis cannot contribute to understanding the models at a\nhigher level. In this work, we present evidence that insights (both low-level\nfindings about specific heads and higher-level findings about general\nalgorithms) can indeed generalize across tasks. Specifically, we study the\ncircuit discovered in Wang et al. (2022) for the Indirect Object Identification\n(IOI) task and 1.) show that it reproduces on a larger GPT2 model, and 2.) that\nit is mostly reused to solve a seemingly different task: Colored Objects\n(Ippolito &amp; Callison-Burch, 2023). We provide evidence that the process\nunderlying both tasks is functionally very similar, and contains about a 78%\noverlap in in-circuit attention heads. We further present a proof-of-concept\nintervention experiment, in which we adjust four attention heads in middle\nlayers in order to 'repair' the Colored Objects circuit and make it behave like\nthe IOI circuit. In doing so, we boost accuracy from 49.6% to 93.7% on the\nColored Objects task and explain most sources of error. The intervention\naffects downstream attention heads in specific ways predicted by their\ninteractions in the IOI circuit, indicating that this subcircuit behavior is\ninvariant to the different task inputs. Overall, our results provide evidence\nthat it may yet be possible to explain large language models' behavior in terms\nof a relatively small number of interpretable task-general algorithmic building\nblocks and computational components.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Merullo_J/0/1/0/all/0/1\">Jack Merullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models. (arXiv:2310.08753v1 [cs.SD])","link":"http://arxiv.org/abs/2310.08753","description":"<p>A fundamental characteristic of audio is its compositional nature.\nAudio-language models (ALMs) trained using a contrastive approach (e.g., CLAP)\nthat learns a shared representation between audio and language modalities have\nimproved performance in many downstream applications, including zero-shot audio\nclassification, audio retrieval, etc. However, the ability of these models to\neffectively perform compositional reasoning remains largely unexplored and\nnecessitates additional research. In this paper, we propose CompA, a collection\nof two expert-annotated benchmarks with a majority of real-world audio samples,\nto evaluate compositional reasoning in ALMs. Our proposed CompA-order evaluates\nhow well an ALM understands the order or occurrence of acoustic events in\naudio, and CompA-attribute evaluates attribute binding of acoustic events. An\ninstance from either benchmark consists of two audio-caption pairs, where both\naudios have the same acoustic events but with different compositions. An ALM is\nevaluated on how well it matches the right audio to the right caption. Using\nthis benchmark, we first show that current ALMs perform only marginally better\nthan random chance, thereby struggling with compositional reasoning. Next, we\npropose CompA-CLAP, where we fine-tune CLAP using a novel learning method to\nimprove its compositional reasoning abilities. To train CompA-CLAP, we first\npropose improvements to contrastive training with composition-aware hard\nnegatives, allowing for more focused training. Next, we propose a novel modular\ncontrastive loss that helps the model learn fine-grained compositional\nunderstanding and overcomes the acute scarcity of openly available\ncompositional audios. CompA-CLAP significantly improves over all our baseline\nmodels on the CompA benchmark, indicating its superior compositional reasoning\ncapabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sreyan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seth_A/0/1/0/all/0/1\">Ashish Seth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sonal Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_U/0/1/0/all/0/1\">Utkarsh Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evuru_C/0/1/0/all/0/1\">Chandra Kiran Evuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramaneswaran_S/0/1/0/all/0/1\">S. Ramaneswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakshi_S/0/1/0/all/0/1\">S. Sakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nieto_O/0/1/0/all/0/1\">Oriol Nieto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duraiswami_R/0/1/0/all/0/1\">Ramani Duraiswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Calibrating Likelihoods towards Consistency in Summarization Models. (arXiv:2310.08764v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08764","description":"<p>Despite the recent advances in abstractive text summarization, current\nsummarization models still suffer from generating factually inconsistent\nsummaries, reducing their utility for real-world application. We argue that the\nmain reason for such behavior is that the summarization models trained with\nmaximum likelihood objective assign high probability to plausible sequences\ngiven the context, but they often do not accurately rank sequences by their\nconsistency. In this work, we solve this problem by calibrating the likelihood\nof model generated sequences to better align with a consistency metric measured\nby natural language inference (NLI) models. The human evaluation study and\nautomatic metrics show that the calibrated models generate more consistent and\nhigher-quality summaries. We also show that the models trained using our method\nreturn probabilities that are better aligned with the NLI scores, which\nsignificantly increase reliability of summarization models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zablotskaia_P/0/1/0/all/0/1\">Polina Zablotskaia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalman_M/0/1/0/all/0/1\">Misha Khalman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Rishabh Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soares_L/0/1/0/all/0/1\">Livio Baldini Soares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobovits_S/0/1/0/all/0/1\">Shoshana Jakobovits</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1\">Shashi Narayan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Im not Racist but...\": Discovering Bias in the Internal Knowledge of Large Language Models. (arXiv:2310.08780v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08780","description":"<p>Large language models (LLMs) have garnered significant attention for their\nremarkable performance in a continuously expanding set of natural language\nprocessing tasks. However, these models have been shown to harbor inherent\nsocietal biases, or stereotypes, which can adversely affect their performance\nin their many downstream applications. In this paper, we introduce a novel,\npurely prompt-based approach to uncover hidden stereotypes within any arbitrary\nLLM. Our approach dynamically generates a knowledge representation of internal\nstereotypes, enabling the identification of biases encoded within the LLM's\ninternal knowledge. By illuminating the biases present in LLMs and offering a\nsystematic methodology for their analysis, our work contributes to advancing\ntransparency and promoting fairness in natural language processing systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salinas_A/0/1/0/all/0/1\">Abel Salinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penafiel_L/0/1/0/all/0/1\">Louis Penafiel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCormack_R/0/1/0/all/0/1\">Robert McCormack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1\">Fred Morstatter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Bias for Question Answering Models by Tracking Bias Influence. (arXiv:2310.08795v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08795","description":"<p>Models of various NLP tasks have been shown to exhibit stereotypes, and the\nbias in the question answering (QA) models is especially harmful as the output\nanswers might be directly consumed by the end users. There have been datasets\nto evaluate bias in QA models, while bias mitigation technique for the QA\nmodels is still under-explored. In this work, we propose BMBI, an approach to\nmitigate the bias of multiple-choice QA models. Based on the intuition that a\nmodel would lean to be more biased if it learns from a biased example, we\nmeasure the bias level of a query instance by observing its influence on\nanother instance. If the influenced instance is more biased, we derive that the\nquery instance is biased. We then use the bias level detected as an\noptimization objective to form a multi-task learning setting in addition to the\noriginal QA task. We further introduce a new bias evaluation metric to quantify\nbias in a comprehensive and sensitive way. We show that our method could be\napplied to multiple QA formulations across multiple bias categories. It can\nsignificantly reduce the bias level in all 9 bias categories in the BBQ dataset\nwhile maintaining comparable QA accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyu Derek Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kao_J/0/1/0/all/0/1\">Jiun-Yu Kao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Arpit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yu-Hsiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_T/0/1/0/all/0/1\">Tagyoung Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-end Story Plot Generator. (arXiv:2310.08796v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08796","description":"<p>Story plots, while short, carry most of the essential information of a full\nstory that may contain tens of thousands of words. We study the problem of\nautomatic generation of story plots, which includes story premise, character\ndescriptions, plot outlines, etc. To generate a single engaging plot, existing\nplot generators (e.g., DOC (Yang et al., 2022a)) require hundreds to thousands\nof calls to LLMs (e.g., OpenAI API) in the planning stage of the story plot,\nwhich is costly and takes at least several minutes. Moreover, the hard-wired\nnature of the method makes the pipeline non-differentiable, blocking fast\nspecialization and personalization of the plot generator. In this paper, we\npropose three models, $\\texttt{OpenPlot}$, $\\texttt{E2EPlot}$ and\n$\\texttt{RLPlot}$, to address these challenges. $\\texttt{OpenPlot}$ replaces\nexpensive OpenAI API calls with LLaMA2 (Touvron et al., 2023) calls via careful\nprompt designs, which leads to inexpensive generation of high-quality training\ndatasets of story plots. We then train an end-to-end story plot generator,\n$\\texttt{E2EPlot}$, by supervised fine-tuning (SFT) using approximately 13000\nstory plots generated by $\\texttt{OpenPlot}$. $\\texttt{E2EPlot}$ generates\nstory plots of comparable quality to $\\texttt{OpenPlot}$, and is &gt; 10$\\times$\nfaster (1k tokens in only 30 seconds on average). Finally, we obtain\n$\\texttt{RLPlot}$ that is further fine-tuned with RLHF on several different\nreward models for different aspects of story quality, which yields 60.0$\\%$\nwinning rate against $\\texttt{E2EPlot}$ along the aspect of suspense and\nsurprise.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1\">Andrew Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Danqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaomeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparative Analysis of Task-Agnostic Distillation Methods for Compressing Transformer Language Models. (arXiv:2310.08797v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08797","description":"<p>Large language models have become a vital component in modern NLP, achieving\nstate of the art performance in a variety of tasks. However, they are often\ninefficient for real-world deployment due to their expensive inference costs.\nKnowledge distillation is a promising technique to improve their efficiency\nwhile retaining most of their effectiveness. In this paper, we reproduce,\ncompare and analyze several representative methods for task-agnostic\n(general-purpose) distillation of Transformer language models. Our target of\nstudy includes Output Distribution (OD) transfer, Hidden State (HS) transfer\nwith various layer mapping strategies, and Multi-Head Attention (MHA) transfer\nbased on MiniLMv2. Through our extensive experiments, we study the\neffectiveness of each method for various student architectures in both\nmonolingual (English) and multilingual settings. Overall, we show that MHA\ntransfer based on MiniLMv2 is generally the best option for distillation and\nexplain the potential reasons behind its success. Moreover, we show that HS\ntransfer remains as a competitive baseline, especially under a sophisticated\nlayer mapping strategy, while OD transfer consistently lags behind other\napproaches. Findings from this study helped us deploy efficient yet effective\nstudent models for latency-critical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Udagawa_T/0/1/0/all/0/1\">Takuma Udagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1\">Aashka Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merler_M/0/1/0/all/0/1\">Michele Merler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharjee_B/0/1/0/all/0/1\">Bishwaranjan Bhattacharjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Source Planner for Personalized Knowledge-grounded Dialogue. (arXiv:2310.08840v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08840","description":"<p>Open-domain dialogue system usually requires different sources of knowledge\nto generate more informative and evidential responses. However, existing\nknowledge-grounded dialogue systems either focus on a single knowledge source\nor overlook the dependency between multiple sources of knowledge, which may\nresult in generating inconsistent or even paradoxical responses. To incorporate\nmultiple knowledge sources and dependencies between them, we propose SAFARI, a\nnovel framework that leverages the exceptional capabilities of large language\nmodels (LLMs) in planning, understanding, and incorporating under both\nsupervised and unsupervised settings. Specifically, SAFARI decouples the\nknowledge grounding into multiple sources and response generation, which allows\neasy extension to various knowledge sources including the possibility of not\nusing any sources. To study the problem, we construct a personalized\nknowledge-grounded dialogue dataset \\textit{\\textbf{K}nowledge \\textbf{B}ehind\n\\textbf{P}ersona}~(\\textbf{KBP}), which is the first to consider the dependency\nbetween persona and implicit knowledge. Experimental results on the KBP dataset\ndemonstrate that the SAFARI framework can effectively produce\npersona-consistent and knowledge-enhanced responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Minda Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weichao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwan_W/0/1/0/all/0/1\">Wai-Chung Kwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Guiding AMR Parsing with Reverse Graph Linearization. (arXiv:2310.08860v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08860","description":"<p>Abstract Meaning Representation (AMR) parsing aims to extract an abstract\nsemantic graph from a given sentence. The sequence-to-sequence approaches,\nwhich linearize the semantic graph into a sequence of nodes and edges and\ngenerate the linearized graph directly, have achieved good performance.\nHowever, we observed that these approaches suffer from structure loss\naccumulation during the decoding process, leading to a much lower F1-score for\nnodes and edges decoded later compared to those decoded earlier. To address\nthis issue, we propose a novel Reverse Graph Linearization (RGL) enhanced\nframework. RGL defines both default and reverse linearization orders of an AMR\ngraph, where most structures at the back part of the default order appear at\nthe front part of the reversed order and vice versa. RGL incorporates the\nreversed linearization to the original AMR parser through a two-pass\nself-distillation mechanism, which guides the model when generating the default\nlinearizations. Our analysis shows that our proposed method significantly\nmitigates the problem of structure loss accumulation, outperforming the\npreviously best AMR parsing model by 0.8 and 0.5 Smatch scores on the AMR 2.0\nand AMR 3.0 dataset, respectively. The code are available at\nhttps://github.com/pkunlp-icler/AMR_reverse_graph_linearization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1\">Bofei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System. (arXiv:2310.08877v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08877","description":"<p>Developing an efficient retriever to retrieve knowledge from a large-scale\nknowledge base (KB) is critical for task-oriented dialogue systems to\neffectively handle localized and specialized tasks. However, widely used\ngenerative models such as T5 and ChatGPT often struggle to differentiate subtle\ndifferences among the retrieved KB records when generating responses, resulting\nin suboptimal quality of generated responses. In this paper, we propose the\napplication of maximal marginal likelihood to train a perceptive retriever by\nutilizing signals from response generation for supervision. In addition, our\napproach goes beyond considering solely retrieved entities and incorporates\nvarious meta knowledge to guide the generator, thus improving the utilization\nof knowledge. We evaluate our approach on three task-oriented dialogue datasets\nusing T5 and ChatGPT as the backbone models. The results demonstrate that when\ncombined with meta knowledge, the response generator can effectively leverage\nhigh-quality knowledge records from the retriever and enhance the quality of\ngenerated responses. The codes and models of this paper are available at\nhttps://github.com/shenwzh3/MK-TOD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Weizhou Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yingqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Canbin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructTODS: Large Language Models for End-to-End Task-Oriented Dialogue Systems. (arXiv:2310.08885v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08885","description":"<p>Large language models (LLMs) have been used for diverse tasks in natural\nlanguage processing (NLP), yet remain under-explored for task-oriented dialogue\nsystems (TODS), especially for end-to-end TODS. We present InstructTODS, a\nnovel off-the-shelf framework for zero-shot end-to-end task-oriented dialogue\nsystems that can adapt to diverse domains without fine-tuning. By leveraging\nLLMs, InstructTODS generates a proxy belief state that seamlessly translates\nuser intentions into dynamic queries for efficient interaction with any KB. Our\nextensive experiments demonstrate that InstructTODS achieves comparable\nperformance to fully fine-tuned TODS in guiding dialogues to successful\ncompletion without prior knowledge or task-specific data. Furthermore, a\nrigorous human evaluation of end-to-end TODS shows that InstructTODS produces\ndialogue responses that notably outperform both the gold responses and the\nstate-of-the-art TODS in terms of helpfulness, informativeness, and humanness.\nMoreover, the effectiveness of LLMs in TODS is further supported by our\ncomprehensive evaluations on TODS subtasks: dialogue state tracking, intent\nclassification, and response generation. Code and implementations could be\nfound here https://github.com/WillyHC22/InstructTODS/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilie_B/0/1/0/all/0/1\">Bryan Wilie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PerturbScore: Connecting Discrete and Continuous Perturbations in NLP. (arXiv:2310.08889v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08889","description":"<p>With the rapid development of neural network applications in NLP, model\nrobustness problem is gaining more attention. Different from computer vision,\nthe discrete nature of texts makes it more challenging to explore robustness in\nNLP. Therefore, in this paper, we aim to connect discrete perturbations with\ncontinuous perturbations, therefore we can use such connections as a bridge to\nhelp understand discrete perturbations in NLP models. Specifically, we first\nexplore how to connect and measure the correlation between discrete\nperturbations and continuous perturbations. Then we design a regression task as\na PerturbScore to learn the correlation automatically. Through experimental\nresults, we find that we can build a connection between discrete and continuous\nperturbations and use the proposed PerturbScore to learn such correlation,\nsurpassing previous methods used in discrete perturbation measuring. Further,\nthe proposed PerturbScore can be well generalized to different datasets,\nperturbation methods, indicating that we can use it as a powerful tool to study\nmodel robustness in NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Ke Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1\">Yunfan Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploration with Principles for Diverse AI Supervision. (arXiv:2310.08899v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08899","description":"<p>Training large transformers using next-token prediction has given rise to\ngroundbreaking advancements in AI. While this generative AI approach has\nproduced impressive results, it heavily leans on human supervision. Even\nstate-of-the-art AI models like ChatGPT depend on fine-tuning through human\ndemonstrations, demanding extensive human input and domain expertise. This\nstrong reliance on human oversight poses a significant hurdle to the\nadvancement of AI innovation. To address this limitation, we propose a novel\nparadigm termed Exploratory AI (EAI) aimed at autonomously generating\nhigh-quality training data. Drawing inspiration from unsupervised reinforcement\nlearning (RL) pretraining, EAI achieves exploration within the natural language\nspace. We accomplish this by harnessing large language models to assess the\nnovelty of generated content. Our approach employs two key components: an actor\nthat generates novel content following exploration principles and a critic that\nevaluates the generated content, offering critiques to guide the actor.\nEmpirical evaluations demonstrate that EAI significantly boosts model\nperformance on complex reasoning tasks, addressing the limitations of\nhuman-intensive supervision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Welfare Diplomacy: Benchmarking Language Model Cooperation. (arXiv:2310.08901v1 [cs.MA])","link":"http://arxiv.org/abs/2310.08901","description":"<p>The growing capabilities and increasingly widespread deployment of AI systems\nnecessitate robust benchmarks for measuring their cooperative capabilities.\nUnfortunately, most multi-agent benchmarks are either zero-sum or purely\ncooperative, providing limited opportunities for such measurements. We\nintroduce a general-sum variant of the zero-sum board game Diplomacy -- called\nWelfare Diplomacy -- in which players must balance investing in military\nconquest and domestic welfare. We argue that Welfare Diplomacy facilitates both\na clearer assessment of and stronger training incentives for cooperative\ncapabilities. Our contributions are: (1) proposing the Welfare Diplomacy rules\nand implementing them via an open-source Diplomacy engine; (2) constructing\nbaseline agents using zero-shot prompted language models; and (3) conducting\nexperiments where we find that baselines using state-of-the-art models attain\nhigh social welfare but are exploitable. Our work aims to promote societal\nsafety by aiding researchers in developing and assessing multi-agent AI\nsystems. Code to evaluate Welfare Diplomacy and reproduce our experiments is\navailable at https://github.com/mukobi/welfare-diplomacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mukobi_G/0/1/0/all/0/1\">Gabriel Mukobi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erlebach_H/0/1/0/all/0/1\">Hannah Erlebach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauffer_N/0/1/0/all/0/1\">Niklas Lauffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammond_L/0/1/0/all/0/1\">Lewis Hammond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Alan Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_J/0/1/0/all/0/1\">Jesse Clifton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SeqXGPT: Sentence-Level AI-Generated Text Detection. (arXiv:2310.08903v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08903","description":"<p>Widely applied large language models (LLMs) can generate human-like content,\nraising concerns about the abuse of LLMs. Therefore, it is important to build\nstrong AI-generated text (AIGT) detectors. Current works only consider\ndocument-level AIGT detection, therefore, in this paper, we first introduce a\nsentence-level detection challenge by synthesizing a dataset that contains\ndocuments that are polished with LLMs, that is, the documents contain sentences\nwritten by humans and sentences modified by LLMs. Then we propose\n\\textbf{Seq}uence \\textbf{X} (Check) \\textbf{GPT}, a novel method that utilizes\nlog probability lists from white-box LLMs as features for sentence-level AIGT\ndetection. These features are composed like \\textit{waves} in speech processing\nand cannot be studied by LLMs. Therefore, we build SeqXGPT based on convolution\nand self-attention networks. We test it in both sentence and document-level\ndetection challenges. Experimental results show that previous methods struggle\nin solving sentence-level AIGT detection, while our method not only\nsignificantly surpasses baseline methods in both sentence and document-level\ndetection challenges but also exhibits strong generalization capabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Ke Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Botian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-in-the-loop Machine Translation with Large Language Model. (arXiv:2310.08908v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08908","description":"<p>The large language model (LLM) has garnered significant attention due to its\nin-context learning mechanisms and emergent capabilities. The research\ncommunity has conducted several pilot studies to apply LLMs to machine\ntranslation tasks and evaluate their performance from diverse perspectives.\nHowever, previous research has primarily focused on the LLM itself and has not\nexplored human intervention in the inference process of LLM. The\ncharacteristics of LLM, such as in-context learning and prompt engineering,\nclosely mirror human cognitive abilities in language tasks, offering an\nintuitive solution for human-in-the-loop generation. In this study, we propose\na human-in-the-loop pipeline that guides LLMs to produce customized outputs\nwith revision instructions. The pipeline initiates by prompting the LLM to\nproduce a draft translation, followed by the utilization of automatic retrieval\nor human feedback as supervision signals to enhance the LLM's translation\nthrough in-context learning. The human-machine interactions generated in this\npipeline are also stored in an external database to expand the in-context\nretrieval database, enabling us to leverage human supervision in an offline\nsetting. We evaluate the proposed pipeline using GPT-3.5-turbo API on five\ndomain-specific benchmarks for German-English translation. The results\ndemonstrate the effectiveness of the pipeline in tailoring in-domain\ntranslations and improving translation performance compared to direct\ntranslation. Additionally, we discuss the results from the following\nperspectives: 1) the effectiveness of different in-context retrieval methods;\n2) the construction of a retrieval database under low-resource scenarios; 3)\nthe observed domains differences; 4) the quantitative analysis of linguistic\nstatistics; and 5) the qualitative analysis of translation cases. The code and\ndata are available at https://github.com/NLP2CT/HIL-MT/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1\">Runzhe Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junchao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_L/0/1/0/all/0/1\">Lidia S. Chao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Relation-aware Ensemble Learning for Knowledge Graph Embedding. (arXiv:2310.08917v1 [cs.LG])","link":"http://arxiv.org/abs/2310.08917","description":"<p>Knowledge graph (KG) embedding is a fundamental task in natural language\nprocessing, and various methods have been proposed to explore semantic patterns\nin distinctive ways. In this paper, we propose to learn an ensemble by\nleveraging existing methods in a relation-aware manner. However, exploring\nthese semantics using relation-aware ensemble leads to a much larger search\nspace than general ensemble methods. To address this issue, we propose a\ndivide-search-combine algorithm RelEns-DSC that searches the relation-wise\nensemble weights independently. This algorithm has the same computation cost as\ngeneral ensemble methods but with much better performance. Experimental results\non benchmark datasets demonstrate the effectiveness of the proposed method in\nefficiently searching relation-aware ensemble weights and achieving\nstate-of-the-art embedding performance. The code is public at\nhttps://github.com/LARS-research/RelEns.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_L/0/1/0/all/0/1\">Ling Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1\">Quanming Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhenxi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning. (arXiv:2310.08923v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08923","description":"<p>Large Language models (LLMs) possess the capability to engage In-context\nLearning (ICL) by leveraging a few demonstrations pertaining to a new\ndownstream task as conditions. However, this particular learning paradigm\nsuffers from high instability stemming from substantial variances induced by\nfactors such as the input distribution of selected examples, their ordering,\nand prompt formats. In this work, we demonstrate that even when all these\nfactors are held constant, the random selection of examples still results in\nhigh variance. Consequently, we aim to explore the informative ability of data\nexamples by quantifying the Information Gain (IG) obtained in prediction after\nobserving a given example candidate. Then we propose to sample those with\nmaximum IG. Additionally, we identify the presence of template bias, which can\nlead to unfair evaluations of IG during the sampling process. To mitigate this\nbias, we introduce Calibration Before Sampling strategy. The experimental\nresults illustrate that our proposed method can yield an average relative\nimprovement of 14.3% across six classification tasks using three LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation. (arXiv:2310.08943v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08943","description":"<p>Knowledge-grounded dialogue generation aims to mitigate the issue of text\ndegeneration by incorporating external knowledge to supplement the context.\nHowever, the model often fails to internalize this information into responses\nin a human-like manner. Instead, it simply inserts segments of the provided\nknowledge into generic responses. As a result, the generated responses tend to\nbe tedious, incoherent, and in lack of interactivity which means the\ndegeneration problem is still unsolved. In this work, we first find that such\ncopying-style degeneration is primarily due to the weak likelihood objective,\nwhich allows the model to \"cheat\" the objective by merely duplicating knowledge\nsegments in a superficial pattern matching based on overlap. To overcome this\nchallenge, we then propose a Multi-level Adaptive Contrastive Learning (MACL)\nframework that dynamically samples negative examples and subsequently penalizes\ndegeneration behaviors at both the token-level and sequence-level. Extensive\nexperiments on the WoW dataset demonstrate the effectiveness of our approach\nacross various pre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenxu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lanrui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CAMELL: Confidence-based Acquisition Model for Efficient Self-supervised Active Learning with Label Validation. (arXiv:2310.08944v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08944","description":"<p>Supervised neural approaches are hindered by their dependence on large,\nmeticulously annotated datasets, a requirement that is particularly cumbersome\nfor sequential tasks. The quality of annotations tends to deteriorate with the\ntransition from expert-based to crowd-sourced labelling. To address these\nchallenges, we present \\textbf{CAMELL} (Confidence-based Acquisition Model for\nEfficient self-supervised active Learning with Label validation), a pool-based\nactive learning framework tailored for sequential multi-output problems. CAMELL\npossesses three core features: (1) it requires expert annotators to label only\na fraction of a chosen sequence, (2) it facilitates self-supervision for the\nremainder of the sequence, and (3) it employs a label validation mechanism to\nprevent erroneous labels from contaminating the dataset and harming model\nperformance. We evaluate CAMELL on sequential tasks, with a special emphasis on\ndialogue belief tracking, a task plagued by the constraints of limited and\nnoisy datasets. Our experiments demonstrate that CAMELL outperforms the\nbaselines in terms of efficiency. Furthermore, the data corrections suggested\nby our method contribute to an overall improvement in the quality of the\nresulting datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niekerk_C/0/1/0/all/0/1\">Carel van Niekerk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geishauser_C/0/1/0/all/0/1\">Christian Geishauser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heck_M/0/1/0/all/0/1\">Michael Heck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shutong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hsien-chin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lubis_N/0/1/0/all/0/1\">Nurul Lubis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruppik_B/0/1/0/all/0/1\">Benjamin Ruppik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vukovic_R/0/1/0/all/0/1\">Renato Vukovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1\">Milica Ga&#x161;i&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making Multimodal Generation Easier: When Diffusion Models Meet LLMs. (arXiv:2310.08949v1 [cs.AI])","link":"http://arxiv.org/abs/2310.08949","description":"<p>We present EasyGen, an efficient model designed to enhance multimodal\nunderstanding and generation by harnessing the capabilities of diffusion models\nand large language models (LLMs). Unlike existing multimodal models that\npredominately depend on encoders like CLIP or ImageBind and need ample amounts\nof training data to bridge the gap between modalities, EasyGen is built upon a\nbidirectional conditional diffusion model named BiDiffuser, which promotes more\nefficient interactions between modalities. EasyGen handles image-to-text\ngeneration by integrating BiDiffuser and an LLM via a simple projection layer.\nUnlike most existing multimodal models that are limited to generating text\nresponses, EasyGen can also facilitate text-to-image generation by leveraging\nthe LLM to create textual descriptions, which can be interpreted by BiDiffuser\nto generate appropriate visual responses. Extensive quantitative and\nqualitative experiments demonstrate the effectiveness of EasyGen, whose\ntraining can be easily achieved in a lab setting. The source code is available\nat https://github.com/zxy556677/EasyGen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiangyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qijiong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1\">Guangyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiao-Ming Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Textual Analysis of ICALEPCS and IPAC Conference Proceedings: Revealing Research Trends, Topics, and Collaborations for Future Insights and Advanced Search. (arXiv:2310.08954v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08954","description":"<p>In this paper, we show a textual analysis of past ICALEPCS and IPAC\nconference proceedings to gain insights into the research trends and topics\ndiscussed in the field. We use natural language processing techniques to\nextract meaningful information from the abstracts and papers of past conference\nproceedings. We extract topics to visualize and identify trends, analyze their\nevolution to identify emerging research directions, and highlight interesting\npublications based solely on their content with an analysis of their network.\nAdditionally, we will provide an advanced search tool to better search the\nexisting papers to prevent duplication and easier reference findings. Our\nanalysis provides a comprehensive overview of the research landscape in the\nfield and helps researchers and practitioners to better understand the\nstate-of-the-art and identify areas for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sulc_A/0/1/0/all/0/1\">Antonin Sulc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eichler_A/0/1/0/all/0/1\">Annika Eichler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilksen_T/0/1/0/all/0/1\">Tim Wilksen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"xDial-Eval: A Multilingual Open-Domain Dialogue Evaluation Benchmark. (arXiv:2310.08958v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08958","description":"<p>Recent advancements in reference-free learned metrics for open-domain\ndialogue evaluation have been driven by the progress in pre-trained language\nmodels and the availability of dialogue data with high-quality human\nannotations. However, current studies predominantly concentrate on English\ndialogues, and the generalization of these metrics to other languages has not\nbeen fully examined. This is largely due to the absence of a multilingual\ndialogue evaluation benchmark. To address the issue, we introduce xDial-Eval,\nbuilt on top of open-source English dialogue evaluation datasets. xDial-Eval\nincludes 12 turn-level and 6 dialogue-level English datasets, comprising 14930\nannotated turns and 8691 annotated dialogues respectively. The English dialogue\ndata are extended to nine other languages with commercial machine translation\nsystems. On xDial-Eval, we conduct comprehensive analyses of previous\nBERT-based metrics and the recently-emerged large language models. Lastly, we\nestablish strong self-supervised and multilingual baselines. In terms of\naverage Pearson correlations over all datasets and languages, the best baseline\noutperforms OpenAI's ChatGPT by absolute improvements of 6.5% and 4.6% at the\nturn and dialogue levels respectively, albeit with much fewer parameters. The\ndata and code are publicly available at https://github.com/e0397123/xDial-Eval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1\">Luis Fernando D&#x27;Haro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chengguang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Ke Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1\">Guohua Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Example-Based NMT with Multi-Levenshtein Transformers. (arXiv:2310.08967v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08967","description":"<p>Retrieval-Augmented Machine Translation (RAMT) is attracting growing\nattention. This is because RAMT not only improves translation metrics, but is\nalso assumed to implement some form of domain adaptation. In this contribution,\nwe study another salient trait of RAMT, its ability to make translation\ndecisions more transparent by allowing users to go back to examples that\ncontributed to these decisions.\n</p>\n<p>For this, we propose a novel architecture aiming to increase this\ntransparency. This model adapts a retrieval-augmented version of the\nLevenshtein Transformer and makes it amenable to simultaneously edit multiple\nfuzzy matches found in memory. We discuss how to perform training and inference\nin this model, based on multi-way alignment algorithms and imitation learning.\nOur experiments show that editing several examples positively impacts\ntranslation scores, notably increasing the number of target spans that are\ncopied from existing instances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bouthors_M/0/1/0/all/0/1\">Maxime Bouthors</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crego_J/0/1/0/all/0/1\">Josep Crego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1\">Fran&#xe7;ois Yvon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models. (arXiv:2310.08975v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08975","description":"<p>Knowledge Base Question Answering (KBQA) aims to derive answers to natural\nlanguage questions over large-scale knowledge bases (KBs), which are generally\ndivided into two research components: knowledge retrieval and semantic parsing.\nHowever, three core challenges remain, including inefficient knowledge\nretrieval, retrieval errors adversely affecting semantic parsing, and the\ncomplexity of previous KBQA methods. In the era of large language models\n(LLMs), we introduce ChatKBQA, a novel generate-then-retrieve KBQA framework\nbuilt on fine-tuning open-source LLMs such as Llama-2, ChatGLM2 and Baichuan2.\nChatKBQA proposes generating the logical form with fine-tuned LLMs first, then\nretrieving and replacing entities and relations through an unsupervised\nretrieval method, which improves both generation and retrieval more\nstraightforwardly. Experimental results reveal that ChatKBQA achieves new\nstate-of-the-art performance on standard KBQA datasets, WebQSP, and\nComplexWebQuestions (CWQ). This work also provides a new paradigm for combining\nLLMs with knowledge graphs (KGs) for interpretable and knowledge-required\nquestion answering. Our code is publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haoran Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+E_H/0/1/0/all/0/1\">Haihong E</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zichen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shiyao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yikai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chenghao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Guanting Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Meina Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules. (arXiv:2310.08992v1 [cs.AI])","link":"http://arxiv.org/abs/2310.08992","description":"<p>Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hailin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Amrita Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokul_A/0/1/0/all/0/1\">Akash Gokul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahoo_D/0/1/0/all/0/1\">Doyen Sahoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dont Add, dont Miss: Effective Content Preserving Generation from Pre-Selected Text Spans. (arXiv:2310.09017v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09017","description":"<p>The recently introduced Controlled Text Reduction (CTR) task isolates the\ntext generation step within typical summarization-style tasks. It does so by\nchallenging models to generate coherent text conforming to pre-selected content\nwithin the input text (\"highlights\").\n</p>\n<p>This framing enables increased modularity in summarization-like tasks,\nallowing to couple a single CTR model with various content-selection setups and\nmodules.\n</p>\n<p>However, there are currently no reliable CTR models, while the performance of\nthe existing baseline for the task is mediocre, falling short of practical\nutility.\n</p>\n<p>Here, we address this gap by introducing a high-quality, open-source CTR\nmodel that tackles two prior key limitations: inadequate enforcement of the\ncontent-preservation constraint, and suboptimal silver training data.\n</p>\n<p>Addressing these, we amplify the content-preservation constraint in both\ntraining, via RL, and inference, via a controlled decoding strategy.\n</p>\n<p>Further, we substantially improve the silver training data quality via GPT-4\ndistillation.\n</p>\n<p>Overall, pairing the distilled dataset with the highlight-adherence\nstrategies yields marked gains over the current baseline, of up to 30 ROUGE-L\npoints, providing a reliable CTR model for downstream use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Slobodkin_A/0/1/0/all/0/1\">Aviv Slobodkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_E/0/1/0/all/0/1\">Eran Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-BigBench: Evaluating Multimodal Models on Multimodal Content Comprehension Tasks. (arXiv:2310.09036v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09036","description":"<p>The popularity of multimodal large language models (MLLMs) has triggered a\nrecent surge in research efforts dedicated to evaluating these models.\nNevertheless, existing evaluation studies of MLLMs primarily focus on the\ncomprehension and reasoning of unimodal (vision) content, neglecting\nperformance evaluations in the domain of multimodal (vision-language) content\nunderstanding. Beyond multimodal reasoning, tasks related to multimodal content\ncomprehension necessitate a profound understanding of multimodal contexts,\nachieved through the multimodal interaction to obtain a final answer. In this\npaper, we introduce a comprehensive assessment framework called MM-BigBench,\nwhich incorporates a diverse range of metrics to offer an extensive evaluation\nof the performance of various models and instructions across a wide spectrum of\ndiverse multimodal content comprehension tasks. Consequently, our work\ncomplements research on the performance of MLLMs in multimodal comprehension\ntasks, achieving a more comprehensive and holistic evaluation of MLLMs. To\nbegin, we employ the Best Performance metric to ascertain each model's\nperformance upper bound on different datasets. Subsequently, the Mean Relative\nGain metric offers an assessment of the overall performance of various models\nand instructions, while the Stability metric measures their sensitivity.\nFurthermore, previous research centers on evaluating models independently or\nsolely assessing instructions, neglecting the adaptability between models and\ninstructions. We propose the Adaptability metric to quantify the adaptability\nbetween models and instructions. Our paper evaluates a total of 20 language\nmodels (14 MLLMs) on 14 multimodal datasets spanning 6 tasks, with 10\ninstructions for each task, and derives novel insights. Our code will be\nreleased at https://github.com/declare-lab/MM-BigBench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaocui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenfang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Ming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Daling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xiaoming Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection. (arXiv:2310.09044v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09044","description":"<p>Large Language Models (LLMs) have demonstrated remarkable human-level natural\nlanguage generation capabilities. However, their potential to generate\nmisinformation, often called the hallucination problem, poses a significant\nrisk to their deployment. A common approach to address this issue is to\nretrieve relevant knowledge and fine-tune the LLM with the knowledge in its\ninput. Unfortunately, this method incurs high training costs and may cause\ncatastrophic forgetting for multi-tasking models. To overcome these\nlimitations, we propose a knowledge-constrained decoding method called KCTS\n(Knowledge-Constrained Tree Search), which guides a frozen LM to generate text\naligned with the reference knowledge at each decoding step using a knowledge\nclassifier score and MCTS (Monte-Carlo Tree Search). To adapt the\nsequence-level knowledge classifier to token-level guidance, we also propose a\nnovel token-level hallucination detection method called RIPA (Reward Inflection\nPoint Approximation). Our empirical results on knowledge-grounded dialogue and\nabstractive summarization demonstrate the strength of KCTS as a plug-and-play,\nmodel-agnostic decoding method that can effectively reduce hallucinations in\nnatural language generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sehyun Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialect Transfer for Swiss German Speech Translation. (arXiv:2310.09088v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09088","description":"<p>This paper investigates the challenges in building Swiss German speech\ntranslation systems, specifically focusing on the impact of dialect diversity\nand differences between Swiss German and Standard German. Swiss German is a\nspoken language with no formal writing system, it comprises many diverse\ndialects and is a low-resource language with only around 5 million speakers.\nThe study is guided by two key research questions: how does the inclusion and\nexclusion of dialects during the training of speech translation models for\nSwiss German impact the performance on specific dialects, and how do the\ndifferences between Swiss German and Standard German impact the performance of\nthe systems? We show that dialect diversity and linguistic differences pose\nsignificant challenges to Swiss German speech translation, which is in line\nwith linguistic hypotheses derived from empirical investigations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paonessa_C/0/1/0/all/0/1\">Claudio Paonessa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schraner_Y/0/1/0/all/0/1\">Yanick Schraner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deriu_J/0/1/0/all/0/1\">Jan Deriu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hurlimann_M/0/1/0/all/0/1\">Manuela H&#xfc;rlimann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vogel_M/0/1/0/all/0/1\">Manfred Vogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cieliebak_M/0/1/0/all/0/1\">Mark Cieliebak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large Language Model. (arXiv:2310.09089v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09089","description":"<p>Integrating large language models (LLMs) into healthcare presents potential\nbut faces challenges. Directly pre-training LLMs for domains like medicine is\nresource-heavy and sometimes unfeasible. Sole reliance on Supervised\nFine-tuning (SFT) can result in overconfident predictions and may not tap into\ndomain specific insights. Addressing these challenges, we present a multi-stage\ntraining method combining Domain-specific Continued Pre-training (DCPT), SFT,\nand Direct Preference Optimization (DPO). A notable contribution of our study\nis the introduction of a 3Gb Chinese Medicine (ChiMed) dataset, encompassing\nmedical question answering, plain texts, knowledge graphs, and dialogues,\nsegmented into three training stages. The medical LLM trained with our\npipeline, Qilin-Med, exhibits significant performance boosts. In the CPT and\nSFT phases, it achieves 38.4% and 40.0% accuracy on the CMExam, surpassing\nBaichuan-7B's 33.5%. In the DPO phase, on the Huatuo-26M test set, it scores\n16.66 in BLEU-1 and 27.44 in ROUGE1, outperforming the SFT's 12.69 and 24.21.\nThis highlights the strength of our training approach in refining LLMs for\nmedical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qichen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junling Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_D/0/1/0/all/0/1\">Dading Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peilin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yining Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Andrew Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GLoRE: Evaluating Logical Reasoning of Large Language Models. (arXiv:2310.09107v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09107","description":"<p>Recently, large language models (LLMs), including notable models such as\nGPT-4 and burgeoning community models, have showcased significant general\nlanguage understanding abilities. However, there has been a scarcity of\nattempts to assess the logical reasoning capacities of these LLMs, an essential\nfacet of natural language understanding. To encourage further investigation in\nthis area, we introduce GLoRE, a meticulously assembled General Logical\nReasoning Evaluation benchmark comprised of 12 datasets that span three\ndifferent types of tasks. Our experimental results show that compared to the\nperformance of human and supervised fine-tuning, the logical reasoning\ncapabilities of open LLM models necessitate additional improvement; ChatGPT and\nGPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing\nChatGPT by a large margin. We propose a self-consistency probing method to\nenhance the accuracy of ChatGPT and a fine-tuned method to boost the\nperformance of an open LLM. We release the datasets and evaluation programs to\nfacilitate future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+liu_H/0/1/0/all/0/1\">Hanmeng liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1\">Zhiyang Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_R/0/1/0/all/0/1\">Ruoxi Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qiji Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Frustratingly Easy Plug-and-Play Detection-and-Reasoning Module for Chinese Spelling Check. (arXiv:2310.09119v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09119","description":"<p>In recent years, Chinese Spelling Check (CSC) has been greatly improved by\ndesigning task-specific pre-training methods or introducing auxiliary tasks,\nwhich mostly solve this task in an end-to-end fashion. In this paper, we\npropose to decompose the CSC workflow into detection, reasoning, and searching\nsubtasks so that the rich external knowledge about the Chinese language can be\nleveraged more directly and efficiently. Specifically, we design a\nplug-and-play detection-and-reasoning module that is compatible with existing\nSOTA non-autoregressive CSC models to further boost their performance. We find\nthat the detection-and-reasoning module trained for one model can also benefit\nother models. We also study the primary interpretability provided by the task\ndecomposition. Extensive experiments and detailed analyses demonstrate the\neffectiveness and competitiveness of the proposed module.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haojing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jingheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling. (arXiv:2310.09135v1 [cs.AI])","link":"http://arxiv.org/abs/2310.09135","description":"<p>In task-oriented dialogue scenarios, cross-domain zero-shot slot filling\nplays a vital role in leveraging source domain knowledge to learn a model with\nhigh generalization ability in unknown target domain where annotated data is\nunavailable. However, the existing state-of-the-art zero-shot slot filling\nmethods have limited generalization ability in target domain, they only show\neffective knowledge transfer on seen slots and perform poorly on unseen slots.\nTo alleviate this issue, we present a novel Hierarchical Contrastive Learning\nFramework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse-\nto fine-grained contrastive learning based on Gaussian-distributed embedding to\nlearn the generalized deep semantic relations between utterance-tokens, by\noptimizing inter- and intra-token distribution distance. This encourages HiCL\nto generalize to the slot types unseen at training phase. Furthermore, we\npresent a new iterative label set semantics inference method to unbiasedly and\nseparately evaluate the performance of unseen slot types which entangled with\ntheir counterparts (i.e., seen slot types) in the previous zero-shot slot\nfilling evaluation methods. The extensive empirical experiments on four\ndatasets demonstrate that the proposed method achieves comparable or even\nbetter performance than the current state-of-the-art zero-shot slot filling\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Consensus Game: Language Model Generation via Equilibrium Search. (arXiv:2310.09139v1 [cs.GT])","link":"http://arxiv.org/abs/2310.09139","description":"<p>When applied to question answering and other text generation tasks, language\nmodels (LMs) may be queried generatively (by sampling answers from their output\ndistribution) or discriminatively (by using them to score or rank a set of\ncandidate outputs). These procedures sometimes yield very different\npredictions. How do we reconcile mutually incompatible scoring procedures to\nobtain coherent LM predictions? We introduce a new, a training-free,\ngame-theoretic procedure for language model decoding. Our approach casts\nlanguage model decoding as a regularized imperfect-information sequential\nsignaling game - which we term the CONSENSUS GAME - in which a GENERATOR seeks\nto communicate an abstract correctness parameter using natural language\nsentences to a DISCRIMINATOR. We develop computational procedures for finding\napproximate equilibria of this game, resulting in a decoding algorithm we call\nEQUILIBRIUM-RANKING. Applied to a large number of tasks (including reading\ncomprehension, commonsense reasoning, mathematical problem-solving, and\ndialog), EQUILIBRIUM-RANKING consistently, and sometimes substantially,\nimproves performance over existing LM decoding procedures - on multiple\nbenchmarks, we observe that applying EQUILIBRIUM-RANKING to LLaMA-7B\noutperforms the much larger LLaMA-65B and PaLM-540B models. These results\nhighlight the promise of game-theoretic tools for addressing fundamental\nchallenges of truthfulness and consistency in LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacob_A/0/1/0/all/0/1\">Athul Paul Jacob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yikang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farina_G/0/1/0/all/0/1\">Gabriele Farina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PuoBERTa: Training and evaluation of a curated language model for Setswana. (arXiv:2310.09141v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09141","description":"<p>Natural language processing (NLP) has made significant progress for\nwell-resourced languages such as English but lagged behind for low-resource\nlanguages like Setswana. This paper addresses this gap by presenting PuoBERTa,\na customised masked language model trained specifically for Setswana. We cover\nhow we collected, curated, and prepared diverse monolingual texts to generate a\nhigh-quality corpus for PuoBERTa's training. Building upon previous efforts in\ncreating monolingual resources for Setswana, we evaluated PuoBERTa across\nseveral NLP tasks, including part-of-speech (POS) tagging, named entity\nrecognition (NER), and news categorisation. Additionally, we introduced a new\nSetswana news categorisation dataset and provided the initial benchmarks using\nPuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP\ncapabilities for understudied languages like Setswana and paves the way for\nfuture research directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1\">Vukosi Marivate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MotsOehli_M/0/1/0/all/0/1\">Moseli Mots&#x27;Oehli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_V/0/1/0/all/0/1\">Valencia Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lastrucci_R/0/1/0/all/0/1\">Richard Lastrucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dzingirai_I/0/1/0/all/0/1\">Isheanesu Dzingirai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BibRank: Automatic Keyphrase Extraction Platform Using~Metadata. (arXiv:2310.09151v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09151","description":"<p>Automatic Keyphrase Extraction involves identifying essential phrases in a\ndocument. These keyphrases are crucial in various tasks such as document\nclassification, clustering, recommendation, indexing, searching, summarization,\nand text simplification. This paper introduces a platform that integrates\nkeyphrase datasets and facilitates the evaluation of keyphrase extraction\nalgorithms. The platform includes BibRank, an automatic keyphrase extraction\nalgorithm that leverages a rich dataset obtained by parsing bibliographic data\nin BibTeX format. BibRank combines innovative weighting techniques with\npositional, statistical, and word co-occurrence information to extract\nkeyphrases from documents. The platform proves valuable for researchers and\ndevelopers seeking to enhance their keyphrase extraction algorithms and advance\nthe field of natural language processing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eldallal_A/0/1/0/all/0/1\">Abdelrhman Eldallal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbu_E/0/1/0/all/0/1\">Eduard Barbu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Developing a Natural Language Understanding Model to Characterize Cable News Bias. (arXiv:2310.09166v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09166","description":"<p>Media bias has been extensively studied by both social and computational\nsciences. However, current work still has a large reliance on human input and\nsubjective assessment to label biases. This is especially true for cable news\nresearch. To address these issues, we develop an unsupervised machine learning\nmethod to characterize the bias of cable news programs without any human input.\nThis method relies on the analysis of what topics are mentioned through Named\nEntity Recognition and how those topics are discussed through Stance Analysis\nin order to cluster programs with similar biases together. Applying our method\nto 2020 cable news transcripts, we find that program clusters are consistent\nover time and roughly correspond to the cable news network of the program. This\nmethod reveals the potential for future tools to objectively assess media bias\nand characterize unfamiliar media environments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Benson_S/0/1/0/all/0/1\">Seth P. Benson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruickshank_I/0/1/0/all/0/1\">Iain J. Cruickshank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration. (arXiv:2310.09168v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09168","description":"<p>Instruction-tuning can be substantially optimized through enhanced diversity,\nresulting in models capable of handling a broader spectrum of tasks. However,\nexisting data employed for such tuning often exhibit an inadequate coverage of\nindividual domains, limiting the scope for nuanced comprehension and\ninteractions within these areas. To address this deficiency, we propose\nExplore-Instruct, a novel approach to enhance the data coverage to be used in\ndomain-specific instruction-tuning through active exploration via Large\nLanguage Models (LLMs). Built upon representative domain use cases,\nExplore-Instruct explores a multitude of variations or possibilities by\nimplementing a search algorithm to obtain diversified and domain-focused\ninstruction-tuning data. Our data-centric analysis validates the effectiveness\nof this proposed approach in improving domain-specific instruction coverage.\nMoreover, our model's performance demonstrates considerable advancements over\nmultiple baselines, including those utilizing domain-specific data enhancement.\nOur findings offer a promising opportunity to improve instruction coverage,\nespecially in domain-specific contexts, thereby advancing the development of\nadaptable language models. Our code, model weights, and data are public at\n\\url{https://github.com/fanqiwan/Explore-Instruct}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xinting Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Kelly is a Warm Person, Joseph is a Role Model\": Gender Biases in LLM-Generated Reference Letters. (arXiv:2310.09219v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09219","description":"<p>As generative language models advance, users have started to utilize Large\nLanguage Models (LLMs) to assist in writing various types of content, including\nprofessional documents such as recommendation letters. Despite their\nconvenience, these applications introduce unprecedented fairness concerns. As\ngenerated reference letters might be directly utilized by users in professional\nor academic scenarios, they have the potential to cause direct social harms,\nsuch as lowering success rates for female applicants. Therefore, it is imminent\nand necessary to comprehensively study fairness issues and associated harms in\nsuch real-world use cases for future mitigation and monitoring. In this paper,\nwe critically examine gender bias in LLM-generated reference letters. Inspired\nby findings in social science, we design evaluation methods to manifest gender\nbiases in LLM-generated letters through 2 dimensions: biases in language style\nand biases in lexical content. Furthermore, we investigate the extent of bias\npropagation by separately analyze bias amplification in model-hallucinated\ncontents, which we define to be the hallucination bias of model-generated\ndocuments. Through benchmarking evaluation on 4 popular LLMs, including\nChatGPT, Alpaca, Vicuna and StableLM, our study reveals significant gender\nbiases in LLM-generated recommendation letters. Our findings further point\ntowards the importance and imminence to recognize biases in LLM-generated\nprofessional documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yixin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_G/0/1/0/all/0/1\">George Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_A/0/1/0/all/0/1\">Aparna Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Claim Matching with Large Language Models: Empowering Fact-Checkers in the Fight Against Misinformation. (arXiv:2310.09223v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09223","description":"<p>In today's digital era, the rapid spread of misinformation poses threats to\npublic well-being and societal trust. As online misinformation proliferates,\nmanual verification by fact checkers becomes increasingly challenging. We\nintroduce FACT-GPT (Fact-checking Augmentation with Claim matching\nTask-oriented Generative Pre-trained Transformer), a framework designed to\nautomate the claim matching phase of fact-checking using Large Language Models\n(LLMs). This framework identifies new social media content that either supports\nor contradicts claims previously debunked by fact-checkers. Our approach\nemploys GPT-4 to generate a labeled dataset consisting of simulated social\nmedia posts. This data set serves as a training ground for fine-tuning more\nspecialized LLMs. We evaluated FACT-GPT on an extensive dataset of social media\ncontent related to public health. The results indicate that our fine-tuned LLMs\nrival the performance of larger pre-trained LLMs in claim matching tasks,\naligning closely with human annotations. This study achieves three key\nmilestones: it provides an automated framework for enhanced fact-checking;\ndemonstrates the potential of LLMs to complement human expertise; offers public\nresources, including datasets and models, to further research and applications\nin the fact-checking domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eun Cheol Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1\">Emilio Ferrara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AgentCF: Collaborative Learning with Autonomous Language Agents for Recommender Systems. (arXiv:2310.09233v1 [cs.IR])","link":"http://arxiv.org/abs/2310.09233","description":"<p>Recently, there has been an emergence of employing LLM-powered agents as\nbelievable human proxies, based on their remarkable decision-making capability.\nHowever, existing studies mainly focus on simulating human dialogue. Human\nnon-verbal behaviors, such as item clicking in recommender systems, although\nimplicitly exhibiting user preferences and could enhance the modeling of users,\nhave not been deeply explored. The main reasons lie in the gap between language\nmodeling and behavior modeling, as well as the incomprehension of LLMs about\nuser-item relations.\n</p>\n<p>To address this issue, we propose AgentCF for simulating user-item\ninteractions in recommender systems through agent-based collaborative\nfiltering. We creatively consider not only users but also items as agents, and\ndevelop a collaborative learning approach that optimizes both kinds of agents\ntogether. Specifically, at each time step, we first prompt the user and item\nagents to interact autonomously. Then, based on the disparities between the\nagents' decisions and real-world interaction records, user and item agents are\nprompted to reflect on and adjust the misleading simulations collaboratively,\nthereby modeling their two-sided relations. The optimized agents can also\npropagate their preferences to other agents in subsequent interactions,\nimplicitly capturing the collaborative filtering idea. Overall, the optimized\nagents exhibit diverse interaction behaviors within our framework, including\nuser-item, user-user, item-item, and collective interactions. The results show\nthat these agents can demonstrate personalized behaviors akin to those of\nreal-world individuals, sparking the development of next-generation user\nbehavior simulation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yupeng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wenqi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Leyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models for Sentiment Analysis of Bangla Social Media Posts. (arXiv:2310.09238v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09238","description":"<p>Bangla is the 7th most widely spoken language globally, with a staggering 234\nmillion native speakers primarily hailing from India and Bangladesh. This\nmorphologically rich language boasts a rich literary tradition, encompassing\ndiverse dialects and language-specific challenges. Despite its linguistic\nrichness and history, Bangla remains categorized as a low-resource language\nwithin the natural language processing (NLP) and speech community. This paper\npresents our submission to Task 2 (Sentiment Analysis of Bangla Social Media\nPosts) of the BLP Workshop. We experiment with various Transformer-based\narchitectures to solve this task. Our quantitative results show that transfer\nlearning really helps in better learning of the models in this low-resource\nlanguage scenario. This becomes evident when we further finetune a model which\nhas already been finetuned on twitter data for sentiment analysis task and that\nfinetuned model performs the best among all other models. We also perform a\ndetailed error analysis where we find some instances where ground truth labels\nneed to be relooked at. We obtain a micro-F1 of 67.02\\% on the test set and our\nperformance in this shared task is ranked at 21 in the leaderboard.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Saumajit Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanda_A/0/1/0/all/0/1\">Albert Nanda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model Collaboration. (arXiv:2310.09241v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09241","description":"<p>Legal Judgment Prediction (LJP) has become an increasingly crucial task in\nLegal AI, i.e., predicting the judgment of the case in terms of case fact\ndescription. Precedents are the previous legal cases with similar facts, which\nare the basis for the judgment of the subsequent case in national legal\nsystems. Thus, it is worthwhile to explore the utilization of precedents in the\nLJP. Recent advances in deep learning have enabled a variety of techniques to\nbe used to solve the LJP task. These can be broken down into two categories:\nlarge language models (LLMs) and domain-specific models. LLMs are capable of\ninterpreting and generating complex natural language, while domain models are\nefficient in learning task-specific information. In this paper, we propose the\nprecedent-enhanced LJP framework (PLJP), a system that leverages the strength\nof both LLM and domain models in the context of precedents. Specifically, the\ndomain models are designed to provide candidate labels and find the proper\nprecedents efficiently, and the large models will make the final prediction\nwith an in-context precedents comprehension. Experiments on the real-world\ndataset demonstrate the effectiveness of our PLJP. Moreover, our work shows a\npromising direction for LLM and domain-model collaboration that can be\ngeneralized to other vertical domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yiquan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Siying Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yifei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weiming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yating Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Changlong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1\">Kun Kuang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet Hierarchy. (arXiv:2310.09247v1 [cs.CV])","link":"http://arxiv.org/abs/2310.09247","description":"<p>Text-to-image synthesis has recently attracted widespread attention due to\nrapidly improving quality and numerous practical applications. However, the\nlanguage understanding capabilities of text-to-image models are still poorly\nunderstood, which makes it difficult to reason about prompt formulations that a\ngiven model would understand well. In this work, we measure the capability of\npopular text-to-image models to understand $\\textit{hypernymy}$, or the \"is-a\"\nrelation between words. We design two automatic metrics based on the WordNet\nsemantic hierarchy and existing image classifiers pretrained on ImageNet. These\nmetrics both enable broad quantitative comparison of linguistic capabilities\nfor text-to-image models and offer a way of finding fine-grained qualitative\ndifferences, such as words that are unknown to models and thus are difficult\nfor them to draw. We comprehensively evaluate popular text-to-image models,\nincluding GLIDE, Latent Diffusion, and Stable Diffusion, showing how our\nmetrics can provide a better understanding of the individual strengths and\nweaknesses of these models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baryshnikov_A/0/1/0/all/0/1\">Anton Baryshnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryabinin_M/0/1/0/all/0/1\">Max Ryabinin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Political claim identification and categorization in a multilingual setting: First experiments. (arXiv:2310.09256v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09256","description":"<p>The identification and classification of political claims is an important\nstep in the analysis of political newspaper reports; however, resources for\nthis task are few and far between. This paper explores different strategies for\nthe cross-lingual projection of political claims analysis. We conduct\nexperiments on a German dataset, DebateNet2.0, covering the policy debate\nsparked by the 2015 refugee crisis. Our evaluation involves two tasks (claim\nidentification and categorization), three languages (German, English, and\nFrench) and two methods (machine translation -- the best method in our\nexperiments -- and multilingual embeddings).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zaberer_U/0/1/0/all/0/1\">Urs Zaberer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pado_S/0/1/0/all/0/1\">Sebastian Pad&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapesa_G/0/1/0/all/0/1\">Gabriella Lapesa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Table-GPT: Table-tuned GPT for Diverse Table Tasks. (arXiv:2310.09263v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09263","description":"<p>Language models, such as GPT-3.5 and ChatGPT, demonstrate remarkable\nabilities to follow diverse human instructions and perform a wide range of\ntasks. However, when probing language models using a range of basic\ntable-understanding tasks, we observe that today's language models are still\nsub-optimal in many table-related tasks, likely because they are pre-trained\npredominantly on \\emph{one-dimensional} natural-language texts, whereas\nrelational tables are \\emph{two-dimensional} objects.\n</p>\n<p>In this work, we propose a new \"\\emph{table-tuning}\" paradigm, where we\ncontinue to train/fine-tune language models like GPT-3.5 and ChatGPT, using\ndiverse table-tasks synthesized from real tables as training data, with the\ngoal of enhancing language models' ability to understand tables and perform\ntable tasks. We show that our resulting Table-GPT models demonstrate (1) better\n\\emph{table-understanding} capabilities, by consistently outperforming the\nvanilla GPT-3.5 and ChatGPT, on a wide-range of table tasks, including holdout\nunseen tasks, and (2) strong \\emph{generalizability}, in its ability to respond\nto diverse human instructions to perform new table-tasks, in a manner similar\nto GPT-3.5 and ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yeye He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yashar_D/0/1/0/all/0/1\">Dror Yashar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Weiwei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Song Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haidong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fainman_D/0/1/0/all/0/1\">Danielle Rifinski Fainman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1\">Surajit Chaudhuri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptRE: Weakly-Supervised Document-Level Relation Extraction via Prompting-Based Data Programming. (arXiv:2310.09265v1 [cs.CL])","link":"http://arxiv.org/abs/2310.09265","description":"<p>Relation extraction aims to classify the relationships between two entities\ninto pre-defined categories. While previous research has mainly focused on\nsentence-level relation extraction, recent studies have expanded the scope to\ndocument-level relation extraction. Traditional relation extraction methods\nheavily rely on human-annotated training data, which is time-consuming and\nlabor-intensive. To mitigate the need for manual annotation, recent\nweakly-supervised approaches have been developed for sentence-level relation\nextraction while limited work has been done on document-level relation\nextraction. Weakly-supervised document-level relation extraction faces\nsignificant challenges due to an imbalanced number \"no relation\" instances and\nthe failure of directly probing pretrained large language models for document\nrelation extraction. To address these challenges, we propose PromptRE, a novel\nweakly-supervised document-level relation extraction method that combines\nprompting-based techniques with data programming. Furthermore, PromptRE\nincorporates the label distribution and entity types as prior knowledge to\nimprove the performance. By leveraging the strengths of both prompting and data\nprogramming, PromptRE achieves improved performance in relation classification\nand effectively handles the \"no relation\" problem. Experimental results on\nReDocRED, a benchmark dataset for document-level relation extraction,\ndemonstrate the superiority of PromptRE over baseline approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chufan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xulin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"User Inference Attacks on Large Language Models. (arXiv:2310.09266v1 [cs.CR])","link":"http://arxiv.org/abs/2310.09266","description":"<p>Fine-tuning is a common and effective method for tailoring large language\nmodels (LLMs) to specialized tasks and applications. In this paper, we study\nthe privacy implications of fine-tuning LLMs on user data. To this end, we\ndefine a realistic threat model, called user inference, wherein an attacker\ninfers whether or not a user's data was used for fine-tuning. We implement\nattacks for this threat model that require only a small set of samples from a\nuser (possibly different from the samples used for training) and black-box\naccess to the fine-tuned LLM. We find that LLMs are susceptible to user\ninference attacks across a variety of fine-tuning datasets, at times with near\nperfect attack success rates. Further, we investigate which properties make\nusers vulnerable to user inference, finding that outlier users (i.e. those with\ndata distributions sufficiently different from other users) and users who\ncontribute large quantities of data are most susceptible to attack. Finally, we\nexplore several heuristics for mitigating privacy attacks. We find that\ninterventions in the training algorithm, such as batch or per-example gradient\nclipping and early stopping fail to prevent user inference. However, limiting\nthe number of fine-tuning samples from a single user can reduce attack\neffectiveness, albeit at the cost of reducing the total amount of fine-tuning\ndata.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kandpal_N/0/1/0/all/0/1\">Nikhil Kandpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1\">Alina Oprea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1\">Peter Kairouz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choquette_Choo_C/0/1/0/all/0/1\">Christopher A. Choquette-Choo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zheng Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stylized innovation: generating timelines by interrogating incrementally available randomised dictionaries. (arXiv:1806.07722v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/1806.07722","description":"<p>A key challenge when trying to understand innovation is that it is a dynamic,\nongoing process, which can be highly contingent on ephemeral factors such as\nculture, economics, or luck. This means that any analysis of the real-world\nprocess must necessarily be historical - and thus probably too late to be most\nuseful - but also cannot be sure what the properties of the web of connections\nbetween innovations is or was. Here I try to address this by designing and\ngenerating a set of synthetic innovation web \"dictionaries\" that can be used to\nhost sampled innovation timelines, probe the overall statistics and behaviours\nof these processes, and determine the degree of their reliance on the structure\nor generating algorithm. Thus, inspired by the work of Fink, Reeves, Palma and\nFarr (2017) on innovation in language, gastronomy, and technology, I study how\nnew symbol discovery manifests itself in terms of additional \"word\" vocabulary\nbeing available from dictionaries generated from a finite number of symbols.\nSeveral distinct dictionary generation models are investigated using numerical\nsimulation, with emphasis on the scaling of knowledge as dictionary generators\nand parameters are varied, and the role of which order the symbols are\ndiscovered in.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kinsler_P/0/1/0/all/0/1\">Paul Kinsler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What should I Ask: A Knowledge-driven Approach for Follow-up Questions Generation in Conversational Surveys. (arXiv:2205.10977v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.10977","description":"<p>Generating follow-up questions on the fly could significantly improve\nconversational survey quality and user experiences by enabling a more dynamic\nand personalized survey structure. In this paper, we proposed a novel task for\nknowledge-driven follow-up question generation in conversational surveys. We\nconstructed a new human-annotated dataset of human-written follow-up questions\nwith dialogue history and labeled knowledge in the context of conversational\nsurveys. Along with the dataset, we designed and validated a set of\nreference-free Gricean-inspired evaluation metrics to systematically evaluate\nthe quality of generated follow-up questions. We then propose a two-staged\nknowledge-driven model for the task, which generates informative and coherent\nfollow-up questions by using knowledge to steer the generation process. The\nexperiments demonstrate that compared to GPT-based baseline models, our\ntwo-staged model generates more informative, coherent, and clear follow-up\nquestions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yubin Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Ziang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diesner_J/0/1/0/all/0/1\">Jana Diesner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karahalios_K/0/1/0/all/0/1\">Karrie Karahalios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_H/0/1/0/all/0/1\">Hari Sundaram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficiently Enhancing Zero-Shot Performance of Instruction Following Model via Retrieval of Soft Prompt. (arXiv:2210.03029v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03029","description":"<p>Enhancing the zero-shot performance of instruction-following models requires\nheavy computation, either by scaling the total number of training datasets or\nthe model size. In this work, we explore how retrieval of soft prompts obtained\nthrough prompt tuning can efficiently assist hard prompts in zero-shot task\ngeneralization. Specifically, we train soft prompt embeddings for each prompt\nthrough prompt tuning, store the samples of the training instances mapped with\nthe prompt embeddings, and retrieve the corresponding prompt embedding of the\ntraining instance closest to the query instance during inference. While only\nadding 0.007% additional parameters, retrieval of soft prompt enhances the\nperformance of T0 on unseen tasks by outperforming it on 10 out of 11 datasets\nas well as improving the mean accuracy of T0 on BIG-bench benchmark by 2.39%\npoints. Also, we report an interesting finding that retrieving source\nembeddings trained on similar answer choice formats is more important than\nthose on similar task types.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1\">Seonghyeon Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Joel Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Doyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yongrae Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NAPG: Non-Autoregressive Program Generation for Hybrid Tabular-Textual Question Answering. (arXiv:2211.03462v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.03462","description":"<p>Hybrid tabular-textual question answering (QA) requires reasoning from\nheterogeneous information, and the types of reasoning are mainly divided into\nnumerical reasoning and span extraction. Current numerical reasoning methods\nautoregressively decode program sequences, and each decoding step produces\neither an operator or an operand. However, the step-by-step decoding suffers\nfrom exposure bias, and the accuracy of program generation drops sharply as the\ndecoding steps unfold due to error propagation. In this paper, we propose a\nnon-autoregressive program generation framework, which independently generates\ncomplete program tuples containing both operators and operands, can address the\nerror propagation issue while significantly boosting the speed of program\ngeneration. Experiments on the ConvFinQA and MultiHiertt datasets show that our\nnon-autoregressive program generation method can bring about substantial\nimprovements over the strong FinQANet (+5.06 Exe Acc and +4.80 Prog Acc points)\nand MT2Net (+7.97 EM and +6.38 F1 points) baselines, establishing the new\nstate-of-the-art performance, while being much faster (21x) in program\ngeneration. Finally, with increasing numbers of numerical reasoning steps the\nperformance drop of our method is significantly smaller than that of the\nbaselines. Our code will be publicly available soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tengxun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hongfei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genabith_J/0/1/0/all/0/1\">Josef van Genabith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_H/0/1/0/all/0/1\">Hongying Zan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dataless Knowledge Fusion by Merging Weights of Language Models. (arXiv:2212.09849v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09849","description":"<p>Fine-tuning pre-trained language models has become the prevalent paradigm for\nbuilding downstream NLP models. Oftentimes fine-tuned models are readily\navailable but their training data is not, due to data privacy or intellectual\nproperty concerns. This creates a barrier to fusing knowledge across individual\nmodels to yield a better single model. In this paper, we study the problem of\nmerging individual models built on different training data sets to obtain a\nsingle model that performs well both across all data set domains and can\ngeneralize on out-of-domain data. We propose a dataless knowledge fusion method\nthat merges models in their parameter space, guided by weights that minimize\nprediction differences between the merged model and the individual models. Over\na battery of evaluation settings, we show that the proposed method\nsignificantly outperforms baselines such as Fisher-weighted averaging or model\nensembling. Further, we find that our method is a promising alternative to\nmulti-task learning that can preserve or sometimes improve over the individual\nmodels without access to the training data. Finally, model merging is more\nefficient than training a multi-task model, thus making it applicable to a\nwider set of scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xisen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preotiuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pengxiang Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge is a Region in Weight Space for Fine-tuned Language Models. (arXiv:2302.04863v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.04863","description":"<p>Research on neural networks has focused on understanding a single model\ntrained on a single dataset. However, relatively little is known about the\nrelationships between different models, particularly those trained or tested on\ndifferent datasets. We address this by studying how the weight space and the\nunderlying loss landscape of different models are interconnected.\n</p>\n<p>Specifically, we demonstrate that finetuned models that were optimized for\nhigh performance, reside in well-defined regions in weight space, and vice\nversa -- that any model that resides anywhere in those regions also exhibits\nhigh performance. Notably, we show that language models that have been\nfinetuned on the same dataset form a tight cluster in the weight space, while\nmodels finetuned on different datasets from the same underlying task form a\nlooser cluster. Moreover, traversing around the region between the models leads\nto new models that perform comparably or even better than models obtained via\nfinetuning, even on tasks that the original models were not finetuned on.\n</p>\n<p>Our findings provide insight into the relationships between models,\ndemonstrating that a model positioned between two similar models can acquire\nthe knowledge of both. We leverage this and design a method for selecting a\nbetter model for efficient finetuning. Specifically, we show that starting from\nthe center of the region is as effective, if not more, than using the\npretrained model in 11 out of 12 datasets, resulting in an average accuracy\nimprovement of 3.06.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gueta_A/0/1/0/all/0/1\">Almog Gueta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venezian_E/0/1/0/all/0/1\">Elad Venezian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading Comprehension. (arXiv:2302.13619v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.13619","description":"<p>The conversational machine reading comprehension (CMRC) task aims to answer\nquestions in conversations, which has been a hot research topic in recent years\nbecause of its wide applications. However, existing CMRC benchmarks in which\neach conversation is assigned a static passage are inconsistent with real\nscenarios. Thus, model's comprehension ability towards real scenarios are hard\nto evaluate reasonably. To this end, we propose the first Chinese CMRC\nbenchmark Orca and further provide zero-shot/few-shot settings to evaluate\nmodel's generalization ability towards diverse domains. We collect 831\nhot-topic driven conversations with 4,742 turns in total. Each turn of a\nconversation is assigned with a response-related passage, aiming to evaluate\nmodel's comprehension ability more reasonably. The topics of conversations are\ncollected from social media platform and cover 33 domains, trying to be\nconsistent with real scenarios. Importantly, answers in Orca are all\nwell-annotated natural responses rather than the specific spans or short phrase\nin previous datasets. Besides, we implement three strong baselines to tackle\nthe challenge in Orca. The results indicate the great challenge of our CMRC\nbenchmark. Our datatset and checkpoints are available at\nhttps://github.com/nuochenpku/Orca.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongguang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junqing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yinan Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xinshi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jianfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Baoyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers. (arXiv:2303.00807v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2303.00807","description":"<p>Many information retrieval tasks require large labeled datasets for\nfine-tuning. However, such datasets are often unavailable, and their utility\nfor real-world applications can diminish quickly due to domain shifts. To\naddress this challenge, we develop and motivate a method for using large\nlanguage models (LLMs) to generate large numbers of synthetic queries cheaply.\nThe method begins by generating a small number of synthetic queries using an\nexpensive LLM. After that, a much less expensive one is used to create large\nnumbers of synthetic queries, which are used to fine-tune a family of reranker\nmodels. These rerankers are then distilled into a single efficient retriever\nfor use in the target domain. We show that this technique boosts zero-shot\naccuracy in long-tail domains and achieves substantially lower latency than\nstandard reranking methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saad_Falcon_J/0/1/0/all/0/1\">Jon Saad-Falcon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1\">Omar Khattab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santhanam_K/0/1/0/all/0/1\">Keshav Santhanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florian_R/0/1/0/all/0/1\">Radu Florian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franz_M/0/1/0/all/0/1\">Martin Franz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sil_A/0/1/0/all/0/1\">Avirup Sil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1\">Md Arafat Sultan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Assess Human Personalities? A General Evaluation Framework. (arXiv:2303.01248v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.01248","description":"<p>Large Language Models (LLMs) especially ChatGPT have produced impressive\nresults in various areas, but their potential human-like psychology is still\nlargely unexplored. Existing works study the virtual personalities of LLMs but\nrarely explore the possibility of analyzing human personalities via LLMs. This\npaper presents a generic evaluation framework for LLMs to assess human\npersonalities based on Myers Briggs Type Indicator (MBTI) tests. Specifically,\nwe first devise unbiased prompts by randomly permuting options in MBTI\nquestions and adopt the average testing result to encourage more impartial\nanswer generation. Then, we propose to replace the subject in question\nstatements to enable flexible queries and assessments on different subjects\nfrom LLMs. Finally, we re-formulate the question instructions in a manner of\ncorrectness evaluation to facilitate LLMs to generate clearer responses. The\nproposed framework enables LLMs to flexibly assess personalities of different\ngroups of people. We further propose three evaluation metrics to measure the\nconsistency, robustness, and fairness of assessment results from\nstate-of-the-art LLMs including ChatGPT and GPT-4. Our experiments reveal\nChatGPT's ability to assess human personalities, and the average results\ndemonstrate that it can achieve more consistent and fairer assessments in spite\nof lower robustness against prompt biases compared with InstructGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rao_H/0/1/0/all/0/1\">Haocong Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leung_C/0/1/0/all/0/1\">Cyril Leung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to Enhance Causal Discrimination of Utterances: A Case on Affective Reasoning. (arXiv:2305.02615v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02615","description":"<p>Our investigation into the Affective Reasoning in Conversation (ARC) task\nhighlights the challenge of causal discrimination. Almost all existing models,\nincluding large language models (LLMs), excel at capturing semantic\ncorrelations within utterance embeddings but fall short in determining the\nspecific causal relationships. To overcome this limitation, we propose the\nincorporation of \\textit{i.i.d.} noise terms into the conversation process,\nthereby constructing a structural causal model (SCM). It explores how distinct\ncausal relationships of fitted embeddings can be discerned through independent\nconditions. To facilitate the implementation of deep learning, we introduce the\ncogn frameworks to handle unstructured conversation data, and employ an\nautoencoder architecture to regard the unobservable noise as learnable\n\"implicit causes.\" Moreover, we curate a synthetic dataset that includes i.i.d.\nnoise. Through comprehensive experiments, we validate the effectiveness and\ninterpretability of our approach. Our code is available in\nhttps://github.com/Zodiark-ch/mater-of-our-EMNLP2023-paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jing Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenjing Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DUMB: A Benchmark for Smart Evaluation of Dutch Models. (arXiv:2305.13026v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13026","description":"<p>We introduce the Dutch Model Benchmark: DUMB. The benchmark includes a\ndiverse set of datasets for low-, medium- and high-resource tasks. The total\nset of nine tasks includes four tasks that were previously not available in\nDutch. Instead of relying on a mean score across tasks, we propose Relative\nError Reduction (RER), which compares the DUMB performance of language models\nto a strong baseline which can be referred to in the future even when assessing\ndifferent sets of language models. Through a comparison of 14 pre-trained\nlanguage models (mono- and multi-lingual, of varying sizes), we assess the\ninternal consistency of the benchmark tasks, as well as the factors that likely\nenable high performance. Our results indicate that current Dutch monolingual\nmodels under-perform and suggest training larger Dutch models with other\narchitectures and pre-training objectives. At present, the highest performance\nis achieved by DeBERTaV3 (large), XLM-R (large) and mDeBERTaV3 (base). In\naddition to highlighting best strategies for training larger Dutch models, DUMB\nwill foster further research on Dutch. A public leaderboard is available at\nhttps://dumbench.nl.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vries_W/0/1/0/all/0/1\">Wietse de Vries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wieling_M/0/1/0/all/0/1\">Martijn Wieling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nissim_M/0/1/0/all/0/1\">Malvina Nissim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Biomedical Named Entity Recognition via Dictionary-based Synonym Generalization. (arXiv:2305.13066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13066","description":"<p>Biomedical named entity recognition is one of the core tasks in biomedical\nnatural language processing (BioNLP). To tackle this task, numerous\nsupervised/distantly supervised approaches have been proposed. Despite their\nremarkable success, these approaches inescapably demand laborious human effort.\nTo alleviate the need of human effort, dictionary-based approaches have been\nproposed to extract named entities simply based on a given dictionary. However,\none downside of existing dictionary-based approaches is that they are\nchallenged to identify concept synonyms that are not listed in the given\ndictionary, which we refer as the synonym generalization problem. In this\nstudy, we propose a novel Synonym Generalization (SynGen) framework that\nrecognizes the biomedical concepts contained in the input text using span-based\npredictions. In particular, SynGen introduces two regularization terms, namely,\n(1) a synonym distance regularizer; and (2) a noise perturbation regularizer,\nto minimize the synonym generalization error. To demonstrate the effectiveness\nof our approach, we provide a theoretical analysis of the bound of synonym\ngeneralization error. We extensively evaluate our approach on a wide range of\nbenchmarks and the results verify that SynGen outperforms previous\ndictionary-based models by notable margins. Lastly, we provide a detailed\nanalysis to further reveal the merits and inner-workings of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zihao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zaiqiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Semantic Role Labeling from Compatible Label Sequences. (arXiv:2305.14600v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14600","description":"<p>Semantic role labeling (SRL) has multiple disjoint label sets, e.g., VerbNet\nand PropBank. Creating these datasets is challenging, therefore a natural\nquestion is how to use each one to help the other. Prior work has shown that\ncross-task interaction helps, but only explored multitask learning so far. A\ncommon issue with multi-task setup is that argument sequences are still\nseparately decoded, running the risk of generating structurally inconsistent\nlabel sequences (as per lexicons like Semlink). In this paper, we eliminate\nsuch issue with a framework that jointly models VerbNet and PropBank labels as\none sequence. In this setup, we show that enforcing Semlink constraints during\ndecoding constantly improves the overall F1. With special input constructions,\nour joint model infers VerbNet arguments from given PropBank arguments with\nover 99 F1. For learning, we propose a constrained marginal model that learns\nwith knowledge defined in Semlink to further benefit from the large amounts of\nPropBank-only data. On the joint benchmark based on CoNLL05, our models achieve\nstate-of-the-art F1's, outperforming the prior best in-domain model by 3.5\n(VerbNet) and 0.8 (PropBank). For out-of-domain generalization, our models\nsurpass the prior best by 3.4 (VerbNet) and 0.2 (PropBank).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazeminejad_G/0/1/0/all/0/1\">Ghazaleh Kazeminejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_S/0/1/0/all/0/1\">Susan W. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1\">Martha Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SciFix: Outperforming GPT3 on Scientific Factual Error Correction. (arXiv:2305.14707v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14707","description":"<p>Due to the prohibitively high cost of creating error correction datasets,\nmost Factual Claim Correction methods rely on a powerful verification model to\nguide the correction process. This leads to a significant drop in performance\nin domains like scientific claims, where good verification models do not always\nexist. In this work, we introduce SciFix, a scientific claim correction system\nthat does not require a verifier but can outperform existing methods by a\nconsiderable margin -- achieving correction accuracy of 84% on the SciFact\ndataset, 77% on SciFact-Open and 72% on the CovidFact dataset, compared to next\nbest accuracies of 7%, 5%, and 15% on the same datasets respectively. Our\nmethod leverages the power of prompting with LLMs during training to create a\nrichly annotated dataset that can be used for fully supervised training and\nregularization. We additionally use a claim-aware decoding procedure to improve\nthe quality of corrected claims. Our method outperforms the very LLM that was\nused to generate the annotated dataset -- with Few-Shot Prompting on GPT3.5\nachieving 58%, 61%, and 64% on the respective datasets, a consistently lower\ncorrection accuracy, despite using nearly 800 times as many parameters as our\nmodel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ashok_D/0/1/0/all/0/1\">Dhananjay Ashok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Atharva Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1\">Hai Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poczos_B/0/1/0/all/0/1\">Barnab&#xe1;s P&#xf3;czos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Mechanism for Solving Relational Tasks in Transformer Language Models. (arXiv:2305.16130v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16130","description":"<p>A primary criticism towards language models (LMs) is their inscrutability.\nThis paper presents evidence that, despite their size and complexity, LMs\nsometimes exploit a simple computational mechanism to solve one-to-one\nrelational tasks (e.g., capital_of(Poland)=Warsaw). We investigate a range of\nlanguage model sizes (from 124M parameters to 176B parameters) in an in-context\nlearning setting, and find that for a variety of tasks (involving capital\ncities, upper-casing, and past-tensing) a key part of the mechanism reduces to\na simple linear update typically applied by the feedforward (FFN) networks.\nThese updates also tend to promote the output of the relation in a\ncontent-independent way (e.g., encoding Poland:Warsaw::China:Beijing),\nrevealing a predictable pattern that these models take in solving these tasks.\nWe further show that this mechanism is specific to tasks that require retrieval\nfrom pretraining memory, rather than retrieval from local context. Our results\ncontribute to a growing body of work on the mechanistic interpretability of\nLLMs, and offer reason to be optimistic that, despite the massive and\nnon-linear nature of the models, the strategies they ultimately use to solve\ntasks can sometimes reduce to familiar and even intuitive algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Merullo_J/0/1/0/all/0/1\">Jack Merullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Images with Multimodal Language Models. (arXiv:2305.17216v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17216","description":"<p>We propose a method to fuse frozen text-only large language models (LLMs)\nwith pre-trained image encoder and decoder models, by mapping between their\nembedding spaces. Our model demonstrates a wide suite of multimodal\ncapabilities: image retrieval, novel image generation, and multimodal dialogue.\nOurs is the first approach capable of conditioning on arbitrarily interleaved\nimage and text inputs to generate coherent image (and text) outputs. To achieve\nstrong performance on image generation, we propose an efficient mapping network\nto ground the LLM to an off-the-shelf text-to-image generation model. This\nmapping network translates hidden representations of text into the embedding\nspace of the visual models, enabling us to leverage the strong text\nrepresentations of the LLM for visual outputs. Our approach outperforms\nbaseline generation models on tasks with longer and more complex language. In\naddition to novel image generation, our model is also capable of image\nretrieval from a prespecified dataset, and decides whether to retrieve or\ngenerate at inference time. This is done with a learnt decision module which\nconditions on the hidden representations of the LLM. Our model exhibits a wider\nrange of capabilities compared to prior multimodal language models. It can\nprocess image-and-text inputs, and produce retrieved images, generated images,\nand generated text -- outperforming non-LLM based generation models across\nseveral text-to-image tasks that measure context dependence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koh_J/0/1/0/all/0/1\">Jing Yu Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Being Right for Whose Right Reasons?. (arXiv:2306.00639v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00639","description":"<p>Explainability methods are used to benchmark the extent to which model\npredictions align with human rationales i.e., are 'right for the right\nreasons'. Previous work has failed to acknowledge, however, that what counts as\na rationale is sometimes subjective. This paper presents what we think is a\nfirst of its kind, a collection of human rationale annotations augmented with\nthe annotators demographic information. We cover three datasets spanning\nsentiment analysis and common-sense reasoning, and six demographic groups\n(balanced across age and ethnicity). Such data enables us to ask both what\ndemographics our predictions align with and whose reasoning patterns our\nmodels' rationales align with. We find systematic inter-group annotator\ndisagreement and show how 16 Transformer-based models align better with\nrationales provided by certain demographic groups: We find that models are\nbiased towards aligning best with older and/or white annotators. We zoom in on\nthe effects of model size and model distillation, finding -- contrary to our\nexpectations -- negative correlations between model size and rationale\nagreement as well as no evidence that either model size or model distillation\nimproves fairness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jakobsen_T/0/1/0/all/0/1\">Terne Sasha Thorn Jakobsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cabello_L/0/1/0/all/0/1\">Laura Cabello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Provable Robust Watermarking for AI-Generated Text. (arXiv:2306.17439v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17439","description":"<p>We study the problem of watermarking large language models (LLMs) generated\ntext -- one of the most promising approaches for addressing the safety\nchallenges of LLM usage. In this paper, we propose a rigorous theoretical\nframework to quantify the effectiveness and robustness of LLM watermarks. We\npropose a robust and high-quality watermark method, Unigram-Watermark, by\nextending an existing approach with a simplified fixed grouping strategy. We\nprove that our watermark method enjoys guaranteed generation quality,\ncorrectness in watermark detection, and is robust against text editing and\nparaphrasing. Experiments on three varying LLMs and two datasets verify that\nour Unigram-Watermark achieves superior detection accuracy and comparable\ngeneration quality in perplexity, thus promoting the responsible use of LLMs.\nCode is available at https://github.com/XuandongZhao/Unigram-Watermark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xuandong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananth_P/0/1/0/all/0/1\">Prabhanjan Ananth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evade ChatGPT Detectors via A Single Space. (arXiv:2307.02599v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.02599","description":"<p>ChatGPT brings revolutionary social value but also raises concerns about the\nmisuse of AI-generated text. Consequently, an important question is how to\ndetect whether texts are generated by ChatGPT or by human. Existing detectors\nare built upon the assumption that there are distributional gaps between\nhuman-generated and AI-generated text. These gaps are typically identified\nusing statistical information or classifiers. Our research challenges the\ndistributional gap assumption in detectors. We find that detectors do not\neffectively discriminate the semantic and stylistic gaps between\nhuman-generated and AI-generated text. Instead, the \"subtle differences\", such\nas an extra space, become crucial for detection. Based on this discovery, we\npropose the SpaceInfi strategy to evade detection. Experiments demonstrate the\neffectiveness of this strategy across multiple benchmarks and detectors. We\nalso provide a theoretical explanation for why SpaceInfi is successful in\nevading perplexity-based detection. And we empirically show that a phenomenon\ncalled token mutation causes the evasion for language model-based detectors.\nOur findings offer new insights and challenges for understanding and\nconstructing more applicable ChatGPT detectors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1\">Shuyang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wanyun Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors. (arXiv:2308.01497v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01497","description":"<p>Recent advances in the performance of large language models (LLMs) have\nsparked debate over whether, given sufficient training, high-level human\nabilities emerge in such generic forms of artificial intelligence (AI). Despite\nthe exceptional performance of LLMs on a wide range of tasks involving natural\nlanguage processing and reasoning, there has been sharp disagreement as to\nwhether their abilities extend to more creative human abilities. A core example\nis the ability to interpret novel metaphors. Given the enormous and non curated\ntext corpora used to train LLMs, a serious obstacle to designing tests is the\nrequirement of finding novel yet high quality metaphors that are unlikely to\nhave been included in the training data. Here we assessed the ability of GPT4,\na state of the art large language model, to provide natural-language\ninterpretations of novel literary metaphors drawn from Serbian poetry and\ntranslated into English. Despite exhibiting no signs of having been exposed to\nthese metaphors previously, the AI system consistently produced detailed and\nincisive interpretations. Human judges, blind to the fact that an AI model was\ninvolved, rated metaphor interpretations generated by GPT4 as superior to those\nprovided by a group of college students. In interpreting reversed metaphors,\nGPT4, as well as humans, exhibited signs of sensitivity to the Gricean\ncooperative principle. In addition, for several novel English poems GPT4\nproduced interpretations that were rated as excellent or good by a human\nliterary critic. These results indicate that LLMs such as GPT4 have acquired an\nemergent ability to interpret complex metaphors, including those embedded in\nnovel poems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ichien_N/0/1/0/all/0/1\">Nicholas Ichien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stamenkovic_D/0/1/0/all/0/1\">Du&#x161;an Stamenkovi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holyoak_K/0/1/0/all/0/1\">Keith J. Holyoak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.02490","description":"<p>We propose MM-Vet, an evaluation benchmark that examines large multimodal\nmodels (LMMs) on complicated multimodal tasks. Recent LMMs have shown various\nintriguing abilities, such as solving math problems written on the blackboard,\nreasoning about events and celebrities in news images, and explaining visual\njokes. Rapid model advancements pose challenges to evaluation benchmark\ndevelopment. Problems include: (1) How to systematically structure and evaluate\nthe complicated multimodal tasks; (2) How to design evaluation metrics that\nwork well across question and answer types; and (3) How to give model insights\nbeyond a simple performance ranking. To this end, we present MM-Vet, designed\nbased on the insight that the intriguing ability to solve complicated tasks is\noften achieved by a generalist model being able to integrate different core\nvision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and\nexamines the 16 integrations of interest derived from the capability\ncombination. For evaluation metrics, we propose an LLM-based evaluator for\nopen-ended outputs. The evaluator enables the evaluation across different\nquestion types and answer styles, resulting in a unified scoring metric. We\nevaluate representative LMMs on MM-Vet, providing insights into the\ncapabilities of different LMM system paradigms and models. Code and data are\navailable at https://github.com/yuweihao/MM-Vet.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Weihao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval. (arXiv:2308.04711v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04711","description":"<p>When provided with sufficient explanatory context, smaller Language Models\nhave been shown to exhibit strong reasoning ability on challenging short-answer\nquestion-answering tasks where the questions are unseen in training. We\nevaluate two methods for further improvement in this setting. Both methods\nfocus on combining rationales generated by a larger Language Model with longer\ncontexts created from a multi-hop dense retrieval system. The first method\n($\\textit{RR}$) involves training a Rationale Ranking model to score both\ngenerated rationales and retrieved contexts with respect to relevance and\ntruthfulness. We then use the scores to derive combined contexts from both\nknowledge sources using a number of combinatory strategies. For the second\nmethod ($\\textit{RATD}$) we utilise retrieval-augmented training datasets\ndeveloped by Hartill et al. 2023 to train a smaller Reasoning model such that\nit becomes proficient at utilising relevant information from longer text\nsequences that may be only partially evidential and frequently contain many\nirrelevant sentences. We find that both methods significantly improve results.\nOur single best Reasoning model materially improves upon strong comparable\nprior baselines for unseen evaluation datasets (StrategyQA 58.9 $\\rightarrow$\n61.7 acc., CommonsenseQA 63.6 $\\rightarrow$ 72.7 acc., ARC-DA 31.6\n$\\rightarrow$ 52.1 F1, IIRC 25.5 $\\rightarrow$ 27.3 F1) and a version utilising\nour prior knowledge of each type of question in selecting a context combination\nstrategy does even better. Our proposed models also generally outperform direct\nprompts against much larger models (BLOOM 175B and StableVicuna 13B) in both\nfew-shot chain-of-thought and standard few-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hartill_T/0/1/0/all/0/1\">Tim Hartill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benavides_Prado_D/0/1/0/all/0/1\">Diana Benavides-Prado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riddle_P/0/1/0/all/0/1\">Patricia J. Riddle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond. (arXiv:2308.12966v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.12966","description":"<p>In this work, we introduce the Qwen-VL series, a set of large-scale\nvision-language models (LVLMs) designed to perceive and understand both texts\nand images. Starting from the Qwen-LM as a foundation, we endow it with visual\ncapacity by the meticulously designed (i) visual receptor, (ii) input-output\ninterface, (iii) 3-stage training pipeline, and (iv) multilingual multimodal\ncleaned corpus. Beyond the conventional image description and\nquestion-answering, we implement the grounding and text-reading ability of\nQwen-VLs by aligning image-caption-box tuples. The resulting models, including\nQwen-VL and Qwen-VL-Chat, set new records for generalist models under similar\nmodel scales on a broad range of visual-centric benchmarks (e.g., image\ncaptioning, question answering, visual grounding) and different settings (e.g.,\nzero-shot, few-shot). Moreover, on real-world dialog benchmarks, our\ninstruction-tuned Qwen-VL-Chat also demonstrates superiority compared to\nexisting vision-language chatbots. Code, demo and models are available at\nhttps://github.com/QwenLM/Qwen-VL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jinze Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1\">Shuai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shusheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Sinan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DictaBERT: A State-of-the-Art BERT Suite for Modern Hebrew. (arXiv:2308.16687v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16687","description":"<p>We present DictaBERT, a new state-of-the-art pre-trained BERT model for\nmodern Hebrew, outperforming existing models on most benchmarks. Additionally,\nwe release three fine-tuned versions of the model, designed to perform three\nspecific foundational tasks in the analysis of Hebrew texts: prefix\nsegmentation, morphological tagging and question answering. These fine-tuned\nmodels allow any developer to perform prefix segmentation, morphological\ntagging and question answering of a Hebrew input with a single call to a\nHuggingFace model, without the need to integrate any additional libraries or\ncode. In this paper we describe the details of the training as well and the\nresults on the different benchmarks. We release the models to the community,\nalong with sample code demonstrating their use. We release these models as part\nof our goal to help further research and development in Hebrew NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shmidman_S/0/1/0/all/0/1\">Shaltiel Shmidman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmidman_A/0/1/0/all/0/1\">Avi Shmidman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koppel_M/0/1/0/all/0/1\">Moshe Koppel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response. (arXiv:2309.08730v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.08730","description":"<p>Large Language Models (LLMs) have shown immense potential in multimodal\napplications, yet the convergence of textual and musical domains remains\nrelatively unexplored. To address this gap, we present MusiLingo, a novel\nsystem for music caption generation and music-related query responses.\nMusiLingo employs a single projection layer to align music representations from\nthe pre-trained frozen music audio model MERT with the frozen Vicuna-7B\nlanguage model (an adaption of LLaMA), bridging the gap between music audio and\ntextual contexts. We train it on an extensive music caption dataset and\nfine-tune it with instructional data. Due to the scarcity of high-quality music\nQ\\&amp;A datasets, we created the Music Instruct (MI) dataset from captions in the\nMusicCaps datasets, tailored for open-ended music inquiries. Empirical\nevaluations demonstrate its competitive performance in generating music\ncaptions and composing music-related Q&amp;A pairs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Deng_Z/0/1/0/all/0/1\">Zihao Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_Y/0/1/0/all/0/1\">Yinghao Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yudong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_R/0/1/0/all/0/1\">Rongchen Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benetos_E/0/1/0/all/0/1\">Emmanouil Benetos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EchoPrompt: Instructing the Model to Rephrase Queries for Improved In-context Learning. (arXiv:2309.10687v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.10687","description":"<p>Language models are achieving impressive performance on various tasks by\naggressively adopting inference-time prompting techniques, such as zero-shot\nand few-shot prompting. In this work, we introduce EchoPrompt, a simple yet\neffective approach that prompts the model to rephrase its queries before\nanswering them. EchoPrompt is adapted for both zero-shot and few-shot\nin-context learning with standard and chain-of-thought prompting. Experimental\nresults show that EchoPrompt yields substantial improvements across all these\nsettings for four families of causal language models. These improvements are\nobserved across various numerical reasoning (e.g. GSM8K, SVAMP), reading\ncomprehension (e.g. DROP), and logical reasoning (e.g. Coin Flipping) tasks. On\naverage, EchoPrompt improves the Zero-shot-CoT performance of code-davinci-002\nby 5% in numerical tasks and 13% in reading comprehension tasks. We investigate\nthe factors contributing to EchoPrompt's effectiveness through ablation\nstudies, which reveal that both the original query and the model-generated\nrephrased version are instrumental in its performance gains. Our empirical\nresults indicate that EchoPrompt is an effective technique that enhances\nin-context learning performance. We recommend incorporating EchoPrompt into\nvarious baseline prompting strategies to achieve performance boosts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mekala_R/0/1/0/all/0/1\">Rajasekhar Reddy Mekala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razeghi_Y/0/1/0/all/0/1\">Yasaman Razeghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Emotional Expression and Cohesion in Image-Based Playlist Description and Music Topics: A Continuous Parameterization Approach. (arXiv:2310.01248v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01248","description":"<p>Text generation in image-based platforms, particularly for music-related\ncontent, requires precise control over text styles and the incorporation of\nemotional expression. However, existing approaches often need help to control\nthe proportion of external factors in generated text and rely on discrete\ninputs, lacking continuous control conditions for desired text generation. This\nstudy proposes Continuous Parameterization for Controlled Text Generation\n(CPCTG) to overcome these limitations. Our approach leverages a Language Model\n(LM) as a style learner, integrating Semantic Cohesion (SC) and Emotional\nExpression Proportion (EEP) considerations. By enhancing the reward method and\nmanipulating the CPCTG level, our experiments on playlist description and music\ntopic generation tasks demonstrate significant improvements in ROUGE scores,\nindicating enhanced relevance and coherence in the generated text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1\">Yuelyu Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruoyi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhongqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huiyun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond. (arXiv:2310.02071v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.02071","description":"<p>In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zefan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuchi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating UMLS Knowledge into Large Language Models for Medical Question Answering. (arXiv:2310.02778v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02778","description":"<p>Large language models (LLMs) have demonstrated powerful text generation\ncapabilities, bringing unprecedented innovation to the healthcare field. While\nLLMs hold immense promise for applications in healthcare, applying them to real\nclinical scenarios presents significant challenges, as these models may\ngenerate content that deviates from established medical facts and even exhibit\npotential biases. In our research, we develop an augmented LLM framework based\non the Unified Medical Language System (UMLS), aiming to better serve the\nhealthcare community. We employ LLaMa2-13b-chat and ChatGPT-3.5 as our\nbenchmark models, and conduct automatic evaluations using the ROUGE Score and\nBERTScore on 104 questions from the LiveQA test set. Additionally, we establish\ncriteria for physician-evaluation based on four dimensions: Factuality,\nCompleteness, Readability and Relevancy. ChatGPT-3.5 is used for physician\nevaluation with 20 questions on the LiveQA test set. Multiple resident\nphysicians conducted blind reviews to evaluate the generated content, and the\nresults indicate that this framework effectively enhances the factuality,\ncompleteness, and relevance of generated content. Our research demonstrates the\neffectiveness of using UMLS-augmented LLMs and highlights the potential\napplication value of LLMs in in medical question-answering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Rui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marrese_Taylor_E/0/1/0/all/0/1\">Edison Marrese-Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_Y/0/1/0/all/0/1\">Yuhe Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lechao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving. (arXiv:2310.03026v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2310.03026","description":"<p>Existing learning-based autonomous driving (AD) systems face challenges in\ncomprehending high-level information, generalizing to rare events, and\nproviding interpretability. To address these problems, this work employs Large\nLanguage Models (LLMs) as a decision-making component for complex AD scenarios\nthat require human commonsense understanding. We devise cognitive pathways to\nenable comprehensive reasoning with LLMs, and develop algorithms for\ntranslating LLM decisions into actionable driving commands. Through this\napproach, LLM decisions are seamlessly integrated with low-level controllers by\nguided parameter matrix adaptation. Extensive experiments demonstrate that our\nproposed method not only consistently surpasses baseline approaches in\nsingle-vehicle tasks, but also helps handle complex driving behaviors even\nmulti-vehicle coordination, thanks to the commonsense reasoning capabilities of\nLLMs. This paper presents an initial step toward leveraging LLMs as effective\ndecision-makers for intricate AD scenarios in terms of safety, efficiency,\ngeneralizability, and interoperability. We aspire for it to serve as\ninspiration for future research in this field. Project page:\nhttps://sites.google.com/view/llm-mpc\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sha_H/0/1/0/all/0/1\">Hao Sha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yao Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuxuan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chenfeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shengbo Eben Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wei Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reformulating Domain Adaptation of Large Language Models as Adapt-Retrieve-Revise. (arXiv:2310.03328v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03328","description":"<p>While large language models (LLMs) like GPT-4 have recently demonstrated\nastonishing zero-shot capabilities in general domain tasks, they often generate\ncontent with hallucinations in specific domains such as Chinese law, hindering\ntheir application in these areas. This is typically due to the absence of\ntraining data that encompasses such a specific domain, preventing GPT-4 from\nacquiring in-domain knowledge. A pressing challenge is that it's not plausible\nto continue training LLMs of such scale on in-domain data.\n</p>\n<p>This paper introduces a simple and effective domain adaptation framework for\nGPT-4 by reformulating generation as an \\textbf{adapt-retrieve-revise} process.\nThe initial step is to \\textbf{adapt} an affordable 7B LLM to the target domain\nby continuing learning on in-domain data. When solving a task, we leverage the\nadapted LLM to generate a draft answer given a task query. Then, the draft\nanswer will be used to \\textbf{retrieve} supporting evidence candidates from an\nexternal in-domain knowledge base. Finally, the draft answer and retrieved\nevidence are concatenated into a whole prompt to let GPT-4 assess the evidence\nand \\textbf{revise} the draft answer to generate the final answer.\n</p>\n<p>Our proposal combines the advantages of the efficiency of adapting a smaller\n7B model with the evidence-assessing capability of GPT-4 and effectively\nprevents GPT-4 from generating hallucinatory content. In the zero-shot setting\nof four Chinese legal tasks, our method improves accuracy by 33.3\\% compared to\nthe direct generation by GPT-4. When compared to two stronger retrieval-based\nbaselines, our method outperforms them by 15.4\\% and 23.9\\%. Our code will be\nreleased\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+wan_Z/0/1/0/all/0/1\">Zhen wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yating Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yexiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human Mobility Question Answering (Vision Paper). (arXiv:2310.04443v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04443","description":"<p>Question answering (QA) systems have attracted much attention from the\nartificial intelligence community as they can learn to answer questions based\non the given knowledge source (e.g., images in visual question answering).\nHowever, the research into question answering systems with human mobility data\nremains unexplored. Mining human mobility data is crucial for various\napplications such as smart city planning, pandemic management, and personalised\nrecommendation system. In this paper, we aim to tackle this gap and introduce a\nnovel task, that is, human mobility question answering (MobQA). The aim of the\ntask is to let the intelligent system learn from mobility data and answer\nrelated questions. This task presents a new paradigm change in mobility\nprediction research and further facilitates the research of human mobility\nrecommendation systems. To better support this novel research topic, this\nvision paper also proposes an initial design of the dataset and a potential\ndeep learning model framework for the introduced MobQA task. We hope that this\npaper will provide novel insights and open new directions in human mobility\nresearch and question answering research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Label-free Node Classification on Graphs with Large Language Models (LLMS). (arXiv:2310.04668v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.04668","description":"<p>In recent years, there have been remarkable advancements in node\nclassification achieved by Graph Neural Networks (GNNs). However, they\nnecessitate abundant high-quality labels to ensure promising performance. In\ncontrast, Large Language Models (LLMs) exhibit impressive zero-shot proficiency\non text-attributed graphs. Yet, they face challenges in efficiently processing\nstructural data and suffer from high inference costs. In light of these\nobservations, this work introduces a label-free node classification on graphs\nwith LLMs pipeline, LLM-GNN. It amalgamates the strengths of both GNNs and LLMs\nwhile mitigating their limitations. Specifically, LLMs are leveraged to\nannotate a small portion of nodes and then GNNs are trained on LLMs'\nannotations to make predictions for the remaining large portion of nodes. The\nimplementation of LLM-GNN faces a unique challenge: how can we actively select\nnodes for LLMs to annotate and consequently enhance the GNN training? How can\nwe leverage LLMs to obtain annotations of high quality, representativeness, and\ndiversity, thereby enhancing GNN performance with less cost? To tackle this\nchallenge, we develop an annotation quality heuristic and leverage the\nconfidence scores derived from LLMs to advanced node selection. Comprehensive\nexperimental results validate the effectiveness of LLM-GNN. In particular,\nLLM-GNN can achieve an accuracy of 74.9% on a vast-scale dataset \\products with\na cost less than 1 dollar.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhikai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1\">Haitao Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1\">Hongzhi Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1\">Haoyu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Wei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haiyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational Knowledge Graph Construction. (arXiv:2310.05185v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.05185","description":"<p>Beyond traditional binary relational facts, n-ary relational knowledge graphs\n(NKGs) are comprised of n-ary relational facts containing more than two\nentities, which are closer to real-world facts with broader applications.\nHowever, the construction of NKGs still significantly relies on manual labor,\nand n-ary relation extraction still remains at a course-grained level, which is\nalways in a single schema and fixed arity of entities. To address these\nrestrictions, we propose Text2NKG, a novel fine-grained n-ary relation\nextraction framework for n-ary relational knowledge graph construction. We\nintroduce a span-tuple classification approach with hetero-ordered merging to\naccomplish fine-grained n-ary relation extraction in different arity.\nFurthermore, Text2NKG supports four typical NKG schemas: hyper-relational\nschema, event-based schema, role-based schema, and hypergraph-based schema,\nwith high flexibility and practicality. Experimental results demonstrate that\nText2NKG outperforms the previous state-of-the-art model by nearly 20\\% points\nin the $F_1$ scores on the fine-grained n-ary relation extraction benchmark in\nthe hyper-relational schema. Our code and datasets are publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haoran Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+E_H/0/1/0/all/0/1\">Haihong E</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1\">Tianyu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yikai Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zichen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wentai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_K/0/1/0/all/0/1\">Kaiyang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shiyao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Meina Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems. (arXiv:2310.05280v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05280","description":"<p>Recent advancements in Large Language Models empower them to follow freeform\ninstructions, including imitating generic or specific demographic personas in\nconversations. Generic personas refer to an individual from a demographic group\n(e.g. an Asian person), whereas specific personas can be actual names of\nhistorical figures. While the adoption of personas allows dialogue systems to\nbe more engaging and approachable to users, it also carries the potential risk\nof exacerbating social biases in model responses, further causing societal\nharms through interactions with users. In this paper, we systematically study\n\"persona biases\", which we define to be the sensitivity of harmful dialogue\nmodel behaviors to different persona adoptions. We categorize persona biases\ninto biases in harmful expression and harmful agreement, as well as establish a\ncomprehensive evaluation framework to measure persona biases in five aspects:\nOffensiveness, Toxic Continuation, Regard, Stereotype Agreement, and Toxic\nAgreement. Additionally, we propose to comprehensively investigate persona\nbiases through experimenting with UniversalPersona, a systematized persona\ndataset with a comprehensive list of both generic and specific model personas.\nThrough benchmarking on four different models, including Blender, ChatGPT,\nAlpaca, and Vicuna, our study uncovers significant persona biases in these\ndialogue systems.Findings of our study underscores the immediate need to\nrevisit the use of persona traits in dialogue agents, to ensure their safe\napplication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yixin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Multi-modal Entity Alignment via Iteratively Fusing Modality Similarity Paths. (arXiv:2310.05364v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05364","description":"<p>The objective of Entity Alignment (EA) is to identify equivalent entity pairs\nfrom multiple Knowledge Graphs (KGs) and create a more comprehensive and\nunified KG. The majority of EA methods have primarily focused on the structural\nmodality of KGs, lacking exploration of multi-modal information. A few\nmulti-modal EA methods have made good attempts in this field. Still, they have\ntwo shortcomings: (1) inconsistent and inefficient modality modeling that\ndesigns complex and distinct models for each modality; (2) ineffective modality\nfusion due to the heterogeneous nature of modalities in EA. To tackle these\nchallenges, we propose PathFusion, consisting of two main components: (1) MSP,\na unified modeling approach that simplifies the alignment process by\nconstructing paths connecting entities and modality nodes to represent multiple\nmodalities; (2) IRF, an iterative fusion method that effectively combines\ninformation from different modalities using the path as an information carrier.\nExperimental results on real-world datasets demonstrate the superiority of\nPathFusion over state-of-the-art methods, with 22.4%-28.9% absolute improvement\non Hits@1, and 0.194-0.245 absolute improvement on MRR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Bolin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoze Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1\">Xin Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Lingbing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can language models learn analogical reasoning? Investigating training objectives and comparisons to human performance. (arXiv:2310.05597v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05597","description":"<p>While analogies are a common way to evaluate word embeddings in NLP, it is\nalso of interest to investigate whether or not analogical reasoning is a task\nin itself that can be learned. In this paper, we test several ways to learn\nbasic analogical reasoning, specifically focusing on analogies that are more\ntypical of what is used to evaluate analogical reasoning in humans than those\nin commonly used NLP benchmarks. Our experiments find that models are able to\nlearn analogical reasoning, even with a small amount of data. We additionally\ncompare our models to a dataset with a human baseline, and find that after\ntraining, models approach human performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_M/0/1/0/all/0/1\">Molly R. Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plas_L/0/1/0/all/0/1\">Lonneke van der Plas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sparse Fine-tuning for Inference Acceleration of Large Language Models. (arXiv:2310.06927v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06927","description":"<p>We consider the problem of accurate sparse fine-tuning of large language\nmodels (LLMs), that is, fine-tuning pretrained LLMs on specialized tasks, while\ninducing sparsity in their weights. On the accuracy side, we observe that\nstandard loss-based fine-tuning may fail to recover accuracy, especially at\nhigh sparsities. To address this, we perform a detailed study of\ndistillation-type losses, determining an L2-based distillation approach we term\nSquareHead which enables accurate recovery even at higher sparsities, across\nall model types. On the practical efficiency side, we show that sparse LLMs can\nbe executed with speedups by taking advantage of sparsity, for both CPU and GPU\nruntimes. While the standard approach is to leverage sparsity for computational\nreduction, we observe that in the case of memory-bound LLMs sparsity can also\nbe leveraged for reducing memory bandwidth. We exhibit end-to-end results\nshowing speedups due to sparsity, while recovering accuracy, on T5 (language\ntranslation), Whisper (speech translation), and open GPT-type (MPT for text\ngeneration). For MPT text generation, we show for the first time that sparse\nfine-tuning can reach 75% sparsity without accuracy drops, provide notable\nend-to-end speedups for both CPU and GPU inference, and highlight that sparsity\nis also compatible with quantization approaches. Models and software for\nreproducing our results are provided in Section 6.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1\">Eldar Kurtic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznedelev_D/0/1/0/all/0/1\">Denis Kuznedelev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1\">Elias Frantar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goin_M/0/1/0/all/0/1\">Michael Goin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1\">Dan Alistarh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Impact of Cross-Domain Data on German Language Models. (arXiv:2310.07321v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07321","description":"<p>Traditionally, large language models have been either trained on general web\ncrawls or domain-specific data. However, recent successes of generative large\nlanguage models, have shed light on the benefits of cross-domain datasets. To\nexamine the significance of prioritizing data diversity over quality, we\npresent a German dataset comprising texts from five domains, along with another\ndataset aimed at containing high-quality data. Through training a series of\nmodels ranging between 122M and 750M parameters on both datasets, we conduct a\ncomprehensive benchmark on multiple downstream tasks. Our findings demonstrate\nthat the models trained on the cross-domain dataset outperform those trained on\nquality data alone, leading to improvements up to $4.45\\%$ over the previous\nstate-of-the-art. The models are available at\nhttps://huggingface.co/ikim-uk-essen\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dada_A/0/1/0/all/0/1\">Amin Dada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Aokun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Cheng Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kaleb E Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Idrissi_Yaghir_A/0/1/0/all/0/1\">Ahmad Idrissi-Yaghir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seibold_C/0/1/0/all/0/1\">Constantin Marc Seibold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heiliger_L/0/1/0/all/0/1\">Lars Heiliger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_C/0/1/0/all/0/1\">Christoph M. Friedrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truhn_D/0/1/0/all/0/1\">Daniel Truhn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1\">Jan Egger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1\">Jens Kleesiek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Target-oriented Proactive Dialogue Systems with Personalization: Problem Formulation and Dataset Curation. (arXiv:2310.07397v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07397","description":"<p>Target-oriented dialogue systems, designed to proactively steer conversations\ntoward predefined targets or accomplish specific system-side goals, are an\nexciting area in conversational AI. In this work, by formulating a &lt;dialogue\nact, topic&gt; pair as the conversation target, we explore a novel problem of\npersonalized target-oriented dialogue by considering personalization during the\ntarget accomplishment process. However, there remains an emergent need for\nhigh-quality datasets, and building one from scratch requires tremendous human\neffort. To address this, we propose an automatic dataset curation framework\nusing a role-playing approach. Based on this framework, we construct a\nlarge-scale personalized target-oriented dialogue dataset, TopDial, which\ncomprises about 18K multi-turn dialogues. The experimental results show that\nthis dataset is of high quality and could contribute to exploring personalized\ntarget-oriented dialogue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dongding Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leong_C/0/1/0/all/0/1\">Chak Tou Leong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations. (arXiv:2310.07849v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07849","description":"<p>The collection and curation of high-quality training data is crucial for\ndeveloping text classification models with superior performance, but it is\noften associated with significant costs and time investment. Researchers have\nrecently explored using large language models (LLMs) to generate synthetic\ndatasets as an alternative approach. However, the effectiveness of the\nLLM-generated synthetic data in supporting model training is inconsistent\nacross different classification tasks. To better understand factors that\nmoderate the effectiveness of the LLM-generated synthetic data, in this study,\nwe look into how the performance of models trained on these synthetic data may\nvary with the subjectivity of classification. Our results indicate that\nsubjectivity, at both the task level and instance level, is negatively\nassociated with the performance of the model trained on synthetic data. We\nconclude by discussing the implications of our work on the potential and\nlimitations of leveraging LLM for synthetic data generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hangxiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhuoran Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Ming Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Model. (arXiv:2310.08072v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08072","description":"<p>This paper presents a simple and cost-effective method for synthesizing data\nto train question-answering systems. For training, fine-tuning GPT models is a\ncommon practice in resource-rich languages like English, however, it becomes\nchallenging for non-English languages due to the scarcity of sufficient\nquestion-answer (QA) pairs. Existing approaches use question and answer\ngenerators trained on human-authored QA pairs, which involves substantial human\nexpenses. In contrast, we use an instruct-tuned model to generate QA pairs in a\nzero-shot or few-shot manner. We conduct experiments to compare various\nstrategies for obtaining QA pairs from the instruct-tuned model. The results\ndemonstrate that a model trained on our proposed synthetic data achieves\ncomparable performance to a model trained on manually curated datasets, without\nincurring human costs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_K/0/1/0/all/0/1\">Kosuke Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omi_T/0/1/0/all/0/1\">Takahiro Omi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arima_K/0/1/0/all/0/1\">Kosuke Arima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishigaki_T/0/1/0/all/0/1\">Tatsuya Ishigaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can We Edit Multimodal Large Language Models?. (arXiv:2310.08475v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08475","description":"<p>In this paper, we focus on editing Multimodal Large Language Models (MLLMs).\nCompared to editing single-modal LLMs, multimodal model editing is more\nchallenging, which demands a higher level of scrutiny and careful consideration\nin the editing process. To facilitate research in this area, we construct a new\nbenchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite\nof innovative metrics for evaluation. We conduct comprehensive experiments\ninvolving various model editing baselines and analyze the impact of editing\ndifferent components for multimodal LLMs. Empirically, we notice that previous\nbaselines can implement editing multimodal LLMs to some extent, but the effect\nis still barely satisfactory, indicating the potential difficulty of this task.\nWe hope that our work can provide the NLP community with insights. Code and\ndataset are available in https://github.com/zjunlp/EasyEdit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Siyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1\">Bozhong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qingbin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-15T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}