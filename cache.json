{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-05-26T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Language Model Tokenizers Introduce Unfairness Between Languages. (arXiv:2305.15425v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15425","description":"<p>Recent language models have shown impressive multilingual performance, even\nwhen not explicitly trained for it. Despite this, concerns have been raised\nabout the quality of their outputs across different languages. In this paper,\nwe show how disparity in the treatment of different languages arises at the\ntokenization stage, well before a model is even invoked. The same text\ntranslated into different languages can have drastically different tokenization\nlengths, with differences up to 15 times in some cases. These disparities\npersist across the 17 tokenizers we evaluate, even if they are intentionally\ntrained for multilingual support. Character-level and byte-level models also\nexhibit over 4 times the difference in the encoding length for some language\npairs. This induces unfair treatment for some language communities in regard to\nthe cost of accessing commercial language services, the processing time and\nlatency, as well as the amount of content that can be provided as context to\nthe models. Therefore, we make the case that we should train future language\nmodels using multilingually fair tokenizers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petrov_A/0/1/0/all/0/1\">Aleksandar Petrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1\">Emanuele La Malfa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1\">Adel Bibi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptNER: Prompting For Named Entity Recognition. (arXiv:2305.15444v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15444","description":"<p>In a surprising turn, Large Language Models (LLMs) together with a growing\narsenal of prompt-based heuristics now offer powerful off-the-shelf approaches\nproviding few-shot solutions to myriad classic NLP problems. However, despite\npromising early results, these LLM-based few-shot methods remain far from the\nstate of the art in Named Entity Recognition (NER), where prevailing methods\ninclude learning representations via end-to-end structural understanding and\nfine-tuning on standard labeled corpora. In this paper, we introduce PromptNER,\na new state-of-the-art algorithm for few-Shot and cross-domain NER. To adapt to\nany new NER task PromptNER requires a set of entity definitions in addition to\nthe standard few-shot examples. Given a sentence, PromptNER prompts an LLM to\nproduce a list of potential entities along with corresponding explanations\njustifying their compatibility with the provided entity type definitions.\nRemarkably, PromptNER achieves state-of-the-art performance on few-shot NER,\nachieving an 11% (absolute) improvement in F1 score on the ConLL dataset, and a\n10% (absolute) improvement on the FewNERD dataset. PromptNER also moves the\nstate of the art on Cross Domain NER, outperforming all prior methods\n(including those not limited to the few-shot setting), setting a new mark on\nall 5 CrossNER target domains, with an average F1 gain of 9%, despite using\nless than 2% of the available data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ashok_D/0/1/0/all/0/1\">Dhananjay Ashok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1\">Zachary C. Lipton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for User Interest Journeys. (arXiv:2305.15498v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15498","description":"<p>Large language models (LLMs) have shown impressive capabilities in natural\nlanguage understanding and generation. Their potential for deeper user\nunderstanding and improved personalized user experience on recommendation\nplatforms is, however, largely untapped. This paper aims to address this gap.\nRecommender systems today capture users' interests through encoding their\nhistorical activities on the platforms. The generated user representations are\nhard to examine or interpret. On the other hand, if we were to ask people about\ninterests they pursue in their life, they might talk about their hobbies, like\nI just started learning the ukulele, or their relaxation routines, e.g., I like\nto watch Saturday Night Live, or I want to plant a vertical garden. We argue,\nand demonstrate through extensive experiments, that LLMs as foundation models\ncan reason through user activities, and describe their interests in nuanced and\ninteresting ways, similar to how a human would.\n</p>\n<p>We define interest journeys as the persistent and overarching user interests,\nin other words, the non-transient ones. These are the interests that we believe\nwill benefit most from the nuanced and personalized descriptions. We introduce\na framework in which we first perform personalized extraction of interest\njourneys, and then summarize the extracted journeys via LLMs, using techniques\nlike few-shot prompting, prompt-tuning and fine-tuning. Together, our results\nin prompting LLMs to name extracted user journeys in a large-scale industrial\nplatform demonstrate great potential of these models in providing deeper, more\ninterpretable, and controllable user understanding. We believe LLM powered user\nunderstanding can be a stepping stone to entirely new user experiences on\nrecommendation platforms that are journey-aware, assistive, and enabling\nfrictionless conversation down the line.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Christakopoulou_K/0/1/0/all/0/1\">Konstantina Christakopoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalama_A/0/1/0/all/0/1\">Alberto Lalama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adams_C/0/1/0/all/0/1\">Cj Adams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_I/0/1/0/all/0/1\">Iris Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amir_Y/0/1/0/all/0/1\">Yifat Amir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chucri_S/0/1/0/all/0/1\">Samer Chucri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vollucci_P/0/1/0/all/0/1\">Pierce Vollucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldo_F/0/1/0/all/0/1\">Fabio Soldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bseiso_D/0/1/0/all/0/1\">Dina Bseiso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scodel_S/0/1/0/all/0/1\">Sarah Scodel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_L/0/1/0/all/0/1\">Lucas Dixon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minmin Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deriving Language Models from Masked Language Models. (arXiv:2305.15501v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15501","description":"<p>Masked language models (MLM) do not explicitly define a distribution over\nlanguage, i.e., they are not language models per se. However, recent work has\nimplicitly treated them as such for the purposes of generation and scoring.\nThis paper studies methods for deriving explicit joint distributions from MLMs,\nfocusing on distributions over two tokens, which makes it possible to calculate\nexact distributional properties. We find that an approach based on identifying\njoints whose conditionals are closest to those of the MLM works well and\noutperforms existing Markov random field-based approaches. We further find that\nthis derived model's conditionals can even occasionally outperform the original\nMLM's conditionals.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hennigen_L/0/1/0/all/0/1\">Lucas Torroba Hennigen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python. (arXiv:2305.15507v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15507","description":"<p>Large Language Models (LLMs) have successfully been applied to code\ngeneration tasks, raising the question of how well these models understand\nprogramming. Typical programming languages have invariances and equivariances\nin their semantics that human programmers intuitively understand and exploit,\nsuch as the (near) invariance to the renaming of identifiers. We show that LLMs\nnot only fail to properly generate correct Python code when default function\nnames are swapped, but some of them even become more confident in their\nincorrect predictions as the model size increases, an instance of the recently\ndiscovered phenomenon of Inverse Scaling, which runs contrary to the commonly\nobserved trend of increasing prediction quality with increasing model size. Our\nfindings indicate that, despite their astonishing typical-case performance,\nLLMs still lack a deep, abstract understanding of the content they manipulate,\nmaking them unsuitable for tasks that statistically deviate from their training\ndata, and that mere scaling is not enough to achieve such capability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miceli_Barone_A/0/1/0/all/0/1\">Antonio Valerio Miceli-Barone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barez_F/0/1/0/all/0/1\">Fazl Barez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstas_I/0/1/0/all/0/1\">Ioannis Konstas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Free Lunch for Efficient Textual Commonsense Integration in Language Models. (arXiv:2305.15516v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15516","description":"<p>Recent years have witnessed the emergence of textual commonsense knowledge\nbases, aimed at providing more nuanced and context-rich knowledge. The\nintegration of external commonsense into language models has been shown to be a\nkey enabler in advancing the state-of-the-art for a wide range of NLP tasks.\nHowever, incorporating textual commonsense descriptions is computationally\nexpensive, as compared to encoding conventional symbolic knowledge. In this\npaper, we propose a method to improve its efficiency without modifying the\nmodel. We group training samples with similar commonsense descriptions into a\nsingle batch, thus reusing the encoded description across multiple samples. One\nkey observation is that the upper bound of batch partitioning can be reduced to\nthe classic {\\it graph k-cut problem}. Consequently, we propose a spectral\nclustering-based algorithm to solve this problem. Extensive experiments\nillustrate that the proposed batch partitioning approach effectively reduces\nthe computational cost while preserving performance. The efficiency improvement\nis more pronounced on larger datasets and on devices with more memory capacity,\nattesting to its practical utility for large-scale applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wanyun Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingran Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Automatically Perturbed Natural Language Explanations in Relation Extraction. (arXiv:2305.15520v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15520","description":"<p>Previous research has demonstrated that natural language explanations provide\nvaluable inductive biases that guide models, thereby improving the\ngeneralization ability and data efficiency. In this paper, we undertake a\nsystematic examination of the effectiveness of these explanations. Remarkably,\nwe find that corrupted explanations with diminished inductive biases can\nachieve competitive or superior performance compared to the original\nexplanations. Our findings furnish novel insights into the characteristics of\nnatural language explanations in the following ways: (1) the impact of\nexplanations varies across different training styles and datasets, with\npreviously believed improvements primarily observed in frozen language models.\n(2) While previous research has attributed the effect of explanations solely to\ntheir inductive biases, our study shows that the effect persists even when the\nexplanations are completely corrupted. We propose that the main effect is due\nto the provision of additional context space. (3) Utilizing the proposed\nautomatic perturbed context, we were able to attain comparable results to\nannotated explanations, but with a significant increase in computational\nefficiency, 20-30 times faster.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wanyun Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingran Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Few-Shot Health Learners. (arXiv:2305.15525v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15525","description":"<p>Large language models (LLMs) can capture rich representations of concepts\nthat are useful for real-world tasks. However, language alone is limited. While\nexisting LLMs excel at text-based inferences, health applications require that\nmodels be grounded in numerical data (e.g., vital signs, laboratory values in\nclinical domains; steps, movement in the wellness domain) that is not easily or\nreadily expressed as text in existing training corpus. We demonstrate that with\nonly few-shot tuning, a large language model is capable of grounding various\nphysiological and behavioral time-series data and making meaningful inferences\non numerous health tasks for both clinical and wellness contexts. Using data\nfrom wearable and medical sensor recordings, we evaluate these capabilities on\nthe tasks of cardiac signal analysis, physical activity recognition, metabolic\ncalculation (e.g., calories burned), and estimation of stress reports and\nmental health screeners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McDuff_D/0/1/0/all/0/1\">Daniel McDuff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovacs_G/0/1/0/all/0/1\">Geza Kovacs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galatzer_Levy_I/0/1/0/all/0/1\">Isaac Galatzer-Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunshine_J/0/1/0/all/0/1\">Jacob Sunshine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1\">Jiening Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poh_M/0/1/0/all/0/1\">Ming-Zher Poh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1\">Shun Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Achille_P/0/1/0/all/0/1\">Paolo Di Achille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1\">Shwetak Patel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Refugee Case Analysis: An NLP Pipeline for Supporting Legal Practitioners. (arXiv:2305.15533v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15533","description":"<p>In this paper, we introduce an end-to-end pipeline for retrieving,\nprocessing, and extracting targeted information from legal cases. We\ninvestigate an under-studied legal domain with a case study on refugee law in\nCanada. Searching case law for past similar cases is a key part of legal work\nfor both lawyers and judges, the potential end-users of our prototype. While\ntraditional named-entity recognition labels such as dates provide meaningful\ninformation in legal work, we propose to extend existing models and retrieve a\ntotal of 19 useful categories of items from refugee cases. After creating a\nnovel data set of cases, we perform information extraction based on\nstate-of-the-art neural named-entity recognition (NER). We test different\narchitectures including two transformer models, using contextual and\nnon-contextual embeddings, and compare general purpose versus domain-specific\npre-training. The results demonstrate that models pre-trained on legal data\nperform best despite their smaller size, suggesting that domain matching had a\nlarger effect than network architecture. We achieve a F1 score above 90% on\nfive of the targeted categories and over 80% on four further categories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barale_C/0/1/0/all/0/1\">Claire Barale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rovatsos_M/0/1/0/all/0/1\">Michael Rovatsos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhuta_N/0/1/0/all/0/1\">Nehal Bhuta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation. (arXiv:2305.15541v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15541","description":"<p>Translating natural language sentences to first-order logic (NL-FOL\ntranslation) is a longstanding challenge in the NLP and formal logic\nliterature. This paper introduces LogicLLaMA, a LLaMA-7B model fine-tuned for\nNL-FOL translation using LoRA on a single GPU. LogicLLaMA is capable of\ndirectly translating natural language into FOL rules, which outperforms\nGPT-3.5. LogicLLaMA is also equipped to correct FOL rules predicted by GPT-3.5,\nand can achieve similar performance as GPT-4 with a fraction of the cost. This\ncorrection ability was achieved by a novel supervised fine-tuning (SFT) +\nreinforcement learning with human feedback (RLHF) framework, which initially\ntrains on synthetically perturbed NL-FOL pairs to encourage chain-of-thought\nreasoning and then fine-tunes with RLHF on GPT-3.5 outputs using a FOL verifier\nas the reward model.\n</p>\n<p>To train LogicLLaMA, we present MALLS (large language $\\textbf{M}$odel\ngener$\\textbf{A}$ted N$\\textbf{L}$-FO$\\textbf{L}$ pair$\\textbf{S}$), a dataset\nof 34K high-quality and diverse sentence-level NL-FOL pairs collected from\nGPT-4. The dataset was created by implementing a pipeline that prompts GPT-4\nfor pairs, and dynamically adjusts the prompts to ensure the collection of\npairs with rich and diverse contexts at different levels of complexity, and\nverifies the validity of the generated FOL rules. Codes, weights, and data are\navailable at $\\href{https://github.com/gblackout/LogicLLaMA}{{\\small\n\\text{https://github.com/gblackout/LogicLLaMA}}}$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_S/0/1/0/all/0/1\">Siheng Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payani_A/0/1/0/all/0/1\">Ali Payani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fekri_F/0/1/0/all/0/1\">Faramarz Fekri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Refocusing Is Key to Transfer Learning. (arXiv:2305.15542v1 [cs.CV])","link":"http://arxiv.org/abs/2305.15542","description":"<p>Transfer learning involves adapting a pre-trained model to novel downstream\ntasks. However, we observe that current transfer learning methods often fail to\nfocus on task-relevant features. In this work, we emphasize the importance of\nrefocusing the attention in transfer learning. We introduce Top-Down Attention\nSteering (TOAST), a novel transfer learning algorithm that keeps the\npre-trained backbone frozen, while selecting the task-relevant elements in the\noutput and feeding them back to the model to steer its attention to the\ntask-specific features. By refocusing the attention only, TOAST achieves\nstate-of-the-art results on a number of transfer learning benchmarks, while\nhaving a small portion of tunable parameters. Compared to fully fine-tuning,\nLoRA, and prompt tuning, TOAST substantially improves performance across a\nrange of fine-grained visual classification datasets (e.g., 81.1% -&gt; 86.2% on\nFGVC). TOAST also outperforms the fully fine-tuned Alpaca model on\ninstruction-following language generation. Code is available at\nhttps://github.com/bfshi/TOAST.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Baifeng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_S/0/1/0/all/0/1\">Siyu Gai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Balancing Effect of Training Dataset Distribution of Multiple Styles for Multi-Style Text Transfer. (arXiv:2305.15582v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15582","description":"<p>Text style transfer is an exciting task within the field of natural language\ngeneration that is often plagued by the need for high-quality paired datasets.\nFurthermore, training a model for multi-attribute text style transfer requires\ndatasets with sufficient support across all combinations of the considered\nstylistic attributes, adding to the challenges of training a style transfer\nmodel. This paper explores the impact of training data input diversity on the\nquality of the generated text from the multi-style transfer model. We construct\na pseudo-parallel dataset by devising heuristics to adjust the style\ndistribution in the training samples. We balance our training dataset using\nmarginal and joint distributions to train our style transfer models. We observe\nthat a balanced dataset produces more effective control effects over multiple\nstyles than an imbalanced or skewed one. Through quantitative analysis, we\nexplore the impact of multiple style distributions in training data on\nstyle-transferred output. These findings will better inform the design of\nstyle-transfer datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1\">Debarati Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">David Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How do humans perceive adversarial text? A reality check on the validity and naturalness of word-based adversarial attacks. (arXiv:2305.15587v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15587","description":"<p>Natural Language Processing (NLP) models based on Machine Learning (ML) are\nsusceptible to adversarial attacks -- malicious algorithms that imperceptibly\nmodify input text to force models into making incorrect predictions. However,\nevaluations of these attacks ignore the property of imperceptibility or study\nit under limited settings. This entails that adversarial perturbations would\nnot pass any human quality gate and do not represent real threats to\nhuman-checked NLP systems. To bypass this limitation and enable proper\nassessment (and later, improvement) of NLP model robustness, we have surveyed\n378 human participants about the perceptibility of text adversarial examples\nproduced by state-of-the-art methods. Our results underline that existing text\nattacks are impractical in real-world scenarios where humans are involved. This\ncontrasts with previous smaller-scale human studies, which reported overly\noptimistic conclusions regarding attack success. Through our work, we hope to\nposition human perceptibility as a first-class success criterion for text\nattacks, and provide guidance for research to build effective attack algorithms\nand, in turn, design appropriate defence mechanisms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dyrmishi_S/0/1/0/all/0/1\">Salijona Dyrmishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghamizi_S/0/1/0/all/0/1\">Salah Ghamizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cordy_M/0/1/0/all/0/1\">Maxime Cordy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models. (arXiv:2305.15594v1 [cs.LG])","link":"http://arxiv.org/abs/2305.15594","description":"<p>Large language models (LLMs) are excellent in-context learners. However, the\nsensitivity of data contained in prompts raises privacy concerns. Our work\nfirst shows that these concerns are valid: we instantiate a simple but highly\neffective membership inference attack against the data used to prompt LLMs. To\naddress this vulnerability, one could forego prompting and resort to\nfine-tuning LLMs with known algorithms for private gradient descent. However,\nthis comes at the expense of the practicality and efficiency offered by\nprompting. Therefore, we propose to privately learn to prompt. We first show\nthat soft prompts can be obtained privately through gradient descent on\ndownstream data. However, this is not the case for discrete prompts. Thus, we\norchestrate a noisy vote among an ensemble of LLMs presented with different\nprompts, i.e., a flock of stochastic parrots. The vote privately transfers the\nflock's knowledge into a single public prompt. We show that LLMs prompted with\nour private algorithms closely match the non-private baselines. For example,\nusing GPT3 as the base model, we achieve a downstream accuracy of 92.7% on the\nsst2 dataset with ($\\epsilon=0.147, \\delta=10^{-6}$)-differential privacy vs.\n95.2% for the non-private baseline. Through our experiments, we also show that\nour prompt-based approach is easily deployed with existing commercial APIs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Duan_H/0/1/0/all/0/1\">Haonan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziedzic_A/0/1/0/all/0/1\">Adam Dziedzic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1\">Nicolas Papernot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boenisch_F/0/1/0/all/0/1\">Franziska Boenisch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-Augmented Open Knowledge Graph Completion via Pre-Trained Language Models. (arXiv:2305.15597v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15597","description":"<p>The mission of open knowledge graph (KG) completion is to draw new findings\nfrom known facts. Existing works that augment KG completion require either (1)\nfactual triples to enlarge the graph reasoning space or (2) manually designed\nprompts to extract knowledge from a pre-trained language model (PLM),\nexhibiting limited performance and requiring expensive efforts from experts. To\nthis end, we propose TAGREAL that automatically generates quality query prompts\nand retrieves support information from large text corpora to probe knowledge\nfrom PLM for KG completion. The results show that TAGREAL achieves\nstate-of-the-art performance on two benchmark datasets. We find that TAGREAL\nhas superb performance even with limited training data, outperforming existing\nembedding-based, graph-based, and PLM-based methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1\">Pengcheng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Shivam Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bowen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Sentence Union Generation as a Testbed for Text Consolidation. (arXiv:2305.15605v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15605","description":"<p>Tasks involving text generation based on multiple input texts, such as\nmulti-document summarization, long-form question answering and contemporary\ndialogue applications, challenge models for their ability to properly\nconsolidate partly-overlapping multi-text information. However, these tasks\nentangle the consolidation phase with the often subjective and ill-defined\ncontent selection requirement, impeding proper assessment of models'\nconsolidation capabilities. In this paper, we suggest revisiting the sentence\nunion generation task as an effective well-defined testbed for assessing text\nconsolidation capabilities, decoupling the consolidation challenge from\nsubjective content selection. To support research on this task, we present\nrefined annotation methodology and tools for crowdsourcing sentence union,\ncreate the largest union dataset to date and provide an analysis of its rich\ncoverage of various consolidation aspects. We then propose a comprehensive\nevaluation protocol for union generation, including both human and automatic\nevaluation. Finally, as baselines, we evaluate state-of-the-art language models\non the task, along with a detailed analysis of their capacity to address\nmulti-text consolidation challenges and their limitations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_E/0/1/0/all/0/1\">Eran Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolhandler_R/0/1/0/all/0/1\">Ruben Wolhandler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shefer_A/0/1/0/all/0/1\">Asi Shefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Morphological Inflection: A Reality Check. (arXiv:2305.15637v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15637","description":"<p>Morphological inflection is a popular task in sub-word NLP with both\npractical and cognitive applications. For years now, state-of-the-art systems\nhave reported high, but also highly variable, performance across data sets and\nlanguages. We investigate the causes of this high performance and high\nvariability; we find several aspects of data set creation and evaluation which\nsystematically inflate performance and obfuscate differences between languages.\nTo improve generalizability and reliability of results, we propose new data\nsampling and evaluation strategies that better reflect likely use-cases. Using\nthese new strategies, we make new observations on the generalization abilities\nof current inflection systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kodner_J/0/1/0/all/0/1\">Jordan Kodner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Payne_S/0/1/0/all/0/1\">Sarah Payne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_S/0/1/0/all/0/1\">Salam Khalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zoey Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConvGQR: Generative Query Reformulation for Conversational Search. (arXiv:2305.15645v1 [cs.IR])","link":"http://arxiv.org/abs/2305.15645","description":"<p>In conversational search, the user's real search intent for the current turn\nis dependent on the previous conversation history. It is challenging to\ndetermine a good search query from the whole conversation context. To avoid the\nexpensive re-training of the query encoder, most existing methods try to learn\na rewriting model to de-contextualize the current query by mimicking the manual\nquery rewriting. However, manually rewritten queries are not always the best\nsearch queries. Training a rewriting model on them would limit the model's\nability to produce good search queries. Another useful hint is the potential\nanswer to the question. In this paper, we propose ConvGQR, a new framework to\nreformulate conversational queries based on generative pre-trained language\nmodels (PLMs), one for query rewriting and another for generating potential\nanswers. By combining both, ConvGQR can produce better search queries. In\naddition, to relate query reformulation to retrieval performance, we propose a\nknowledge infusion mechanism to optimize both query reformulation and\nretrieval. Extensive experiments on four conversational search datasets\ndemonstrate the effectiveness of ConvGQR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mo_F/0/1/0/all/0/1\">Fengran Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_K/0/1/0/all/0/1\">Kelong Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yutao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yihong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaiyu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mixture-of-Expert Conformer for Streaming Multilingual ASR. (arXiv:2305.15663v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15663","description":"<p>End-to-end models with large capacity have significantly improved\nmultilingual automatic speech recognition, but their computation cost poses\nchallenges for on-device applications. We propose a streaming truly\nmultilingual Conformer incorporating mixture-of-expert (MoE) layers that learn\nto only activate a subset of parameters in training and inference. The MoE\nlayer consists of a softmax gate which chooses the best two experts among many\nin forward propagation. The proposed MoE layer offers efficient inference by\nactivating a fixed number of parameters as the number of experts increases. We\nevaluate the proposed model on a set of 12 languages, and achieve an average\n11.9% relative improvement in WER over the baseline. Compared to an adapter\nmodel using ground truth information, our MoE model achieves similar WER and\nactivates similar number of parameters but without any language information. We\nfurther show around 3% relative WER improvement by multilingual shallow fusion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Ke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beaufays_F/0/1/0/all/0/1\">Francoise Beaufays</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BookGPT: A General Framework for Book Recommendation Empowered by Large Language Model. (arXiv:2305.15673v1 [cs.IR])","link":"http://arxiv.org/abs/2305.15673","description":"<p>With the continuous development and change exhibited by large language model\n(LLM) technology, represented by generative pretrained transformers (GPTs),\nmany classic scenarios in various fields have re-emerged with new\nopportunities. This paper takes ChatGPT as the modeling object, incorporates\nLLM technology into the typical book resource understanding and recommendation\nscenario for the first time, and puts it into practice. By building a\nChatGPT-like book recommendation system (BookGPT) framework based on ChatGPT,\nthis paper attempts to apply ChatGPT to recommendation modeling for three\ntypical tasks, book rating recommendation, user rating recommendation, and book\nsummary recommendation, and explores the feasibility of LLM technology in book\nrecommendation scenarios. At the same time, based on different evaluation\nschemes for book recommendation tasks and the existing classic recommendation\nmodels, this paper discusses the advantages and disadvantages of the BookGPT in\nbook recommendation scenarios and analyzes the opportunities and improvement\ndirections for subsequent LLMs in these scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhiyuli_A/0/1/0/all/0/1\">Aakas Zhiyuli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanfang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xun Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Grammatical Error Correction Systems with Explanations. (arXiv:2305.15676v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15676","description":"<p>Grammatical error correction systems improve written communication by\ndetecting and correcting language mistakes. To help language learners better\nunderstand why the GEC system makes a certain correction, the causes of errors\n(evidence words) and the corresponding error types are two key factors. To\nenhance GEC systems with explanations, we introduce EXPECT, a large dataset\nannotated with evidence words and grammatical error types. We propose several\nbaselines and anlysis to understand this task. Furthermore, human evaluation\nverifies our explainable GEC system's explanations can assist second-language\nlearners in determining whether to accept a correction suggestion and in\nunderstanding the associated grammar rule.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yuejiao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting non-English Text Simplification: A Unified Multilingual Benchmark. (arXiv:2305.15678v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15678","description":"<p>Recent advancements in high-quality, large-scale English resources have\npushed the frontier of English Automatic Text Simplification (ATS) research.\nHowever, less work has been done on multilingual text simplification due to the\nlack of a diverse evaluation benchmark that covers complex-simple sentence\npairs in many languages. This paper introduces the MultiSim benchmark, a\ncollection of 27 resources in 12 distinct languages containing over 1.7 million\ncomplex-simple sentence pairs. This benchmark will encourage research in\ndeveloping more effective multilingual text simplification models and\nevaluation metrics. Our experiments using MultiSim with pre-trained\nmultilingual language models reveal exciting performance improvements from\nmultilingual training in non-English settings. We observe strong performance\nfrom Russian in zero-shot cross-lingual transfer to low-resource languages. We\nfurther show that few-shot prompting with BLOOM-176b achieves comparable\nquality to reference simplifications outperforming fine-tuned models in most\nlanguages. We validate these findings through human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ryan_M/0/1/0/all/0/1\">Michael J. Ryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naous_T/0/1/0/all/0/1\">Tarek Naous</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Perturbation-based Self-supervised Attention for Attention Bias in Text Classification. (arXiv:2305.15684v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15684","description":"<p>In text classification, the traditional attention mechanisms usually focus\ntoo much on frequent words, and need extensive labeled data in order to learn.\nThis paper proposes a perturbation-based self-supervised attention approach to\nguide attention learning without any annotation overhead. Specifically, we add\nas much noise as possible to all the words in the sentence without changing\ntheir semantics and predictions. We hypothesize that words that tolerate more\nnoise are less significant, and we can use this information to refine the\nattention distribution. Experimental results on three text classification tasks\nshow that our approach can significantly improve the performance of current\nattention-based models, and is more effective than existing self-supervised\nmethods. We also provide a visualization analysis to verify the effectiveness\nof our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Huawen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhenxi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1\">Qianli Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting. (arXiv:2305.15685v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15685","description":"<p>Large Language Models (LLMs) have demonstrated impressive zero-shot\ncapabilities in long-form text generation tasks expressed through natural\nlanguage instructions. However, user expectations for long-form text rewriting\nis high, and unintended rewrites (''hallucinations'') produced by the model can\nnegatively impact its overall performance. Existing evaluation benchmarks\nprimarily focus on limited rewriting styles and sentence-level rewriting rather\nthan long-form open-ended rewriting.We introduce OpenRewriteEval, a novel\nbenchmark that covers a wide variety of rewriting types expressed through\nnatural language instructions. It is specifically designed to facilitate the\nevaluation of open-ended rewriting of long-form texts. In addition, we propose\na strong baseline model, RewriteLM, an instruction-tuned large language model\nfor long-form text rewriting. We develop new strategies that facilitate the\ngeneration of diverse instructions and preference data with minimal human\nintervention. We conduct empirical experiments and demonstrate that our model\noutperforms the current state-of-the-art LLMs in text rewriting. Specifically,\nit excels in preserving the essential content and meaning of the source text,\nminimizing the generation of ''hallucinated'' content, while showcasing the\nability to generate rewrites with diverse wording and structures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shu_L/0/1/0/all/0/1\">Lei Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Liangchen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoskere_J/0/1/0/all/0/1\">Jayakumar Hoskere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Canoee Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Simon Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jindong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1\">Lei Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts. (arXiv:2305.15689v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15689","description":"<p>Recent studies have demonstrated that natural-language prompts can help to\nleverage the knowledge learned by pre-trained language models for the binary\nsentence-level sentiment classification task. Specifically, these methods\nutilize few-shot learning settings to fine-tune the sentiment classification\nmodel using manual or automatically generated prompts. However, the performance\nof these methods is sensitive to the perturbations of the utilized prompts.\nFurthermore, these methods depend on a few labeled instances for automatic\nprompt generation and prompt ranking. This study aims to find high-quality\nprompts for the given task in a zero-shot setting. Given a base prompt, our\nproposed approach automatically generates multiple prompts similar to the base\nprompt employing positional, reasoning, and paraphrasing techniques and then\nranks the prompts using a novel metric. We empirically demonstrate that the\ntop-ranked prompts are high-quality and significantly outperform the base\nprompt and the prompts generated using few-shot learning for the binary\nsentence-level sentiment classification task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Mohna Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Adithya Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The False Promise of Imitating Proprietary LLMs. (arXiv:2305.15717v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15717","description":"<p>An emerging method to cheaply improve a weaker language model is to finetune\nit on outputs from a stronger model, such as a proprietary system like ChatGPT\n(e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply\nimitate the proprietary model's capabilities using a weaker open-source model.\nIn this work, we critically analyze this approach. We first finetune a series\nof LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data\nsources, and imitation data amounts (0.3M--150M tokens). We then evaluate the\nmodels using crowd raters and canonical NLP benchmarks. Initially, we were\nsurprised by the output quality of our imitation models -- they appear far\nbetter at following instructions, and crowd workers rate their outputs as\ncompetitive with ChatGPT. However, when conducting more targeted automatic\nevaluations, we find that imitation models close little to none of the gap from\nthe base LM to ChatGPT on tasks that are not heavily supported in the imitation\ndata. We show that these performance discrepancies may slip past human raters\nbecause imitation models are adept at mimicking ChatGPT's style but not its\nfactuality. Overall, we conclude that model imitation is a false promise: there\nexists a substantial capabilities gap between open and closed LMs that, with\ncurrent methods, can only be bridged using an unwieldy amount of imitation data\nor by using more capable base LMs. In turn, we argue that the highest leverage\naction for improving open-source models is to tackle the difficult challenge of\ndeveloping better base LMs, rather than taking the shortcut of imitating\nproprietary systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gudibande_A/0/1/0/all/0/1\">Arnav Gudibande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snell_C/0/1/0/all/0/1\">Charlie Snell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xinyang Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawn Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Higher Pareto Frontier in Multilingual Machine Translation. (arXiv:2305.15718v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15718","description":"<p>Multilingual neural machine translation has witnessed remarkable progress in\nrecent years. However, the long-tailed distribution of multilingual corpora\nposes a challenge of Pareto optimization, i.e., optimizing for some languages\nmay come at the cost of degrading the performance of others. Existing balancing\ntraining strategies are equivalent to a series of Pareto optimal solutions,\nwhich trade off on a Pareto frontier. In this work, we propose a new training\nframework, Pareto Mutual Distillation (Pareto-MD), towards pushing the Pareto\nfrontier outwards rather than making trade-offs. Specifically, Pareto-MD\ncollaboratively trains two Pareto optimal solutions that favor different\nlanguages and allows them to learn from the strengths of each other via\nknowledge distillation. Furthermore, we introduce a novel strategy to enable\nstronger communication between Pareto optimal solutions and broaden the\napplicability of our approach. Experimental results on the widely-used WMT and\nTED datasets show that our method significantly pushes the Pareto frontier and\noutperforms baselines by up to +2.46 BLEU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yichong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaocheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xinwei Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baohang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Study of Pre-Trained BERT Models for Code-Mixed Hindi-English Data. (arXiv:2305.15722v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15722","description":"<p>The term \"Code Mixed\" refers to the use of more than one language in the same\ntext. This phenomenon is predominantly observed on social media platforms, with\nan increasing amount of adaptation as time goes on. It is critical to detect\nforeign elements in a language and process them correctly, as a considerable\nnumber of individuals are using code-mixed languages that could not be\ncomprehended by understanding one of those languages. In this work, we focus on\nlow-resource Hindi-English code-mixed language and enhancing the performance of\ndifferent code-mixed natural language processing tasks such as sentiment\nanalysis, emotion recognition, and hate speech identification. We perform a\ncomparative analysis of different Transformer-based language Models pre-trained\nusing unsupervised approaches. We have included the code-mixed models like\nHingBERT, HingRoBERTa, HingRoBERTa-Mixed, mBERT, and non-code-mixed models like\nAlBERT, BERT, and RoBERTa for comparative analysis of code-mixed Hindi-English\ndownstream tasks. We report state-of-the-art results on respective datasets\nusing HingBERT-based models which are specifically pre-trained on real\ncode-mixed text. Our HingBERT-based models provide significant improvements\nthus highlighting the poor performance of vanilla BERT models on code-mixed\ntext.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1\">Aryan Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwardhan_V/0/1/0/all/0/1\">Varad Patwardhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phaltankar_A/0/1/0/all/0/1\">Abhishek Phaltankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takawane_G/0/1/0/all/0/1\">Gauri Takawane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learn to Not Link: Exploring NIL Prediction in Entity Linking. (arXiv:2305.15725v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15725","description":"<p>Entity linking models have achieved significant success via utilizing\npretrained language models to capture semantic features. However, the NIL\nprediction problem, which aims to identify mentions without a corresponding\nentity in the knowledge base, has received insufficient attention. We\ncategorize mentions linking to NIL into Missing Entity and Non-Entity Phrase,\nand propose an entity linking dataset NEL that focuses on the NIL prediction\nproblem. NEL takes ambiguous entities as seeds, collects relevant mention\ncontext in the Wikipedia corpus, and ensures the presence of mentions linking\nto NIL by human annotation and entity masking. We conduct a series of\nexperiments with the widely used bi-encoder and cross-encoder entity linking\nmodels, results show that both types of NIL mentions in training data have a\nsignificant influence on the accuracy of NIL prediction. Our code and dataset\ncan be accessed at https://github.com/solitaryzero/NIL_EL\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1\">Fangwei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hailong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Text-to-Speech Synthesis for Turkic Languages Using Transliteration. (arXiv:2305.15749v1 [eess.AS])","link":"http://arxiv.org/abs/2305.15749","description":"<p>This work aims to build a multilingual text-to-speech (TTS) synthesis system\nfor ten lower-resourced Turkic languages: Azerbaijani, Bashkir, Kazakh, Kyrgyz,\nSakha, Tatar, Turkish, Turkmen, Uyghur, and Uzbek. We specifically target the\nzero-shot learning scenario, where a TTS model trained using the data of one\nlanguage is applied to synthesise speech for other, unseen languages. An\nend-to-end TTS system based on the Tacotron 2 architecture was trained using\nonly the available data of the Kazakh language. To generate speech for the\nother Turkic languages, we first mapped the letters of the Turkic alphabets\nonto the symbols of the International Phonetic Alphabet (IPA), which were then\nconverted to the Kazakh alphabet letters. To demonstrate the feasibility of the\nproposed approach, we evaluated the multilingual Turkic TTS model subjectively\nand obtained promising results. To enable replication of the experiments, we\nmake our code and dataset publicly available in our GitHub repository.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yeshpanov_R/0/1/0/all/0/1\">Rustem Yeshpanov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mussakhojayeva_S/0/1/0/all/0/1\">Saida Mussakhojayeva</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khassanov_Y/0/1/0/all/0/1\">Yerbolat Khassanov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniTRec: A Unified Text-to-Text Transformer and Joint Contrastive Learning Framework for Text-based Recommendation. (arXiv:2305.15756v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15756","description":"<p>Prior study has shown that pretrained language models (PLM) can boost the\nperformance of text-based recommendation. In contrast to previous works that\neither use PLM to encode user history as a whole input text, or impose an\nadditional aggregation network to fuse multi-turn history representations, we\npropose a unified local- and global-attention Transformer encoder to better\nmodel two-level contexts of user history. Moreover, conditioned on user history\nencoded by Transformer encoders, our framework leverages Transformer decoders\nto estimate the language perplexity of candidate text items, which can serve as\na straightforward yet significant contrastive signal for user-item text\nmatching. Based on this, our framework, UniTRec, unifies the contrastive\nobjectives of discriminative matching scores and candidate text perplexity to\njointly enhance text-based recommendation. Extensive evaluation shows that\nUniTRec delivers SOTA performance on three text-based recommendation tasks.\nCode is available at https://github.com/Veason-silverbullet/UniTRec.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhiming Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huimin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yiming Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Healing Unsafe Dialogue Responses with Weak Supervision Signals. (arXiv:2305.15757v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15757","description":"<p>Recent years have seen increasing concerns about the unsafe response\ngeneration of large-scale dialogue systems, where agents will learn offensive\nor biased behaviors from the real-world corpus. Some methods are proposed to\naddress the above issue by detecting and replacing unsafe training examples in\na pipeline style. Though effective, they suffer from a high annotation cost and\nadapt poorly to unseen scenarios as well as adversarial attacks. Besides, the\nneglect of providing safe responses (e.g. simply replacing with templates) will\ncause the information-missing problem of dialogues. To address these issues, we\npropose an unsupervised pseudo-label sampling method, TEMP, that can\nautomatically assign potential safe responses. Specifically, our TEMP method\ngroups responses into several clusters and samples multiple labels with an\nadaptively sharpened sampling strategy, inspired by the observation that unsafe\nsamples in the clusters are usually few and distribute in the tail. Extensive\nexperiments in chitchat and task-oriented dialogues show that our TEMP\noutperforms state-of-the-art models with weak supervision signals and obtains\ncomparable results under unsupervised learning settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pinghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaofan Ye Yi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Junlan Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Svarah: Evaluating English ASR Systems on Indian Accents. (arXiv:2305.15760v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15760","description":"<p>India is the second largest English-speaking country in the world with a\nspeaker base of roughly 130 million. Thus, it is imperative that automatic\nspeech recognition (ASR) systems for English should be evaluated on Indian\naccents. Unfortunately, Indian speakers find a very poor representation in\nexisting English ASR benchmarks such as LibriSpeech, Switchboard, Speech Accent\nArchive, etc. In this work, we address this gap by creating Svarah, a benchmark\nthat contains 9.6 hours of transcribed English audio from 117 speakers across\n65 geographic locations throughout India, resulting in a diverse range of\naccents. Svarah comprises both read speech and spontaneous conversational data,\ncovering various domains, such as history, culture, tourism, etc., ensuring a\ndiverse vocabulary. We evaluate 6 open source ASR models and 2 commercial ASR\nsystems on Svarah and show that there is clear scope for improvement on Indian\naccents. Svarah as well as all our code will be publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Javed_T/0/1/0/all/0/1\">Tahir Javed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Sakshi Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagarajan_V/0/1/0/all/0/1\">Vignesh Nagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_S/0/1/0/all/0/1\">Sai Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nawale_J/0/1/0/all/0/1\">Janki Nawale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_A/0/1/0/all/0/1\">Abhigyan Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhogale_K/0/1/0/all/0/1\">Kaushal Bhogale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MERGE: Fast Private Text Generation. (arXiv:2305.15769v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15769","description":"<p>Recent years have seen increasing concerns about the private inference of NLP\nservices and Transformer models. However, existing two-party privacy-preserving\nmethods solely consider NLU scenarios, while the private inference of text\ngeneration such as translation, dialogue, and code completion remains unsolved.\nBesides, while migrated to NLG models, existing privacy-preserving methods\nperform poorly in terms of inference speed, and suffer from the convergence\nproblem during the training stage. To address these issues, we propose MERGE, a\nfast private text generation framework for Transformer-based language models.\nSpecifically, MERGE reuse the output hidden state as the word embedding to\nbypass the embedding computation, and reorganize the linear operations in the\nTransformer module to accelerate the forward procedure. Based on these two\noptimizations, extensive experiments show that MERGE can achieve a 26.5x\nspeedup under the sequence length 512, and reduce 80\\% communication bytes,\nwith an up to 10x speedup to existing state-of-art models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pinghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers. (arXiv:2305.15805v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15805","description":"<p>Autoregressive Transformers adopted in Large Language Models (LLMs) are hard\nto scale to long sequences. Despite several works trying to reduce their\ncomputational cost, most of LLMs still adopt attention layers between all pairs\nof tokens in the sequence, thus incurring a quadratic cost. In this study, we\npresent a novel approach that dynamically prunes contextual information while\npreserving the model's expressiveness, resulting in reduced memory and\ncomputational requirements during inference. Our method employs a learnable\nmechanism that determines which uninformative tokens can be dropped from the\ncontext at any point across the generation process. By doing so, our approach\nnot only addresses performance concerns but also enhances interpretability,\nproviding valuable insight into the model's decision-making process. Our\ntechnique can be applied to existing pre-trained models through a\nstraightforward fine-tuning process, and the pruning strength can be specified\nby a sparsity parameter. Notably, our empirical findings demonstrate that we\ncan effectively prune up to 80\\% of the context without significant performance\ndegradation on downstream tasks, offering a valuable tool for mitigating\ninference costs. Our reference implementation achieves up to $2\\times$ increase\nin inference throughput and even greater memory savings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Anagnostidis_S/0/1/0/all/0/1\">Sotiris Anagnostidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavllo_D/0/1/0/all/0/1\">Dario Pavllo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biggio_L/0/1/0/all/0/1\">Luca Biggio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noci_L/0/1/0/all/0/1\">Lorenzo Noci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1\">Aurelien Lucchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_T/0/1/0/all/0/1\">Thomas Hoffmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bhasha-Abhijnaanam: Native-script and romanized Language Identification for 22 Indic languages. (arXiv:2305.15814v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15814","description":"<p>We create publicly available language identification (LID) datasets and\nmodels in all 22 Indian languages listed in the Indian constitution in both\nnative-script and romanized text. First, we create Bhasha-Abhijnaanam, a\nlanguage identification test set for native-script as well as romanized text\nwhich spans all 22 Indic languages. We also train IndicLID, a language\nidentifier for all the above-mentioned languages in both native and romanized\nscript. For native-script text, it has better language coverage than existing\nLIDs and is competitive or better than other LIDs. IndicLID is the first LID\nfor romanized text in Indian languages. Two major challenges for romanized text\nLID are the lack of training data and low-LID performance when languages are\nsimilar. We provide simple and effective solutions to these problems. In\ngeneral, there has been limited work on romanized text in any language, and our\nfindings are relevant to other languages that need romanized language\nidentification. Our models are publicly available at\nhttps://github.com/AI4Bharat/IndicLID under open-source licenses. Our training\nand test sets are also publicly available at\nhttps://huggingface.co/datasets/ai4bharat/Bhasha-Abhijnaanam under open-source\nlicenses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madhani_Y/0/1/0/all/0/1\">Yash Madhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-contradictory Hallucinations of Large Language Models: Evaluation, Detection and Mitigation. (arXiv:2305.15852v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15852","description":"<p>Large language models (large LMs) are susceptible to producing text with\nhallucinated content. Self-contradiction, where the LM generates two\ncontradictory sentences within the same context, is an important form of\nhallucination. In this work, we present a comprehensive analysis on\nself-contradiction for state-of-the-art, instruction-tuned LMs, including\nevaluation, detection, and mitigation. To effectively trigger\nself-contradictions, we design a framework that constrains LMs to generate\nappropriate sentence pairs. Our evaluation on these sentence pairs reveals that\nself-contradictions occur frequently across different LMs for both famous and\nlesser-known topics. Next, we prompt the LMs to detect self-contradictions. Our\nresults indicate that ChatGPT and GPT-4 are able to accurately identify\nself-contradictions, while Vicuna-13B struggles to do so. For example, with our\nbest prompting method, ChatGPT achieves 91.0% precision and 80.5% recall on the\nsentence pairs generated by itself. To automatically mitigate\nself-contradictions, we develop an iterative algorithm that prompts the LMs to\nremove the detected self-contradictions from the generated text. Our algorithm\nsuccessfully revises the text such that self-contradictions are significantly\nreduced, while maintaining its fluency and informativeness. Importantly, our\nentire pipeline of triggering, detecting, and mitigating self-contradictions is\napplicable to black-box LMs and does not require any external grounded\nknowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mundler_N/0/1/0/all/0/1\">Niels M&#xfc;ndler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingxuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jenko_S/0/1/0/all/0/1\">Slobodan Jenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sequential Integrated Gradients: a simple but effective method for explaining language models. (arXiv:2305.15853v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15853","description":"<p>Several explanation methods such as Integrated Gradients (IG) can be\ncharacterised as path-based methods, as they rely on a straight line between\nthe data and an uninformative baseline. However, when applied to language\nmodels, these methods produce a path for each word of a sentence\nsimultaneously, which could lead to creating sentences from interpolated words\neither having no clear meaning, or having a significantly different meaning\ncompared to the original sentence. In order to keep the meaning of these\nsentences as close as possible to the original one, we propose Sequential\nIntegrated Gradients (SIG), which computes the importance of each word in a\nsentence by keeping fixed every other words, only creating interpolations\nbetween the baseline and the word of interest. Moreover, inspired by the\ntraining procedure of several language models, we also propose to replace the\nbaseline token \"pad\" with the trained token \"mask\". While being a simple\nimprovement over the original IG method, we show on various models and datasets\nthat SIG proves to be a very effective method for explaining language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Enguehard_J/0/1/0/all/0/1\">Joseph Enguehard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extracting Text Representations for Terms and Phrases in Technical Domains. (arXiv:2305.15867v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15867","description":"<p>Extracting dense representations for terms and phrases is a task of great\nimportance for knowledge discovery platforms targeting highly-technical fields.\nDense representations are used as features for downstream components and have\nmultiple applications ranging from ranking results in search to summarization.\nCommon approaches to create dense representations include training\ndomain-specific embeddings with self-supervised setups or using sentence\nencoder models trained over similarity tasks. In contrast to static embeddings,\nsentence encoders do not suffer from the out-of-vocabulary (OOV) problem, but\nimpose significant computational costs. In this paper, we propose a fully\nunsupervised approach to text encoding that consists of training small\ncharacter-based models with the objective of reconstructing large pre-trained\nembedding matrices. Models trained with this approach can not only match the\nquality of sentence encoders in technical domains, but are 5 times smaller and\nup to 10 times faster, even on high-end GPUs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Francesco Fusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1\">Diego Antognini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jointprop: Joint Semi-supervised Learning for Entity and Relation Extraction with Heterogeneous Graph-based Propagation. (arXiv:2305.15872v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15872","description":"<p>Semi-supervised learning has been an important approach to address challenges\nin extracting entities and relations from limited data. However, current\nsemi-supervised works handle the two tasks (i.e., Named Entity Recognition and\nRelation Extraction) separately and ignore the cross-correlation of entity and\nrelation instances as well as the existence of similar instances across\nunlabeled data. To alleviate the issues, we propose Jointprop, a Heterogeneous\nGraph-based Propagation framework for joint semi-supervised entity and relation\nextraction, which captures the global structure information between individual\ntasks and exploits interactions within unlabeled data. Specifically, we\nconstruct a unified span-based heterogeneous graph from entity and relation\ncandidates and propagate class labels based on confidence scores. We then\nemploy a propagation learning scheme to leverage the affinities between\nlabelled and unlabeled samples. Experiments on benchmark datasets show that our\nframework outperforms the state-of-the-art semi-supervised approaches on NER\nand RE tasks. We show that the joint semi-supervised learning of the two tasks\nbenefits from their codependency and validates the importance of utilizing the\nshared information between unlabeled data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yandan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_A/0/1/0/all/0/1\">Anran Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic Properties of Truthful Response. (arXiv:2305.15875v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15875","description":"<p>We investigate the phenomenon of an LLM's untruthful response using a large\nset of 220 handcrafted linguistic features. We focus on GPT-3 models and find\nthat the linguistic profiles of responses are similar across model sizes. That\nis, how varying-sized LLMs respond to given prompts stays similar on the\nlinguistic properties level. We expand upon this finding by training support\nvector machines that rely only upon the stylistic components of model responses\nto classify the truthfulness of statements. Though the dataset size limits our\ncurrent findings, we present promising evidence that truthfulness detection is\npossible without evaluating the content itself.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Bruce W. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arockiaraj_B/0/1/0/all/0/1\">Benedict Florance Arockiaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Helen Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LFTK: Handcrafted Features in Computational Linguistics. (arXiv:2305.15878v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15878","description":"<p>Past research has identified a rich set of handcrafted linguistic features\nthat can potentially assist various tasks. However, their extensive number\nmakes it difficult to effectively select and utilize existing handcrafted\nfeatures. Coupled with the problem of inconsistent implementation across\nresearch works, there has been no categorization scheme or generally-accepted\nfeature names. This creates unwanted confusion. Also, most existing handcrafted\nfeature extraction libraries are not open-source or not actively maintained. As\na result, a researcher often has to build such an extraction system from the\nground up.\n</p>\n<p>We collect and categorize more than 220 popular handcrafted features grounded\non past literature. Then, we conduct a correlation analysis study on several\ntask-specific datasets and report the potential use cases of each feature.\nLastly, we devise a multilingual handcrafted linguistic feature extraction\nsystem in a systematically expandable manner. We open-source our system for\npublic access to a rich set of pre-implemented handcrafted features. Our system\nis coined LFTK and is the largest of its kind. Find it at\ngithub.com/brucewlee/lftk.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1\">Bruce W. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason Hyung-Jong Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CSS: A Large-scale Cross-schema Chinese Text-to-SQL Medical Dataset. (arXiv:2305.15891v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15891","description":"<p>The cross-domain text-to-SQL task aims to build a system that can parse user\nquestions into SQL on complete unseen databases, and the single-domain\ntext-to-SQL task evaluates the performance on identical databases. Both of\nthese setups confront unavoidable difficulties in real-world applications. To\nthis end, we introduce the cross-schema text-to-SQL task, where the databases\nof evaluation data are different from that in the training data but come from\nthe same domain. Furthermore, we present CSS, a large-scale CrosS-Schema\nChinese text-to-SQL dataset, to carry on corresponding studies. CSS originally\nconsisted of 4,340 question/SQL pairs across 2 databases. In order to\ngeneralize models to different medical systems, we extend CSS and create 19 new\ndatabases along with 29,280 corresponding dataset examples. Moreover, CSS is\nalso a large corpus for single-domain Chinese text-to-SQL studies. We present\nthe data collection approach and a series of analyses of the data statistics.\nTo show the potential and usefulness of CSS, benchmarking baselines have been\nconducted and reported. Our dataset is publicly available at\n\\url{https://huggingface.co/datasets/zhanghanchong/css}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanchong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jieyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1\">Ruisheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Private Meeting Summarization Without Performance Loss. (arXiv:2305.15894v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15894","description":"<p>Meeting summarization has an enormous business potential, but in addition to\nbeing a hard problem, roll-out is challenged by privacy concerns. We explore\nthe problem of meeting summarization under differential privacy constraints and\nfind, to our surprise, that while differential privacy leads to slightly lower\nperformance on in-sample data, differential privacy improves performance when\nevaluated on unseen meeting types. Since meeting summarization systems will\nencounter a great variety of meeting types in practical employment scenarios,\nthis observation makes safe meeting summarization seem much more feasible. We\nperform extensive error analysis and identify potential risks in meeting\nsummarization under differential privacy, including a faithfulness analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seolhwa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Collective Knowledge Graph Completion with Mutual Knowledge Distillation. (arXiv:2305.15895v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15895","description":"<p>Knowledge graph completion (KGC), the task of predicting missing information\nbased on the existing relational data inside a knowledge graph (KG), has drawn\nsignificant attention in recent years. However, the predictive power of KGC\nmethods is often limited by the completeness of the existing knowledge graphs\nfrom different sources and languages. In monolingual and multilingual settings,\nKGs are potentially complementary to each other. In this paper, we study the\nproblem of multi-KG completion, where we focus on maximizing the collective\nknowledge from different KGs to alleviate the incompleteness of individual KGs.\nSpecifically, we propose a novel method called CKGC-CKD that uses\nrelation-aware graph convolutional network encoder models on both individual\nKGs and a large fused KG in which seed alignments between KGs are regarded as\nedges for message propagation. An additional mutual knowledge distillation\nmechanism is also employed to maximize the knowledge transfer between the\nmodels of \"global\" fused KG and the \"local\" individual KGs. Experimental\nresults on multilingual datasets have shown that our method outperforms all\nstate-of-the-art models in the KGC task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weihang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serban_O/0/1/0/all/0/1\">Ovidiu Serban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiahao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi-ke Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MTCue: Learning Zero-Shot Control of Extra-Textual Attributes by Leveraging Unstructured Context in Neural Machine Translation. (arXiv:2305.15904v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15904","description":"<p>Efficient utilisation of both intra- and extra-textual context remains one of\nthe critical gaps between machine and human translation. Existing research has\nprimarily focused on providing individual, well-defined types of context in\ntranslation, such as the surrounding text or discrete external variables like\nthe speaker's gender. This work introduces MTCue, a novel neural machine\ntranslation (NMT) framework that interprets all context (including discrete\nvariables) as text. MTCue learns an abstract representation of context,\nenabling transferability across different data settings and leveraging similar\nattributes in low-resource scenarios. With a focus on a dialogue domain with\naccess to document and metadata context, we extensively evaluate MTCue in four\nlanguage pairs in both translation directions. Our framework demonstrates\nsignificant improvements in translation quality over a parameter-matched\nnon-contextual baseline, as measured by BLEU (+0.88) and Comet (+1.58).\nMoreover, MTCue significantly outperforms a \"tagging\" baseline at translating\nEnglish text. Analysis reveals that the context encoder of MTCue learns a\nrepresentation space that organises context based on specific attributes, such\nas formality, enabling effective zero-shot control. Pre-training on context\nembeddings also improves MTCue's few-shot performance compared to the \"tagging\"\nbaseline. Finally, an ablation study conducted on model components and\ncontextual variables further supports the robustness of MTCue for context-based\nNMT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vincent_S/0/1/0/all/0/1\">Sebastian Vincent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flynn_R/0/1/0/all/0/1\">Robert Flynn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Response Generation in Longitudinal Dialogues: Which Knowledge Representation Helps?. (arXiv:2305.15908v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15908","description":"<p>Longitudinal Dialogues (LD) are the most challenging type of conversation for\nhuman-machine dialogue systems. LDs include the recollections of events,\npersonal thoughts, and emotions specific to each individual in a sparse\nsequence of dialogue sessions. Dialogue systems designed for LDs should\nuniquely interact with the users over multiple sessions and long periods of\ntime (e.g. weeks), and engage them in personal dialogues to elaborate on their\nfeelings, thoughts, and real-life events. In this paper, we study the task of\nresponse generation in LDs. We evaluate whether general-purpose Pre-trained\nLanguage Models (PLM) are appropriate for this purpose. We fine-tune two PLMs,\nGePpeTto (GPT-2) and iT5, using a dataset of LDs. We experiment with different\nrepresentations of the personal knowledge extracted from LDs for grounded\nresponse generation, including the graph representation of the mentioned events\nand participants. We evaluate the performance of the models via automatic\nmetrics and the contribution of the knowledge via the Integrated Gradients\ntechnique. We categorize the natural language generation errors via human\nevaluations of contextualization, appropriateness and engagement of the user.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1\">Seyed Mahed Mousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caldarella_S/0/1/0/all/0/1\">Simone Caldarella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riccardi_G/0/1/0/all/0/1\">Giuseppe Riccardi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. (arXiv:2305.15913v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15913","description":"<p>Memes are a powerful tool for communication over social media. Their affinity\nfor evolving across politics, history, and sociocultural phenomena makes them\nan ideal communication vehicle. To comprehend the subtle message conveyed\nwithin a meme, one must understand the background that facilitates its holistic\nassimilation. Besides digital archiving of memes and their metadata by a few\nwebsites like knowyourmeme.com, currently, there is no efficient way to deduce\na meme's context dynamically. In this work, we propose a novel task, MEMEX -\ngiven a meme and a related document, the aim is to mine the context that\nsuccinctly explains the background of the meme. At first, we develop MCC (Meme\nContext Corpus), a novel dataset for MEMEX. Further, to benchmark MCC, we\npropose MIME (MultImodal Meme Explainer), a multimodal neural framework that\nuses common sense enriched meme representation and a layered approach to\ncapture the cross-modal semantic dependencies between the meme and the context.\nMIME surpasses several unimodal and multimodal systems and yields an absolute\nimprovement of ~ 4% F1-score over the best baseline. Lastly, we conduct\ndetailed analyses of MIME's performance, highlighting the aspects that could\nlead to optimal modeling of cross-modal contextual associations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_R/0/1/0/all/0/1\">Ramaneswaram S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_U/0/1/0/all/0/1\">Udit Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md. Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliable identification of selection mechanisms in language change. (arXiv:2305.15914v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15914","description":"<p>Language change is a cultural evolutionary process in which variants of\nlinguistic variables change in frequency through processes analogous to\nmutation, selection and genetic drift. In this work, we apply a\nrecently-introduced method to corpus data to quantify the strength of selection\nin specific instances of historical language change. We first demonstrate, in\nthe context of English irregular verbs, that this method is more reliable and\ninterpretable than similar methods that have previously been applied. We\nfurther extend this study to demonstrate that a bias towards phonological\nsimplicity overrides that favouring grammatical simplicity when these are in\nconflict. Finally, with reference to Spanish spelling reforms, we show that the\nmethod can also detect points in time at which selection strengths change, a\nfeature that is generically expected for socially-motivated language change.\nTogether, these results indicate how hypotheses for mechanisms of language\nchange can be tested quantitatively using historical corpus data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Montero_J/0/1/0/all/0/1\">Juan Guerrero Montero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karjus_A/0/1/0/all/0/1\">Andres Karjus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kenny Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blythe_R/0/1/0/all/0/1\">Richard A. Blythe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergence of a phonological bias in ChatGPT. (arXiv:2305.15929v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15929","description":"<p>Current large language models, such as OpenAI's ChatGPT, have captured the\npublic's attention because how remarkable they are in the use of language.\nHere, I demonstrate that ChatGPT displays phonological biases that are a\nhallmark of human language processing. More concretely, just like humans,\nChatGPT has a consonant bias. That is, the chatbot has a tendency to use\nconsonants over vowels to identify words. This is observed across languages\nthat differ in their relative distribution of consonants and vowels such as\nEnglish and Spanish. Despite the differences in how current artificial\nintelligence language models are trained to process linguistic stimuli and how\nhuman infants acquire language, such training seems to be enough for the\nemergence of a phonological bias in ChatGPT\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toro_J/0/1/0/all/0/1\">Juan Manuel Toro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BUCA: A Binary Classification Approach to Unsupervised Commonsense Question Answering. (arXiv:2305.15932v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15932","description":"<p>Unsupervised commonsense reasoning (UCR) is becoming increasingly popular as\nthe construction of commonsense reasoning datasets is expensive, and they are\ninevitably limited in their scope. A popular approach to UCR is to fine-tune\nlanguage models with external knowledge (e.g., knowledge graphs), but this\nusually requires a large number of training examples. In this paper, we propose\nto transform the downstream multiple choice question answering task into a\nsimpler binary classification task by ranking all candidate answers according\nto their reasonableness. To this end, for training the model, we convert the\nknowledge graph triples into reasonable and unreasonable texts. Extensive\nexperimental results show the effectiveness of our approach on various multiple\nchoice question answering benchmarks. Furthermore, compared with existing UCR\napproaches using KGs, ours is less data hungry. Our code is available at\nhttps://github.com/probe2/BUCA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jie He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+U_S/0/1/0/all/0/1\">Simon Chi Lok U</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_Basulto_V/0/1/0/all/0/1\">V&#xed;ctor Guti&#xe9;rrez-Basulto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jeff Z. Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visually grounded few-shot word acquisition with fewer shots. (arXiv:2305.15937v1 [cs.CL])","link":"http://arxiv.org/abs/2305.15937","description":"<p>We propose a visually grounded speech model that acquires new words and their\nvisual depictions from just a few word-image example pairs. Given a set of test\nimages and a spoken query, we ask the model which image depicts the query word.\nPrevious work has simplified this problem by either using an artificial setting\nwith digit word-image pairs or by using a large number of examples per class.\nWe propose an approach that can work on natural word-image pairs but with less\nexamples, i.e. fewer shots. Our approach involves using the given word-image\nexample pairs to mine new unsupervised word-image training pairs from large\ncollections of unlabelled speech and images. Additionally, we use a\nword-to-image attention mechanism to determine word-image similarity. With this\nnew model, we achieve better performance with fewer shots than any existing\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nortje_L/0/1/0/all/0/1\">Leanne Nortje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekerk_B/0/1/0/all/0/1\">Benjamin van Niekerk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"pNLP-Mixer: an Efficient all-MLP Architecture for Language. (arXiv:2202.04350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.04350","description":"<p>Large pre-trained language models based on transformer architecture have\ndrastically changed the natural language processing (NLP) landscape. However,\ndeploying those models for on-device applications in constrained devices such\nas smart watches is completely impractical due to their size and inference\ncost. As an alternative to transformer-based architectures, recent work on\nefficient NLP has shown that weight-efficient models can attain competitive\nperformance for simple tasks, such as slot filling and intent classification,\nwith model sizes in the order of the megabyte. This work introduces the\npNLP-Mixer architecture, an embedding-free MLP-Mixer model for on-device NLP\nthat achieves high weight-efficiency thanks to a novel projection layer. We\nevaluate a pNLP-Mixer model of only one megabyte in size on two multi-lingual\nsemantic parsing datasets, MTOP and multiATIS. Our quantized model achieves\n99.4% and 97.8% the performance of mBERT on MTOP and multi-ATIS, while using\n170x fewer parameters. Our model consistently beats the state-of-the-art of\ntiny models (pQRNN), which is twice as large, by a margin up to 7.8% on MTOP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fusco_F/0/1/0/all/0/1\">Francesco Fusco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pascual_D/0/1/0/all/0/1\">Damian Pascual</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staar_P/0/1/0/all/0/1\">Peter Staar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1\">Diego Antognini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HyperMixer: An MLP-based Low Cost Alternative to Transformers. (arXiv:2203.03691v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.03691","description":"<p>Transformer-based architectures are the model of choice for natural language\nunderstanding, but they come at a significant cost, as they have quadratic\ncomplexity in the input length, require a lot of training data, and can be\ndifficult to tune. In the pursuit of lower costs, we investigate simple\nMLP-based architectures. We find that existing architectures such as MLPMixer,\nwhich achieves token mixing through a static MLP applied to each feature\nindependently, are too detached from the inductive biases required for natural\nlanguage understanding. In this paper, we propose a simple variant, HyperMixer,\nwhich forms the token mixing MLP dynamically using hypernetworks. Empirically,\nwe demonstrate that our model performs better than alternative MLP-based\nmodels, and on par with Transformers. In contrast to Transformers, HyperMixer\nachieves these results at substantially lower costs in terms of processing\ntime, training data, and hyperparameter tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mai_F/0/1/0/all/0/1\">Florian Mai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pannatier_A/0/1/0/all/0/1\">Arnaud Pannatier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fehr_F/0/1/0/all/0/1\">Fabio Fehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haolin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marelli_F/0/1/0/all/0/1\">Francois Marelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleuret_F/0/1/0/all/0/1\">Francois Fleuret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Henderson_J/0/1/0/all/0/1\">James Henderson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Learning of Sociopragmatic Meaning in Social Media. (arXiv:2203.07648v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.07648","description":"<p>Recent progress in representation and contrastive learning in NLP has not\nwidely considered the class of \\textit{sociopragmatic meaning} (i.e., meaning\nin interaction within different language communities). To bridge this gap, we\npropose a novel framework for learning task-agnostic representations\ntransferable to a wide range of sociopragmatic tasks (e.g., emotion, hate\nspeech, humor, sarcasm). Our framework outperforms other contrastive learning\nframeworks for both in-domain and out-of-domain data, across both the general\nand few-shot settings. For example, compared to two popular pre-trained\nlanguage models, our method obtains an improvement of $11.66$ average $F_1$ on\n$16$ datasets when fine-tuned on only $20$ training samples per dataset.Our\ncode is available at: https://github.com/UBC-NLP/infodcl\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chiyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jawahar_G/0/1/0/all/0/1\">Ganesh Jawahar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explore More Guidance: A Task-aware Instruction Network for Sign Language Translation Enhanced with Data Augmentation. (arXiv:2204.05953v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.05953","description":"<p>Sign language recognition and translation first uses a recognition module to\ngenerate glosses from sign language videos and then employs a translation\nmodule to translate glosses into spoken sentences. Most existing works focus on\nthe recognition step, while paying less attention to sign language translation.\nIn this work, we propose a task-aware instruction network, namely TIN-SLT, for\nsign language translation, by introducing the instruction module and the\nlearning-based feature fuse strategy into a Transformer network. In this way,\nthe pre-trained model's language ability can be well explored and utilized to\nfurther boost the translation performance. Moreover, by exploring the\nrepresentation space of sign language glosses and target spoken language, we\npropose a multi-level data augmentation scheme to adjust the data distribution\nof the training set. We conduct extensive experiments on two challenging\nbenchmark datasets, PHOENIX-2014-T and ASLG-PC12, on which our method\noutperforms former best solutions by 1.65 and 1.42 in terms of BLEU-4. Our code\nis published at https://github.com/yongcaoplus/TIN-SLT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangyong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1\">Long Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhengdao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kai_H/0/1/0/all/0/1\">Hwang Kai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Computational Inflection for Scientific Discovery. (arXiv:2205.02007v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.02007","description":"<p>We stand at the foot of a significant inflection in the trajectory of\nscientific discovery. As society continues on its fast-paced digital\ntransformation, so does humankind's collective scientific knowledge and\ndiscourse. We now read and write papers in digitized form, and a great deal of\nthe formal and informal processes of science are captured digitally --\nincluding papers, preprints and books, code and datasets, conference\npresentations, and interactions in social networks and collaboration and\ncommunication platforms. The transition has led to the creation and growth of a\ntremendous amount of information -- much of which is available for public\naccess -- opening exciting opportunities for computational models and systems\nthat analyze and harness it. In parallel, exponential growth in data processing\npower has fueled remarkable advances in artificial intelligence, including\nlarge neural language models capable of learning powerful representations from\nunstructured text. Dramatic changes in scientific communication -- such as the\nadvent of the first scientific journal in the 17th century -- have historically\ncatalyzed revolutions in scientific thought. The confluence of societal and\ncomputational trends suggests that computer science is poised to ignite a\nrevolution in the scientific process itself.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etzioni_O/0/1/0/all/0/1\">Oren Etzioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weld_D/0/1/0/all/0/1\">Daniel S. Weld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles. (arXiv:2205.12505v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12505","description":"<p>Recent works in Event Argument Extraction (EAE) have focused on improving\nmodel generalizability to cater to new events and domains. However, standard\nbenchmarking datasets like ACE and ERE cover less than 40 event types and 25\nentity-centric argument roles. Limited diversity and coverage hinder these\ndatasets from adequately evaluating the generalizability of EAE models. In this\npaper, we first contribute by creating a large and diverse EAE ontology. This\nontology is created by transforming FrameNet, a comprehensive semantic role\nlabeling (SRL) dataset for EAE, by exploiting the similarity between these two\ntasks. Then, exhaustive human expert annotations are collected to build the\nontology, concluding with 115 events and 220 argument roles, with a significant\nportion of roles not being entities. We utilize this ontology to further\nintroduce GENEVA, a diverse generalizability benchmarking dataset comprising\nfour test suites, aimed at evaluating models' ability to handle limited data\nand unseen event type generalization. We benchmark six EAE models from various\nfamilies. The results show that owing to non-entity argument roles, even the\nbest-performing model can only achieve 39% F1 score, indicating how GENEVA\nprovides new challenges for generalization in EAE. Overall, our large and\ndiverse EAE ontology can aid in creating more comprehensive future resources,\nwhile GENEVA is a challenging benchmarking dataset encouraging further research\nfor improving generalizability in EAE. The code and data can be found at\nhttps://github.com/PlusLabNLP/GENEVA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_T/0/1/0/all/0/1\">Tanmay Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_I/0/1/0/all/0/1\">I-Hung Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction. (arXiv:2207.14116v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.14116","description":"<p>We present Claim-Dissector: a novel latent variable model for fact-checking\nand analysis, which given a claim and a set of retrieved evidences jointly\nlearns to identify: (i) the relevant evidences to the given claim, (ii) the\nveracity of the claim. We propose to disentangle the per-evidence relevance\nprobability and its contribution to the final veracity probability in an\ninterpretable way -- the final veracity probability is proportional to a linear\nensemble of per-evidence relevance probabilities. In this way, the individual\ncontributions of evidences towards the final predicted probability can be\nidentified. In per-evidence relevance probability, our model can further\ndistinguish whether each relevant evidence is supporting (S) or refuting (R)\nthe claim. This allows to quantify how much the S/R probability contributes to\nthe final verdict or to detect disagreeing evidence.\n</p>\n<p>Despite its interpretable nature, our system achieves results competitive\nwith state-of-the-art on the FEVER dataset, as compared to typical two-stage\nsystem pipelines, while using significantly fewer parameters. It also sets new\nstate-of-the-art on FAVIQ and RealFC datasets. Furthermore, our analysis shows\nthat our model can learn fine-grained relevance cues while using coarse-grained\nsupervision, and we demonstrate it in 2 ways. (i) We show that our model can\nachieve competitive sentence recall while using only paragraph-level relevance\nsupervision. (ii) Traversing towards the finest granularity of relevance, we\nshow that our model is capable of identifying relevance at the token level. To\ndo this, we present a new benchmark TLR-FEVER focusing on token-level\ninterpretability -- humans annotate tokens in relevant evidences they\nconsidered essential when making their judgment. Then we measure how similar\nare these annotations to the tokens our model is focusing on.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fajcik_M/0/1/0/all/0/1\">Martin Fajcik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1\">Petr Motlicek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smrz_P/0/1/0/all/0/1\">Pavel Smrz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DICE: Data-Efficient Clinical Event Extraction with Generative Models. (arXiv:2208.07989v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.07989","description":"<p>Event extraction for the clinical domain is an under-explored research area.\nThe lack of training data along with the high volume of domain-specific\nterminologies with vague entity boundaries makes the task especially\nchallenging. In this paper, we introduce DICE, a robust and data-efficient\ngenerative model for clinical event extraction. DICE frames event extraction as\na conditional generation problem and introduces a contrastive learning\nobjective to accurately decide the boundaries of biomedical mentions. DICE also\ntrains an auxiliary mention identification task jointly with event extraction\ntasks to better identify entity mention boundaries, and further introduces\nspecial markers to incorporate identified entity mentions as trigger and\nargument candidates for their respective tasks. To benchmark clinical event\nextraction, we compose MACCROBAT-EE, the first clinical event extraction\ndataset with argument annotation, based on an existing clinical information\nextraction dataset MACCROBAT. Our experiments demonstrate state-of-the-art\nperformances of DICE for clinical and news domain event extraction, especially\nunder low data settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyu Derek Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_A/0/1/0/all/0/1\">Alexander K. Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Better Masking for Better Language Model Pre-training. (arXiv:2208.10806v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.10806","description":"<p>Masked Language Modeling (MLM) has been widely used as the denoising\nobjective in pre-training language models (PrLMs). Existing PrLMs commonly\nadopt a Random-Token Masking strategy where a fixed masking ratio is applied\nand different contents are masked by an equal probability throughout the entire\ntraining. However, the model may receive complicated impact from pre-training\nstatus, which changes accordingly as training time goes on. In this paper, we\nshow that such time-invariant MLM settings on masking ratio and masked content\nare unlikely to deliver an optimal outcome, which motivates us to explore the\ninfluence of time-variant MLM settings. We propose two scheduled masking\napproaches that adaptively tune the masking ratio and masked content in\ndifferent training stages, which improves the pre-training efficiency and\neffectiveness verified on the downstream tasks. Our work is a pioneer study on\ntime-variant masking strategy on ratio and content and gives a better\nunderstanding of how masking ratio and masked content influence the MLM\npre-training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dongjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Parameter-Efficient Integration of Pre-Trained Language Models In Temporal Video Grounding. (arXiv:2209.13359v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2209.13359","description":"<p>This paper explores the task of Temporal Video Grounding (TVG) where, given\nan untrimmed video and a natural language sentence query, the goal is to\nrecognize and determine temporal boundaries of action instances in the video\ndescribed by the query. Recent works tackled this task by improving query\ninputs with large pre-trained language models (PLM) at the cost of more\nexpensive training. However, the effects of this integration are unclear, as\nthese works also propose improvements in the visual inputs. Therefore, this\npaper studies the effects of PLMs in TVG and assesses the applicability of\nparameter-efficient training with NLP adapters. We couple popular PLMs with a\nselection of existing approaches and test different adapters to reduce the\nimpact of the additional parameters. Our results on three challenging datasets\nshow that, without changing the visual inputs, TVG models greatly benefited\nfrom the PLM integration and fine-tuning, stressing the importance of sentence\nquery representation in this task. Furthermore, NLP adapters were an effective\nalternative to full fine-tuning, even though they were not tailored to our\ntask, allowing PLM integration in larger TVG models and delivering results\ncomparable to SOTA models. Finally, our results shed light on which adapters\nwork best in different scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shimomoto_E/0/1/0/all/0/1\">Erica K. Shimomoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marrese_Taylor_E/0/1/0/all/0/1\">Edison Marrese-Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takamura_H/0/1/0/all/0/1\">Hiroya Takamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_I/0/1/0/all/0/1\">Ichiro Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakayama_H/0/1/0/all/0/1\">Hideki Nakayama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyao_Y/0/1/0/all/0/1\">Yusuke Miyao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Code4Struct: Code Generation for Few-Shot Event Structure Prediction. (arXiv:2210.12810v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.12810","description":"<p>Large Language Model (LLM) trained on a mixture of text and code has\ndemonstrated impressive capability in translating natural language (NL) into\nstructured code. We observe that semantic structures can be conveniently\ntranslated into code and propose Code4Struct to leverage such text-to-structure\ntranslation capability to tackle structured prediction tasks. As a case study,\nwe formulate Event Argument Extraction (EAE) as converting text into\nevent-argument structures that can be represented as a class object using code.\nThis alignment between structures and code enables us to take advantage of\nProgramming Language (PL) features such as inheritance and type annotation to\nintroduce external knowledge or add constraints. We show that, with sufficient\nin-context examples, formulating EAE as a code generation problem is\nadvantageous over using variants of text-based prompts. Despite only using 20\ntraining event instances for each event type, Code4Struct is comparable to\nsupervised models trained on 4,202 instances and outperforms current\nstate-of-the-art (SOTA) trained on 20-shot data by 29.5% absolute F1.\nCode4Struct can use 10-shot training data from a sibling event type to predict\narguments for zero-resource event types and outperforms the zero-shot baseline\nby 12% absolute F1.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Random Utterance Concatenation Based Data Augmentation for Improving Short-video Speech Recognition. (arXiv:2210.15876v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2210.15876","description":"<p>One of limitations in end-to-end automatic speech recognition (ASR) framework\nis its performance would be compromised if train-test utterance lengths are\nmismatched. In this paper, we propose an on-the-fly random utterance\nconcatenation (RUC) based data augmentation method to alleviate train-test\nutterance length mismatch issue for short-video ASR task. Specifically, we are\nmotivated by observations that our human-transcribed training utterances tend\nto be much shorter for short-video spontaneous speech (~3 seconds on average),\nwhile our test utterance generated from voice activity detection front-end is\nmuch longer (~10 seconds on average). Such a mismatch can lead to suboptimal\nperformance. Empirically, it's observed the proposed RUC method significantly\nimproves long utterance recognition without performance drop on short one.\nOverall, it achieves 5.72% word error rate reduction on average for 15\nlanguages and improved robustness to various utterance length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Lin_Y/0/1/0/all/0/1\">Yist Y. Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Han_T/0/1/0/all/0/1\">Tao Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_H/0/1/0/all/0/1\">Haihua Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pham_V/0/1/0/all/0/1\">Van Tung Pham</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Khassanov_Y/0/1/0/all/0/1\">Yerbolat Khassanov</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chong_T/0/1/0/all/0/1\">Tze Yuang Chong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_Y/0/1/0/all/0/1\">Yi He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextual information integration for stance detection via cross-attention. (arXiv:2211.01874v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.01874","description":"<p>Stance detection deals with identifying an author's stance towards a target.\nMost existing stance detection models are limited because they do not consider\nrelevant contextual information which allows for inferring the stance\ncorrectly. Complementary context can be found in knowledge bases but\nintegrating the context into pretrained language models is non-trivial due to\nthe graph structure of standard knowledge bases. To overcome this, we explore\nan approach to integrate contextual information as text which allows for\nintegrating contextual information from heterogeneous sources, such as\nstructured knowledge sources and by prompting large language models. Our\napproach can outperform competitive baselines on a large and diverse stance\ndetection benchmark in a cross-target setup, i.e. for targets unseen during\ntraining. We demonstrate that it is more robust to noisy context and can\nregularize for unwanted correlations between labels and target-specific\nvocabulary. Finally, it is independent of the pretrained language model in use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Beck_T/0/1/0/all/0/1\">Tilman Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Classification by Logical Reasoning on Natural Language Explanations. (arXiv:2211.03252v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.03252","description":"<p>Humans can classify data of an unseen category by reasoning on its language\nexplanations. This ability is owing to the compositional nature of language: we\ncan combine previously seen attributes to describe the new category. For\nexample, we might describe a sage thrasher as \"it has a slim straight\nrelatively short bill, yellow eyes and a long tail\", so that others can use\ntheir knowledge of attributes \"slim straight relatively short bill\", \"yellow\neyes\" and \"long tail\" to recognize a sage thrasher. Inspired by this\nobservation, in this work we tackle zero-shot classification task by logically\nparsing and reasoning on natural language expla-nations. To this end, we\npropose the framework CLORE (Classification by LOgical Reasoning on\nExplanations). While previous methods usually regard textual information as\nimplicit features, CLORE parses explanations into logical structures and then\nexplicitly reasons along thess structures on the input to produce a\nclassification score. Experimental results on explanation-based zero-shot\nclassification benchmarks demonstrate that CLORE is superior to baselines,\nwhich we further show mainly comes from higher scores on tasks requiring more\nlogical reasoning. We also demonstrate that our framework can be extended to\nzero-shot classification on visual modality. Alongside classification\ndecisions, CLORE can provide the logical parsing and reasoning process as a\nclear form of rationale. Through empirical analysis we demonstrate that CLORE\nis also less affected by linguistic biases than baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_H/0/1/0/all/0/1\">Hengzhi Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xinya Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Impact of Adversarial Training on Robustness and Generalizability of Language Models. (arXiv:2211.05523v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05523","description":"<p>Adversarial training is widely acknowledged as the most effective defense\nagainst adversarial attacks. However, it is also well established that\nachieving both robustness and generalization in adversarially trained models\ninvolves a trade-off. The goal of this work is to provide an in depth\ncomparison of different approaches for adversarial training in language models.\nSpecifically, we study the effect of pre-training data augmentation as well as\ntraining time input perturbations vs. embedding space perturbations on the\nrobustness and generalization of transformer-based language models. Our\nfindings suggest that better robustness can be achieved by pre-training data\naugmentation or by training with input space perturbation. However, training\nwith embedding space perturbation significantly improves generalization. A\nlinguistic correlation analysis of neurons of the learned models reveals that\nthe improved generalization is due to 'more specialized' neurons. To the best\nof our knowledge, this is the first work to carry out a deep qualitative\nanalysis of different methods of generating adversarial examples in adversarial\ntraining of language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Altinisik_E/0/1/0/all/0/1\">Enes Altinisik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sencar_H/0/1/0/all/0/1\">Husrev Taha Sencar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messaoud_S/0/1/0/all/0/1\">Safa Messaoud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chawla_S/0/1/0/all/0/1\">Sanjay Chawla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Persuasive Writing Strategies to Explain and Detect Health Misinformation. (arXiv:2211.05985v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05985","description":"<p>The spread of misinformation is a prominent problem in today's society, and\nmany researchers in academia and industry are trying to combat it. Due to the\nvast amount of misinformation that is created every day, it is unrealistic to\nleave this task to human fact-checkers. Data scientists and researchers have\nbeen working on automated misinformation detection for years, and it is still a\nchallenging problem today. The goal of our research is to add a new level to\nautomated misinformation detection; classifying segments of text with\npersuasive writing techniques in order to produce interpretable reasoning for\nwhy an article can be marked as misinformation. To accomplish this, we present\na novel annotation scheme containing many common persuasive writing tactics,\nalong with a dataset with human annotations accordingly. For this task, we make\nuse of a RoBERTa model for text classification, due to its high performance in\nNLP. We develop several language model-based baselines and present the results\nof our persuasive strategy label predictions as well as the improvements these\nintermediate labels make in detecting misinformation and producing\ninterpretable results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamali_D/0/1/0/all/0/1\">Danial Kamali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romain_J/0/1/0/all/0/1\">Joseph Romain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huiyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_J/0/1/0/all/0/1\">Jingbo Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kordjamshidi_P/0/1/0/all/0/1\">Parisa Kordjamshidi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The NCTE Transcripts: A Dataset of Elementary Math Classroom Transcripts. (arXiv:2211.11772v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11772","description":"<p>Classroom discourse is a core medium of instruction - analyzing it can\nprovide a window into teaching and learning as well as driving the development\nof new tools for improving instruction. We introduce the largest dataset of\nmathematics classroom transcripts available to researchers, and demonstrate how\nthis data can help improve instruction. The dataset consists of 1,660 45-60\nminute long 4th and 5th grade elementary mathematics observations collected by\nthe National Center for Teacher Effectiveness (NCTE) between 2010-2013. The\nanonymized transcripts represent data from 317 teachers across 4 school\ndistricts that serve largely historically marginalized students. The\ntranscripts come with rich metadata, including turn-level annotations for\ndialogic discourse moves, classroom observation scores, demographic\ninformation, survey responses and student test scores. We demonstrate that our\nnatural language processing model, trained on our turn-level annotations, can\nlearn to identify dialogic discourse moves and these moves are correlated with\nbetter classroom observation scores and learning outcomes. This dataset opens\nup several possibilities for researchers, educators and policymakers to learn\nabout and improve K-12 instruction. The dataset can be found at\nhttps://github.com/ddemszky/classroom-transcript-analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Demszky_D/0/1/0/all/0/1\">Dorottya Demszky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_H/0/1/0/all/0/1\">Heather Hill</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Global and Local Hierarchy-aware Contrastive Framework for Implicit Discourse Relation Recognition. (arXiv:2211.13873v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.13873","description":"<p>Due to the absence of explicit connectives, implicit discourse relation\nrecognition (IDRR) remains a challenging task in discourse analysis. The\ncritical step for IDRR is to learn high-quality discourse relation\nrepresentations between two arguments. Recent methods tend to integrate the\nwhole hierarchical information of senses into discourse relation\nrepresentations for multi-level sense recognition. Nevertheless, they\ninsufficiently incorporate the static hierarchical structure containing all\nsenses (defined as global hierarchy), and ignore the hierarchical sense label\nsequence corresponding to each instance (defined as local hierarchy). For the\npurpose of sufficiently exploiting global and local hierarchies of senses to\nlearn better discourse relation representations, we propose a novel GlObal and\nLocal Hierarchy-aware Contrastive Framework (GOLF), to model two kinds of\nhierarchies with the aid of multi-task learning and contrastive learning.\nExperimental results on PDTB 2.0 and PDTB 3.0 datasets demonstrate that our\nmethod remarkably outperforms current state-of-the-art models at all\nhierarchical levels. Our code is publicly available at\nhttps://github.com/YJiangcm/GOLF_for_IDRR\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linhan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating and reducing the distance between synthetic and real speech distributions. (arXiv:2211.16049v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2211.16049","description":"<p>While modern Text-to-Speech (TTS) systems can produce natural-sounding\nspeech, they remain unable to reproduce the full diversity found in natural\nspeech data. We consider the distribution of all possible real speech samples\nthat could be generated by these speakers alongside the distribution of all\nsynthetic samples that could be generated for the same set of speakers, using a\nparticular TTS system. We set out to quantify the distance between real and\nsynthetic speech via a range of utterance-level statistics related to\nproperties of the speaker, speech prosody and acoustic environment. Differences\nin the distribution of these statistics are evaluated using the Wasserstein\ndistance. We reduce these distances by providing ground-truth values at\ngeneration time, and quantify the improvements to the overall distribution\ndistance, approximated using an automatic speech recognition system. Our best\nsystem achieves a 10\\% reduction in distribution distance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Minixhofer_C/0/1/0/all/0/1\">Christoph Minixhofer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Klejch_O/0/1/0/all/0/1\">Ond&#x159;ej Klejch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bell_P/0/1/0/all/0/1\">Peter Bell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data-Efficient Finetuning Using Cross-Task Nearest Neighbors. (arXiv:2212.00196v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.00196","description":"<p>Obtaining labeled data to train a model for a task of interest is often\nexpensive. Prior work shows training models on multitask data augmented with\ntask descriptions (prompts) effectively transfers knowledge to new tasks.\nTowards efficiently building task-specific models, we assume access to a small\nnumber (32-1000) of unlabeled target-task examples and use those to retrieve\nthe most similar labeled examples from a large pool of multitask data augmented\nwith prompts. Compared to the current practice of finetuning models on\nuniformly sampled prompted multitask data (e.g.: FLAN, T0), our approach of\nfinetuning on cross-task nearest neighbors is significantly more\ndata-efficient. Using only 2% of the data from the P3 pool without any labeled\ntarget-task data, our models outperform strong baselines trained on all\navailable data by 3-30% on 12 out of 14 datasets representing held-out tasks\nincluding legal and scientific document QA. Similarly, models trained on\ncross-task nearest neighbors from SuperNaturalInstructions, representing about\n5% of the pool, obtain comparable performance to state-of-the-art models on 12\nheld-out tasks from that pool. Moreover, the models produced by our approach\nalso provide a better initialization than single multitask finetuned models for\nfew-shot finetuning on target-task data, as shown by a 2-23% relative\nimprovement over few-shot finetuned T0-3B models on 8 datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ivison_H/0/1/0/all/0/1\">Hamish Ivison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasigi_P/0/1/0/all/0/1\">Pradeep Dasigi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lattice-Free Sequence Discriminative Training for Phoneme-Based Neural Transducers. (arXiv:2212.04325v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2212.04325","description":"<p>Recently, RNN-Transducers have achieved remarkable results on various\nautomatic speech recognition tasks. However, lattice-free sequence\ndiscriminative training methods, which obtain superior performance in hybrid\nmodels, are rarely investigated in RNN-Transducers. In this work, we propose\nthree lattice-free training objectives, namely lattice-free maximum mutual\ninformation, lattice-free segment-level minimum Bayes risk, and lattice-free\nminimum Bayes risk, which are used for the final posterior output of the\nphoneme-based neural transducer with a limited context dependency. Compared to\ncriteria using N-best lists, lattice-free methods eliminate the decoding step\nfor hypotheses generation during training, which leads to more efficient\ntraining. Experimental results show that lattice-free methods gain up to 6.5%\nrelative improvement in word error rate compared to a sequence-level\ncross-entropy trained model. Compared to the N-best-list based minimum Bayes\nrisk objectives, lattice-free methods gain 40% - 70% relative training time\nspeedup with a small degradation in performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_Z/0/1/0/all/0/1\">Zijian Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting. (arXiv:2212.09535v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09535","description":"<p>The BLOOM model is a large publicly available multilingual language model,\nbut its pretraining was limited to 46 languages. To extend the benefits of\nBLOOM to other languages without incurring prohibitively large costs, it is\ndesirable to adapt BLOOM to new languages not seen during pretraining. In this\nwork, we apply existing language adaptation strategies to BLOOM and benchmark\nits zero-shot prompting performance on eight new languages in a\nresource-constrained setting. We find language adaptation to be effective at\nimproving zero-shot performance in new languages. Surprisingly, we find that\nadapter-based finetuning is more effective than continued pretraining for large\nmodels. In addition, we discover that prompting performance is not\nsignificantly affected by language specifics, such as the writing system. It is\nprimarily determined by the size of the language adaptation data. We also add\nnew languages to BLOOMZ, which is a multitask finetuned version of BLOOM\ncapable of following task instructions zero-shot. We find including a new\nlanguage in the multitask fine-tuning mixture to be the most effective method\nto teach BLOOMZ a new language. We conclude that with sufficient training data\nlanguage adaptation can generalize well to diverse languages. Our code is\navailable at https://github.com/bigscience-workshop/multilingual-modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng-Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoelkopf_H/0/1/0/all/0/1\">Hailey Schoelkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almubarak_K/0/1/0/all/0/1\">Khalid Almubarak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutawika_L/0/1/0/all/0/1\">Lintang Sutawika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baruwa_A/0/1/0/all/0/1\">Ahmed Baruwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1\">Edward Raff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1\">Vassilina Nikoulina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Decades Progress on Code-Switching Research in NLP: A Systematic Survey on Trends and Challenges. (arXiv:2212.09660v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09660","description":"<p>Code-Switching, a common phenomenon in written text and conversation, has\nbeen studied over decades by the natural language processing (NLP) research\ncommunity. Initially, code-switching is intensively explored by leveraging\nlinguistic theories and, currently, more machine-learning oriented approaches\nto develop models. We introduce a comprehensive systematic survey on\ncode-switching research in natural language processing to understand the\nprogress of the past decades and conceptualize the challenges and tasks on the\ncode-switching topic. Finally, we summarize the trends and findings and\nconclude with a discussion for future direction and open questions for further\ninvestigation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng-Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solorio_T/0/1/0/all/0/1\">Thamar Solorio</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments. (arXiv:2212.09683v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09683","description":"<p>We present a human-in-the-loop evaluation framework for fact-checking novel\nmisinformation claims and identifying social media messages that support them.\nOur approach extracts check-worthy claims, which are aggregated and ranked for\nreview. Stance classifiers are then used to identify tweets supporting novel\nmisinformation claims, which are further reviewed to determine whether they\nviolate relevant policies. To demonstrate the feasibility of our approach, we\ndevelop a baseline system based on modern NLP methods for human-in-the-loop\nfact-checking in the domain of COVID-19 treatments. We make our data and\ndetailed annotation guidelines available to support the evaluation of\nhuman-in-the-loop systems that identify novel misinformation directly from raw\nuser-generated content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mendes_E/0/1/0/all/0/1\">Ethan Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do language models have coherent mental models of everyday things?. (arXiv:2212.10029v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10029","description":"<p>When people think of everyday things like an \"egg,\" they typically have a\nmental image associated with it. This commonsense knowledge helps us understand\nhow these everyday things work and how to interact with them. For example, when\nsomeone tries to make a fried egg, they know that it has a shell and that it\ncan be cracked open to reveal the egg white and yolk inside. However, if a\nsystem does not have a coherent picture of such everyday things, thinking that\nthe egg yolk surrounds the shell, then it might have to resort to ridiculous\napproaches such as trying to scrape the egg yolk off the shell into the pan. Do\nlanguage models have a coherent picture of such everyday things? To investigate\nthis, we propose a benchmark dataset consisting of 100 everyday things, their\nparts, and the relationships between these parts. We observe that\nstate-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have\nfragments of knowledge about these entities, but they fail to produce\nconsistent parts mental models. We propose a simple extension to these LMs\nwhere we apply a constraint satisfaction layer on top of raw predictions from\nLMs to produce more consistent and accurate parts mental models of everyday\nthings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuling Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1\">Bhavana Dalvi Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HINT: Hypernetwork Instruction Tuning for Efficient Zero- & Few-Shot Generalisation. (arXiv:2212.10315v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10315","description":"<p>Recent NLP models have shown the remarkable ability to effectively generalise\n`zero-shot' to new tasks using only natural language instructions as guidance.\nHowever, many of these approaches suffer from high computational costs due to\ntheir reliance on concatenating lengthy instructions with every input example,\nresulting in costly reprocessing of the instruction. To avoid this, we\nintroduce Hypernetworks for INstruction Tuning (HINT), which convert task\ninstructions and examples into parameter-efficient modules inserted into an\nunderlying model using a pretrained text encoder, eliminating the need to\ninclude instructions in the model input. The hypernetwork in HINT also produces\nan encoded instruction, which we concatenate with encoded inputs during\ndecoding to further improve performance. HINT models outperform strong\nstate-of-the-art baselines by over 10% when controlling for compute (measured\nin FLOPs). By converting instructions into modules, HINT models can effectively\ndisregard the length of instructions and few-shot example inputs in terms of\ncompute usage. As a result, HINT can enhance its performance by up to 25% by\nincorporating additional few-shot data, while utilizing only up to 5% more\ncompute. This combines the strengths of parameter-efficient fine-tuning and\nin-context learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ivison_H/0/1/0/all/0/1\">Hamish Ivison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagia_A/0/1/0/all/0/1\">Akshita Bhagia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_M/0/1/0/all/0/1\">Matthew Peters</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Curation Alone Can Stabilize In-context Learning. (arXiv:2212.10378v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10378","description":"<p>In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks by prompting them with a sequence of training examples. However, it is\nknown that ICL is very sensitive to the choice of training examples: randomly\nsampling examples from a training set leads to high variance in performance. In\nthis paper, we show that carefully curating a subset of training data greatly\nstabilizes ICL performance without any other changes to the ICL algorithm\n(e.g., prompt retrieval or calibration). We introduce two methods to choose\ntraining subsets -- both score training examples individually, then select the\nhighest-scoring ones. CondAcc scores a training example by its average dev-set\nICL accuracy when combined with random training examples, while Datamodels\nlearns linear regressors that estimate how the presence of each training\nexample influences LLM outputs. Across five tasks and two LLMs, sampling from\nstable subsets selected by CondAcc and Datamodels improves average accuracy\nover sampling from the entire training set by 7.7% and 6.3%, respectively.\nSurprisingly, the stable subset examples are not especially diverse in content\nor low in perplexity, in contrast with other work suggesting that diversity and\nperplexity are important when prompting LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Ting-Yun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PropSegmEnt: A Large-Scale Corpus for Proposition-Level Segmentation and Entailment Recognition. (arXiv:2212.10750v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10750","description":"<p>The widely studied task of Natural Language Inference (NLI) requires a system\nto recognize whether one piece of text is textually entailed by another, i.e.\nwhether the entirety of its meaning can be inferred from the other. In current\nNLI datasets and models, textual entailment relations are typically defined on\nthe sentence- or paragraph-level. However, even a simple sentence often\ncontains multiple propositions, i.e. distinct units of meaning conveyed by the\nsentence. As these propositions can carry different truth values in the context\nof a given premise, we argue for the need to recognize the textual entailment\nrelation of each proposition in a sentence individually.\n</p>\n<p>We propose PropSegmEnt, a corpus of over 45K propositions annotated by expert\nhuman raters. Our dataset structure resembles the tasks of (1) segmenting\nsentences within a document to the set of propositions, and (2) classifying the\nentailment relation of each proposition with respect to a different yet\ntopically-aligned document, i.e. documents describing the same event or entity.\nWe establish strong baselines for the segmentation and entailment tasks.\nThrough case studies on summary hallucination detection and document-level NLI,\nwe demonstrate that our conceptual framework is potentially useful for\nunderstanding and explaining the compositionality of NLI labels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buthpitiya_S/0/1/0/all/0/1\">Senaka Buthpitiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabrikant_A/0/1/0/all/0/1\">Alex Fabrikant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_T/0/1/0/all/0/1\">Tal Schuster</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Selective Explanations: Leveraging Human Input to Align Explainable AI. (arXiv:2301.09656v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2301.09656","description":"<p>While a vast collection of explainable AI (XAI) algorithms have been\ndeveloped in recent years, they are often criticized for significant gaps with\nhow humans produce and consume explanations. As a result, current XAI\ntechniques are often found to be hard to use and lack effectiveness. In this\nwork, we attempt to close these gaps by making AI explanations selective -- a\nfundamental property of human explanations -- by selectively presenting a\nsubset from a large set of model reasons based on what aligns with the\nrecipient's preferences. We propose a general framework for generating\nselective explanations by leveraging human input on a small sample. This\nframework opens up a rich design space that accounts for different selectivity\ngoals, types of input, and more. As a showcase, we use a decision-support task\nto explore selective explanations based on what the decision-maker would\nconsider relevant to the decision task. We conducted two experimental studies\nto examine three out of a broader possible set of paradigms based on our\nproposed framework: in Study 1, we ask the participants to provide their own\ninput to generate selective explanations, with either open-ended or\ncritique-based input. In Study 2, we show participants selective explanations\nbased on input from a panel of similar users (annotators). Our experiments\ndemonstrate the promise of selective explanations in reducing over-reliance on\nAI and improving decision outcomes and subjective perceptions of the AI, but\nalso paint a nuanced picture that attributes some of these positive effects to\nthe opportunity to provide one's own input to augment AI explanations. Overall,\nour work proposes a novel XAI framework inspired by human communication\nbehaviors and demonstrates its potentials to encourage future work to better\nalign AI explanations with human production and consumption of explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1\">Vivian Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chacha Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1\">Q. Vera Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input Noises. (arXiv:2302.07324v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07324","description":"<p>For many real-world applications, the user-generated inputs usually contain\nvarious noises due to speech recognition errors caused by linguistic\nvariations1 or typographical errors (typos). Thus, it is crucial to test model\nperformance on data with realistic input noises to ensure robustness and\nfairness. However, little study has been done to construct such benchmarks for\nChinese, where various language-specific input noises happen in the real world.\nIn order to fill this important gap, we construct READIN: a Chinese multi-task\nbenchmark with REalistic And Diverse Input Noises. READIN contains four diverse\ntasks and requests annotators to re-enter the original test data with two\ncommonly used Chinese input methods: Pinyin input and speech input. We designed\nour annotation pipeline to maximize diversity, for example by instructing the\nannotators to use diverse input method editors (IMEs) for keyboard noises and\nrecruiting speakers from diverse dialectical groups for speech noises. We\nexperiment with a series of strong pretrained language models as well as robust\ntraining methods, we find that these models often suffer significant\nperformance drops on READIN even with robustness methods like data\naugmentation. As the first large-scale attempt in creating a benchmark with\nnoises geared towards user-generated inputs, we believe that READIN serves as\nan important complement to existing Chinese NLP benchmarks. The source code and\ndataset can be obtained from https://github.com/thunlp/READIN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yingfa Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer models: an introduction and catalog. (arXiv:2302.07730v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07730","description":"<p>In the past few years we have seen the meteoric appearance of dozens of\nfoundation models of the Transformer family, all of which have memorable and\nsometimes funny, but not self-explanatory, names. The goal of this paper is to\noffer a somewhat comprehensive but simple catalog and classification of the\nmost popular Transformer models. The paper also includes an introduction to the\nmost important aspects and innovations in Transformer models. Our catalog will\ninclude models that are trained using self-supervised learning (e.g., BERT or\nGPT3) as well as those that are further trained using a human-in-the-loop (e.g.\nthe InstructGPT model used by ChatGPT).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amatriain_X/0/1/0/all/0/1\">Xavier Amatriain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Whats New? Identifying the Unfolding of New Events in Narratives. (arXiv:2302.07748v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07748","description":"<p>Narratives include a rich source of events unfolding over time and context.\nAutomatic understanding of these events provides a summarised comprehension of\nthe narrative for further computation (such as reasoning). In this paper, we\nstudy the Information Status (IS) of the events and propose a novel challenging\ntask: the automatic identification of \\textit{new} events in a narrative. We\ndefine an event as a triplet of subject, predicate, and object. The event is\ncategorized as new with respect to the discourse context and whether it can be\ninferred through commonsense reasoning. We annotated a publicly available\ncorpus of narratives with the new events at sentence level using human\nannotators. We present the annotation protocol and study the quality of the\nannotation and the difficulty of the task. We publish the annotated dataset,\nannotation materials, and machine learning baseline models for the task of new\nevent extraction for narrative understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1\">Seyed Mahed Mousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_S/0/1/0/all/0/1\">Shohei Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roccabruna_G/0/1/0/all/0/1\">Gabriel Roccabruna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshino_K/0/1/0/all/0/1\">Koichiro Yoshino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1\">Satoshi Nakamura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riccardi_G/0/1/0/all/0/1\">Giuseppe Riccardi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis. (arXiv:2302.08624v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08624","description":"<p>In this paper, we present InstructABSA, Aspect Based Sentiment Analysis\n(ABSA) using the instruction learning paradigm for the ABSA subtasks: Aspect\nTerm Extraction (ATE), Aspect Term Sentiment Classification (ATSC), and Joint\nTask modeling. Our method introduces positive, negative, and neutral examples\nto each training sample, and instruction tunes the model (Tk-Instruct) the ABSA\nsubtasks, yielding significant performance improvements. Experimental results\non the Sem Eval 2014, 15, and 16 datasets demonstrate that InstructABSA\noutperforms the previous state-of-the-art (SOTA) approaches on the three ABSA\nsubtasks (ATE, ATSC, and Joint Task) by a significant margin, outperforming 7x\nlarger models. In particular, InstructABSA surpasses the SOTA on the Rest14 ATE\nsubtask by 5.69% points, Rest15 ATSC subtask by 9.59% points, and on the Lapt14\nJoint Task by 3.37% points. Our results also suggest a strong generalization\nability to new domains across all three subtasks\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scaria_K/0/1/0/all/0/1\">Kevin Scaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1\">Himanshu Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1\">Siddharth Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawant_S/0/1/0/all/0/1\">Saurabh Arjun Sawant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face. (arXiv:2303.17580v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.17580","description":"<p>Solving complicated AI tasks with different domains and modalities is a key\nstep toward artificial general intelligence. While there are abundant AI models\navailable for different domains and modalities, they cannot handle complicated\nAI tasks. Considering large language models (LLMs) have exhibited exceptional\nability in language understanding, generation, interaction, and reasoning, we\nadvocate that LLMs could act as a controller to manage existing AI models to\nsolve complicated AI tasks and language could be a generic interface to empower\nthis. Based on this philosophy, we present HuggingGPT, a framework that\nleverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning\ncommunities (e.g., Hugging Face) to solve AI tasks. Specifically, we use\nChatGPT to conduct task planning when receiving a user request, select models\naccording to their function descriptions available in Hugging Face, execute\neach subtask with the selected AI model, and summarize the response according\nto the execution results. By leveraging the strong language capability of\nChatGPT and abundant AI models in Hugging Face, HuggingGPT is able to cover\nnumerous sophisticated AI tasks in different modalities and domains and achieve\nimpressive results in language, vision, speech, and other challenging tasks,\nwhich paves a new way towards artificial general intelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yongliang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weiming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yueting Zhuang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models. (arXiv:2304.00457v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.00457","description":"<p>Large Language Models (LLMs) have revolutionized natural language processing\nand demonstrated impressive capabilities in various tasks. Unfortunately, they\nare prone to hallucinations, where the model exposes incorrect or false\ninformation in its responses, which renders diligent evaluation approaches\nmandatory. While LLM performance in specific knowledge fields is often\nevaluated based on question and answer (Q&amp;A) datasets, such evaluations usually\nreport only a single accuracy number for the entire field, a procedure which is\nproblematic with respect to transparency and model improvement. A stratified\nevaluation could instead reveal subfields, where hallucinations are more likely\nto occur and thus help to better assess LLMs' risks and guide their further\ndevelopment. To support such stratified evaluations, we propose LLMMaps as a\nnovel visualization technique that enables users to evaluate LLMs' performance\nwith respect to Q&amp;A datasets. LLMMaps provide detailed insights into LLMs'\nknowledge capabilities in different subfields, by transforming Q&amp;A datasets as\nwell as LLM responses into our internal knowledge structure. An extension for\ncomparative visualization furthermore, allows for the detailed comparison of\nmultiple LLMs. To assess LLMMaps we use them to conduct a comparative analysis\nof several state-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and\nLLaMa-13B, as well as two qualitative user evaluations. All necessary source\ncode and data for generating LLMMaps to be used in scientific publications and\nelsewhere will be available on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1\">Patrik Puchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poonam_P/0/1/0/all/0/1\">Poonam Poonam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onzenoodt_C/0/1/0/all/0/1\">Christian van Onzenoodt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1\">Timo Ropinski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Gender Bias in West Slavic Language Models. (arXiv:2304.05783v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.05783","description":"<p>Pre-trained language models have been known to perpetuate biases from the\nunderlying datasets to downstream tasks. However, these findings are\npredominantly based on monolingual language models for English, whereas there\nare few investigative studies of biases encoded in language models for\nlanguages beyond English. In this paper, we fill this gap by analysing gender\nbias in West Slavic language models. We introduce the first template-based\ndataset in Czech, Polish, and Slovak for measuring gender bias towards male,\nfemale and non-binary subjects. We complete the sentences using both mono- and\nmultilingual language models and assess their suitability for the masked\nlanguage modelling objective. Next, we measure gender bias encoded in West\nSlavic language models by quantifying the toxicity and genderness of the\ngenerated words. We find that these language models produce hurtful completions\nthat depend on the subject's gender. Perhaps surprisingly, Czech, Slovak, and\nPolish language models produce more hurtful completions with men as subjects,\nwhich, upon inspection, we find is due to completions being related to\nviolence, death, and sickness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martinkova_S/0/1/0/all/0/1\">Sandra Martinkov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanczak_K/0/1/0/all/0/1\">Karolina Sta&#x144;czak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2304.06767","description":"<p>Generative foundation models are susceptible to implicit biases that can\narise from extensive unsupervised training data. Such biases can produce\nsuboptimal samples, skewed outcomes, and unfairness, with potentially\nsignificant repercussions. Consequently, aligning these models with human\nethics and preferences is an essential step toward ensuring their responsible\nand effective deployment in real-world applications. Prior research has\nprimarily employed Reinforcement Learning from Human Feedback (RLHF) as a means\nof addressing this problem, wherein generative models are fine-tuned using RL\nalgorithms guided by a human-feedback-informed reward model. However, the\ninefficiencies and instabilities associated with RL algorithms frequently\npresent substantial obstacles to the successful alignment of generative models,\nnecessitating the development of a more robust and streamlined approach. To\nthis end, we introduce a new framework, Reward rAnked FineTuning (RAFT),\ndesigned to align generative models more effectively. Utilizing a reward model\nand a sufficient number of samples, our approach selects the high-quality\nsamples, discarding those that exhibit undesired behavior, and subsequently\nassembles a streaming dataset. This dataset serves as the basis for aligning\nthe generative model and can be employed under both offline and online\nsettings. Notably, the sample generation process within RAFT is gradient-free,\nrendering it compatible with black-box generators. Through extensive\nexperiments, we demonstrate that our proposed algorithm exhibits strong\nperformance in the context of both large language models and diffusion models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hanze Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wei Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_D/0/1/0/all/0/1\">Deepanshu Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_R/0/1/0/all/0/1\">Rui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_S/0/1/0/all/0/1\">Shizhe Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shum_K/0/1/0/all/0/1\">Kashun Shum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-shot Event Detection: An Empirical Study and a Unified View. (arXiv:2305.01901v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01901","description":"<p>Few-shot event detection (ED) has been widely studied, while this brings\nnoticeable discrepancies, e.g., various motivations, tasks, and experimental\nsettings, that hinder the understanding of models for future progress.This\npaper presents a thorough empirical study, a unified view of ED models, and a\nbetter unified baseline. For fair evaluation, we compare 12 representative\nmethods on three datasets, which are roughly grouped into prompt-based and\nprototype-based models for detailed analysis. Experiments consistently\ndemonstrate that prompt-based methods, including ChatGPT, still significantly\ntrail prototype-based methods in terms of overall performance. To investigate\ntheir superior performance, we break down their design elements along several\ndimensions and build a unified framework on prototype-based methods. Under such\nunified view, each prototype-method can be viewed a combination of different\nmodules from these design elements. We further combine all advantageous modules\nand propose a simple yet effective baseline, which outperforms existing methods\nby a large margin (e.g., 2.7% F1 gains under low-resource setting).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yubo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zehao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pay More Attention to Relation Exploration for Knowledge Base Question Answering. (arXiv:2305.02118v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02118","description":"<p>Knowledge base question answering (KBQA) is a challenging task that aims to\nretrieve correct answers from large-scale knowledge bases. Existing attempts\nprimarily focus on entity representation and final answer reasoning, which\nresults in limited supervision for this task. Moreover, the relations, which\nempirically determine the reasoning path selection, are not fully considered in\nrecent advancements. In this study, we propose a novel framework, RE-KBQA, that\nutilizes relations in the knowledge base to enhance entity representation and\nintroduce additional supervision. We explore guidance from relations in three\naspects, including (1) distinguishing similar entities by employing a\nvariational graph auto-encoder to learn relation importance; (2) exploring\nextra supervision by predicting relation distributions as soft labels with a\nmulti-task scheme; (3) designing a relation-guided re-ranking algorithm for\npost-processing. Experimental results on two benchmark datasets demonstrate the\neffectiveness and superiority of our framework, improving the F1 score by 5.7%\nfrom 40.5 to 46.3 on CWQ and 5.8% from 62.8 to 68.5 on WebQSP, better or on par\nwith state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huiwen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wen Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Min Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1\">Daniel Hershcovich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation. (arXiv:2305.04720v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04720","description":"<p>Despite the recent advances in open-domain dialogue systems, building a\nreliable evaluation metric is still a challenging problem. Recent studies\nproposed learnable metrics based on classification models trained to\ndistinguish the correct response. However, neural classifiers are known to make\noverly confident predictions for examples from unseen distributions. We propose\nDEnsity, which evaluates a response by utilizing density estimation on the\nfeature space derived from a neural classifier. Our metric measures how likely\na response would appear in the distribution of human conversations. Moreover,\nto improve the performance of DEnsity, we utilize contrastive learning to\nfurther compress the feature space. Experiments on multiple response evaluation\ndatasets show that DEnsity correlates better with human evaluations than the\nexisting metrics. Our code is available at https://github.com/ddehun/DEnsity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">ChaeHun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seungil Chad Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rim_D/0/1/0/all/0/1\">Daniel Rim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Drop of Ink Makes a Million Think: The Spread of False Information in Large Language Models. (arXiv:2305.04812v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04812","description":"<p>Large language models (LLMs) have gained increasing prominence in artificial\nintelligence, making a profound impact on society and various industries like\nbusiness and science. However, the presence of false information on the\ninternet and in text corpus poses a significant risk to the reliability and\nsafety of LLMs, underscoring the urgent need to understand the mechanisms of\nhow false information influences the behaviors of LLMs. In this paper, we dive\ninto this problem and investigate how false information spreads in LLMs and\naffects related responses. Specifically, in our series of experiments, we\ninvestigate different factors that can influence the spread of information in\nLLMs by comparing three degrees of information relevance (direct, indirect, and\nperipheral), four information source styles (Twitter, web blogs, news reports,\nand research papers) and two common knowledge injection paradigms (in-context\ninjection and learning-based injection). The experimental results show that\n(1)False information will spread and contaminate related memories in LLMs via a\nsemantic diffusion process, i.e., false information has global detrimental\neffects beyond its direct impact. (2)Current LLMs are susceptible to authority\nbias, i.e., LLMs are more likely to follow false information presented in\ntrustworthy styles such as news reports and research papers, which usually\ncause deeper and wider pollution of information. (3)Current LLMs are more\nsensitive to false information through in-context injection than through\nlearning-based injection, which severely challenges the reliability and safety\nof LLMs even when all training data are trusty and correct. The above findings\nraise the need for new false information defense algorithms to address the\nglobal impact of false information, and new alignment algorithms to unbiasedly\nlead LLMs to follow essential human values rather than superficial patterns.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bian_N/0/1/0/all/0/1\">Ning Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaojie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Ben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Do In-Context Examples Affect Compositional Generalization?. (arXiv:2305.04835v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04835","description":"<p>Compositional generalization--understanding unseen combinations of seen\nprimitives--is an essential reasoning capability in human intelligence. The AI\ncommunity mainly studies this capability by fine-tuning neural networks on lots\nof training samples, while it is still unclear whether and how in-context\nlearning--the prevailing few-shot paradigm based on large language\nmodels--exhibits compositional generalization. In this paper, we present CoFe,\na test suite to investigate in-context compositional generalization. We find\nthat the compositional generalization performance can be easily affected by the\nselection of in-context examples, thus raising the research question what the\nkey factors are to make good in-context examples for compositional\ngeneralization. We study three potential factors: similarity, diversity and\ncomplexity. Our systematic experiments indicate that in-context examples should\nbe structurally similar to the test case, diverse from each other, and\nindividually simple. Furthermore, two strong limitations are observed:\nin-context compositional generalization on fictional words is much weaker than\nthat on commonly used ones; it is still critical that the in-context examples\nshould cover required linguistic structures, even though the backbone model has\nbeen pre-trained on large corpus. We hope our analysis would facilitate the\nunderstanding and utilization of in-context learning paradigm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_S/0/1/0/all/0/1\">Shengnan An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zeqi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Q/0/1/0/all/0/1\">Qiang Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1\">Nanning Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2). (arXiv:2305.06586v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06586","description":"<p>We present the findings of SemEval-2023 Task 2 on Fine-grained Multilingual\nNamed Entity Recognition (MultiCoNER 2). Divided into 13 tracks, the task\nfocused on methods to identify complex fine-grained named entities (like\nWRITTENWORK, VEHICLE, MUSICALGRP) across 12 languages, in both monolingual and\nmultilingual scenarios, as well as noisy settings. The task used the MultiCoNER\nV2 dataset, composed of 2.2 million instances in Bangla, Chinese, English,\nFarsi, French, German, Hindi, Italian., Portuguese, Spanish, Swedish, and\nUkrainian. MultiCoNER 2 was one of the most popular tasks of SemEval-2023. It\nattracted 842 submissions from 47 teams, and 34 teams submitted system papers.\nResults showed that complex entity types such as media titles and product names\nwere the most challenging. Methods fusing external knowledge into transformer\nmodels achieved the best performance, and the largest gains were on the\nCreative Work and Group classes, which are still challenging even with external\nknowledge. Some fine-grained classes proved to be more challenging than others,\nsuch as SCIENTIST, ARTWORK, and PRIVATECORP. We also observed that noisy data\nhas a significant impact on model performance, with an average drop of 10% on\nthe noisy subset. The task highlights the need for future research on improving\nNER robustness on noisy data containing complex entities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fetahu_B/0/1/0/all/0/1\">Besnik Fetahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kar_S/0/1/0/all/0/1\">Sudipta Kar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokhlenko_O/0/1/0/all/0/1\">Oleg Rokhlenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malmasi_S/0/1/0/all/0/1\">Shervin Malmasi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Masked Audio Text Encoders are Effective Multi-Modal Rescorers. (arXiv:2305.07677v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2305.07677","description":"<p>Masked Language Models (MLMs) have proven to be effective for second-pass\nrescoring in Automatic Speech Recognition (ASR) systems. In this work, we\npropose Masked Audio Text Encoder (MATE), a multi-modal masked language model\nrescorer which incorporates acoustic representations into the input space of\nMLM. We adopt contrastive learning for effectively aligning the modalities by\nlearning shared representations. We show that using a multi-modal rescorer is\nbeneficial for domain generalization of the ASR system when target domain data\nis unavailable. MATE reduces word error rate (WER) by 4%-16% on in-domain, and\n3%-7% on out-of-domain datasets, over the text-only baseline. Additionally,\nwith very limited amount of training data (0.8 hours), MATE achieves a WER\nreduction of 8%-23% over the first-pass baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jinglun Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1\">Monica Sunkara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xilai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_A/0/1/0/all/0/1\">Anshu Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiao Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1\">Sravan Bodapati</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TinyStories: How Small Can Language Models Be and Still Speak Coherent English?. (arXiv:2305.07759v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07759","description":"<p>Language models (LMs) are powerful tools for natural language processing, but\nthey often struggle to produce coherent and fluent text when they are small.\nModels with around 125M parameters such as GPT-Neo (small) or GPT-2 (small) can\nrarely generate coherent and consistent English text beyond a few words even\nafter extensive training. This raises the question of whether the emergence of\nthe ability to produce coherent English text only occurs at larger scales (with\nhundreds of millions of parameters or more) and complex architectures (with\nmany layers of global attention).\n</p>\n<p>In this work, we introduce TinyStories, a synthetic dataset of short stories\nthat only contain words that a typical 3 to 4-year-olds usually understand,\ngenerated by GPT-3.5 and GPT-4. We show that TinyStories can be used to train\nand evaluate LMs that are much smaller than the state-of-the-art models (below\n10 million total parameters), or have much simpler architectures (with only one\ntransformer block), yet still produce fluent and consistent stories with\nseveral paragraphs that are diverse and have almost perfect grammar, and\ndemonstrate reasoning capabilities.\n</p>\n<p>We also introduce a new paradigm for the evaluation of language models: We\nsuggest a framework which uses GPT-4 to grade the content generated by these\nmodels as if those were stories written by students and graded by a (human)\nteacher. This new paradigm overcomes the flaws of standard benchmarks which\noften requires the model's output to be very structures, and moreover provides\na multidimensional score for the model, providing scores for different\ncapabilities such as grammar, creativity and consistency.\n</p>\n<p>We hope that TinyStories can facilitate the development, analysis and\nresearch of LMs, especially for low-resource or specialized domains, and shed\nlight on the emergence of language capabilities in LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eldan_R/0/1/0/all/0/1\">Ronen Eldan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using LLM-assisted Annotation for Corpus Linguistics: A Case Study of Local Grammar Analysis. (arXiv:2305.08339v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08339","description":"<p>Chatbots based on Large Language Models (LLMs) have shown strong capabilities\nin language understanding. In this study, we explore the potential of LLMs in\nassisting corpus-based linguistic studies through automatic annotation of texts\nwith specific categories of linguistic information. Specifically, we examined\nto what extent LLMs understand the functional elements constituting the speech\nact of apology from a local grammar perspective, by comparing the performance\nof ChatGPT (powered by GPT-3.5), the Bing chatbot (powered by GPT-4), and a\nhuman coder in the annotation task. The results demonstrate that the Bing\nchatbot significantly outperformed ChatGPT in the task. Compared to human\nannotator, the overall performance of the Bing chatbot was slightly less\nsatisfactory. However, it already achieved high F1 scores: 99.95% for the tag\nof APOLOGISING, 91.91% for REASON, 95.35% for APOLOGISER, 89.74% for\nAPOLOGISEE, and 96.47% for INTENSIFIER. This suggests that it is feasible to\nuse LLM-assisted annotation for local grammar analysis, together with human\nintervention on tags that are less accurately recognized by machine. We\nstrongly advocate conducting future studies to evaluate the performance of LLMs\nin annotating other linguistic phenomena. These studies have the potential to\noffer valuable insights into the advancement of theories developed in corpus\nlinguistics, as well into the linguistic capabilities of LLMs..\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Danni Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuoli_M/0/1/0/all/0/1\">Matteo Fuoli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"sustain.AI: a Recommender System to analyze Sustainability Reports. (arXiv:2305.08711v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08711","description":"<p>We present $\\text{sustain.AI}$, an intelligent, context-aware recommender\nsystem that assists auditors and financial investors as well as the general\npublic to efficiently analyze companies' sustainability reports. The tool\nleverages an end-to-end trainable architecture that couples a BERT-based\nencoding module with a multi-label classification head to match relevant text\npassages from sustainability reports to their respective law regulations from\nthe Global Reporting Initiative (GRI) standards. We evaluate our model on two\nnovel German sustainability reporting data sets and consistently achieve a\nsignificantly higher recommendation performance compared to multiple strong\nbaselines. Furthermore, $\\text{sustain.AI}$ is publicly available for everyone\nat https://sustain.ki.nrw/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hillebrand_L/0/1/0/all/0/1\">Lars Hillebrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pielka_M/0/1/0/all/0/1\">Maren Pielka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonhard_D/0/1/0/all/0/1\">David Leonhard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deusser_T/0/1/0/all/0/1\">Tobias Deu&#xdf;er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilmaghani_T/0/1/0/all/0/1\">Tim Dilmaghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kliem_B/0/1/0/all/0/1\">Bernd Kliem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loitz_R/0/1/0/all/0/1\">R&#xfc;diger Loitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morad_M/0/1/0/all/0/1\">Milad Morad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Temath_C/0/1/0/all/0/1\">Christian Temath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bell_T/0/1/0/all/0/1\">Thiago Bell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenzel_R/0/1/0/all/0/1\">Robin Stenzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifa_R/0/1/0/all/0/1\">Rafet Sifa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From chocolate bunny to chocolate crocodile: Do Language Models Understand Noun Compounds?. (arXiv:2305.10568v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10568","description":"<p>Noun compound interpretation is the task of expressing a noun compound (e.g.\nchocolate bunny) in a free-text paraphrase that makes the relationship between\nthe constituent nouns explicit (e.g. bunny-shaped chocolate). We propose\nmodifications to the data and evaluation setup of the standard task (Hendrickx\net al., 2013), and show that GPT-3 solves it almost perfectly. We then\ninvestigate the task of noun compound conceptualization, i.e. paraphrasing a\nnovel or rare noun compound. E.g., chocolate crocodile is a crocodile-shaped\nchocolate. This task requires creativity, commonsense, and the ability to\ngeneralize knowledge about similar concepts. While GPT-3's performance is not\nperfect, it is better than that of humans -- likely thanks to its access to\nvast amounts of knowledge, and because conceptual processing is effortful for\npeople (Connell and Lynott, 2012). Finally, we estimate the extent to which\nGPT-3 is reasoning about the world vs. parroting its training data. We find\nthat the outputs from GPT-3 often have significant overlap with a large web\ncorpus, but that the parroting strategy is less beneficial for novel noun\ncompounds.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Coil_J/0/1/0/all/0/1\">Jordan Coil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Accurate and Reliable Confidence Estimation Based on Non-Autoregressive End-to-End Speech Recognition System. (arXiv:2305.10680v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2305.10680","description":"<p>Estimating confidence scores for recognition results is a classic task in ASR\nfield and of vital importance for kinds of downstream tasks and training\nstrategies. Previous end-to-end~(E2E) based confidence estimation models (CEM)\npredict score sequences of equal length with input transcriptions, leading to\nunreliable estimation when deletion and insertion errors occur. In this paper\nwe proposed CIF-Aligned confidence estimation model (CA-CEM) to achieve\naccurate and reliable confidence estimation based on novel non-autoregressive\nE2E ASR model - Paraformer. CA-CEM utilizes the modeling character of\ncontinuous integrate-and-fire (CIF) mechanism to generate token-synchronous\nacoustic embedding, which solves the estimation failure issue above. We measure\nthe quality of estimation with AUC and RMSE in token level and ECE-U - a\nproposed metrics in utterance level. CA-CEM gains 24% and 19% relative\nreduction on ECE-U and also better AUC and RMSE on two test sets. Furthermore,\nwe conduct analysis to explore the potential of CEM for different ASR related\nusage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haoneng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhifu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhijie Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning Implicit Sentiment with Chain-of-Thought Prompting. (arXiv:2305.11255v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11255","description":"<p>While sentiment analysis systems try to determine the sentiment polarities of\ngiven targets based on the key opinion expressions in input texts, in implicit\nsentiment analysis (ISA) the opinion cues come in an implicit and obscure\nmanner. Thus detecting implicit sentiment requires the common-sense and\nmulti-hop reasoning ability to infer the latent intent of opinion. Inspired by\nthe recent chain-of-thought (CoT) idea, in this work we introduce a Three-hop\nReasoning (THOR) CoT framework to mimic the human-like reasoning process for\nISA. We design a three-step prompting principle for THOR to step-by-step induce\nthe implicit aspect, opinion, and finally the sentiment polarity. Our\nTHOR+Flan-T5 (11B) pushes the state-of-the-art (SoTA) by over 6% F1 on\nsupervised setup. More strikingly, THOR+GPT3 (175B) boosts the SoTA by over 50%\nF1 on zero-shot setting. Our code is at\nhttps://github.com/scofield7419/THOR-ISA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Text Classification via Self-Supervised Tuning. (arXiv:2305.11442v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11442","description":"<p>Existing solutions to zero-shot text classification either conduct prompting\nwith pre-trained language models, which is sensitive to the choices of\ntemplates, or rely on large-scale annotated data of relevant tasks for\nmeta-tuning. In this work, we propose a new paradigm based on self-supervised\nlearning to solve zero-shot text classification tasks by tuning the language\nmodels with unlabeled data, called self-supervised tuning. By exploring the\ninherent structure of free texts, we propose a new learning objective called\nfirst sentence prediction to bridge the gap between unlabeled data and text\nclassification tasks. After tuning the model to learn to predict the first\nsentence in a paragraph based on the rest, the model is able to conduct\nzero-shot inference on unseen tasks such as topic classification and sentiment\nanalysis. Experimental results show that our model outperforms the\nstate-of-the-art baselines on 7 out of 10 tasks. Moreover, the analysis reveals\nthat our model is less sensitive to the prompt design. Our code and pre-trained\nmodels are publicly available at https://github.com/DAMO-NLP-SG/SSTuning .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chaoqun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guizhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaobao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Chip Hong Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Information Screening whilst Exploiting! Multimodal Relation Extraction with Feature Denoising and Multimodal Topic Modeling. (arXiv:2305.11719v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.11719","description":"<p>Existing research on multimodal relation extraction (MRE) faces two\nco-existing challenges, internal-information over-utilization and\nexternal-information under-exploitation. To combat that, we propose a novel\nframework that simultaneously implements the idea of internal-information\nscreening and external-information exploiting. First, we represent the\nfine-grained semantic structures of the input image and text with the visual\nand textual scene graphs, which are further fused into a unified cross-modal\ngraph (CMG). Based on CMG, we perform structure refinement with the guidance of\nthe graph information bottleneck principle, actively denoising the\nless-informative features. Next, we perform topic modeling over the input image\nand text, incorporating latent multimodal topic features to enrich the\ncontexts. On the benchmark MRE dataset, our system outperforms the current best\nmodel significantly. With further in-depth analyses, we reveal the great\npotential of our method for the MRE task. Our codes are open at\nhttps://github.com/ChocoWu/MRE-ISE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Visual Spatial Description via Holistic 3D Scene Understanding. (arXiv:2305.11768v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.11768","description":"<p>Visual spatial description (VSD) aims to generate texts that describe the\nspatial relations of the given objects within images. Existing VSD work merely\nmodels the 2D geometrical vision features, thus inevitably falling prey to the\nproblem of skewed spatial understanding of target objects. In this work, we\ninvestigate the incorporation of 3D scene features for VSD. With an external 3D\nscene extractor, we obtain the 3D objects and scene features for input images,\nbased on which we construct a target object-centered 3D spatial scene graph\n(Go3D-S2G), such that we model the spatial semantics of target objects within\nthe holistic 3D scenes. Besides, we propose a scene subgraph selecting\nmechanism, sampling topologically-diverse subgraphs from Go3D-S2G, where the\ndiverse local structure features are navigated to yield spatially-diversified\ntext generation. Experimental results on two VSD datasets demonstrate that our\nframework outperforms the baselines significantly, especially improving on the\ncases with complex visual spatial relations. Meanwhile, our method can produce\nmore spatially-diversified generation. Code is available at\nhttps://github.com/zhaoyucs/VSD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jianguo Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meishan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prefix Propagation: Parameter-Efficient Tuning for Long Sequences. (arXiv:2305.12086v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12086","description":"<p>Parameter-efficient tuning aims to mitigate the large memory requirements of\nadapting pretrained language models for downstream tasks. For example, one\npopular method, prefix-tuning, prepends trainable tokens to sequences while\nfreezing the rest of the model's parameters. Although such models attain\ncomparable performance with fine-tuning when applied to sequences with short to\nmoderate lengths, we show their inferior performance when modelling long\nsequences. To bridge this gap, we propose prefix-propagation, a simple but\neffective approach that conditions prefixes on previous hidden states. We\nempirically demonstrate that prefix-propagation outperforms prefix-tuning\nacross long-document tasks, while using 50% fewer parameters. To further\ninvestigate the proposed architecture, we also show its advantage in\ncalibration, and perform additional study on its relationship with kernel\nattention. To the best of our knowledge, this work is the first to focus on\nparameter-efficient learning for long-sequence language tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jonathan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_W/0/1/0/all/0/1\">Will Aitken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhambhoria_R/0/1/0/all/0/1\">Rohan Bhambhoria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Collaborative Development of NLP models. (arXiv:2305.12219v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.12219","description":"<p>Despite substantial advancements, Natural Language Processing (NLP) models\noften require post-training adjustments to enforce business rules, rectify\nundesired behavior, and align with user values. These adjustments involve\noperationalizing \"concepts\"--dictating desired model responses to certain\ninputs. However, it's difficult for a single entity to enumerate and define all\npossible concepts, indicating a need for a multi-user, collaborative model\nalignment framework. Moreover, the exhaustive delineation of a concept is\nchallenging, and an improper approach can create shortcuts or interfere with\noriginal data or other concepts.\n</p>\n<p>To address these challenges, we introduce CoDev, a framework that enables\nmulti-user interaction with the model, thereby mitigating individual\nlimitations. CoDev aids users in operationalizing their concepts using Large\nLanguage Models, and relying on the principle that NLP models exhibit simpler\nbehaviors in local regions. Our main insight is learning a \\emph{local} model\nfor each concept, and a \\emph{global} model to integrate the original data with\nall concepts. We then steer a large language model to generate instances within\nconcept boundaries where local and global disagree. Our experiments show CoDev\nis effective at helping multiple users operationalize concepts and avoid\ninterference for a variety of scenarios, tasks, and models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khani_F/0/1/0/all/0/1\">Fereshte Khani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1\">Marco Tulio Ribeiro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scene Graph as Pivoting: Inference-time Image-free Unsupervised Multimodal Machine Translation with Visual Scene Hallucination. (arXiv:2305.12256v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12256","description":"<p>In this work, we investigate a more realistic unsupervised multimodal machine\ntranslation (UMMT) setup, inference-time image-free UMMT, where the model is\ntrained with source-text image pairs, and tested with only source-text inputs.\nFirst, we represent the input images and texts with the visual and language\nscene graphs (SG), where such fine-grained vision-language features ensure a\nholistic understanding of the semantics. To enable pure-text input during\ninference, we devise a visual scene hallucination mechanism that dynamically\ngenerates pseudo visual SG from the given textual SG. Several SG-pivoting based\nlearning objectives are introduced for unsupervised translation training. On\nthe benchmark Multi30K data, our SG-based method outperforms the\nbest-performing baseline by significant BLEU scores on the task and setup,\nhelping yield translations with better completeness, relevance and fluency\nwithout relying on paired images. Further in-depth analyses reveal how our\nmodel advances in the task setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meishan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constructing Code-mixed Universal Dependency Forest for Unbiased Cross-lingual Relation Extraction. (arXiv:2305.12258v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12258","description":"<p>Latest efforts on cross-lingual relation extraction (XRE) aggressively\nleverage the language-consistent structural features from the universal\ndependency (UD) resource, while they may largely suffer from biased transfer\n(e.g., either target-biased or source-biased) due to the inevitable linguistic\ndisparity between languages. In this work, we investigate an unbiased UD-based\nXRE transfer by constructing a type of code-mixed UD forest. We first translate\nthe sentence of the source language to the parallel target-side language, for\nboth of which we parse the UD tree respectively. Then, we merge the\nsource-/target-side UD structures as a unified code-mixed UD forest. With such\nforest features, the gaps of UD-based XRE between the training and predicting\nphases can be effectively closed. We conduct experiments on the ACE XRE\nbenchmark datasets, where the results demonstrate that the proposed code-mixed\nUD forests help unbiased UD-based XRE transfer, with which we achieve\nsignificant XRE performance gains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meishan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross2StrA: Unpaired Cross-lingual Image Captioning with Cross-lingual Cross-modal Structure-pivoted Alignment. (arXiv:2305.12260v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.12260","description":"<p>Unpaired cross-lingual image captioning has long suffered from irrelevancy\nand disfluency issues, due to the inconsistencies of the semantic scene and\nsyntax attributes during transfer. In this work, we propose to address the\nabove problems by incorporating the scene graph (SG) structures and the\nsyntactic constituency (SC) trees. Our captioner contains the semantic\nstructure-guided image-to-pivot captioning and the syntactic structure-guided\npivot-to-target translation, two of which are joined via pivot language. We\nthen take the SG and SC structures as pivoting, performing cross-modal semantic\nstructure alignment and cross-lingual syntactic structure alignment learning.\nWe further introduce cross-lingual&amp;cross-modal back-translation training to\nfully align the captioning and translation stages. Experiments on\nEnglish-Chinese transfers show that our model shows great superiority in\nimproving captioning relevancy and fluency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient-Boosted Decision Tree for Listwise Context Model in Multimodal Review Helpfulness Prediction. (arXiv:2305.12678v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12678","description":"<p>Multimodal Review Helpfulness Prediction (MRHP) aims to rank product reviews\nbased on predicted helpfulness scores and has been widely applied in e-commerce\nvia presenting customers with useful reviews. Previous studies commonly employ\nfully-connected neural networks (FCNNs) as the final score predictor and\npairwise loss as the training objective. However, FCNNs have been shown to\nperform inefficient splitting for review features, making the model difficult\nto clearly differentiate helpful from unhelpful reviews. Furthermore, pairwise\nobjective, which works on review pairs, may not completely capture the MRHP\ngoal to produce the ranking for the entire review list, and possibly induces\nlow generalization during testing. To address these issues, we propose a\nlistwise attention network that clearly captures the MRHP ranking context and a\nlistwise optimization objective that enhances model generalization. We further\npropose gradient-boosted decision tree as the score predictor to efficaciously\npartition product reviews' representations. Extensive experiments demonstrate\nthat our method achieves state-of-the-art results and polished generalization\nperformance on two large-scale MRHP benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaobao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xinshuai Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cong-Duy Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hai_Z/0/1/0/all/0/1\">Zhen Hai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FIT: Far-reaching Interleaved Transformers. (arXiv:2305.12689v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.12689","description":"<p>We present FIT: a transformer-based architecture with efficient\nself-attention and adaptive computation. Unlike original transformers, which\noperate on a single sequence of data tokens, we divide the data tokens into\ngroups, with each group being a shorter sequence of tokens. We employ two types\nof transformer layers: local layers operate on data tokens within each group,\nwhile global layers operate on a smaller set of introduced latent tokens. These\nlayers, comprising the same set of self-attention and feed-forward layers as\nstandard transformers, are interleaved, and cross-attention is used to\nfacilitate information exchange between data and latent tokens within the same\ngroup. The attention complexity is $O(n^2)$ locally within each group of size\n$n$, but can reach $O(L^{{4}/{3}})$ globally for sequence length of $L$. The\nefficiency can be further enhanced by relying more on global layers that\nperform adaptive computation using a smaller set of latent tokens. FIT is a\nversatile architecture and can function as an encoder, diffusion decoder, or\nautoregressive decoder. We provide initial evidence demonstrating its\neffectiveness in high-resolution image understanding and generation tasks.\nNotably, FIT exhibits potential in performing end-to-end training on\ngigabit-scale data, such as 6400$\\times$6400 images, or 160K tokens (after\npatch tokenization), within a memory capacity of 16GB, without requiring\nspecific optimizations or model parallelism.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lala Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Optimal Policy for Simultaneous Machine Translation via Binary Search. (arXiv:2305.12774v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12774","description":"<p>Simultaneous machine translation (SiMT) starts to output translation while\nreading the source sentence and needs a precise policy to decide when to output\nthe generated translation. Therefore, the policy determines the number of\nsource tokens read during the translation of each target token. However, it is\ndifficult to learn a precise translation policy to achieve good latency-quality\ntrade-offs, because there is no golden policy corresponding to parallel\nsentences as explicit supervision. In this paper, we present a new method for\nconstructing the optimal policy online via binary search. By employing explicit\nsupervision, our approach enables the SiMT model to learn the optimal policy,\nwhich can guide the model in completing the translation during inference.\nExperiments on four translation tasks show that our method can exceed strong\nbaselines across all latency scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shoutao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EMNS /Imz/ Corpus: An emotive single-speaker dataset for narrative storytelling in games, television and graphic novels. (arXiv:2305.13137v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13137","description":"<p>The increasing adoption of text-to-speech technologies has led to a growing\ndemand for natural and emotive voices that adapt to a conversation's context\nand emotional tone. The Emotive Narrative Storytelling (EMNS) corpus is a\nunique speech dataset created to enhance conversations' expressiveness and\nemotive quality in interactive narrative-driven systems. The corpus consists of\na 2.3-hour recording featuring a female speaker delivering labelled utterances.\nIt encompasses eight acted emotional states, evenly distributed with a variance\nof 0.68%, along with expressiveness levels and natural language descriptions\nwith word emphasis labels. The evaluation of audio samples from different\ndatasets revealed that the EMNS corpus achieved the highest average scores in\naccurately conveying emotions and demonstrating expressiveness. It outperformed\nother datasets in conveying shared emotions and achieved comparable levels of\ngenuineness. A classification task confirmed the accurate representation of\nintended emotions in the corpus, with participants recognising the recordings\nas genuine and expressive. Additionally, the availability of the dataset\ncollection tool under the Apache 2.0 License simplifies remote speech data\ncollection for researchers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noriy_K/0/1/0/all/0/1\">Kari Ali Noriy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaosong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jian Jun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Role of Feed-Forward Networks in Transformers Using Parallel Attention and Feed-Forward Net Design. (arXiv:2305.13297v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13297","description":"<p>This paper investigates the key role of Feed-Forward Networks (FFNs) in\ntransformer models by utilizing the Parallel Attention and Feed-Forward Net\nDesign (PAF) architecture, and comparing it to their Series Attention and\nFeed-Forward Net Design (SAF) counterparts. Central to the effectiveness of PAF\nare two main assumptions regarding the FFN block and the attention block within\na layer: 1) the primary function of the FFN block is to maintain isotropy among\ntoken embeddings and prevent their degeneration, and 2) the residual norm\ncomputed in the attention block is substantially smaller than the input token\nembedding norm. To empirically validate these assumptions, we train PAF\nvariants of two large language models (RoBERTa-large and bert-large-uncased).\nOur results demonstrate that both assumptions hold true in the PAF design. This\nstudy contributes to a deeper understanding of the roles and interactions\nbetween FFNs and self-attention mechanisms in transformer architectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sonkar_S/0/1/0/all/0/1\">Shashank Sonkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1\">Richard G. Baraniuk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Readability Assessment for Closely Related Languages. (arXiv:2305.13478v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13478","description":"<p>In recent years, the main focus of research on automatic readability\nassessment (ARA) has shifted towards using expensive deep learning-based\nmethods with the primary goal of increasing models' accuracy. This, however, is\nrarely applicable for low-resource languages where traditional handcrafted\nfeatures are still widely used due to the lack of existing NLP tools to extract\ndeeper linguistic representations. In this work, we take a step back from the\ntechnical component and focus on how linguistic aspects such as mutual\nintelligibility or degree of language relatedness can improve ARA in a\nlow-resource setting. We collect short stories written in three languages in\nthe Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment\nmodels and explore the interaction of data and features in various\ncross-lingual setups. Our results show that the inclusion of CrossNGO, a novel\nspecialized feature exploiting n-gram overlap applied to languages with high\nmutual intelligibility, significantly improves the performance of ARA models\ncompared to the use of off-the-shelf large multilingual language models alone.\nConsequently, when both linguistic representations are combined, we achieve\nstate-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA\nin Bikol.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Imperial_J/0/1/0/all/0/1\">Joseph Marvin Imperial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochmar_E/0/1/0/all/0/1\">Ekaterina Kochmar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation. (arXiv:2305.14635v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14635","description":"<p>End-to-end speech translation (ST) is the task of translating speech signals\nin the source language into text in the target language. As a cross-modal task,\nend-to-end ST is difficult to train with limited data. Existing methods often\ntry to transfer knowledge from machine translation (MT), but their performances\nare restricted by the modality gap between speech and text. In this paper, we\npropose Cross-modal Mixup via Optimal Transport CMOT to overcome the modality\ngap. We find the alignment between speech and text sequences via optimal\ntransport and then mix up the sequences from different modalities at a token\nlevel using the alignment. Experiments on the MuST-C ST benchmark demonstrate\nthat CMOT achieves an average BLEU of 30.0 in 8 translation directions,\noutperforming previous methods. Further analysis shows CMOT can adaptively find\nthe alignment between modalities, which helps alleviate the modality gap\nbetween speech and text. Code is publicly available at\nhttps://github.com/ictnlp/CMOT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Q/0/1/0/all/0/1\">Qingkai Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Denoising Bottleneck with Mutual Information Maximization for Video Multimodal Fusion. (arXiv:2305.14652v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14652","description":"<p>Video multimodal fusion aims to integrate multimodal signals in videos, such\nas visual, audio and text, to make a complementary prediction with multiple\nmodalities contents. However, unlike other image-text multimodal tasks, video\nhas longer multimodal sequences with more redundancy and noise in both visual\nand audio modalities. Prior denoising methods like forget gate are coarse in\nthe granularity of noise filtering. They often suppress the redundant and noisy\ninformation at the risk of losing critical information. Therefore, we propose a\ndenoising bottleneck fusion (DBF) model for fine-grained video multimodal\nfusion. On the one hand, we employ a bottleneck mechanism to filter out noise\nand redundancy with a restrained receptive field. On the other hand, we use a\nmutual information maximization module to regulate the filter-out module to\npreserve key information within different modalities. Our DBF model achieves\nsignificant improvement over current state-of-the-art baselines on multiple\nbenchmarks covering multimodal sentiment analysis and multimodal summarization\ntasks. It proves that our model can effectively capture salient features from\nnoisy and redundant video, audio, and text inputs. The code for this paper is\npublicly available at https://github.com/WSXRHFG/DBF.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shaoxaing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Ziwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Binghuai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunbo Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utility-Probability Duality of Neural Networks. (arXiv:2305.14859v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.14859","description":"<p>It is typically understood that the training of modern neural networks is a\nprocess of fitting the probability distribution of desired output. However,\nrecent paradoxical observations in a number of language generation tasks let\none wonder if this canonical probability-based explanation can really account\nfor the empirical success of deep learning. To resolve this issue, we propose\nan alternative utility-based explanation to the standard supervised learning\nprocedure in deep learning. The basic idea is to interpret the learned neural\nnetwork not as a probability model but as an ordinal utility function that\nencodes the preference revealed in training data. In this perspective, training\nof the neural network corresponds to a utility learning process. Specifically,\nwe show that for all neural networks with softmax outputs, the SGD learning\ndynamic of maximum likelihood estimation (MLE) can be seen as an iteration\nprocess that optimizes the neural network toward an optimal utility function.\nThis utility-based interpretation can explain several otherwise-paradoxical\nobservations about the neural networks thus trained. Moreover, our\nutility-based theory also entails an equation that can transform the learned\nutility values back to a new kind of probability estimation with which\nprobability-compatible decision rules enjoy dramatic (double-digits)\nperformance improvements. These evidences collectively reveal a phenomenon of\nutility-probability duality in terms of what modern neural networks are (truly)\nmodeling: We thought they are one thing (probabilities), until the\nunexplainable showed up; changing mindset and treating them as another thing\n(utility values) largely reconcile the theory, despite remaining subtleties\nregarding its original (probabilistic) identity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bojun_H/0/1/0/all/0/1\">Huang Bojun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1\">Fei Yuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RefGPT: Reference -> Truthful & Customized Dialogues Generation by GPTs and for GPTs. (arXiv:2305.14994v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14994","description":"<p>General chat models, like ChatGPT, have attained impressive capability to\nresolve a wide range of NLP tasks by tuning Large Language Models (LLMs) with\nhigh-quality instruction data. However, collecting human-written high-quality\ndata, especially multi-turn dialogues, is expensive and unattainable for most\npeople. Though previous studies have used powerful LLMs to generate the\ndialogues automatically, but they all suffer from generating untruthful\ndialogues because of the LLMs hallucination. Therefore, we propose a method\ncalled RefGPT to generate enormous truthful and customized dialogues without\nworrying about factual errors caused by the model hallucination. RefGPT solves\nthe model hallucination in dialogue generation by restricting the LLMs to\nleverage the given reference instead of reciting their own knowledge to\ngenerate dialogues. Additionally, RefGPT adds detailed controls on every\nutterances to enable highly customization capability, which previous studies\nhave ignored. On the basis of RefGPT, we also propose two high-quality dialogue\ndatasets generated by GPT-4, namely RefGPT-Fact and RefGPT-Code. RefGPT-Fact is\n100k multi-turn dialogue datasets based on factual knowledge and RefGPT-Code is\n76k multi-turn dialogue dataset covering a wide range of coding scenarios. Our\ncode and datasets are released in https://github.com/ziliwangnlp/RefGPT\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dongjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Ruifeng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">YuanTao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">YiFei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zili Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shusen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Level Knowledge Distillation for Out-of-Distribution Detection in Text. (arXiv:2211.11300v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2211.11300","description":"<p>Self-supervised representation learning has proved to be a valuable component\nfor out-of-distribution (OoD) detection with only the texts of in-distribution\n(ID) examples. These approaches either train a language model from scratch or\nfine-tune a pre-trained language model using ID examples, and then take the\nperplexity output by the language model as OoD scores. In this paper, we\nanalyze the complementary characteristics of both OoD detection methods and\npropose a multi-level knowledge distillation approach that integrates their\nstrengths while mitigating their limitations. Specifically, we use a fine-tuned\nmodel as the teacher to teach a randomly initialized student model on the ID\nexamples. Besides the prediction layer distillation, we present a\nsimilarity-based intermediate layer distillation method to thoroughly explore\nthe representation space of the teacher model. In this way, the learned student\ncan better represent the ID data manifold while gaining a stronger ability to\nmap OoD examples outside the ID data manifold with the regularization inherited\nfrom pre-training. Besides, the student model sees only ID examples during\nparameter learning, further promoting more distinguishable features for OoD\ndetection. We conduct extensive experiments over multiple benchmark datasets,\ni.e., CLINC150, SST, ROSTD, 20 NewsGroups, and AG News; showing that the\nproposed method yields new state-of-the-art performance. We also explore its\napplication as an AIGC detector to distinguish between answers generated by\nChatGPT and human experts. It is observed that our model exceeds human\nevaluators in the pair-expert task on the Human ChatGPT Comparison Corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qianhui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Huiqiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Haonan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlsson_B/0/1/0/all/0/1\">B&#xf6;rje F. Karlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chin-Yew Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Contrastive Finetuning Improves Low-Resource Relation Extraction. (arXiv:2212.10823v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2212.10823","description":"<p>Relation extraction (RE), which has relied on structurally annotated corpora\nfor model training, has been particularly challenging in low-resource scenarios\nand domains. Recent literature has tackled low-resource RE by self-supervised\nlearning, where the solution involves pretraining the relation embedding by\nRE-based objective and finetuning on labeled data by classification-based\nobjective. However, a critical challenge to this approach is the gap in\nobjectives, which prevents the RE model from fully utilizing the knowledge in\npretrained representations. In this paper, we aim at bridging the gap and\npropose to pretrain and finetune the RE model using consistent objectives of\ncontrastive learning. Since in this kind of representation learning paradigm,\none relation may easily form multiple clusters in the representation space, we\nfurther propose a multi-center contrastive loss that allows one relation to\nform multiple clusters to better align with pretraining. Experiments on two\ndocument-level RE datasets, BioRED and Re-DocRED, demonstrate the effectiveness\nof our method. Particularly, when using 1% end-task training data, our method\noutperforms PLM-based RE classifier by 10.5% and 5.8% on the two datasets,\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1\">Tristan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-05-25T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/"}}]}]}