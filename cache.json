{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-25T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple Experts Fine-tuning. (arXiv:2310.15205v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15205","description":"<p>We propose Multiple Experts Fine-tuning Framework to build a financial large\nlanguage model (LLM), DISC-FinLLM. Our methodology improves general LLMs by\nendowing them with multi-turn question answering abilities, domain text\nprocessing capabilities, mathematical computation skills, and\nretrieval-enhanced generation capabilities. We build a financial\ninstruction-tuning dataset named DISC-FIN-SFT, including instruction samples of\nfour categories (consulting, NLP tasks, computing and retrieval-augmented\ngeneration). Evaluations conducted on multiple benchmarks demonstrate that our\nmodel performs better than baseline models in various financial scenarios.\nFurther resources can be found at https://github.com/FudanDISC/DISC-FinLLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qiushi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1\">Zefei Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xianyin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhongtian Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiarong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xiang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Function Vectors in Large Language Models. (arXiv:2310.15213v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15213","description":"<p>We report the presence of a simple neural mechanism that represents an\ninput-output function as a vector within autoregressive transformer language\nmodels (LMs). Using causal mediation analysis on a diverse range of\nin-context-learning (ICL) tasks, we find that a small number attention heads\ntransport a compact representation of the demonstrated task, which we call a\nfunction vector (FV). FVs are robust to changes in context, i.e., they trigger\nexecution of the task on inputs such as zero-shot and natural text settings\nthat do not resemble the ICL contexts from which they are collected. We test\nFVs across a range of tasks, models, and layers and find strong causal effects\nacross settings in middle layers. We investigate the internal structure of FVs\nand find while that they often contain information that encodes the output\nspace of the function, this information alone is not sufficient to reconstruct\nan FV. Finally, we test semantic vector composition in FVs, and find that to\nsome extent they can be summed to create vectors that trigger new complex\ntasks. Taken together, our findings suggest that LLMs contain internal\nabstractions of general-purpose functions that can be invoked in a variety of\ncontexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Todd_E/0/1/0/all/0/1\">Eric Todd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Millicent L. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Arnab Sen Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mueller_A/0/1/0/all/0/1\">Aaron Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1\">David Bau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks. (arXiv:2310.15239v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15239","description":"<p>Recent efforts in natural language processing (NLP) commonsense reasoning\nresearch have yielded a considerable number of new datasets and benchmarks.\nHowever, most of these datasets formulate commonsense reasoning challenges in\nartificial scenarios that are not reflective of the tasks which real-world NLP\nsystems are designed to solve. In this work, we present CRoW, a\nmanually-curated, multi-task benchmark that evaluates the ability of models to\napply commonsense reasoning in the context of six real-world NLP tasks. CRoW is\nconstructed using a multi-stage data collection pipeline that rewrites examples\nfrom existing datasets using commonsense-violating perturbations. We use CRoW\nto study how NLP systems perform across different dimensions of commonsense\nknowledge, such as physical, temporal, and social reasoning. We find a\nsignificant performance gap when NLP systems are evaluated on CRoW compared to\nhumans, showcasing that commonsense reasoning is far from being solved in\nreal-world task settings. We make our dataset and leaderboard available to the\nresearch community at https://github.com/mismayil/crow.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ismayilzada_M/0/1/0/all/0/1\">Mete Ismayilzada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjit Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montariol_S/0/1/0/all/0/1\">Syrielle Montariol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention. (arXiv:2310.15258v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15258","description":"<p>In this work, we study whether multilingual language models (MultiLMs) can\ntransfer logical reasoning abilities to other languages when they are\nfine-tuned for reasoning in a different language. We evaluate the cross-lingual\nreasoning abilities of MultiLMs in two schemes: (1) where the language of the\ncontext and the question remain the same in the new languages that are tested\n(i.e., the reasoning is still monolingual, but the model must transfer the\nlearned reasoning ability across languages), and (2) where the language of the\ncontext and the question is different (which we term code-switched reasoning).\nOn two logical reasoning datasets, RuleTaker and LeapOfThought, we demonstrate\nthat although MultiLMs can transfer reasoning ability across languages in a\nmonolingual setting, they struggle to transfer reasoning abilities in a\ncode-switched setting. Following this observation, we propose a novel attention\nmechanism that uses a dedicated set of parameters to encourage cross-lingual\nattention in code-switched sequences, which improves the reasoning performance\nby up to 14% and 4% on the RuleTaker and LeapOfThought datasets, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Foroutan_N/0/1/0/all/0/1\">Negar Foroutan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banaei_M/0/1/0/all/0/1\">Mohammadreza Banaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aberer_K/0/1/0/all/0/1\">Karl Aberer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards. (arXiv:2310.15259v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15259","description":"<p>Community Question-Answering (CQA) portals serve as a valuable tool for\nhelping users within an organization. However, making them accessible to\nnon-English-speaking users continues to be a challenge. Translating questions\ncan broaden the community's reach, benefiting individuals with similar\ninquiries in various languages. Translating questions using Neural Machine\nTranslation (NMT) poses more challenges, especially in noisy environments,\nwhere the grammatical correctness of the questions is not monitored. These\nquestions may be phrased as statements by non-native speakers, with incorrect\nsubject-verb order and sometimes even missing question marks. Creating a\nsynthetic parallel corpus from such data is also difficult due to its noisy\nnature. To address this issue, we propose a training methodology that\nfine-tunes the NMT system only using source-side data. Our approach balances\nadequacy and fluency by utilizing a loss function that combines BERTScore and\nMasked Language Model (MLM) Score. Our method surpasses the conventional\nMaximum Likelihood Estimation (MLE) based fine-tuning approach, which relies on\nsynthetic target data, by achieving a 1.9 BLEU score improvement. Our model\nexhibits robustness while we add noise to our baseline, and still achieve 1.1\nBLEU improvement and large improvements on TER and BLEURT metrics. Our proposed\nmethodology is model-agnostic and is only necessary during the training phase.\nWe make the codes and datasets publicly available at\n\\url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DomainAdapt} for\nfacilitating further research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gain_B/0/1/0/all/0/1\">Baban Gain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Appicharla_R/0/1/0/all/0/1\">Ramakrishna Appicharla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chennabasavaraj_S/0/1/0/all/0/1\">Soumya Chennabasavaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garera_N/0/1/0/all/0/1\">Nikesh Garera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekbal_A/0/1/0/all/0/1\">Asif Ekbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chelliah_M/0/1/0/all/0/1\">Muthusamy Chelliah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation Techniques for Machine Translation of Code-Switched Texts: A Comparative Study. (arXiv:2310.15262v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15262","description":"<p>Code-switching (CSW) text generation has been receiving increasing attention\nas a solution to address data scarcity. In light of this growing interest, we\nneed more comprehensive studies comparing different augmentation approaches. In\nthis work, we compare three popular approaches: lexical replacements,\nlinguistic theories, and back-translation (BT), in the context of Egyptian\nArabic-English CSW. We assess the effectiveness of the approaches on machine\ntranslation and the quality of augmentations through human evaluation. We show\nthat BT and CSW predictive-based lexical replacement, being trained on CSW\nparallel data, perform best on both tasks. Linguistic theories and random\nlexical replacement prove to be effective in the lack of CSW parallel data,\nwhere both approaches achieve similar results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hamed_I/0/1/0/all/0/1\">Injy Hamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habash_N/0/1/0/all/0/1\">Nizar Habash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey. (arXiv:2310.15264v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15264","description":"<p>Large Language Models (LLMs) have revolutionized the domain of natural\nlanguage processing (NLP) with remarkable capabilities of generating human-like\ntext responses. However, despite these advancements, several works in the\nexisting literature have raised serious concerns about the potential misuse of\nLLMs such as spreading misinformation, generating fake news, plagiarism in\nacademia, and contaminating the web. To address these concerns, a consensus\namong the research community is to develop algorithmic solutions to detect\nAI-generated text. The basic idea is that whenever we can tell if the given\ntext is either written by a human or an AI, we can utilize this information to\naddress the above-mentioned concerns. To that end, a plethora of detection\nframeworks have been proposed, highlighting the possibilities of AI-generated\ntext detection. But in parallel to the development of detection frameworks,\nresearchers have also concentrated on designing strategies to elude detection,\ni.e., focusing on the impossibilities of AI-generated text detection. This is a\ncrucial step in order to make sure the detection frameworks are robust enough\nand it is not too easy to fool a detector. Despite the huge interest and the\nflurry of research in this domain, the community currently lacks a\ncomprehensive analysis of recent developments. In this survey, we aim to\nprovide a concise categorization and overview of current work encompassing both\nthe prospects and the limitations of AI-generated text detection. To enrich the\ncollective knowledge, we engage in an exhaustive discussion on critical and\nchallenging open questions related to ongoing research on AI-generated text\ndetection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosal_S/0/1/0/all/0/1\">Soumya Suvra Ghosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Souradip Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1\">Jonas Geiping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bedi_A/0/1/0/all/0/1\">Amrit Singh Bedi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GradSim: Gradient-Based Language Grouping for Effective Multilingual Training. (arXiv:2310.15269v1 [cs.LG])","link":"http://arxiv.org/abs/2310.15269","description":"<p>Most languages of the world pose low-resource challenges to natural language\nprocessing models. With multilingual training, knowledge can be shared among\nlanguages. However, not all languages positively influence each other and it is\nan open research question how to select the most suitable set of languages for\nmultilingual training and avoid negative interference among languages whose\ncharacteristics or data distributions are not compatible. In this paper, we\npropose GradSim, a language grouping method based on gradient similarity. Our\nexperiments on three diverse multilingual benchmark datasets show that it leads\nto the largest performance gains compared to other similarity measures and it\nis better correlated with cross-lingual model performance. As a result, we set\nthe new state of the art on AfriSenti, a benchmark dataset for sentiment\nanalysis on low-resource African languages. In our extensive analysis, we\nfurther reveal that besides linguistic features, the topics of the datasets\nplay an important role for language grouping and that lower layers of\ntransformer models encode language-specific features while higher layers\ncapture task-specific information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adel_H/0/1/0/all/0/1\">Heike Adel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_L/0/1/0/all/0/1\">Lukas Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strotgen_J/0/1/0/all/0/1\">Jannik Str&#xf6;tgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Algorithms for Recognizing Weighted Tree-Adjoining Languages. (arXiv:2310.15276v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15276","description":"<p>The class of tree-adjoining languages can be characterized by various\ntwo-level formalisms, consisting of a context-free grammar (CFG) or pushdown\nautomaton (PDA) controlling another CFG or PDA. These four formalisms are\nequivalent to tree-adjoining grammars (TAG), linear indexed grammars (LIG),\npushdown-adjoining automata (PAA), and embedded pushdown automata (EPDA). We\ndefine semiring-weighted versions of the above two-level formalisms, and we\ndesign new algorithms for computing their stringsums (the weight of all\nderivations of a string) and allsums (the weight of all derivations). From\nthese, we also immediately obtain stringsum and allsum algorithms for TAG, LIG,\nPAA, and EPDA. For LIG, our algorithm is more time-efficient by a factor of\n$\\mathcal{O}(n|\\mathcal{N}|)$ (where $n$ is the string length and\n$|\\mathcal{N}|$ is the size of the nonterminal set) and more space-efficient by\na factor of $\\mathcal{O}(|\\Gamma|)$ (where $|\\Gamma|$ is the size of the stack\nalphabet) than the algorithm of Vijay-Shanker and Weir (1989). For EPDA, our\nalgorithm is both more space-efficient and time-efficient than the algorithm of\nAlonso et al. (2001) by factors of $\\mathcal{O}(|\\Gamma|^2)$ and\n$\\mathcal{O}(|\\Gamma|^3)$, respectively. Finally, we give the first PAA\nstringsum and allsum algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Butoi_A/0/1/0/all/0/1\">Alexandra Butoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1\">David Chiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Dimensionality of Sentence Embeddings. (arXiv:2310.15285v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15285","description":"<p>Learning sentence embeddings is a fundamental problem in natural language\nprocessing. While existing research primarily focuses on enhancing the quality\nof sentence embeddings, the exploration of sentence embedding dimensions is\nlimited. Here we present a comprehensive and empirical analysis of the\ndimensionality of sentence embeddings. First, we demonstrate that the optimal\ndimension of sentence embeddings is usually smaller than the default value.\nSubsequently, to compress the dimension of sentence embeddings with minimum\nperformance degradation, we identify two components contributing to the overall\nperformance loss: the encoder's performance loss and the pooler's performance\nloss. Therefore, we propose a two-step training method for sentence\nrepresentation learning models, wherein the encoder and the pooler are\noptimized separately to mitigate the overall performance loss in low-dimension\nscenarios. Experimental results on seven STS tasks and seven sentence\nclassification tasks demonstrate that our method significantly improves the\nperformance of low-dimensional sentence embeddings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling. (arXiv:2310.15294v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15294","description":"<p>Recently slot filling has witnessed great development thanks to deep learning\nand the availability of large-scale annotated data. However, it poses a\ncritical challenge to handle a novel domain whose samples are never seen during\ntraining. The recognition performance might be greatly degraded due to severe\ndomain shifts. Most prior works deal with this problem in a two-pass pipeline\nmanner based on metric learning. In practice, these dominant pipeline models\nmay be limited in computational efficiency and generalization capacity because\nof non-parallel inference and context-free discrete label embeddings. To this\nend, we re-examine the typical metric-based methods, and propose a new adaptive\nend-to-end metric learning scheme for the challenging zero-shot slot filling.\nConsidering simplicity, efficiency and generalizability, we present a\ncascade-style joint learning framework coupled with context-aware soft label\nrepresentations and slot-level contrastive representation learning to mitigate\nthe data and label shift problems effectively. Extensive experiments on public\nbenchmarks demonstrate the superiority of the proposed approach over a series\nof competitive baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanjun Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Linzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_M/0/1/0/all/0/1\">Minglai Shao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM. (arXiv:2310.15296v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15296","description":"<p>In the burgeoning field of natural language processing, Neural Topic Models\n(NTMs) and Large Language Models (LLMs) have emerged as areas of significant\nresearch interest. Despite this, NTMs primarily utilize contextual embeddings\nfrom LLMs, which are not optimal for clustering or capable for topic\ngeneration. Our study addresses this gap by introducing a novel framework named\nDiffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME).\nDeTiME leverages ncoder-Decoder-based LLMs to produce highly clusterable\nembeddings that could generate topics that exhibit both superior clusterability\nand enhanced semantic coherence compared to existing methods. Additionally, by\nexploiting the power of diffusion, our framework also provides the capability\nto generate content relevant to the identified topics. This dual functionality\nallows users to efficiently produce highly clustered topics and related content\nsimultaneously. DeTiME's potential extends to generating clustered embeddings\nas well. Notably, our proposed framework proves to be efficient to train and\nexhibits high adaptability, demonstrating its potential for a wide array of\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weijie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wenxiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fanyou Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengamedu_S/0/1/0/all/0/1\">Srinivasan Sengamedu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TaskDiff: A Similarity Metric for Task-Oriented Conversations. (arXiv:2310.15298v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15298","description":"<p>The popularity of conversational digital assistants has resulted in the\navailability of large amounts of conversational data which can be utilized for\nimproved user experience and personalized response generation. Building these\nassistants using popular large language models like ChatGPT also require\nadditional emphasis on prompt engineering and evaluation methods. Textual\nsimilarity metrics are a key ingredient for such analysis and evaluations.\nWhile many similarity metrics have been proposed in the literature, they have\nnot proven effective for task-oriented conversations as they do not take\nadvantage of unique conversational features. To address this gap, we present\nTaskDiff, a novel conversational similarity metric that utilizes different\ndialogue components (utterances, intents, and slots) and their distributions to\ncompute similarity. Extensive experimental evaluation of TaskDiff on a\nbenchmark dataset demonstrates its superior performance and improved robustness\nover other related approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhaumik_A/0/1/0/all/0/1\">Ankita Bhaumik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkateswaran_P/0/1/0/all/0/1\">Praveen Venkateswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rizk_Y/0/1/0/all/0/1\">Yara Rizk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isahagian_V/0/1/0/all/0/1\">Vatche Isahagian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City. (arXiv:2310.15302v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15302","description":"<p>Critical toponymy examines the dynamics of power, capital, and resistance\nthrough place names and the sites to which they refer. Studies here have\ntraditionally focused on the semantic content of toponyms and the top-down\ninstitutional processes that produce them. However, they have generally ignored\nthe ways in which toponyms are used by ordinary people in everyday discourse,\nas well as the other strategies of geospatial description that accompany and\ncontextualize toponymic reference. Here, we develop computational methods to\nmeasure how cultural and economic capital shape the ways in which people refer\nto places, through a novel annotated dataset of 47,440 New York City Airbnb\nlistings from the 2010s. Building on this dataset, we introduce a new named\nentity recognition (NER) model able to identify important discourse categories\nintegral to the characterization of place. Our findings point toward new\ndirections for critical toponymy and to a range of previously understudied\nlinguistic signals relevant to research on neighborhood status, housing and\ntourism markets, and gentrification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brunila_M/0/1/0/all/0/1\">Mikael Brunila</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LaViolette_J/0/1/0/all/0/1\">Jack LaViolette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+CH_Wang_S/0/1/0/all/0/1\">Sky CH-Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1\">Priyanka Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fere_C/0/1/0/all/0/1\">Clara F&#xe9;r&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKenzie_G/0/1/0/all/0/1\">Grant McKenzie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing Representations for Document-level Event Extraction. (arXiv:2310.15316v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15316","description":"<p>The probing classifiers framework has been employed for interpreting deep\nneural network models for a variety of natural language processing (NLP)\napplications. Studies, however, have largely focused on sentencelevel NLP\ntasks. This work is the first to apply the probing paradigm to representations\nlearned for document-level information extraction (IE). We designed eight\nembedding probes to analyze surface, semantic, and event-understanding\ncapabilities relevant to document-level event extraction. We apply them to the\nrepresentations acquired by learning models from three different LLM-based\ndocument-level IE approaches on a standard dataset. We found that trained\nencoders from these models yield embeddings that can modestly improve argument\ndetections and labeling but only slightly enhance event-level tasks, albeit\ntrade-offs in information helpful for coherence and event-type prediction. We\nfurther found that encoder models struggle with document length and\ncross-sentence discourse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Barry Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xinya Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1\">Claire Cardie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses. (arXiv:2310.15317v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15317","description":"<p>In this paper, we explore the application of large language models (LLMs) for\ngenerating code-tracing questions in introductory programming courses. We\ndesigned targeted prompts for GPT4, guiding it to generate code-tracing\nquestions based on code snippets and descriptions. We established a set of\nhuman evaluation metrics to assess the quality of questions produced by the\nmodel compared to those created by human experts. Our analysis provides\ninsights into the capabilities and potential of LLMs in generating diverse\ncode-tracing questions. Additionally, we present a unique dataset of human and\nLLM-generated tracing questions, serving as a valuable resource for both the\neducation and NLP research communities. This work contributes to the ongoing\ndialogue on the potential uses of LLMs in educational settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Aysa Xuemo Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ranran Haoran Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paquette_L/0/1/0/all/0/1\">Luc Paquette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hallucination Detection for Grounded Instruction Generation. (arXiv:2310.15319v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15319","description":"<p>We investigate the problem of generating instructions to guide humans to\nnavigate in simulated residential environments. A major issue with current\nmodels is hallucination: they generate references to actions or objects that\nare inconsistent with what a human follower would perform or encounter along\nthe described path. We develop a model that detects these hallucinated\nreferences by adopting a model pre-trained on a large corpus of image-text\npairs, and fine-tuning it with a contrastive loss that separates correct\ninstructions from instructions containing synthesized hallucinations. Our final\nmodel outperforms several baselines, including using word probability estimated\nby the instruction-generation model, and supervised models based on LSTM and\nTransformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lingjun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daume_H/0/1/0/all/0/1\">Hal Daum&#xe9; III</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LXMERT Model Compression for Visual Question Answering. (arXiv:2310.15325v1 [cs.CV])","link":"http://arxiv.org/abs/2310.15325","description":"<p>Large-scale pretrained models such as LXMERT are becoming popular for\nlearning cross-modal representations on text-image pairs for vision-language\ntasks. According to the lottery ticket hypothesis, NLP and computer vision\nmodels contain smaller subnetworks capable of being trained in isolation to\nfull performance. In this paper, we combine these observations to evaluate\nwhether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA\ntask. In addition, we perform a model size cost-benefit analysis by\ninvestigating how much pruning can be done without significant loss in\naccuracy. Our experiment results demonstrate that LXMERT can be effectively\npruned by 40%-60% in size with 3% loss in accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1\">Maryam Hashemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmoudi_G/0/1/0/all/0/1\">Ghazaleh Mahmoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kodeiri_S/0/1/0/all/0/1\">Sara Kodeiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheikhi_H/0/1/0/all/0/1\">Hadi Sheikhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eetemadi_S/0/1/0/all/0/1\">Sauleh Eetemadi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Specialist or Generalist? Instruction Tuning for Specific NLP Tasks. (arXiv:2310.15326v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15326","description":"<p>The potential of large language models (LLMs) to simultaneously perform a\nwide range of natural language processing (NLP) tasks has been the subject of\nextensive research. Although instruction tuning has proven to be a\ndata-efficient method for transforming LLMs into such generalist models, their\nperformance still lags behind specialist models trained exclusively for\nspecific tasks. In this paper, we investigate whether incorporating\nbroad-coverage generalist instruction tuning can contribute to building a\nspecialist model. We hypothesize that its efficacy depends on task specificity\nand skill requirements. Our experiments assess four target tasks with distinct\ncoverage levels, revealing that integrating generalist instruction tuning\nconsistently enhances model performance when the task coverage is broad. The\neffect is particularly pronounced when the amount of task-specific training\ndata is limited. Further investigation into three target tasks focusing on\ndifferent capabilities demonstrates that generalist instruction tuning improves\nunderstanding and reasoning abilities. However, for tasks requiring factual\nknowledge, generalist data containing hallucinatory information may negatively\naffect the model's performance. Overall, our work provides a systematic guide\nfor developing specialist models with general instruction tuning. Our code and\nother related resources can be found at\nhttps://github.com/DavidFanzz/Generalist_or_Specialist.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chufan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Moral Foundations of Large Language Models. (arXiv:2310.15337v1 [cs.AI])","link":"http://arxiv.org/abs/2310.15337","description":"<p>Moral foundations theory (MFT) is a psychological assessment tool that\ndecomposes human moral reasoning into five factors, including care/harm,\nliberty/oppression, and sanctity/degradation (Graham et al., 2009). People vary\nin the weight they place on these dimensions when making moral decisions, in\npart due to their cultural upbringing and political ideology. As large language\nmodels (LLMs) are trained on datasets collected from the internet, they may\nreflect the biases that are present in such corpora. This paper uses MFT as a\nlens to analyze whether popular LLMs have acquired a bias towards a particular\nset of moral values. We analyze known LLMs and find they exhibit particular\nmoral foundations, and show how these relate to human moral foundations and\npolitical affiliations. We also measure the consistency of these biases, or\nwhether they vary strongly depending on the context of how the model is\nprompted. Finally, we show that we can adversarially select prompts that\nencourage the moral to exhibit a particular set of moral foundations, and that\nthis can affect the model's behavior on downstream tasks. These findings help\nillustrate the potential risks and unintended consequences of LLMs assuming a\nparticular moral stance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1\">Marwa Abdulhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serapio_Garcia_G/0/1/0/all/0/1\">Gregory Serapio-Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crepy_C/0/1/0/all/0/1\">Cl&#xe9;ment Crepy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valter_D/0/1/0/all/0/1\">Daria Valter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1\">John Canny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaques_N/0/1/0/all/0/1\">Natasha Jaques</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation. (arXiv:2310.15355v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15355","description":"<p>We show that LLMs hallucinate because their output is not constrained to be\nsynonymous with claims for which they have evidence: a condition that we call\nevidential closure. Information about the truth or falsity of sentences is not\nstatistically identified in the standard neural probabilistic language model\nsetup, and so cannot be conditioned on to generate new strings. We then show\nhow to constrain LLMs to produce output that does satisfy evidential closure. A\nmultimodal LLM must learn about the external world (perceptual learning); it\nmust learn a mapping from strings to states of the world (extensional\nlearning); and, to achieve fluency when generalizing beyond a body of evidence,\nit must learn mappings from strings to their synonyms (intensional learning).\nThe output of a unimodal LLM must be synonymous with strings in a validated\nevidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune,\nthat yields faithful output from an LLM by rejecting output that is not\nsynonymous with claims for which the LLM has evidence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bouyamourn_A/0/1/0/all/0/1\">Adam Bouyamourn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EpiK-Eval: Evaluation for Language Models as Epistemic Models. (arXiv:2310.15372v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15372","description":"<p>In the age of artificial intelligence, the role of large language models\n(LLMs) is becoming increasingly central. Despite their growing prevalence,\ntheir capacity to consolidate knowledge from different training documents - a\ncrucial ability in numerous applications - remains unexplored. This paper\npresents the first study examining the capability of LLMs to effectively\ncombine such information within their parameter space. We introduce EpiK-Eval,\na novel question-answering benchmark tailored to evaluate LLMs' proficiency in\nformulating a coherent and consistent knowledge representation from segmented\nnarratives. Evaluations across various LLMs reveal significant weaknesses in\nthis domain. We contend that these shortcomings stem from the intrinsic nature\nof prevailing training objectives. Consequently, we advocate for refining the\napproach towards knowledge consolidation, as it harbors the potential to\ndramatically improve their overall effectiveness and performance. The findings\nfrom this study offer insights for developing more robust and reliable LLMs.\nOur code and benchmark are available at\nhttps://github.com/chandar-lab/EpiK-Eval\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prato_G/0/1/0/all/0/1\">Gabriele Prato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jerry Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1\">Prasannna Parthasarathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1\">Shagun Sodhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Data Management in Data Lakes. (arXiv:2310.15373v1 [cs.DB])","link":"http://arxiv.org/abs/2310.15373","description":"<p>In recent years, data lakes emerged as away to manage large amounts of\nheterogeneous data for modern data analytics. One way to prevent data lakes\nfrom turning into inoperable data swamps is semantic data management. Some\napproaches propose the linkage of metadata to knowledge graphs based on the\nLinked Data principles to provide more meaning and semantics to the data in the\nlake. Such a semantic layer may be utilized not only for data management but\nalso to tackle the problem of data integration from heterogeneous sources, in\norder to make data access more expressive and interoperable. In this survey, we\nreview recent approaches with a specific focus on the application within data\nlake systems and scalability to Big Data. We classify the approaches into (i)\nbasic semantic data management, (ii) semantic modeling approaches for enriching\nmetadata in data lakes, and (iii) methods for ontologybased data access. In\neach category, we cover the main techniques and their background, and compare\nlatest research. Finally, we point out challenges for future work in this\nresearch area, which needs a closer integration of Big Data and Semantic Web\ntechnologies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hoseini_S/0/1/0/all/0/1\">Sayed Hoseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theissen_Lipp_J/0/1/0/all/0/1\">Johannes Theissen-Lipp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quix_C/0/1/0/all/0/1\">Christoph Quix</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GD-COMET: A Geo-Diverse Commonsense Inference Model. (arXiv:2310.15383v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15383","description":"<p>With the increasing integration of AI into everyday life, it's becoming\ncrucial to design AI systems that serve users from diverse backgrounds by\nmaking them culturally aware. In this paper, we present GD-COMET, a geo-diverse\nversion of the COMET commonsense inference model. GD-COMET goes beyond Western\ncommonsense knowledge and is capable of generating inferences pertaining to a\nbroad range of cultures. We demonstrate the effectiveness of GD-COMET through a\ncomprehensive human evaluation across 5 diverse cultures, as well as extrinsic\nevaluation on a geo-diverse task. The evaluation shows that GD-COMET captures\nand generates culturally nuanced commonsense knowledge, demonstrating its\npotential to benefit NLP applications across the board and contribute to making\nNLP more inclusive.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_M/0/1/0/all/0/1\">Mehar Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Irreducible Curriculum for Language Model Pretraining. (arXiv:2310.15389v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15389","description":"<p>Automatic data selection and curriculum design for training large language\nmodels is challenging, with only a few existing methods showing improvements\nover standard training. Furthermore, current schemes focus on domain-level\nselection, overlooking the more fine-grained contributions of each individual\ntraining point. It is difficult to apply traditional datapoint selection\nmethods on large language models: most online batch selection methods perform\ntwo-times forward or backward passes, which introduces considerable extra costs\nwith large-scale models. To mitigate these obstacles, we propose irreducible\ncurriculum as a curriculum learning algorithm for language model pretraining,\nwhich prioritizes samples with higher learnability. Specifically, to avoid\nprohibitive extra computation overhead, we simulate the sample loss along the\nmain model's training trajectory using a small-scale proxy model. Our\nexperiments on the RedPajama-1B dataset demonstrate a consistent improvement on\nvalidation perplexity across all 7 domains compared to random uniform baseline\nand the anti-curriculum strategy. Our method also reduces the sharpness of the\nnetwork and illustrates a better 5-shot accuracy on MMLU benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Simin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DoGE: Domain Reweighting with Generalization Estimation. (arXiv:2310.15393v1 [cs.LG])","link":"http://arxiv.org/abs/2310.15393","description":"<p>The coverage and composition of the pretraining data corpus significantly\nimpacts the generalization ability of large language models. Conventionally,\nthe pretraining corpus is composed of various source domains (e.g. CommonCrawl,\nWikipedia, Github etc.) according to certain sampling probabilities (domain\nweights). However, current methods lack a principled way to optimize domain\nweights for ultimate goal for generalization. We propose DOmain reweighting\nwith Generalization Estimation (DoGE), where we reweigh the sampling\nprobability from each domain based on its contribution to the final\ngeneralization objective assessed by a gradient-based generalization estimation\nfunction. First, we train a small-scale proxy model with a min-max optimization\nto obtain the reweighted domain weights. At each step, the domain weights are\nupdated to maximize the overall generalization gain by mirror descent. Finally\nwe use the obtained domain weights to train a larger scale full-size language\nmodel. On SlimPajama-6B dataset, with universal generalization objective, DoGE\nachieves better average perplexity and zero-shot reasoning accuracy. On\nout-of-domain generalization tasks, DoGE reduces perplexity on the target\ndomain by a large margin. We further apply a parameter-selection scheme which\nimproves the efficiency of generalization estimation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Simin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliardini_M/0/1/0/all/0/1\">Matteo Pagliardini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"One-size-fits-all\"? Observations and Expectations of NLG Systems Across Identity-Related Language Features. (arXiv:2310.15398v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15398","description":"<p>Fairness-related assumptions about what constitutes appropriate NLG system\nbehaviors range from invariance, where systems are expected to respond\nidentically to social groups, to adaptation, where responses should instead\nvary across them. We design and conduct five case studies, in which we perturb\ndifferent types of identity-related language features (names, roles, locations,\ndialect, and style) in NLG system inputs to illuminate tensions around\ninvariance and adaptation. We outline people's expectations of system\nbehaviors, and surface potential caveats of these two contrasting yet\ncommonly-held assumptions. We find that motivations for adaptation include\nsocial norms, cultural differences, feature-specific information, and\naccommodation; motivations for invariance include perspectives that favor\nprescriptivism, view adaptation as unnecessary or too difficult for NLG systems\nto do appropriately, and are wary of false assumptions. Our findings highlight\nopen challenges around defining what constitutes fair NLG system behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lucy_L/0/1/0/all/0/1\">Li Lucy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blodgett_S/0/1/0/all/0/1\">Su Lin Blodgett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1\">Milad Shokouhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallach_H/0/1/0/all/0/1\">Hanna Wallach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olteanu_A/0/1/0/all/0/1\">Alexandra Olteanu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions. (arXiv:2310.15405v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15405","description":"<p>There is growing interest in systems that generate captions for scientific\nfigures. However, assessing these systems output poses a significant challenge.\nHuman evaluation requires academic expertise and is costly, while automatic\nevaluation depends on often low-quality author-written captions. This paper\ninvestigates using large language models (LLMs) as a cost-effective,\nreference-free method for evaluating figure captions. We first constructed\nSCICAP-EVAL, a human evaluation dataset that contains human judgments for 3,600\nscientific figure captions, both original and machine-made, for 600 arXiv\nfigures. We then prompted LLMs like GPT-4 and GPT-3 to score (1-6) each caption\nbased on its potential to aid reader understanding, given relevant context such\nas figure-mentioning paragraphs. Results show that GPT-4, used as a zero-shot\nevaluator, outperformed all other models and even surpassed assessments made by\nComputer Science and Informatics undergraduates, achieving a Kendall\ncorrelation score of 0.401 with Ph.D. students rankings\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_T/0/1/0/all/0/1\">Ting-Yao Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chieh-Yang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungchul Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giles_C/0/1/0/all/0/1\">C. Lee Giles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1\">Ting-Hao K. Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation. (arXiv:2310.15415v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15415","description":"<p>Knowing how to end and resume conversations over time is a natural part of\ncommunication, allowing for discussions to span weeks, months, or years. The\nduration of gaps between conversations dictates which topics are relevant and\nwhich questions to ask, and dialogue systems which do not explicitly model time\nmay generate responses that are unnatural. In this work we explore the idea of\nmaking dialogue models aware of time, and present GapChat, a multi-session\ndialogue dataset in which the time between each session varies. While the\ndataset is constructed in real-time, progress on events in speakers' lives is\nsimulated in order to create realistic dialogues occurring across a long\ntimespan. We expose time information to the model and compare different\nrepresentations of time and event progress. In human evaluation we show that\ntime-aware models perform better in metrics that judge the relevance of the\nchosen topics and the information gained from the conversation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naradowsky_J/0/1/0/all/0/1\">Jason Naradowsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miyao_Y/0/1/0/all/0/1\">Yusuke Miyao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let the Pretrained Language Models \"Imagine\" for Short Texts Topic Modeling. (arXiv:2310.15420v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15420","description":"<p>Topic models are one of the compelling methods for discovering latent\nsemantics in a document collection. However, it assumes that a document has\nsufficient co-occurrence information to be effective. However, in short texts,\nco-occurrence information is minimal, which results in feature sparsity in\ndocument representation. Therefore, existing topic models (probabilistic or\nneural) mostly fail to mine patterns from them to generate coherent topics. In\nthis paper, we take a new approach to short-text topic modeling to address the\ndata-sparsity issue by extending short text into longer sequences using\nexisting pre-trained language models (PLMs). Besides, we provide a simple\nsolution extending a neural topic model to reduce the effect of noisy\nout-of-topics text generation from PLMs. We observe that our model can\nsubstantially improve the performance of short-text topic modeling. Extensive\nexperiments on multiple real-world datasets under extreme data sparsity\nscenarios show that our models can generate high-quality topics outperforming\nstate-of-the-art models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akash_P/0/1/0/all/0/1\">Pritom Saha Akash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. (arXiv:2310.15421v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15421","description":"<p>Theory of mind (ToM) evaluations currently focus on testing models using\npassive narratives that inherently lack interactivity. We introduce FANToM, a\nnew benchmark designed to stress-test ToM within information-asymmetric\nconversational contexts via question answering. Our benchmark draws upon\nimportant theoretical requisites from psychology and necessary empirical\nconsiderations when evaluating large language models (LLMs). In particular, we\nformulate multiple types of questions that demand the same underlying reasoning\nto identify illusory or false sense of ToM capabilities in LLMs. We show that\nFANToM is challenging for state-of-the-art LLMs, which perform significantly\nworse than humans even with chain-of-thought reasoning or fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclar_M/0/1/0/all/0/1\">Melanie Sclar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Mason-Alberta Phonetic Segmenter: A forced alignment system based on deep neural networks and interpolation. (arXiv:2310.15425v1 [eess.AS])","link":"http://arxiv.org/abs/2310.15425","description":"<p>Forced alignment systems automatically determine boundaries between segments\nin speech data, given an orthographic transcription. These tools are\ncommonplace in phonetics to facilitate the use of speech data that would be\ninfeasible to manually transcribe and segment. In the present paper, we\ndescribe a new neural network-based forced alignment system, the Mason-Alberta\nPhonetic Segmenter (MAPS). The MAPS aligner serves as a testbed for two\npossible improvements we pursue for forced alignment systems. The first is\ntreating the acoustic model in a forced aligner as a tagging task, rather than\na classification task, motivated by the common understanding that segments in\nspeech are not truly discrete and commonly overlap. The second is an\ninterpolation technique to allow boundaries more precise than the common 10 ms\nlimit in modern forced alignment systems. We compare configurations of our\nsystem to a state-of-the-art system, the Montreal Forced Aligner. The tagging\napproach did not generally yield improved results over the Montreal Forced\nAligner. However, a system with the interpolation technique had a 27.92%\nincrease relative to the Montreal Forced Aligner in the amount of boundaries\nwithin 10 ms of the target on the test set. We also reflect on the task and\ntraining process for acoustic modeling in forced alignment, highlighting how\nthe output targets for these models do not match phoneticians' conception of\nsimilarity between phones and that reconciliation of this tension may require\nrethinking the task and output targets or how speech itself should be\nsegmented.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Kelley_M/0/1/0/all/0/1\">Matthew C. Kelley</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Perry_S/0/1/0/all/0/1\">Scott James Perry</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tucker_B/0/1/0/all/0/1\">Benjamin V. Tucker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Sentiment: Leveraging Topic Metrics for Political Stance Classification. (arXiv:2310.15429v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15429","description":"<p>Sentiment analysis, widely critiqued for capturing merely the overall tone of\na corpus, falls short in accurately reflecting the latent structures and\npolitical stances within texts. This study introduces topic metrics, dummy\nvariables converted from extracted topics, as both an alternative and\ncomplement to sentiment metrics in stance classification. By employing three\ndatasets identified by Bestvater and Monroe (2023), this study demonstrates\nBERTopic's proficiency in extracting coherent topics and the effectiveness of\ntopic metrics in stance classification. The experiment results show that\nBERTopic improves coherence scores by 17.07% to 54.20% when compared to\ntraditional approaches such as Dirichlet Allocation (LDA) and Non-negative\nMatrix Factorization (NMF), prevalent in earlier political science research.\nAdditionally, our results indicate topic metrics outperform sentiment metrics\nin stance classification, increasing performance by as much as 18.95%. Our\nfindings suggest topic metrics are especially effective for context-rich texts\nand corpus where stance and sentiment correlations are weak. The combination of\nsentiment and topic metrics achieve an optimal performance in most of the\nscenarios and can further address the limitations of relying solely on\nsentiment as well as the low coherence score of topic metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weihong Qi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations. (arXiv:2310.15431v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15431","description":"<p>Moral or ethical judgments rely heavily on the specific contexts in which\nthey occur. Understanding varying shades of defeasible contextualizations\n(i.e., additional information that strengthens or attenuates the moral\nacceptability of an action) is critical to accurately represent the subtlety\nand intricacy of grounded human moral judgment in real-life scenarios.\n</p>\n<p>We introduce defeasible moral reasoning: a task to provide grounded contexts\nthat make an action more or less morally acceptable, along with commonsense\nrationales that justify the reasoning. To elicit high-quality task data, we\ntake an iterative self-distillation approach that starts from a small amount of\nunstructured seed knowledge from GPT-3 and then alternates between (1)\nself-distillation from student models; (2) targeted filtering with a critic\nmodel trained by human judgment (to boost validity) and NLI (to boost\ndiversity); (3) self-imitation learning (to amplify the desired data quality).\nThis process yields a student model that produces defeasible contexts with\nimproved validity, diversity, and defeasibility. From this model we distill a\nhigh-quality dataset, \\delta-Rules-of-Thumb, of 1.2M entries of\ncontextualizations and rationales for 115K defeasible moral actions rated\nhighly by human annotators 85.9% to 99.8% of the time. Using \\delta-RoT we\nobtain a final student model that wins over all intermediate student models by\na notable margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1\">Kavel Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuling Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_N/0/1/0/all/0/1\">Niket Tandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziri_N/0/1/0/all/0/1\">Nouha Dziri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings. (arXiv:2310.15439v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15439","description":"<p>Numerous datasets have been proposed to combat the spread of online hate.\nDespite these efforts, a majority of these resources are English-centric,\nprimarily focusing on overt forms of hate. This research gap calls for\ndeveloping high-quality corpora in diverse languages that also encapsulate more\nsubtle hate expressions. This study introduces K-HATERS, a new corpus for hate\nspeech detection in Korean, comprising approximately 192K news comments with\ntarget-specific offensiveness ratings. This resource is the largest offensive\nlanguage corpus in Korean and is the first to offer target-specific ratings on\na three-point Likert scale, enabling the detection of hate expressions in\nKorean across varying degrees of offensiveness. We conduct experiments showing\nthe effectiveness of the proposed corpus, including a comparison with existing\ndatasets. Additionally, to address potential noise and bias in human\nannotations, we explore a novel idea of adopting the Cognitive Reflection Test,\nwhich is widely used in social science for assessing an individual's cognitive\nability, as a proxy of labeling quality. Findings indicate that annotations\nfrom individuals with the lowest test scores tend to yield detection models\nthat make biased predictions toward specific target groups and are less\naccurate. This study contributes to the NLP research on hate speech detection\nand resource construction. The code and dataset can be accessed at\nhttps://github.com/ssu-humane/K-HATERS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chaewon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Soohwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kyubyong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Kunwoo Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring. (arXiv:2310.15461v1 [cs.HC])","link":"http://arxiv.org/abs/2310.15461","description":"<p>Self-guided mental health interventions, such as \"do-it-yourself\" tools to\nlearn and practice coping strategies, show great promise to improve access to\nmental health care. However, these interventions are often cognitively\ndemanding and emotionally triggering, creating accessibility barriers that\nlimit their wide-scale implementation and adoption. In this paper, we study how\nhuman-language model interaction can support self-guided mental health\ninterventions. We take cognitive restructuring, an evidence-based therapeutic\ntechnique to overcome negative thinking, as a case study. In an IRB-approved\nrandomized field study on a large mental health website with 15,531\nparticipants, we design and evaluate a system that uses language models to\nsupport people through various steps of cognitive restructuring. Our findings\nreveal that our system positively impacts emotional intensity for 67% of\nparticipants and helps 65% overcome negative thoughts. Although adolescents\nreport relatively worse outcomes, we find that tailored interventions that\nsimplify language model generations improve overall effectiveness and equity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Ashish Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rushton_K/0/1/0/all/0/1\">Kevin Rushton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_I/0/1/0/all/0/1\">Inna Wanyin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Theresa Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Althoff_T/0/1/0/all/0/1\">Tim Althoff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpreting Answers to Yes-No Questions in User-Generated Content. (arXiv:2310.15464v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15464","description":"<p>Interpreting answers to yes-no questions in social media is difficult. Yes\nand no keywords are uncommon, and the few answers that include them are rarely\nto be interpreted what the keywords suggest. In this paper, we present a new\ncorpus of 4,442 yes-no question-answer pairs from Twitter. We discuss\nlinguistic characteristics of answers whose interpretation is yes or no, as\nwell as answers whose interpretation is unknown. We show that large language\nmodels are far from solving this problem, even after fine-tuning and blending\nother corpora for the same problem but outside social media.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mathur_S/0/1/0/all/0/1\">Shivam Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Keun Hee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinnappa_D/0/1/0/all/0/1\">Dhivya Chinnappa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotamraju_S/0/1/0/all/0/1\">Saketh Kotamraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanco_E/0/1/0/all/0/1\">Eduardo Blanco</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks. (arXiv:2310.15469v1 [cs.CR])","link":"http://arxiv.org/abs/2310.15469","description":"<p>The era post-2018 marked the advent of Large Language Models (LLMs), with\ninnovations such as OpenAI's ChatGPT showcasing prodigious linguistic prowess.\nAs the industry galloped toward augmenting model parameters and capitalizing on\nvast swaths of human language data, security and privacy challenges also\nemerged. Foremost among these is the potential inadvertent accrual of Personal\nIdentifiable Information (PII) during web-based data acquisition, posing risks\nof unintended PII disclosure. While strategies like RLHF during training and\nCatastrophic Forgetting have been marshaled to control the risk of privacy\ninfringements, recent advancements in LLMs, epitomized by OpenAI's fine-tuning\ninterface for GPT-3.5, have reignited concerns. One may ask: can the\nfine-tuning of LLMs precipitate the leakage of personal information embedded\nwithin training datasets? This paper reports the first endeavor to seek the\nanswer to the question, particularly our discovery of a new LLM exploitation\navenue, called the Janus attack. In the attack, one can construct a PII\nassociation task, whereby an LLM is fine-tuned using a minuscule PII dataset,\nto potentially reinstate and reveal concealed PIIs. Our findings indicate that,\nwith a trivial fine-tuning outlay, LLMs such as GPT-3.5 can transition from\nbeing impermeable to PII extraction to a state where they divulge a substantial\nproportion of concealed PII. This research, through its deep dive into the\nJanus attack vector, underscores the imperative of navigating the intricate\ninterplay between LLM utility and privacy preservation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siyuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1\">Rui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shijun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lei Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Liya Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">XiaoFeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haixu Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Event Extraction with Semantic Confusion Rectification. (arXiv:2310.15470v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15470","description":"<p>We study continual event extraction, which aims to extract incessantly\nemerging event information while avoiding forgetting. We observe that the\nsemantic confusion on event types stems from the annotations of the same text\nbeing updated over time. The imbalance between event types even aggravates this\nissue. This paper proposes a novel continual event extraction model with\nsemantic confusion rectification. We mark pseudo labels for each sentence to\nalleviate semantic confusion. We transfer pivotal knowledge between current and\nprevious models to enhance the understanding of event types. Moreover, we\nencourage the model to focus on the semantics of long-tailed event types by\nleveraging other associated types. Experimental results show that our model\noutperforms state-of-the-art baselines and is proficient in imbalanced\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zitao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model. (arXiv:2310.15477v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15477","description":"<p>Instruction tuning has recently been recognized as an effective way of\naligning Large Language Models (LLMs) to enhance their generalization ability\nacross various tasks. However, when tuning publicly accessible, centralized\nLLMs with private instruction data, privacy concerns are inevitable. While\ndirect transfer of parameterized modules between models is a plausible approach\nto address this, its implications and effectiveness need further exploration.\nThis paper focuses on Offsite-Tuning (OFT), a representative technique that\ntransfers transformer blocks between centralized LLMs and downstream emulators.\nGiven the limited understanding of the underlying mechanism of OFT, we perform\nan empirical analysis on LLMs from the perspectives of representation and\nfunctional similarity. Interestingly, our findings reveal a unique modular\nstructure within the layers of LLMs that appears to emerge as the model size\nexpands. Simultaneously, we note subtle but potentially significant changes in\nrepresentation and intermediate predictions across the layers. Inspired by\nthese observations, we propose CRaSh, involving Clustering, Removing, and\nSharing, a training-free strategy to derive improved emulators from LLMs. CRaSh\nsignificantly boosts performance of OFT with billions of parameters.\nFurthermore, we investigate the optimal solutions yielded by fine-tuning with\nand without full model through the lens of loss landscape. Our findings\ndemonstrate a linear connectivity among these optima falling over the same\nbasin, thereby highlighting the effectiveness of CRaSh and OFT. The source code\nis publicly available at https://github.com/TsinghuaC3I/CRaSh.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Ning Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1\">Biqing Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xuekai Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_X/0/1/0/all/0/1\">Xinwei Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA. (arXiv:2310.15484v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15484","description":"<p>Multi-hop Knowledge Graph Question Answering (KGQA) is a task that involves\nretrieving nodes from a knowledge graph (KG) to answer natural language\nquestions. Recent GNN-based approaches formulate this task as a KG path\nsearching problem, where messages are sequentially propagated from the seed\nnode towards the answer nodes. However, these messages are past-oriented, and\nthey do not consider the full KG context. To make matters worse, KG nodes often\nrepresent proper noun entities and are sometimes encrypted, being uninformative\nin selecting between paths. To address these problems, we propose Neural Tree\nSearch (NuTrea), a tree search-based GNN model that incorporates the broader KG\ncontext. Our model adopts a message-passing scheme that probes the unreached\nsubtree regions to boost the past-oriented embeddings. In addition, we\nintroduce the Relation Frequency-Inverse Entity Frequency (RF-IEF) node\nembedding that considers the global KG context to better characterize ambiguous\nKG nodes. The general effectiveness of our approach is demonstrated through\nexperiments on three major multi-hop KGQA benchmark datasets, and our extensive\nanalyses further validate its expressiveness and robustness. Overall, NuTrea\nprovides a powerful means to query the KG with complex natural language\nquestions. Code is available at https://github.com/mlvlab/NuTrea.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1\">Hyeong Kyu Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seunghun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_J/0/1/0/all/0/1\">Jaewon Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo J. Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TRAMS: Training-free Memory Selection for Long-range Language Modeling. (arXiv:2310.15494v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15494","description":"<p>The Transformer architecture is crucial for numerous AI models, but it still\nfaces challenges in long-range language modeling. Though several specific\ntransformer architectures have been designed to tackle issues of long-range\ndependencies, existing methods like Transformer-XL are plagued by a high\npercentage of ineffective memories. In this study, we present a plug-and-play\nstrategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens\nparticipating in attention calculation based on one simple metric. This\nstrategy allows us to keep tokens that are likely to have a high attention\nscore with the current queries and ignore the other ones. We have tested our\napproach on the word-level benchmark (WikiText-103) and the character-level\nbenchmark (enwik8), and the results indicate an improvement without having\nadditional training or adding additional parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+wang_C/0/1/0/all/0/1\">Cunxiang wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval. (arXiv:2310.15511v1 [cs.LG])","link":"http://arxiv.org/abs/2310.15511","description":"<p>We study the ability of state-of-the art models to answer constraint\nsatisfaction queries for information retrieval (e.g., 'a list of ice cream\nshops in San Diego'). In the past, such queries were considered to be tasks\nthat could only be solved via web-search or knowledge bases. More recently,\nlarge language models (LLMs) have demonstrated initial emergent abilities in\nthis task. However, many current retrieval benchmarks are either saturated or\ndo not measure constraint satisfaction. Motivated by rising concerns around\nfactual incorrectness and hallucinations of LLMs, we present KITAB, a new\ndataset for measuring constraint satisfaction abilities of language models.\nKITAB consists of book-related data across more than 600 authors and 13,000\nqueries, and also offers an associated dynamic data collection and constraint\nverification approach for acquiring similar test data for other authors. Our\nextended experiments on GPT4 and GPT3.5 characterize and decouple common\nfailure modes across dimensions such as information popularity, constraint\ntypes, and context availability. Results show that in the absence of context,\nmodels exhibit severe limitations as measured by irrelevant information,\nfactual errors, and incompleteness, many of which exacerbate as information\npopularity decreases. While context availability mitigates irrelevant\ninformation, it is not helpful for satisfying constraints, identifying\nfundamental barriers to constraint satisfaction. We open source our\ncontributions to foster further research on improving constraint satisfaction\nabilities of future models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdin_M/0/1/0/all/0/1\">Marah I Abdin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunasekar_S/0/1/0/all/0/1\">Suriya Gunasekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekaran_V/0/1/0/all/0/1\">Varun Chandrasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuksekgonul_M/0/1/0/all/0/1\">Mert Yuksekgonul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peshawaria_R/0/1/0/all/0/1\">Rahee Ghosh Peshawaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_R/0/1/0/all/0/1\">Ranjita Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nushi_B/0/1/0/all/0/1\">Besmira Nushi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Joint Matrix Factorization Analysis of Multilingual Representations. (arXiv:2310.15513v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15513","description":"<p>We present an analysis tool based on joint matrix factorization for comparing\nlatent representations of multilingual and monolingual models. An alternative\nto probing, this tool allows us to analyze multiple sets of representations in\na joint manner. Using this tool, we study to what extent and how\nmorphosyntactic features are reflected in the representations learned by\nmultilingual pre-trained models. We conduct a large-scale empirical study of\nover 33 languages and 17 morphosyntactic categories. Our findings demonstrate\nvariations in the encoding of morphosyntactic information across upper and\nlower layers, with category-specific differences influenced by language\nproperties. Hierarchical clustering of the factorization outputs yields a tree\nstructure that is related to phylogenetic trees manually crafted by linguists.\nMoreover, we find the factorization outputs exhibit strong associations with\nperformance observed across different cross-lingual tasks. We release our code\nto facilitate future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziser_Y/0/1/0/all/0/1\">Yftah Ziser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webber_B/0/1/0/all/0/1\">Bonnie Webber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation. (arXiv:2310.15515v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15515","description":"<p>Recent ubiquity and disruptive impacts of large language models (LLMs) have\nraised concerns about their potential to be misused (.i.e, generating\nlarge-scale harmful and misleading content). To combat this emerging risk of\nLLMs, we propose a novel \"Fighting Fire with Fire\" (F3) strategy that harnesses\nmodern LLMs' generative and emergent reasoning capabilities to counter\nhuman-written and LLM-generated disinformation. First, we leverage\nGPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content\nthrough paraphrase-based and perturbation-based prefix-style prompts,\nrespectively. Second, we apply zero-shot in-context semantic reasoning\ntechniques with cloze-style prompts to discern genuine from deceptive posts and\nnews articles. In our extensive experiments, we observe GPT-3.5-turbo's\nzero-shot superiority for both in-distribution and out-of-distribution\ndatasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike\nthe decline observed in previous customized and fine-tuned disinformation\ndetectors. Our codebase and dataset are available at\nhttps://github.com/mickeymst/F3.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lucas_J/0/1/0/all/0/1\">Jason Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uchendu_A/0/1/0/all/0/1\">Adaku Uchendu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_M/0/1/0/all/0/1\">Michiharu Yamashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jooyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohatgi_S/0/1/0/all/0/1\">Shaurya Rohatgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongwon Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MarkQA: A large scale KBQA dataset with numerical reasoning. (arXiv:2310.15517v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15517","description":"<p>While question answering over knowledge bases (KBQA) has shown progress in\naddressing factoid questions, KBQA with numerical reasoning remains relatively\nunexplored. In this paper, we focus on the complex numerical reasoning in KBQA\nand propose a new task, NR-KBQA, which necessitates the ability to perform both\nmulti-hop reasoning and numerical reasoning. We design a logic form in Python\nformat called PyQL to represent the reasoning process of numerical reasoning\nquestions. To facilitate the development of NR-KBQA, we present a large dataset\ncalled MarkQA, which is automatically constructed from a small set of seeds.\nEach question in MarkQA is equipped with its corresponding SPARQL query,\nalongside the step-by-step reasoning process in the QDMR format and PyQL\nprogram. Experimental results of some state-of-the-art QA methods on the MarkQA\nshow that complex numerical reasoning in KBQA faces great challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sitao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yuheng Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shanshan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yuzhong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code Translation. (arXiv:2310.15539v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15539","description":"<p>With the recent focus on Large Language Models (LLMs), both StarCoder (Li et\nal., 2023) and Code Llama (Rozi\\`ere et al., 2023) have demonstrated remarkable\nperformance in code generation. However, there is still a need for improvement\nin code translation functionality with efficient training techniques. In\nresponse to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM\ndesigned specifically for multi-programming language-to-Python code\ntranslation. In particular, SteloCoder achieves C++, C#, JavaScript, Java, or\nPHP-to-Python code translation without specifying the input programming\nlanguage. We modified StarCoder model architecture by incorporating a\nMixture-of-Experts (MoE) technique featuring five experts and a gating network\nfor multi-task handling. Experts are obtained by StarCoder fine-tuning.\nSpecifically, we use a Low-Rank Adaptive Method (LoRA) technique, limiting each\nexpert size as only 0.06% of number of StarCoder's parameters. At the same\ntime, to enhance training efficiency in terms of time, we adopt curriculum\nlearning strategy and use self-instruct data for efficient fine-tuning. As a\nresult, each expert takes only 6 hours to train on one single 80Gb A100 HBM.\nWith experiments on XLCoST datasets, SteloCoder achieves an average of 73.76\nCodeBLEU score in multi-programming language-to-Python translation, surpassing\nthe top performance from the leaderboard by at least 3.5. This accomplishment\nis attributed to only 45M extra parameters with StarCoder as the backbone and\n32 hours of valid training on one 80GB A100 HBM. The source code is release\nhere: https://github.com/sade-adrien/SteloCoder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jialing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sade_A/0/1/0/all/0/1\">Adrien Sad&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soriano_E/0/1/0/all/0/1\">Eric Soriano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sole_G/0/1/0/all/0/1\">Guillem Sole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flamant_S/0/1/0/all/0/1\">Sylvain Flamant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary. (arXiv:2310.15541v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15541","description":"<p>The non-humanlike behaviour of contemporary pre-trained language models\n(PLMs) is a leading cause undermining their trustworthiness. A striking\nphenomenon of such faulty behaviours is the generation of inconsistent\npredictions, which produces logically contradictory results, such as generating\ndifferent predictions for texts delivering the same meaning or violating\nlogical properties. Previous studies exploited data augmentation or implemented\nspecialised loss functions to alleviate the issue. However, their usage is\nlimited, because they consume expensive training resources for large-sized PLMs\nand can only handle a certain consistency type. To this end, we propose a\npractical approach that alleviates the inconsistent behaviour issue by\nfundamentally improving PLMs' meaning awareness. Based on the conceptual role\ntheory, our method allows PLMs to capture accurate meaning by learning precise\ninterrelationships between concepts from word-definition pairs in a dictionary.\nNext, we propose an efficient parameter integration technique that updates only\na few additional parameters to combine the learned interrelationship with PLMs'\npre-trained knowledge. Our experimental results reveal that the approach can\nconcurrently improve multiple types of consistency, enables efficient knowledge\nintegration, and easily applies to other languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jang_M/0/1/0/all/0/1\">Myeongjun Erik Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unveiling Multilinguality in Transformer Models: Exploring Language Specificity in Feed-Forward Networks. (arXiv:2310.15552v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15552","description":"<p>Recent research suggests that the feed-forward module within Transformers can\nbe viewed as a collection of key-value memories, where the keys learn to\ncapture specific patterns from the input based on the training examples. The\nvalues then combine the output from the 'memories' of the keys to generate\npredictions about the next token. This leads to an incremental process of\nprediction that gradually converges towards the final token choice near the\noutput layers. This interesting perspective raises questions about how\nmultilingual models might leverage this mechanism. Specifically, for\nautoregressive models trained on two or more languages, do all neurons (across\nlayers) respond equally to all languages? No! Our hypothesis centers around the\nnotion that during pretraining, certain model parameters learn strong\nlanguage-specific features, while others learn more language-agnostic (shared\nacross languages) features. To validate this, we conduct experiments utilizing\nparallel corpora of two languages that the model was initially pretrained on.\nOur findings reveal that the layers closest to the network's input or output\ntend to exhibit more language-specific behaviour compared to the layers in the\nmiddle.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1\">Sunit Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojar_O/0/1/0/all/0/1\">Ondrej Bojar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction. (arXiv:2310.15556v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15556","description":"<p>Since ChatGPT released its API for public use, the number of applications\nbuilt on top of commercial large language models (LLMs) increase exponentially.\nOne popular usage of such models is leveraging its in-context learning ability\nand generating responses given user queries leveraging knowledge obtained by\nretrieval augmentation. One problem of deploying commercial retrieval-augmented\nLLMs is the cost due to the additionally retrieved context that largely\nincreases the input token size of the LLMs. To mitigate this, we propose a\ntoken compression scheme that includes two methods: summarization compression\nand semantic compression. The first method applies a T5-based model that is\nfine-tuned by datasets generated using self-instruct containing samples with\nvarying lengths and reduce token size by doing summarization. The second method\nfurther compresses the token size by removing words with lower impact on the\nsemantic. In order to adequately evaluate the effectiveness of the proposed\nmethods, we propose and utilize a dataset called Food-Recommendation DB (FRDB)\nfocusing on food recommendation for women around pregnancy period or infants.\nOur summarization compression can reduce 65% of the retrieval token size with\nfurther 0.3% improvement on the accuracy; semantic compression provides a more\nflexible way to trade-off the token size with performance, for which we can\nreduce the token size by 20% with only 1.6% of accuracy drop.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1\">Tong Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yiming Qian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MuLMS: A Multi-Layer Annotated Text Corpus for Information Extraction in the Materials Science Domain. (arXiv:2310.15569v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15569","description":"<p>Keeping track of all relevant recent publications and experimental results\nfor a research area is a challenging task. Prior work has demonstrated the\nefficacy of information extraction models in various scientific areas.\nRecently, several datasets have been released for the yet understudied\nmaterials science domain. However, these datasets focus on sub-problems such as\nparsing synthesis procedures or on sub-domains, e.g., solid oxide fuel cells.\nIn this resource paper, we present MuLMS, a new dataset of 50 open-access\narticles, spanning seven sub-domains of materials science. The corpus has been\nannotated by domain experts with several layers ranging from named entities\nover relations to frame structures. We present competitive neural models for\nall tasks and demonstrate that multi-task training with existing related\nresources leads to benefits.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schrader_T/0/1/0/all/0/1\">Timo Pierre Schrader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finco_M/0/1/0/all/0/1\">Matteo Finco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grunewald_S/0/1/0/all/0/1\">Stefan Gr&#xfc;newald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hildebrand_F/0/1/0/all/0/1\">Felix Hildebrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Friedrich_A/0/1/0/all/0/1\">Annemarie Friedrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visually Grounded Continual Language Learning with Selective Specialization. (arXiv:2310.15571v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15571","description":"<p>A desirable trait of an artificial agent acting in the visual world is to\ncontinually learn a sequence of language-informed tasks while striking a\nbalance between sufficiently specializing in each task and building a\ngeneralized knowledge for transfer. Selective specialization, i.e., a careful\nselection of model components to specialize in each task, is a strategy to\nprovide control over this trade-off. However, the design of selection\nstrategies requires insights on the role of each model component in learning\nrather specialized or generalizable representations, which poses a gap in\ncurrent research. Thus, our aim with this work is to provide an extensive\nanalysis of selection strategies for visually grounded continual language\nlearning. Due to the lack of suitable benchmarks for this purpose, we introduce\ntwo novel diagnostic datasets that provide enough control and flexibility for a\nthorough model analysis. We assess various heuristics for module specialization\nstrategies as well as quantifiable measures for two different types of model\narchitectures. Finally, we design conceptually simple approaches based on our\nanalysis that outperform common continual learning baselines. Our results\ndemonstrate the need for further efforts towards better aligning continual\nlearning algorithms with the learning behaviors of individual model parts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahrens_K/0/1/0/all/0/1\">Kyra Ahrens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengtson_L/0/1/0/all/0/1\">Lennart Bengtson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jae Hee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1\">Stefan Wermter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Language Processing for Drug Discovery Knowledge Graphs: promises and pitfalls. (arXiv:2310.15572v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15572","description":"<p>Building and analysing knowledge graphs (KGs) to aid drug discovery is a\ntopical area of research. A salient feature of KGs is their ability to combine\nmany heterogeneous data sources in a format that facilitates discovering\nconnections. The utility of KGs has been exemplified in areas such as drug\nrepurposing, with insights made through manual exploration and modelling of the\ndata. In this article, we discuss promises and pitfalls of using natural\nlanguage processing (NLP) to mine unstructured text typically from scientific\nliterature as a data source for KGs. This draws on our experience of initially\nparsing structured data sources such as ChEMBL as the basis for data within a\nKG, and then enriching or expanding upon them using NLP. The fundamental\npromise of NLP for KGs is the automated extraction of data from millions of\ndocuments a task practically impossible to do via human curation alone.\nHowever, there are many potential pitfalls in NLP-KG pipelines such as\nincorrect named entity recognition and ontology linking all of which could\nultimately lead to erroneous inferences and conclusions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeynes_J/0/1/0/all/0/1\">J. Charles G. Jeynes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_T/0/1/0/all/0/1\">Tim James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corney_M/0/1/0/all/0/1\">Matthew Corney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"POE: Process of Elimination for Multiple Choice Reasoning. (arXiv:2310.15575v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15575","description":"<p>Language models (LMs) are capable of conducting in-context learning for\nmultiple choice reasoning tasks, but the options in these tasks are treated\nequally. As humans often first eliminate wrong options before picking the final\ncorrect answer, we argue a similar two-step strategy can make LMs better at\nthese tasks. To this end, we present the Process of Elimination (POE), a\ntwo-step scoring method. In the first step, POE scores each option, and\neliminates seemingly wrong options. In the second step, POE masks these wrong\noptions, and makes the final prediction from the remaining options. Zero-shot\nexperiments on 8 reasoning tasks illustrate the effectiveness of POE, and a\nfollowing analysis finds our method to be especially performant on logical\nreasoning tasks. We further analyze the effect of masks, and show that POE\napplies to few-shot settings and large language models (LLMs) like ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chenkai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xinya Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction. (arXiv:2310.15577v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15577","description":"<p>Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus\non developing more efficient fine-tuning techniques for the task. Instead, our\nmotivation is to come up with a generic approach that can improve the\ndownstream performances of multiple ABSA tasks simultaneously. Towards this, we\npresent CONTRASTE, a novel pre-training strategy using CONTRastive learning to\nenhance the ASTE performance. While we primarily focus on ASTE, we also\ndemonstrate the advantage of our proposed technique on other ABSA tasks such as\nACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion,\nsentiment) triplets, first, we design aspect-based prompts with corresponding\nsentiments masked. We then (pre)train an encoder-decoder model by applying\ncontrastive learning on the decoder-generated aspect-aware sentiment\nrepresentations of the masked terms. For fine-tuning the model weights thus\nobtained, we then propose a novel multi-task approach where the base\nencoder-decoder model is combined with two complementary modules, a\ntagging-based Opinion Term Detector, and a regression-based Triplet Count\nEstimator. Exhaustive experiments on four benchmark datasets and a detailed\nablation study establish the importance of each of our proposed components as\nwe achieve new state-of-the-art ASTE results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Rajdeep Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kannen_N/0/1/0/all/0/1\">Nithish Kannen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1\">Saurabh Kumar Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Representations for Teacher-Guided Compositional Visual Reasoning. (arXiv:2310.15585v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15585","description":"<p>Neural Module Networks (NMN) are a compelling method for visual question\nanswering, enabling the translation of a question into a program consisting of\na series of reasoning sub-tasks that are sequentially executed on the image to\nproduce an answer. NMNs provide enhanced explainability compared to integrated\nmodels, allowing for a better understanding of the underlying reasoning\nprocess. To improve the effectiveness of NMNs we propose to exploit features\nobtained by a large-scale cross-modal encoder. Also, the current training\napproach of NMNs relies on the propagation of module outputs to subsequent\nmodules, leading to the accumulation of prediction errors and the generation of\nfalse answers. To mitigate this, we introduce an NMN learning strategy\ninvolving scheduled teacher guidance. Initially, the model is fully guided by\nthe ground-truth intermediate outputs, but gradually transitions to an\nautonomous behavior as training progresses. This reduces error accumulation,\nthus improving training efficiency and final performance.We demonstrate that by\nincorporating cross-modal features and employing more effective training\ntechniques for NMN, we achieve a favorable balance between performance and\ntransparency in the reasoning process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aissa_W/0/1/0/all/0/1\">Wafa Aissa</a> (CEDRIC - VERTIGO), <a href=\"http://arxiv.org/find/cs/1/au:+Ferecatu_M/0/1/0/all/0/1\">Marin Ferecatu</a> (CEDRIC - VERTIGO), <a href=\"http://arxiv.org/find/cs/1/au:+Crucianu_M/0/1/0/all/0/1\">Michel Crucianu</a> (CEDRIC - VERTIGO)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts. (arXiv:2310.15587v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15587","description":"<p>Eye movements in reading play a crucial role in psycholinguistic research\nstudying the cognitive mechanisms underlying human language processing. More\nrecently, the tight coupling between eye movements and cognition has also been\nleveraged for language-related machine learning tasks such as the\ninterpretability, enhancement, and pre-training of language models, as well as\nthe inference of reader- and text-specific properties. However, scarcity of eye\nmovement data and its unavailability at application time poses a major\nchallenge for this line of research. Initially, this problem was tackled by\nresorting to cognitive models for synthesizing eye movement data. However, for\nthe sole purpose of generating human-like scanpaths, purely data-driven\nmachine-learning-based methods have proven to be more suitable. Following\nrecent advances in adapting diffusion processes to discrete data, we propose\nScanDL, a novel discrete sequence-to-sequence diffusion model that generates\nsynthetic scanpaths on texts. By leveraging pre-trained word representations\nand jointly embedding both the stimulus text and the fixation sequence, our\nmodel captures multi-modal interactions between the two inputs. We evaluate\nScanDL within- and across-dataset and demonstrate that it significantly\noutperforms state-of-the-art scanpath generation methods. Finally, we provide\nan extensive psycholinguistic analysis that underlines the model's ability to\nexhibit human-like reading behavior. Our implementation is made available at\nhttps://github.com/DiLi-Lab/ScanDL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bolliger_L/0/1/0/all/0/1\">Lena S. Bolliger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reich_D/0/1/0/all/0/1\">David R. Reich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haller_P/0/1/0/all/0/1\">Patrick Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobi_D/0/1/0/all/0/1\">Deborah N. Jakobi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasse_P/0/1/0/all/0/1\">Paul Prasse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jager_L/0/1/0/all/0/1\">Lena A. J&#xe4;ger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression. (arXiv:2310.15594v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15594","description":"<p>Large-scale pre-trained language models (LLMs) have demonstrated exceptional\nperformance in various natural language processing (NLP) tasks. However, the\nmassive size of these models poses huge challenges for their deployment in\nreal-world applications. While numerous model compression techniques have been\nproposed, most of them are not well-suited for achieving extreme model\ncompression when there is a significant gap in model scale. In this paper, we\nintroduce a novel compression paradigm called Retrieval-based Knowledge\nTransfer (RetriKT), which effectively transfers the knowledge of LLMs to\nextremely small-scale models (e.g., 1%). In particular, our approach extracts\nknowledge from LLMs to construct a knowledge store, from which the small-scale\nmodel can retrieve relevant information and leverage it for effective\ninference. To improve the quality of the model, soft prompt tuning and Proximal\nPolicy Optimization (PPO) reinforcement learning techniques are employed.\nExtensive experiments are conducted on low-resource tasks from SuperGLUE and\nGLUE benchmarks. The results demonstrate that the proposed approach\nsignificantly enhances the performance of small-scale models by leveraging the\nknowledge from LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiduan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiahao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xunliang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ran Lucien Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MUSER: A Multi-View Similar Case Retrieval Dataset. (arXiv:2310.15602v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15602","description":"<p>Similar case retrieval (SCR) is a representative legal AI application that\nplays a pivotal role in promoting judicial fairness. However, existing SCR\ndatasets only focus on the fact description section when judging the similarity\nbetween cases, ignoring other valuable sections (e.g., the court's opinion)\nthat can provide insightful reasoning process behind. Furthermore, the case\nsimilarities are typically measured solely by the textual semantics of the fact\ndescriptions, which may fail to capture the full complexity of legal cases from\nthe perspective of legal knowledge. In this work, we present MUSER, a similar\ncase retrieval dataset based on multi-view similarity measurement and\ncomprehensive legal element with sentence-level legal element annotations.\nSpecifically, we select three perspectives (legal fact, dispute focus, and law\nstatutory) and build a comprehensive and structured label schema of legal\nelements for each of them, to enable accurate and knowledgeable evaluation of\ncase similarities. The constructed dataset originates from Chinese civil cases\nand contains 100 query cases and 4,024 candidate cases. We implement several\ntext classification algorithms for legal element prediction and various\nretrieval methods for retrieving similar cases on MUSER. The experimental\nresults indicate that incorporating legal elements can benefit the performance\nof SCR models, but further efforts are still required to address the remaining\nchallenges posed by MUSER. The source code and dataset are released at\nhttps://github.com/THUlawtech/MUSER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qingquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yiran Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1\">Feng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaojun Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Weixing Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Translation for Nko: Tools, Corpora and Baseline Results. (arXiv:2310.15612v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15612","description":"<p>Currently, there is no usable machine translation system for Nko, a language\nspoken by tens of millions of people across multiple West African countries,\nwhich holds significant cultural and educational value. To address this issue,\nwe present a set of tools, resources, and baseline results aimed towards the\ndevelopment of usable machine translation systems for Nko and other languages\nthat do not currently have sufficiently large parallel text corpora available.\n(1) Friallel: A novel collaborative parallel text curation software that\nincorporates quality control through copyedit-based workflows. (2) Expansion of\nthe FLoRes-200 and NLLB-Seed corpora with 2,009 and 6,193 high-quality Nko\ntranslations in parallel with 204 and 40 other languages. (3) nicolingua-0005:\nA collection of trilingual and bilingual corpora with 130,850 parallel segments\nand monolingual corpora containing over 3 million Nko words. (4) Baseline\nbilingual and multilingual neural machine translation results with the best\nmodel scoring 30.83 English-Nko chrF++ on FLoRes-devtest.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doumbouya_M/0/1/0/all/0/1\">Moussa Koulako Bala Doumbouya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diane_B/0/1/0/all/0/1\">Baba Mamadi Dian&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cisse_S/0/1/0/all/0/1\">Solo Farabado Ciss&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diane_D/0/1/0/all/0/1\">Djibrila Dian&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sow_A/0/1/0/all/0/1\">Abdoulaye Sow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doumbouya_S/0/1/0/all/0/1\">S&#xe9;r&#xe9; Moussa Doumbouya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bangoura_D/0/1/0/all/0/1\">Daouda Bangoura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bayo_F/0/1/0/all/0/1\">Fod&#xe9; Moriba Bayo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_I/0/1/0/all/0/1\">Ibrahima Sory 2. Cond&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diane_K/0/1/0/all/0/1\">Kalo Mory Dian&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piech_C/0/1/0/all/0/1\">Chris Piech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher Manning</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tips for making the most of 64-bit architectures in langage design, libraries or garbage collection. (arXiv:2310.15632v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15632","description":"<p>The 64-bit architectures that have become standard today offer unprecedented\nlow-level programming possibilities. For the first time in the history of\ncomputing, the size of address registers far exceeded the physical capacity of\ntheir bus.After a brief reminder of the possibilities offered by the small size\nof addresses compared to the available 64 bits,we develop three concrete\nexamples of how the vacant bits of these registers can be used.Among these\nexamples, two of them concern the implementation of a library for a new\nstatically typed programming language.Firstly, the implementation of\nmulti-precision integers, with the aim of improving performance in terms of\nboth calculation speed and RAM savings.The second example focuses on the\nlibrary's handling of UTF-8 character strings.Here, the idea is to make\nindexing easier by ignoring the physical size of each UTF-8 characters.Finally,\nthe third example is a possible enhancement of garbage collectors, in\nparticular the mark \\&amp; sweep for the object marking phase.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sonntag_B/0/1/0/all/0/1\">Beno&#xee;t Sonntag</a> (UNISTRA), <a href=\"http://arxiv.org/find/cs/1/au:+Colnet_D/0/1/0/all/0/1\">Dominique Colnet</a> (LORIA)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Career Path Prediction using Resume Representation Learning and Skill-based Matching. (arXiv:2310.15636v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15636","description":"<p>The impact of person-job fit on job satisfaction and performance is widely\nacknowledged, which highlights the importance of providing workers with next\nsteps at the right time in their career. This task of predicting the next step\nin a career is known as career path prediction, and has diverse applications\nsuch as turnover prevention and internal job mobility. Existing methods to\ncareer path prediction rely on large amounts of private career history data to\nmodel the interactions between job titles and companies. We propose leveraging\nthe unexplored textual descriptions that are part of work experience sections\nin resumes. We introduce a structured dataset of 2,164 anonymized career\nhistories, annotated with ESCO occupation labels. Based on this dataset, we\npresent a novel representation learning approach, CareerBERT, specifically\ndesigned for work history data. We develop a skill-based model and a text-based\nmodel for career path prediction, which achieve 35.24% and 39.61% recall@10\nrespectively on our dataset. Finally, we show that both approaches are\ncomplementary as a hybrid approach achieves the strongest result with 43.01%\nrecall@10.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Decorte_J/0/1/0/all/0/1\">Jens-Joris Decorte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hautte_J/0/1/0/all/0/1\">Jeroen Van Hautte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1\">Johannes Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation. (arXiv:2310.15638v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15638","description":"<p>Annotated data plays a critical role in Natural Language Processing (NLP) in\ntraining models and evaluating their performance. Given recent developments in\nLarge Language Models (LLMs), models such as ChatGPT demonstrate zero-shot\ncapability on many text-annotation tasks, comparable with or even exceeding\nhuman annotators. Such LLMs can serve as alternatives for manual annotation,\ndue to lower costs and higher scalability. However, limited work has leveraged\nLLMs as complementary annotators, nor explored how annotation work is best\nallocated among humans and LLMs to achieve both quality and cost objectives. We\npropose CoAnnotating, a novel paradigm for Human-LLM co-annotation of\nunstructured texts at scale. Under this framework, we utilize uncertainty to\nestimate LLMs' annotation capability. Our empirical study shows CoAnnotating to\nbe an effective means to allocate work from results on different datasets, with\nup to 21% performance improvement over random baseline. For code\nimplementation, see https://github.com/SALT-NLP/CoAnnotating.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1\">Taiwei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziems_C/0/1/0/all/0/1\">Caleb Ziems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Detection of LLMs-Generated Content. (arXiv:2310.15654v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15654","description":"<p>The burgeoning capabilities of advanced large language models (LLMs) such as\nChatGPT have led to an increase in synthetic content generation with\nimplications across a variety of sectors, including media, cybersecurity,\npublic discourse, and education. As such, the ability to detect LLMs-generated\ncontent has become of paramount importance. We aim to provide a detailed\noverview of existing detection strategies and benchmarks, scrutinizing their\ndifferences and identifying key challenges and prospects in the field,\nadvocating for more adaptable and robust models to enhance detection accuracy.\nWe also posit the necessity for a multi-faceted approach to defend against\nvarious attacks to counter the rapidly advancing capabilities of LLMs. To the\nbest of our knowledge, this work is the first comprehensive survey on the\ndetection in the era of LLMs. We hope it will provide a broad understanding of\nthe current landscape of LLMs-generated content detection, offering a guiding\nreference for researchers and practitioners striving to uphold the integrity of\ndigital information in an era increasingly dominated by synthetic content. The\nrelevant papers are summarized and will be consistently updated at\nhttps://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xianjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xuandong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petzold_L/0/1/0/all/0/1\">Linda Petzold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Expression Syntax Information Bottleneck for Math Word Problems. (arXiv:2310.15664v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15664","description":"<p>Math Word Problems (MWP) aims to automatically solve mathematical questions\ngiven in texts. Previous studies tend to design complex models to capture\nadditional information in the original text so as to enable the model to gain\nmore comprehensive features. In this paper, we turn our attention in the\nopposite direction, and work on how to discard redundant features containing\nspurious correlations for MWP. To this end, we design an Expression Syntax\nInformation Bottleneck method for MWP (called ESIB) based on variational\ninformation bottleneck, which extracts essential features of expression syntax\ntree while filtering latent-specific redundancy containing syntax-irrelevant\nfeatures. The key idea of ESIB is to encourage multiple models to predict the\nsame expression syntax tree for different problem representations of the same\nproblem by mutual learning so as to capture consistent information of\nexpression syntax tree and discard latent-specific redundancy. To improve the\ngeneralization ability of the model and generate more diverse expressions, we\ndesign a self-distillation loss to encourage the model to rely more on the\nexpression syntax information in the latent space. Experimental results on two\nlarge-scale benchmarks show that our model not only achieves state-of-the-art\nresults but also generates more diverse solutions. The code is available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiping Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Bin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Much Context Does My Attention-Based ASR System Need?. (arXiv:2310.15672v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15672","description":"<p>For the task of speech recognition, the use of more than 30 seconds of\nacoustic context during training is uncommon, and under-investigated in\nliterature. In this work, we examine the effect of scaling the sequence length\nused to train/evaluate (dense-attention based) acoustic and language models on\nspeech recognition performance. For these experiments a dataset of roughly\n100,000 pseudo-labelled Spotify podcasts is used, with context lengths of 5\nseconds to 1 hour being explored. Zero-shot evaluations on long-format datasets\nEarnings-22 and Tedlium demonstrate a benefit from training with around 80\nseconds of acoustic context, showing up to a 14.9% relative improvement from a\nlimited context baseline. Furthermore, we perform a system combination with\nlong-context transformer language models via beam search for a fully\nlong-context ASR system, with results that are competitive with the current\nstate-of-the-art.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Flynn_R/0/1/0/all/0/1\">Robert Flynn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prevalence and prevention of large language model use in crowd work. (arXiv:2310.15683v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15683","description":"<p>We show that the use of large language models (LLMs) is prevalent among crowd\nworkers, and that targeted mitigation strategies can significantly reduce, but\nnot eliminate, LLM use. On a text summarization task where workers were not\ndirected in any way regarding their LLM use, the estimated prevalence of LLM\nuse was around 30%, but was reduced by about half by asking workers to not use\nLLMs and by raising the cost of using them, e.g., by disabling copy-pasting.\nSecondary analyses give further insight into LLM use and its prevention: LLM\nuse yields high-quality but homogeneous responses, which may harm research\nconcerned with human (rather than model) behavior and degrade future models\ntrained with crowdsourced data. At the same time, preventing LLM use may be at\nodds with obtaining high-quality responses; e.g., when requesting workers not\nto use LLMs, summaries contained fewer keywords carrying essential information.\nOur estimates will likely change as LLMs increase in popularity or\ncapabilities, and as norms around their usage change. Yet, understanding the\nco-evolution of LLM-based tools and users is key to maintaining the validity of\nresearch done using crowdsourcing, and we provide a critical baseline before\nwidespread adoption ensues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Veselovsky_V/0/1/0/all/0/1\">Veniamin Veselovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1\">Manoel Horta Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cozzolino_P/0/1/0/all/0/1\">Philip Cozzolino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordon_A/0/1/0/all/0/1\">Andrew Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rothschild_D/0/1/0/all/0/1\">David Rothschild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers. (arXiv:2310.15684v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15684","description":"<p>Abstracts derived from biomedical literature possess distinct domain-specific\ncharacteristics, including specialised writing styles and biomedical\nterminologies, which necessitate a deep understanding of the related\nliterature. As a result, existing language models struggle to generate\ntechnical summaries that are on par with those produced by biomedical experts,\ngiven the absence of domain-specific background knowledge. This paper aims to\nenhance the performance of language models in biomedical abstractive\nsummarisation by aggregating knowledge from external papers cited within the\nsource article. We propose a novel attention-based citation aggregation model\nthat integrates domain-specific knowledge from citation papers, allowing neural\nnetworks to generate summaries by leveraging both the paper content and\nrelevant knowledge from citation papers. Furthermore, we construct and release\na large-scale biomedical summarisation dataset that serves as a foundation for\nour research. Extensive experiments demonstrate that our model outperforms\nstate-of-the-art approaches and achieves substantial improvements in\nabstractive biomedical text summarisation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldsack_T/0/1/0/all/0/1\">Tomas Goldsack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Creating a silver standard for patent simplification. (arXiv:2310.15689v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15689","description":"<p>Patents are legal documents that aim at protecting inventions on the one hand\nand at making technical knowledge circulate on the other. Their complex style\n-- a mix of legal, technical, and extremely vague language -- makes their\ncontent hard to access for humans and machines and poses substantial challenges\nto the information retrieval community. This paper proposes an approach to\nautomatically simplify patent text through rephrasing. Since no in-domain\nparallel simplification data exist, we propose a method to automatically\ngenerate a large-scale silver standard for patent sentences. To obtain\ncandidates, we use a general-domain paraphrasing system; however, the process\nis error-prone and difficult to control. Thus, we pair it with proper filters\nand construct a cleaner corpus that can successfully be used to train a\nsimplification system. Human evaluation of the synthetic silver corpus shows\nthat it is considered grammatical, adequate, and contains simple sentences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Casola_S/0/1/0/all/0/1\">Silvia Casola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavelli_A/0/1/0/all/0/1\">Alberto Lavelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saggion_H/0/1/0/all/0/1\">Horacio Saggion</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Automated Recipe Genre Classification using Semi-Supervised Learning. (arXiv:2310.15693v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15693","description":"<p>Sharing cooking recipes is a great way to exchange culinary ideas and provide\ninstructions for food preparation. However, categorizing raw recipes found\nonline into appropriate food genres can be challenging due to a lack of\nadequate labeled data. In this study, we present a dataset named the\n``Assorted, Archetypal, and Annotated Two Million Extended (3A2M+) Cooking\nRecipe Dataset\" that contains two million culinary recipes labeled in\nrespective categories with extended named entities extracted from recipe\ndescriptions. This collection of data includes various features such as title,\nNER, directions, and extended NER, as well as nine different labels\nrepresenting genres including bakery, drinks, non-veg, vegetables, fast food,\ncereals, meals, sides, and fusions. The proposed pipeline named 3A2M+ extends\nthe size of the Named Entity Recognition (NER) list to address missing named\nentities like heat, time or process from the recipe directions using two NER\nextraction tools. 3A2M+ dataset provides a comprehensive solution to the\nvarious challenging recipe-related tasks, including classification, named\nentity recognition, and recipe generation. Furthermore, we have demonstrated\ntraditional machine learning, deep learning and pre-trained language models to\nclassify the recipes into their corresponding genre and achieved an overall\naccuracy of 98.6\\%. Our investigation indicates that the title feature played a\nmore significant role in classifying the genre.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sakib_N/0/1/0/all/0/1\">Nazmus Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahariar_G/0/1/0/all/0/1\">G. M. Shahariar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabir_M/0/1/0/all/0/1\">Md. Mohsinul Kabir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Md. Kamrul Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1\">Hasan Mahmud</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COPF: Continual Learning Human Preference through Optimal Policy Fitting. (arXiv:2310.15694v1 [cs.LG])","link":"http://arxiv.org/abs/2310.15694","description":"<p>The technique of Reinforcement Learning from Human Feedback (RLHF) is a\ncommonly employed method to improve pre-trained Language Models (LM), enhancing\ntheir ability to conform to human preferences. Nevertheless, the current\nRLHF-based LMs necessitate full retraining each time novel queries or feedback\nare introduced, which becomes a challenging task because human preferences can\nvary between different domains or tasks. Retraining LMs poses practical\ndifficulties in many real-world situations due to the significant time and\ncomputational resources required, along with concerns related to data privacy.\nTo address this limitation, we propose a new method called Continual Optimal\nPolicy Fitting (COPF), in which we estimate a series of optimal policies using\nthe Monte Carlo method, and then continually fit the policy sequence with the\nfunction regularization. COPF involves a single learning phase and doesn't\nnecessitate complex reinforcement learning. Importantly, it shares the\ncapability with RLHF to learn from unlabeled data, making it flexible for\ncontinual preference learning. Our experimental results show that COPF\noutperforms strong Continuous learning (CL) baselines when it comes to\nconsistently aligning with human preferences on different tasks and domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_Y/0/1/0/all/0/1\">Yuanzhao Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Biomedical Lay Summarisation with External Knowledge Graphs. (arXiv:2310.15702v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15702","description":"<p>Previous approaches for automatic lay summarisation are exclusively reliant\non the source article that, given it is written for a technical audience (e.g.,\nresearchers), is unlikely to explicitly define all technical concepts or state\nall of the background information that is relevant for a lay audience. We\naddress this issue by augmenting eLife, an existing biomedical lay\nsummarisation dataset, with article-specific knowledge graphs, each containing\ndetailed information on relevant biomedical concepts. Using both automatic and\nhuman evaluations, we systematically investigate the effectiveness of three\ndifferent approaches for incorporating knowledge graphs within lay\nsummarisation models, with each method targeting a distinct area of the\nencoder-decoder model architecture. Our results confirm that integrating\ngraph-based domain knowledge can significantly benefit lay summarisation by\nsubstantially increasing the readability of generated text and improving the\nexplanation of technical concepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goldsack_T/0/1/0/all/0/1\">Tomas Goldsack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Chen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ensemble of Task-Specific Language Models for Brain Encoding. (arXiv:2310.15720v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15720","description":"<p>Language models have been shown to be rich enough to encode fMRI activations\nof certain Regions of Interest in our Brains. Previous works have explored\ntransfer learning from representations learned for popular natural language\nprocessing tasks for predicting brain responses. In our work, we improve the\nperformance of such encoders by creating an ensemble model out of 10 popular\nLanguage Models (2 syntactic and 8 semantic). We beat the current baselines by\n10% on average across all ROIs through our ensembling methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumaran_S/0/1/0/all/0/1\">Sanjai Kumaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arun_A/0/1/0/all/0/1\">Arvindh Arun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+John_J/0/1/0/all/0/1\">Jerrin John</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion. (arXiv:2310.15722v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15722","description":"<p>Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting\naims to predict the missing entity from a fact in the future, posing a\nchallenge that aligns more closely with real-world prediction problems.\nExisting research mostly encodes entities and relations using sequential graph\nneural networks applied to recent snapshots. However, these approaches tend to\noverlook the ability to skip irrelevant snapshots according to entity-related\nrelations in the query and disregard the importance of explicit temporal\ninformation. To address this, we propose our model, Re-Temp (Relation-Aware\nTemporal Representation Learning), which leverages explicit temporal embedding\nas input and incorporates skip information flow after each timestamp to skip\nunnecessary information for prediction. Additionally, we introduce a two-phase\nforward propagation method to prevent information leakage. Through the\nevaluation on six TKGC (extrapolation) datasets, we demonstrate that our model\noutperforms all eight recent state-of-the-art models by a significant margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kunze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1\">Josiah Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules. (arXiv:2310.15724v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15724","description":"<p>Pre-trained language models (PLMs) have achieved remarkable results on NLP\ntasks but at the expense of huge parameter sizes and the consequent\ncomputational costs. In this paper, we propose Variator, a parameter-efficient\nacceleration method that enhances computational efficiency through\nplug-and-play compression plugins. Compression plugins are designed to reduce\nthe sequence length via compressing multiple hidden vectors into one and\ntrained with original PLMs frozen. Different from traditional model\nacceleration methods, which compress PLMs to smaller sizes, Variator offers two\ndistinct advantages: (1) In real-world applications, the plug-and-play nature\nof our compression plugins enables dynamic selection of different compression\nplugins with varying acceleration ratios based on the current workload. (2) The\ncompression plugin comprises a few compact neural network layers with minimal\nparameters, significantly saving storage and memory overhead, particularly in\nscenarios with a growing number of tasks. We validate the effectiveness of\nVariator on seven datasets. Experimental results show that Variator can save\n53% computational costs using only 0.9% additional parameters with a\nperformance drop of less than 2%. Moreover, when the model scales to billions\nof parameters, Variator matches the strong performance of uncompressed PLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaojun Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuqi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenbin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengle Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction. (arXiv:2310.15743v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15743","description":"<p>How to identify semantic relations among entities in a document when only a\nfew labeled documents are available? Few-shot document-level relation\nextraction (FSDLRE) is crucial for addressing the pervasive data scarcity\nproblem in real-world scenarios. Metric-based meta-learning is an effective\nframework widely adopted for FSDLRE, which constructs class prototypes for\nclassification. However, existing works often struggle to obtain class\nprototypes with accurate relational semantics: 1) To build prototype for a\ntarget relation type, they aggregate the representations of all entity pairs\nholding that relation, while these entity pairs may also hold other relations,\nthus disturbing the prototype. 2) They use a set of generic NOTA\n(none-of-the-above) prototypes across all tasks, neglecting that the NOTA\nsemantics differs in tasks with different target relation types. In this paper,\nwe propose a relation-aware prototype learning method for FSDLRE to strengthen\nthe relational semantics of prototype representations. By judiciously\nleveraging the relation descriptions and realistic NOTA instances as guidance,\nour method effectively refines the relation prototypes and generates\ntask-specific NOTA prototypes. Extensive experiments demonstrate that our\nmethod outperforms state-of-the-art approaches by average 2.61% $F_1$ across\nvarious settings of two FSDLRE benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meng_S/0/1/0/all/0/1\">Shiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Aiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shu&#x27;ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1\">Fukun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yawen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation. (arXiv:2310.15746v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15746","description":"<p>Large Language Models (LLMs) have showcased impressive performance. However,\ndue to their inability to capture relationships among samples, these frozen\nLLMs inevitably keep repeating similar mistakes. In this work, we propose our\nTuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving\ntheir performance by learning from previous mistakes. Considering data arrives\nsequentially, LLMs gradually accumulate rules from incorrect cases, forming a\nrule collection. These rules are then utilized by the LLMs to avoid making\nsimilar mistakes when processing subsequent inputs. Moreover, the rules remain\nindependent of the primary prompts, seamlessly complementing prompt design\nstrategies. Experimentally, we show that TRAN improves over recent baselines by\na large margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zeyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection. (arXiv:2310.15752v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15752","description":"<p>When translating words referring to the speaker, speech translation (ST)\nsystems should not resort to default masculine generics nor rely on potentially\nmisleading vocal traits. Rather, they should assign gender according to the\nspeakers' preference. The existing solutions to do so, though effective, are\nhardly feasible in practice as they involve dedicated model re-training on\ngender-labeled ST data. To overcome these limitations, we propose the first\ninference-time solution to control speaker-related gender inflections in ST.\nOur approach partially replaces the (biased) internal language model (LM)\nimplicitly learned by the ST decoder with gender-specific external LMs.\nExperiments on en-&gt;es/fr/it show that our solution outperforms the base models\nand the best training-time mitigation strategy by up to 31.0 and 1.6 points in\ngender accuracy, respectively, for feminine forms. The gains are even larger\n(up to 32.0 and 3.4) in the challenging condition where speakers' vocal traits\nconflict with their gender.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fucci_D/0/1/0/all/0/1\">Dennis Fucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaido_M/0/1/0/all/0/1\">Marco Gaido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papi_S/0/1/0/all/0/1\">Sara Papi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cettolo_M/0/1/0/all/0/1\">Mauro Cettolo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1\">Matteo Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bentivogli_L/0/1/0/all/0/1\">Luisa Bentivogli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Differences in Values Influence Disagreements in Online Discussions?. (arXiv:2310.15757v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15757","description":"<p>Disagreements are common in online discussions. Disagreement may foster\ncollaboration and improve the quality of a discussion under some conditions.\nAlthough there exist methods for recognizing disagreement, a deeper\nunderstanding of factors that influence disagreement is lacking in the\nliterature. We investigate a hypothesis that differences in personal values are\nindicative of disagreement in online discussions. We show how state-of-the-art\nmodels can be used for estimating values in online discussions and how the\nestimated values can be aggregated into value profiles. We evaluate the\nestimated value profiles based on human-annotated agreement labels. We find\nthat the dissimilarity of value profiles correlates with disagreement in\nspecific cases. We also find that including value information in agreement\nprediction improves performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meer_M/0/1/0/all/0/1\">Michiel van der Meer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vossen_P/0/1/0/all/0/1\">Piek Vossen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1\">Catholijn M. Jonker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murukannaiah_P/0/1/0/all/0/1\">Pradeep K. Murukannaiah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend Existing Ones?. (arXiv:2310.15758v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15758","description":"<p>Learning from free-text human feedback is essential for dialog systems, but\nannotated data is scarce and usually covers only a small fraction of error\ntypes known in conversational AI. Instead of collecting and annotating new\ndatasets from scratch, recent advances in synthetic dialog generation could be\nused to augment existing dialog datasets with the necessary annotations.\nHowever, to assess the feasibility of such an effort, it is important to know\nthe types and frequency of free-text human feedback included in these datasets.\nIn this work, we investigate this question for a variety of commonly used\ndialog datasets, including MultiWoZ, SGD, BABI, PersonaChat,\nWizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot.\nUsing our observations, we derive new taxonomies for the annotation of\nfree-text human feedback in dialogs and investigate the impact of including\nsuch data in response generation for three SOTA language generation models,\nincluding GPT-2, LLAMA, and Flan-T5. Our findings provide new insights into the\ncomposition of the datasets examined, including error types, user response\ntypes, and the relations between them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petrak_D/0/1/0/all/0/1\">Dominic Petrak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moosavi_N/0/1/0/all/0/1\">Nafise Sadat Moosavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Ye Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozanov_N/0/1/0/all/0/1\">Nikolai Rozanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLESS: Benchmarking Large Language Models on Sentence Simplification. (arXiv:2310.15773v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15773","description":"<p>We present BLESS, a comprehensive performance benchmark of the most recent\nstate-of-the-art large language models (LLMs) on the task of text\nsimplification (TS). We examine how well off-the-shelf LLMs can solve this\nchallenging task, assessing a total of 44 models, differing in size,\narchitecture, pre-training methods, and accessibility, on three test sets from\ndifferent domains (Wikipedia, news, and medical) under a few-shot setting. Our\nanalysis considers a suite of automatic metrics as well as a large-scale\nquantitative investigation into the types of common edit operations performed\nby the different models. Furthermore, we perform a manual qualitative analysis\non a subset of model outputs to better gauge the quality of the generated\nsimplifications. Our evaluation indicates that the best LLMs, despite not being\ntrained on TS, perform comparably with state-of-the-art TS baselines.\nAdditionally, we find that certain LLMs demonstrate a greater range and\ndiversity of edit operations. Our performance benchmark will be available as a\nresource for the development of future TS methods and evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kew_T/0/1/0/all/0/1\">Tannon Kew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_A/0/1/0/all/0/1\">Alison Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasquez_Rodriguez_L/0/1/0/all/0/1\">Laura V&#xe1;squez-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Sweta Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aumiller_D/0/1/0/all/0/1\">Dennis Aumiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alva_Manchego_F/0/1/0/all/0/1\">Fernando Alva-Manchego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shardlow_M/0/1/0/all/0/1\">Matthew Shardlow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications. (arXiv:2310.15777v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15777","description":"<p>Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious natural language tasks, marking significant strides towards general\nartificial intelligence. While general artificial intelligence is leveraged by\ndeveloping increasingly large-scale models, there could be another branch to\ndevelop lightweight custom models that better serve certain domains, taking\ninto account the high cost of training and deploying LLMs and the scarcity of\nresources. In this paper, we present MindLLM, a novel series of bilingual\nlightweight large language models, trained from scratch, alleviating such\nburdens by offering models with 1.3 billion and 3 billion parameters. A\nthorough account of experiences accrued during large model development is\ngiven, covering every step of the process, including data construction, model\narchitecture, evaluation, and applications. Such insights are hopefully\nvaluable for fellow academics and developers. MindLLM consistently matches or\nsurpasses the performance of other open-source larger models on some public\nbenchmarks. We also introduce an innovative instruction tuning framework\ntailored for smaller models to enhance their capabilities efficiently.\nMoreover, we explore the application of MindLLM in specific vertical domains\nsuch as law and finance, underscoring the agility and adaptability of our\nlightweight models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yizhe Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huashan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Runheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuhang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yang Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving generalization in large language models by learning prefix subspaces. (arXiv:2310.15793v1 [cs.LG])","link":"http://arxiv.org/abs/2310.15793","description":"<p>This article focuses on large language models (LLMs) fine-tuning in the\nscarce data regime (also known as the \"few-shot\" learning setting). We propose\na method to increase the generalization capabilities of LLMs based on neural\nnetwork subspaces. This optimization method, recently introduced in computer\nvision, aims to improve model generalization by identifying wider local optima\nthrough the joint optimization of an entire simplex of models in parameter\nspace. Its adaptation to massive, pretrained transformers, however, poses some\nchallenges. First, their considerable number of parameters makes it difficult\nto train several models jointly, and second, their deterministic parameter\ninitialization schemes make them unfit for the subspace method as originally\nproposed. We show in this paper that \"Parameter Efficient Fine-Tuning\" (PEFT)\nmethods, however, are perfectly compatible with this original approach, and\npropose to learn entire simplex of continuous prefixes. We test our method on a\nvariant of the GLUE benchmark adapted to the few-shot learning setting, and\nshow that both our contributions jointly lead to a gain in average performances\ncompared to sota methods. The implementation can be found at the following\nlink: https://github.com/Liloulou/prefix_subspace\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Falissard_L/0/1/0/all/0/1\">Louis Falissard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guigue_V/0/1/0/all/0/1\">Vincent Guigue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soulier_L/0/1/0/all/0/1\">Laure Soulier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Random Entity Quantization for Parameter-Efficient Compositional Knowledge Graph Representation. (arXiv:2310.15797v1 [cs.AI])","link":"http://arxiv.org/abs/2310.15797","description":"<p>Representation Learning on Knowledge Graphs (KGs) is essential for downstream\ntasks. The dominant approach, KG Embedding (KGE), represents entities with\nindependent vectors and faces the scalability challenge. Recent studies propose\nan alternative way for parameter efficiency, which represents entities by\ncomposing entity-corresponding codewords matched from predefined small-scale\ncodebooks. We refer to the process of obtaining corresponding codewords of each\nentity as entity quantization, for which previous works have designed\ncomplicated strategies. Surprisingly, this paper shows that simple random\nentity quantization can achieve similar results to current strategies. We\nanalyze this phenomenon and reveal that entity codes, the quantization outcomes\nfor expressing entities, have higher entropy at the code level and Jaccard\ndistance at the codeword level under random entity quantization. Therefore,\ndifferent entities become more easily distinguished, facilitating effective KG\nrepresentation. The above results show that current quantization strategies are\nnot critical for KG representation, and there is still room for improvement in\nentity distinguishability beyond current strategies. The code to reproduce our\nresults is available at https://github.com/JiaangL/RandomQuantization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Licheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhendong Mao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DALE: Generative Data Augmentation for Low-Resource Legal NLP. (arXiv:2310.15799v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15799","description":"<p>We present DALE, a novel and effective generative Data Augmentation framework\nfor low-resource LEgal NLP. DALE addresses the challenges existing frameworks\npose in generating effective data augmentations of legal documents - legal\nlanguage, with its specialized vocabulary and complex semantics, morphology,\nand syntax, does not benefit from data augmentations that merely rephrase the\nsource sentence. To address this, DALE, built on an Encoder-Decoder Language\nModel, is pre-trained on a novel unsupervised text denoising objective based on\nselective masking - our masking strategy exploits the domain-specific language\ncharacteristics of templatized legal documents to mask collocated spans of\ntext. Denoising these spans helps DALE acquire knowledge about legal concepts,\nprinciples, and language usage. Consequently, it develops the ability to\ngenerate coherent and diverse augmentations with novel contexts. Finally, DALE\nperforms conditional generation to generate synthetic augmentations for\nlow-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13\ndatasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our\nbaselines, including LLMs, qualitatively and quantitatively, with improvements\nof 1%-50%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sreyan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evuru_C/0/1/0/all/0/1\">Chandra Kiran Evuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sonal Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramaneswaran_S/0/1/0/all/0/1\">S Ramaneswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakshi_S/0/1/0/all/0/1\">S Sakshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_U/0/1/0/all/0/1\">Utkarsh Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Language Models Exhibit Social Identity Biases. (arXiv:2310.15819v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15819","description":"<p>The surge in popularity of large language models has given rise to concerns\nabout biases that these models could learn from humans. In this study, we\ninvestigate whether ingroup solidarity and outgroup hostility, fundamental\nsocial biases known from social science, are present in 51 large language\nmodels. We find that almost all foundational language models and some\ninstruction fine-tuned models exhibit clear ingroup-positive and\noutgroup-negative biases when prompted to complete sentences (e.g., \"We\nare...\"). A comparison of LLM-generated sentences with human-written sentences\non the internet reveals that these models exhibit similar level, if not\ngreater, levels of bias than human text. To investigate where these biases stem\nfrom, we experimentally varied the amount of ingroup-positive or\noutgroup-negative sentences the model was exposed to during fine-tuning in the\ncontext of the United States Democrat-Republican divide. Doing so resulted in\nthe models exhibiting a marked increase in ingroup solidarity and an even\ngreater increase in outgroup hostility. Furthermore, removing either\ningroup-positive or outgroup-negative sentences (or both) from the fine-tuning\ndata leads to a significant reduction in both ingroup solidarity and outgroup\nhostility, suggesting that biases can be reduced by removing biased training\ndata. Our findings suggest that modern language models exhibit fundamental\nsocial identity biases and that such biases can be mitigated by curating\ntraining data. Our results have practical implications for creating less biased\nlarge-language models and further underscore the need for more research into\nuser interactions with LLMs to prevent potential bias reinforcement in humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Tiancheng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrychenko_Y/0/1/0/all/0/1\">Yara Kyrychenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathje_S/0/1/0/all/0/1\">Steve Rathje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linden_S/0/1/0/all/0/1\">Sander van der Linden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roozenbeek_J/0/1/0/all/0/1\">Jon Roozenbeek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15823","description":"<p>A Reverse Dictionary is a tool enabling users to discover a word based on its\nprovided definition, meaning, or description. Such a technique proves valuable\nin various scenarios, aiding language learners who possess a description of a\nword without its identity, and benefiting writers seeking precise terminology.\nThese scenarios often encapsulate what is referred to as the\n\"Tip-of-the-Tongue\" (TOT) phenomena. In this work, we present our winning\nsolution for the Arabic Reverse Dictionary shared task. This task focuses on\nderiving a vector representation of an Arabic word from its accompanying\ndescription. The shared task encompasses two distinct subtasks: the first\ninvolves an Arabic definition as input, while the second employs an English\ndefinition. For the first subtask, our approach relies on an ensemble of\nfinetuned Arabic BERT-based models, predicting the word embedding for a given\ndefinition. The final representation is obtained through averaging the output\nembeddings from each model within the ensemble. In contrast, the most effective\nsolution for the second subtask involves translating the English test\ndefinitions into Arabic and applying them to the finetuned models originally\ntrained for the first subtask. This straightforward method achieves the highest\nscore across both subtasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ElBakry_A/0/1/0/all/0/1\">Ahmed ElBakry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabr_M/0/1/0/all/0/1\">Mohamed Gabr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElNokrashy_M/0/1/0/all/0/1\">Muhammad ElNokrashy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unnatural language processing: How do language models handle machine-generated prompts?. (arXiv:2310.15829v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15829","description":"<p>Language model prompt optimization research has shown that semantically and\ngrammatically well-formed manually crafted prompts are routinely outperformed\nby automatically generated token sequences with no apparent meaning or\nsyntactic structure, including sequences of vectors from a model's embedding\nspace. We use machine-generated prompts to probe how models respond to input\nthat is not composed of natural language expressions. We study the behavior of\nmodels of different sizes in multiple semantic tasks in response to both\ncontinuous and discrete machine-generated prompts, and compare it to the\nbehavior in response to human-generated natural-language prompts. Even when\nproducing a similar output, machine-generated and human prompts trigger\ndifferent response patterns through the network processing pathways, including\ndifferent perplexities, different attention and output entropy distributions,\nand different unit activation profiles. We provide preliminary insight into the\nnature of the units activated by different prompt types, suggesting that only\nnatural language prompts recruit a genuinely linguistic circuit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franzon_F/0/1/0/all/0/1\">Francesca Franzon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1\">Marco Baroni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Diffusion Weighted Graph Framework for New Intent Discovery. (arXiv:2310.15836v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15836","description":"<p>New Intent Discovery (NID) aims to recognize both new and known intents from\nunlabeled data with the aid of limited labeled data containing only known\nintents. Without considering structure relationships between samples, previous\nmethods generate noisy supervisory signals which cannot strike a balance\nbetween quantity and quality, hindering the formation of new intent clusters\nand effective transfer of the pre-training knowledge. To mitigate this\nlimitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to\ncapture both semantic similarities and structure relationships inherent in\ndata, enabling more sufficient and reliable supervisory signals. Specifically,\nfor each sample, we diffuse neighborhood relationships along semantic paths\nguided by the nearest neighbors for multiple hops to characterize its local\nstructure discriminately. Then, we sample its positive keys and weigh them\nbased on semantic similarities and local structures for contrastive learning.\nDuring inference, we further propose Graph Smoothing Filter (GSF) to explicitly\nutilize the structure relationships to filter high-frequency noise embodied in\nsemantically ambiguous samples on the cluster boundary. Extensive experiments\nshow that our method outperforms state-of-the-art models on all evaluation\nmetrics across multiple benchmark datasets. Code and data are available at\nhttps://github.com/yibai-shi/DWGF.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Wenkai Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_W/0/1/0/all/0/1\">Wenbin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_F/0/1/0/all/0/1\">Feng Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinghua Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">QianYing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Ping Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Guard: Empower the LLM to Safeguard Itself. (arXiv:2310.15851v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15851","description":"<p>The jailbreak attack can bypass the safety measures of a Large Language Model\n(LLM), generating harmful content. This misuse of LLM has led to negative\nsocietal consequences. Currently, there are two main approaches to address\njailbreak attacks: safety training and safeguards. Safety training focuses on\nfurther training LLM to enhance its safety. On the other hand, safeguards\ninvolve implementing external models or filters to prevent harmful outputs.\nHowever, safety training has constraints in its ability to adapt to new attack\ntypes and often leads to a drop in model performance. Safeguards have proven to\nbe of limited help. To tackle these issues, we propose a novel approach called\nSelf-Guard, which combines the strengths of both safety methods. Self-Guard\nincludes two stages. In the first stage, we enhance the model's ability to\nassess harmful content, and in the second stage, we instruct the model to\nconsistently perform harmful content detection on its own responses. The\nexperiment has demonstrated that Self-Guard is robust against jailbreak\nattacks. In the bad case analysis, we find that LLM occasionally provides\nharmless responses to harmful queries. Additionally, we evaluated the general\ncapabilities of the LLM before and after safety training, providing evidence\nthat Self-Guard does not result in the LLM's performance degradation. In\nsensitivity tests, Self-Guard not only avoids inducing over-sensitivity in LLM\nbut also can even mitigate this issue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zezhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fangkai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1\">Pu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1\">Qingwei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models. (arXiv:2310.15852v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15852","description":"<p>Numerous studies have demonstrated the ability of neural language models to\nlearn various linguistic properties without direct supervision. This work takes\nan initial step towards exploring the less researched topic of how neural\nmodels discover linguistic properties of words, such as gender, as well as the\nrules governing their usage. We propose to use an artificial corpus generated\nby a PCFG based on French to precisely control the gender distribution in the\ntraining data and determine under which conditions a model correctly captures\ngender information or, on the contrary, appears gender-biased.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Conti_L/0/1/0/all/0/1\">Lina Conti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wisniewski_G/0/1/0/all/0/1\">Guillaume Wisniewski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT. (arXiv:2310.15896v1 [cs.CL])","link":"http://arxiv.org/abs/2310.15896","description":"<p>Large language models (LLMs) have performed well in providing general and\nextensive health suggestions in single-turn conversations, exemplified by\nsystems such as ChatGPT, ChatGLM, ChatDoctor, DoctorGLM, and etc. However, the\nlimited information provided by users during single turn results in inadequate\npersonalization and targeting of the generated suggestions, which requires\nusers to independently select the useful part. It is mainly caused by the\nmissing ability to engage in multi-turn questioning. In real-world medical\nconsultations, doctors usually employ a series of iterative inquiries to\ncomprehend the patient's condition thoroughly, enabling them to provide\neffective and personalized suggestions subsequently, which can be defined as\nchain of questioning (CoQ) for LLMs. To improve the CoQ of LLMs, we propose\nBianQue, a ChatGLM-based LLM finetuned with the self-constructed health\nconversation dataset BianQueCorpus that is consist of multiple turns of\nquestioning and health suggestions polished by ChatGPT. Experimental results\ndemonstrate that the proposed BianQue can simultaneously balance the\ncapabilities of both questioning and health suggestions, which will help\npromote the research and application of LLMs in the field of proactive health.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yirong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1\">Xiaofen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+zheng_h/0/1/0/all/0/1\">huimin zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhipei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_K/0/1/0/all/0/1\">Kai Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sihang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jieling Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiangmin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretable Text Classification Via Prototype Trajectories. (arXiv:2007.01777v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2007.01777","description":"<p>We propose a novel interpretable deep neural network for text classification,\ncalled ProtoryNet, based on a new concept of prototype trajectories. Motivated\nby the prototype theory in modern linguistics, ProtoryNet makes a prediction by\nfinding the most similar prototype for each sentence in a text sequence and\nfeeding an RNN backbone with the proximity of each sentence to the\ncorresponding active prototype. The RNN backbone then captures the temporal\npattern of the prototypes, which we refer to as prototype trajectories.\nPrototype trajectories enable intuitive and fine-grained interpretation of the\nreasoning process of the RNN model, in resemblance to how humans analyze texts.\nWe also design a prototype pruning procedure to reduce the total number of\nprototypes used by the model for better interpretability. Experiments on\nmultiple public data sets show that ProtoryNet is more accurate than the\nbaseline prototype-based deep neural net and reduces the performance gap\ncompared to state-of-the-art black-box models. In addition, after prototype\npruning, the resulting ProtoryNet models only need less than or around 20\nprototypes for all datasets, which significantly benefits interpretability.\nFurthermore, we report a survey result indicating that human users find\nProtoryNet more intuitive and easier to understand than other prototype-based\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Dat Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1\">Stephen S. Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"JAMES: Normalizing Job Titles with Multi-Aspect Graph Embeddings and Reasoning. (arXiv:2202.10739v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2202.10739","description":"<p>In online job marketplaces, it is important to establish a well-defined job\ntitle taxonomy for various downstream tasks (e.g., job recommendation, users'\ncareer analysis, and turnover prediction). Job Title Normalization (JTN) is\nsuch a cleaning step to classify user-created non-standard job titles into\nnormalized ones. However, solving the JTN problem is non-trivial with\nchallenges: (1) semantic similarity of different job titles, (2) non-normalized\nuser-created job titles, and (3) large-scale and long-tailed job titles in\nreal-world applications. To this end, we propose a novel solution, named JAMES,\nthat constructs three unique embeddings (i.e., graph, contextual, and\nsyntactic) of a target job title to effectively capture its various traits. We\nfurther propose a multi-aspect co-attention mechanism to attentively combine\nthese embeddings, and employ neural logical reasoning representations to\ncollaboratively estimate similarities between messy job titles and normalized\njob titles in a reasoning space. To evaluate JAMES, we conduct comprehensive\nexperiments against ten competing models on a large-scale real-world dataset\nwith over 350,000 job titles. Our experimental results show that JAMES\nsignificantly outperforms the best baseline by 10.06% in Precision@10 and by\n17.52% in NDCG@10, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_M/0/1/0/all/0/1\">Michiharu Yamashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jia Tracy Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thanh Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekhtiari_H/0/1/0/all/0/1\">Hamoon Ekhtiari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongwon Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCL-RAI: Span-based Contrastive Learning with Retrieval Augmented Inference for Unlabeled Entity Problem in NER. (arXiv:2209.01646v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.01646","description":"<p>Named Entity Recognition is the task to locate and classify the entities in\nthe text. However, Unlabeled Entity Problem in NER datasets seriously hinders\nthe improvement of NER performance. This paper proposes SCL-RAI to cope with\nthis problem. Firstly, we decrease the distance of span representations with\nthe same label while increasing it for different ones via span-based\ncontrastive learning, which relieves the ambiguity among entities and improves\nthe robustness of the model over unlabeled entities. Then we propose retrieval\naugmented inference to mitigate the decision boundary shifting problem. Our\nmethod significantly outperforms the previous SOTA method by 4.21% and 8.64%\nF1-score on two real-world datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Shuzheng Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jiaxing Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MaXM: Towards Multilingual Visual Question Answering. (arXiv:2209.05401v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.05401","description":"<p>Visual Question Answering (VQA) has been primarily studied through the lens\nof the English language. Yet, tackling VQA in other languages in the same\nmanner would require a considerable amount of resources. In this paper, we\npropose scalable solutions to multilingual visual question answering (mVQA), on\nboth data and modeling fronts. We first propose a translation-based framework\nto mVQA data generation that requires much less human annotation efforts than\nthe conventional approach of directly collection questions and answers. Then,\nwe apply our framework to the multilingual captions in the Crossmodal-3600\ndataset and develop an efficient annotation protocol to create MaXM, a\ntest-only VQA benchmark in 7 diverse languages. Finally, we develop a simple,\nlightweight, and effective approach as well as benchmark state-of-the-art\nEnglish and multilingual VQA models. We hope that our benchmark encourages\nfurther research on mVQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Linting Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yarom_M/0/1/0/all/0/1\">Michal Yarom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thapliyal_A/0/1/0/all/0/1\">Ashish V. Thapliyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amelot_J/0/1/0/all/0/1\">Julien Amelot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization. (arXiv:2212.10465v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10465","description":"<p>Data scarcity has been a long standing issue in the field of open-domain\nsocial dialogue. To quench this thirst, we present SODA: the first publicly\navailable, million-scale high-quality social dialogue dataset. By\ncontextualizing social commonsense knowledge from a knowledge graph, we are\nable to distill an exceptionally broad spectrum of social interactions from a\nlarge language model. Human evaluation shows that conversations in SODA are\nmore consistent, specific, and (surprisingly) natural than those in prior\nhuman-authored datasets.\n</p>\n<p>Using SODA, we train COSMO: a generalizable conversation model that is\nsignificantly more natural and consistent on unseen datasets than\nbest-performing conversation models (e.g., GODEL, BlenderBot-1, Koala, Vicuna).\nExperiments reveal COSMO is sometimes even preferred to the original\nhuman-written gold responses. Additionally, our results shed light on the\ndistinction between knowledge-enriched conversations and natural social\nchitchats. We plan to make our data, model, and code public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alikhani_M/0/1/0/all/0/1\">Malihe Alikhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks. (arXiv:2212.10548v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10548","description":"<p>In the absence of readily available labeled data for a given sequence\nlabeling task and language, annotation projection has been proposed as one of\nthe possible strategies to automatically generate annotated data. Annotation\nprojection has often been formulated as the task of transporting, on parallel\ncorpora, the labels pertaining to a given span in the source language into its\ncorresponding span in the target language. In this paper we present\nT-Projection, a novel approach for annotation projection that leverages large\npretrained text-to-text language models and state-of-the-art machine\ntranslation technology. T-Projection decomposes the label projection task into\ntwo subtasks: (i) A candidate generation step, in which a set of projection\ncandidates using a multilingual T5 model is generated and, (ii) a candidate\nselection step, in which the generated candidates are ranked based on\ntranslation probabilities. We conducted experiments on intrinsic and extrinsic\ntasks in 5 Indo-European and 8 low-resource African languages. We demostrate\nthat T-projection outperforms previous annotation projection methods by a wide\nmargin. We believe that T-Projection can help to automatically alleviate the\nlack of high-quality training data for sequence labeling tasks. Code and data\nare publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Ferrero_I/0/1/0/all/0/1\">Iker Garc&#xed;a-Ferrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1\">German Rigau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Batch Prompting: Efficient Inference with Large Language Model APIs. (arXiv:2301.08721v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08721","description":"<p>Performing inference on large volumes of samples with large language models\n(LLMs) can be computationally and financially costly in industry and real-world\nuse. We propose batch prompting, a simple yet effective prompting approach that\nenables the LLM to run inference in batches, instead of one sample at a time.\nOur method reduces both token and time costs while retaining downstream\nperformance. We theoretically demonstrate that under a few-shot in-context\nlearning setting, the inference costs decrease almost inverse linearly with the\nnumber of samples in each batch. We extensively validate the effectiveness of\nbatch prompting on ten datasets across commonsense QA, arithmetic reasoning,\nand NLI/NLU: batch prompting significantly~(up to 5x with six samples in batch)\nreduces the LLM (Codex) inference token and time costs while achieving better\nor comparable performance. For state-of-the-art Chat-based LLMs, e.g., GPT-3.5\nand GPT-4, we show the benefits of batch prompting also hold. Further analysis\nshows that the number of samples in each batch and the complexity of tasks\naffect its performance. Moreover, batch prompting can be applied across\ndifferent reasoning methods using LLMs. Our code can be found at the site\nhttps://github.com/xlang-ai/batch-prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zhoujun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mo\\^usai: Text-to-Music Generation with Long-Context Latent Diffusion. (arXiv:2301.11757v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11757","description":"<p>Recent years have seen the rapid development of large generative models for\ntext; however, much less research has explored the connection between text and\nanother \"language\" of communication -- music. Music, much like text, can convey\nemotions, stories, and ideas, and has its own unique structure and syntax. In\nour work, we bridge text and music via a text-to-music generation model that is\nhighly efficient, expressive, and can handle long-term structure. Specifically,\nwe develop Mo\\^usai, a cascading two-stage latent diffusion model that can\ngenerate multiple minutes of high-quality stereo music at 48kHz from textual\ndescriptions. Moreover, our model features high efficiency, which enables\nreal-time inference on a single consumer GPU with a reasonable speed. Through\nexperiments and property analyses, we show our model's competence over a\nvariety of criteria compared with existing music generation models. Lastly, to\npromote the open-source culture, we provide a collection of open-source\nlibraries with the hope of facilitating future work in the field. We\nopen-source the following: Codes:\nhttps://github.com/archinetai/audio-diffusion-pytorch; music samples for this\npaper: <a href=\"http://bit.ly/44ozWDH\">this http URL</a>; all music samples for all models:\nhttps://bit.ly/audio-diffusion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_F/0/1/0/all/0/1\">Flavio Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_O/0/1/0/all/0/1\">Ojasv Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Selection for Language Models via Importance Resampling. (arXiv:2302.03169v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03169","description":"<p>Selecting a suitable pretraining dataset is crucial for both general-domain\n(e.g., GPT-3) and domain-specific (e.g., Codex) language models (LMs). We\nformalize this problem as selecting a subset of a large raw unlabeled dataset\nto match a desired target distribution given some unlabeled target samples. Due\nto the large scale and dimensionality of the raw text data, existing methods\nuse simple heuristics or use experts to manually curate data. Instead, we\nextend the classic importance resampling approach used in low-dimensions for LM\ndata selection. We propose Data Selection with Importance Resampling (DSIR), an\nefficient and scalable framework that estimates importance weights in a reduced\nfeature space for tractability and selects data with importance resampling\naccording to these weights. To determine an appropriate feature space, we show\nthat KL reduction, a data metric that measures the proximity between selected\npretraining data and the target in a feature space, has high correlation with\naverage downstream accuracy (r=0.89) when computed with simple n-gram features.\nThis motivates our instantiation of DSIR using n-gram features. When performing\ncontinued pretraining towards a specific domain, DSIR performs comparably to\nexpert curation across 8 target distributions. When pretraining general-domain\nmodels (target is Wikipedia + books), DSIR improves over random selection and\nheuristic filtering baselines by 2-2.5% on the GLUE benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Sang Michael Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santurkar_S/0/1/0/all/0/1\">Shibani Santurkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.14229","description":"<p>Given a document in a source language, cross-lingual summarization (CLS) aims\nto generate a summary in a different target language. Recently, the emergence\nof Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has\nattracted wide attention from the computational linguistics community. However,\nit is not yet known the performance of LLMs on CLS. In this report, we\nempirically use various prompts to guide LLMs to perform zero-shot CLS from\ndifferent paradigms (i.e., end-to-end and pipeline), and provide a preliminary\nevaluation on the generated summaries. We find that ChatGPT and GPT-4\noriginally prefer to produce lengthy summaries with detailed information. These\ntwo LLMs can further balance informativeness and conciseness with the help of\nan interactive prompt, significantly improving their CLS performance.\nExperimental results on three widely-used CLS datasets show that GPT-4 achieves\nstate-of-the-art zero-shot CLS performance, and performs competitively compared\nwith the fine-tuned mBART-50. Moreover, we also find some multi-lingual and\nbilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limited\nzero-shot CLS ability. Due to the composite nature of CLS, which requires\nmodels to perform summarization and translation simultaneously, accomplishing\nthis task in a zero-shot manner is even a challenge for LLMs. Therefore, we\nsincerely hope and recommend future LLM research could use CLS as a testbed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yunlong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_B/0/1/0/all/0/1\">Beiqi Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhixu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_J/0/1/0/all/0/1\">Jianfeng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network. (arXiv:2303.03387v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.03387","description":"<p>The tremendous growth of social media users interacting in online\nconversations has led to significant growth in hate speech, affecting people\nfrom various demographics. Most of the prior works focus on detecting explicit\nhate speech, which is overt and leverages hateful phrases, with very little\nwork focusing on detecting hate speech that is implicit or denotes hatred\nthrough indirect or coded language. In this paper, we present CoSyn, a\ncontext-synergized neural network that explicitly incorporates user- and\nconversational context for detecting implicit hate speech in online\nconversations. CoSyn introduces novel ways to encode these external contexts\nand employs a novel context interaction mechanism that clearly captures the\ninterplay between them, making independent assessments of the amounts of\ninformation to be retrieved from these noisy contexts. Additionally, it carries\nout all these operations in the hyperbolic space to account for the scale-free\ndynamics of social media. We demonstrate the effectiveness of CoSyn on 6 hate\nspeech datasets and show that CoSyn outperforms all our baselines in detecting\nimplicit hate speech with absolute improvements in the range of 1.24% - 57.8%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sreyan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_M/0/1/0/all/0/1\">Manan Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiniya_P/0/1/0/all/0/1\">Purva Chiniya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyagi_U/0/1/0/all/0/1\">Utkarsh Tyagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sonal Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is ChatGPT a Good NLG Evaluator? A Preliminary Study. (arXiv:2303.04048v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.04048","description":"<p>Recently, the emergence of ChatGPT has attracted wide attention from the\ncomputational linguistics community. Many prior studies have shown that ChatGPT\nachieves remarkable performance on various NLP tasks in terms of automatic\nevaluation metrics. However, the ability of ChatGPT to serve as an evaluation\nmetric is still underexplored. Considering assessing the quality of natural\nlanguage generation (NLG) models is an arduous task and NLG metrics notoriously\nshow their poor correlation with human judgments, we wonder whether ChatGPT is\na good NLG evaluation metric. In this report, we provide a preliminary\nmeta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail,\nwe regard ChatGPT as a human evaluator and give task-specific (e.g.,\nsummarization) and aspect-specific (e.g., relevance) instruction to prompt\nChatGPT to evaluate the generated results of NLG models. We conduct experiments\non five NLG meta-evaluation datasets (including summarization, story generation\nand data-to-text tasks). Experimental results show that compared with previous\nautomatic metrics, ChatGPT achieves state-of-the-art or competitive correlation\nwith human judgments in most cases. In addition, we find that the effectiveness\nof the ChatGPT evaluator might be influenced by the creation method of the\nmeta-evaluation datasets. For the meta-evaluation datasets which are created\ngreatly depending on the reference and thus are biased, the ChatGPT evaluator\nmight lose its effectiveness. We hope our preliminary study could prompt the\nemergence of a general-purposed reliable NLG metric.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yunlong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zengkui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Haoxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhixu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_J/0/1/0/all/0/1\">Jianfeng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Consistency Analysis of ChatGPT. (arXiv:2303.06273v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.06273","description":"<p>ChatGPT has gained a huge popularity since its introduction. Its positive\naspects have been reported through many media platforms, and some analyses even\nshowed that ChatGPT achieved a decent grade in professional exams, adding extra\nsupport to the claim that AI can now assist and even replace humans in\nindustrial fields. Others, however, doubt its reliability and trustworthiness.\nThis paper investigates the trustworthiness of ChatGPT and GPT-4 regarding\nlogically consistent behaviour, focusing specifically on semantic consistency\nand the properties of negation, symmetric, and transitive consistency. Our\nfindings suggest that while both models appear to show an enhanced language\nunderstanding and reasoning ability, they still frequently fall short of\ngenerating logically consistent predictions. We also ascertain via experiments\nthat prompt designing, few-shot learning and employing larger large language\nmodels (LLMs) are unlikely to be the ultimate solution to resolve the\ninconsistency issue of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jang_M/0/1/0/all/0/1\">Myeongjun Erik Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1\">Thomas Lukasiewicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoLT5: Faster Long-Range Transformers with Conditional Computation. (arXiv:2303.09752v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09752","description":"<p>Many natural language processing tasks benefit from long inputs, but\nprocessing long documents with Transformers is expensive -- not only due to\nquadratic attention complexity but also from applying feedforward and\nprojection layers to every token. However, not all tokens are equally\nimportant, especially for longer documents. We propose CoLT5, a long-input\nTransformer model that builds on this intuition by employing conditional\ncomputation, devoting more resources to important tokens in both feedforward\nand attention layers. We show that CoLT5 achieves stronger performance than\nLongT5 with much faster training and inference, achieving SOTA on the\nlong-input SCROLLS benchmark. Moreover, CoLT5 can effectively and tractably\nmake use of extremely long inputs, showing strong gains up to 64k input length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1\">Tao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1\">Santiago Onta&#xf1;&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1\">Siddhartha Brahma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemlyanskiy_Y/0/1/0/all/0/1\">Yury Zemlyanskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uthus_D/0/1/0/all/0/1\">David Uthus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Mandy Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1\">James Lee-Thorp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yun-Hsuan Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghai_S/0/1/0/all/0/1\">Sumit Sanghai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13988","description":"<p>Large language models (LLMs) are currently at the forefront of intertwining\nAI systems with human communication and everyday life. Due to rapid\ntechnological advances and their extreme versatility, LLMs nowadays have\nmillions of users and are at the cusp of being the main go-to technology for\ninformation retrieval, content generation, problem-solving, etc. Therefore, it\nis of great importance to thoroughly assess and scrutinize their capabilities.\nDue to increasingly complex and novel behavioral patterns in current LLMs, this\ncan be done by treating them as participants in psychology experiments that\nwere originally designed to test humans. For this purpose, the paper introduces\na new field of research called \"machine psychology\". The paper outlines how\ndifferent subfields of psychology can inform behavioral tests for LLMs. It\ndefines methodological standards for machine psychology research, especially by\nfocusing on policies for prompt designs. Additionally, it describes how\nbehavioral patterns discovered in LLMs are to be interpreted. In sum, machine\npsychology aims to discover emergent abilities in LLMs that cannot be detected\nby most traditional natural language processing benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hagendorff_T/0/1/0/all/0/1\">Thilo Hagendorff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document-Level Machine Translation with Large Language Models. (arXiv:2304.02210v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.02210","description":"<p>Large language models (LLMs) such as ChatGPT can produce coherent, cohesive,\nrelevant, and fluent answers for various natural language processing (NLP)\ntasks. Taking document-level machine translation (MT) as a testbed, this paper\nprovides an in-depth evaluation of LLMs' ability on discourse modeling. The\nstudy focuses on three aspects: 1) Effects of Context-Aware Prompts, where we\ninvestigate the impact of different prompts on document-level translation\nquality and discourse phenomena; 2) Comparison of Translation Models, where we\ncompare the translation performance of ChatGPT with commercial MT systems and\nadvanced document-level MT methods; 3) Analysis of Discourse Modelling\nAbilities, where we further probe discourse knowledge encoded in LLMs and shed\nlight on impacts of training techniques on discourse modeling. By evaluating on\na number of benchmarks, we surprisingly find that LLMs have demonstrated\nsuperior performance and show potential to become a new paradigm for\ndocument-level translation: 1) leveraging their powerful long-text modeling\ncapabilities, GPT-3.5 and GPT-4 outperform commercial MT systems in terms of\nhuman evaluation; 2) GPT-4 demonstrates a stronger ability for probing\nlinguistic knowledge than GPT-3.5. This work highlights the challenges and\nopportunities of LLMs for MT, which we hope can inspire the future design and\nevaluation of LLMs.We release our data and annotations at\nhttps://github.com/longyuewangdcu/Document-MT-LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1\">Chenyang Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1\">Tianbo Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Verifiability in Generative Search Engines. (arXiv:2304.09848v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09848","description":"<p>Generative search engines directly generate responses to user queries, along\nwith in-line citations. A prerequisite trait of a trustworthy generative search\nengine is verifiability, i.e., systems should cite comprehensively (high\ncitation recall; all statements are fully supported by citations) and\naccurately (high citation precision; every cite supports its associated\nstatement). We conduct human evaluation to audit four popular generative search\nengines -- Bing Chat, NeevaAI, perplexity.ai, and YouChat -- across a diverse\nset of queries from a variety of sources (e.g., historical Google user queries,\ndynamically-collected open-ended questions on Reddit, etc.). We find that\nresponses from existing generative search engines are fluent and appear\ninformative, but frequently contain unsupported statements and inaccurate\ncitations: on average, a mere 51.5% of generated sentences are fully supported\nby citations and only 74.5% of citations support their associated sentence. We\nbelieve that these results are concerningly low for systems that may serve as a\nprimary tool for information-seeking users, especially given their facade of\ntrustworthiness. We hope that our results further motivate the development of\ntrustworthy generative search engines and help researchers and users better\nunderstand the shortcomings of existing commercial systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nelson F. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model. (arXiv:2305.00586v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.00586","description":"<p>Pre-trained language models can be surprisingly adept at tasks they were not\nexplicitly trained on, but how they implement these capabilities is poorly\nunderstood. In this paper, we investigate the basic mathematical abilities\noften acquired by pre-trained language models. Concretely, we use mechanistic\ninterpretability techniques to explain the (limited) mathematical abilities of\nGPT-2 small. As a case study, we examine its ability to take in sentences such\nas \"The war lasted from the year 1732 to the year 17\", and predict valid\ntwo-digit end years (years &gt; 32). We first identify a circuit, a small subset\nof GPT-2 small's computational graph that computes this task's output. Then, we\nexplain the role of each circuit component, showing that GPT-2 small's final\nmulti-layer perceptrons boost the probability of end years greater than the\nstart year. Finally, we find related tasks that activate our circuit. Our\nresults suggest that GPT-2 small computes greater-than using a complex but\ngeneral mechanism that activates across diverse contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1\">Michael Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Ollie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Variengien_A/0/1/0/all/0/1\">Alexandre Variengien</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VPGTrans: Transfer Visual Prompt Generator across LLMs. (arXiv:2305.01278v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.01278","description":"<p>While developing a new multimodal LLM (MLLM) by pre-training on tremendous\nimage-text pairs from scratch can be exceedingly resource-consuming, connecting\nan existing LLM with a comparatively lightweight visual prompt generator (VPG)\nbecomes a feasible paradigm. However, further tuning the VPG part of the MLLM\nstill suffers from indispensable computational costs, i.e., requiring thousands\nof GPU hours and millions of training data. One alternative solution is to\ntransfer an existing VPG from any existing MLLMs for the target MLLM.\n</p>\n<p>In this work, we for the first time investigate the VPG transferability\nacross LLMs, and explore a solution to reduce the cost of VPG transfer. We\nfirst study the VPG transfer across different LLM sizes (e.g., small-to-large),\nand across different LLM types, through which we diagnose the key factors to\nmaximize the transfer efficiency. Based on our observation, we design a\ntwo-stage transfer framework named VPGTrans, which is simple yet highly\neffective. Through extensive experiments, we demonstrate that VPGTrans helps\nsignificantly speed up the transfer learning process without compromising\nperformance. Remarkably, it helps achieve the VPG transfer from BLIP-2\nOPT$_\\text{2.7B}$ to BLIP-2 OPT$_\\text{6.7B}$ with over 10 times speed-up and\n10.7% training data compared with connecting a VPG to OPT$_\\text{6.7B}$ from\nscratch. Further, a series of intriguing findings and potential rationales\nbehind them are provided and discussed. Finally, we showcase the practical\nvalue of our VPGTrans approach, by customizing two novel MLLMs, including\nVL-LLaMA and VL-Vicuna, with recently released LLaMA and Vicuna LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Ao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Li Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoEdIT: Text Editing by Task-Specific Instruction Tuning. (arXiv:2305.09857v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09857","description":"<p>We introduce CoEdIT, a state-of-the-art text editing system for writing\nassistance. CoEdIT takes instructions from the user specifying the attributes\nof the desired text, such as \"Make the sentence simpler\" or \"Write it in a more\nneutral style,\" and outputs the edited text. We present a large language model\nfine-tuned on a diverse collection of task-specific instructions for text\nediting (a total of 82K instructions). Our model (1) achieves state-of-the-art\nperformance on various text editing benchmarks, (2) is competitive with\npublicly available largest-sized LLMs trained on instructions while being\nnearly 60x smaller, (3) is capable of generalizing to unseen edit instructions,\nand (4) exhibits abilities to generalize to composite instructions containing\ndifferent combinations of edit actions. Through extensive qualitative and\nquantitative analysis, we show that writers prefer the edits suggested by\nCoEdIT relative to other state-of-the-art text editing models. Our code, data,\nand models are publicly available at https://github.com/vipulraheja/coedit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raheja_V/0/1/0/all/0/1\">Vipul Raheja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1\">Dhruv Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koo_R/0/1/0/all/0/1\">Ryan Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Elaborative Simplification as Implicit Questions Under Discussion. (arXiv:2305.10387v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10387","description":"<p>Automated text simplification, a technique useful for making text more\naccessible to people such as children and emergent bilinguals, is often thought\nof as a monolingual translation task from complex sentences to simplified\nsentences using encoder-decoder models. This view fails to account for\nelaborative simplification, where new information is added into the simplified\ntext. This paper proposes to view elaborative simplification through the lens\nof the Question Under Discussion (QUD) framework, providing a robust way to\ninvestigate what writers elaborate upon, how they elaborate, and how\nelaborations fit into the discourse context by viewing elaborations as explicit\nanswers to implicit questions. We introduce ElabQUD, consisting of 1.3K\nelaborations accompanied with implicit QUDs, to study these phenomena. We show\nthat explicitly modeling QUD (via question generation) not only provides\nessential understanding of elaborative simplification and how the elaborations\nconnect with the rest of the discourse, but also substantially improves the\nquality of elaboration generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yating Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheffield_W/0/1/0/all/0/1\">William Sheffield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models. (arXiv:2305.12001v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12001","description":"<p>In this paper, we conduct a thorough investigation into the reasoning\ncapabilities of Large Language Models (LLMs), focusing specifically on the Open\nPretrained Transformers (OPT) models as a representative of such models. Our\nstudy entails finetuning three different sizes of OPT on a carefully curated\nreasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned\nwithout explanations, and OPT-RE, finetuned with explanations. We then evaluate\nall models on 57 out-of-domain tasks drawn from the SUPER-NATURALINSTRUCTIONS\nbenchmark, covering 26 distinct reasoning skills, utilizing three prompting\ntechniques. Through a comprehensive grid of 27 configurations and 6,156 test\nevaluations, we investigate the dimensions of finetuning, prompting, and scale\nto understand the role of explanations on different reasoning skills. Our\nfindings reveal that having explanations in the fewshot exemplar has no\nsignificant impact on the model's performance when the model is finetuned,\nwhile positively affecting the non-finetuned counterpart. Moreover, we observe\na slight yet consistent increase in classification accuracy as we incorporate\nexplanations during prompting and finetuning, respectively. Finally, we offer\ninsights on which skills benefit the most from incorporating explanations\nduring finetuning and prompting, such as Numerical (+20.4%) and Analogical\n(+13.9%) reasoning, as well as skills that exhibit negligible or negative\neffects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Siddharth Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Ping Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Diachronic Analysis of Paradigm Shifts in NLP Research: When, How, and Why?. (arXiv:2305.12920v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12920","description":"<p>Understanding the fundamental concepts and trends in a scientific field is\ncrucial for keeping abreast of its continuous advancement. In this study, we\npropose a systematic framework for analyzing the evolution of research topics\nin a scientific field using causal discovery and inference techniques. We\ndefine three variables to encompass diverse facets of the evolution of research\ntopics within NLP and utilize a causal discovery algorithm to unveil the causal\nconnections among these variables using observational data. Subsequently, we\nleverage this structure to measure the intensity of these relationships. By\nconducting extensive experiments on the ACL Anthology corpus, we demonstrate\nthat our framework effectively uncovers evolutionary trends and the underlying\ncauses for a wide range of NLP research topics. Specifically, we show that\ntasks and methods are primary drivers of research in NLP, with datasets\nfollowing, while metrics have minimal impact.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pramanick_A/0/1/0/all/0/1\">Aniket Pramanick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yufang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling ChatGPT for Explainable Automated Student Answer Assessment. (arXiv:2305.12962v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12962","description":"<p>Providing explainable and faithful feedback is crucial for automated student\nanswer assessment. In this paper, we introduce a novel framework that explores\nusing ChatGPT, a cutting-edge large language model, for the concurrent tasks of\nstudent answer scoring and rationale generation. We identify the appropriate\ninstructions by prompting ChatGPT with different templates to collect the\nrationales, where inconsistent rationales are refined to align with marking\nstandards. The refined ChatGPT outputs enable us to fine-tune a smaller\nlanguage model that simultaneously assesses student answers and provides\nrationales. Extensive experiments on the benchmark dataset show that the\nproposed method improves the overall QWK score by 11% compared to ChatGPT.\nFurthermore, our thorough analysis and human evaluation demonstrate that the\nrationales generated by our proposed method are comparable to those of ChatGPT.\nOur approach provides a viable solution to achieve explainable automated\nassessment in education. Code available at\nhttps://github.com/lijiazheng99/aera.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiazheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuxiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_D/0/1/0/all/0/1\">David West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aloisi_C/0/1/0/all/0/1\">Cesare Aloisi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nearest Neighbor Machine Translation is Meta-Optimizer on Output Projection Layer. (arXiv:2305.13034v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13034","description":"<p>Nearest Neighbor Machine Translation ($k$NN-MT) has achieved great success in\ndomain adaptation tasks by integrating pre-trained Neural Machine Translation\n(NMT) models with domain-specific token-level retrieval. However, the reasons\nunderlying its success have not been thoroughly investigated. In this paper, we\ncomprehensively analyze $k$NN-MT through theoretical and empirical studies.\nInitially, we provide new insights into the working mechanism of $k$NN-MT as an\nefficient technique to implicitly execute gradient descent on the output\nprojection layer of NMT, indicating that it is a specific case of model\nfine-tuning. Subsequently, we conduct multi-domain experiments and word-level\nanalysis to examine the differences in performance between $k$NN-MT and\nentire-model fine-tuning. Our findings suggest that: (1) Incorporating $k$NN-MT\nwith adapters yields comparable translation performance to fine-tuning on\nin-domain test sets, while achieving better performance on out-of-domain test\nsets; (2) Fine-tuning significantly outperforms $k$NN-MT on the recall of\nin-domain low-frequency words, but this gap could be bridged by optimizing the\ncontext representations with additional adapter layers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruize Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yichao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpokenWOZ: A Large-Scale Speech-Text Benchmark for Spoken Task-Oriented Dialogue Agents. (arXiv:2305.13040v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13040","description":"<p>Task-oriented dialogue (TOD) models have made significant progress in recent\nyears. However, previous studies primarily focus on datasets written by\nannotators, which has resulted in a gap between academic research and\nreal-world spoken conversation scenarios. While several small-scale spoken TOD\ndatasets are proposed to address robustness issues such as ASR errors, they\nignore the unique challenges in spoken conversation. To tackle the limitations,\nwe introduce SpokenWOZ, a large-scale speech-text dataset for spoken TOD,\ncontaining 8 domains, 203k turns, 5.7k dialogues and 249 hours of audios from\nhuman-to-human spoken conversations. SpokenWOZ further incorporates common\nspoken characteristics such as word-by-word processing and reasoning in spoken\nlanguage. Based on these characteristics, we present cross-turn slot and\nreasoning slot detection as new challenges. We conduct experiments on various\nbaselines, including text-modal models, newly proposed dual-modal models, and\nLLMs, e.g., ChatGPT. The results show that the current models still have\nsubstantial room for improvement in spoken conversation, where the most\nadvanced dialogue state tracker only achieves 25.65% in joint goal accuracy and\nthe SOTA end-to-end model only correctly completes the user request in 52.1% of\ndialogues. The dataset, code, and leaderboard are available:\nhttps://spokenwoz.github.io/SpokenWOZ-github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Shuzheng Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Wentao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Haoyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuchuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1\">Ting-En Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yinpei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hangyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongbin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints. (arXiv:2305.13245v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13245","description":"<p>Multi-query attention (MQA), which only uses a single key-value head,\ndrastically speeds up decoder inference. However, MQA can lead to quality\ndegradation, and moreover it may not be desirable to train a separate model\njust for faster inference. We (1) propose a recipe for uptraining existing\nmulti-head language model checkpoints into models with MQA using 5% of original\npre-training compute, and (2) introduce grouped-query attention (GQA), a\ngeneralization of multi-query attention which uses an intermediate (more than\none, less than number of query heads) number of key-value heads. We show that\nuptrained GQA achieves quality close to multi-head attention with comparable\nspeed to MQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Thorp_J/0/1/0/all/0/1\">James Lee-Thorp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1\">Michiel de Jong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zemlyanskiy_Y/0/1/0/all/0/1\">Yury Zemlyanskiy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lebron_F/0/1/0/all/0/1\">Federico Lebr&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanghai_S/0/1/0/all/0/1\">Sumit Sanghai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructAlign: High-and-Low Resource Language Alignment via Continual Crosslingual Instruction Tuning. (arXiv:2305.13627v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13627","description":"<p>Large language models (LLMs) that are tuned with instructions have\ndemonstrated remarkable capabilities in various tasks and languages. However,\ntheir ability to generalize to underrepresented languages is limited due to the\nscarcity of available data. Additionally, directly adapting new languages to\ninstruction-tuned LLMs can result in catastrophic forgetting, which leads to\nthe loss of multitasking ability. To address this issue, we propose\nInstructAlign which uses continual crosslingual instruction tuning to enable\nLLMs to align new unseen languages with previously learned high-resource\nlanguages. Our results demonstrate the effectiveness of InstructAlign in\nenabling the model to understand low-resource languages with limited parallel\ndata while preventing catastrophic forgetting. Our work contributes to the\nadvancement of language adaptation methods, particularly for adapting\ninstruction-tuned LLMs to underrepresented languages. Our code is released on\nhttps://github.com/HLTCHKUST/InstructAlign\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Compositional Data Augmentation in Typologically Diverse Morphological Inflection. (arXiv:2305.13658v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13658","description":"<p>Data augmentation techniques are widely used in low-resource automatic\nmorphological inflection to overcome data sparsity. However, the full\nimplications of these techniques remain poorly understood. In this study, we\naim to shed light on the theoretical aspects of the prominent data augmentation\nstrategy StemCorrupt (Silfverberg et al., 2017; Anastasopoulos and Neubig,\n2019), a method that generates synthetic examples by randomly substituting stem\ncharacters in gold standard training examples. To begin, we conduct an\ninformation-theoretic analysis, arguing that StemCorrupt improves compositional\ngeneralization by eliminating spurious correlations between morphemes,\nspecifically between the stem and the affixes. Our theoretical analysis further\nleads us to study the sample efficiency with which StemCorrupt reduces these\nspurious correlations. Through evaluation across seven typologically distinct\nlanguages, we demonstrate that selecting a subset of datapoints with both high\ndiversity and high predictive uncertainty significantly enhances the\ndata-efficiency of StemCorrupt. However, we also explore the impact of\ntypological features on the choice of the data selection strategy and find that\nlanguages incorporating a high degree of allomorphy and phonological\nalternations derive less benefit from synthetic examples with high uncertainty.\nWe attribute this effect to phonotactic violations induced by StemCorrupt,\nemphasizing the need for further research to ensure optimal performance across\nthe entire spectrum of natural language morphology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Samir_F/0/1/0/all/0/1\">Farhan Samir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silfverberg_M/0/1/0/all/0/1\">Miikka Silfverberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenges in Context-Aware Neural Machine Translation. (arXiv:2305.13751v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13751","description":"<p>Context-aware neural machine translation involves leveraging information\nbeyond sentence-level context to resolve inter-sentential discourse\ndependencies and improve document-level translation quality, and has given rise\nto a number of recent techniques. However, despite well-reasoned intuitions,\nmost context-aware translation models show only modest improvements over\nsentence-level systems. In this work, we investigate several challenges that\nimpede progress within this field, relating to discourse phenomena, context\nusage, model architectures, and document-level evaluation. To address these\nproblems, we propose a more realistic setting for document-level translation,\ncalled paragraph-to-paragraph (para2para) translation, and collect a new\ndataset of Chinese-English novels to promote future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Linghao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jacqueline He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from Mistakes via Cooperative Study Assistant for Large Language Models. (arXiv:2305.13829v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13829","description":"<p>Large language models (LLMs) have demonstrated their potential to refine\ntheir generation based on their own feedback. However, the feedback from LLM\nitself is often inaccurate, thereby limiting its benefits. In this paper, we\npropose Study Assistant for Large LAnguage Model (SALAM), a novel framework\nwith an auxiliary agent to assist the main LLM in learning from mistakes\nthrough interactive cooperation. In the gathering phase, the student assistant\nagent probes the main LLM, analyzes its errors, and collects the interaction in\na mistake memory. During the examination phase, the study assistant provides\nguidelines by retrieving relevant cases to help the main LLM anticipate and\navoid similar errors. We first investigate the effectiveness of a general study\nassistant and then customize it to provide LLM-specific guidance through\nimitation learning from successful guidance experiences. Our experiments on\nthree LLMs using two challenging frameworks demonstrate that SALAM can\nsignificantly boost LLMs by an accuracy margin of up to 6.6 on BBH and 12.6 on\nBBQ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Danqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction. (arXiv:2305.13981v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13981","description":"<p>The robustness to distribution changes ensures that NLP models can be\nsuccessfully applied in the realistic world, especially for information\nextraction tasks. However, most prior evaluation benchmarks have been devoted\nto validating pairwise matching correctness, ignoring the crucial measurement\nof robustness. In this paper, we present the first benchmark that simulates the\nevaluation of open information extraction models in the real world, where the\nsyntactic and expressive distributions under the same knowledge meaning may\ndrift variously. We design and annotate a large-scale testbed in which each\nexample is a knowledge-invariant clique that consists of sentences with\nstructured knowledge of the same meaning but with different syntactic and\nexpressive forms. By further elaborating the robustness metric, a model is\njudged to be robust if its performance is consistently accurate on the overall\ncliques. We perform experiments on typical models published in the last decade\nas well as a popular large language model, the results show that the existing\nsuccessful models exhibit a frustrating degradation, with a maximum drop of\n23.43 F1 score. Our resources and code are available at\nhttps://github.com/qijimrc/ROBUST.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ji Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuchun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kaisheng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiuding Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model. (arXiv:2305.13999v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13999","description":"<p>Large and sparse feed-forward layers (S-FFN) such as Mixture-of-Experts (MoE)\nhave proven effective in scaling up Transformers model size for\n\\textit{pretraining} large language models. By only activating part of the FFN\nparameters conditioning on input, S-FFN improves generalization performance\nwhile keeping training and inference costs (in FLOPs) fixed. In this work, we\nanalyzed two major design choices of S-FFN: the memory block (a.k.a. expert)\nsize and the memory block selection method under a general conceptual framework\nof sparse neural memory. Using this unified framework, we compare several S-FFN\narchitectures for language modeling and provide insights into their relative\nefficacy and efficiency. We found a simpler selection method --\n\\textbf{\\texttt{Avg-K}} that selects blocks through their mean aggregated\nhidden states, achieving lower perplexity in language model pretraining\ncompared to existing MoE architectures including Switch Transformer (Fedus et\nal., 2021) and HashLayer (Roller et al., 2021).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zeyu Leo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dettmers_T/0/1/0/all/0/1\">Tim Dettmers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Veselin Stoyanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Pixel Representations for Translation and Effective Cross-lingual Transfer. (arXiv:2305.14280v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14280","description":"<p>We introduce and demonstrate how to effectively train multilingual machine\ntranslation models with pixel representations. We experiment with two different\ndata settings with a variety of language and script coverage, demonstrating\nimproved performance compared to subword embeddings. We explore various\nproperties of pixel representations such as parameter sharing within and across\nscripts to better understand where they lead to positive transfer. We observe\nthat these properties not only enable seamless cross-lingual transfer to unseen\nscripts, but make pixel representations more data-efficient than alternatives\nsuch as vocabulary expansion. We hope this work contributes to more extensible\nmultilingual models for all languages and scripts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salesky_E/0/1/0/all/0/1\">Elizabeth Salesky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_N/0/1/0/all/0/1\">Neha Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1\">Matt Post</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Affordance and Situated Meaning in Image Captions: A Multimodal Analysis. (arXiv:2305.14616v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14616","description":"<p>This paper explores the grounding issue regarding multimodal semantic\nrepresentation from a computational cognitive-linguistic view. We annotate\nimages from the Flickr30k dataset with five perceptual properties: Affordance,\nPerceptual Salience, Object Number, Gaze Cueing, and Ecological Niche\nAssociation (ENA), and examine their association with textual elements in the\nimage captions. Our findings reveal that images with Gibsonian affordance show\na higher frequency of captions containing 'holding-verbs' and 'container-nouns'\ncompared to images displaying telic affordance. Perceptual Salience, Object\nNumber, and ENA are also associated with the choice of linguistic expressions.\nOur study demonstrates that comprehensive understanding of objects or events\nrequires cognitive attention, semantic nuances in language, and integration\nacross multiple modalities. We highlight the vital importance of situated\nmeaning and affordance grounding in natural language understanding, with the\npotential to advance human-like interpretation in various scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Er Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Po-Ya Angela Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_H/0/1/0/all/0/1\">Hsin-Yu Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tseng_Y/0/1/0/all/0/1\">Yu-Hsiang Tseng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_S/0/1/0/all/0/1\">Shu-Kai Hsieh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta-learning For Vision-and-language Cross-lingual Transfer. (arXiv:2305.14843v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14843","description":"<p>Current pre-trained vison-language models (PVLMs) achieve excellent\nperformance on a range of multi-modal datasets. Recent work has aimed at\nbuilding multilingual models, and a range of novel multilingual multi-modal\ndatasets have been proposed. Current PVLMs typically perform poorly on these\ndatasets when used for multi-modal zero-shot or few-shot cross-lingual\ntransfer, especially for low-resource languages. To alleviate this problem, we\npropose a novel meta-learning fine-tuning framework. Our framework makes\ncurrent PVLMs rapidly adaptive to new languages in vision-language scenarios by\ndesigning MAML in a cross-lingual multi-modal manner. Experiments show that our\nmethod boosts the performance of current state-of-the-art PVLMs in both\nzero-shot and few-shot cross-lingual transfer on a range of vision-language\nunderstanding tasks and datasets (XVNLI, xGQA, MaRVL, xFlicker&amp;Co)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanxu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_F/0/1/0/all/0/1\">Frank Keller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging GPT-4 for Automatic Translation Post-Editing. (arXiv:2305.14878v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14878","description":"<p>While Neural Machine Translation (NMT) represents the leading approach to\nMachine Translation (MT), the outputs of NMT models still require translation\npost-editing to rectify errors and enhance quality under critical settings. In\nthis work, we formalize the task of direct translation post-editing with Large\nLanguage Models (LLMs) and explore the use of GPT-4 to automatically post-edit\nNMT outputs across several language pairs. Our results demonstrate that GPT-4\nis adept at translation post-editing, producing meaningful and trustworthy\nedits to translations that help improve its general quality as well as remove\ndifferent classes of major errors in translations. In particular, human\nevaluations on assessing edit trustworthiness show that GPT-4 exhibits a large\nimprovement over the prior state-of-the-art LLM. Notably, we improve upon\nstate-of-the-art performance on WMT-22 English-Chinese, English-German,\nChinese-English and German-English language pairs using GPT-4 based\npost-editing, as evaluated by state-of-the-art MT quality metrics. However, we\nalso show that GPT-4 could produce hallucinated edits, thereby urging caution\nin its use as an expert translation post-editor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raunak_V/0/1/0/all/0/1\">Vikas Raunak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharaf_A/0/1/0/all/0/1\">Amr Sharaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiren Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_H/0/1/0/all/0/1\">Hany Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Menezes_A/0/1/0/all/0/1\">Arul Menezes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ByteSized32: A Corpus and Challenge Task for Generating Task-Specific World Models Expressed as Text Games. (arXiv:2305.14879v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14879","description":"<p>In this work, we investigate the capacity of language models to generate\nexplicit, interpretable, and interactive world models of scientific and\ncommon-sense reasoning tasks. We operationalize this as a task of generating\ntext games, expressed as hundreds of lines of Python code. To facilitate this\ntask, we introduce ByteSized32 (Code: github.com/cognitiveailab/BYTESIZED32), a\ncorpus of 32 reasoning-focused text games totaling 20k lines of Python code. We\nempirically demonstrate that GPT-4 can use these games as templates for\nsingle-shot in-context learning, successfully producing runnable games on\nunseen topics in 28% of cases. When allowed to self-reflect on program errors,\ngame runnability substantially increases to 57%. While evaluating simulation\nfidelity is labor-intensive, we introduce a suite of automated metrics to\nassess game fidelity, technical validity, adherence to task specifications, and\nwinnability, showing a high degree of agreement with expert human ratings. We\npose this as a challenge task to spur further development at the juncture of\nworld modeling and code generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruoyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Todd_G/0/1/0/all/0/1\">Graham Todd</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_E/0/1/0/all/0/1\">Eric Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Ziang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cote_M/0/1/0/all/0/1\">Marc-Alexandre C&#xf4;t&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jansen_P/0/1/0/all/0/1\">Peter Jansen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GRACE: Discriminator-Guided Chain-of-Thought Reasoning. (arXiv:2305.14934v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14934","description":"<p>In the context of multi-step reasoning, e.g., with chain-of-thought, language\nmodels (LMs) can easily assign a high likelihood to incorrect steps. As a\nresult, decoding strategies that optimize for solution likelihood often yield\nincorrect solutions. To address this issue, we propose Guiding chain-of-thought\nReAsoning with a CorrectnEss Discriminator (GRACE), a stepwise decoding\napproach that steers the decoding process towards producing correct reasoning\nsteps. GRACE employs a discriminator trained with a contrastive loss over\ncorrect and incorrect steps, which is used during decoding to score next-step\ncandidates based on their correctness. Importantly, GRACE only requires\nsampling from the LM, without the need for LM training or fine-tuning. Using\nmodels from FLAN-T5 and LLaMA families, we evaluate GRACE over four math and\ntwo symbolic reasoning tasks, where it exhibits substantial performance gains\ncompared to greedy decoding, verifiers, and self-consistency in most settings.\nWhen further combined with self-consistency, GRACE outperforms all the\nbaselines by sizeable margins. Human and LLM evaluations over GSM8K show that\nGRACE not only improves the final answer accuracy but also the correctness of\nthe intermediate reasoning. Our implementation can be accessed at\n\\url{https://github.com/mukhal/grace}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_M/0/1/0/all/0/1\">Muhammad Khalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Logeswaran_L/0/1/0/all/0/1\">Lajanugen Logeswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Moontae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Just Ask for Calibration: Strategies for Eliciting Calibrated Confidence Scores from Language Models Fine-Tuned with Human Feedback. (arXiv:2305.14975v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14975","description":"<p>A trustworthy real-world prediction system should produce well-calibrated\nconfidence scores; that is, its confidence in an answer should be indicative of\nthe likelihood that the answer is correct, enabling deferral to an expert in\ncases of low-confidence predictions. Recent studies have shown that\nunsupervised pre-training produces large language models (LMs) whose\nconditional probabilities are remarkably well-calibrated. However, the most\nwidely-used LMs are fine-tuned with reinforcement learning from human feedback\n(RLHF-LMs), and some studies have suggested that RLHF-LMs produce conditional\nprobabilities that are very poorly calibrated. In light of this perceived\nweakness, we conduct a broad evaluation of methods for extracting confidence\nscores from RLHF-LMs. For RLHF-LMs such as ChatGPT, GPT-4, and Claude, we find\nthat verbalized confidences emitted as output tokens are typically\nbetter-calibrated than the model's conditional probabilities on the TriviaQA,\nSciQ, and TruthfulQA benchmarks, often reducing the expected calibration error\nby a relative 50%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1\">Katherine Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1\">Eric Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Allan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Archit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafailov_R/0/1/0/all/0/1\">Rafael Rafailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Huaxiu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher D. Manning</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dolphin: A Challenging and Diverse Benchmark for Arabic NLG. (arXiv:2305.14989v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14989","description":"<p>We present Dolphin, a novel benchmark that addresses the need for a natural\nlanguage generation (NLG) evaluation framework dedicated to the wide collection\nof Arabic languages and varieties. The proposed benchmark encompasses a broad\nrange of 13 different NLG tasks, including dialogue generation, question\nanswering, machine translation, summarization, among others. Dolphin comprises\na substantial corpus of 40 diverse and representative public datasets across 50\ntest splits, carefully curated to reflect real-world scenarios and the\nlinguistic richness of Arabic. It sets a new standard for evaluating the\nperformance and generalization capabilities of Arabic and multilingual models,\npromising to enable researchers to push the boundaries of current\nmethodologies. We provide an extensive analysis of Dolphin, highlighting its\ndiversity and identifying gaps in current Arabic NLG research. We also offer a\npublic leaderboard that is both interactive and modular and evaluate several\nmodels on our benchmark, allowing us to set strong baselines against which\nresearchers can compare.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Shangiti_A/0/1/0/all/0/1\">Ahmed El-Shangiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The ACL OCL Corpus: Advancing Open Science in Computational Linguistics. (arXiv:2305.14996v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14996","description":"<p>We present ACL OCL, a scholarly corpus derived from the ACL Anthology to\nassist Open scientific research in the Computational Linguistics domain.\nIntegrating and enhancing the previous versions of the ACL Anthology, the ACL\nOCL contributes metadata, PDF files, citation graphs and additional structured\nfull texts with sections, figures, and links to a large knowledge resource\n(Semantic Scholar). The ACL OCL spans seven decades, containing 73K papers,\nalongside 210K figures.\n</p>\n<p>We spotlight how ACL OCL applies to observe trends in computational\nlinguistics. By detecting paper topics with a supervised neural model, we note\nthat interest in \"Syntax: Tagging, Chunking and Parsing\" is waning and \"Natural\nLanguage Generation\" is resurging. Our dataset is available from HuggingFace\n(https://huggingface.co/datasets/WINGNUS/ACL-OCL).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rohatgi_S/0/1/0/all/0/1\">Shaurya Rohatgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yanxia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aw_B/0/1/0/all/0/1\">Benjamin Aw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Unnithan_N/0/1/0/all/0/1\">Niranjana Unnithan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dior-CVAE: Pre-trained Language Models and Diffusion Priors for Variational Dialog Generation. (arXiv:2305.15025v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15025","description":"<p>Current variational dialog models have employed pre-trained language models\n(PLMs) to parameterize the likelihood and posterior distributions. However, the\nGaussian assumption made on the prior distribution is incompatible with these\ndistributions, thus restricting the diversity of generated responses. These\nmodels also suffer from posterior collapse, i.e., the decoder tends to ignore\nlatent variables and directly access information captured in the encoder\nthrough the cross-attention mechanism. In this work, we propose Dior-CVAE, a\nhierarchical conditional variational autoencoder (CVAE) with diffusion priors\nto address these challenges. We employ a diffusion model to increase the\ncomplexity of the prior distribution and its compatibility with the\ndistributions produced by a PLM. Also, we propose memory dropout to the\ncross-attention mechanism, which actively encourages the use of latent\nvariables for response generation. Overall, experiments across two commonly\nused open-domain dialog datasets show that our method can generate more diverse\nresponses without large-scale dialog pre-training. Code is available at\nhttps://github.com/UKPLab/dior-cvae.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thy Thy Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToMChallenges: A Principle-Guided Dataset and Diverse Evaluation Tasks for Exploring Theory of Mind. (arXiv:2305.15068v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15068","description":"<p>Theory of Mind (ToM), the capacity to comprehend the mental states of\ndistinct individuals, is essential for numerous practical applications. With\nthe development of large language models (LLMs), there is a heated debate about\nwhether they are able to perform ToM tasks. Previous studies have used\ndifferent tasks and prompts to test the ToM on LLMs and the results are\ninconsistent: some studies asserted these models are capable of exhibiting ToM,\nwhile others suggest the opposite. In this study, We present ToMChallenges, a\ndataset for comprehensively evaluating the Theory of Mind based on the\nSally-Anne and Smarties tests with a diverse set of tasks. In addition, we also\npropose an auto-grader to streamline the answer evaluation process. We tested\nthree models: davinci, turbo, and gpt-4. Our evaluation results and error\nanalyses show that LLMs have inconsistent behaviors across prompts and tasks.\nPerforming the ToM tasks robustly remains a challenge for the LLMs. In\naddition, our paper wants to raise awareness in evaluating the ToM in LLMs and\nwe want to invite more discussion on how to design the prompts and tasks for\nToM tasks that can better assess the LLMs' ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaomeng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Lingyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qihui Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Learning of Sentence Embeddings from Scratch. (arXiv:2305.15077v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15077","description":"<p>Contrastive learning has been the dominant approach to train state-of-the-art\nsentence embeddings. Previous studies have typically learned sentence\nembeddings either through the use of human-annotated natural language inference\n(NLI) data or via large-scale unlabeled sentences in an unsupervised manner.\nHowever, even in the case of unlabeled data, their acquisition presents\nchallenges in certain domains due to various reasons. To address these issues,\nwe present SynCSE, a contrastive learning framework that trains sentence\nembeddings with synthesized data. Specifically, we explore utilizing large\nlanguage models to synthesize the required data samples for contrastive\nlearning, including (1) producing positive and negative annotations given\nunlabeled sentences (SynCSE-partial), and (2) generating sentences along with\ntheir corresponding annotations from scratch (SynCSE-scratch). Experimental\nresults on sentence similarity and reranking tasks indicate that both\nSynCSE-partial and SynCSE-scratch greatly outperform unsupervised baselines,\nand SynCSE-partial even achieves comparable performance to the supervised\nmodels in most settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junlei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't Trust ChatGPT when Your Question is not in English: A Study of Multilingual Abilities and Types of LLMs. (arXiv:2305.16339v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16339","description":"<p>Large Language Models (LLMs) have demonstrated exceptional natural language\nunderstanding abilities and have excelled in a variety of natural language\nprocessing (NLP)tasks in recent years. Despite the fact that most LLMs are\ntrained predominantly in English, multiple studies have demonstrated their\ncomparative performance in many other languages. However, fundamental questions\npersist regarding how LLMs acquire their multi-lingual abilities and how\nperformance varies across different languages. These inquiries are crucial for\nthe study of LLMs since users and researchers often come from diverse language\nbackgrounds, potentially influencing their utilization and interpretation of\nLLMs' results. In this work, we propose a systematic way of qualifying the\nperformance disparities of LLMs under multilingual settings. We investigate the\nphenomenon of across-language generalizations in LLMs, wherein insufficient\nmulti-lingual training data leads to advanced multi-lingual capabilities. To\naccomplish this, we employ a novel back-translation-based prompting method. The\nresults show that GPT exhibits highly translating-like behaviour in\nmultilingual settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Senyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauer_B/0/1/0/all/0/1\">Bradley Hauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Ning Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondrak_G/0/1/0/all/0/1\">Grzegorz Kondrak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RADAR: Robust AI-Text Detection via Adversarial Learning. (arXiv:2307.03838v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03838","description":"<p>Recent advances in large language models (LLMs) and the intensifying\npopularity of ChatGPT-like applications have blurred the boundary of\nhigh-quality text generation between humans and machines. However, in addition\nto the anticipated revolutionary changes to our technology and society, the\ndifficulty of distinguishing LLM-generated texts (AI-text) from human-generated\ntexts poses new challenges of misuse and fairness, such as fake content\ngeneration, plagiarism, and false accusations of innocent writers. While\nexisting works show that current AI-text detectors are not robust to LLM-based\nparaphrasing, this paper aims to bridge this gap by proposing a new framework\ncalled RADAR, which jointly trains a robust AI-text detector via adversarial\nlearning. RADAR is based on adversarial training of a paraphraser and a\ndetector. The paraphraser's goal is to generate realistic content to evade\nAI-text detection. RADAR uses the feedback from the detector to update the\nparaphraser, and vice versa. Evaluated with 8 different LLMs (Pythia, Dolly\n2.0, Palmyra, Camel, GPT-J, Dolly 1.0, LLaMA, and Vicuna) across 4 datasets,\nexperimental results show that RADAR significantly outperforms existing AI-text\ndetection methods, especially when paraphrasing is in place. We also identify\nthe strong transferability of RADAR from instruction-tuned LLMs to other LLMs,\nand evaluate the improved capability of RADAR via GPT-3.5-Turbo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiaomeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pin-Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_T/0/1/0/all/0/1\">Tsung-Yi Ho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2307.13854","description":"<p>With advances in generative AI, there is now potential for autonomous agents\nto manage daily tasks via natural language commands. However, current agents\nare primarily created and tested in simplified synthetic environments, leading\nto a disconnect with real-world scenarios. In this paper, we build an\nenvironment for language-guided agents that is highly realistic and\nreproducible. Specifically, we focus on agents that perform tasks on the web,\nand create an environment with fully functional websites from four common\ndomains: e-commerce, social forum discussions, collaborative software\ndevelopment, and content management. Our environment is enriched with tools\n(e.g., a map) and external knowledge bases (e.g., user manuals) to encourage\nhuman-like task-solving. Building upon our environment, we release a set of\nbenchmark tasks focusing on evaluating the functional correctness of task\ncompletions. The tasks in our benchmark are diverse, long-horizon, and designed\nto emulate tasks that humans routinely perform on the internet. We experiment\nwith several baseline agents, integrating recent techniques such as reasoning\nbefore acting. The results demonstrate that solving complex tasks is\nchallenging: our best GPT-4-based agent only achieves an end-to-end task\nsuccess rate of 14.41%, significantly lower than the human performance of\n78.24%. These results highlight the need for further development of robust\nagents, that current state-of-the-art large language models are far from\nperfect performance in these real-life tasks, and that WebArena can be used to\nmeasure such progress.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Frank F. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1\">Robert Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Abishek Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xianyi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_T/0/1/0/all/0/1\">Tianyue Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alon_U/0/1/0/all/0/1\">Uri Alon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Baby Llama: knowledge distillation from an ensemble of teachers trained on a small dataset with no performance penalty. (arXiv:2308.02019v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.02019","description":"<p>We present our submission to the BabyLM challenge, whose goal was to improve\nthe sample efficiency of language models. We trained an ensemble consisting of\na GPT-2 and small LLaMA models on the developmentally-plausible, 10M-word\nBabyLM dataset, then distilled it into a small, 58M-parameter LLaMA model,\nwhich exceeds in performance both of its teachers as well as a similar model\ntrained without distillation. This suggests that distillation can not only\nretain the full performance of the teacher model when the latter is trained on\na sufficiently small dataset; it can exceed it, and lead to significantly\nbetter performance than direct training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Timiryasov_I/0/1/0/all/0/1\">Inar Timiryasov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tastet_J/0/1/0/all/0/1\">Jean-Loup Tastet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.02490","description":"<p>We propose MM-Vet, an evaluation benchmark that examines large multimodal\nmodels (LMMs) on complicated multimodal tasks. Recent LMMs have shown various\nintriguing abilities, such as solving math problems written on the blackboard,\nreasoning about events and celebrities in news images, and explaining visual\njokes. Rapid model advancements pose challenges to evaluation benchmark\ndevelopment. Problems include: (1) How to systematically structure and evaluate\nthe complicated multimodal tasks; (2) How to design evaluation metrics that\nwork well across question and answer types; and (3) How to give model insights\nbeyond a simple performance ranking. To this end, we present MM-Vet, designed\nbased on the insight that the intriguing ability to solve complicated tasks is\noften achieved by a generalist model being able to integrate different core\nvision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and\nexamines the 16 integrations of interest derived from the capability\ncombination. For evaluation metrics, we propose an LLM-based evaluator for\nopen-ended outputs. The evaluator enables the evaluation across different\nquestion types and answer styles, resulting in a unified scoring metric. We\nevaluate representative LMMs on MM-Vet, providing insights into the\ncapabilities of different LMM system paradigms and models. Code and data are\navailable at https://github.com/yuweihao/MM-Vet.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Weihao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties. (arXiv:2308.03051v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.03051","description":"<p>Despite the purported multilingual proficiency of instruction-finetuned large\nlanguage models (LLMs) such as ChatGPT and Bard, the linguistic inclusivity of\nthese models remains insufficiently explored. Considering this constraint, we\npresent a thorough assessment of Bard and ChatGPT (encompassing both GPT-3.5\nand GPT-4) regarding their machine translation proficiencies across ten\nvarieties of Arabic. Our evaluation covers diverse Arabic varieties such as\nClassical Arabic (CA), Modern Standard Arabic (MSA), and several country-level\ndialectal variants. Our analysis indicates that LLMs may encounter challenges\nwith dialects for which minimal public datasets exist, but on average are\nbetter translators of dialects than existing commercial systems. On CA and MSA,\ninstruction-tuned LLMs, however, trail behind commercial systems such as Google\nTranslate. Finally, we undertake a human-centric study to scrutinize the\nefficacy of the relatively recent model, Bard, in following human instructions\nduring translation tasks. Our analysis reveals a circumscribed capability of\nBard in aligning with human instructions in translation contexts. Collectively,\nour findings underscore that prevailing LLMs remain far from inclusive, with\nonly limited ability to cater for the linguistic and cultural intricacies of\ndiverse communities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kadaoui_K/0/1/0/all/0/1\">Karima Kadaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magdy_S/0/1/0/all/0/1\">Samar M. Magdy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waheed_A/0/1/0/all/0/1\">Abdul Waheed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khondaker_M/0/1/0/all/0/1\">Md Tawkat Islam Khondaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Shangiti_A/0/1/0/all/0/1\">Ahmed Oumar El-Shangiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM Self Defense: By Self Examination, LLMs Know They Are Being Tricked. (arXiv:2308.07308v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07308","description":"<p>Large language models (LLMs) are popular for high-quality text generation but\ncan produce harmful content, even when aligned with human values through\nreinforcement learning. Adversarial prompts can bypass their safety measures.\nWe propose LLM Self Defense, a simple approach to defend against these attacks\nby having an LLM screen the induced responses. Our method does not require any\nfine-tuning, input preprocessing, or iterative output generation. Instead, we\nincorporate the generated content into a pre-defined prompt and employ another\ninstance of an LLM to analyze the text and predict whether it is harmful. We\ntest LLM Self Defense on GPT 3.5 and Llama 2, two of the current most prominent\nLLMs against various types of attacks, such as forcefully inducing affirmative\nresponses to prompts and prompt engineering attacks. Notably, LLM Self Defense\nsucceeds in reducing the attack success rate to virtually 0 using both GPT 3.5\nand Llama 2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Phute_M/0/1/0/all/0/1\">Mansi Phute</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Helbling_A/0/1/0/all/0/1\">Alec Helbling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hull_M/0/1/0/all/0/1\">Matthew Hull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">ShengYun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szyller_S/0/1/0/all/0/1\">Sebastian Szyller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornelius_C/0/1/0/all/0/1\">Cory Cornelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1\">Duen Horng Chau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"nanoT5: A PyTorch Framework for Pre-training and Fine-tuning T5-style Models with Limited Resources. (arXiv:2309.02373v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02373","description":"<p>State-of-the-art language models like T5 have revolutionized the NLP\nlandscape, but their computational demands hinder a large portion of the\nresearch community. To address this challenge, we present nanoT5, a\nspecially-optimized PyTorch framework for efficient pre-training and\nfine-tuning of T5 models. Drawing on insights from optimizer differences and\nprioritizing efficiency, nanoT5 allows a T5-Base model to be pre-trained on a\nsingle GPU in just 16 hours, without any loss in performance. With the\nintroduction of this open-source framework, we hope to widen the accessibility\nto language modelling research and cater to the community's demand for more\nuser-friendly T5 (Encoder-Decoder) implementations. We make our contributions,\nincluding configurations, codebase, pre-training insights, and pre-trained\nmodels, available to the public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nawrot_P/0/1/0/all/0/1\">Piotr Nawrot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring vagueness and subjectivity in texts: from symbolic to neural VAGO. (arXiv:2309.06132v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06132","description":"<p>We present a hybrid approach to the automated measurement of vagueness and\nsubjectivity in texts. We first introduce the expert system VAGO, we illustrate\nit on a small benchmark of fact vs. opinion sentences, and then test it on the\nlarger French press corpus FreSaDa to confirm the higher prevalence of\nsubjective markers in satirical vs. regular texts. We then build a neural clone\nof VAGO, based on a BERT-like architecture, trained on the symbolic VAGO scores\nobtained on FreSaDa. Using explainability tools (LIME), we show the interest of\nthis neural version for the enrichment of the lexicons of the symbolic version,\nand for the production of versions in other languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Icard_B/0/1/0/all/0/1\">Benjamin Icard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Claveau_V/0/1/0/all/0/1\">Vincent Claveau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atemezing_G/0/1/0/all/0/1\">Ghislain Atemezing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egre_P/0/1/0/all/0/1\">Paul &#xc9;gr&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts. (arXiv:2309.07430v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07430","description":"<p>Sifting through vast textual data and summarizing key information from\nelectronic health records (EHR) imposes a substantial burden on how clinicians\nallocate their time. Although large language models (LLMs) have shown immense\npromise in natural language processing (NLP) tasks, their efficacy on a diverse\nrange of clinical summarization tasks has not yet been rigorously demonstrated.\nIn this work, we apply domain adaptation methods to eight LLMs, spanning six\ndatasets and four distinct clinical summarization tasks: radiology reports,\npatient questions, progress notes, and doctor-patient dialogue. Our thorough\nquantitative assessment reveals trade-offs between models and adaptation\nmethods in addition to instances where recent advances in LLMs may not improve\nresults. Further, in a clinical reader study with ten physicians, we show that\nsummaries from our best-adapted LLMs are preferable to human summaries in terms\nof completeness and correctness. Our ensuing qualitative analysis highlights\nchallenges faced by both LLMs and human experts. Lastly, we correlate\ntraditional quantitative NLP metrics with reader study scores to enhance our\nunderstanding of how these metrics align with physician preferences. Our\nresearch marks the first evidence of LLMs outperforming human experts in\nclinical text summarization across multiple tasks. This implies that\nintegrating LLMs into clinical workflows could alleviate documentation burden,\nempowering clinicians to focus more on personalized patient care and the\ninherently human aspects of medicine.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Veen_D/0/1/0/all/0/1\">Dave Van Veen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uden_C/0/1/0/all/0/1\">Cara Van Uden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blankemeier_L/0/1/0/all/0/1\">Louis Blankemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delbrouck_J/0/1/0/all/0/1\">Jean-Benoit Delbrouck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aali_A/0/1/0/all/0/1\">Asad Aali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bluethgen_C/0/1/0/all/0/1\">Christian Bluethgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pareek_A/0/1/0/all/0/1\">Anuj Pareek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polacin_M/0/1/0/all/0/1\">Malgorzata Polacin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_E/0/1/0/all/0/1\">Eduardo Pontes Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seehofnerova_A/0/1/0/all/0/1\">Anna Seehofnerova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohatgi_N/0/1/0/all/0/1\">Nidhi Rohatgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosamani_P/0/1/0/all/0/1\">Poonam Hosamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_W/0/1/0/all/0/1\">William Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_N/0/1/0/all/0/1\">Neera Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1\">Curtis P. Langlotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hom_J/0/1/0/all/0/1\">Jason Hom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1\">Sergios Gatidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauly_J/0/1/0/all/0/1\">John Pauly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_A/0/1/0/all/0/1\">Akshay S. Chaudhari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement. (arXiv:2309.08030v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.08030","description":"<p>Speech enhancement systems are typically trained using pairs of clean and\nnoisy speech. In audio-visual speech enhancement (AVSE), there is not as much\nground-truth clean data available; most audio-visual datasets are collected in\nreal-world environments with background noise and reverberation, hampering the\ndevelopment of AVSE. In this work, we introduce AV2Wav, a resynthesis-based\naudio-visual speech enhancement approach that can generate clean speech despite\nthe challenges of real-world training data. We obtain a subset of nearly clean\nspeech from an audio-visual corpus using a neural quality estimator, and then\ntrain a diffusion model on this subset to generate waveforms conditioned on\ncontinuous speech representations from AV-HuBERT with noise-robust training. We\nuse continuous rather than discrete representations to retain prosody and\nspeaker information. With this vocoding task alone, the model can perform\nspeech enhancement better than a masking-based baseline. We further fine-tune\nthe diffusion model on clean/noisy utterance pairs to improve the performance.\nOur approach outperforms a masking-based baseline in terms of both automatic\nmetrics and a human listening test and is close in quality to the target speech\nin the listening test. Audio samples can be found at\nhttps://home.ttic.edu/~jcchou/demo/avse/avse_demo.html.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Chou_J/0/1/0/all/0/1\">Ju-Chieh Chou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chien_C/0/1/0/all/0/1\">Chung-Ming Chien</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AnglE-optimized Text Embeddings. (arXiv:2309.12871v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12871","description":"<p>High-quality text embedding is pivotal in improving semantic textual\nsimilarity (STS) tasks, which are crucial components in Large Language Model\n(LLM) applications. However, a common challenge existing text embedding models\nface is the problem of vanishing gradients, primarily due to their reliance on\nthe cosine function in the optimization objective, which has saturation zones.\nTo address this issue, this paper proposes a novel angle-optimized text\nembedding model called AnglE. The core idea of AnglE is to introduce angle\noptimization in a complex space. This novel approach effectively mitigates the\nadverse effects of the saturation zone in the cosine function, which can impede\ngradient and hinder optimization processes. To set up a comprehensive STS\nevaluation, we experimented on existing short-text STS datasets and a newly\ncollected long-text STS dataset from GitHub Issues. Furthermore, we examine\ndomain-specific STS scenarios with limited labeled data and explore how AnglE\nworks with LLM-annotated data. Extensive experiments were conducted on various\ntasks including short-text STS, long-text STS, and domain-specific STS tasks.\nThe results show that AnglE outperforms the state-of-the-art (SOTA) STS models\nthat ignore the cosine saturation zone. These findings demonstrate the ability\nof AnglE to generate high-quality text embeddings and the usefulness of angle\noptimization in STS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unify word-level and span-level tasks: NJUNLP's Participation for the WMT2023 Quality Estimation Shared Task. (arXiv:2309.13230v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.13230","description":"<p>We introduce the submissions of the NJUNLP team to the WMT 2023 Quality\nEstimation (QE) shared task. Our team submitted predictions for the\nEnglish-German language pair on all two sub-tasks: (i) sentence- and word-level\nquality prediction; and (ii) fine-grained error span detection. This year, we\nfurther explore pseudo data methods for QE based on NJUQE framework\n(https://github.com/NJUNLP/njuqe). We generate pseudo MQM data using parallel\ndata from the WMT translation task. We pre-train the XLMR large model on pseudo\nQE data, then fine-tune it on real QE data. At both stages, we jointly learn\nsentence-level scores and word-level tags. Empirically, we conduct experiments\nto find the key hyper-parameters that improve the performance. Technically, we\npropose a simple method that covert the word-level outputs to fine-grained\nerror span results. Overall, our models achieved the best results in\nEnglish-German for both word-level and fine-grained error span detection\nsub-tasks by a considerable margin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiang Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1\">Zhejian Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_S/0/1/0/all/0/1\">Shimin Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation. (arXiv:2310.01320v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.01320","description":"<p>Recent breakthroughs in large language models (LLMs) have brought remarkable\nsuccess in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is\nthat the information processed by LLMs is consistently honest, neglecting the\npervasive deceptive or misleading information in human society and AI-generated\ncontent. This oversight makes LLMs susceptible to malicious manipulations,\npotentially resulting in detrimental outcomes. This study utilizes the\nintricate Avalon game as a testbed to explore LLMs' potential in deceptive\nenvironments. Avalon, full of misinformation and requiring sophisticated logic,\nmanifests as a \"Game-of-Thoughts\". Inspired by the efficacy of humans'\nrecursive thinking and perspective-taking in the Avalon game, we introduce a\nnovel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to\nidentify and counteract deceptive information. ReCon combines formulation and\nrefinement contemplation processes; formulation contemplation produces initial\nthoughts and speech, while refinement contemplation further polishes them.\nAdditionally, we incorporate first-order and second-order perspective\ntransitions into these processes respectively. Specifically, the first-order\nallows an LLM agent to infer others' mental states, and the second-order\ninvolves understanding how others perceive the agent's mental state. After\nintegrating ReCon with different LLMs, extensive experiment results from the\nAvalon game indicate its efficacy in aiding LLMs to discern and maneuver around\ndeceptive information without extra fine-tuning and data. Finally, we offer a\npossible explanation for the efficacy of ReCon and explore the current\nlimitations of LLMs in terms of safety, reasoning, speaking style, and format,\npotentially furnishing insights for subsequent research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shenzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zilong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_S/0/1/0/all/0/1\">Siyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qisen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1\">Andrew Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaofei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech Model. (arXiv:2310.02971v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2310.02971","description":"<p>Prompting and adapter tuning have emerged as efficient alternatives to\nfine-tuning (FT) methods. However, existing studies on speech prompting focused\non classification tasks and failed on more complex sequence generation tasks.\nBesides, adapter tuning is primarily applied with a focus on encoder-only\nself-supervised models. Our experiments show that prompting on Wav2Seq, a\nself-supervised encoder-decoder model, surpasses previous works in sequence\ngeneration tasks. It achieves a remarkable 53% relative improvement in word\nerror rate for ASR and a 27% in F1 score for slot filling. Additionally,\nprompting competes with the FT method in the low-resource scenario. Moreover,\nwe show the transferability of prompting and adapter tuning on Wav2Seq in\ncross-lingual ASR. When limited trainable parameters are involved, prompting\nand adapter tuning consistently outperform conventional FT across 7 languages.\nNotably, in the low-resource scenario, prompting consistently outperforms\nadapter tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Ming-Hsin Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lin_Y/0/1/0/all/0/1\">Yun-Ping Lin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_J/0/1/0/all/0/1\">Jing Neng Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_P/0/1/0/all/0/1\">Paul Kuo-Ming Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1\">Chien-yu Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use. (arXiv:2310.03128v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2310.03128","description":"<p>Large language models (LLMs) have garnered significant attention due to their\nimpressive natural language processing (NLP) capabilities. Recently, many\nstudies have focused on the tool utilization ability of LLMs. They primarily\ninvestigated how LLMs effectively collaborate with given specific tools.\nHowever, in scenarios where LLMs serve as intelligent agents, as seen in\napplications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate\ndecision-making processes that involve deciding whether to employ a tool and\nselecting the most suitable tool(s) from a collection of available tools to\nfulfill user requests. Therefore, in this paper, we introduce MetaTool, a\nbenchmark designed to evaluate whether LLMs have tool usage awareness and can\ncorrectly choose tools. Specifically, we create a dataset called ToolE within\nthe benchmark. This dataset contains various types of user queries in the form\nof prompts that trigger LLMs to use tools, including both single-tool and\nmulti-tool scenarios. Subsequently, we set the tasks for both tool usage\nawareness and tool selection. We define four subtasks from different\nperspectives in tool selection, including tool selection with similar choices,\ntool selection in specific scenarios, tool selection with possible reliability\nissues, and multi-tool selection. We conduct experiments involving nine popular\nLLMs and find that the majority of them still struggle to effectively select\ntools, highlighting the existing gaps between LLMs and genuine intelligent\nagents. However, through the error analysis, we found there is still\nsignificant room for improvement. Finally, we conclude with insights for tool\ndevelopers that follow ChatGPT to provide detailed descriptions that can\nenhance the tool selection performance of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiawen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chenrui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qihui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Hallucinations in Chinese Large Language Models. (arXiv:2310.03368v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03368","description":"<p>In this paper, we establish a benchmark named HalluQA (Chinese Hallucination\nQuestion-Answering) to measure the hallucination phenomenon in Chinese large\nlanguage models. HalluQA contains 450 meticulously designed adversarial\nquestions, spanning multiple domains, and takes into account Chinese historical\nculture, customs, and social phenomena. During the construction of HalluQA, we\nconsider two types of hallucinations: imitative falsehoods and factual errors,\nand we construct adversarial samples based on GLM-130B and ChatGPT. For\nevaluation, we design an automated evaluation method using GPT-4 to judge\nwhether a model output is hallucinated. We conduct extensive experiments on 24\nlarge language models, including ERNIE-Bot, Baichuan2, ChatGLM, Qwen, SparkDesk\nand etc. Out of the 24 models, 18 achieved non-hallucination rates lower than\n50%. This indicates that HalluQA is highly challenging. We analyze the primary\ntypes of hallucinations in different types of models and their causes.\nAdditionally, we discuss which types of hallucinations should be prioritized\nfor different types of models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qinyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mozhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Mianqiu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as You May Think -- Introducing AI Detectability Index. (arXiv:2310.05030v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05030","description":"<p>With the rise of prolific ChatGPT, the risk and consequences of AI-generated\ntext has increased alarmingly. To address the inevitable question of ownership\nattribution for AI-generated artifacts, the US Copyright Office released a\nstatement stating that 'If a work's traditional elements of authorship were\nproduced by a machine, the work lacks human authorship and the Office will not\nregister it'. Furthermore, both the US and the EU governments have recently\ndrafted their initial proposals regarding the regulatory framework for AI.\nGiven this cynosural spotlight on generative AI, AI-generated text detection\n(AGTD) has emerged as a topic that has already received immediate attention in\nresearch, with some initial methods having been proposed, soon followed by\nemergence of techniques to bypass detection. This paper introduces the Counter\nTuring Test (CT^2), a benchmark consisting of techniques aiming to offer a\ncomprehensive evaluation of the robustness of existing AGTD techniques. Our\nempirical findings unequivocally highlight the fragility of the proposed AGTD\nmethods under scrutiny. Amidst the extensive deliberations on policy-making for\nregulating AI development, it is of utmost importance to assess the\ndetectability of content generated by LLMs. Thus, to establish a quantifiable\nspectrum facilitating the evaluation and ranking of LLMs according to their\ndetectability levels, we propose the AI Detectability Index (ADI). We conduct a\nthorough examination of 15 contemporary LLMs, empirically demonstrating that\nlarger LLMs tend to have a higher ADI, indicating they are less detectable\ncompared to smaller LLMs. We firmly believe that ADI holds significant value as\na tool for the wider NLP community, with the potential to serve as a rubric in\nAI-related policy-making.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Megha Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonmoy_S/0/1/0/all/0/1\">S.M Towhidul Islam Tonmoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaman_S/0/1/0/all/0/1\">S M Mehedi Zaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1\">Krish Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barman_N/0/1/0/all/0/1\">Niyar R Barman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Chandan Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gautam_S/0/1/0/all/0/1\">Shreya Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_T/0/1/0/all/0/1\">Tanay Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit P. Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis. (arXiv:2310.05374v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05374","description":"<p>Training a high performance end-to-end speech (E2E) processing model requires\nan enormous amount of labeled speech data, especially in the era of\ndata-centric artificial intelligence. However, labeled speech data are usually\nscarcer and more expensive for collection, compared to textual data. We propose\nLatent Synthesis (LaSyn), an efficient textual data utilization framework for\nE2E speech processing models. We train a latent synthesizer to convert textual\ndata into an intermediate latent representation of a pre-trained speech model.\nThese pseudo acoustic representations of textual data augment acoustic data for\nmodel training. We evaluate LaSyn on low-resource automatic speech recognition\n(ASR) and spoken language understanding (SLU) tasks. For ASR, LaSyn improves an\nE2E baseline trained on LibriSpeech train-clean-100, with relative word error\nrate reductions over 22.3% on different test sets. For SLU, LaSyn improves our\nE2E baseline by absolute 4.1% for intent classification accuracy and 3.8% for\nslot filling SLU-F1 on SLURP, and absolute 4.49% and 2.25% for exact match (EM)\nand EM-Tree accuracies on STOP respectively. With fewer parameters, the results\nof LaSyn are competitive to published state-of-the-art works. The results\ndemonstrate the quality of the augmented training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jianqiao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1\">Nianzu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xingshan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_Y/0/1/0/all/0/1\">Yu Ting Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GROVE: A Retrieval-augmented Complex Story Generation Framework with A Forest of Evidence. (arXiv:2310.05388v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05388","description":"<p>Conditional story generation is significant in human-machine interaction,\nparticularly in producing stories with complex plots. While Large language\nmodels (LLMs) perform well on multiple NLP tasks, including story generation,\nit is challenging to generate stories with both complex and creative plots.\nExisting methods often rely on detailed prompts to guide LLMs to meet target\nconditions, which inadvertently restrict the creative potential of the\ngenerated stories. We argue that leveraging information from exemplary\nhuman-written stories facilitates generating more diverse plotlines. Delving\ndeeper into story details helps build complex and credible plots. In this\npaper, we propose a retrieval-au\\textbf{G}mented sto\\textbf{R}y generation\nframework with a f\\textbf{O}rest of e\\textbf{V}id\\textbf{E}nce (GROVE) to\nenhance stories' complexity. We build a retrieval repository for target\nconditions to produce few-shot examples to prompt LLMs. Additionally, we design\nan ``asking-why'' prompting scheme that extracts a forest of evidence,\nproviding compensation for the ambiguities that may occur in the generated\nstory. This iterative process uncovers underlying story backgrounds. Finally,\nwe select the most fitting chains of evidence from the evidence forest and\nintegrate them into the generated story, thereby enhancing the narrative's\ncomplexity and credibility. Experimental results and numerous examples verify\nthe effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zhihua Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yanqi Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A New Benchmark and Reverse Validation Method for Passage-level Hallucination Detection. (arXiv:2310.06498v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06498","description":"<p>Large Language Models (LLMs) have shown their ability to collaborate\neffectively with humans in real-world scenarios. However, LLMs are apt to\ngenerate hallucinations, i.e., makeup incorrect text and unverified\ninformation, which can cause significant damage when deployed for\nmission-critical tasks. In this paper, we propose a self-check approach based\non reverse validation to detect factual errors automatically in a zero-resource\nfashion. To facilitate future studies and assess different methods, we\nconstruct a hallucination detection benchmark named PHD, which is generated by\nChatGPT and annotated by human annotators. Contrasting previous studies of\nzero-resource hallucination detection, our method and benchmark concentrate on\npassage-level detection instead of sentence-level. We empirically evaluate our\nmethod and existing zero-resource detection methods on two datasets. The\nexperimental results demonstrate that the proposed method considerably\noutperforms the baselines while costing fewer tokens and less time.\nFurthermore, we manually analyze some hallucination cases that LLM failed to\ncapture, revealing the shared limitation of zero-resource methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shiping Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Renliang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PuoBERTa: Training and evaluation of a curated language model for Setswana. (arXiv:2310.09141v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09141","description":"<p>Natural language processing (NLP) has made significant progress for\nwell-resourced languages such as English but lagged behind for low-resource\nlanguages like Setswana. This paper addresses this gap by presenting PuoBERTa,\na customised masked language model trained specifically for Setswana. We cover\nhow we collected, curated, and prepared diverse monolingual texts to generate a\nhigh-quality corpus for PuoBERTa's training. Building upon previous efforts in\ncreating monolingual resources for Setswana, we evaluated PuoBERTa across\nseveral NLP tasks, including part-of-speech (POS) tagging, named entity\nrecognition (NER), and news categorisation. Additionally, we introduced a new\nSetswana news categorisation dataset and provided the initial benchmarks using\nPuoBERTa. Our work demonstrates the efficacy of PuoBERTa in fostering NLP\ncapabilities for understudied languages like Setswana and paves the way for\nfuture research directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1\">Vukosi Marivate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MotsOehli_M/0/1/0/all/0/1\">Moseli Mots&#x27;Oehli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_V/0/1/0/all/0/1\">Valencia Wagner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lastrucci_R/0/1/0/all/0/1\">Richard Lastrucci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dzingirai_I/0/1/0/all/0/1\">Isheanesu Dzingirai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration. (arXiv:2310.09168v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09168","description":"<p>Instruction-tuning can be substantially optimized through enhanced diversity,\nresulting in models capable of handling a broader spectrum of tasks. However,\nexisting data employed for such tuning often exhibit an inadequate coverage of\nindividual domains, limiting the scope for nuanced comprehension and\ninteractions within these areas. To address this deficiency, we propose\nExplore-Instruct, a novel approach to enhance the data coverage to be used in\ndomain-specific instruction-tuning through active exploration via Large\nLanguage Models (LLMs). Built upon representative domain use cases,\nExplore-Instruct explores a multitude of variations or possibilities by\nimplementing a search algorithm to obtain diversified and domain-focused\ninstruction-tuning data. Our data-centric analysis validates the effectiveness\nof this proposed approach in improving domain-specific instruction coverage.\nMoreover, our model's performance demonstrates considerable advancements over\nmultiple baselines, including those utilizing domain-specific data enhancement.\nOur findings offer a promising opportunity to improve instruction coverage,\nespecially in domain-specific contexts, thereby advancing the development of\nadaptable language models. Our code, model weights, and data are public at\n\\url{https://github.com/fanqiwan/Explore-Instruct}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xinting Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative Language Models. (arXiv:2310.10180v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10180","description":"<p>Automated theorem proving (ATP) has become an appealing domain for exploring\nthe reasoning ability of the recent successful generative language models.\nHowever, current ATP benchmarks mainly focus on symbolic inference, but rarely\ninvolve the understanding of complex number combination reasoning. In this\nwork, we propose TRIGO, an ATP benchmark that not only requires a model to\nreduce a trigonometric expression with step-by-step proofs but also evaluates a\ngenerative LM's reasoning ability on formulas and its capability to manipulate,\ngroup, and factor number terms. We gather trigonometric expressions and their\nreduced forms from the web, annotate the simplification process manually, and\ntranslate it into the Lean formal language system. We then automatically\ngenerate additional examples from the annotated samples to expand the dataset.\nFurthermore, we develop an automatic generator based on Lean-Gym to create\ndataset splits of varying difficulties and distributions in order to thoroughly\nanalyze the model's generalization ability. Our extensive experiments show our\nproposed TRIGO poses a new challenge for advanced generative LM's including\nGPT-4 which is pre-trained on a considerable amount of open-source formal\ntheorem-proving language data, and provide a new tool to study the generative\nLM's ability on both formal and mathematical reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jianhao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Ye Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yichun Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingxing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yinya Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chuanyang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing Weak Supervision To Generate Indonesian Conservation Dataset. (arXiv:2310.11258v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11258","description":"<p>Weak supervision has emerged as a promising approach for rapid and\nlarge-scale dataset creation in response to the increasing demand for\naccelerated NLP development. By leveraging labeling functions, weak supervision\nallows practitioners to generate datasets quickly by creating learned label\nmodels that produce soft-labeled datasets. This paper aims to show how such an\napproach can be utilized to build an Indonesian NLP dataset from conservation\nnews text. We construct two types of datasets: multi-class classification and\nsentiment classification. We then provide baseline experiments using various\npretrained language models. These baseline results demonstrate test\nperformances of 59.79% accuracy and 55.72% F1-score for sentiment\nclassification, 66.87% F1-score-macro, 71.5% F1-score-micro, and 83.67% ROC-AUC\nfor multi-class classification. Additionally, we release the datasets and\nlabeling functions used in this work for further research and exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fransiska_M/0/1/0/all/0/1\">Mega Fransiska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitaloka_D/0/1/0/all/0/1\">Diah Pitaloka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saripudin/0/1/0/all/0/1\">Saripudin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putra_S/0/1/0/all/0/1\">Satrio Putra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutawika_L/0/1/0/all/0/1\">Lintang Sutawika</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights. (arXiv:2310.11368v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11368","description":"<p>Recognizing vulnerability is crucial for understanding and implementing\ntargeted support to empower individuals in need. This is especially important\nat the European Court of Human Rights (ECtHR), where the court adapts\nConvention standards to meet actual individual needs and thus ensures effective\nhuman rights protection. However, the concept of vulnerability remains elusive\nat the ECtHR and no prior NLP research has dealt with it. To enable future\nresearch in this area, we present VECHR, a novel expert-annotated multi-label\ndataset comprising of vulnerability type classification and explanation\nrationale. We benchmark the performance of state-of-the-art models on VECHR\nfrom both prediction and explainability perspectives. Our results demonstrate\nthe challenging nature of the task with lower prediction performance and\nlimited agreement between models and experts. Further, we analyze the\nrobustness of these models in dealing with out-of-domain (OOD) data and observe\noverall limited performance. Our dataset poses unique challenges offering\nsignificant room for improvement regarding performance, explainability, and\nrobustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shanshan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staufer_L/0/1/0/all/0/1\">Leon Staufer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santosh_T/0/1/0/all/0/1\">T.Y.S.S Santosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichim_O/0/1/0/all/0/1\">Oana Ichim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heri_C/0/1/0/all/0/1\">Corina Heri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1\">Matthias Grabmair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism with Neural Networks. (arXiv:2310.11398v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11398","description":"<p>In the realm of deep learning, the self-attention mechanism has substantiated\nits pivotal role across a myriad of tasks, encompassing natural language\nprocessing and computer vision. Despite achieving success across diverse\napplications, the traditional self-attention mechanism primarily leverages\nlinear transformations for the computation of query, key, and value (QKV),\nwhich may not invariably be the optimal choice under specific circumstances.\nThis paper probes into a novel methodology for QKV computation-implementing a\nspecially-designed neural network structure for the calculation. Utilizing a\nmodified Marian model, we conducted experiments on the IWSLT 2017\nGerman-English translation task dataset and juxtaposed our method with the\nconventional approach. The experimental results unveil a significant\nenhancement in BLEU scores with our method. Furthermore, our approach also\nmanifested superiority when training the Roberta model with the Wikitext-103\ndataset, reflecting a notable reduction in model perplexity compared to its\noriginal counterpart. These experimental outcomes not only validate the\nefficacy of our method but also reveal the immense potential in optimizing the\nself-attention mechanism through neural network-based QKV computation, paving\nthe way for future research and practical applications. The source code and\nimplementation details for our proposed method can be accessed at\nhttps://github.com/ocislyjrti/NeuralAttention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muhan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification. (arXiv:2310.11878v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11878","description":"<p>In legal NLP, Case Outcome Classification (COC) must not only be accurate but\nalso trustworthy and explainable. Existing work in explainable COC has been\nlimited to annotations by a single expert. However, it is well-known that\nlawyers may disagree in their assessment of case facts. We hence collect a\nnovel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two\nexperts in the domain of international human rights law, for whom we observe\nweak agreement. We study their disagreements and build a two-level\ntask-independent taxonomy, supplemented with COC-specific subcategories. To our\nknowledge, this is the first work in the legal NLP that focuses on human label\nvariation. We quantitatively assess different taxonomy categories and find that\ndisagreements mainly stem from underspecification of the legal context, which\nposes challenges given the typically limited granularity and noise in COC\nmetadata. We further assess the explainablility of SOTA COC models on RAVE and\nobserve limited agreement between models and experts. Overall, our case study\nreveals hitherto underappreciated complexities in creating benchmark datasets\nin legal NLP that revolve around identifying aspects of a case's facts\nsupposedly relevant to its outcome.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shanshan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santosh_T/0/1/0/all/0/1\">T.Y.S.S Santosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichim_O/0/1/0/all/0/1\">Oana Ichim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risini_I/0/1/0/all/0/1\">Isabella Risini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1\">Matthias Grabmair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining. (arXiv:2310.12172v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12172","description":"<p>This paper presents an overview of the ImageArg shared task, the first\nmultimodal Argument Mining shared task co-located with the 10th Workshop on\nArgument Mining at EMNLP 2023. The shared task comprises two classification\nsubtasks - (1) Subtask-A: Argument Stance Classification; (2) Subtask-B: Image\nPersuasiveness Classification. The former determines the stance of a tweet\ncontaining an image and a piece of text toward a controversial topic (e.g., gun\ncontrol and abortion). The latter determines whether the image makes the tweet\ntext more persuasive. The shared task received 31 submissions for Subtask-A and\n21 submissions for Subtask-B from 9 different teams across 6 countries. The top\nsubmission in Subtask-A achieved an F1-score of 0.8647 while the best\nsubmission in Subtask-B achieved an F1-score of 0.5561.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhexiong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elaraby_M/0/1/0/all/0/1\">Mohamed Elaraby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litman_D/0/1/0/all/0/1\">Diane Litman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ask Language Model to Clean Your Noisy Translation Data. (arXiv:2310.13469v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13469","description":"<p>Transformer models have demonstrated remarkable performance in neural machine\ntranslation (NMT). However, their vulnerability to noisy input poses a\nsignificant challenge in practical implementation, where generating clean\noutput from noisy input is crucial. The MTNT dataset is widely used as a\nbenchmark for evaluating the robustness of NMT models against noisy input.\nNevertheless, its utility is limited due to the presence of noise in both the\nsource and target sentences. To address this limitation, we focus on cleaning\nthe noise from the target sentences in MTNT, making it more suitable as a\nbenchmark for noise evaluation. Leveraging the capabilities of large language\nmodels (LLMs), we observe their impressive abilities in noise removal. For\nexample, they can remove emojis while considering their semantic meaning.\nAdditionally, we show that LLM can effectively rephrase slang, jargon, and\nprofanities. The resulting datasets, called C-MTNT, exhibit significantly less\nnoise in the target sentences while preserving the semantic integrity of the\noriginal sentences. Our human and GPT-4 evaluations also lead to a consistent\nconclusion that LLM performs well on this task. Lastly, experiments on C-MTNT\nshowcased its effectiveness in evaluating the robustness of NMT models,\nhighlighting the potential of advanced language models for data cleaning and\nemphasizing C-MTNT as a valuable resource.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bolding_Q/0/1/0/all/0/1\">Quinten Bolding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denis_B/0/1/0/all/0/1\">Brandon James Denis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13548","description":"<p>Reinforcement learning from human feedback (RLHF) is a popular technique for\ntraining high-quality AI assistants. However, RLHF may also encourage model\nresponses that match user beliefs over truthful responses, a behavior known as\nsycophancy. We investigate the prevalence of sycophancy in RLHF-trained models\nand whether human preference judgements are responsible. We first demonstrate\nthat five state-of-the-art AI assistants consistently exhibit sycophantic\nbehavior across four varied free-form text-generation tasks. To understand if\nhuman preferences drive this broadly observed behavior of RLHF models, we\nanalyze existing human preference data. We find that when a response matches a\nuser's views, it is more likely to be preferred. Moreover, both humans and\npreference models (PMs) prefer convincingly-written sycophantic responses over\ncorrect ones a non-negligible fraction of the time. Optimizing model outputs\nagainst PMs also sometimes sacrifices truthfulness in favor of sycophancy.\nOverall, our results indicate that sycophancy is a general behavior of RLHF\nmodels, likely driven in part by human preference judgements favoring\nsycophantic responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Mrinank Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1\">Meg Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1\">Amanda Askell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1\">Newton Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1\">Esin Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatfield_Dodds_Z/0/1/0/all/0/1\">Zac Hatfield-Dodds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnston_S/0/1/0/all/0/1\">Scott R. Johnston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kravec_S/0/1/0/all/0/1\">Shauna Kravec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1\">Timothy Maxwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1\">Sam McCandlish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ndousse_K/0/1/0/all/0/1\">Kamal Ndousse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rausch_O/0/1/0/all/0/1\">Oliver Rausch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1\">Nicholas Schiefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1\">Da Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miranda Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1\">Ethan Perez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CorefPrompt: Prompt-based Event Coreference Resolution by Measuring Event Type and Argument Compatibilities. (arXiv:2310.14512v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14512","description":"<p>Event coreference resolution (ECR) aims to group event mentions referring to\nthe same real-world event into clusters. Most previous studies adopt the\n\"encoding first, then scoring\" framework, making the coreference judgment rely\non event encoding. Furthermore, current methods struggle to leverage\nhuman-summarized ECR rules, e.g., coreferential events should have the same\nevent type, to guide the model. To address these two issues, we propose a\nprompt-based approach, CorefPrompt, to transform ECR into a cloze-style MLM\n(masked language model) task. This allows for simultaneous event modeling and\ncoreference discrimination within a single template, with a fully shared\ncontext. In addition, we introduce two auxiliary prompt tasks, event-type\ncompatibility and argument compatibility, to explicitly demonstrate the\nreasoning process of ECR, which helps the model make final predictions.\nExperimental results show that our method CorefPrompt performs well in a\nstate-of-the-art (SOTA) benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Sheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qiaoming Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Word-Level Auto-Completion in Computer-Aided Translation. (arXiv:2310.14523v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14523","description":"<p>Word-Level Auto-Completion (WLAC) plays a crucial role in Computer-Assisted\nTranslation. It aims at providing word-level auto-completion suggestions for\nhuman translators. While previous studies have primarily focused on designing\ncomplex model architectures, this paper takes a different perspective by\nrethinking the fundamental question: what kind of words are good\nauto-completions? We introduce a measurable criterion to answer this question\nand discover that existing WLAC models often fail to meet this criterion.\nBuilding upon this observation, we propose an effective approach to enhance\nWLAC performance by promoting adherence to the criterion. Notably, the proposed\napproach is general and can be applied to various encoder-based architectures.\nThrough extensive experiments, we demonstrate that our approach outperforms the\ntop-performing system submitted to the WLAC shared tasks in WMT2022, while\nutilizing significantly smaller model sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Guoping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing ChatGPT for thematic analysis: Are we ready?. (arXiv:2310.14545v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14545","description":"<p>ChatGPT is an advanced natural language processing tool with growing\napplications across various disciplines in medical research. Thematic analysis,\na qualitative research method to identify and interpret patterns in data, is\none application that stands to benefit from this technology. This viewpoint\nexplores the utilization of ChatGPT in three core phases of thematic analysis\nwithin a medical context: 1) direct coding of transcripts, 2) generating themes\nfrom a predefined list of codes, and 3) preprocessing quotes for manuscript\ninclusion. Additionally, we explore the potential of ChatGPT to generate\ninterview transcripts, which may be used for training purposes. We assess the\nstrengths and limitations of using ChatGPT in these roles, highlighting areas\nwhere human intervention remains necessary. Overall, we argue that ChatGPT can\nfunction as a valuable tool during analysis, enhancing the efficiency of the\nthematic analysis and offering additional insights into the qualitative data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_V/0/1/0/all/0/1\">V Vien Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lubbe_S/0/1/0/all/0/1\">Stephanie C. C. van der Lubbe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goh_L/0/1/0/all/0/1\">Lay Hoon Goh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valderas_J/0/1/0/all/0/1\">Jose M. Valderas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPRING-INX: A Multilingual Indian Language Speech Corpus by SPRING Lab, IIT Madras. (arXiv:2310.14654v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14654","description":"<p>India is home to a multitude of languages of which 22 languages are\nrecognised by the Indian Constitution as official. Building speech based\napplications for the Indian population is a difficult problem owing to limited\ndata and the number of languages and accents to accommodate. To encourage the\nlanguage technology community to build speech based applications in Indian\nlanguages, we are open sourcing SPRING-INX data which has about 2000 hours of\nlegally sourced and manually transcribed speech data for ASR system building in\nAssamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Odia, Punjabi\nand Tamil. This endeavor is by SPRING Lab , Indian Institute of Technology\nMadras and is a part of National Language Translation Mission (NLTM), funded by\nthe Indian Ministry of Electronics and Information Technology (MeitY),\nGovernment of India. We describe the data collection and data cleaning process\nalong with the data statistics in this paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+R_N/0/1/0/all/0/1\">Nithya R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_M/0/1/0/all/0/1\">Malavika S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+F_J/0/1/0/all/0/1\">Jordan F</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangwar_A/0/1/0/all/0/1\">Arjun Gangwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+J_M/0/1/0/all/0/1\">Metilda N J</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Umesh_S/0/1/0/all/0/1\">S Umesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarab_R/0/1/0/all/0/1\">Rithik Sarab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1\">Akhilesh Kumar Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_G/0/1/0/all/0/1\">Govind Divakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1\">Samudra Vijaya K</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangashetty_S/0/1/0/all/0/1\">Suryakanth V Gangashetty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on LLM-generated Text Detection: Necessity, Methods, and Future Directions. (arXiv:2310.14724v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14724","description":"<p>The powerful ability to understand, follow, and generate complex language\nemerging from large language models (LLMs) makes LLM-generated text flood many\nareas of our daily lives at an incredible speed and is widely accepted by\nhumans. As LLMs continue to expand, there is an imperative need to develop\ndetectors that can detect LLM-generated text. This is crucial to mitigate\npotential misuse of LLMs and safeguard realms like artistic expression and\nsocial networks from harmful influence of LLM-generated content. The\nLLM-generated text detection aims to discern if a piece of text was produced by\nan LLM, which is essentially a binary classification task. The detector\ntechniques have witnessed notable advancements recently, propelled by\ninnovations in watermarking techniques, zero-shot methods, fine-turning LMs\nmethods, adversarial learning methods, LLMs as detectors, and human-assisted\nmethods. In this survey, we collate recent research breakthroughs in this area\nand underscore the pressing need to bolster detector research. We also delve\ninto prevalent datasets, elucidating their limitations and developmental\nrequirements. Furthermore, we analyze various LLM-generated text detection\nparadigms, shedding light on challenges like out-of-distribution problems,\npotential attacks, and data ambiguity. Conclusively, we highlight interesting\ndirections for future research in LLM-generated text detection to advance the\nimplementation of responsible artificial intelligence (AI). Our aim with this\nsurvey is to provide a clear and comprehensive introduction for newcomers while\nalso offering seasoned researchers a valuable update in the field of\nLLM-generated text detection. The useful resources are publicly available at:\nhttps://github.com/NLP2CT/LLM-generated-Text-Detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junchao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_R/0/1/0/all/0/1\">Runzhe Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yulin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chao_L/0/1/0/all/0/1\">Lidia S. Chao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MCC-KD: Multi-CoT Consistent Knowledge Distillation. (arXiv:2310.14747v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14747","description":"<p>Large language models (LLMs) have showcased remarkable capabilities in\ncomplex reasoning through chain of thought (CoT) prompting. Recently, there has\nbeen a growing interest in transferring these reasoning abilities from LLMs to\nsmaller models. However, achieving both the diversity and consistency in\nrationales presents a challenge. In this paper, we focus on enhancing these two\naspects and propose Multi-CoT Consistent Knowledge Distillation (MCC-KD) to\nefficiently distill the reasoning capabilities. In MCC-KD, we generate multiple\nrationales for each question and enforce consistency among the corresponding\npredictions by minimizing the bidirectional KL-divergence between the answer\ndistributions. We investigate the effectiveness of MCC-KD with different model\narchitectures (LLaMA/FlanT5) and various model scales (3B/7B/11B/13B) on both\nmathematical reasoning and commonsense reasoning benchmarks. The empirical\nresults not only confirm MCC-KD's superior performance on in-distribution\ndatasets but also highlight its robust generalization ability on\nout-of-distribution datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hongzhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Air-Decoding: Attribute Distribution Reconstruction for Decoding-Time Controllable Text Generation. (arXiv:2310.14892v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14892","description":"<p>Controllable text generation (CTG) aims to generate text with desired\nattributes, and decoding-time-based methods have shown promising performance on\nthis task. However, in this paper, we identify the phenomenon of Attribute\nCollapse for the first time. It causes the fluency of generated text to rapidly\ndecrease when the control strength exceeds a critical value, rendering the text\ncompletely unusable. This limitation hinders the effectiveness of decoding\nmethods in achieving high levels of controllability. To address this problem,\nwe propose a novel lightweight decoding framework named Air-Decoding. Its main\nidea is reconstructing the attribute distributions to balance the weights\nbetween attribute words and non-attribute words to generate more fluent text.\nSpecifically, we train prefixes by prefix-tuning to obtain attribute\ndistributions. Then we design a novel attribute distribution reconstruction\nmethod to balance the obtained distributions and use the reconstructed\ndistributions to guide language models for generation, effectively avoiding the\nissue of Attribute Collapse. Experiments on multiple CTG tasks prove that our\nmethod achieves a new state-of-the-art control performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_T/0/1/0/all/0/1\">Tianqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jingxuan Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhendong Mao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta learning with language models: Challenges and opportunities in the classification of imbalanced text. (arXiv:2310.15019v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.15019","description":"<p>Detecting out of policy speech (OOPS) content is important but difficult.\nWhile machine learning is a powerful tool to tackle this challenging task, it\nis hard to break the performance ceiling due to factors like quantity and\nquality limitations on training data and inconsistencies in OOPS definition and\ndata labeling. To realize the full potential of available limited resources, we\npropose a meta learning technique (MLT) that combines individual models built\nwith different text representations. We analytically show that the resulting\ntechnique is numerically stable and produces reasonable combining weights. We\ncombine the MLT with a threshold-moving (TM) technique to further improve the\nperformance of the combined predictor on highly-imbalanced in-distribution and\nout-of-distribution datasets. We also provide computational results to show the\nstatistically significant advantages of the proposed MLT approach.\n</p>\n<p>All authors contributed equally to this work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vassilev_A/0/1/0/all/0/1\">Apostol Vassilev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Honglan Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Munawar Hasan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cultural and Linguistic Diversity Improves Visual Representations. (arXiv:2310.14356v1 [cs.CV] CROSS LISTED)","link":"http://arxiv.org/abs/2310.14356","description":"<p>Computer vision often treats perception as objective, and this assumption\ngets reflected in the way that datasets are collected and models are trained.\nFor instance, image descriptions in different languages are typically assumed\nto be translations of the same semantic content. However, work in\ncross-cultural psychology and linguistics has shown that individuals differ in\ntheir visual perception depending on their cultural background and the language\nthey speak. In this paper, we demonstrate significant differences in semantic\ncontent across languages in both dataset and model-produced captions. When data\nis multilingual as opposed to monolingual, captions have higher semantic\ncoverage on average, as measured by scene graph, embedding, and linguistic\ncomplexity. For example, multilingual captions have on average 21.8% more\nobjects, 24.5% more relations, and 27.1% more attributes than a set of\nmonolingual captions. Moreover, models trained on content from different\nlanguages perform best against test data from those languages, while those\ntrained on multilingual content perform consistently well across all evaluation\ndata compositions. Our research provides implications for how diverse modes of\nperception can improve image understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_A/0/1/0/all/0/1\">Andre Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santy_S/0/1/0/all/0/1\">Sebastin Santy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy X. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1\">Ranjay Krishna</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-24T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}