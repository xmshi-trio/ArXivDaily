{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-18T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Hybrid Quantum-Classical Machine Learning for Sentiment Analysis. (arXiv:2310.10672v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10672","description":"<p>The collaboration between quantum computing and classical machine learning\noffers potential advantages in natural language processing, particularly in the\nsentiment analysis of human emotions and opinions expressed in large-scale\ndatasets. In this work, we propose a methodology for sentiment analysis using\nhybrid quantum-classical machine learning algorithms. We investigate quantum\nkernel approaches and variational quantum circuit-based classifiers and\nintegrate them with classical dimension reduction techniques such as PCA and\nHaar wavelet transform. The proposed methodology is evaluated using two\ndistinct datasets, based on English and Bengali languages. Experimental results\nshow that after dimensionality reduction of the data, performance of the\nquantum-based hybrid algorithms were consistent and better than classical\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Masum_A/0/1/0/all/0/1\">Abu Kaisar Mohammad Masum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maurya_A/0/1/0/all/0/1\">Anshul Maurya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murthy_D/0/1/0/all/0/1\">Dhruthi Sridhar Murthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pratibha/0/1/0/all/0/1\">Pratibha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_N/0/1/0/all/0/1\">Naveed Mahmud</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Emotion-Based Synthetic Consciousness: Using LLMs to Estimate Emotion Probability Vectors. (arXiv:2310.10673v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10673","description":"<p>This paper shows how LLMs (Large Language Models) may be used to estimate a\nsummary of the emotional state associated with piece of text. The summary of\nemotional state is a dictionary of words used to describe emotion together with\nthe probability of the word appearing after a prompt comprising the original\ntext and an emotion eliciting tail. Through emotion analysis of Amazon product\nreviews we demonstrate emotion descriptors can be mapped into a PCA type space.\nIt was hoped that text descriptions of actions to improve a current text\ndescribed state could also be elicited through a tail prompt. Experiment seemed\nto indicate that this is not straightforward to make work. This failure put our\nhoped for selection of action via choosing the best predict ed outcome via\ncomparing emotional responses out of reach for the moment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sinclair_D/0/1/0/all/0/1\">David Sinclair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pye_W/0/1/0/all/0/1\">Willem Pye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Creation Of A ChatBot Based On Natural Language Proccesing For Whatsapp. (arXiv:2310.10675v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10675","description":"<p>In the era of digital transformation, customer service is of paramount\nimportance to the success of organizations, and to meet the growing demand for\nimmediate responses and personalized assistance 24 hours a day, chatbots have\nbecome a promising tool to solve these problems. Currently, there are many\ncompanies that need to provide these solutions to their customers, which\nmotivates us to study this problem and offer a suitable solution. The objective\nof this study is to develop a chatbot based on natural language processing to\nimprove customer satisfaction and improve the quality of service provided by\nthe company through WhatsApp. The solution focuses on creating a chatbot that\nefficiently and effectively handles user queries. A literature review related\nto existing chatbots has been conducted, analyzing methodological approaches,\nartificial intelligence techniques and quality attributes used in the\nimplementation of chatbots. The results found highlight that chatbots based on\nnatural language processing enable fast and accurate responses, which improves\nthe efficiency of customer service, as chatbots contribute to customer\nsatisfaction by providing accurate answers and quick solutions to their queries\nat any time. Some authors point out that artificial intelligence techniques,\nsuch as machine learning, improve the learning and adaptability of chatbots as\nuser interactions occur, so a good choice of appropriate natural language\nunderstanding technologies is essential for optimal chatbot performance. The\nresults of this study will provide a solid foundation for the design and\ndevelopment of effective chatbots for customer service, ensuring a satisfactory\nuser experience and thus meeting the needs of the organization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jonatan_V/0/1/0/all/0/1\">Valderrama Jonatan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Igor_A/0/1/0/all/0/1\">Aguilar-Alonso Igor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs as Potential Brainstorming Partners for Math and Science Problems. (arXiv:2310.10677v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10677","description":"<p>With the recent rise of widely successful deep learning models, there is\nemerging interest among professionals in various math and science communities\nto see and evaluate the state-of-the-art models' abilities to collaborate on\nfinding or solving problems that often require creativity and thus\nbrainstorming. While a significant chasm still exists between current\nhuman-machine intellectual collaborations and the resolution of complex math\nand science problems, such as the six unsolved Millennium Prize Problems, our\ninitial investigation into this matter reveals a promising step towards\nbridging the divide. This is due to the recent advancements in Large Language\nModels (LLMs). More specifically, we conduct comprehensive case studies to\nexplore both the capabilities and limitations of the current state-of-the-art\nLLM, notably GPT-4, in collective brainstorming with humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Sophia Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large language models can replicate cross-cultural differences in personality. (arXiv:2310.10679v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10679","description":"<p>We use a large-scale experiment (N=8000) to determine whether GPT-4 can\nreplicate cross-cultural differences in the Big Five, measured using the\nTen-Item Personality Inventory. We used the US and South Korea as the cultural\npair, given that prior research suggests substantial personality differences\nbetween people from these two countries. We manipulated the target of the\nsimulation (US vs. Korean), the language of the inventory (English vs. Korean),\nand the language model (GPT-4 vs. GPT-3.5). Our results show that GPT-4\nreplicated the cross-cultural differences for each factor. However, mean\nratings had an upward bias and exhibited lower variation than in the human\nsamples, as well as lower structural validity. Overall, we provide preliminary\nevidence that LLMs can aid cross-cultural psychological research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niszczota_P/0/1/0/all/0/1\">Pawe&#x142; Niszczota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janczak_M/0/1/0/all/0/1\">Mateusz Janczak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model Unlearning. (arXiv:2310.10683v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10683","description":"<p>We study how to perform unlearning, i.e. forgetting undesirable\n(mis)behaviors, on large language models (LLMs). We show at least three\nscenarios of aligning LLMs with human preferences can benefit from unlearning:\n(1) removing harmful responses, (2) erasing copyright-protected content as\nrequested, and (3) eliminating hallucinations. Unlearning, as an alignment\ntechnique, has three advantages. (1) It only requires negative (e.g. harmful)\nexamples, which are much easier and cheaper to collect (e.g. via red teaming or\nuser reporting) than positive (e.g. helpful and often human-written) examples\nrequired in RLHF (RL from human feedback). (2) It is computationally efficient.\n(3) It is especially effective when we know which training samples cause the\nmisbehavior. To the best of our knowledge, our work is among the first to\nexplore LLM unlearning. We are also among the first to formulate the settings,\ngoals, and evaluations in LLM unlearning. We show that if practitioners only\nhave limited resources, and therefore the priority is to stop generating\nundesirable outputs rather than to try to generate desirable outputs,\nunlearning is particularly appealing. Despite only having negative samples, our\nablation study shows that unlearning can still achieve better alignment\nperformance than RLHF with just 2% of its computational time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuanshun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaojun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Autonomous Tree-search Ability of Large Language Models. (arXiv:2310.10686v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10686","description":"<p>Large Language Models have excelled in remarkable reasoning capabilities with\nadvanced prompting techniques, but they fall short on tasks that require\nexploration, strategic foresight, and sequential decision-making. Recent works\npropose to utilize external programs to define search logic, such that LLMs can\nperform passive tree search to solve more challenging reasoning tasks. Though\nimpressive results have been achieved, there are several fundamental\nlimitations of these approaches. First, passive tree searches are not efficient\nas they usually require multiple rounds of LLM API calls to solve one single\nproblem. Moreover, passive search methods are not flexible since they need\ntask-specific program designs. Then a natural question arises: can we maintain\nthe tree-search capability of LLMs without the aid of external programs, and\ncan still generate responses that clearly demonstrate the process of a\ntree-structure search? To this end, we propose a new concept called autonomous\ntree-search ability of LLM, which can automatically generate a response\ncontaining search trajectories for the correct answer. Concretely, we perform\nsearch trajectories using capable LLM API via a fixed system prompt, allowing\nthem to perform autonomous tree-search (ATS) right out of the box. Experiments\non 4 puzzle games demonstrate our method can achieve huge improvements. The\nATS-BFS method outperforms the Chain of Thought approach by achieving an\naverage accuracy improvement of 33%. Compared to Tree of Thoughts, it requires\n65.6% or 47.7% less GPT-api cost to attain a comparable level of accuracy.\nMoreover, we have collected data using the ATS prompt method and fine-tuned\nLLaMA. This approach yield a greater improvement compared to the ones\nfine-tuned on CoT data. Specifically, it outperforms CoT-tuned LLaMAs by an\naverage of 40.6% and 38.5% for LLaMA2-7B and LLaMA2-13B, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1\">Zhuorui Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yikang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chuang Gan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A decoder-only foundation model for time-series forecasting. (arXiv:2310.10688v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10688","description":"<p>Motivated by recent advances in large language models for Natural Language\nProcessing (NLP), we design a time-series foundation model for forecasting\nwhose out-of-the-box zero-shot performance on a variety of public datasets\ncomes close to the accuracy of state-of-the-art supervised forecasting models\nfor each individual dataset. Our model is based on pretraining a\npatched-decoder style attention model on a large time-series corpus, and can\nwork well across different forecasting history lengths, prediction lengths and\ntemporal granularities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Abhimanyu Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_W/0/1/0/all/0/1\">Weihao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_R/0/1/0/all/0/1\">Rajat Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yichen Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for In-Context Student Modeling: Synthesizing Student's Behavior in Visual Programming from One-Shot Observation. (arXiv:2310.10690v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10690","description":"<p>Student modeling is central to many educational technologies as it enables\nthe prediction of future learning outcomes and targeted instructional\nstrategies. However, open-ended learning environments pose challenges for\naccurately modeling students due to the diverse behaviors exhibited by students\nand the absence of a well-defined set of learning skills. To approach these\nchallenges, we explore the application of Large Language Models (LLMs) for\nin-context student modeling in open-ended learning environments. We introduce a\nnovel framework, LLM-SS, that leverages LLMs for synthesizing student's\nbehavior. More concretely, given a particular student's solving attempt on a\nreference task as observation, the goal is to synthesize the student's attempt\non a target task. Our framework can be combined with different LLMs; moreover,\nwe fine-tune LLMs using domain-specific expertise to boost their understanding\nof domain background and student behaviors. We evaluate several concrete\nmethods based on LLM-SS using the StudentSyn benchmark, an existing student's\nattempt synthesis benchmark in visual programming. Experimental results show a\nsignificant improvement compared to baseline methods included in the StudentSyn\nbenchmark. Furthermore, our method using the fine-tuned Llama2-70B model\nimproves noticeably compared to using the base model and becomes on par with\nusing the state-of-the-art GPT-4 model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Manh Hung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tschiatschek_S/0/1/0/all/0/1\">Sebastian Tschiatschek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1\">Adish Singla</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation. (arXiv:2310.10698v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10698","description":"<p>Large language models (LLMs) have showcased remarkable prowess in code\ngeneration. However, automated code generation is still challenging since it\nrequires a high-level semantic mapping between natural language requirements\nand codes. Most existing LLMs-based approaches for code generation rely on\ndecoder-only causal language models often treate codes merely as plain text\ntokens, i.e., feeding the requirements as a prompt input, and outputing code as\nflat sequence of tokens, potentially missing the rich semantic features\ninherent in source code. To bridge this gap, this paper proposes the \"Semantic\nChain-of-Thought\" approach to intruduce semantic information of code, named\nSeCoT. Our motivation is that the semantic information of the source code (\\eg\ndata flow and control flow) describes more precise program execution behavior,\nintention and function. By guiding LLM consider and integrate semantic\ninformation, we can achieve a more granular understanding and representation of\ncode, enhancing code generation accuracy. Meanwhile, while traditional\ntechniques leveraging such semantic information require complex static or\ndynamic code analysis to obtain features such as data flow and control flow,\nSeCoT demonstrates that this process can be fully automated via the intrinsic\ncapabilities of LLMs (i.e., in-context learning), while being generalizable and\napplicable to challenging domains. While SeCoT can be applied with different\nLLMs, this paper focuses on the powerful GPT-style models: ChatGPT(close-source\nmodel) and WizardCoder(open-source model). The experimental study on three\npopular DL benchmarks (i.e., HumanEval, HumanEval-ET and MBPP) shows that SeCoT\ncan achieves state-of-the-art performance, greatly improving the potential for\nlarge models and code generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingwei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shanshan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yutao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xiangke Liao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Theory of Mind for Multi-Agent Collaboration via Large Language Models. (arXiv:2310.10701v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10701","description":"<p>While Large Language Models (LLMs) have demonstrated impressive\naccomplishments in both reasoning and planning, their abilities in multi-agent\ncollaborations remains largely unexplored. This study evaluates LLM-based\nagents in a multi-agent cooperative text game with Theory of Mind (ToM)\ninference tasks, comparing their performance with Multi-Agent Reinforcement\nLearning (MARL) and planning-based baselines. We observed evidence of emergent\ncollaborative behaviors and high-order Theory of Mind capabilities among\nLLM-based agents. Our results reveal limitations in LLM-based agents' planning\noptimization due to systematic failures in managing long-horizon contexts and\nhallucination about the task state. We explore the use of explicit belief state\nrepresentations to mitigate these issues, finding that it enhances task\nperformance and the accuracy of ToM inferences for LLM-based agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_Y/0/1/0/all/0/1\">Yu Quan Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stepputtis_S/0/1/0/all/0/1\">Simon Stepputtis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_J/0/1/0/all/0/1\">Joseph Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_D/0/1/0/all/0/1\">Dana Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Michael Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1\">Katia Sycara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimized Tokenization for Transcribed Error Correction. (arXiv:2310.10704v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10704","description":"<p>The challenges facing speech recognition systems, such as variations in\npronunciations, adverse audio conditions, and the scarcity of labeled data,\nemphasize the necessity for a post-processing step that corrects recurring\nerrors. Previous research has shown the advantages of employing dedicated error\ncorrection models, yet training such models requires large amounts of labeled\ndata which is not easily obtained. To overcome this limitation, synthetic\ntranscribed-like data is often utilized, however, bridging the distribution gap\nbetween transcribed errors and synthetic noise is not trivial. In this paper,\nwe demonstrate that the performance of correction models can be significantly\nincreased by training solely using synthetic data. Specifically, we empirically\nshow that: (1) synthetic data generated using the error distribution derived\nfrom a set of transcribed data outperforms the common approach of applying\nrandom perturbations; (2) applying language-specific adjustments to the\nvocabulary of a BPE tokenizer strike a balance between adapting to unseen\ndistributions and retaining knowledge of transcribed errors. We showcase the\nbenefits of these key observations, and evaluate our approach using multiple\nlanguages, speech recognition systems and prominent speech recognition\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wullach_T/0/1/0/all/0/1\">Tomer Wullach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chazan_S/0/1/0/all/0/1\">Shlomo E. Chazan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing the Power of LLMs: Evaluating Human-AI text Co-Creation through the Lens of News Headline Generation. (arXiv:2310.10706v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10706","description":"<p>To explore how humans can best leverage LLMs for writing and how interacting\nwith these models affects feelings of ownership and trust in the writing\nprocess, we compared common human-AI interaction types (e.g., guiding system,\nselecting from system outputs, post-editing outputs) in the context of\nLLM-assisted news headline generation. While LLMs alone can generate\nsatisfactory news headlines, on average, human control is needed to fix\nundesirable model outputs. Of the interaction methods, guiding and selecting\nmodel output added the most benefit with the lowest cost (in time and effort).\nFurther, AI assistance did not harm participants' perception of control\ncompared to freeform editing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zijian Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_Renner_A/0/1/0/all/0/1\">Alison Smith-Renner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tetreault_J/0/1/0/all/0/1\">Joel R. Tetreault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaimes_A/0/1/0/all/0/1\">Alejandro Jaimes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning. (arXiv:2310.10707v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10707","description":"<p>Paraphrasing of offensive content is a better alternative to content removal\nand helps improve civility in a communication environment. Supervised\nparaphrasers; however, rely heavily on large quantities of labelled data to\nhelp preserve meaning and intent. They also retain a large portion of the\noffensiveness of the original content, which raises questions on their overall\nusability. In this paper we aim to assist practitioners in developing usable\nparaphrasers by exploring In-Context Learning (ICL) with large language models\n(LLMs), i.e., using a limited number of input-label demonstration pairs to\nguide the model in generating desired outputs for specific queries. Our study\nfocuses on key factors such as -- number and order of demonstrations, exclusion\nof prompt instruction, and reduction in measured toxicity. We perform\nprincipled evaluation on three datasets, including our proposed Context-Aware\nPolite Paraphrase dataset, comprising of dialogue-style rude utterances, polite\nparaphrases, and additional dialogue context. We evaluate our approach using\ntwo closed source and one open source LLM. Our results reveal that ICL is\ncomparable to supervised methods in generation quality, while being\nqualitatively better by 25% on human evaluation and attaining lower toxicity by\n76%. Also, ICL-based paraphrasers only show a slight reduction in performance\neven with just 10% training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1\">Anirudh Som</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikka_K/0/1/0/all/0/1\">Karan Sikka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gent_H/0/1/0/all/0/1\">Helen Gent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divakaran_A/0/1/0/all/0/1\">Ajay Divakaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kathol_A/0/1/0/all/0/1\">Andreas Kathol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergyri_D/0/1/0/all/0/1\">Dimitra Vergyri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning. (arXiv:2310.10735v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10735","description":"<p>Maintaining a consistent persona is a key quality for any open domain\ndialogue system. Current state-of-the-art systems do this by training agents\nwith supervised learning or online reinforcement learning (RL). However,\nsystems trained with supervised learning often lack consistency as they are\nnever punished for uttering contradictions. Additional training with RL can\nalleviate some of these issues, however the training process is expensive.\nInstead, we propose an offline RL framework to improve the persona consistency\nof dialogue systems. Our framework allows us to combine the advantages of\nprevious methods as we can inexpensively train our model on existing data as in\nsupervised learning, while punishing and rewarding specific utterances as in\nRL. We also introduce a simple importance sampling method to reduce the\nvariance of importance weights in offline RL training which we call\nVariance-Reducing MLE-Initialized (VaRMI) importance sampling. Our automatic\nand human evaluations show that our framework improves both the persona\nconsistency and dialogue quality of a state-of-the-art social chatbot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shea_R/0/1/0/all/0/1\">Ryan Shea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards reducing hallucination in extracting information from financial reports using Large Language Models. (arXiv:2310.10760v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10760","description":"<p>For a financial analyst, the question and answer (Q\\&amp;A) segment of the\ncompany financial report is a crucial piece of information for various analysis\nand investment decisions. However, extracting valuable insights from the Q\\&amp;A\nsection has posed considerable challenges as the conventional methods such as\ndetailed reading and note-taking lack scalability and are susceptible to human\nerrors, and Optical Character Recognition (OCR) and similar techniques\nencounter difficulties in accurately processing unstructured transcript text,\noften missing subtle linguistic nuances that drive investor decisions. Here, we\ndemonstrate the utilization of Large Language Models (LLMs) to efficiently and\nrapidly extract information from earnings report transcripts while ensuring\nhigh accuracy transforming the extraction process as well as reducing\nhallucination by combining retrieval-augmented generation technique as well as\nmetadata. We evaluate the outcomes of various LLMs with and without using our\nproposed approach based on various objective metrics for evaluating Q\\&amp;A\nsystems, and empirically demonstrate superiority of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarmah_B/0/1/0/all/0/1\">Bhaskarjit Sarmah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tianjie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1\">Dhagash Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasquali_S/0/1/0/all/0/1\">Stefano Pasquali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys. (arXiv:2310.10765v1 [cs.CV])","link":"http://arxiv.org/abs/2310.10765","description":"<p>Rapid progress has been made in instruction-learning for image editing with\nnatural-language instruction, as exemplified by InstructPix2Pix. In\nbiomedicine, such methods can be applied to counterfactual image generation,\nwhich helps differentiate causal structure from spurious correlation and\nfacilitate robust image interpretation for disease progression modeling.\nHowever, generic image-editing models are ill-suited for the biomedical domain,\nand counterfactual biomedical image generation is largely underexplored. In\nthis paper, we present BiomedJourney, a novel method for counterfactual\nbiomedical image generation by instruction-learning from multimodal patient\njourneys. Given a patient with two biomedical images taken at different time\npoints, we use GPT-4 to process the corresponding imaging reports and generate\na natural language description of disease progression. The resulting triples\n(prior image, progression description, new image) are then used to train a\nlatent diffusion model for counterfactual biomedical image generation. Given\nthe relative scarcity of image time series data, we introduce a two-stage\ncurriculum that first pretrains the denoising network using the much more\nabundant single image-report pairs (with dummy prior image), and then continues\ntraining using the counterfactual triples. Experiments using the standard\nMIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive\nbattery of tests on counterfactual medical image generation, BiomedJourney\nsubstantially outperforms prior state-of-the-art methods in instruction image\nediting and medical image generation such as InstructPix2Pix and RoentGen. To\nfacilitate future study in counterfactual medical generation, we plan to\nrelease our instruction-learning code and pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1\">Matthew P. Lungren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models for Violence Inciting Text Detection in Bengali. (arXiv:2310.10781v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10781","description":"<p>This paper presents the system that we have developed while solving this\nshared task on violence inciting text detection in Bangla. We explain both the\ntraditional and the recent approaches that we have used to make our models\nlearn. Our proposed system helps to classify if the given text contains any\nthreat. We studied the impact of data augmentation when there is a limited\ndataset available. Our quantitative results show that finetuning a\nmultilingual-e5-base model performed the best in our task compared to other\ntransformer-based architectures. We obtained a macro F1 of 68.11\\% in the test\nset and our performance in this shared task is ranked at 23 in the leaderboard.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1\">Saumajit Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanda_A/0/1/0/all/0/1\">Albert Nanda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Supervised Models of Speech Infer Universal Articulatory Kinematics. (arXiv:2310.10788v1 [eess.AS])","link":"http://arxiv.org/abs/2310.10788","description":"<p>Self-Supervised Learning (SSL) based models of speech have shown remarkable\nperformance on a range of downstream tasks. These state-of-the-art models have\nremained blackboxes, but many recent studies have begun \"probing\" models like\nHuBERT, to correlate their internal representations to different aspects of\nspeech. In this paper, we show \"inference of articulatory kinematics\" as\nfundamental property of SSL models, i.e., the ability of these models to\ntransform acoustics into the causal articulatory dynamics underlying the speech\nsignal. We also show that this abstraction is largely overlapping across the\nlanguage of the data used to train the model, with preference to the language\nwith similar phonological system. Furthermore, we show that with simple affine\ntransformations, Acoustic-to-Articulatory inversion (AAI) is transferrable\nacross speakers, even across genders, languages, and dialects, showing the\ngeneralizability of this property. Together, these results shed new light on\nthe internals of SSL models that are critical to their superior performance,\nand open up new avenues into language-agnostic universal models for speech\nengineering, that are interpretable and grounded in speech science.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Cho_C/0/1/0/all/0/1\">Cheol Jun Cho</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala K. Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT. (arXiv:2310.10803v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10803","description":"<p>Data-driven unit discovery in self-supervised learning (SSL) of speech has\nembarked on a new era of spoken language processing. Yet, the discovered units\noften remain in phonetic space, limiting the utility of SSL representations.\nHere, we demonstrate that a syllabic organization emerges in learning\nsentence-level representation of speech. In particular, we adopt\n\"self-distillation\" objective to fine-tune the pretrained HuBERT with an\naggregator token that summarizes the entire sentence. Without any supervision,\nthe resulting model draws definite boundaries in speech, and the\nrepresentations across frames show salient syllabic structures. We demonstrate\nthat this emergent structure largely corresponds to the ground truth syllables.\nFurthermore, we propose a new benchmark task, Spoken Speech ABX, for evaluating\nsentence-level representation of speech. When compared to previous models, our\nmodel outperforms in both unsupervised syllable discovery and learning\nsentence-level representation. Together, we demonstrate that the\nself-distillation of HuBERT gives rise to syllabic organization without relying\non external labels or modalities, and potentially provides novel data-driven\nunits for spoken language modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_C/0/1/0/all/0/1\">Cheol Jun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Abdelrahman Mohamed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1\">Alan W Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala K. Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fake News in Sheep's Clothing: Robust Fake News Detection Against LLM-Empowered Style Attacks. (arXiv:2310.10830v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10830","description":"<p>It is commonly perceived that online fake news and reliable news exhibit\nstark differences in writing styles, such as the use of sensationalist versus\nobjective language. However, we emphasize that style-related features can also\nbe exploited for style-based attacks. Notably, the rise of powerful Large\nLanguage Models (LLMs) has enabled malicious users to mimic the style of\ntrustworthy news outlets at minimal cost. Our analysis reveals that\nLLM-camouflaged fake news content leads to substantial performance degradation\nof state-of-the-art text-based detectors (up to 38% decrease in F1 Score),\nposing a significant challenge for automated detection in online ecosystems. To\naddress this, we introduce SheepDog, a style-agnostic fake news detector robust\nto news writing styles. SheepDog achieves this adaptability through\nLLM-empowered news reframing, which customizes each article to match different\nwriting styles using style-oriented reframing prompts. By employing\nstyle-agnostic training, SheepDog enhances its resilience to stylistic\nvariations by maximizing prediction consistency across these diverse\nreframings. Furthermore, SheepDog extracts content-focused veracity\nattributions from LLMs, where the news content is evaluated against a set of\nfact-checking rationales. These attributions provide supplementary information\nand potential interpretability that assist veracity prediction. On three\nbenchmark datasets, empirical results show that SheepDog consistently yields\nsignificant improvements over competitive baselines and enhances robustness\nagainst LLM-empowered style attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiaying Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survey of Vulnerabilities in Large Language Models Revealed by Adversarial Attacks. (arXiv:2310.10844v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10844","description":"<p>Large Language Models (LLMs) are swiftly advancing in architecture and\ncapability, and as they integrate more deeply into complex systems, the urgency\nto scrutinize their security properties grows. This paper surveys research in\nthe emerging interdisciplinary field of adversarial attacks on LLMs, a subfield\nof trustworthy ML, combining the perspectives of Natural Language Processing\nand Security. Prior work has shown that even safety-aligned LLMs (via\ninstruction tuning and reinforcement learning through human feedback) can be\nsusceptible to adversarial attacks, which exploit weaknesses and mislead AI\nsystems, as evidenced by the prevalence of `jailbreak' attacks on models like\nChatGPT and Bard. In this survey, we first provide an overview of large\nlanguage models, describe their safety alignment, and categorize existing\nresearch based on various learning structures: textual-only attacks,\nmulti-modal attacks, and additional attack methods specifically targeting\ncomplex systems, such as federated learning or multi-agent systems. We also\noffer comprehensive remarks on works that focus on the fundamental sources of\nvulnerabilities and potential defenses. To make this field more accessible to\nnewcomers, we present a systematic review of existing works, a structured\ntypology of adversarial attack concepts, and additional resources, including\nslides for presentations on related topics at the 62nd Annual Meeting of the\nAssociation for Computational Linguistics (ACL'24).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shayegani_E/0/1/0/all/0/1\">Erfan Shayegani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamun_M/0/1/0/all/0/1\">Md Abdullah Al Mamun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaree_P/0/1/0/all/0/1\">Pedram Zaree</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yue Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abu_Ghazaleh_N/0/1/0/all/0/1\">Nael Abu-Ghazaleh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoTFormer: More Tokens With Attention Make Up For Less Depth. (arXiv:2310.10845v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10845","description":"<p>The race to continually develop ever larger and deeper foundational models is\nunderway. However, techniques like the Chain-of-Thought (CoT) method continue\nto play a pivotal role in achieving optimal downstream performance. In this\nwork, we establish an approximate parallel between using chain-of-thought and\nemploying a deeper transformer. Building on this insight, we introduce\nCoTFormer, a transformer variant that employs an implicit CoT-like mechanism to\nachieve capacity comparable to a deeper model. Our empirical findings\ndemonstrate the effectiveness of CoTFormers, as they significantly outperform\nlarger standard transformers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohtashami_A/0/1/0/all/0/1\">Amirkeivan Mohtashami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pagliardini_M/0/1/0/all/0/1\">Matteo Pagliardini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1\">Martin Jaggi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender Perturbation over Fairytale Texts. (arXiv:2310.10865v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10865","description":"<p>Recent studies show that traditional fairytales are rife with harmful gender\nbiases. To help mitigate these gender biases in fairytales, this work aims to\nassess learned biases of language models by evaluating their robustness against\ngender perturbations. Specifically, we focus on Question Answering (QA) tasks\nin fairytales. Using counterfactual data augmentation to the FairytaleQA\ndataset, we evaluate model robustness against swapped gender character\ninformation, and then mitigate learned biases by introducing counterfactual\ngender stereotypes during training time. We additionally introduce a novel\napproach that utilizes the massive vocabulary of language models to support\ntext genres beyond fairytales. Our experimental results suggest that models are\nsensitive to gender perturbations, with significant performance drops compared\nto the original testing set. However, when first fine-tuned on a counterfactual\ntraining dataset, models are less sensitive to the later introduced anti-gender\nstereotyped text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chance_C/0/1/0/all/0/1\">Christina Chance</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dakuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models. (arXiv:2310.10873v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10873","description":"<p>In-context learning is a promising paradigm that utilizes in-context examples\nas prompts for the predictions of large language models. These prompts are\ncrucial for achieving strong performance. However, since the prompts need to be\nsampled from a large volume of annotated examples, finding the right prompt may\nresult in high annotation costs. To address this challenge, this paper\nintroduces an influence-driven selective annotation method that aims to\nminimize annotation costs while improving the quality of in-context examples.\nThe essence of our method is to select a pivotal subset from a large-scale\nunlabeled data pool to annotate for the subsequent sampling of prompts.\nSpecifically, a directed graph is first constructed to represent unlabeled\ndata. Afterward, the influence of candidate unlabeled subsets is quantified\nwith a diffusion process. A simple yet effective greedy algorithm for unlabeled\ndata selection is lastly introduced. It iteratively selects the data if it\nprovides a maximum marginal gain with respect to quantified influence. Compared\nwith previous efforts on selective annotations, our influence-driven method\nworks in an end-to-end manner, avoids an intractable explicit balance between\ndata diversity and representativeness, and enjoys theoretical support.\nExperiments confirm the superiority of the proposed method on various\nbenchmarks, achieving better performance under lower time consumption during\nsubset selection. The project page is available at\nhttps://skzhang1.github.io/IDEAL/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaokun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xiaobo Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling-Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiale Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergent AI-Assisted Discourse: Case Study of a Second Language Writer Authoring with ChatGPT. (arXiv:2310.10903v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10903","description":"<p>The rapid proliferation of ChatGPT has incited debates regarding its impact\non human writing. Amid concerns about declining writing standards, this study\ninvestigates the role of ChatGPT in facilitating academic writing, especially\namong language learners. Using a case study approach, this study examines the\nexperiences of Kailing, a doctoral student, who integrates ChatGPT throughout\ntheir academic writing process. The study employs activity theory as a lens for\nunderstanding writing with generative AI tools and data analyzed includes\nsemi-structured interviews, writing samples, and GPT logs. Results indicate\nthat Kailing effectively collaborates with ChatGPT across various writing\nstages while preserving her distinct authorial voice and agency. This\nunderscores the potential of AI tools such as ChatGPT to enhance academic\nwriting for language learners without overshadowing individual authenticity.\nThis case study offers a critical exploration of how ChatGPT is utilized in the\nacademic writing process and the preservation of a student's authentic voice\nwhen engaging with the tool.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacob_S/0/1/0/all/0/1\">Sharin Jacob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tate_T/0/1/0/all/0/1\">Tamara Tate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warschauer_M/0/1/0/all/0/1\">Mark Warschauer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NuclearQA: A Human-Made Benchmark for Language Models for the Nuclear Domain. (arXiv:2310.10920v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10920","description":"<p>As LLMs have become increasingly popular, they have been used in almost every\nfield. But as the application for LLMs expands from generic fields to narrow,\nfocused science domains, there exists an ever-increasing gap in ways to\nevaluate their efficacy in those fields. For the benchmarks that do exist, a\nlot of them focus on questions that don't require proper understanding of the\nsubject in question. In this paper, we present NuclearQA, a human-made\nbenchmark of 100 questions to evaluate language models in the nuclear domain,\nconsisting of a varying collection of questions that have been specifically\ndesigned by experts to test the abilities of language models. We detail our\napproach and show how the mix of several types of questions makes our benchmark\nuniquely capable of evaluating models in the nuclear domain. We also present\nour own evaluation metric for assessing LLM's performances due to the\nlimitations of existing ones. Our experiments on state-of-the-art models\nsuggest that even the best LLMs perform less than satisfactorily on our\nbenchmark, demonstrating the scientific knowledge gap of existing LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Anurag Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munikoti_S/0/1/0/all/0/1\">Sai Munikoti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hellinger_A/0/1/0/all/0/1\">Aaron Hellinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1\">Sara Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagle_S/0/1/0/all/0/1\">Sridevi Wagle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horawalavithana_S/0/1/0/all/0/1\">Sameera Horawalavithana</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spatial HuBERT: Self-supervised Spatial Speech Representation Learning for a Single Talker from Multi-channel Audio. (arXiv:2310.10922v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10922","description":"<p>Self-supervised learning has been used to leverage unlabelled data, improving\naccuracy and generalisation of speech systems through the training of\nrepresentation models. While many recent works have sought to produce effective\nrepresentations across a variety of acoustic domains, languages, modalities and\neven simultaneous speakers, these studies have all been limited to\nsingle-channel audio recordings. This paper presents Spatial HuBERT, a\nself-supervised speech representation model that learns both acoustic and\nspatial information pertaining to a single speaker in a potentially noisy\nenvironment by using multi-channel audio inputs. Spatial HuBERT learns\nrepresentations that outperform state-of-the-art single-channel speech\nrepresentations on a variety of spatial downstream tasks, particularly in\nreverberant and noisy environments. We also demonstrate the utility of the\nrepresentations learned by Spatial HuBERT on a speech localisation downstream\ntask. Along with this paper, we publicly release a new dataset of 100 000\nsimulated first-order ambisonics room impulse responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_A/0/1/0/all/0/1\">Antoni Dimitriadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Siqi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethu_V/0/1/0/all/0/1\">Vidhyasaharan Sethu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_B/0/1/0/all/0/1\">Beena Ahmed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhanced Transformer Architecture for Natural Language Processing. (arXiv:2310.10930v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10930","description":"<p>Transformer is a state-of-the-art model in the field of natural language\nprocessing (NLP). Current NLP models primarily increase the number of\ntransformers to improve processing performance. However, this technique\nrequires a lot of training resources such as computing capacity. In this paper,\na novel structure of Transformer is proposed. It is featured by full layer\nnormalization, weighted residual connection, positional encoding exploiting\nreinforcement learning, and zero masked self-attention. The proposed\nTransformer model, which is called Enhanced Transformer, is validated by the\nbilingual evaluation understudy (BLEU) score obtained with the Multi30k\ntranslation dataset. As a result, the Enhanced Transformer achieves 202.96%\nhigher BLEU score as compared to the original transformer with the translation\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moon_W/0/1/0/all/0/1\">Woohyeon Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taeyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_B/0/1/0/all/0/1\">Bumgeun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Har_D/0/1/0/all/0/1\">Dongsoo Har</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intent Detection and Slot Filling for Home Assistants: Dataset and Analysis for Bangla and Sylheti. (arXiv:2310.10935v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10935","description":"<p>As voice assistants cement their place in our technologically advanced\nsociety, there remains a need to cater to the diverse linguistic landscape,\nincluding colloquial forms of low-resource languages. Our study introduces the\nfirst-ever comprehensive dataset for intent detection and slot filling in\nformal Bangla, colloquial Bangla, and Sylheti languages, totaling 984 samples\nacross 10 unique intents. Our analysis reveals the robustness of large language\nmodels for tackling downstream tasks with inadequate data. The GPT-3.5 model\nachieves an impressive F1 score of 0.94 in intent detection and 0.51 in slot\nfilling for colloquial Bangla.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sakib_F/0/1/0/all/0/1\">Fardin Ahsan Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karim_A/0/1/0/all/0/1\">A H M Rezaul Karim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Saadat Hasan Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mushfiqur Rahman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression Symptoms from Social Media Texts. (arXiv:2310.10941v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10941","description":"<p>Depression is a mental health disorder that has a profound impact on people's\nlives. Recent research suggests that signs of depression can be detected in the\nway individuals communicate, both through spoken words and written texts. In\nparticular, social media posts are a rich and convenient text source that we\nmay examine for depressive symptoms. The Beck Depression Inventory (BDI)\nQuestionnaire, which is frequently used to gauge the severity of depression, is\none instrument that can aid in this study. We can narrow our study to only\nthose symptoms since each BDI question is linked to a particular depressive\nsymptom. It's important to remember that not everyone with depression exhibits\nall symptoms at once, but rather a combination of them. Therefore, it is\nextremely useful to be able to determine if a sentence or a piece of\nuser-generated content is pertinent to a certain condition. With this in mind,\nthe eRisk 2023 Task 1 was designed to do exactly that: assess the relevance of\ndifferent sentences to the symptoms of depression as outlined in the BDI\nquestionnaire. This report is all about how our team, Mason-NLP, participated\nin this subtask, which involved identifying sentences related to different\ndepression symptoms. We used a deep learning approach that incorporated\nMentalBERT, RoBERTa, and LSTM. Despite our efforts, the evaluation results were\nlower than expected, underscoring the challenges inherent in ranking sentences\nfrom an extensive dataset about depression, which necessitates both appropriate\nmethodological choices and significant computational resources. We anticipate\nthat future iterations of this shared task will yield improved results as our\nunderstanding and techniques evolve.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sakib_F/0/1/0/all/0/1\">Fardin Ahsan Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_A/0/1/0/all/0/1\">Ahnaf Atef Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uzuner_O/0/1/0/all/0/1\">Ozlem Uzuner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TEQ: Trainable Equivalent Transformation for Quantization of LLMs. (arXiv:2310.10944v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10944","description":"<p>As large language models (LLMs) become more prevalent, there is a growing\nneed for new and improved quantization methods that can meet the\ncomputationalast layer demands of these modern architectures while maintaining\nthe accuracy. In this paper, we present TEQ, a trainable equivalent\ntransformation that preserves the FP32 precision of the model output while\ntaking advantage of low-precision quantization, especially 3 and 4 bits\nweight-only quantization. The training process is lightweight, requiring only\n1K steps and fewer than 0.1 percent of the original model's trainable\nparameters. Furthermore, the transformation does not add any computational\noverhead during inference. Our results are on-par with the state-of-the-art\n(SOTA) methods on typical LLMs. Our approach can be combined with other methods\nto achieve even better performance. The code is available at\nhttps://github.com/intel/neural-compressor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wenhua Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yiyang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_K/0/1/0/all/0/1\">Kaokao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Haihao Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A State-Vector Framework for Dataset Effects. (arXiv:2310.10955v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10955","description":"<p>The impressive success of recent deep neural network (DNN)-based systems is\nsignificantly influenced by the high-quality datasets used in training.\nHowever, the effects of the datasets, especially how they interact with each\nother, remain underexplored. We propose a state-vector framework to enable\nrigorous studies in this direction. This framework uses idealized probing test\nresults as the bases of a vector space. This framework allows us to quantify\nthe effects of both standalone and interacting datasets. We show that the\nsignificant effects of some commonly-used language understanding datasets are\ncharacteristic and are concentrated on a few linguistic dimensions.\nAdditionally, we observe some ``spill-over'' effects: the datasets could impact\nthe models along dimensions that may seem unrelated to the intended tasks. Our\nstate-vector framework paves the way for a systematic understanding of the\ndataset effects, a crucial component in responsible and robust model\ndevelopment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sahak_E/0/1/0/all/0/1\">Esmat Sahak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zining Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudzicz_F/0/1/0/all/0/1\">Frank Rudzicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Computing the optimal keyboard through a geometric analysis of the English language. (arXiv:2310.10956v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10956","description":"<p>In the context of a group project for the course COMSW4995 002 - Geometric\nData Analysis, we bring our attention to the design of fast-typing keyboards.\nLeveraging some geometric tools in an optimization framework allowed us to\npropose novel keyboard layouts that offer a faster typing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deschamps_J/0/1/0/all/0/1\">Jules Deschamps</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hubert_Q/0/1/0/all/0/1\">Quentin Hubert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryckelynck_L/0/1/0/all/0/1\">Lucas Ryckelynck</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic-Aware Contrastive Sentence Representation Learning with Large Language Models. (arXiv:2310.10962v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10962","description":"<p>Contrastive learning has been proven to be effective in learning better\nsentence representations. However, to train a contrastive learning model, large\nnumbers of labeled sentences are required to construct positive and negative\npairs explicitly, such as those in natural language inference (NLI) datasets.\nUnfortunately, acquiring sufficient high-quality labeled data can be both\ntime-consuming and resource-intensive, leading researchers to focus on\ndeveloping methods for learning unsupervised sentence representations. As there\nis no clear relationship between these unstructured randomly-sampled sentences,\nbuilding positive and negative pairs over them is tricky and problematic. To\ntackle these challenges, in this paper, we propose SemCSR, a semantic-aware\ncontrastive sentence representation framework. By leveraging the generation and\nevaluation capabilities of large language models (LLMs), we can automatically\nconstruct a high-quality NLI-style corpus without any human annotation, and\nfurther incorporate the generated sentence pairs into learning a contrastive\nsentence representation model. Extensive experiments and comprehensive analyses\ndemonstrate the effectiveness of our proposed framework for learning a better\nsentence representation with LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Liying Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaodonghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soh_D/0/1/0/all/0/1\">De Wen Soh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EXMODD: An EXplanatory Multimodal Open-Domain Dialogue dataset. (arXiv:2310.10967v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10967","description":"<p>The need for high-quality data has been a key issue hindering the research of\ndialogue tasks. Recent studies try to build datasets through manual, web\ncrawling, and large pre-trained models. However, man-made data is expensive and\ndata collected from the internet often includes generic responses, meaningless\nstatements, and toxic dialogues. Automatic data generation through large models\nis a cost-effective method, but for open-domain multimodal dialogue tasks,\nthere are still three drawbacks: 1) There is currently no open-source large\nmodel that can accept multimodal input; 2) The content generated by the model\nlacks interpretability; 3) The generated data is usually difficult to quality\ncontrol and require extensive resource to collect. To alleviate the significant\nhuman and resource expenditure in data collection, we propose a Multimodal Data\nConstruction Framework (MDCF). MDCF designs proper prompts to spur the\nlarge-scale pre-trained language model to generate well-formed and satisfactory\ncontent. Additionally, MDCF also automatically provides explanation for a given\nimage and its corresponding dialogue, which can provide a certain degree of\ninterpretability and facilitate manual follow-up quality inspection. Based on\nthis, we release an Explanatory Multimodal Open-Domain dialogue dataset\n(EXMODD). Experiments indicate a positive correlation between the model's\nability to generate accurate understandings and high-quality responses. Our\ncode and data can be found at https://github.com/poplpr/EXMODD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pinren Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Bin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kan Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instructive Dialogue Summarization with Query Aggregations. (arXiv:2310.10981v1 [cs.CL])","link":"http://arxiv.org/abs/2310.10981","description":"<p>Conventional dialogue summarization methods directly generate summaries and\ndo not consider user's specific interests. This poses challenges in cases where\nthe users are more focused on particular topics or aspects. With the\nadvancement of instruction-finetuned language models, we introduce\ninstruction-tuning to dialogues to expand the capability set of dialogue\nsummarization models. To overcome the scarcity of instructive dialogue\nsummarization data, we propose a three-step approach to synthesize high-quality\nquery-based summarization triples. This process involves summary-anchored query\ngeneration, query filtering, and query-based summary generation. By training a\nunified model called InstructDS (Instructive Dialogue Summarization) on three\nsummarization datasets with multi-purpose instructive triples, we expand the\ncapability of dialogue summarization models. We evaluate our method on four\ndatasets, including dialogue summarization and dialogue reading comprehension.\nExperimental results show that our approach outperforms the state-of-the-art\nmodels and even models with larger sizes. Additionally, our model exhibits\nhigher generalizability and faithfulness, as confirmed by human subjective\nevaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Correction Focused Language Model Training for Speech Recognition. (arXiv:2310.11003v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11003","description":"<p>Language models (LMs) have been commonly adopted to boost the performance of\nautomatic speech recognition (ASR) particularly in domain adaptation tasks.\nConventional way of LM training treats all the words in corpora equally,\nresulting in suboptimal improvements in ASR performance. In this work, we\nintroduce a novel correction focused LM training approach which aims to\nprioritize ASR fallible words. The word-level ASR fallibility score,\nrepresenting the likelihood of ASR mis-recognition, is defined and shaped as a\nprior word distribution to guide the LM training. To enable correction focused\ntraining with text-only corpora, large language models (LLMs) are employed as\nfallibility score predictors and text generators through multi-task\nfine-tuning. Experimental results for domain adaptation tasks demonstrate the\neffectiveness of our proposed method. Compared with conventional LMs,\ncorrection focused training achieves up to relatively 5.5% word error rate\n(WER) reduction in sufficient text scenarios. In insufficient text scenarios,\nLM training with LLM-generated text achieves up to relatively 13% WER\nreduction, while correction focused training further obtains up to relatively\n6% WER reduction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingyi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reading Order Matters: Information Extraction from Visually-rich Documents by Token Path Prediction. (arXiv:2310.11016v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11016","description":"<p>Recent advances in multimodal pre-trained models have significantly improved\ninformation extraction from visually-rich documents (VrDs), in which named\nentity recognition (NER) is treated as a sequence-labeling task of predicting\nthe BIO entity tags for tokens, following the typical setting of NLP. However,\nBIO-tagging scheme relies on the correct order of model inputs, which is not\nguaranteed in real-world NER on scanned VrDs where text are recognized and\narranged by OCR systems. Such reading order issue hinders the accurate marking\nof entities by BIO-tagging scheme, making it impossible for sequence-labeling\nmethods to predict correct named entities. To address the reading order issue,\nwe introduce Token Path Prediction (TPP), a simple prediction head to predict\nentity mentions as token sequences within documents. Alternative to token\nclassification, TPP models the document layout as a complete directed graph of\ntokens, and predicts token paths within the graph as entities. For better\nevaluation of VrD-NER systems, we also propose two revised benchmark datasets\nof NER on scanned documents which can reflect real-world scenarios. Experiment\nresults demonstrate the effectiveness of our method, and suggest its potential\nto be a universal solution to various information extraction tasks on\ndocuments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Ya Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Y/0/1/0/all/0/1\">Yi Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jinyang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Huijia Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Automatic Evaluation Methods based on a Decoder-based LLM for Text Generation. (arXiv:2310.11026v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11026","description":"<p>Automatic evaluation of text generation is essential for improving the\naccuracy of generation tasks. In light of the current trend towards\nincreasingly larger decoder-based language models, we investigate automatic\nevaluation methods based on such models for text generation. This paper\ncompares various methods, including tuning with encoder-based models and large\nlanguage models under equal conditions, on two different tasks, machine\ntranslation evaluation and semantic textual similarity, in two languages,\nJapanese and English. Experimental results show that compared to the tuned\nencoder-based models, the tuned decoder-based models perform poorly. The\nanalysis of the causes for this suggests that the decoder-based models focus on\nsurface word sequences and do not capture meaning. It is also revealed that\nin-context learning of very large decoder-based models such as ChatGPT makes it\ndifficult to identify fine-grained semantic differences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kasahara_T/0/1/0/all/0/1\">Tomohito Kasahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawahara_D/0/1/0/all/0/1\">Daisuke Kawahara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lyricist-Singer Entropy Affects Lyric-Lyricist Classification Performance. (arXiv:2310.11035v1 [cs.SD])","link":"http://arxiv.org/abs/2310.11035","description":"<p>Although lyrics represent an essential component of music, few music\ninformation processing studies have been conducted on the characteristics of\nlyricists. Because these characteristics may be valuable for musical\napplications, such as recommendations, they warrant further study. We\nconsidered a potential method that extracts features representing the\ncharacteristics of lyricists from lyrics. Because these features must be\nidentified prior to extraction, we focused on lyricists with easily\nidentifiable features. We believe that it is desirable for singers to perform\nunique songs that share certain characteristics specific to the singer.\nAccordingly, we hypothesized that lyricists account for the unique\ncharacteristics of the singers they write lyrics for. In other words,\nlyric-lyricist classification performance or the ease of capturing the features\nof a lyricist from the lyrics may depend on the variety of singers. In this\nstudy, we observed a relationship between lyricist-singer entropy or the\nvariety of singers associated with a single lyricist and lyric-lyricist\nclassification performance. As an example, the lyricist-singer entropy is\nminimal when the lyricist writes lyrics for only one singer. In our\nexperiments, we grouped lyricists among five groups in terms of lyricist-singer\nentropy and assessed the lyric-lyricist classification performance within each\ngroup. Consequently, the best F1 score was obtained for the group with the\nlowest lyricist-singer entropy. Our results suggest that further analyses of\nthe features contributing to lyric-lyricist classification performance on the\nlowest lyricist-singer entropy group may improve the feature extraction task\nfor lyricists.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Morita_M/0/1/0/all/0/1\">Mitsuki Morita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kikuchi_M/0/1/0/all/0/1\">Masato Kikuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozono_T/0/1/0/all/0/1\">Tadachika Ozono</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation. (arXiv:2310.11049v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11049","description":"<p>This paper describes our submission to the SemEval-2023 for Task 6 on\nLegalEval: Understanding Legal Texts. Our submission concentrated on three\nsubtasks: Legal Named Entity Recognition (L-NER) for Task-B, Legal Judgment\nPrediction (LJP) for Task-C1, and Court Judgment Prediction with Explanation\n(CJPE) for Task-C2. We conducted various experiments on these subtasks and\npresented the results in detail, including data statistics and methodology. It\nis worth noting that legal tasks, such as those tackled in this research, have\nbeen gaining importance due to the increasing need to automate legal analysis\nand support. Our team obtained competitive rankings of 15$^{th}$, 11$^{th}$,\nand 1$^{st}$ in Task-B, Task-C1, and Task-C2, respectively, as reported on the\nleaderboard.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nigam_S/0/1/0/all/0/1\">Shubham Kumar Nigam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deroy_A/0/1/0/all/0/1\">Aniket Deroy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shallum_N/0/1/0/all/0/1\">Noel Shallum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Ayush Kumar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1\">Anup Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Shubham Kumar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Saptarshi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_K/0/1/0/all/0/1\">Kripabandhu Ghosh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Denevil: Towards Deciphering and Navigating the Ethical Values of Large Language Models via Instruction Learning. (arXiv:2310.11053v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11053","description":"<p>Large Language Models (LLMs) have made unprecedented breakthroughs, yet their\nincreasing integration into everyday life might raise societal risks due to\ngenerated unethical content. Despite extensive study on specific issues like\nbias, the intrinsic values of LLMs remain largely unexplored from a moral\nphilosophy perspective. This work delves into ethical values utilizing Moral\nFoundation Theory. Moving beyond conventional discriminative evaluations with\npoor reliability, we propose DeNEVIL, a novel prompt generation algorithm\ntailored to dynamically exploit LLMs' value vulnerabilities and elicit the\nviolation of ethics in a generative manner, revealing their underlying value\ninclinations. On such a basis, we construct MoralPrompt, a high-quality dataset\ncomprising 2,397 prompts covering 500+ value principles, and then benchmark the\nintrinsic values across a spectrum of LLMs. We discovered that most models are\nessentially misaligned, necessitating further ethical value alignment. In\nresponse, we develop VILMO, an in-context alignment method that substantially\nenhances the value compliance of LLM outputs by learning to generate\nappropriate value instructions, outperforming existing competitors. Our methods\nare suitable for black-box and open-source models, offering a promising initial\nstep in studying the ethical values of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1\">Shitong Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Tun Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Ning Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System. (arXiv:2310.11069v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11069","description":"<p>Arabic is a complex language with many varieties and dialects spoken by over\n450 millions all around the world. Due to the linguistic diversity and\nvariations, it is challenging to build a robust and generalized ASR system for\nArabic. In this work, we address this gap by developing and demoing a system,\ndubbed VoxArabica, for dialect identification (DID) as well as automatic speech\nrecognition (ASR) of Arabic. We train a wide range of models such as HuBERT\n(DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR\ntasks. Our DID models are trained to identify 17 different dialects in addition\nto MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data.\nAdditionally, for the remaining dialects in ASR, we provide the option to\nchoose various models such as Whisper and MMS in a zero-shot setting. We\nintegrate these models into a single web interface with diverse features such\nas audio recording, file upload, model selection, and the option to raise flags\nfor incorrect outputs. Overall, we believe VoxArabica will be useful for a wide\nrange of audiences concerned with Arabic research. Our system is currently\nrunning at https://cdce-206-12-100-168.ngrok.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Waheed_A/0/1/0/all/0/1\">Abdul Waheed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talafha_B/0/1/0/all/0/1\">Bashar Talafha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suvellin_P/0/1/0/all/0/1\">Peter Suvellin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadney_A/0/1/0/all/0/1\">Abdelrahman Elmadney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from Red Teaming: Gender Bias Provocation and Mitigation in Large Language Models. (arXiv:2310.11079v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11079","description":"<p>Recently, researchers have made considerable improvements in dialogue systems\nwith the progress of large language models (LLMs) such as ChatGPT and GPT-4.\nThese LLM-based chatbots encode the potential biases while retaining\ndisparities that can harm humans during interactions. The traditional biases\ninvestigation methods often rely on human-written test cases. However, these\ntest cases are usually expensive and limited. In this work, we propose a\nfirst-of-its-kind method that automatically generates test cases to detect\nLLMs' potential gender bias. We apply our method to three well-known LLMs and\nfind that the generated test cases effectively identify the presence of biases.\nTo address the biases identified, we propose a mitigation strategy that uses\nthe generated test cases as demonstrations for in-context learning to\ncircumvent the need for parameter fine-tuning. The experimental results show\nthat LLMs generate fairer responses with the proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hsuan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Cheng-Chu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farn_H/0/1/0/all/0/1\">Hua Farn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shachi H Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahay_S/0/1/0/all/0/1\">Saurav Sahay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shang-Tse Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding writing style in social media with a supervised contrastively pre-trained transformer. (arXiv:2310.11081v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11081","description":"<p>Online Social Networks serve as fertile ground for harmful behavior, ranging\nfrom hate speech to the dissemination of disinformation. Malicious actors now\nhave unprecedented freedom to misbehave, leading to severe societal unrest and\ndire consequences, as exemplified by events such as the Capitol assault during\nthe US presidential election and the Antivaxx movement during the COVID-19\npandemic. Understanding online language has become more pressing than ever.\nWhile existing works predominantly focus on content analysis, we aim to shift\nthe focus towards understanding harmful behaviors by relating content to their\nrespective authors. Numerous novel approaches attempt to learn the stylistic\nfeatures of authors in texts, but many of these approaches are constrained by\nsmall datasets or sub-optimal training losses. To overcome these limitations,\nwe introduce the Style Transformer for Authorship Representations (STAR),\ntrained on a large corpus derived from public sources of 4.5 x 10^6 authored\ntexts involving 70k heterogeneous authors. Our model leverages Supervised\nContrastive Loss to teach the model to minimize the distance between texts\nauthored by the same individual. This author pretext pre-training task yields\ncompetitive performance at zero-shot with PAN challenges on attribution and\nclustering. Additionally, we attain promising results on PAN verification\nchallenges using a single dense layer, with our model serving as an embedding\nencoder. Finally, we present results from our test partition on Reddit. Using a\nsupport base of 8 documents of 512 tokens, we can discern authors from sets of\nup to 1616 authors with at least 80\\% accuracy. We share our pre-trained model\nat huggingface (https://huggingface.co/AIDA-UPM/star) and our code is available\nat (https://github.com/jahuerta92/star)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1\">Javier Huertas-Tato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1\">Alejandro Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1\">David Camacho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Few-Shot Relation Extraction via Pre-Trained Language Models. (arXiv:2310.11085v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11085","description":"<p>Relation extraction aims at inferring structured human knowledge from textual\ndocuments. State-of-the-art methods based on language models commonly have two\nlimitations: (1) they require named entities to be either given as input or\ninfer them, which introduces additional noise, and (2) they require human\nannotations of documents. As a remedy, we present a novel framework for\nin-context few-shot relation extraction via pre-trained language models. To the\nbest of our knowledge, we are the first to reformulate the relation extraction\ntask as a tailored in-context few-shot learning paradigm. Thereby, we achieve\ncrucial benefits in that we eliminate the need for both named entity\nrecognition and human annotation of documents. Unlike existing methods based on\nfine-tuning, our framework is flexible in that it can be easily updated for a\nnew set of relations without re-training. We evaluate our framework using\nDocRED, the largest publicly available dataset for document-level relation\nextraction, and demonstrate that our framework achieves state-of-the-art\nperformance. Finally, our framework allows us to identify missing annotations,\nand we thus show that our framework actually performs much better than the\noriginal labels from the development set of DocRED.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ozyurt_Y/0/1/0/all/0/1\">Yilmazcan Ozyurt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experimenting AI Technologies for Disinformation Combat: the IDMO Project. (arXiv:2310.11097v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11097","description":"<p>The Italian Digital Media Observatory (IDMO) project, part of a European\ninitiative, focuses on countering disinformation and fake news. This report\noutlines contributions from Rai-CRITS to the project, including: (i) the\ncreation of novel datasets for testing technologies (ii) development of an\nautomatic model for categorizing Pagella Politica verdicts to facilitate\nbroader analysis (iii) creation of an automatic model for recognizing textual\nentailment with exceptional accuracy on the FEVER dataset (iv) assessment using\nGPT-4 to identify textual entailmen (v) a game to raise awareness about fake\nnews at national events.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Canale_L/0/1/0/all/0/1\">Lorenzo Canale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_A/0/1/0/all/0/1\">Alberto Messina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Long-form Simultaneous Speech Translation: Thesis Proposal. (arXiv:2310.11141v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11141","description":"<p>Simultaneous speech translation (SST) aims to provide real-time translation\nof spoken language, even before the speaker finishes their sentence.\nTraditionally, SST has been addressed primarily by cascaded systems that\ndecompose the task into subtasks, including speech recognition, segmentation,\nand machine translation. However, the advent of deep learning has sparked\nsignificant interest in end-to-end (E2E) systems. Nevertheless, a major\nlimitation of most approaches to E2E SST reported in the current literature is\nthat they assume that the source speech is pre-segmented into sentences, which\nis a significant obstacle for practical, real-world applications. This thesis\nproposal addresses end-to-end simultaneous speech translation, particularly in\nthe long-form setting, i.e., without pre-segmentation. We present a survey of\nthe latest advancements in E2E SST, assess the primary obstacles in SST and its\nrelevance to long-form scenarios, and suggest approaches to tackle these\nchallenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Polak_P/0/1/0/all/0/1\">Peter Pol&#xe1;k</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Quo Vadis of the Relationship between Language and Large Language Models. (arXiv:2310.11146v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11146","description":"<p>In the field of Artificial (General) Intelligence (AI), the several recent\nadvancements in Natural language processing (NLP) activities relying on Large\nLanguage Models (LLMs) have come to encourage the adoption of LLMs as\nscientific models of language. While the terminology employed for the\ncharacterization of LLMs favors their embracing as such, it is not clear that\nthey are in a place to offer insights into the target system they seek to\nrepresent. After identifying the most important theoretical and empirical risks\nbrought about by the adoption of scientific models that lack transparency, we\ndiscuss LLMs relating them to every scientific model's fundamental components:\nthe object, the medium, the meaning and the user. We conclude that, at their\ncurrent stage of development, LLMs hardly offer any explanations for language,\nand then we provide an outlook for more informative future research directions\non this topic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Leivada_E/0/1/0/all/0/1\">Evelina Leivada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dentella_V/0/1/0/all/0/1\">Vittoria Dentella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_E/0/1/0/all/0/1\">Elliot Murphy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing the Creativity of Large Language Models: Can models produce divergent semantic association?. (arXiv:2310.11158v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11158","description":"<p>Large language models possess remarkable capacity for processing language,\nbut it remains unclear whether these models can further generate creative\ncontent. The present study aims to investigate the creative thinking of large\nlanguage models through a cognitive perspective. We utilize the divergent\nassociation task (DAT), an objective measurement of creativity that asks models\nto generate unrelated words and calculates the semantic distance between them.\nWe compare the results across different models and decoding strategies. Our\nfindings indicate that: (1) When using the greedy search strategy, GPT-4\noutperforms 96% of humans, while GPT-3.5-turbo exceeds the average human level.\n(2) Stochastic sampling and temperature scaling are effective to obtain higher\nDAT scores for models except GPT-4, but face a trade-off between creativity and\nstability. These results imply that advanced large language models have\ndivergent semantic associations, which is a fundamental process underlying\ncreativity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Honghua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nai Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing Interactive Machine Translation Systems. (arXiv:2310.11163v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11163","description":"<p>We present IMTLab, an open-source end-to-end interactive machine translation\n(IMT) system platform that enables researchers to quickly build IMT systems\nwith state-of-the-art models, perform an end-to-end evaluation, and diagnose\nthe weakness of systems. IMTLab treats the whole interactive translation\nprocess as a task-oriented dialogue with a human-in-the-loop setting, in which\nhuman interventions can be explicitly incorporated to produce high-quality,\nerror-free translations. To this end, a general communication interface is\ndesigned to support the flexible IMT architectures and user policies. Based on\nthe proposed design, we construct a simulated and real interactive environment\nto achieve end-to-end evaluation and leverage the framework to systematically\nevaluate previous IMT systems. Our simulated and manual experiments show that\nthe prefix-constrained decoding approach still gains the lowest editing cost in\nthe end-to-end evaluation, while BiTIIMT achieves comparable editing cost with\na better interactive experience.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhirui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Ruize Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yichao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gouping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ViSoBERT: A Pre-Trained Language Model for Vietnamese Social Media Text Processing. (arXiv:2310.11166v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11166","description":"<p>English and Chinese, known as resource-rich languages, have witnessed the\nstrong development of transformer-based language models for natural language\nprocessing tasks. Although Vietnam has approximately 100M people speaking\nVietnamese, several pre-trained models, e.g., PhoBERT, ViBERT, and vELECTRA,\nperformed well on general Vietnamese NLP tasks, including POS tagging and named\nentity recognition. These pre-trained language models are still limited to\nVietnamese social media tasks. In this paper, we present the first monolingual\npre-trained language model for Vietnamese social media texts, ViSoBERT, which\nis pre-trained on a large-scale corpus of high-quality and diverse Vietnamese\nsocial media texts using XLM-R architecture. Moreover, we explored our\npre-trained model on five important natural language downstream tasks on\nVietnamese social media texts: emotion recognition, hate speech detection,\nsentiment analysis, spam reviews detection, and hate speech spans detection.\nOur experiments demonstrate that ViSoBERT, with far fewer parameters, surpasses\nthe previous state-of-the-art models on multiple Vietnamese social media tasks.\nOur ViSoBERT model is\navailable\\footnote{\\url{https://huggingface.co/uitnlp/visobert}} only for\nresearch purposes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc-Nam Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_T/0/1/0/all/0/1\">Thang Chau Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Duc-Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Medical Text Simplification: Optimizing for Readability with Unlikelihood Training and Reranked Beam Search Decoding. (arXiv:2310.11191v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11191","description":"<p>Text simplification has emerged as an increasingly useful application of AI\nfor bridging the communication gap in specialized fields such as medicine,\nwhere the lexicon is often dominated by technical jargon and complex\nconstructs. Despite notable progress, methods in medical simplification\nsometimes result in the generated text having lower quality and diversity. In\nthis work, we explore ways to further improve the readability of text\nsimplification in the medical domain. We propose (1) a new unlikelihood loss\nthat encourages generation of simpler terms and (2) a reranked beam search\ndecoding method that optimizes for simplicity, which achieve better performance\non readability metrics on three datasets. This study's findings offer promising\navenues for improving text simplification in the medical field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Flores_L/0/1/0/all/0/1\">Lorenzo Jaime Yu Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kejian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chheang_S/0/1/0/all/0/1\">Sophie Chheang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Explain Themselves? A Study of LLM-Generated Self-Explanations. (arXiv:2310.11207v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11207","description":"<p>Large language models (LLMs) such as ChatGPT have demonstrated superior\nperformance on a variety of natural language processing (NLP) tasks including\nsentiment analysis, mathematical reasoning and summarization. Furthermore,\nsince these models are instruction-tuned on human conversations to produce\n\"helpful\" responses, they can and often will produce explanations along with\nthe response, which we call self-explanations. For example, when analyzing the\nsentiment of a movie review, the model may output not only the positivity of\nthe sentiment, but also an explanation (e.g., by listing the sentiment-laden\nwords such as \"fantastic\" and \"memorable\" in the review). How good are these\nautomatically generated self-explanations? In this paper, we investigate this\nquestion on the task of sentiment analysis and for feature attribution\nexplanation, one of the most commonly studied settings in the interpretability\nliterature (for pre-ChatGPT models). Specifically, we study different ways to\nelicit the self-explanations, evaluate their faithfulness on a set of\nevaluation metrics, and compare them to traditional explanation methods such as\nocclusion or LIME saliency maps. Through an extensive set of experiments, we\nfind that ChatGPT's self-explanations perform on par with traditional ones, but\nare quite different from them according to various agreement metrics, meanwhile\nbeing much cheaper to produce (as they are generated along with the\nprediction). In addition, we identified several interesting characteristics of\nthem, which prompt us to rethink many current model interpretability practices\nin the era of ChatGPT(-like) LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shiyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mamidanna_S/0/1/0/all/0/1\">Siddarth Mamidanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jangam_S/0/1/0/all/0/1\">Shreedhar Jangam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yilun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gilpin_L/0/1/0/all/0/1\">Leilani H. Gilpin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models. (arXiv:2310.11220v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11220","description":"<p>While large language models (LLMs) have made considerable advancements in\nunderstanding and generating unstructured text, their application in structured\ndata remains underexplored. Particularly, using LLMs for complex reasoning\ntasks on knowledge graphs (KGs) remains largely untouched. To address this, we\npropose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing\nKGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and\nInference, each aimed at partitioning sentences, retrieving relevant graph\ncomponents, and deriving logical conclusions, respectively. We evaluate KG-GPT\nusing KG-based fact verification and KGQA benchmarks, with the model showing\ncompetitive and robust performance, even outperforming several fully-supervised\nmodels. Our work, therefore, marks a significant step in unifying structured\nand unstructured data processing within the realm of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1\">Yeonsu Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yohan Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RealBehavior: A Framework for Faithfully Characterizing Foundation Models' Human-like Behavior Mechanisms. (arXiv:2310.11227v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11227","description":"<p>Reports of human-like behaviors in foundation models are growing, with\npsychological theories providing enduring tools to investigate these behaviors.\nHowever, current research tends to directly apply these human-oriented tools\nwithout verifying the faithfulness of their outcomes. In this paper, we\nintroduce a framework, RealBehavior, which is designed to characterize the\nhumanoid behaviors of models faithfully. Beyond simply measuring behaviors, our\nframework assesses the faithfulness of results based on reproducibility,\ninternal and external consistency, and generalizability. Our findings suggest\nthat a simple application of psychological tools cannot faithfully characterize\nall human-like behaviors. Moreover, we discuss the impacts of aligning models\nwith human and social values, arguing for the necessity of diversifying\nalignment objectives to prevent the creation of models with restricted\ncharacteristics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1\">Enyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Songyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaoran Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zichu Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jingting Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Watermarking LLMs with Weight Quantization. (arXiv:2310.11237v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11237","description":"<p>Abuse of large language models reveals high risks as large language models\nare being deployed at an astonishing speed. It is important to protect the\nmodel weights to avoid malicious usage that violates licenses of open-source\nlarge language models. This paper proposes a novel watermarking strategy that\nplants watermarks in the quantization process of large language models without\npre-defined triggers during inference. The watermark works when the model is\nused in the fp32 mode and remains hidden when the model is quantized to int8,\nin this way, the users can only inference the model without further supervised\nfine-tuning of the model. We successfully plant the watermark into open-source\nlarge language model weights including GPT-Neo and LLaMA. We hope our proposed\nmethod can provide a potential direction for protecting model weights in the\nera of large language model applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Botian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Ke Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entity Matching using Large Language Models. (arXiv:2310.11244v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11244","description":"<p>Entity Matching is the task of deciding whether two entity descriptions refer\nto the same real-world entity. Entity Matching is a central step in most data\nintegration pipelines and an enabler for many e-commerce applications which\nrequire to match products offers from different vendors. State-of-the-art\nentity matching methods often rely on pre-trained language models (PLMs) such\nas BERT or RoBERTa. Two major drawbacks of these models for entity matching are\nthat (i) the models require significant amounts of task-specific training data\nand (ii) the fine-tuned models are not robust concerning out-of-distribution\nentities. In this paper, we investigate using large language models (LLMs) for\nentity matching as a less domain-specific training data reliant and more robust\nalternative to PLM-based matchers. Our study covers hosted LLMs, such as GPT3.5\nand GPT4, as well as open source LLMs based on Llama2 which can be run locally.\nWe evaluate these models in a zero-shot scenario as well as a scenario where\ntask-specific training data is available. We compare different prompt designs\nas well as the prompt sensitivity of the models in the zero-shot scenario. We\ninvestigate (i) the selection of in-context demonstrations, (ii) the generation\nof matching rules, as well as (iii) fine-tuning GPT3.5 in the second scenario\nusing the same pool of training data across the different approaches. Our\nexperiments show that GPT4 without any task-specific training data outperforms\nfine-tuned PLMs (RoBERTa and Ditto) on three out of five benchmark datasets\nreaching F1 scores around 90%. The experiments with in-context learning and\nrule generation show that all models beside of GPT4 benefit from these\ntechniques (on average 5.9% and 2.2% F1), while GPT4 does not need such\nadditional guidance in most cases...\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peeters_R/0/1/0/all/0/1\">Ralph Peeters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizer_C/0/1/0/all/0/1\">Christian Bizer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code Completion. (arXiv:2310.11248v1 [cs.LG])","link":"http://arxiv.org/abs/2310.11248","description":"<p>Code completion models have made significant progress in recent years, yet\ncurrent popular evaluation datasets, such as HumanEval and MBPP, predominantly\nfocus on code completion tasks within a single file. This over-simplified\nsetting falls short of representing the real-world software development\nscenario where repositories span multiple files with numerous cross-file\ndependencies, and accessing and understanding cross-file context is often\nrequired to complete the code correctly.\n</p>\n<p>To fill in this gap, we propose CrossCodeEval, a diverse and multilingual\ncode completion benchmark that necessitates an in-depth cross-file contextual\nunderstanding to complete the code accurately. CrossCodeEval is built on a\ndiverse set of real-world, open-sourced, permissively-licensed repositories in\nfour popular programming languages: Python, Java, TypeScript, and C#. To create\nexamples that strictly require cross-file context for accurate completion, we\npropose a straightforward yet efficient static-analysis-based approach to\npinpoint the use of cross-file context within the current file.\n</p>\n<p>Extensive experiments on state-of-the-art code language models like CodeGen\nand StarCoder demonstrate that CrossCodeEval is extremely challenging when the\nrelevant cross-file context is absent, and we see clear improvements when\nadding these context into the prompt. However, despite such improvements, the\npinnacle of performance remains notably unattained even with the\nhighest-performing model, indicating that CrossCodeEval is also capable of\nassessing model's capability in leveraging extensive context to make better\ncode completion. Finally, we benchmarked various methods in retrieving\ncross-file context, and show that CrossCodeEval can also be used to measure the\ncapability of code retrievers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yangruibo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1\">Hantian Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Ming Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Nihal Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_M/0/1/0/all/0/1\">Murali Krishna Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallapati_R/0/1/0/all/0/1\">Ramesh Nallapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_P/0/1/0/all/0/1\">Parminder Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revealing the Unwritten: Visual Investigation of Beam Search Trees to Address Language Model Prompting Challenges. (arXiv:2310.11252v1 [cs.CL])","link":"http://arxiv.org/abs/2310.11252","description":"<p>The growing popularity of generative language models has amplified interest\nin interactive methods to guide model outputs. Prompt refinement is considered\none of the most effective means to influence output among these methods. We\nidentify several challenges associated with prompting large language models,\ncategorized into data- and model-specific, linguistic, and socio-linguistic\nchallenges. A comprehensive examination of model outputs, including runner-up\ncandidates and their corresponding probabilities, is needed to address these\nissues. The beam search tree, the prevalent algorithm to sample model outputs,\ncan inherently supply this information. Consequently, we introduce an\ninteractive visual method for investigating the beam search tree, facilitating\nanalysis of the decisions made by the model during generation. We\nquantitatively show the value of exposing the beam search tree and present five\ndetailed analysis scenarios addressing the identified challenges. Our\nmethodology validates existing results and offers additional insights.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Spinner_T/0/1/0/all/0/1\">Thilo Spinner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kehlbeck_R/0/1/0/all/0/1\">Rebecca Kehlbeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sevastjanova_R/0/1/0/all/0/1\">Rita Sevastjanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stahle_T/0/1/0/all/0/1\">Tobias St&#xe4;hle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keim_D/0/1/0/all/0/1\">Daniel A. Keim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deussen_O/0/1/0/all/0/1\">Oliver Deussen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spitz_A/0/1/0/all/0/1\">Andreas Spitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1\">Mennatallah El-Assady</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on Twitter. (arXiv:2105.01331v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.01331","description":"<p>Protection of human rights is one of the most important problems of our\nworld. In this paper, our aim is to provide a dataset which covers one of the\nmost significant human rights contradiction in recent months affected the whole\nworld, George Floyd incident. We propose a labeled dataset for topic detection\nthat contains 17 million tweets. These Tweets are collected from 25 May 2020 to\n21 August 2020 that covers 89 days from start of this incident. We labeled the\ndataset by monitoring most trending news topics from global and local\nnewspapers. Apart from that, we present two baselines, TF-IDF and LDA. We\nevaluated the results of these two methods with three different k values for\nmetrics of precision, recall and f1-score. The collected dataset is available\nat https://github.com/MeysamAsgariC/BLMT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kemik_H/0/1/0/all/0/1\">Hasan Kemik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozates_N/0/1/0/all/0/1\">Nusret &#xd6;zate&#x15f;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asgari_Chenaghlu_M/0/1/0/all/0/1\">Meysam Asgari-Chenaghlu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fake news detection using parallel BERT deep neural networks. (arXiv:2204.04793v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.04793","description":"<p>Fake news is a growing challenge for social networks and media. Detection of\nfake news always has been a problem for many years, but after the evolution of\nsocial networks and increasing speed of news dissemination in recent years has\nbeen considered again. There are several approaches to solving this problem,\none of which is to detect fake news based on its text style using deep neural\nnetworks. In recent years, one of the most used forms of deep neural networks\nfor natural language processing is transfer learning with transformers. BERT is\none of the most promising transformers who outperforms other models in many NLP\nbenchmarks. This article, we introduce MWPBert, which uses two parallel BERT\nnetworks to perform veracity detection on full-text news articles. One of the\nBERT networks encodes news headline, and another encodes news body. Since the\ninput length of the BERT network is limited and constant and the news body is\nusually a long text, we cannot fed the whole news text into the BERT.\nTherefore, using the MaxWorth algorithm, we selected the part of the news text\nthat is more valuable for fact-checking, and fed it into the BERT network.\nFinally, we encode the output of the two BERT networks to an output network to\nclassify the news. The experiment results showed that the proposed model\noutperformed previous models in terms of accuracy and other performance\nmeasures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Farokhian_M/0/1/0/all/0/1\">Mahmood Farokhian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rafe_V/0/1/0/all/0/1\">Vahid Rafe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veisi_H/0/1/0/all/0/1\">Hadi Veisi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ConvLab-3: A Flexible Dialogue System Toolkit Based on a Unified Data Format. (arXiv:2211.17148v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.17148","description":"<p>Task-oriented dialogue (TOD) systems function as digital assistants, guiding\nusers through various tasks such as booking flights or finding restaurants.\nExisting toolkits for building TOD systems often fall short of in delivering\ncomprehensive arrays of data, models, and experimental environments with a\nuser-friendly experience. We introduce ConvLab-3: a multifaceted dialogue\nsystem toolkit crafted to bridge this gap. Our unified data format simplifies\nthe integration of diverse datasets and models, significantly reducing\ncomplexity and cost for studying generalization and transfer. Enhanced with\nrobust reinforcement learning (RL) tools, featuring a streamlined training\nprocess, in-depth evaluation tools, and a selection of user simulators,\nConvLab-3 supports the rapid development and evaluation of robust dialogue\npolicies. Through an extensive study, we demonstrate the efficacy of transfer\nlearning and RL and showcase that ConvLab-3 is not only a powerful tool for\nseasoned researchers but also an accessible platform for newcomers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geishauser_C/0/1/0/all/0/1\">Christian Geishauser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hsien-chin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekerk_C/0/1/0/all/0/1\">Carel van Niekerk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heck_M/0/1/0/all/0/1\">Michael Heck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lubis_N/0/1/0/all/0/1\">Nurul Lubis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1\">Dazhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaochen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1\">Milica Ga&#x161;i&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Are Latent Variable Models: Explaining and Finding Good Demonstrations for In-Context Learning. (arXiv:2301.11916v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11916","description":"<p>In recent years, pre-trained large language models (LLMs) have demonstrated\nremarkable efficiency in achieving an inference-time few-shot learning\ncapability known as in-context learning. However, existing literature has\nhighlighted the sensitivity of this capability to the selection of few-shot\ndemonstrations. Current understandings of the underlying mechanisms by which\nthis capability arises from regular language model pretraining objectives\nremain disconnected from the real-world LLMs. This study aims to examine the\nin-context learning phenomenon through a Bayesian lens, viewing real-world LLMs\nas latent variable models. On this premise, we propose an algorithm to select\noptimal demonstrations from a set of annotated data with a small LM, and then\ndirectly generalize the selected demonstrations to larger LMs. We demonstrate\nsignificant improvement over baselines, averaged over eight GPT models on eight\nreal-world text classification datasets. We also demonstrate the real-world\nusefulness of our algorithm on GSM8K, a math word problem dataset. Our\nempirical findings support our hypothesis that LLMs implicitly infer a latent\nvariable containing task information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steyvers_M/0/1/0/all/0/1\">Mark Steyvers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?. (arXiv:2302.11713v5 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2302.11713","description":"<p>Pre-trained vision and language models have demonstrated state-of-the-art\ncapabilities over existing tasks involving images and texts, including visual\nquestion answering. However, it remains unclear whether these models possess\nthe capability to answer questions that are not only querying visual content\nbut knowledge-intensive and information-seeking. In this study, we introduce\nInfoSeek, a visual question answering dataset tailored for information-seeking\nquestions that cannot be answered with only common sense knowledge. Using\nInfoSeek, we analyze various pre-trained visual question answering models and\ngain insights into their characteristics. Our findings reveal that\nstate-of-the-art pre-trained multi-modal models (e.g., PaLI-X, BLIP2, etc.)\nface challenges in answering visual information-seeking questions, but\nfine-tuning on the InfoSeek dataset elicits models to use fine-grained\nknowledge that was learned during their pre-training. Furthermore, we show that\naccurate visual entity recognition can be used to improve performance on\nInfoSeek by retrieving relevant documents, showing a significant space for\nimprovement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_Y/0/1/0/all/0/1\">Yi Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Ming-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Make Every Example Count: On the Stability and Utility of Self-Influence for Learning from Noisy NLP Datasets. (arXiv:2302.13959v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.13959","description":"<p>Increasingly larger datasets have become a standard ingredient to advancing\nthe state-of-the-art in NLP. However, data quality might have already become\nthe bottleneck to unlock further gains. Given the diversity and the sizes of\nmodern datasets, standard data filtering is not straight-forward to apply,\nbecause of the multifacetedness of the harmful data and elusiveness of\nfiltering rules that would generalize across multiple tasks. We study the\nfitness of task-agnostic self-influence scores of training examples for data\ncleaning, analyze their efficacy in capturing naturally occurring outliers, and\ninvestigate to what extent self-influence based data cleaning can improve\ndownstream performance in machine translation, question answering and text\nclassification, building up on recent approaches to self-influence calculation\nand automated curriculum learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bejan_I/0/1/0/all/0/1\">Irina Bejan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sokolov_A/0/1/0/all/0/1\">Artem Sokolov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippova_K/0/1/0/all/0/1\">Katja Filippova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Making the Most of ChatGPT for Machine Translation. (arXiv:2303.13780v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13780","description":"<p>ChatGPT shows remarkable capabilities for machine translation (MT). Several\nprior studies have shown that it achieves comparable results to commercial\nsystems for high-resource languages, but lags behind in complex tasks, e.g.,\nlow-resource and distant-language-pairs translation. However, they usually\nadopt simple prompts which can not fully elicit the capability of ChatGPT. In\nthis paper, we aim to further mine ChatGPT's translation ability by revisiting\nseveral aspects: temperature, task information, and domain information, and\ncorrespondingly propose an optimal temperature setting and two (simple but\neffective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts\n(DSP). We show that: 1) The performance of ChatGPT depends largely on\ntemperature, and a lower temperature usually can achieve better performance; 2)\nEmphasizing the task information can further improve ChatGPT's performance,\nparticularly in complex MT tasks; 3) Introducing domain information can elicit\nChatGPT's generalization ability and improve its performance in the specific\ndomain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT\ntasks, which can be partially addressed by our proposed prompts but still need\nto be highlighted for the MT/NLP community. We also explore the effects of\nadvanced in-context learning strategies and find a (negative but interesting)\nobservation: the powerful chain-of-thought prompt leads to word-by-word\ntranslation behavior, thus bringing significant translation degradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Keqin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Yuanxin Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Contrastive Transfer Framework with Propagation Structure for Boosting Low-Resource Rumor Detection. (arXiv:2304.01492v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01492","description":"<p>The truth is significantly hampered by massive rumors that spread along with\nbreaking news or popular topics. Since there is sufficient corpus gathered from\nthe same domain for model training, existing rumor detection algorithms show\npromising performance on yesterday's news. However, due to a lack of\nsubstantial training data and prior expert knowledge, they are poor at spotting\nrumors concerning unforeseen events, especially those propagated in different\nlanguages (i.e., low-resource regimes). In this paper, we propose a unified\ncontrastive transfer framework to detect rumors by adapting the features\nlearned from well-resourced rumor data to that of the low-resourced with only\nfew-shot annotations. More specifically, we first represent rumor circulated on\nsocial media as an undirected topology for enhancing the interaction of user\nopinions, and then train a Multi-scale Graph Convolutional Network via a\nunified contrastive paradigm to mine effective clues simultaneously from post\nsemantics and propagation structure. Our model explicitly breaks the barriers\nof the domain and/or language issues, via language alignment and a novel\ndomain-adaptive contrastive learning mechanism. To well-generalize the\nrepresentation learning using a small set of annotated target events, we reveal\nthat rumor-indicative signal is closely correlated with the uniformity of the\ndistribution of these events. We design a target-wise contrastive training\nmechanism with three event-level data augmentation strategies, capable of\nunifying the representations by distinguishing target events. Extensive\nexperiments conducted on four low-resource datasets collected from real-world\nmicroblog platforms demonstrate that our framework achieves much better\nperformance than state-of-the-art methods and exhibits a superior capacity for\ndetecting rumors at early stages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhiwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1\">Mingfei Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Editable User Profiles for Controllable Text Recommendation. (arXiv:2304.04250v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2304.04250","description":"<p>Methods for making high-quality recommendations often rely on learning latent\nrepresentations from interaction data. These methods, while performant, do not\nprovide ready mechanisms for users to control the recommendation they receive.\nOur work tackles this problem by proposing LACE, a novel concept value\nbottleneck model for controllable text recommendations. LACE represents each\nuser with a succinct set of human-readable concepts through retrieval given\nuser-interacted documents and learns personalized representations of the\nconcepts based on user documents. This concept based user profile is then\nleveraged to make recommendations. The design of our model affords control over\nthe recommendations through a number of intuitive interactions with a\ntransparent user profile. We first establish the quality of recommendations\nobtained from LACE in an offline evaluation on three recommendation tasks\nspanning six datasets in warm-start, cold-start, and zero-shot setups. Next, we\nvalidate the controllability of LACE under simulated user interactions.\nFinally, we implement LACE in an interactive controllable recommender system\nand conduct a user study to demonstrate that users are able to improve the\nquality of recommendations they receive through interactions with an editable\nuser profile.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1\">Sheshera Mysore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jasim_M/0/1/0/all/0/1\">Mahmood Jasim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PAXQA: Generating Cross-lingual Question Answering Examples at Training Scale. (arXiv:2304.12206v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.12206","description":"<p>Existing question answering (QA) systems owe much of their success to large,\nhigh-quality training data. Such annotation efforts are costly, and the\ndifficulty compounds in the cross-lingual setting. Therefore, prior\ncross-lingual QA work has focused on releasing evaluation datasets, and then\napplying zero-shot methods as baselines. This work proposes a synthetic data\ngeneration method for cross-lingual QA which leverages indirect supervision\nfrom existing parallel corpora. Our method termed PAXQA (Projecting annotations\nfor cross-lingual (x) QA) decomposes cross-lingual QA into two stages. First,\nwe apply a question generation (QG) model to the English side. Second, we apply\nannotation projection to translate both the questions and answers. To better\ntranslate questions, we propose a novel use of lexically-constrained machine\ntranslation, in which constrained entities are extracted from the parallel\nbitexts.\n</p>\n<p>We apply PAXQA to generate cross-lingual QA examples in 4 languages (662K\nexamples total), and perform human evaluation on a subset to create validation\nand test splits. We then show that models fine-tuned on these datasets\noutperform prior synthetic data generation models over several extractive QA\ndatasets. The largest performance gains are for directions with non-English\nquestions and English contexts. Ablation studies show that our dataset\ngeneration method is relatively robust to noise from automatic word alignments,\nshowing the sufficient quality of our generations. To facilitate follow-up\nwork, we release our code and datasets at https://github.com/manestay/paxqa .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bryan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Internal State of an LLM Knows When It's Lying. (arXiv:2304.13734v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.13734","description":"<p>While Large Language Models (LLMs) have shown exceptional performance in\nvarious tasks, one of their most prominent drawbacks is generating inaccurate\nor false information with a confident tone. In this paper, we provide evidence\nthat the LLM's internal state can be used to reveal the truthfulness of\nstatements. This includes both statements provided to the LLM, and statements\nthat the LLM itself generates. Our approach is to train a classifier that\noutputs the probability that a statement is truthful, based on the hidden layer\nactivations of the LLM as it reads or generates the statement. Experiments\ndemonstrate that given a set of test sentences, of which half are true and half\nfalse, our trained classifier achieves an average of 71\\% to 83\\% accuracy\nlabeling which sentences are true versus false, depending on the LLM base\nmodel. Furthermore, we explore the relationship between our classifier's\nperformance and approaches based on the probability assigned to the sentence by\nthe LLM. We show that while LLM-assigned sentence probability is related to\nsentence truthfulness, this probability is also dependent on sentence length\nand the frequencies of words in the sentence, resulting in our trained\nclassifier providing a more reliable approach to detecting truthfulness,\nhighlighting its potential to enhance the reliability of LLM-generated content\nand its practical applicability in real-world scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Azaria_A/0/1/0/all/0/1\">Amos Azaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1\">Tom Mitchell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.07609","description":"<p>The remarkable achievements of Large Language Models (LLMs) have led to the\nemergence of a novel recommendation paradigm -- Recommendation via LLM\n(RecLLM). Nevertheless, it is important to note that LLMs may contain social\nprejudices, and therefore, the fairness of recommendations made by RecLLM\nrequires further investigation. To avoid the potential risks of RecLLM, it is\nimperative to evaluate the fairness of RecLLM with respect to various sensitive\nattributes on the user side. Due to the differences between the RecLLM paradigm\nand the traditional recommendation paradigm, it is problematic to directly use\nthe fairness benchmark of traditional recommendation. To address the dilemma,\nwe propose a novel benchmark called Fairness of Recommendation via LLM\n(FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset\nthat accounts for eight sensitive attributes1 in two recommendation scenarios:\nmusic and movies. By utilizing our FaiRLLM benchmark, we conducted an\nevaluation of ChatGPT and discovered that it still exhibits unfairness to some\nsensitive attributes when generating recommendations. Our code and dataset can\nbe found at https://github.com/jizhi-zhang/FaiRLLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jizhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_K/0/1/0/all/0/1\">Keqin Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation. (arXiv:2305.09652v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09652","description":"<p>End-to-end spoken language understanding (SLU) remains elusive even with\ncurrent large pretrained language models on text and speech, especially in\nmultilingual cases. Machine translation has been established as a powerful\npretraining objective on text as it enables the model to capture high-level\nsemantics of the input utterance and associations between different languages,\nwhich is desired for speech models that work on lower-level acoustic frames.\nMotivated particularly by the task of cross-lingual SLU, we demonstrate that\nthe task of speech translation (ST) is a good means of pretraining speech\nmodels for end-to-end SLU on both intra- and cross-lingual scenarios.\n</p>\n<p>By introducing ST, our models reach higher performance over baselines on\nmonolingual and multilingual intent classification as well as spoken question\nanswering using SLURP, MINDS-14, and NMSQA benchmarks. To verify the\neffectiveness of our methods, we also create new benchmark datasets from both\nsynthetic and real sources, for speech summarization and low-resource/zero-shot\ntransfer from English to French or Spanish. We further show the value of\npreserving knowledge for the ST pretraining task for better downstream\nperformance, possibly using Bayesian transfer regularizers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mutian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garner_P/0/1/0/all/0/1\">Philip N. Garner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLEME: Debiasing Multi-reference Evaluation for Grammatical Error Correction. (arXiv:2305.10819v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10819","description":"<p>Evaluating the performance of Grammatical Error Correction (GEC) systems is a\nchallenging task due to its subjectivity. Designing an evaluation metric that\nis as objective as possible is crucial to the development of GEC task. However,\nmainstream evaluation metrics, i.e., reference-based metrics, introduce bias\ninto the multi-reference evaluation by extracting edits without considering the\npresence of multiple references. To overcome this issue, we propose Chunk-LEvel\nMulti-reference Evaluation (CLEME), designed to evaluate GEC systems in the\nmulti-reference evaluation setting. CLEME builds chunk sequences with\nconsistent boundaries for the source, the hypothesis and references, thus\neliminating the bias caused by inconsistent edit boundaries. Furthermore, we\nobserve the consistent boundary could also act as the boundary of grammatical\nerrors, based on which the F$_{0.5}$ score is then computed following the\ncorrection independence assumption. We conduct experiments on six English\nreference sets based on the CoNLL-2014 shared task. Extensive experiments and\ndetailed analyses demonstrate the correctness of our discovery and the\neffectiveness of CLEME. Further analysis reveals that CLEME is robust to\nevaluate GEC systems across reference sets with varying numbers of references\nand annotation style.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jingheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shirong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Ying Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models. (arXiv:2305.11171v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11171","description":"<p>Factual consistency evaluation is often conducted using Natural Language\nInference (NLI) models, yet these models exhibit limited success in evaluating\nsummaries. Previous work improved such models with synthetic training data.\nHowever, the data is typically based on perturbed human-written summaries,\nwhich often differ in their characteristics from real model-generated summaries\nand have limited coverage of possible factual errors. Alternatively, large\nlanguage models (LLMs) have recently shown promising results in directly\nevaluating generative tasks, but are too computationally expensive for\npractical use. Motivated by these limitations, we introduce TrueTeacher, a\nmethod for generating synthetic data by annotating diverse model-generated\nsummaries using a LLM. Unlike prior work, TrueTeacher does not rely on\nhuman-written summaries, and is multilingual by nature. Experiments on the TRUE\nbenchmark show that a student model trained using our data, substantially\noutperforms both the state-of-the-art model with similar capacity, and the LLM\nteacher. In a systematic study, we compare TrueTeacher to existing synthetic\ndata generation methods and demonstrate its superiority and robustness to\ndomain-shift. We also show that our method generalizes to multilingual\nscenarios. Lastly, we release our large scale synthetic dataset (1.4M\nexamples), generated using TrueTeacher, and a checkpoint trained on this data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gekhman_Z/0/1/0/all/0/1\">Zorik Gekhman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elkind_C/0/1/0/all/0/1\">Chen Elkind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-CXR: Instruction-Finetuned LLM for CXR Image Understanding and Generation. (arXiv:2305.11490v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.11490","description":"<p>Following the impressive development of LLMs, vision-language alignment in\nLLMs is actively being researched to enable multimodal reasoning and visual IO.\nThis direction of research is particularly relevant to medical imaging because\nmedical image analysis and generation consist of reasoning based on a\ncombination of visual features and prior knowledge. Many recent works have\nfocused on training adapter networks that serve as an information bridge\nbetween image processing networks and LLMs; but presumably, in order to achieve\nmaximum reasoning potential of LLMs on visual information as well, visual and\nlanguage features should be allowed to interact more freely. This is especially\nimportant in the medical domain because understanding and generating medical\nimages such as chest X-rays (CXR) require not only accurate visual and\nlanguage-based reasoning but also a more intimate mapping between the two\nmodalities. Thus, taking inspiration from previous work on the transformer and\nVQ-GAN combination for bidirectional image and text generation, we build upon\nthis approach and develop a method for instruction-tuning an LLM pre-trained\nonly on text to gain vision-language capabilities for medical images.\nSpecifically, we leverage a pretrained LLM's existing question-answering and\ninstruction-following abilities to teach it to understand visual inputs by\ninstructing it to answer questions about image inputs and, symmetrically,\noutput both text and image responses appropriate to a given query by tuning the\nLLM with diverse tasks that encompass image-based text-generation and\ntext-based image-generation. We show that our model, LLM-CXR, trained in this\napproach shows better image-text alignment in both CXR understanding and\ngeneration tasks while being smaller in size compared to previously developed\nmodels that perform a narrower range of tasks. The code is at\nhttps://github.com/hyn2028/llm-cxr.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Suhyeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Won Jun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jinho Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Simplification of Medical Texts. (arXiv:2305.12532v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12532","description":"<p>Automated text simplification aims to produce simple versions of complex\ntexts. This task is especially useful in the medical domain, where the latest\nmedical findings are typically communicated via complex and technical articles.\nThis creates barriers for laypeople seeking access to up-to-date medical\nfindings, consequently impeding progress on health literacy. Most existing work\non medical text simplification has focused on monolingual settings, with the\nresult that such evidence would be available only in just one language (most\noften, English). This work addresses this limitation via multilingual\nsimplification, i.e., directly simplifying complex texts into simplified texts\nin multiple languages. We introduce MultiCochrane, the first sentence-aligned\nmultilingual text simplification dataset for the medical domain in four\nlanguages: English, Spanish, French, and Farsi. We evaluate fine-tuned and\nzero-shot models across these languages, with extensive human assessments and\nanalyses. Although models can now generate viable simplified texts, we identify\noutstanding challenges that this dataset might be used to address.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joseph_S/0/1/0/all/0/1\">Sebastian Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazanas_K/0/1/0/all/0/1\">Kathryn Kazanas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reina_K/0/1/0/all/0/1\">Keziah Reina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_V/0/1/0/all/0/1\">Vishnesh J. Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MacLaSa: Multi-Aspect Controllable Text Generation via Efficient Sampling from Compact Latent Space. (arXiv:2305.12785v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12785","description":"<p>Multi-aspect controllable text generation aims to generate fluent sentences\nthat possess multiple desired attributes simultaneously. Traditional methods\neither combine many operators in the decoding stage, often with costly\niteration or search in the discrete text space, or train separate controllers\nfor each aspect, resulting in a degeneration of text quality due to the\ndiscrepancy between different aspects. To address these limitations, we\nintroduce a novel approach for multi-aspect control, namely MacLaSa, that\nestimates compact latent space for multiple aspects and performs efficient\nsampling with a robust sampler based on ordinary differential equations (ODEs).\nTo eliminate the domain gaps between different aspects, we utilize a\nVariational Autoencoder (VAE) network to map text sequences from varying data\nsources into close latent representations. The estimated latent space enables\nthe formulation of joint energy-based models (EBMs) and the plugging in of\narbitrary attribute discriminators to achieve multi-aspect control. Afterwards,\nwe draw latent vector samples with an ODE-based sampler and feed sampled\nexamples to the VAE decoder to produce target text sequences. Experimental\nresults demonstrate that MacLaSa outperforms several strong baselines on\nattribute relevance and textual quality while maintaining a high inference\nspeed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1\">Hanxing Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zihao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Unsupervised Recognition of Semantic Differences in Related Documents. (arXiv:2305.13303v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13303","description":"<p>Automatically highlighting words that cause semantic differences between two\ndocuments could be useful for a wide range of applications. We formulate\nrecognizing semantic differences (RSD) as a token-level regression task and\nstudy three unsupervised approaches that rely on a masked language model. To\nassess the approaches, we begin with basic English sentences and gradually move\nto more complex, cross-lingual document pairs. Our results show that an\napproach based on word alignment and sentence-level contrastive learning has a\nrobust correlation to gold labels. However, all unsupervised approaches still\nleave a large margin of improvement. Code to reproduce our experiments is\navailable at https://github.com/ZurichNLP/recognizing-semantic-differences\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13812","description":"<p>Contrastively trained vision-language models have achieved remarkable\nprogress in vision and language representation learning, leading to\nstate-of-the-art models for various downstream multimodal tasks. However,\nrecent research has highlighted severe limitations of these models in their\nability to perform compositional reasoning over objects, attributes, and\nrelations. Scene graphs have emerged as an effective way to understand images\ncompositionally. These are graph-structured semantic representations of images\nthat contain objects, their attributes, and relations with other objects in a\nscene. In this work, we consider the scene graph parsed from text as a proxy\nfor the image scene graph and propose a graph decomposition and augmentation\nframework along with a coarse-to-fine contrastive learning objective between\nimages and text that aligns sentences of various complexities to the same\nimage. Along with this, we propose novel negative mining techniques in the\nscene graph space for improving attribute binding and relation understanding.\nThrough extensive experiments, we demonstrate the effectiveness of our approach\nthat significantly improves attribute binding, relation understanding,\nsystematic generalization, and productivity on multiple recently proposed\nbenchmarks (For example, improvements upto $18\\%$ for systematic\ngeneralization, $16.5\\%$ for relation understanding over a strong baseline),\nwhile achieving similar or better performance than CLIP on various general\nmultimodal tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_H/0/1/0/all/0/1\">Harman Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengchuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengjiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jingfei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"R2H: Building Multimodal Navigation Helpers that Respond to Help Requests. (arXiv:2305.14260v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14260","description":"<p>Intelligent navigation-helper agents are critical as they can navigate users\nin unknown areas through environmental awareness and conversational ability,\nserving as potential accessibility tools for individuals with disabilities. In\nthis work, we first introduce a novel benchmark, Respond to Help Requests\n(R2H), to promote the development of multi-modal navigation helpers capable of\nresponding to requests for help, utilizing existing dialog-based embodied\ndatasets. R2H mainly includes two tasks: (1) Respond to Dialog History (RDH),\nwhich assesses the helper agent's ability to generate informative responses\nbased on a given dialog history, and (2) Respond during Interaction (RdI),\nwhich evaluates the effectiveness and efficiency of the response during\nconsistent cooperation with a task performer. Furthermore, we explore two\napproaches to construct the navigation-helper agent, including fine-tuning a\nnovel task-oriented multi-modal response generation model that can see and\nrespond, named SeeRee, and employing a multi-modal large language model in a\nzero-shot manner. Analysis of the task and method was conducted based on both\nautomatic benchmarking and human evaluations. Project website:\nhttps://sites.google.com/view/response2helprequests/home.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yue Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jing Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kaizhi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and Tie Calibration. (arXiv:2305.14324v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14324","description":"<p>Kendall's tau is frequently used to meta-evaluate how well machine\ntranslation (MT) evaluation metrics score individual translations. Its focus on\npairwise score comparisons is intuitive but raises the question of how ties\nshould be handled, a gray area that has motivated different variants in the\nliterature. We demonstrate that, in settings like modern MT meta-evaluation,\nexisting variants have weaknesses arising from their handling of ties, and in\nsome situations can even be gamed. We propose instead to meta-evaluate metrics\nwith a version of pairwise accuracy that gives metrics credit for correctly\npredicting ties, in combination with a tie calibration procedure that\nautomatically introduces ties into metric scores, enabling fair comparison\nbetween metrics that do and do not predict ties. We argue and provide\nexperimental evidence that these modifications lead to fairer ranking-based\nassessments of metric performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deutsch_D/0/1/0/all/0/1\">Daniel Deutsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_G/0/1/0/all/0/1\">George Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1\">Markus Freitag</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training. (arXiv:2305.14342v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.14342","description":"<p>Given the massive cost of language model pre-training, a non-trivial\nimprovement of the optimization algorithm would lead to a material reduction on\nthe time and cost of training. Adam and its variants have been state-of-the-art\nfor years, and more sophisticated second-order (Hessian-based) optimizers often\nincur too much per-step overhead. In this paper, we propose Sophia,\nSecond-order Clipped Stochastic Optimization, a simple scalable second-order\noptimizer that uses a light-weight estimate of the diagonal Hessian as the\npre-conditioner. The update is the moving average of the gradients divided by\nthe moving average of the estimated Hessian, followed by element-wise clipping.\nThe clipping controls the worst-case update size and tames the negative impact\nof non-convexity and rapid change of Hessian along the trajectory. Sophia only\nestimates the diagonal Hessian every handful of iterations, which has\nnegligible average per-step time and memory overhead. On language modeling with\nGPT models of sizes ranging from 125M to 1.5B, Sophia achieves a 2x speed-up\ncompared to Adam in the number of steps, total compute, and wall-clock time,\nachieving the same perplexity with 50% fewer steps, less total compute, and\nreduced wall-clock time. Theoretically, we show that Sophia, in a much\nsimplified setting, adapts to the heterogeneous curvatures in different\nparameter dimensions, and thus has a run-time bound that does not depend on the\ncondition number of the loss.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_D/0/1/0/all/0/1\">David Hall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tengyu Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Learning for Natural Language Generation. (arXiv:2305.15040v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15040","description":"<p>The field of Natural Language Generation (NLG) suffers from a severe shortage\nof labeled data due to the extremely expensive and time-consuming process\ninvolved in manual annotation. A natural approach for coping with this problem\nis active learning (AL), a well-known machine learning technique for improving\nannotation efficiency by selectively choosing the most informative examples to\nlabel. However, while AL has been well-researched in the context of text\nclassification, its application to NLG remains largely unexplored. In this\npaper, we present a first systematic study of active learning for NLG,\nconsidering a diverse set of tasks and multiple leading selection strategies,\nand harnessing a strong instruction-tuned model. Our results indicate that the\nperformance of existing AL strategies is inconsistent, surpassing the baseline\nof random example selection in some cases but not in others. We highlight some\nnotable differences between the classification and generation scenarios, and\nanalyze the selection behaviors of existing AL strategies. Our findings\nmotivate exploring novel approaches for applying AL to generation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perlitz_Y/0/1/0/all/0/1\">Yotam Perlitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gera_A/0/1/0/all/0/1\">Ariel Gera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_Scheuer_M/0/1/0/all/0/1\">Michal Shmueli-Scheuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheinwald_D/0/1/0/all/0/1\">Dafna Sheinwald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ein_Dor_L/0/1/0/all/0/1\">Liat Ein-Dor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Are Not Strong Abstract Reasoners. (arXiv:2305.19555v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19555","description":"<p>Large Language Models have shown tremendous performance on a large variety of\nnatural language processing tasks, ranging from text comprehension to common\nsense reasoning. However, the mechanisms responsible for this success remain\nopaque, and it is unclear whether LLMs can achieve human-like cognitive\ncapabilities or whether these models are still fundamentally circumscribed.\nAbstract reasoning is a fundamental task for cognition, consisting of finding\nand applying a general pattern from few data. Evaluating deep neural\narchitectures on this task could give insight into their potential limitations\nregarding reasoning and their broad generalisation abilities, yet this is\ncurrently an under-explored area. In this paper, we introduce a new benchmark\nfor evaluating language models beyond memorization on abstract reasoning tasks.\nWe perform extensive evaluations of state-of-the-art LLMs, showing that they\ncurrently achieve very limited performance in contrast with other natural\nlanguage tasks, and we examine the reasons for this difference. We apply\ntechniques that have been shown to improve performance on other NLP tasks and\nshow that their impact on abstract reasoning is limited.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1\">Ga&#xeb;l Gendron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobbie_G/0/1/0/all/0/1\">Gillian Dobbie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is Self-Repair a Silver Bullet for Code Generation?. (arXiv:2306.09896v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09896","description":"<p>Large language models have shown remarkable aptitude in code generation, but\nstill struggle on challenging tasks. Self-repair -- in which the model debugs\nand fixes mistakes in its own code -- has recently become a popular way to\nboost performance in these settings. However, only very limited studies on how\nand when self-repair works effectively exist in the literature, and one might\nwonder to what extent a model is really capable of repairing mistakes in code\nwhich was originally generated by that very same model. In this paper, we\nanalyze Code Llama, GPT-3.5 and GPT-4's ability to perform self-repair on\nproblems taken from HumanEval or APPS, finding that when the cost of carrying\nout repair is taken into account, gains are often modest, vary significantly\nbetween subsets of the data, and are sometimes not present at all. We\nhypothesize that this is because self-repair is bottlenecked by the model's\nability to provide feedback on its own code; boosting the feedback with\nstronger models, we observe performance gains even in settings where the model\ndoes not benefit from self-repair. Finally, we find that providing the model\nwith feedback from human participants greatly benefits repair even for GPT-4,\nand carry out a brief qualitative analysis of the differences observed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Olausson_T/0/1/0/all/0/1\">Theo X. Olausson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inala_J/0/1/0/all/0/1\">Jeevana Priya Inala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenglong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1\">Armando Solar-Lezama</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Opportunities and Challenges for ChatGPT and Large Language Models in Biomedicine and Health. (arXiv:2306.10070v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2306.10070","description":"<p>ChatGPT has drawn considerable attention from both the general public and\ndomain experts with its remarkable text generation capabilities. This has\nsubsequently led to the emergence of diverse applications in the field of\nbiomedicine and health. In this work, we examine the diverse applications of\nlarge language models (LLMs), such as ChatGPT, in biomedicine and health.\nSpecifically we explore the areas of biomedical information retrieval, question\nanswering, medical text summarization, information extraction, and medical\neducation, and investigate whether LLMs possess the transformative power to\nrevolutionize these tasks or whether the distinct complexities of biomedical\ndomain presents unique challenges. Following an extensive literature survey, we\nfind that significant advances have been made in the field of text generation\ntasks, surpassing the previous state-of-the-art methods. For other\napplications, the advances have been modest. Overall, LLMs have not yet\nrevolutionized biomedicine, but recent rapid progress indicates that such\nmethods hold great potential to provide valuable means for accelerating\ndiscovery and improving health. We also find that the use of LLMs, like\nChatGPT, in the fields of biomedicine and health entails various risks and\nchallenges, including fabricated information in its generated responses, as\nwell as legal and privacy concerns associated with sensitive patient data. We\nbelieve this survey can provide a comprehensive and timely overview to\nbiomedical researchers and healthcare practitioners on the opportunities and\nchallenges associated with using ChatGPT and other LLMs for transforming\nbiomedicine and health.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shubo Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeganova_L/0/1/0/all/0/1\">Lana Yeganova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_P/0/1/0/all/0/1\">Po-Ting Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiuying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Won Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Comeau_D/0/1/0/all/0/1\">Donald C. Comeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islamaj_R/0/1/0/all/0/1\">Rezarta Islamaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1\">Aadit Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xin Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"REFLECT: Summarizing Robot Experiences for Failure Explanation and Correction. (arXiv:2306.15724v4 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2306.15724","description":"<p>The ability to detect and analyze failed executions automatically is crucial\nfor an explainable and robust robotic system. Recently, Large Language Models\n(LLMs) have demonstrated strong reasoning abilities on textual inputs. To\nleverage the power of LLMs for robot failure explanation, we introduce REFLECT,\na framework which queries LLM for failure reasoning based on a hierarchical\nsummary of robot past experiences generated from multisensory observations. The\nfailure explanation can further guide a language-based planner to correct the\nfailure and complete the task. To systematically evaluate the framework, we\ncreate the RoboFail dataset with a variety of tasks and failure scenarios. We\ndemonstrate that the LLM-based framework is able to generate informative\nfailure explanations that assist successful correction planning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zeyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bahety_A/0/1/0/all/0/1\">Arpit Bahety</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuran Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17181","description":"<p>Generative Adversarial Networks (GAN) is a model for data synthesis, which\ncreates plausible data through the competition of generator and discriminator.\nAlthough GAN application to image synthesis is extensively studied, it has\ninherent limitations to natural language generation. Because natural language\nis composed of discrete tokens, a generator has difficulty updating its\ngradient through backpropagation; therefore, most text-GAN studies generate\nsentences starting with a random token based on a reward system. Thus, the\ngenerators of previous studies are pre-trained in an autoregressive way before\nadversarial training, causing data memorization that synthesized sentences\nreproduce the training data. In this paper, we synthesize sentences using a\nframework similar to the original GAN. More specifically, we propose Text\nEmbedding Space Generative Adversarial Networks (TESGAN) which generate\ncontinuous text embedding spaces instead of discrete tokens to solve the\ngradient backpropagation problem. Furthermore, TESGAN conducts unsupervised\nlearning which does not directly refer to the text of the training data to\novercome the data memorization issue. By adopting this novel method, TESGAN can\nsynthesize new sentences, showing the potential of unsupervised learning for\ntext synthesis. We expect to see extended research combining Large Language\nModels with a new perspective of viewing text as an continuous space.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jun-Min Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_T/0/1/0/all/0/1\">Tae-Bin Ha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v8 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03109","description":"<p>Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yupeng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Look Before You Leap: An Exploratory Study of Uncertainty Measurement for Large Language Models. (arXiv:2307.10236v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2307.10236","description":"<p>The recent performance leap of Large Language Models (LLMs) opens up new\nopportunities across numerous industrial applications and domains. However,\nerroneous generations, such as false predictions, misinformation, and\nhallucination made by LLMs, have also raised severe concerns for the\ntrustworthiness of LLMs', especially in safety-, security- and\nreliability-sensitive scenarios, potentially hindering real-world adoptions.\nWhile uncertainty estimation has shown its potential for interpreting the\nprediction risks made by general machine learning (ML) models, little is known\nabout whether and to what extent it can help explore an LLM's capabilities and\ncounteract its undesired behavior. To bridge the gap, in this paper, we\ninitiate an exploratory study on the risk assessment of LLMs from the lens of\nuncertainty. In particular, we experiment with twelve uncertainty estimation\nmethods and four LLMs on four prominent natural language processing (NLP) tasks\nto investigate to what extent uncertainty estimation techniques could help\ncharacterize the prediction risks of LLMs. Our findings validate the\neffectiveness of uncertainty estimation for revealing LLMs'\nuncertain/non-factual predictions. In addition to general NLP tasks, we\nextensively conduct experiments with four LLMs for code generation on two\ndatasets. We find that uncertainty estimation can potentially uncover buggy\nprograms generated by LLMs. Insights from our study shed light on future design\nand development for reliable LLMs, facilitating further research toward\nenhancing the trustworthiness of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiayang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shengming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huaming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1\">Felix Juefei-Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lei Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models. (arXiv:2308.01263v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01263","description":"<p>Without proper safeguards, large language models will readily follow\nmalicious instructions and generate toxic content. This risk motivates safety\nefforts such as red-teaming and large-scale feedback learning, which aim to\nmake models both helpful and harmless. However, there is a tension between\nthese two objectives, since harmlessness requires models to refuse to comply\nwith unsafe prompts, and thus not be helpful. Recent anecdotal evidence\nsuggests that some models may have struck a poor balance, so that even clearly\nsafe prompts are refused if they use similar language to unsafe prompts or\nmention sensitive topics. In this paper, we introduce a new test suite called\nXSTest to identify such eXaggerated Safety behaviours in a systematic way.\nXSTest comprises 250 safe prompts across ten prompt types that well-calibrated\nmodels should not refuse to comply with, and 200 unsafe prompts as contrasts\nthat models, for most applications, should refuse. We describe XSTest's\ncreation and composition, and then use the test suite to highlight systematic\nfailure modes in state-of-the-art language models as well as more general\nchallenges in building safer language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1\">Paul R&#xf6;ttger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Attanasio_G/0/1/0/all/0/1\">Giuseppe Attanasio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1\">Federico Bianchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1\">Dirk Hovy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT replace StackOverflow? A Study on Robustness and Reliability of Large Language Model Code Generation. (arXiv:2308.10335v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10335","description":"<p>Recently, the large language models (LLMs) have shown extraordinary ability\nin understanding natural language and generating programming code. It has been\na common practice of software engineers to consult LLMs when encountering\ncoding questions. Although efforts have been made to avoid syntax errors and\nalign the code with the intended semantics, the reliability and robustness of\nthe code generationfrom LLMs have not yet been thoroughly studied. The\nexecutable code is not equivalent to the reliable and robust code, especially\nin the context of real-world software development. The misuse of APIs in the\ngenerated code could lead to severe problem, such as resource leaks, program\ncrashes. To make things worse, the users of LLM code generation services are\nactually the developers that are most vulnerable to these code that seems right\n-- They are always novice developers that are not familiar with the APIs that\nLLMs generate code for them. Therefore, they could hardly tell the misuse in\nthe code generated by LLMs, which further facilitates the incorrect code\napplied in real-world software. Existing code evaluation benchmark and datasets\nfocus on crafting small tasks such as programming questions in coding\ninterviews, which however deviates from the problem that developers would ask\nLLM for real-world coding help. To fill the missing piece, in this work, we\npropose a dataset RobustAPI for evaluating the reliability and robustness of\ncode generated by LLMs. We collect 1208 coding questions from StackOverflow on\n24 representative Java APIs. We summarize thecommon misuse patterns of these\nAPIs and evaluate them oncurrent popular LLMs. The evaluation results show that\nevenfor GPT-4, 62% of the generated code contains API misuses,which would cause\nunexpected consequences if the code isintroduced into real-world software.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1\">Li Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Do Program-of-Thoughts Work for Reasoning?. (arXiv:2308.15452v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.15452","description":"<p>The reasoning capabilities of Large Language Models (LLMs) play a pivotal\nrole in the realm of embodied artificial intelligence. Although there are\neffective methods like program-of-thought prompting for LLMs which uses\nprogramming language to tackle complex reasoning tasks, the specific impact of\ncode data on the improvement of reasoning capabilities remains under-explored.\nTo address this gap, we propose complexity-impacted reasoning score (CIRS),\nwhich combines structural and logical attributes, to measure the correlation\nbetween code and reasoning abilities. Specifically, we use the abstract syntax\ntree to encode the structural information and calculate logical complexity by\nconsidering the difficulty and the cyclomatic complexity. Through an empirical\nanalysis, we find not all code data of complexity can be learned or understood\nby LLMs. Optimal level of complexity is critical to the improvement of\nreasoning abilities by program-aided prompting. Then we design an\nauto-synthesizing and stratifying algorithm, and apply it to instruction\ngeneration for mathematical reasoning and code data filtering for code\ngeneration tasks. Extensive results demonstrates the effectiveness of our\nproposed approach. Code will be integrated into the EasyInstruct framework at\nhttps://github.com/zjunlp/EasyInstruct.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yinuo Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning. (arXiv:2309.04965v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2309.04965","description":"<p>While impressive performance has been achieved in image captioning, the\nlimited diversity of the generated captions and the large parameter scale\nremain major barriers to the real-word application of these systems. In this\nwork, we propose a lightweight image captioning network in combination with\ncontinuous diffusion, called Prefix-diffusion. To achieve diversity, we design\nan efficient method that injects prefix image embeddings into the denoising\nprocess of the diffusion model. In order to reduce trainable parameters, we\nemploy a pre-trained model to extract image features and further design an\nextra mapping network. Prefix-diffusion is able to generate diverse captions\nwith relatively less parameters, while maintaining the fluency and relevance of\nthe captions benefiting from the generative capabilities of the diffusion\nmodel. Our work paves the way for scaling up diffusion models for image\ncaptioning, and achieves promising performance compared with recent approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guisheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhengcong Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Haiyan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xiangyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yanqing Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Personalized Impression Generation for PET Reports Using Large Language Models. (arXiv:2309.10066v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.10066","description":"<p>In this study, we aimed to determine if fine-tuned large language models\n(LLMs) can generate accurate, personalized impressions for whole-body PET\nreports. Twelve language models were trained on a corpus of PET reports using\nthe teacher-forcing algorithm, with the report findings as input and the\nclinical impressions as reference. An extra input token encodes the reading\nphysician's identity, allowing models to learn physician-specific reporting\nstyles. Our corpus comprised 37,370 retrospective PET reports collected from\nour institution between 2010 and 2022. To identify the best LLM, 30 evaluation\nmetrics were benchmarked against quality scores from two nuclear medicine (NM)\nphysicians, with the most aligned metrics selecting the model for expert\nevaluation. In a subset of data, model-generated impressions and original\nclinical impressions were assessed by three NM physicians according to 6\nquality dimensions (3-point scale) and an overall utility score (5-point\nscale). Each physician reviewed 12 of their own reports and 12 reports from\nother physicians. Bootstrap resampling was used for statistical analysis. Of\nall evaluation metrics, domain-adapted BARTScore and PEGASUSScore showed the\nhighest Spearman's rank correlations (0.568 and 0.563) with physician\npreferences. Based on these metrics, the fine-tuned PEGASUS model was selected\nas the top LLM. When physicians reviewed PEGASUS-generated impressions in their\nown style, 89% were considered clinically acceptable, with a mean utility score\nof 4.08 out of 5. Physicians rated these personalized impressions as comparable\nin overall utility to the impressions dictated by other physicians (4.03,\nP=0.41). In conclusion, personalized impressions generated by PEGASUS were\nclinically useful, highlighting its potential to expedite PET reporting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tie_X/0/1/0/all/0/1\">Xin Tie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_M/0/1/0/all/0/1\">Muheon Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirasteh_A/0/1/0/all/0/1\">Ali Pirasteh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_N/0/1/0/all/0/1\">Nevein Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huemann_Z/0/1/0/all/0/1\">Zachary Huemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castellino_S/0/1/0/all/0/1\">Sharon M. Castellino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelly_K/0/1/0/all/0/1\">Kara M. Kelly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrett_J/0/1/0/all/0/1\">John Garrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Junjie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Steve Y. Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bradshaw_T/0/1/0/all/0/1\">Tyler J. Bradshaw</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AceGPT, Localizing Large Language Models in Arabic. (arXiv:2309.12053v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12053","description":"<p>This paper is devoted to the development of a localized Large Language Model\n(LLM) specifically for Arabic, a language imbued with unique cultural\ncharacteristics inadequately addressed by current mainstream models.\nSignificant concerns emerge when addressing cultural sensitivity and local\nvalues. To address this, the paper proposes a comprehensive solution that\nincludes further pre-training with Arabic texts, Supervised Fine-Tuning (SFT)\nutilizing native Arabic instructions, and GPT-4 responses in Arabic, alongside\nReinforcement Learning with AI Feedback (RLAIF) employing a reward model\nattuned to local culture and values. The goal is to cultivate culturally\ncognizant and value-aligned Arabic LLMs capable of accommodating the diverse,\napplication-specific needs of Arabic-speaking communities. Comprehensive\nevaluations reveal that the resulting model, dubbed 'AceGPT', sets the\nstate-of-the-art standard for open Arabic LLMs across various benchmarks,\nincluding the instruction-following benchmark (i.e., Arabic Vicuna-80 and\nArabic AlpacaEval), knowledge benchmark (i.e., Arabic MMLU and EXAMs), and the\nnewly introduced Arabic Cultural and Value Alignment benchmark. Notably, AceGPT\noutperforms Turbo in the popular Vicuna-80 benchmark when evaluated with GPT-4,\ndespite the benchmark's limited scale. Codes, data, and models are in\nhttps://github.com/FreedomIntelligence/AceGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Huang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xuening Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dingjie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alharthi_A/0/1/0/all/0/1\">Abdulmohsen Alharthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Juncai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziche Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinchao Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AnglE-optimized Text Embeddings. (arXiv:2309.12871v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12871","description":"<p>High-quality text embedding is pivotal in improving semantic textual\nsimilarity (STS) tasks, which are crucial components in Large Language Model\n(LLM) applications. However, a common challenge existing text embedding models\nface is the problem of vanishing gradients, primarily due to their reliance on\nthe cosine function in the optimization objective, which has saturation zones.\nTo address this issue, this paper proposes a novel angle-optimized text\nembedding model called AnglE. The core idea of AnglE is to introduce angle\noptimization in a complex space. This novel approach effectively mitigates the\nadverse effects of the saturation zone in the cosine function, which can impede\ngradient and hinder optimization processes. To set up a comprehensive STS\nevaluation, we experimented on existing short-text STS datasets and a newly\ncollected long-text STS dataset from GitHub Issues. Furthermore, we examine\ndomain-specific STS scenarios with limited labeled data and explore how AnglE\nworks with LLM-annotated data. Extensive experiments were conducted on various\ntasks including short-text STS, long-text STS, and domain-specific STS tasks.\nThe results show that AnglE outperforms the state-of-the-art (SOTA) STS models\nthat ignore the cosine saturation zone. These findings demonstrate the ability\nof AnglE to generate high-quality text embeddings and the usefulness of angle\noptimization in STS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analysis and Detection of Pathological Voice using Glottal Source Features. (arXiv:2309.14080v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.14080","description":"<p>Automatic detection of voice pathology enables objective assessment and\nearlier intervention for the diagnosis. This study provides a systematic\nanalysis of glottal source features and investigates their effectiveness in\nvoice pathology detection. Glottal source features are extracted using glottal\nflows estimated with the quasi-closed phase (QCP) glottal inverse filtering\nmethod, using approximate glottal source signals computed with the zero\nfrequency filtering (ZFF) method, and using acoustic voice signals directly. In\naddition, we propose to derive mel-frequency cepstral coefficients (MFCCs) from\nthe glottal source waveforms computed by QCP and ZFF to effectively capture the\nvariations in glottal source spectra of pathological voice. Experiments were\ncarried out using two databases, the Hospital Universitario Principe de\nAsturias (HUPA) database and the Saarbrucken Voice Disorders (SVD) database.\nAnalysis of features revealed that the glottal source contains information that\ndiscriminates normal and pathological voice. Pathology detection experiments\nwere carried out using support vector machine (SVM). From the detection\nexperiments it was observed that the performance achieved with the studied\nglottal source features is comparable or better than that of conventional MFCCs\nand perceptual linear prediction (PLP) features. The best detection performance\nwas achieved when the glottal source features were combined with the\nconventional MFCCs and PLP features, which indicates the complementary nature\nof the features.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Kadiri_S/0/1/0/all/0/1\">Sudarsana Reddy Kadiri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alku_P/0/1/0/all/0/1\">Paavo Alku</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Wav2vec-based Detection and Severity Level Classification of Dysarthria from Speech. (arXiv:2309.14107v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.14107","description":"<p>Automatic detection and severity level classification of dysarthria directly\nfrom acoustic speech signals can be used as a tool in medical diagnosis. In\nthis work, the pre-trained wav2vec 2.0 model is studied as a feature extractor\nto build detection and severity level classification systems for dysarthric\nspeech. The experiments were carried out with the popularly used UA-speech\ndatabase. In the detection experiments, the results revealed that the best\nperformance was obtained using the embeddings from the first layer of the\nwav2vec model that yielded an absolute improvement of 1.23% in accuracy\ncompared to the best performing baseline feature (spectrogram). In the studied\nseverity level classification task, the results revealed that the embeddings\nfrom the final layer gave an absolute improvement of 10.62% in accuracy\ncompared to the best baseline features (mel-frequency cepstral coefficients).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Javanmardi_F/0/1/0/all/0/1\">Farhad Javanmardi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tirronen_S/0/1/0/all/0/1\">Saska Tirronen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kodali_M/0/1/0/all/0/1\">Manila Kodali</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kadiri_S/0/1/0/all/0/1\">Sudarsana Reddy Kadiri</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Alku_P/0/1/0/all/0/1\">Paavo Alku</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating LLM, EEG, and Eye-Tracking Biomarker Analysis for Word-Level Neural State Classification in Semantic Inference Reading Comprehension. (arXiv:2309.15714v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.15714","description":"<p>With the recent proliferation of large language models (LLMs), such as\nGenerative Pre-trained Transformers (GPT), there has been a significant shift\nin exploring human and machine comprehension of semantic language meaning. This\nshift calls for interdisciplinary research that bridges cognitive science and\nnatural language processing (NLP). This pilot study aims to provide insights\ninto individuals' neural states during a semantic relation\nreading-comprehension task. We propose jointly analyzing LLMs, eye-gaze, and\nelectroencephalographic (EEG) data to study how the brain processes words with\nvarying degrees of relevance to a keyword during reading. We also use a feature\nengineering approach to improve the fixation-related EEG data classification\nwhile participants read words with high versus low relevance to the keyword.\nThe best validation accuracy in this word-level classification is over 60\\%\nacross 12 subjects. Words of high relevance to the inference keyword had\nsignificantly more eye fixations per word: 1.0584 compared to 0.6576 when\nexcluding no-fixation words, and 1.5126 compared to 1.4026 when including them.\nThis study represents the first attempt to classify brain states at a word\nlevel using LLM knowledge. It provides valuable insights into human cognitive\nabilities and the realm of Artificial General Intelligence (AGI), and offers\nguidance for developing potential reading-assisted technologies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nahata_S/0/1/0/all/0/1\">Sujal Nahata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jamal_T/0/1/0/all/0/1\">Tasnia Jamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shih-kuen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cauwenberghs_G/0/1/0/all/0/1\">Gert Cauwenberghs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_T/0/1/0/all/0/1\">Tzyy-Ping Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effective Long-Context Scaling of Foundation Models. (arXiv:2309.16039v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16039","description":"<p>We present a series of long-context LLMs that support effective context\nwindows of up to 32,768 tokens. Our model series are built through continual\npretraining from Llama 2 with longer training sequences and on a dataset where\nlong texts are upsampled. We perform extensive evaluation on language modeling,\nsynthetic context probing tasks, and a wide range of research benchmarks. On\nresearch benchmarks, our models achieve consistent improvements on most regular\ntasks and significant improvements on long-context tasks over Llama 2. Notably,\nwith a cost-effective instruction tuning procedure that does not require\nhuman-annotated long instruction data, the 70B variant can already surpass\ngpt-3.5-turbo-16k's overall performance on a suite of long-context tasks.\nAlongside these results, we provide an in-depth analysis on the individual\ncomponents of our method. We delve into Llama's position encodings and discuss\nits limitation in modeling long dependencies. We also examine the impact of\nvarious design choices in the pretraining process, including the data mix and\nthe training curriculum of sequence lengths -- our ablation experiments suggest\nthat having abundant long texts in the pretrain dataset is not the key to\nachieving strong performance, and we empirically verify that long context\ncontinual pretraining is more efficient and similarly effective compared to\npretraining from scratch with long sequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molybog_I/0/1/0/all/0/1\">Igor Molybog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hejia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_P/0/1/0/all/0/1\">Prajjwal Bhargava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Louis Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rungta_R/0/1/0/all/0/1\">Rashi Rungta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankararaman_K/0/1/0/all/0/1\">Karthik Abinav Sankararaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Han Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1\">Sharan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Angela Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1\">Shruti Bhosale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edunov_S/0/1/0/all/0/1\">Sergey Edunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hao Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Analysis Of Google Bard And GPT-Vision: Experiments In Visual Reasoning. (arXiv:2309.16705v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2309.16705","description":"<p>Addressing the gap in understanding visual comprehension in Large Language\nModels (LLMs), we designed a challenge-response study, subjecting Google Bard\nand GPT-Vision to 64 visual tasks, spanning categories like \"Visual Situational\nReasoning\" and \"Next Scene Prediction.\" Previous models, such as GPT4, leaned\nheavily on optical character recognition tools like Tesseract, whereas Bard and\nGPT-Vision, akin to Google Lens and Visual API, employ deep learning techniques\nfor visual text recognition. However, our findings spotlight both\nvision-language model's limitations: while proficient in solving visual\nCAPTCHAs that stump ChatGPT alone, it falters in recreating visual elements\nlike ASCII art or analyzing Tic Tac Toe grids, suggesting an over-reliance on\neducated visual guesses. The prediction problem based on visual inputs appears\nparticularly challenging with no common-sense guesses for next-scene\nforecasting based on current \"next-token\" multimodal models. This study\nprovides experimental insights into the current capacities and areas for\nimprovement in multimodal LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noever_S/0/1/0/all/0/1\">Samantha Elizabeth Miller Noever</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-Driver: Learning to Drive with GPT. (arXiv:2310.01415v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.01415","description":"<p>We present a simple yet effective approach that can transform the OpenAI\nGPT-3.5 model into a reliable motion planner for autonomous vehicles. Motion\nplanning is a core challenge in autonomous driving, aiming to plan a driving\ntrajectory that is safe and comfortable. Existing motion planners predominantly\nleverage heuristic methods to forecast driving trajectories, yet these\napproaches demonstrate insufficient generalization capabilities in the face of\nnovel and unseen driving scenarios. In this paper, we propose a novel approach\nto motion planning that capitalizes on the strong reasoning capabilities and\ngeneralization potential inherent to Large Language Models (LLMs). The\nfundamental insight of our approach is the reformulation of motion planning as\na language modeling problem, a perspective not previously explored.\nSpecifically, we represent the planner inputs and outputs as language tokens,\nand leverage the LLM to generate driving trajectories through a language\ndescription of coordinate positions. Furthermore, we propose a novel\nprompting-reasoning-finetuning strategy to stimulate the numerical reasoning\npotential of the LLM. With this strategy, the LLM can describe highly precise\ntrajectory coordinates and also its internal decision-making process in natural\nlanguage. We evaluate our approach on the large-scale nuScenes dataset, and\nextensive experiments substantiate the effectiveness, generalization ability,\nand interpretability of our GPT-based motion planner. Code is now available at\nhttps://github.com/PointsCoder/GPT-Driver.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiageng Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yuxi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition. (arXiv:2310.06434v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06434","description":"<p>We introduce a new cross-modal fusion technique designed for generative error\ncorrection in automatic speech recognition (ASR). Our methodology leverages\nboth acoustic information and external linguistic representations to generate\naccurate speech transcription contexts. This marks a step towards a fresh\nparadigm in generative error correction within the realm of n-best hypotheses.\nUnlike the existing ranking-based rescoring methods, our approach adeptly uses\ndistinct initialization techniques and parameter-efficient algorithms to boost\nASR performance derived from pre-trained speech and text models. Through\nevaluation across diverse ASR datasets, we evaluate the stability and\nreproducibility of our fusion technique, demonstrating its improved word error\nrate relative (WERR) performance in comparison to n-best hypotheses by\nrelatively 37.66%. To encourage future research, we have made our code and\npre-trained models open source at\nhttps://github.com/Srijith-rkr/Whispering-LLaMA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1\">Srijith Radhakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1\">Sumeer Ahmad Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_R/0/1/0/all/0/1\">Rohit Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiani_N/0/1/0/all/0/1\">Narsis A. Kiani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Cabrero_D/0/1/0/all/0/1\">David Gomez-Cabrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1\">Jesper N. Tegner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioT5: Enriching Cross-modal Integration in Biology with Chemical Knowledge and Natural Language Associations. (arXiv:2310.07276v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07276","description":"<p>Recent advancements in biological research leverage the integration of\nmolecules, proteins, and natural language to enhance drug discovery. However,\ncurrent models exhibit several limitations, such as the generation of invalid\nmolecular SMILES, underutilization of contextual information, and equal\ntreatment of structured and unstructured knowledge. To address these issues, we\npropose $\\mathbf{BioT5}$, a comprehensive pre-training framework that enriches\ncross-modal integration in biology with chemical knowledge and natural language\nassociations. $\\mathbf{BioT5}$ utilizes SELFIES for $100%$ robust molecular\nrepresentations and extracts knowledge from the surrounding context of\nbio-entities in unstructured biological literature. Furthermore,\n$\\mathbf{BioT5}$ distinguishes between structured and unstructured knowledge,\nleading to more effective utilization of information. After fine-tuning, BioT5\nshows superior performance across a wide range of tasks, demonstrating its\nstrong capability of capturing underlying relations and properties of\nbio-entities. Our code is available at\n$\\href{https://github.com/QizhiPei/BioT5}{Github}$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pei_Q/0/1/0/all/0/1\">Qizhi Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jinhua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1\">Kehan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_K/0/1/0/all/0/1\">Kaiyuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lijun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingce Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models. (arXiv:2310.08659v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08659","description":"<p>Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves the\ngeneralization in downstream tasks. We evaluate our method on natural language\nunderstanding, question answering, summarization, and natural language\ngeneration tasks. Experiments show that our method is highly effective and\noutperforms existing quantization methods, especially in the challenging 2-bit\nand 2/4-bit mixed precision regimes. We will release our code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karampatziakis_N/0/1/0/all/0/1\">Nikos Karampatziakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation. (arXiv:2310.08943v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08943","description":"<p>Knowledge-grounded dialogue generation aims to mitigate the issue of text\ndegeneration by incorporating external knowledge to supplement the context.\nHowever, the model often fails to internalize this information into responses\nin a human-like manner. Instead, it simply inserts segments of the provided\nknowledge into generic responses. As a result, the generated responses tend to\nbe tedious, incoherent, and in lack of interactivity which means the\ndegeneration problem is still unsolved. In this work, we first find that such\ncopying-style degeneration is primarily due to the weak likelihood objective,\nwhich allows the model to \"cheat\" the objective by merely duplicating knowledge\nsegments in a superficial pattern matching based on overlap. To overcome this\nchallenge, we then propose a Multi-level Adaptive Contrastive Learning (MACL)\nframework that dynamically samples negative examples and subsequently penalizes\ndegeneration behaviors at both the token-level and sequence-level. Extensive\nexperiments on the WoW dataset demonstrate the effectiveness of our approach\nacross various pre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenxu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lanrui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1\">Chong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_Q/0/1/0/all/0/1\">Qirong Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09430","description":"<p>Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly\nadvanced the performance of artificial systems on various natural language\nprocessing tasks to human-like levels. However, their generalisation and\nrobustness to perform logical reasoning remain under-evaluated. To probe this\nability, we propose three new logical reasoning datasets named \"ReClor-plus\",\n\"LogiQA-plus\" and \"LogiQAv2-plus\", each featuring three subsets: the first with\nrandomly shuffled options, the second with the correct choices replaced by\n\"none of the other options are correct\", and a combination of the previous two\nsubsets. We carry out experiments on these datasets with both discriminative\nand generative LLMs and show that these simple tricks greatly hinder the\nperformance of the language models. Despite their superior performance on the\noriginal publicly available datasets, we find that all models struggle to\nanswer our newly constructed datasets. We show that introducing task variations\nby perturbing a sizable training set can markedly improve the model's\ngeneralisation and robustness in logical reasoning tasks. Moreover, applying\nlogic-driven data augmentation for fine-tuning, combined with prompting can\nenhance the generalisation performance of both discriminative large language\nmodels and generative large language models. These results offer insights into\nassessing and improving the generalisation and robustness of large language\nmodels for logical reasoning tasks. We make our source code and data publicly\navailable\n\\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1\">Gael Gendron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1\">Alex Yuxuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_N/0/1/0/all/0/1\">Neset Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiamou Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reward-Augmented Decoding: Efficient Controlled Text Generation With a Unidirectional Reward Model. (arXiv:2310.09520v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09520","description":"<p>While large language models have proven effective in a huge range of\ndownstream applications, they often generate text that is problematic or lacks\na desired attribute. In this paper, we introduce Reward-Augmented Decoding\n(RAD), a text generation procedure that uses a small unidirectional reward\nmodel to encourage a language model to generate text that has certain\nproperties. Specifically, RAD uses the reward model to score generations as\nthey are produced and rescales sampling probabilities to favor high-reward\ntokens. By using a unidirectional reward model, RAD can cache activations from\nprior generation steps to decrease computational overhead. Through experiments\non generating non-toxic and sentiment-controlled text, we demonstrate that RAD\nperforms best among methods that change only the generation procedure and\nmatches the performance of state-of-the-art methods that involve re-training\nthe language model. We further validate that RAD is effective on very large\nlanguage models while incurring a minimal computational overhead.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Haikang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Expression Tree Decoding Strategy for Mathematical Equation Generation. (arXiv:2310.09619v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09619","description":"<p>Generating mathematical equations from natural language requires an accurate\nunderstanding of the relations among math expressions. Existing approaches can\nbe broadly categorized into token-level and expression-level generation. The\nformer treats equations as a mathematical language, sequentially generating\nmath tokens. Expression-level methods generate each expression one by one.\nHowever, each expression represents a solving step, and there naturally exist\nparallel or dependent relations between these steps, which are ignored by\ncurrent sequential methods. Therefore, we integrate tree structure into the\nexpression-level generation and advocate an expression tree decoding strategy.\nTo generate a tree with expression as its node, we employ a layer-wise parallel\ndecoding strategy: we decode multiple independent expressions (leaf nodes) in\nparallel at each layer and repeat parallel decoding layer by layer to\nsequentially generate these parent node expressions that depend on others.\nBesides, a bipartite matching algorithm is adopted to align multiple\npredictions with annotations for each layer. Experiments show our method\noutperforms other baselines, especially for these equations with complex\nstructures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yongliang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nong_Q/0/1/0/all/0/1\">Qingpeng Nong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zeqi Tan Yanna Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weiming Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Contextual Recognition In Automatic Speech Recognition Systems By Semantic Lattice Rescoring. (arXiv:2310.09680v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09680","description":"<p>Automatic Speech Recognition (ASR) has witnessed a profound research\ninterest. Recent breakthroughs have given ASR systems different prospects such\nas faithfully transcribing spoken language, which is a pivotal advancement in\nbuilding conversational agents. However, there is still an imminent challenge\nof accurately discerning context-dependent words and phrases. In this work, we\npropose a novel approach for enhancing contextual recognition within ASR\nsystems via semantic lattice processing leveraging the power of deep learning\nmodels in accurately delivering spot-on transcriptions across a wide variety of\nvocabularies and speaking styles. Our solution consists of using Hidden Markov\nModels and Gaussian Mixture Models (HMM-GMM) along with Deep Neural Networks\n(DNN) models integrating both language and acoustic modeling for better\naccuracy. We infused our network with the use of a transformer-based model to\nproperly rescore the word lattice achieving remarkable capabilities with a\npalpable reduction in Word Error Rate (WER). We demonstrate the effectiveness\nof our proposed framework on the LibriSpeech dataset with empirical analyses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sudarshan_A/0/1/0/all/0/1\">Ankitha Sudarshan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samuel_V/0/1/0/all/0/1\">Vinay Samuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1\">Parth Patwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amara_I/0/1/0/all/0/1\">Ibtihel Amara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for Multimodal Medical Diagnosis. (arXiv:2310.09909v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.09909","description":"<p>Driven by the large foundation models, the development of artificial\nintelligence has witnessed tremendous progress lately, leading to a surge of\ngeneral interest from the public. In this study, we aim to assess the\nperformance of OpenAI's newest model, GPT-4V(ision), specifically in the realm\nof multimodal medical diagnosis. Our evaluation encompasses 17 human body\nsystems, including Central Nervous System, Head and Neck, Cardiac, Chest,\nHematology, Hepatobiliary, Gastrointestinal, Urogenital, Gynecology,\nObstetrics, Breast, Musculoskeletal, Spine, Vascular, Oncology, Trauma,\nPediatrics, with images taken from 8 modalities used in daily clinic routine,\ne.g., X-ray, Computed Tomography (CT), Magnetic Resonance Imaging (MRI),\nPositron Emission Tomography (PET), Digital Subtraction Angiography (DSA),\nMammography, Ultrasound, and Pathology. We probe the GPT-4V's ability on\nmultiple clinical tasks with or without patent history provided, including\nimaging modality and anatomy recognition, disease diagnosis, report generation,\ndisease localisation.\n</p>\n<p>Our observation shows that, while GPT-4V demonstrates proficiency in\ndistinguishing between medical image modalities and anatomy, it faces\nsignificant challenges in disease diagnosis and generating comprehensive\nreports. These findings underscore that while large multimodal models have made\nsignificant advancements in computer vision and natural language processing, it\nremains far from being used to effectively support real-world medical\napplications and clinical decision-making.\n</p>\n<p>All images used in this report can be found in\nhttps://github.com/chaoyi-wu/GPT-4V_Medical_Evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chaoyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiayu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qiaoyu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Weike Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weixiong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoman Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Ziheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weidi Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLP for Crypto-Asset Regulation: A Roadmap. (arXiv:2310.10333v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2310.10333","description":"<p>In the rapidly evolving field of crypto-assets, white papers are essential\ndocuments for investor guidance, and are now subject to unprecedented content\nrequirements under the EU's Markets in Crypto-Assets Regulation (MiCAR).\nNatural Language Processing can serve as a powerful tool for both analyzing\nthese documents and assisting in regulatory compliance. This paper delivers two\ncontributions to the topic. First, we survey existing applications of textual\nanalysis to unregulated crypto-asset white papers, uncovering a research gap\nthat could be bridged with interdisciplinary collaboration. We then conduct an\nanalysis of the changes introduced by MiCAR, highlighting the opportunities and\nchallenges of integrating NLP within the new regulatory framework. The findings\nset the stage for further research, with the potential to benefit regulators,\ncrypto-asset issuers, and investors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Camassa_C/0/1/0/all/0/1\">Carolina Camassa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Defining implication relation for classical logic. (arXiv:1312.7832v10 [math.LO] CROSS LISTED)","link":"http://arxiv.org/abs/1312.7832","description":"<p>In classical logic, \"P implies Q\" is equivalent to \"not-P or Q\". It is well\nknown that the equivalence is problematic. Actually, from \"P implies Q\", \"not-P\nor Q\" can be inferred (\"Implication-to-disjunction\" is valid), while from\n\"not-P or Q\", \"P implies Q\" cannot be inferred in general\n(\"Disjunction-to-implication\" is not generally valid), so the equivalence\nbetween them is invalid in general. This work aims to remove exactly the\nincorrect Disjunction-to-implication from classical logic (CL). The paper\nproposes a logical system (IRL) with the expected properties: (1) CL is simply\nobtained by adding Disjunction-to-implication to IRL, and (2)\nDisjunction-to-implication is independent of IRL (either\nDisjunction-to-implication or its negation cannot be derived in IRL) in the\ngeneral case. In other words, IRL is just the system obtained by exactly\nremoving Disjunction-to-implication from CL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/math/1/au:+Fu_L/0/1/0/all/0/1\">Li Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-17T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}