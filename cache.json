{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-08T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Companion Animal Disease Diagnostics based on Literal-aware Medical Knowledge Graph Representation Learning. (arXiv:2309.03219v1 [cs.AI])","link":"http://arxiv.org/abs/2309.03219","description":"<p>Knowledge graph (KG) embedding has been used to benefit the diagnosis of\nanimal diseases by analyzing electronic medical records (EMRs), such as notes\nand veterinary records. However, learning representations to capture entities\nand relations with literal information in KGs is challenging as the KGs show\nheterogeneous properties and various types of literal information. Meanwhile,\nthe existing methods mostly aim to preserve graph structures surrounding target\nnodes without considering different types of literals, which could also carry\nsignificant information. In this paper, we propose a knowledge graph embedding\nmodel for the efficient diagnosis of animal diseases, which could learn various\ntypes of literal information and graph structure and fuse them into unified\nrepresentations, namely LiteralKG. Specifically, we construct a knowledge graph\nthat is built from EMRs along with literal information collected from various\nanimal hospitals. We then fuse different types of entities and node feature\ninformation into unified vector representations through gate networks. Finally,\nwe propose a self-supervised learning task to learn graph structure in pretext\ntasks and then towards various downstream tasks. Experimental results on link\nprediction tasks demonstrate that our model outperforms the baselines that\nconsist of state-of-the-art models. The source code is available at\nhttps://github.com/NSLab-CUK/LiteralKG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hoang_V/0/1/0/all/0/1\">Van Thuy Hoang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_S/0/1/0/all/0/1\">Sang Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sangmyeong Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jooho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1\">Luong Vuong Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_O/0/1/0/all/0/1\">O-Joun Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Examining the Effectiveness of Chatbots in Gathering Family History Information in Comparison to the Standard In-Person Interview-Based Approach. (arXiv:2309.03223v1 [cs.HC])","link":"http://arxiv.org/abs/2309.03223","description":"<p>One of the most common things that a genealogist is tasked with is the\ngathering of a person's initial family history, normally via in-person\ninterviews or with the use of a platform such as ancestry.com, as this can\nprovide a strong foundation upon which a genealogist may build. However, the\nability to conduct these interviews can often be hindered by both geographical\nconstraints and the technical proficiency of the interviewee, as the\ninterviewee in these types of interviews is most often an elderly person with a\nlower than average level of technical proficiency. With this in mind, this\nstudy presents what we believe, based on prior research, to be the first\nchatbot geared entirely towards the gathering of family histories, and explores\nthe viability of utilising such a chatbot by comparing the performance and\nusability of such a method with the aforementioned alternatives. With a\nchatbot-based approach, we show that, though the average time taken to conduct\nan interview may be longer than if the user had used ancestry.com or\nparticipated in an in-person interview, the number of mistakes made and the\nlevel of confusion from the user regarding the UI and process required is lower\nthan the other two methods. Note that the final metric regarding the user's\nconfusion is not applicable for the in-person interview sessions due to its\nlack of a UI. With refinement, we believe this use of a chatbot could be a\nvaluable tool for genealogists, especially when dealing with interviewees who\nare based in other countries where it is not possible to conduct an in-person\ninterview.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Drumm_K/0/1/0/all/0/1\">Kieron Drumm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vincent Tran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning a Patent-Informed Biomedical Knowledge Graph Reveals Technological Potential of Drug Repositioning Candidates. (arXiv:2309.03227v1 [cs.AI])","link":"http://arxiv.org/abs/2309.03227","description":"<p>Drug repositioning-a promising strategy for discovering new therapeutic uses\nfor existing drugs-has been increasingly explored in the computational science\nliterature using biomedical databases. However, the technological potential of\ndrug repositioning candidates has often been overlooked. This study presents a\nnovel protocol to comprehensively analyse various sources such as\npharmaceutical patents and biomedical databases, and identify drug\nrepositioning candidates with both technological potential and scientific\nevidence. To this end, first, we constructed a scientific biomedical knowledge\ngraph (s-BKG) comprising relationships between drugs, diseases, and genes\nderived from biomedical databases. Our protocol involves identifying drugs that\nexhibit limited association with the target disease but are closely located in\nthe s-BKG, as potential drug candidates. We constructed a patent-informed\nbiomedical knowledge graph (p-BKG) by adding pharmaceutical patent information.\nFinally, we developed a graph embedding protocol to ascertain the structure of\nthe p-BKG, thereby calculating the relevance scores of those candidates with\ntarget disease-related patents to evaluate their technological potential. Our\ncase study on Alzheimer's disease demonstrates its efficacy and feasibility,\nwhile the quantitative outcomes and systematic methods are expected to bridge\nthe gap between computational discoveries and successful market applications in\ndrug repositioning research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jegal_Y/0/1/0/all/0/1\">Yongseung Jegal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaewoong Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jiho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Ki-Su Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Seyoung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1\">Janghyeok Yoon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Implicit Design Choices and Their Impact on Emotion Recognition Model Development and Evaluation. (arXiv:2309.03238v1 [cs.LG])","link":"http://arxiv.org/abs/2309.03238","description":"<p>Emotion recognition is a complex task due to the inherent subjectivity in\nboth the perception and production of emotions. The subjectivity of emotions\nposes significant challenges in developing accurate and robust computational\nmodels. This thesis examines critical facets of emotion recognition, beginning\nwith the collection of diverse datasets that account for psychological factors\nin emotion production.\n</p>\n<p>To handle the challenge of non-representative training data, this work\ncollects the Multimodal Stressed Emotion dataset, which introduces controlled\nstressors during data collection to better represent real-world influences on\nemotion production. To address issues with label subjectivity, this research\ncomprehensively analyzes how data augmentation techniques and annotation\nschemes impact emotion perception and annotator labels. It further handles\nnatural confounding variables and variations by employing adversarial networks\nto isolate key factors like stress from learned emotion representations during\nmodel training. For tackling concerns about leakage of sensitive demographic\nvariables, this work leverages adversarial learning to strip sensitive\ndemographic information from multimodal encodings. Additionally, it proposes\noptimized sociological evaluation metrics aligned with cost-effective,\nreal-world needs for model testing.\n</p>\n<p>This research advances robust, practical emotion recognition through\nmultifaceted studies of challenges in datasets, labels, modeling, demographic\nand membership variable encoding in representations, and evaluation. The\ngroundwork has been laid for cost-effective, generalizable emotion recognition\nmodels that are less likely to encode sensitive demographic information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_M/0/1/0/all/0/1\">Mimansa Jaiswal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT Can Solve Mathematical Problems Without a Calculator. (arXiv:2309.03241v1 [cs.LG])","link":"http://arxiv.org/abs/2309.03241","description":"<p>Previous studies have typically assumed that large language models are unable\nto accurately perform arithmetic operations, particularly multiplication of &gt;8\ndigits, and operations involving decimals and fractions, without the use of\ncalculator tools. This paper aims to challenge this misconception. With\nsufficient training data, a 2 billion-parameter language model can accurately\nperform multi-digit arithmetic operations with almost 100% accuracy without\ndata leakage, significantly surpassing GPT-4 (whose multi-digit multiplication\naccuracy is only 4.3%). We also demonstrate that our MathGLM, fine-tuned from\nGLM-10B on a dataset with additional multi-step arithmetic operations and math\nproblems described in text, achieves similar performance to GPT-4 on a\n5,000-samples Chinese math problem test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Ming Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Q/0/1/0/all/0/1\">Qingsong Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhihuan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zehai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jinfeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter Efficient Audio Captioning With Faithful Guidance Using Audio-text Shared Latent Representation. (arXiv:2309.03340v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03340","description":"<p>There has been significant research on developing pretrained transformer\narchitectures for multimodal-to-text generation tasks. Albeit performance\nimprovements, such models are frequently overparameterized, hence suffer from\nhallucination and large memory footprint making them challenging to deploy on\nedge devices. In this paper, we address both these issues for the application\nof automated audio captioning. First, we propose a data augmentation technique\nfor generating hallucinated audio captions and show that similarity based on an\naudio-text shared latent space is suitable for detecting hallucination. Then,\nwe propose a parameter efficient inference time faithful decoding algorithm\nthat enables smaller audio captioning models with performance equivalent to\nlarger models trained with more data. During the beam decoding step, the\nsmaller model utilizes an audio-text shared latent representation to\nsemantically align the generated text with corresponding input audio. Faithful\nguidance is introduced into the beam probability by incorporating the cosine\nsimilarity between latent representation projections of greedy rolled out\nintermediate beams and audio clip. We show the efficacy of our algorithm on\nbenchmark datasets and evaluate the proposed scheme against baselines using\nconventional audio captioning and semantic similarity metrics while\nillustrating tradeoffs between performance and complexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Arvind Krishna Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yinyi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Visser_E/0/1/0/all/0/1\">Erik Visser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahfuz_R/0/1/0/all/0/1\">Rehana Mahfuz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoDia: A New Dataset for Romanian Dialect Identification from Speech. (arXiv:2309.03378v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03378","description":"<p>Dialect identification is a critical task in speech processing and language\ntechnology, enhancing various applications such as speech recognition, speaker\nverification, and many others. While most research studies have been dedicated\nto dialect identification in widely spoken languages, limited attention has\nbeen given to dialect identification in low-resource languages, such as\nRomanian. To address this research gap, we introduce RoDia, the first dataset\nfor Romanian dialect identification from speech. The RoDia dataset includes a\nvaried compilation of speech samples from five distinct regions of Romania,\ncovering both urban and rural environments, totaling 2 hours of manually\nannotated speech data. Along with our dataset, we introduce a set of\ncompetitive models to be used as baselines for future research. The top scoring\nmodel achieves a macro F1 score of 59.83% and a micro F1 score of 62.08%,\nindicating that the task is challenging. We thus believe that RoDia is a\nvaluable resource that will stimulate research aiming to address the challenges\nof Romanian dialect identification. We publicly release our dataset and code at\nhttps://github.com/codrut2/RoDia.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rotaru_C/0/1/0/all/0/1\">Codrut Rotaru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ristea_N/0/1/0/all/0/1\">Nicolae-Catalin Ristea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ionescu_R/0/1/0/all/0/1\">Radu Tudor Ionescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Optimizers. (arXiv:2309.03409v1 [cs.LG])","link":"http://arxiv.org/abs/2309.03409","description":"<p>Optimization is ubiquitous. While derivative-based algorithms have been\npowerful tools for various problems, the absence of gradient imposes challenges\non many real-world applications. In this work, we propose Optimization by\nPROmpting (OPRO), a simple and effective approach to leverage large language\nmodels (LLMs) as optimizers, where the optimization task is described in\nnatural language. In each optimization step, the LLM generates new solutions\nfrom the prompt that contains previously generated solutions with their values,\nthen the new solutions are evaluated and added to the prompt for the next\noptimization step. We first showcase OPRO on linear regression and traveling\nsalesman problems, then move on to prompt optimization where the goal is to\nfind instructions that maximize the task accuracy. With a variety of LLMs, we\ndemonstrate that the best prompts optimized by OPRO outperform human-designed\nprompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chengrun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yifeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models. (arXiv:2309.03412v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03412","description":"<p>Instruction tuning is essential for large language models (LLMs) to become\ninteractive. While many instruction tuning datasets exist in English, there is\na noticeable lack in other languages. Also, their effectiveness has not been\nwell verified in non-English languages. We construct a Japanese instruction\ndataset by expanding and filtering existing datasets and apply the dataset to a\nJapanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning\non both Japanese and English existing models using our instruction dataset. We\nevaluated these models from both quantitative and qualitative perspectives. As\na result, the effectiveness of Japanese instruction datasets is confirmed. The\nresults also indicate that even with relatively small LLMs, performances in\ndownstream tasks would be improved through instruction tuning. Our instruction\ndataset, tuned models, and implementation are publicly available online.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1\">Masahiro Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirano_M/0/1/0/all/0/1\">Masanori Hirano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaji_H/0/1/0/all/0/1\">Hiroki Sakaji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Open Information Extraction with Large Language Models: A Study on Demonstration Uncertainty. (arXiv:2309.03433v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03433","description":"<p>Open Information Extraction (OIE) task aims at extracting structured facts\nfrom unstructured text, typically in the form of (subject, relation, object)\ntriples. Despite the potential of large language models (LLMs) like ChatGPT as\na general task solver, they lag behind state-of-the-art (supervised) methods in\nOIE tasks due to two key issues. First, LLMs struggle to distinguish irrelevant\ncontext from relevant relations and generate structured output due to the\nrestrictions on fine-tuning the model. Second, LLMs generates responses\nautoregressively based on probability, which makes the predicted relations lack\nconfidence. In this paper, we assess the capabilities of LLMs in improving the\nOIE task. Particularly, we propose various in-context learning strategies to\nenhance LLM's instruction-following ability and a demonstration uncertainty\nquantification module to enhance the confidence of the generated relations. Our\nexperiments on three OIE benchmark datasets show that our approach holds its\nown against established supervised methods, both quantitatively and\nqualitatively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1\">Chen Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xujiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhengzhang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osaki_T/0/1/0/all/0/1\">Takao Osaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuda_K/0/1/0/all/0/1\">Katsushi Matsuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XGen-7B Technical Report. (arXiv:2309.03450v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03450","description":"<p>Large Language Models (LLMs) have become ubiquitous across various domains,\ntransforming the way we interact with information and conduct research.\nHowever, most high-performing LLMs remain confined behind proprietary walls,\nhindering scientific progress. Most open-source LLMs, on the other hand, are\nlimited in their ability to support longer sequence lengths, which is a key\nrequirement for many tasks that require inference over an input context. To\naddress this, we have trained XGen, a series of 7B parameter models on up to 8K\nsequence length for up to 1.5T tokens. We have also finetuned the XGen models\non public-domain instructional data, creating their instruction-tuned\ncounterparts (XGen-Inst). We open-source our models for both research\nadvancements and commercial applications. Our evaluation on standard benchmarks\nshows that XGen models achieve comparable or better results when compared with\nstate-of-the-art open-source LLMs. Our targeted evaluation on long sequence\nmodeling tasks shows the benefits of our 8K-sequence models over 2K-sequence\nopen-source LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nijkamp_E/0/1/0/all/0/1\">Erik Nijkamp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_H/0/1/0/all/0/1\">Hiroaki Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1\">Bo Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Congying Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_C/0/1/0/all/0/1\">Chen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vig_J/0/1/0/all/0/1\">Jesse Vig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1\">Philippe Laban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1\">Ben Krause</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purushwalkam_S/0/1/0/all/0/1\">Senthil Purushwalkam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1\">Tong Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kryscinski_W/0/1/0/all/0/1\">Wojciech Kry&#x15b;ci&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murakhovska_L/0/1/0/all/0/1\">Lidiya Murakhovs&#x27;ka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choubey_P/0/1/0/all/0/1\">Prafulla Kumar Choubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alex Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_L/0/1/0/all/0/1\">Lifu Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_M/0/1/0/all/0/1\">Meghana Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chien-Sheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Learning for Tangible Effects: Natural Language Processing for Uncovering the Illicit Massage Industry & Computer Vision for Tactile Sensing. (arXiv:2309.03470v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03470","description":"<p>I explore two questions in this thesis: how can computer science be used to\nfight human trafficking? And how can computer vision create a sense of touch?\n</p>\n<p>I use natural language processing (NLP) to monitor the United States illicit\nmassage industry (IMI), a multi-billion dollar industry that offers not just\ntherapeutic massages but also commercial sexual services. Employees of this\nindustry are often immigrant women with few job opportunities, leaving them\nvulnerable to fraud, coercion, and other facets of human trafficking.\nMonitoring spatiotemporal trends helps prevent trafficking in the IMI. By\ncreating datasets with three publicly-accessible websites: Google Places,\nRubmaps, and AMPReviews, combined with NLP techniques such as bag-of-words and\nWord2Vec, I show how to derive insights into the labor pressures and language\nbarriers that employees face, as well as the income, demographics, and societal\npressures affecting sex buyers. I include a call-to-action to other researchers\ngiven these datasets. I also consider how to creating synthetic financial data,\nwhich can aid with counter-trafficking in the banking sector. I use an\nagent-based model to create both tabular and payee-recipient graph data.\n</p>\n<p>I then consider the role of computer vision in making tactile sensors. I\nreport on a novel sensor, the Digger Finger, that adapts the Gelsight sensor to\nfinding objects in granular media. Changes include using a wedge shape to\nfacilitate digging, replacing the internal lighting LEDs with fluorescent\npaint, and adding a vibrator motor to counteract jamming. Finally, I also show\nhow to use a webcam and a printed reference marker, or fiducial, to create a\nlow-cost six-axis force-torque sensor. This sensor is up to a hundred times\nless expensive than commercial sensors, allowing for a wider range of\napplications. For this and earlier chapters I release design files and code as\nopen source.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_R/0/1/0/all/0/1\">Rui Ouyang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Anchor Learning Approach for Citation Field Learning. (arXiv:2309.03559v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03559","description":"<p>Citation field learning is to segment a citation string into fields of\ninterest such as author, title, and venue. Extracting such fields from\ncitations is crucial for citation indexing, researcher profile analysis, etc.\nUser-generated resources like academic homepages and Curriculum Vitae, provide\nrich citation field information. However, extracting fields from these\nresources is challenging due to inconsistent citation styles, incomplete\nsentence syntax, and insufficient training data. To address these challenges,\nwe propose a novel algorithm, CIFAL (citation field learning by anchor\nlearning), to boost the citation field learning performance. CIFAL leverages\nthe anchor learning, which is model-agnostic for any Pre-trained Language\nModel, to help capture citation patterns from the data of different citation\nstyles. The experiments demonstrate that CIFAL outperforms state-of-the-art\nmethods in citation field learning, achieving a 2.83% improvement in\nfield-level F1-scores. Extensive analysis of the results further confirms the\neffectiveness of CIFAL quantitatively and qualitatively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zilin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Borun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yimeng Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"All Labels Together: Low-shot Intent Detection with an Efficient Label Semantic Encoding Paradigm. (arXiv:2309.03563v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03563","description":"<p>In intent detection tasks, leveraging meaningful semantic information from\nintent labels can be particularly beneficial for few-shot scenarios. However,\nexisting few-shot intent detection methods either ignore the intent labels,\n(e.g. treating intents as indices) or do not fully utilize this information\n(e.g. only using part of the intent labels). In this work, we present an\nend-to-end One-to-All system that enables the comparison of an input utterance\nwith all label candidates. The system can then fully utilize label semantics in\nthis way. Experiments on three few-shot intent detection tasks demonstrate that\nOne-to-All is especially effective when the training resource is extremely\nscarce, achieving state-of-the-art performance in 1-, 3- and 5-shot settings.\nMoreover, we present a novel pretraining strategy for our model that utilizes\nindirect supervision from paraphrasing, enabling zero-shot cross-domain\ngeneralization on intent detection tasks. Our code is at\nhttps://github.com/jiangshdd/AllLablesTogethe.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jiangshu Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Congying Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1\">Tingting Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Efficacy of Supervised Learning vs Large Language Models for Identifying Cognitive Distortions and Suicidal Risks in Chinese Social Media. (arXiv:2309.03564v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03564","description":"<p>Large language models, particularly those akin to the rapidly progressing GPT\nseries, are gaining traction for their expansive influence. While there is keen\ninterest in their applicability within medical domains such as psychology,\ntangible explorations on real-world data remain scant. Concurrently, users on\nsocial media platforms are increasingly vocalizing personal sentiments; under\nspecific thematic umbrellas, these sentiments often manifest as negative\nemotions, sometimes escalating to suicidal inclinations. Timely discernment of\nsuch cognitive distortions and suicidal risks is crucial to effectively\nintervene and potentially avert dire circumstances. Our study ventured into\nthis realm by experimenting on two pivotal tasks: suicidal risk and cognitive\ndistortion identification on Chinese social media platforms. Using supervised\nlearning as a baseline, we examined and contrasted the efficacy of large\nlanguage models via three distinct strategies: zero-shot, few-shot, and\nfine-tuning. Our findings revealed a discernible performance gap between the\nlarge language models and traditional supervised learning approaches, primarily\nattributed to the models' inability to fully grasp subtle categories. Notably,\nwhile GPT-4 outperforms its counterparts in multiple scenarios, GPT-3.5 shows\nsignificant enhancement in suicide risk classification after fine-tuning. To\nour knowledge, this investigation stands as the maiden attempt at gauging large\nlanguage models on Chinese social media tasks. This study underscores the\nforward-looking and transformative implications of using large language models\nin the field of psychology. It lays the groundwork for future applications in\npsychological research and practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Hongzhi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Changwei Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_W/0/1/0/all/0/1\">Wei Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1\">Dan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shuo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yi Jing Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1\">Huijing Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bing Xiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1\">Guanghui Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Loquacity and Visible Emotion: ChatGPT as a Policy Advisor. (arXiv:2309.03595v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03595","description":"<p>ChatGPT, a software seeking to simulate human conversational abilities, is\nattracting increasing attention. It is sometimes portrayed as a groundbreaking\nproductivity aid, including for creative work. In this paper, we run an\nexperiment to assess its potential in complex writing tasks. We ask the\nsoftware to compose a policy brief for the Board of the Bank of Italy. We find\nthat ChatGPT can accelerate workflows by providing well-structured content\nsuggestions, and by producing extensive, linguistically correct text in a\nmatter of seconds. It does, however, require a significant amount of expert\nsupervision, which partially offsets productivity gains. If the app is used\nnaively, output can be incorrect, superficial, or irrelevant. Superficiality is\nan especially problematic limitation in the context of policy advice intended\nfor high-level audiences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Biancotti_C/0/1/0/all/0/1\">Claudia Biancotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camassa_C/0/1/0/all/0/1\">Carolina Camassa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating ChatGPT as a Recommender System: A Rigorous Approach. (arXiv:2309.03613v1 [cs.IR])","link":"http://arxiv.org/abs/2309.03613","description":"<p>Recent popularity surrounds large AI language models due to their impressive\nnatural language capabilities. They contribute significantly to\nlanguage-related tasks, including prompt-based learning, making them valuable\nfor various specific tasks. This approach unlocks their full potential,\nenhancing precision and generalization. Research communities are actively\nexploring their applications, with ChatGPT receiving recognition. Despite\nextensive research on large language models, their potential in recommendation\nscenarios still needs to be explored. This study aims to fill this gap by\ninvestigating ChatGPT's capabilities as a zero-shot recommender system. Our\ngoals include evaluating its ability to use user preferences for\nrecommendations, reordering existing recommendation lists, leveraging\ninformation from similar users, and handling cold-start situations. We assess\nChatGPT's performance through comprehensive experiments using three datasets\n(MovieLens Small, Last.FM, and Facebook Book). We compare ChatGPT's performance\nagainst standard recommendation algorithms and other large language models,\nsuch as GPT-3.5 and PaLM-2. To measure recommendation effectiveness, we employ\nwidely-used evaluation metrics like Mean Average Precision (MAP), Recall,\nPrecision, F1, normalized Discounted Cumulative Gain (nDCG), Item Coverage,\nExpected Popularity Complement (EPC), Average Coverage of Long Tail (ACLT),\nAverage Recommendation Popularity (ARP), and Popularity-based Ranking-based\nEqual Opportunity (PopREO). Through thoroughly exploring ChatGPT's abilities in\nrecommender systems, our study aims to contribute to the growing body of\nresearch on the versatility and potential applications of large language\nmodels. Our experiment code is available on the GitHub repository:\nhttps://github.com/sisinflab/Recommender-ChatGPT\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Palma_D/0/1/0/all/0/1\">Dario Di Palma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biancofiore_G/0/1/0/all/0/1\">Giovanni Maria Biancofiore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1\">Vito Walter Anelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narducci_F/0/1/0/all/0/1\">Fedelucio Narducci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1\">Tommaso Di Noia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sciascio_E/0/1/0/all/0/1\">Eugenio Di Sciascio</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BNS-Net: A Dual-channel Sarcasm Detection Method Considering Behavior-level and Sentence-level Conflicts. (arXiv:2309.03658v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03658","description":"<p>Sarcasm detection is a binary classification task that aims to determine\nwhether a given utterance is sarcastic. Over the past decade, sarcasm detection\nhas evolved from classical pattern recognition to deep learning approaches,\nwhere features such as user profile, punctuation and sentiment words have been\ncommonly employed for sarcasm detection. In real-life sarcastic expressions,\nbehaviors without explicit sentimental cues often serve as carriers of implicit\nsentimental meanings. Motivated by this observation, we proposed a dual-channel\nsarcasm detection model named BNS-Net. The model considers behavior and\nsentence conflicts in two channels. Channel 1: Behavior-level Conflict Channel\nreconstructs the text based on core verbs while leveraging the modified\nattention mechanism to highlight conflict information. Channel 2:\nSentence-level Conflict Channel introduces external sentiment knowledge to\nsegment the text into explicit and implicit sentences, capturing conflicts\nbetween them. To validate the effectiveness of BNS-Net, several comparative and\nablation experiments are conducted on three public sarcasm datasets. The\nanalysis and evaluation of experimental results demonstrate that the BNS-Net\neffectively identifies sarcasm in text and achieves the state-of-the-art\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Liming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaowei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaodong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring an LM to generate Prolog Predicates from Mathematics Questions. (arXiv:2309.03667v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03667","description":"<p>Recently, there has been a surge in interest in NLP driven by ChatGPT.\nChatGPT, a transformer-based generative language model of substantial scale,\nexhibits versatility in performing various tasks based on natural language.\nNevertheless, large language models often exhibit poor performance in solving\nmathematics questions that require reasoning. Prior research has demonstrated\nthe effectiveness of chain-of-thought prompting in enhancing reasoning\ncapabilities. Now, we aim to investigate whether fine-tuning a model for the\ngeneration of Prolog codes, a logic language, and subsequently passing these\ncodes to a compiler can further improve accuracy. Consequently, we employ\nchain-of-thought to fine-tune LLaMA7B as a baseline model and develop other\nfine-tuned LLaMA7B models for the generation of Prolog code, Prolog code +\nchain-of-thought, and chain-of-thought + Prolog code, respectively. The results\nreveal that the Prolog generation model surpasses the baseline in performance,\nwhile the combination generation models do not yield significant improvements.\nThe Prolog corpus based on GSM8K and the correspondingly finetuned Prolog\ngeneration model based on LLaMA7B are released to the research community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaocheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_Y/0/1/0/all/0/1\">Yik-Cheung Tam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Word segmentation granularity in Korean. (arXiv:2309.03713v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03713","description":"<p>This paper describes word {segmentation} granularity in Korean language\nprocessing. From a word separated by blank space, which is termed an eojeol, to\na sequence of morphemes in Korean, there are multiple possible levels of word\nsegmentation granularity in Korean. For specific language processing and corpus\nannotation tasks, several different granularity levels have been proposed and\nutilized, because the agglutinative languages including Korean language have a\none-to-one mapping between functional morpheme and syntactic category. Thus, we\nanalyze these different granularity levels, presenting the examples of Korean\nlanguage processing systems for future reference. Interestingly, the\ngranularity by separating only functional morphemes including case markers and\nverbal endings, and keeping other suffixes for morphological derivation results\nin the optimal performance for phrase structure parsing. This contradicts\nprevious best practices for Korean language processing, which has been the de\nfacto standard for various applications that require separating all morphemes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungyeul Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Mija Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Daunting Dilemma with Sentence Encoders: Success on Standard Benchmarks, Failure in Capturing Basic Semantic Properties. (arXiv:2309.03747v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03747","description":"<p>In this paper, we adopted a retrospective approach to examine and compare\nfive existing popular sentence encoders, i.e., Sentence-BERT, Universal\nSentence Encoder (USE), LASER, InferSent, and Doc2vec, in terms of their\nperformance on downstream tasks versus their capability to capture basic\nsemantic properties. Initially, we evaluated all five sentence encoders on the\npopular SentEval benchmark and found that multiple sentence encoders perform\nquite well on a variety of popular downstream tasks. However, being unable to\nfind a single winner in all cases, we designed further experiments to gain a\ndeeper understanding of their behavior. Specifically, we proposed four semantic\nevaluation criteria, i.e., Paraphrasing, Synonym Replacement, Antonym\nReplacement, and Sentence Jumbling, and evaluated the same five sentence\nencoders using these criteria. We found that the Sentence-Bert and USE models\npass the paraphrasing criterion, with SBERT being the superior between the two.\nLASER dominates in the case of the synonym replacement criterion.\nInterestingly, all the sentence encoders failed the antonym replacement and\njumbling criteria. These results suggest that although these popular sentence\nencoders perform quite well on the SentEval benchmark, they still struggle to\ncapture some basic semantic properties, thus, posing a daunting dilemma in NLP\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_Y/0/1/0/all/0/1\">Yash Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_N/0/1/0/all/0/1\">Naman Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmaker_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker</a> (&quot;Santu&quot;)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Pipeline-Based Conversational Agents with Large Language Models. (arXiv:2309.03748v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03748","description":"<p>The latest advancements in AI and deep learning have led to a breakthrough in\nlarge language model (LLM)-based agents such as GPT-4. However, many commercial\nconversational agent development tools are pipeline-based and have limitations\nin holding a human-like conversation. This paper investigates the capabilities\nof LLMs to enhance pipeline-based conversational agents during two phases: 1)\nin the design and development phase and 2) during operations. In 1) LLMs can\naid in generating training data, extracting entities and synonyms,\nlocalization, and persona design. In 2) LLMs can assist in contextualization,\nintent classification to prevent conversational breakdown and handle\nout-of-scope questions, auto-correcting utterances, rephrasing responses,\nformulating disambiguation questions, summarization, and enabling closed\nquestion-answering capabilities. We conducted informal experiments with GPT-4\nin the private banking domain to demonstrate the scenarios above with a\npractical example. Companies may be hesitant to replace their pipeline-based\nagents with LLMs entirely due to privacy concerns and the need for deep\nintegration within their existing ecosystems. A hybrid approach in which LLMs'\nare integrated into the pipeline-based agents allows them to save time and\ncosts of building and running agents by capitalizing on the capabilities of\nLLMs while retaining the integration and privacy safeguards of their existing\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Foosherian_M/0/1/0/all/0/1\">Mina Foosherian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purwins_H/0/1/0/all/0/1\">Hendrik Purwins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rathnayake_P/0/1/0/all/0/1\">Purna Rathnayake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1\">Touhidul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teimao_R/0/1/0/all/0/1\">Rui Teimao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thoben_K/0/1/0/all/0/1\">Klaus-Dieter Thoben</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"USA: Universal Sentiment Analysis Model & Construction of Japanese Sentiment Text Classification and Part of Speech Dataset. (arXiv:2309.03787v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03787","description":"<p>Sentiment analysis is a pivotal task in the domain of natural language\nprocessing. It encompasses both text-level sentiment polarity classification\nand word-level Part of Speech(POS) sentiment polarity determination. Such\nanalysis challenges models to understand text holistically while also\nextracting nuanced information. With the rise of Large Language Models(LLMs),\nnew avenues for sentiment analysis have opened. This paper proposes enhancing\nperformance by leveraging the Mutual Reinforcement Effect(MRE) between\nindividual words and the overall text. It delves into how word polarity\ninfluences the overarching sentiment of a passage. To support our research, we\nannotated four novel Sentiment Text Classification and Part of Speech(SCPOS)\ndatasets, building upon existing sentiment classification datasets.\nFurthermore, we developed a Universal Sentiment Analysis(USA) model, with a\n7-billion parameter size. Experimental results revealed that our model\nsurpassed the performance of gpt-3.5-turbo across all four datasets,\nunderscoring the significance of MRE in sentiment analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chengguang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Tatsunori Mori</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncovering Drift in Textual Data: An Unsupervised Method for Detecting and Mitigating Drift in Machine Learning Models. (arXiv:2309.03831v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03831","description":"<p>Drift in machine learning refers to the phenomenon where the statistical\nproperties of data or context, in which the model operates, change over time\nleading to a decrease in its performance. Therefore, maintaining a constant\nmonitoring process for machine learning model performance is crucial in order\nto proactively prevent any potential performance regression. However,\nsupervised drift detection methods require human annotation and consequently\nlead to a longer time to detect and mitigate the drift. In our proposed\nunsupervised drift detection method, we follow a two step process. Our first\nstep involves encoding a sample of production data as the target distribution,\nand the model training data as the reference distribution. In the second step,\nwe employ a kernel-based statistical test that utilizes the maximum mean\ndiscrepancy (MMD) distance metric to compare the reference and target\ndistributions and estimate any potential drift. Our method also identifies the\nsubset of production data that is the root cause of the drift. The models\nretrained using these identified high drift samples show improved performance\non online customer experience quality metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1\">Saeed Khaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aditya_A/0/1/0/all/0/1\">Akhouri Abhinav Aditya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karnin_Z/0/1/0/all/0/1\">Zohar Karnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_O/0/1/0/all/0/1\">Olivia Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrashekar_S/0/1/0/all/0/1\">Samarth Marudheri Chandrashekar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FLM-101B: An Open LLM and How to Train It with $100K Budget. (arXiv:2309.03852v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03852","description":"<p>Large language models (LLMs) have achieved remarkable success in NLP and\nmultimodal tasks. Despite these successes, their development faces two main\nchallenges: (i) high computational cost; and (ii) difficulty in conducting fair\nand objective evaluations. LLMs are prohibitively expensive, making it feasible\nfor only a few major players to undertake their training, thereby constraining\nboth research and application opportunities. This underscores the importance of\ncost-effective LLM training. In this paper, we utilize a growth strategy to\nsignificantly reduce LLM training cost. We demonstrate that an LLM with 101B\nparameters and 0.31TB tokens can be trained on a $100K budget. We also adopt a\nsystematic evaluation paradigm for the IQ evaluation of LLMs, in complement to\nexisting evaluations that focus more on knowledge-oriented abilities. We\nintroduce our benchmark including evaluations on important aspects of\nintelligence including symbolic mapping, itrule understanding, pattern mining,\nand anti-interference. Such evaluations minimize the potential impact of\nmemorization. Experimental results show that our model FLM-101B, trained with a\nbudget of $100K, achieves comparable performance to powerful and well-known\nmodels, eg GPT-3 and GLM-130B, especially in the IQ benchmark evaluations with\ncontexts unseen in training data. The checkpoint of FLM-101B will be\nopen-sourced at https://huggingface.co/CofeAI/FLM-101B.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yiqun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xuezhi Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xuying Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Siqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_P/0/1/0/all/0/1\">Peng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bowen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yequan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs. (arXiv:2309.03876v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03876","description":"<p>Instruction-tuned Large Language Models (LLMs) have recently showcased\nremarkable ability to generate fitting responses to natural language\ninstructions. However, an open research question concerns the inherent biases\nof trained models and their responses. For instance, if the data used to tune\nan LLM is dominantly written by persons with a specific political bias, we\nmight expect generated answers to share this bias. Current research work seeks\nto de-bias such models, or suppress potentially biased answers. With this\ndemonstration, we take a different view on biases in instruction-tuning: Rather\nthan aiming to suppress them, we aim to make them explicit and transparent. To\nthis end, we present OpinionGPT, a web demo in which users can ask questions\nand select all biases they wish to investigate. The demo will answer this\nquestion using a model fine-tuned on text representing each of the selected\nbiases, allowing side-by-side comparison. To train the underlying model, we\nidentified 11 different biases (political, geographic, gender, age) and derived\nan instruction-tuning corpus in which each answer was written by members of one\nof these demographics. This paper presents OpinionGPT, illustrates how we\ntrained the bias-aware model and showcases the web application (available at\nhttps://opiniongpt.informatik.hu-berlin.de).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Haller_P/0/1/0/all/0/1\">Patrick Haller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aynetdinov_A/0/1/0/all/0/1\">Ansar Aynetdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbik_A/0/1/0/all/0/1\">Alan Akbik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Introducing \"Forecast Utterance\" for Conversational Data Science. (arXiv:2309.03877v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03877","description":"<p>Envision an intelligent agent capable of assisting users in conducting\nforecasting tasks through intuitive, natural conversations, without requiring\nin-depth knowledge of the underlying machine learning (ML) processes. A\nsignificant challenge for the agent in this endeavor is to accurately\ncomprehend the user's prediction goals and, consequently, formulate precise ML\ntasks. In this paper, we take a pioneering step towards this ambitious goal by\nintroducing a new concept called Forecast Utterance and then focus on the\nautomatic and accurate interpretation of users' prediction goals from these\nutterances. Specifically, we frame the task as a slot-filling problem, where\neach slot corresponds to a specific aspect of the goal prediction task. We then\nemploy two zero-shot methods for solving the slot-filling task, namely: 1)\nEntity Extraction (EE), and 2) Question-Answering (QA) techniques. Our\nexperiments, conducted with three meticulously crafted data sets, validate the\nviability of our ambitious goal and demonstrate the effectiveness of both EE\nand QA techniques in interpreting Forecast Utterances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1\">Md Mahadi Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knipper_A/0/1/0/all/0/1\">Alex Knipper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karmaker_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker</a> (Santu)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Large Language Models' Selection Bias in Multi-Choice Questions. (arXiv:2309.03882v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03882","description":"<p>Multi-choice questions (MCQs) serve as a common yet important task format in\nthe research of large language models (LLMs). Our work shows that LLMs exhibit\nan inherent \"selection bias\" in MCQs, which refers to LLMs' preferences to\nselect options located at specific positions (like \"Option C\"). This bias is\nprevalent across various LLMs, making their performance vulnerable to option\nposition changes in MCQs. We identify that one primary cause resulting in\nselection bias is option numbering, i.e., the ID symbols A/B/C/D associated\nwith the options. To mitigate selection bias, we propose a new method called\nPriDe. PriDe first decomposes the observed model prediction distribution into\nan intrinsic prediction over option contents and a prior distribution over\noption IDs. It then estimates the prior by permutating option contents on a\nsmall number of test samples, which is used to debias the subsequent test\nsamples. We demonstrate that, as a label-free, inference-time method, PriDe\nachieves a more effective and computation-efficient debiasing than strong\nbaselines. We further show that the priors estimated by PriDe generalize well\nacross different domains, highlighting its practical potential in broader\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models. (arXiv:2309.03883v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03883","description":"<p>Despite their impressive capabilities, large language models (LLMs) are prone\nto hallucinations, i.e., generating content that deviates from facts seen\nduring pretraining. We propose a simple decoding strategy for reducing\nhallucinations with pretrained LLMs that does not require conditioning on\nretrieved external knowledge nor additional fine-tuning. Our approach obtains\nthe next-token distribution by contrasting the differences in logits obtained\nfrom projecting the later layers versus earlier layers to the vocabulary space,\nexploiting the fact that factual knowledge in an LLMs has generally been shown\nto be localized to particular transformer layers. We find that this Decoding by\nContrasting Layers (DoLa) approach is able to better surface factual knowledge\nand reduce the generation of incorrect facts. DoLa consistently improves the\ntruthfulness across multiple choices tasks and open-ended generation tasks, for\nexample improving the performance of LLaMA family models on TruthfulQA by\n12-17% absolute points, demonstrating its potential in making LLMs reliably\ngenerate truthful facts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yujia Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Hongyin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Audio Captioning via Audibility Guidance. (arXiv:2309.03884v1 [cs.SD])","link":"http://arxiv.org/abs/2309.03884","description":"<p>The task of audio captioning is similar in essence to tasks such as image and\nvideo captioning. However, it has received much less attention. We propose\nthree desiderata for captioning audio -- (i) fluency of the generated text,\n(ii) faithfulness of the generated text to the input audio, and the somewhat\nrelated (iii) audibility, which is the quality of being able to be perceived\nbased only on audio. Our method is a zero-shot method, i.e., we do not learn to\nperform captioning. Instead, captioning occurs as an inference process that\ninvolves three networks that correspond to the three desired qualities: (i) A\nLarge Language Model, in our case, for reasons of convenience, GPT-2, (ii) A\nmodel that provides a matching score between an audio file and a text, for\nwhich we use a multimodal matching network called ImageBind, and (iii) A text\nclassifier, trained using a dataset we collected automatically by instructing\nGPT-4 with prompts designed to direct the generation of both audible and\ninaudible sentences. We present our results on the AudioCap dataset,\ndemonstrating that audibility guidance significantly enhances performance\ncompared to the baseline, which lacks this objective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shaharabany_T/0/1/0/all/0/1\">Tal Shaharabany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaulov_A/0/1/0/all/0/1\">Ariel Shaulov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Function Interpretation Benchmark for Evaluating Interpretability Methods. (arXiv:2309.03886v1 [cs.CL])","link":"http://arxiv.org/abs/2309.03886","description":"<p>Labeling neural network submodules with human-legible descriptions is useful\nfor many downstream tasks: such descriptions can surface failures, guide\ninterventions, and perhaps even explain important model behaviors. To date,\nmost mechanistic descriptions of trained networks have involved small models,\nnarrowly delimited phenomena, and large amounts of human labor. Labeling all\nhuman-interpretable sub-computations in models of increasing size and\ncomplexity will almost certainly require tools that can generate and validate\ndescriptions automatically. Recently, techniques that use learned models\nin-the-loop for labeling have begun to gain traction, but methods for\nevaluating their efficacy are limited and ad-hoc. How should we validate and\ncompare open-ended labeling tools? This paper introduces FIND (Function\nINterpretation and Description), a benchmark suite for evaluating the building\nblocks of automated interpretability methods. FIND contains functions that\nresemble components of trained neural networks, and accompanying descriptions\nof the kind we seek to generate. The functions are procedurally constructed\nacross textual and numeric domains, and involve a range of real-world\ncomplexities, including noise, composition, approximation, and bias. We\nevaluate new and existing methods that use language models (LMs) to produce\ncode-based and language descriptions of function behavior. We find that an\noff-the-shelf LM augmented with only black-box access to functions can\nsometimes infer their structure, acting as a scientist by forming hypotheses,\nproposing experiments, and updating descriptions in light of new data. However,\nLM-based descriptions tend to capture global function behavior and miss local\ncorruptions. These results show that FIND will be useful for characterizing the\nperformance of more sophisticated interpretability methods before they are\napplied to real-world models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schwettmann_S/0/1/0/all/0/1\">Sarah Schwettmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaham_T/0/1/0/all/0/1\">Tamar Rott Shaham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Materzynska_J/0/1/0/all/0/1\">Joanna Materzynska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_N/0/1/0/all/0/1\">Neil Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1\">David Bau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1\">Antonio Torralba</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ImageBind-LLM: Multi-modality Instruction Tuning. (arXiv:2309.03905v1 [cs.MM])","link":"http://arxiv.org/abs/2309.03905","description":"<p>We present ImageBind-LLM, a multi-modality instruction tuning method of large\nlanguage models (LLMs) via ImageBind. Existing works mainly focus on language\nand image instruction tuning, different from which, our ImageBind-LLM can\nrespond to multi-modality conditions, including audio, 3D point clouds, video,\nand their embedding-space arithmetic by only image-text alignment training.\nDuring training, we adopt a learnable bind network to align the embedding space\nbetween LLaMA and ImageBind's image encoder. Then, the image features\ntransformed by the bind network are added to word tokens of all layers in\nLLaMA, which progressively injects visual instructions via an attention-free\nand zero-initialized gating mechanism. Aided by the joint embedding of\nImageBind, the simple image-text training enables our model to exhibit superior\nmulti-modality instruction-following capabilities. During inference, the\nmulti-modality inputs are fed into the corresponding ImageBind encoders, and\nprocessed by a proposed visual cache model for further cross-modal embedding\nenhancement. The training-free cache model retrieves from three million image\nfeatures extracted by ImageBind, which effectively mitigates the\ntraining-inference modality discrepancy. Notably, with our approach,\nImageBind-LLM can respond to instructions of diverse modalities and demonstrate\nsignificant language generation quality. Code is released at\nhttps://github.com/OpenGVLab/LLaMA-Adapter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiaming Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Renrui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wenqi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Han Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chris Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1\">Song Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Ziyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xudong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yafei Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoxin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiangyu Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Kernelized Concept Erasure. (arXiv:2201.12191v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2201.12191","description":"<p>The representation space of neural models for textual data emerges in an\nunsupervised manner during training. Understanding how those representations\nencode human-interpretable concepts is a fundamental problem. One prominent\napproach for the identification of concepts in neural representations is\nsearching for a linear subspace whose erasure prevents the prediction of the\nconcept from the representations. However, while many linear erasure algorithms\nare tractable and interpretable, neural networks do not necessarily represent\nconcepts in a linear manner. To identify non-linearly encoded concepts, we\npropose a kernelization of a linear minimax game for concept erasure. We\ndemonstrate that it is possible to prevent specific non-linear adversaries from\npredicting the concept. However, the protection does not transfer to different\nnonlinear adversaries. Therefore, exhaustively erasing a non-linearly encoded\nconcept remains an open problem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vargas_F/0/1/0/all/0/1\">Francisco Vargas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph. (arXiv:2212.05798v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.05798","description":"<p>Answering complex questions over textual resources remains a challenge,\nparticularly when dealing with nuanced relationships between multiple entities\nexpressed within natural-language sentences. To this end, curated knowledge\nbases (KBs) like YAGO, DBpedia, Freebase, and Wikidata have been widely used\nand gained great acceptance for question-answering (QA) applications in the\npast decade. While these KBs offer a structured knowledge representation, they\nlack the contextual diversity found in natural-language sources. To address\nthis limitation, BigText-QA introduces an integrated QA approach, which is able\nto answer questions based on a more redundant form of a knowledge graph (KG)\nthat organizes both structured and unstructured (i.e., \"hybrid\") knowledge in a\nunified graphical representation. Thereby, BigText-QA is able to combine the\nbest of both worlds$\\unicode{x2013}$a canonical set of named entities, mapped\nto a structured background KB (such as YAGO or Wikidata), as well as an open\nset of textual clauses providing highly diversified relational paraphrases with\nrich context information. Our experimental results demonstrate that BigText-QA\noutperforms DrQA, a neural-network-based QA system, and achieves competitive\nresults to QUEST, a graph-based unsupervised QA system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biryukov_M/0/1/0/all/0/1\">Maria Biryukov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Theobald_M/0/1/0/all/0/1\">Martin Theobald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_V/0/1/0/all/0/1\">Vinu Ellampallil Venugopal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Claim Optimization in Computational Argumentation. (arXiv:2212.08913v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08913","description":"<p>An optimal delivery of arguments is key to persuasion in any debate, both for\nhumans and for AI systems. This requires the use of clear and fluent claims\nrelevant to the given debate. Prior work has studied the automatic assessment\nof argument quality extensively. Yet, no approach actually improves the quality\nso far. To fill this gap, this paper proposes the task of claim optimization:\nto rewrite argumentative claims in order to optimize their delivery. As\nmultiple types of optimization are possible, we approach this task by first\ngenerating a diverse set of candidate claims using a large language model, such\nas BART, taking into account contextual information. Then, the best candidate\nis selected using various quality metrics. In automatic and human evaluation on\nan English-language corpus, our quality-based candidate selection outperforms\nseveral baselines, improving 60% of all claims (worsening 16% only). Follow-up\nanalyses reveal that, beyond copy editing, our approach often specifies claims\nwith details, whereas it adds less evidence than humans do. Moreover, its\ncapabilities generalize well to other domains, such as instructional texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Skitalinskaya_G/0/1/0/all/0/1\">Gabriella Skitalinskaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spliethover_M/0/1/0/all/0/1\">Maximilian Splieth&#xf6;ver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1\">Henning Wachsmuth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13592","description":"<p>While code-mixing is a common linguistic practice in many parts of the world,\ncollecting high-quality and low-cost code-mixed data remains a challenge for\nnatural language processing (NLP) research. The recent proliferation of Large\nLanguage Models (LLMs) compels one to ask: how capable are these systems in\ngenerating code-mixed data? In this paper, we explore prompting multilingual\nLLMs in a zero-shot manner to generate code-mixed data for seven languages in\nSouth East Asia (SEA), namely Indonesian, Malay, Chinese, Tagalog, Vietnamese,\nTamil, and Singlish. We find that publicly available multilingual\ninstruction-tuned models such as BLOOMZ and Flan-T5-XXL are incapable of\nproducing texts with phrases or clauses from different languages. ChatGPT\nexhibits inconsistent capabilities in generating code-mixed texts, wherein its\nperformance varies depending on the prompt template and language pairing. For\ninstance, ChatGPT generates fluent and natural Singlish texts (an English-based\ncreole spoken in Singapore), but for English-Tamil language pair, the system\nmostly produces grammatically incorrect or semantically meaningless utterances.\nFurthermore, it may erroneously introduce languages not specified in the\nprompt. Based on our investigation, existing multilingual LLMs exhibit a wide\nrange of proficiency in code-mixed data generation for SEA languages. As such,\nwe advise against using LLMs in this context without extensive human checks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yong_Z/0/1/0/all/0/1\">Zheng-Xin Yong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruochen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forde_J/0/1/0/all/0/1\">Jessica Zosa Forde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Skyler Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sutawika_L/0/1/0/all/0/1\">Lintang Sutawika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1\">Jan Christian Blaise Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1\">Long Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yin Lin Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solorio_T/0/1/0/all/0/1\">Thamar Solorio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structured Chain-of-Thought Prompting for Code Generation. (arXiv:2305.06599v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.06599","description":"<p>Large Language Models (LLMs) (e.g., ChatGPT) have shown impressive\nperformance in code generation. LLMs take prompts as inputs, and\nChain-of-Thought (CoT) prompting is the state-of-the-art prompting technique.\nCoT prompting asks LLMs first to generate CoTs (i.e., intermediate natural\nlanguage reasoning steps) and then output the code. However, CoT prompting is\ndesigned for natural language generation and has low accuracy in code\ngeneration.\n</p>\n<p>In this paper, we propose Structured CoTs (SCoTs) and present a novel\nprompting technique for code generation, named SCoT prompting. Our motivation\nis source code contains rich structural information and any code can be\ncomposed of three program structures (i.e., sequence, branch, and loop\nstructures). Intuitively, structured intermediate reasoning steps make for\nstructured source code. Thus, we ask LLMs to use program structures to build\nCoTs, obtaining SCoTs. Then, LLMs generate the final code based on SCoTs.\nCompared to CoT prompting, SCoT prompting explicitly constrains LLMs to think\nabout how to solve requirements from the view of source code and further the\nperformance of LLMs in code generation. We apply SCoT prompting to two LLMs\n(i.e., ChatGPT and Codex) and evaluate it on three benchmarks (i.e., HumanEval,\nMBPP, and MBCPP). (1) SCoT prompting outperforms the state-of-the-art baseline\n- CoT prompting by up to 13.79% in Pass@1. (2) Human evaluation shows human\ndevelopers prefer programs from SCoT prompting. (3) SCoT prompting is robust to\nexamples and achieves substantial improvements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongmin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering. (arXiv:2306.00526v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00526","description":"<p>Layout-aware pre-trained models has achieved significant progress on document\nimage question answering. They introduce extra learnable modules into existing\nlanguage models to capture layout information within document images from text\nbounding box coordinates obtained by OCR tools. However, extra modules\nnecessitate pre-training on extensive document images. This prevents these\nmethods from directly utilizing off-the-shelf instruction-tuning language\nfoundation models, which have recently shown promising potential in zero-shot\nlearning. Instead, in this paper, we find that instruction-tuning language\nmodels like Claude and ChatGPT can understand layout by spaces and line breaks.\nBased on this observation, we propose the LAyout and Task aware Instruction\nPrompt (LATIN-Prompt), which consists of layout-aware document content and\ntask-aware instruction. Specifically, the former uses appropriate spaces and\nline breaks to recover the layout information among text segments obtained by\nOCR tools, and the latter ensures that generated answers adhere to formatting\nrequirements. Moreover, we propose the LAyout and Task aware Instruction Tuning\n(LATIN-Tuning) to improve the performance of small instruction-tuning models\nlike Alpaca. Experimental results show that LATIN-Prompt enables zero-shot\nperformance of Claude and ChatGPT to be comparable to the fine-tuning\nperformance of SOTAs on document image question answering, and LATIN-Tuning\nenhances the zero-shot performance of Alpaca significantly. For example,\nLATIN-Prompt improves the performance of Claude and ChatGPT on DocVQA by 263%\nand 20% respectively. LATIN-Tuning improves the performance of Alpaca on DocVQA\nby 87.7%. Quantitative and qualitative analyses demonstrate the effectiveness\nof LATIN-Prompt and LATIN-Tuning. We provide the code in supplementary and will\nrelease it to facilitate future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases. (arXiv:2306.05301v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05301","description":"<p>Enabling large language models to utilize real-world tools effectively is\ncrucial for achieving embodied intelligence. Existing approaches to tool\nlearning have either primarily relied on extremely large language models, such\nas GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or\nutilized supervised learning to train limited scopes of tools on compact\nmodels. However, it remains uncertain whether smaller language models can\nachieve generalized tool-use abilities without tool-specific training. To\naddress this question, this paper introduces ToolAlpaca, a novel framework\ndesigned to automatically generate a diverse tool-use corpus and learn\ngeneralized tool-use abilities on compact language models with minimal human\nintervention. Specifically, ToolAlpaca first automatically creates a highly\ndiversified tool-use corpus by building a multi-agent simulation environment.\nThe corpus contains 3938 tool-use instances from more than 400 real-world tool\nAPIs spanning 50 distinct categories. Subsequently, the constructed corpus is\nemployed to fine-tune compact language models, resulting in two models, namely\nToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the\nability of these models to utilize previously unseen tools without specific\ntraining. Experimental results demonstrate that ToolAlpaca achieves effective\ngeneralized tool-use capabilities comparable to those of extremely large\nlanguage models like GPT-3.5, demonstrating that learning generalized tool-use\nability is feasible for compact language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1\">Qiaoyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Ziliang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Q/0/1/0/all/0/1\">Qiao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1\">Boxi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Max-Margin Token Selection in Attention Mechanism. (arXiv:2306.13596v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.13596","description":"<p>Attention mechanism is a central component of the transformer architecture\nwhich led to the phenomenal success of large language models. However, the\ntheoretical principles underlying the attention mechanism are poorly\nunderstood, especially its nonconvex optimization dynamics. In this work, we\nexplore the seminal softmax-attention model $f(\\boldsymbol{X})=\\langle\n\\boldsymbol{Xv}, \\texttt{softmax}(\\boldsymbol{XWp})\\rangle$, where\n$\\boldsymbol{X}$ is the token sequence and\n$(\\boldsymbol{v},\\boldsymbol{W},\\boldsymbol{p})$ are trainable parameters. We\nprove that running gradient descent on $\\boldsymbol{p}$, or equivalently\n$\\boldsymbol{W}$, converges in direction to a max-margin solution that\nseparates $\\textit{locally-optimal}$ tokens from non-optimal ones. This clearly\nformalizes attention as an optimal token selection mechanism. Remarkably, our\nresults are applicable to general data and precisely characterize\n$\\textit{optimality}$ of tokens in terms of the value embeddings\n$\\boldsymbol{Xv}$ and problem geometry. We also provide a broader\nregularization path analysis that establishes the margin maximizing nature of\nattention even for nonlinear prediction heads. When optimizing $\\boldsymbol{v}$\nand $\\boldsymbol{p}$ simultaneously with logistic loss, we identify conditions\nunder which the regularization paths directionally converge to their respective\nhard-margin SVM solutions where $\\boldsymbol{v}$ separates the input features\nbased on their labels. Interestingly, the SVM formulation of $\\boldsymbol{p}$\nis influenced by the support vector geometry of $\\boldsymbol{v}$. Finally, we\nverify our theoretical findings via numerical experiments and provide insights.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuechen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Pre-Training of Large Language Models: How to (re)warm your model?. (arXiv:2308.04014v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04014","description":"<p>Large language models (LLMs) are routinely pre-trained on billions of tokens,\nonly to restart the process over again once new data becomes available. A much\ncheaper and more efficient solution would be to enable the continual\npre-training of these models, i.e. updating pre-trained models with new data\ninstead of re-training them from scratch. However, the distribution shift\ninduced by novel data typically results in degraded performance on past data.\nTaking a step towards efficient continual pre-training, in this work, we\nexamine the effect of different warm-up strategies. Our hypothesis is that the\nlearning rate must be re-increased to improve compute efficiency when training\non a new dataset. We study the warmup phase of models pre-trained on the Pile\n(upstream data, 300B tokens) as we continue to pre-train on SlimPajama\n(downstream data, 297B tokens), following a linear warmup and cosine decay\nschedule. We conduct all experiments on the Pythia 410M language model\narchitecture and evaluate performance through validation perplexity. We\nexperiment with different pre-training checkpoints, various maximum learning\nrates, and various warmup lengths. Our results show that while rewarming models\nfirst increases the loss on upstream and downstream data, in the longer run it\nimproves the downstream performance, outperforming models trained from\nscratch$\\unicode{x2013}$even for a large downstream dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kshitij Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Therien_B/0/1/0/all/0/1\">Benjamin Th&#xe9;rien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_A/0/1/0/all/0/1\">Adam Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richter_M/0/1/0/all/0/1\">Mats L. Richter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anthony_Q/0/1/0/all/0/1\">Quentin Anthony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belilovsky_E/0/1/0/all/0/1\">Eugene Belilovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1\">Irina Rish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1\">Timoth&#xe9;e Lesort</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Large Language Model based Autonomous Agents. (arXiv:2308.11432v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.11432","description":"<p>Autonomous agents have long been a prominent research focus in both academic\nand industry communities. Previous research in this field often focuses on\ntraining agents with limited knowledge within isolated environments, which\ndiverges significantly from human learning processes, and thus makes the agents\nhard to achieve human-like decisions. Recently, through the acquisition of vast\namounts of web knowledge, large language models (LLMs) have demonstrated\nremarkable potential in achieving human-level intelligence. This has sparked an\nupsurge in studies investigating LLM-based autonomous agents. In this paper, we\npresent a comprehensive survey of these studies, delivering a systematic review\nof the field of LLM-based autonomous agents from a holistic perspective. More\nspecifically, we first discuss the construction of LLM-based autonomous agents,\nfor which we propose a unified framework that encompasses a majority of the\nprevious work. Then, we present a comprehensive overview of the diverse\napplications of LLM-based autonomous agents in the fields of social science,\nnatural science, and engineering. Finally, we delve into the evaluation\nstrategies commonly used for LLM-based autonomous agents. Based on the previous\nstudies, we also present several challenges and future directions in this\nfield. To keep track of this field and continuously update our survey, we\nmaintain a repository of relevant references at\nhttps://github.com/Paitesanshi/LLM-Agent-Survey.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chen Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xueyang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zeyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingsen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiakai Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhewei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11764","description":"<p>Large Language Models (LLMs) have revolutionized Natural Language Processing\n(NLP). Although convenient for research and practical applications, open-source\nLLMs with fewer parameters often suffer from severe hallucinations compared to\ntheir larger counterparts. This paper focuses on measuring and reducing\nhallucinations in BLOOM 7B, a representative of such weaker open-source LLMs\nthat are publicly available for research and commercial applications. We\nintroduce HaloCheck, a lightweight BlackBox knowledge-free framework designed\nto quantify the severity of hallucinations in LLMs. Additionally, we explore\ntechniques like knowledge injection and teacher-student approaches to alleviate\nhallucinations in low-parameter LLMs. Our experiments effectively demonstrate\nthe reduction of hallucinations in challenging domains for these LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elaraby_M/0/1/0/all/0/1\">Mohamed Elaraby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1\">Mengyin Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dunn_J/0/1/0/all/0/1\">Jacob Dunn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xueying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shizhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_P/0/1/0/all/0/1\">Pingchuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZC3: Zero-Shot Cross-Language Code Clone Detection. (arXiv:2308.13754v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2308.13754","description":"<p>Developers introduce code clones to improve programming productivity. Many\nexisting studies have achieved impressive performance in monolingual code clone\ndetection. However, during software development, more and more developers write\nsemantically equivalent programs with different languages to support different\nplatforms and help developers translate projects from one language to another.\nConsidering that collecting cross-language parallel data, especially for\nlow-resource languages, is expensive and time-consuming, how designing an\neffective cross-language model that does not rely on any parallel data is a\nsignificant problem. In this paper, we propose a novel method named ZC3 for\nZero-shot Cross-language Code Clone detection. ZC3 designs the contrastive\nsnippet prediction to form an isomorphic representation space among different\nprogramming languages. Based on this, ZC3 exploits domain-aware learning and\ncycle consistency learning to further constrain the model to generate\nrepresentations that are aligned among different languages meanwhile are\ndiacritical for different types of clones. To evaluate our approach, we conduct\nextensive experiments on four representative cross-language clone detection\ndatasets. Experimental results show that ZC3 outperforms the state-of-the-art\nbaselines by 67.12%, 51.39%, 14.85%, and 53.01% on the MAP score, respectively.\nWe further investigate the representational distribution of different languages\nand discuss the effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chongyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EditSum: A Retrieve-and-Edit Framework for Source Code Summarization. (arXiv:2308.13775v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2308.13775","description":"<p>Existing studies show that code summaries help developers understand and\nmaintain source code. Unfortunately, these summaries are often missing or\noutdated in software projects. Code summarization aims to generate natural\nlanguage descriptions automatically for source code. Code summaries are highly\nstructured and have repetitive patterns. Besides the patternized words, a code\nsummary also contains important keywords, which are the key to reflecting the\nfunctionality of the code. However, the state-of-the-art approaches perform\npoorly on predicting the keywords, which leads to the generated summaries\nsuffering a loss in informativeness. To alleviate this problem, this paper\nproposes a novel retrieve-and-edit approach named EditSum for code\nsummarization. Specifically, EditSum first retrieves a similar code snippet\nfrom a pre-defined corpus and treats its summary as a prototype summary to\nlearn the pattern. Then, EditSum edits the prototype automatically to combine\nthe pattern in the prototype with the semantic information of input code. Our\nmotivation is that the retrieved prototype provides a good start-point for\npost-generation because the summaries of similar code snippets often have the\nsame pattern. The post-editing process further reuses the patternized words in\nthe prototype and generates keywords based on the semantic information of input\ncode. We conduct experiments on a large-scale Java corpus and experimental\nresults demonstrate that EditSum outperforms the state-of-the-art approaches by\na substantial margin. The human evaluation also proves the summaries generated\nby EditSum are more informative and useful. We also verify that EditSum\nperforms well on predicting the patternized words and keywords.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongmin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xin Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16137","description":"<p>In recent years, there have been remarkable advancements in the performance\nof Transformer-based Large Language Models (LLMs) across various domains. As\nthese LLMs are deployed for increasingly complex tasks, they often face the\nneed to conduct longer reasoning processes or understand larger contexts. In\nthese situations, the length generalization failure of LLMs on long sequences\nbecomes more prominent. Most pre-training schemes truncate training sequences\nto a fixed length. LLMs often struggle to generate fluent and coherent texts,\nlet alone carry out downstream tasks, after longer contexts, even with relative\npositional encoding designed to cope with this problem. Common solutions such\nas finetuning on longer corpora often involve daunting hardware and time costs\nand require careful training process design. To more efficiently leverage the\ngeneration capacity of existing LLMs, we theoretically and empirically\ninvestigate the main out-of-distribution (OOD) factors contributing to this\nproblem. Inspired by this diagnosis, we propose a simple yet effective solution\nfor on-the-fly length generalization, LM-Infinite. It involves only a\n$\\Lambda$-shaped attention mask (to avoid excessive attended tokens) and a\ndistance limit (to avoid unseen distances) while requiring no parameter updates\nor learning. We find it applicable to a variety of LLMs using relative-position\nencoding methods. LM-Infinite is computationally efficient with $O(n)$ time and\nspace, and demonstrates consistent text generation fluency and quality to as\nlong as 32k tokens on ArXiv and OpenWebText2 datasets, with 2.72x decoding\nspeedup. On downstream tasks such as passkey retrieval, it continues to work on\ninputs much longer than training lengths where vanilla models fail immediately.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection. (arXiv:2308.16763v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16763","description":"<p>Stance detection aims to identify the attitude expressed in a document\ntowards a given target. Techniques such as Chain-of-Thought (CoT) prompting\nhave advanced this task, enhancing a model's reasoning capabilities through the\nderivation of intermediate rationales. However, CoT relies primarily on a\nmodel's pre-trained internal knowledge during reasoning, thereby neglecting the\nvaluable external information that is previously unknown to the model. This\nomission, especially within the unsupervised reasoning process, can affect the\nmodel's overall performance. Moreover, while CoT enhances Large Language Models\n(LLMs), smaller LMs, though efficient operationally, face challenges in\ndelivering nuanced reasoning. In response to these identified gaps, we\nintroduce the Ladder-of-Thought (LoT) for the stance detection task.\nConstructed through a dual-phase Progressive Optimization Framework, LoT\ndirects the small LMs to assimilate high-quality external knowledge, refining\nthe intermediate rationales produced. These bolstered rationales subsequently\nserve as the foundation for more precise predictions - akin to how a ladder\nfacilitates reaching elevated goals. LoT achieves a balance between efficiency\nand performance. Our empirical evaluations underscore LoT's efficacy, marking a\n16% improvement over GPT-3.5 and a 10% enhancement compared to GPT-3.5 with CoT\non stance detection task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Kairui Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Joey Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor W. Tsang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_W/0/1/0/all/0/1\">Wen Haw Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yap_Y/0/1/0/all/0/1\">Yong Keong Yap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers as Support Vector Machines. (arXiv:2308.16898v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.16898","description":"<p>Since its inception in \"Attention Is All You Need\", transformer architecture\nhas led to revolutionary advancements in NLP. The attention layer within the\ntransformer admits a sequence of input tokens $X$ and makes them interact\nthrough pairwise similarities computed as softmax$(XQK^\\top X^\\top)$, where\n$(K,Q)$ are the trainable key-query parameters. In this work, we establish a\nformal equivalence between the optimization geometry of self-attention and a\nhard-margin SVM problem that separates optimal input tokens from non-optimal\ntokens using linear constraints on the outer-products of token pairs. This\nformalism allows us to characterize the implicit bias of 1-layer transformers\noptimized with gradient descent: (1) Optimizing the attention layer with\nvanishing regularization, parameterized by $(K,Q)$, converges in direction to\nan SVM solution minimizing the nuclear norm of the combined parameter\n$W=KQ^\\top$. Instead, directly parameterizing by $W$ minimizes a Frobenius norm\nobjective. We characterize this convergence, highlighting that it can occur\ntoward locally-optimal directions rather than global ones. (2) Complementing\nthis, we prove the local/global directional convergence of gradient descent\nunder suitable geometric conditions. Importantly, we show that\nover-parameterization catalyzes global convergence by ensuring the feasibility\nof the SVM problem and by guaranteeing a benign optimization landscape devoid\nof stationary points. (3) While our theory applies primarily to linear\nprediction heads, we propose a more general SVM equivalence that predicts the\nimplicit bias with nonlinear heads. Our findings are applicable to arbitrary\ndatasets and their validity is verified via experiments. We also introduce\nseveral open problems and research directions. We believe these findings\ninspire the interpretation of transformers as a hierarchy of SVMs that\nseparates and selects optimal tokens.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tarzanagh_D/0/1/0/all/0/1\">Davoud Ataee Tarzanagh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingcong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thrampoulidis_C/0/1/0/all/0/1\">Christos Thrampoulidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1\">Samet Oymak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00237","description":"<p>The development of large language models tailored for handling patients'\nclinical notes is often hindered by the limited accessibility and usability of\nthese notes due to strict privacy regulations. To address these challenges, we\nfirst create synthetic large-scale clinical notes using publicly available case\nreports extracted from biomedical literature. We then use these synthetic notes\nto train our specialized clinical large language model, Asclepius. While\nAsclepius is trained on synthetic data, we assess its potential performance in\nreal-world applications by evaluating it using real clinical notes. We\nbenchmark Asclepius against several other large language models, including\nGPT-3.5-turbo and other open-source alternatives. To further validate our\napproach using synthetic notes, we also compare Asclepius with its variants\ntrained on real clinical notes. Our findings convincingly demonstrate that\nsynthetic clinical notes can serve as viable substitutes for real ones when\nconstructing high-performing clinical language models. This conclusion is\nsupported by detailed evaluations conducted by both GPT-4 and medical\nprofessionals. All resources including weights, codes, and data used in the\ndevelopment of Asclepius are made publicly accessible for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kweon_S/0/1/0/all/0/1\">Sunjun Kweon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiyoun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Im_S/0/1/0/all/0/1\">Sujeong Im</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_E/0/1/0/all/0/1\">Eunbyeol Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Seongsu Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Jungwoo Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Gyubok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1\">Jong Hak Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1\">Seng Chan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1\">Seungjin Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chang Hoon Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_Y/0/1/0/all/0/1\">Yoon Bin Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_Y/0/1/0/all/0/1\">Yohan Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot information extraction from radiological reports using ChatGPT. (arXiv:2309.01398v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.01398","description":"<p>Electronic health records contain an enormous amount of valuable information,\nbut many are recorded in free text. Information extraction is the strategy to\ntransform the sequence of characters into structured data, which can be\nemployed for secondary analysis. However, the traditional information\nextraction components, such as named entity recognition and relation\nextraction, require annotated data to optimize the model parameters, which has\nbecome one of the major bottlenecks in building information extraction systems.\nWith the large language models achieving good performances on various\ndownstream NLP tasks without parameter tuning, it becomes possible to use large\nlanguage models for zero-shot information extraction. In this study, we aim to\nexplore whether the most popular large language model, ChatGPT, can extract\nuseful information from the radiological reports. We first design the prompt\ntemplate for the interested information in the CT reports. Then, we generate\nthe prompts by combining the prompt template with the CT reports as the inputs\nof ChatGPT to obtain the responses. A post-processing module is developed to\ntransform the responses into structured extraction results. We conducted the\nexperiments with 847 CT reports collected from Peking University Cancer\nHospital. The experimental results indicate that ChatGPT can achieve\ncompetitive performances for some extraction tasks compared with the baseline\ninformation extraction system, but some limitations need to be further\nimproved.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Danqing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaofeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xudong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Nan Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Wordle: A Microcosm of Life. Luck, Skill, Cheating, Loyalty, and Influence!. (arXiv:2309.02110v2 [math.HO] UPDATED)","link":"http://arxiv.org/abs/2309.02110","description":"<p>Wordle is a popular, online word game offered by the New York Times\n(nytimes.com). Currently there are some 2 million players of the English\nversion worldwide. Players have 6 attempts to guess the daily word (target\nword) and after each attempt, the player receives color-coded information about\nthe correctness and position of each letter in the guess. After either a\nsuccessful completion of the puzzle or the final unsuccessful attempt, software\ncan assess the player's luck and skill using Information Theory and can display\ndata for the first, second, ..., sixth guesses of a random sample of all\nplayers. Recently, I discovered that the latter data is presented in a format\nthat can easily be copied and pasted into a spreadsheet. I compiled data on\nWordle players' first guesses from May 2023 - August 2023 and inferred some\ninteresting information about Wordle players. A) Every day, about 0.2-0.5% of\nplayers solve the puzzle in one attempt. Because the odds of guessing the one\nof 2,315 possible target words at random is 0.043%, this implies that 4,000 -\n10,000 players cheat by obtaining the target word outside of playing the game!\nB) At least 1/3 of the players have a favorite starting word, or cycle through\nseveral. And even though players should be aware that target words are never\nrepeated, most players appear to remain loyal to their starting word even after\nits appearance as a target word. C) On August 15, 2023, about 30,000 players\nabruptly changed their starting word, presumably based on a crossword puzzle\nclue! Wordle players can be influenced! This study goes beyond social media\npostings, surveys, and Google Trends to provide solid, quantitative evidence\nabout cheating in Wordle.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/math/1/au:+Dilger_J/0/1/0/all/0/1\">James P. Dilger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automating Behavioral Testing in Machine Translation. (arXiv:2309.02553v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02553","description":"<p>Behavioral testing in NLP allows fine-grained evaluation of systems by\nexamining their linguistic capabilities through the analysis of input-output\nbehavior. Unfortunately, existing work on behavioral testing in Machine\nTranslation (MT) is currently restricted to largely handcrafted tests covering\na limited range of capabilities and languages. To address this limitation, we\npropose to use Large Language Models (LLMs) to generate a diverse set of source\nsentences tailored to test the behavior of MT models in a range of situations.\nWe can then verify whether the MT model exhibits the expected behavior through\nmatching candidate sets that are also generated using LLMs. Our approach aims\nto make behavioral testing of MT systems practical while requiring only minimal\nhuman effort. In our experiments, we apply our proposed evaluation framework to\nassess multiple available MT systems, revealing that while in general\npass-rates follow the trends observable from traditional accuracy-based\nmetrics, our method was able to uncover several important differences and\npotential bugs that go unnoticed when relying only on accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ferrando_J/0/1/0/all/0/1\">Javier Ferrando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperber_M/0/1/0/all/0/1\">Matthias Sperber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Setiawan_H/0/1/0/all/0/1\">Hendra Setiawan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telaar_D/0/1/0/all/0/1\">Dominic Telaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_S/0/1/0/all/0/1\">Sa&#x161;a Hasan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02706","description":"<p>Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable\ncapabilities across a wide range of tasks, however, the attention given to\nnon-English languages has been limited in this field of research. To address\nthis gap and assess the proficiency of language models in the Korean language\nand culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary,\nhistory, and general knowledge. Our evaluation of language models on this\nbenchmark highlights the potential advantages of employing Large\nLanguage-Specific Models(LLSMs) over a comprehensive, universal model like\nGPT-3.5. Remarkably, our study reveals that models approximately 13 times\nsmaller than GPT-3.5 can exhibit similar performance levels in terms of\nlanguage-specific knowledge retrieval. This observation underscores the\nimportance of homogeneous corpora for training professional-level\nlanguage-specific models. On the contrary, we also observe a perplexing\nperformance dip in these smaller LMs when they are tasked to generate\nstructured answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Son_G/0/1/0/all/0/1\">Guijin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hanwool Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Huiseo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jaecheol Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1\">Je Won Yeom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jihyu Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jung Woo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Songseong Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Large Language Models for Clinical Tasks. (arXiv:2309.02884v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02884","description":"<p>Large Language Models (LLMs) have demonstrated remarkable adaptability,\nshowcasing their capacity to excel in tasks for which they were not explicitly\ntrained. However, despite their impressive natural language processing (NLP)\ncapabilities, effective alignment of LLMs remains a crucial challenge when\ndeploying them for specific clinical applications. The ability to generate\nresponses with factually accurate content and to engage in non-trivial\nreasoning steps are crucial for the LLMs to be eligible for applications in\nclinical medicine. Employing a combination of techniques including\ninstruction-tuning and in-prompt strategies like few-shot and chain-of-thought\nprompting has significantly enhanced the performance of LLMs. Our proposed\nalignment strategy for medical question-answering, known as\n'expand-guess-refine', offers a parameter and data-efficient solution. A\npreliminary analysis of this method demonstrated outstanding performance,\nachieving a score of 70.63% on a subset of questions sourced from the USMLE\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manathunga_S/0/1/0/all/0/1\">Supun Manathunga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hettigoda_I/0/1/0/all/0/1\">Isuru Hettigoda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-07T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}