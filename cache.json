{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-11-13T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Experimental Evidence on Negative Impact of Generative AI on Scientific Learning Outcomes. (arXiv:2311.05629v1 [cs.CY])","link":"http://arxiv.org/abs/2311.05629","description":"<p>In this study, I explored the impact of Generative AI on learning efficacy in\nacademic reading materials using experimental methods. College-educated\nparticipants engaged in three cycles of reading and writing tasks. After each\ncycle, they responded to comprehension questions related to the material. After\nadjusting for background knowledge and demographic factors, complete reliance\non AI for writing tasks led to a 25.1% reduction in accuracy. In contrast,\nAI-assisted reading resulted in a 12% decline. Interestingly, using AI for\nsummarization significantly improved both quality and output. Accuracy\nexhibited notable variance in the AI-assisted section. Further analysis\nrevealed that individuals with a robust background in the reading topic and\nsuperior reading/writing skills benefitted the most. I conclude the research by\ndiscussing educational policy implications, emphasizing the need for educators\nto warn students about the dangers of over-dependence on AI and provide\nguidance on its optimal use in educational settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ju_Q/0/1/0/all/0/1\">Qirui Ju</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FinGPT: Large Generative Models for a Small Language. (arXiv:2311.05640v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05640","description":"<p>Large language models (LLMs) excel in many tasks in NLP and beyond, but most\nopen models have very limited coverage of smaller languages and LLM work tends\nto focus on languages where nearly unlimited data is available for pretraining.\nIn this work, we study the challenges of creating LLMs for Finnish, a language\nspoken by less than 0.1% of the world population. We compile an extensive\ndataset of Finnish combining web crawls, news, social media and eBooks. We\npursue two approaches to pretrain models: 1) we train seven monolingual models\nfrom scratch (186M to 13B parameters) dubbed FinGPT, 2) we continue the\npretraining of the multilingual BLOOM model on a mix of its original training\ndata and Finnish, resulting in a 176 billion parameter model we call BLUUMI.\nFor model evaluation, we introduce FIN-bench, a version of BIG-bench with\nFinnish tasks. We also assess other model qualities such as toxicity and bias.\nOur models and tools are openly available at https://turkunlp.org/gpt3-finnish.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luukkonen_R/0/1/0/all/0/1\">Risto Luukkonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komulainen_V/0/1/0/all/0/1\">Ville Komulainen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luoma_J/0/1/0/all/0/1\">Jouni Luoma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eskelinen_A/0/1/0/all/0/1\">Anni Eskelinen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanerva_J/0/1/0/all/0/1\">Jenna Kanerva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kupari_H/0/1/0/all/0/1\">Hanna-Mari Kupari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ginter_F/0/1/0/all/0/1\">Filip Ginter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laippala_V/0/1/0/all/0/1\">Veronika Laippala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piktus_A/0/1/0/all/0/1\">Aleksandra Piktus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Thomas Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tazi_N/0/1/0/all/0/1\">Nouamane Tazi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scao_T/0/1/0/all/0/1\">Teven Le Scao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_T/0/1/0/all/0/1\">Thomas Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suominen_O/0/1/0/all/0/1\">Osma Suominen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sairanen_S/0/1/0/all/0/1\">Samuli Sairanen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merioksa_M/0/1/0/all/0/1\">Mikko Merioksa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinonen_J/0/1/0/all/0/1\">Jyrki Heinonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vahtola_A/0/1/0/all/0/1\">Aija Vahtola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antao_S/0/1/0/all/0/1\">Samuel Antao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyysalo_S/0/1/0/all/0/1\">Sampo Pyysalo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs. (arXiv:2311.05657v1 [cs.AI])","link":"http://arxiv.org/abs/2311.05657","description":"<p>We introduce Lumos, a novel framework for training language agents that\nemploys a unified data format and a modular architecture based on open-source\nlarge language models (LLMs). Lumos consists of three distinct modules:\nplanning, grounding, and execution. The planning module breaks down a task into\na series of high-level, tool-agnostic subgoals, which are then made specific by\nthe grounding module through a set of low-level actions. These actions are\nsubsequently executed by the execution module, utilizing a range of\noff-the-shelf tools and APIs. In order to train these modules effectively,\nhigh-quality annotations of subgoals and actions were collected and are made\navailable for fine-tuning open-source LLMs for various tasks such as complex\nquestion answering, web tasks, and math problems. Leveraging this unified data\nand modular design, Lumos not only achieves comparable or superior performance\nto current, state-of-the-art agents, but also exhibits several key advantages:\n(1) Lumos surpasses GPT-4/3.5-based agents in complex question answering and\nweb tasks, while equalling the performance of significantly larger LLM agents\non math tasks; (2) Lumos outperforms open-source agents created through\nconventional training methods and those using chain-of-thoughts training; and\n(3) Lumos is capable of effectively generalizing to unseen interactive tasks,\noutperforming larger LLM-based agents and even exceeding performance of\nspecialized agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Da Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravichander_A/0/1/0/all/0/1\">Abhilasha Ravichander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt Engineering a Prompt Engineer. (arXiv:2311.05661v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05661","description":"<p>Prompt engineering is a challenging yet crucial task for optimizing the\nperformance of large language models (LLMs). It requires complex reasoning to\nexamine the model's errors, hypothesize what is missing or misleading in the\ncurrent prompt, and communicate the task with clarity. While recent works\nindicate that LLMs can be meta-prompted to perform automatic prompt\nengineering, their potentials may not be fully untapped due to the lack of\nsufficient guidance to elicit complex reasoning capabilities in LLMs in the\nmeta-prompt. In this work, we investigate the problem of \"prompt engineering a\nprompt engineer\" -- constructing a meta-prompt that more effectively guides\nLLMs to perform automatic prompt engineering. We introduce and analyze key\ncomponents, such as a step-by-step reasoning template and context\nspecification, which lead to improved performance. In addition, inspired by\ncommon optimization concepts such as batch size, step size and momentum, we\nintroduce their verbalized counterparts to the meta-prompt and investigate\ntheir effects. Our final method, named PE2, finds a prompt that outperforms\n\"let's think step by step\" by 6.3% on the MultiArith dataset and 3.1% on the\nGSM8K dataset. To demonstrate its versatility, we apply PE2 to the Instruction\nInduction benchmark, a suite of counterfactual tasks, and a lengthy, real-world\nindustrial prompt. In these settings, PE2 achieves strong performance and\noutperforms prior automatic prompt engineering baselines. Further, we show that\nPE2 makes meaningful and targeted prompt edits, amends erroneous or incomplete\nprompts, and presents non-trivial counterfactual reasoning abilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Axmed_M/0/1/0/all/0/1\">Maxamed Axmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khani_F/0/1/0/all/0/1\">Fereshte Khani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Long-Horizon Dialogue Understanding for Role Identification in the Game of Avalon with Large Language Models. (arXiv:2311.05720v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05720","description":"<p>Deception and persuasion play a critical role in long-horizon dialogues\nbetween multiple parties, especially when the interests, goals, and motivations\nof the participants are not aligned. Such complex tasks pose challenges for\ncurrent Large Language Models (LLM) as deception and persuasion can easily\nmislead them, especially in long-horizon multi-party dialogues. To this end, we\nexplore the game of Avalon: The Resistance, a social deduction game in which\nplayers must determine each other's hidden identities to complete their team's\nobjective. We introduce an online testbed and a dataset containing 20 carefully\ncollected and labeled games among human players that exhibit long-horizon\ndeception in a cooperative-competitive setting. We discuss the capabilities of\nLLMs to utilize deceptive long-horizon conversations between six human players\nto determine each player's goal and motivation. Particularly, we discuss the\nmultimodal integration of the chat between the players and the game's state\nthat grounds the conversation, providing further insights into the true player\nidentities. We find that even current state-of-the-art LLMs do not reach human\nperformance, making our dataset a compelling benchmark to investigate the\ndecision-making and language-processing capabilities of LLMs. Our dataset and\nonline testbed can be found at our project website:\nhttps://sstepput.github.io/Avalon-NLU/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stepputtis_S/0/1/0/all/0/1\">Simon Stepputtis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_J/0/1/0/all/0/1\">Joseph Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yaqi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhengyang Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxin Sharon Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangreji_S/0/1/0/all/0/1\">Sanketh Rangreji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Michael Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1\">Katia Sycara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficiently Adapting Pretrained Language Models To New Languages. (arXiv:2311.05741v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05741","description":"<p>Recent large language models (LLM) exhibit sub-optimal performance on\nlow-resource languages, as the training data of these models is usually\ndominated by English and other high-resource languages. Furthermore, it is\nchallenging to train models for low-resource languages, especially from\nscratch, due to a lack of high quality training data. Adapting pretrained LLMs\nreduces the need for data in the new language while also providing cross\nlingual transfer capabilities. However, naively adapting to new languages leads\nto catastrophic forgetting and poor tokenizer efficiency. In this work, we\nstudy how to efficiently adapt any existing pretrained LLM to a new language\nwithout running into these issues. In particular, we improve the encoding\nefficiency of the tokenizer by adding new tokens from the target language and\nstudy the data mixing recipe to mitigate forgetting. Our experiments on\nadapting an English LLM to Hungarian and Thai show that our recipe can reach\nbetter performance than open source models on the target language, with minimal\nregressions on English.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Csaki_Z/0/1/0/all/0/1\">Zoltan Csaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pawakapan_P/0/1/0/all/0/1\">Pian Pawakapan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakker_U/0/1/0/all/0/1\">Urmish Thakker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiantong Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging the Digital Divide: Performance Variation across Socio-Economic Factors in Vision-Language Models. (arXiv:2311.05746v1 [cs.CY])","link":"http://arxiv.org/abs/2311.05746","description":"<p>Despite the impressive performance of current AI models reported across\nvarious tasks, performance reports often do not include evaluations of how\nthese models perform on the specific groups that will be impacted by these\ntechnologies. Among the minority groups under-represented in AI, data from\nlow-income households are often overlooked in data collection and model\nevaluation. We evaluate the performance of a state-of-the-art vision-language\nmodel (CLIP) on a geo-diverse dataset containing household images associated\nwith different income values (Dollar Street) and show that performance\ninequality exists among households of different income levels. Our results\nindicate that performance for the poorer groups is consistently lower than the\nwealthier groups across various topics and countries. We highlight insights\nthat can help mitigate these issues and propose actionable steps for\neconomic-level inclusive AI development. Code is available at\nhttps://github.com/MichiganNLP/Bridging_the_Digital_Divide.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nwatu_J/0/1/0/all/0/1\">Joan Nwatu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ignat_O/0/1/0/all/0/1\">Oana Ignat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Natural Language Feature Learning for Interpretable Prediction. (arXiv:2311.05754v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05754","description":"<p>We propose a general method to break down a main complex task into a set of\nintermediary easier sub-tasks, which are formulated in natural language as\nbinary questions related to the final target task. Our method allows for\nrepresenting each example by a vector consisting of the answers to these\nquestions. We call this representation Natural Language Learned Features\n(NLLF). NLLF is generated by a small transformer language model (e.g., BERT)\nthat has been trained in a Natural Language Inference (NLI) fashion, using weak\nlabels automatically obtained from a Large Language Model (LLM). We show that\nthe LLM normally struggles for the main task using in-context learning, but can\nhandle these easiest subtasks and produce useful weak labels to train a BERT.\nThe NLI-like training of the BERT allows for tackling zero-shot inference with\nany binary question, and not necessarily the ones seen during the training. We\nshow that this NLLF vector not only helps to reach better performances by\nenhancing any classifier, but that it can be used as input of an\neasy-to-interpret machine learning model like a decision tree. This decision\ntree is interpretable but also reaches high performances, surpassing those of a\npre-trained transformer in some cases.We have successfully applied this method\nto two completely different tasks: detecting incoherence in students' answers\nto open-ended mathematics exam questions, and screening abstracts for a\nsystematic literature review of scientific papers on climate change and\nagroecology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Urrutia_F/0/1/0/all/0/1\">Felipe Urrutia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buc_C/0/1/0/all/0/1\">Cristian Buc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barriere_V/0/1/0/all/0/1\">Valentin Barriere</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chatbots Are Not Reliable Text Annotators. (arXiv:2311.05769v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05769","description":"<p>Recent research highlights the significant potential of ChatGPT for text\nannotation in social science research. However, ChatGPT is a closed-source\nproduct which has major drawbacks with regards to transparency,\nreproducibility, cost, and data protection. Recent advances in open-source (OS)\nlarge language models (LLMs) offer alternatives which remedy these challenges.\nThis means that it is important to evaluate the performance of OS LLMs relative\nto ChatGPT and standard approaches to supervised machine learning\nclassification. We conduct a systematic comparative evaluation of the\nperformance of a range of OS LLM models alongside ChatGPT, using both zero- and\nfew-shot learning as well as generic and custom prompts, with results compared\nto more traditional supervised classification models. Using a new dataset of\nTweets from US news media, and focusing on simple binary text annotation tasks\nfor standard social science concepts, we find significant variation in the\nperformance of ChatGPT and OS models across the tasks, and that supervised\nclassifiers consistently outperform both. Given the unreliable performance of\nChatGPT and the significant challenges it poses to Open Science we advise\nagainst using ChatGPT for substantive text annotation tasks in social science\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kristensen_McLachlan_R/0/1/0/all/0/1\">Ross Deans Kristensen-McLachlan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canavan_M/0/1/0/all/0/1\">Miceal Canavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardos_M/0/1/0/all/0/1\">M&#xe1;rton Kardos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jacobsen_M/0/1/0/all/0/1\">Mia Jacobsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aaroe_L/0/1/0/all/0/1\">Lene Aar&#xf8;e</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ADaPT: As-Needed Decomposition and Planning with Language Models. (arXiv:2311.05772v1 [cs.AI])","link":"http://arxiv.org/abs/2311.05772","description":"<p>Large Language Models (LLMs) are increasingly being used for interactive\ndecision-making tasks requiring planning and adapting to the environment.\nRecent works employ LLMs-as-agents in broadly two ways: iteratively determining\nthe next action (iterative executors) or generating plans and executing\nsub-tasks using LLMs (plan-and-execute). However, these methods struggle with\ntask complexity, as the inability to execute any sub-task may lead to task\nfailure. To address these shortcomings, we introduce As-Needed Decomposition\nand Planning for complex Tasks (ADaPT), an approach that explicitly plans and\ndecomposes complex sub-tasks as-needed, i.e., when the LLM is unable to execute\nthem. ADaPT recursively decomposes sub-tasks to adapt to both task complexity\nand LLM capability. Our results demonstrate that ADaPT substantially\noutperforms established strong baselines, achieving success rates up to 28.3%\nhigher in ALFWorld, 27% in WebShop, and 33% in TextCraft -- a novel\ncompositional dataset that we introduce. Through extensive analysis, we\nillustrate the importance of multilevel decomposition and establish that ADaPT\ndynamically adjusts to the capabilities of the executor LLM as well as to task\ncomplexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prasad_A/0/1/0/all/0/1\">Archiki Prasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koller_A/0/1/0/all/0/1\">Alexander Koller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartmann_M/0/1/0/all/0/1\">Mareike Hartmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging LLMs for Synthesizing Training Data Across Many Languages in Multilingual Dense Retrieval. (arXiv:2311.05800v1 [cs.IR])","link":"http://arxiv.org/abs/2311.05800","description":"<p>Dense retrieval models have predominantly been studied for English, where\nmodels have shown great success, due to the availability of human-labeled\ntraining pairs. However, there has been limited success for multilingual\nretrieval so far, as training data is uneven or scarcely available across\nmultiple languages. Synthetic training data generation is promising (e.g.,\nInPars or Promptagator), but has been investigated only for English. Therefore,\nto study model capabilities across both cross-lingual and monolingual retrieval\ntasks, we develop SWIM-IR, a synthetic retrieval training dataset containing 33\n(high to very-low resource) languages for training multilingual dense retrieval\nmodels without requiring any human supervision. To construct SWIM-IR, we\npropose SAP (summarize-then-ask prompting), where the large language model\n(LLM) generates a textual summary prior to the query generation step. SAP\nassists the LLM in generating informative queries in the target language. Using\nSWIM-IR, we explore synthetic fine-tuning of multilingual dense retrieval\nmodels and evaluate them robustly on three retrieval benchmarks: XOR-Retrieve\n(cross-lingual), XTREME-UP (cross-lingual) and MIRACL (monolingual). Our\nmodels, called SWIM-X, are competitive with human-supervised dense retrieval\nmodels, e.g., mContriever, finding that SWIM-IR can cheaply substitute for\nexpensive human-labeled retrieval training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_N/0/1/0/all/0/1\">Nandan Thakur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrego_G/0/1/0/all/0/1\">Gustavo Hern&#xe1;ndez &#xc1;brego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wieting_J/0/1/0/all/0/1\">John Wieting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cer_D/0/1/0/all/0/1\">Daniel Cer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CFBenchmark: Chinese Financial Assistant Benchmark for Large Language Model. (arXiv:2311.05812v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05812","description":"<p>Large language models (LLMs) have demonstrated great potential in the\nfinancial domain. Thus, it becomes important to assess the performance of LLMs\nin the financial tasks. In this work, we introduce CFBenchmark, to evaluate the\nperformance of LLMs for Chinese financial assistant. The basic version of\nCFBenchmark is designed to evaluate the basic ability in Chinese financial text\nprocessing from three aspects~(\\emph{i.e.} recognition, classification, and\ngeneration) including eight tasks, and includes financial texts ranging in\nlength from 50 to over 1,800 characters. We conduct experiments on several LLMs\navailable in the literature with CFBenchmark-Basic, and the experimental\nresults indicate that while some LLMs show outstanding performance in specific\ntasks, overall, there is still significant room for improvement in basic tasks\nof financial text processing with existing models. In the future, we plan to\nexplore the advanced version of CFBenchmark, aiming to further explore the\nextensive capabilities of language models in more profound dimensions as a\nfinancial assistant in Chinese. Our codes are released at\nhttps://github.com/TongjiFinLab/CFBenchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiangtong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Ming Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Junjie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1\">Dawei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1\">Zhijun Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Changjun Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let's Reinforce Step by Step. (arXiv:2311.05821v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05821","description":"<p>While recent advances have boosted LM proficiency in linguistic benchmarks,\nLMs consistently struggle to reason correctly on complex tasks like\nmathematics. We turn to Reinforcement Learning from Human Feedback (RLHF) as a\nmethod with which to shape model reasoning processes. In particular, we explore\ntwo reward schemes, outcome-supervised reward models (ORMs) and\nprocess-supervised reward models (PRMs), to optimize for logical reasoning. Our\nresults show that the fine-grained reward provided by PRM-based methods\nenhances accuracy on simple mathematical reasoning (GSM8K) while, unexpectedly,\nreducing performance in complex tasks (MATH). Furthermore, we show the critical\nrole reward aggregation functions play in model performance. Providing\npromising avenues for future research, our study underscores the need for\nfurther exploration into fine-grained reward modeling for more reliable\nlanguage models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Sarah Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lialin_V/0/1/0/all/0/1\">Vladislav Lialin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muckatira_S/0/1/0/all/0/1\">Sherin Muckatira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1\">Anna Rumshisky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Face-StyleSpeech: Improved Face-to-Voice latent mapping for Natural Zero-shot Speech Synthesis from a Face Image. (arXiv:2311.05844v1 [cs.CV])","link":"http://arxiv.org/abs/2311.05844","description":"<p>Generating a voice from a face image is crucial for developing virtual humans\ncapable of interacting using their unique voices, without relying on\npre-recorded human speech. In this paper, we propose Face-StyleSpeech, a\nzero-shot Text-To-Speech (TTS) synthesis model that generates natural speech\nconditioned on a face image rather than reference speech. We hypothesize that\nlearning both speaker identity and prosody from a face image poses a\nsignificant challenge. To address the issue, our TTS model incorporates both a\nface encoder and a prosody encoder. The prosody encoder is specifically\ndesigned to model prosodic features that are not captured only with a face\nimage, allowing the face encoder to focus solely on capturing the speaker\nidentity from the face image. Experimental results demonstrate that\nFace-StyleSpeech effectively generates more natural speech from a face image\nthan baselines, even for the face images the model has not trained. Samples are\nat our demo page https://face-stylespeech.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wooseok Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tamil-Llama: A New Tamil Language Model Based on Llama 2. (arXiv:2311.05845v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05845","description":"<p>Language modeling has witnessed remarkable advancements in recent years, with\nLarge Language Models (LLMs) like ChatGPT setting unparalleled benchmarks in\nhuman-like text generation. However, a prevailing limitation is the\nunderrepresentation of languages like Tamil in these cutting-edge models,\nleading to suboptimal performance in diverse linguistic contexts. This paper\naddresses this lacuna, enhancing the open-source LLaMA model with an addition\nof 16,000 Tamil tokens, aiming to achieve superior text generation and\ncomprehension in the Tamil language. We strategically employ the LoRA\nmethodology for efficient model training on a comprehensive Tamil corpus,\nensuring computational feasibility and model robustness. Moreover, we introduce\na Tamil-translated version of the Alpaca dataset and a subset of the OpenOrca\ndataset tailored for instruction fine-tuning. Our results showcase significant\nperformance improvements in Tamil text generation, with potential implications\nfor the broader landscape of LLMs in Indian languages. We further underscore\nour commitment to open research by making our models, datasets, and code\npublicly accessible, fostering further innovations in language modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Balachandran_A/0/1/0/all/0/1\">Abhinand Balachandran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications. (arXiv:2311.05876v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05876","description":"<p>Large language models (LLMs) exhibit superior performance on various natural\nlanguage tasks, but they are susceptible to issues stemming from outdated data\nand domain-specific limitations. In order to address these challenges,\nresearchers have pursued two primary strategies, knowledge editing and\nretrieval augmentation, to enhance LLMs by incorporating external information\nfrom different aspects. Nevertheless, there is still a notable absence of a\ncomprehensive survey. In this paper, we propose a review to discuss the trends\nin integration of knowledge and large language models, including taxonomy of\nmethods, benchmarks, and applications. In addition, we conduct an in-depth\nanalysis of different methods and point out potential research directions in\nthe future. We hope this survey offers the community quick access and a\ncomprehensive overview of this research area, with the intention of inspiring\nfuture research endeavors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhangyin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Weitao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Weijiang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qianglong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Weihua Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaocheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+liu_T/0/1/0/all/0/1\">Ting liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Citation Recommendation on Scholarly Legal Articles. (arXiv:2311.05902v1 [cs.IR])","link":"http://arxiv.org/abs/2311.05902","description":"<p>Citation recommendation is the task of finding appropriate citations based on\na given piece of text. The proposed datasets for this task consist mainly of\nseveral scientific fields, lacking some core ones, such as law. Furthermore,\ncitation recommendation is used within the legal domain to identify supporting\narguments, utilizing non-scholarly legal articles. In order to alleviate the\nlimitations of existing studies, we gather the first scholarly legal dataset\nfor the task of citation recommendation. Also, we conduct experiments with\nstate-of-the-art models and compare their performance on this dataset. The\nstudy suggests that, while BM25 is a strong benchmark for the legal citation\nrecommendation task, the most effective method involves implementing a two-step\nprocess that entails pre-fetching with BM25+, followed by re-ranking with\nSciNCL, which enhances the performance of the baseline from 0.26 to 0.30\nMAP@10. Moreover, fine-tuning leads to considerable performance increases in\npre-trained models, which shows the importance of including legal articles in\nthe training data of these models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arslan_D/0/1/0/all/0/1\">Do&#x11f;ukan Arslan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erdogan_S/0/1/0/all/0/1\">Saadet Sena Erdo&#x11f;an</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eryigit_G/0/1/0/all/0/1\">G&#xfc;l&#x15f;en Eryi&#x11f;it</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fake Alignment: Are LLMs Really Aligned Well?. (arXiv:2311.05915v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05915","description":"<p>The growing awareness of safety concerns in large language models (LLMs) has\nsparked considerable interest in the evaluation of safety within current\nresearch endeavors. This study investigates an interesting issue pertaining to\nthe evaluation of LLMs, namely the substantial discrepancy in performance\nbetween multiple-choice questions and open-ended questions. Inspired by\nresearch on jailbreak attack patterns, we argue this is caused by mismatched\ngeneralization. That is, the LLM does not have a comprehensive understanding of\nthe complex concept of safety. Instead, it only remembers what to answer for\nopen-ended safety questions, which makes it unable to solve other forms of\nsafety tests. We refer to this phenomenon as fake alignment and construct a\ncomparative benchmark to empirically verify its existence in LLMs. Such fake\nalignment renders previous evaluation protocols unreliable. To address this, we\nintroduce the FAEF framework and two novel metrics\\textemdash Consistency Score\n(CS) and Consistent Safety Score (CSS), which jointly assess two complementary\nforms of evaluation to quantify fake alignment and obtain corrected performance\nestimates. Applying FAEF to 14 widely-used LLMs reveals several models with\npurported safety are poorly aligned in practice. Our work highlights potential\nlimitations in prevailing alignment methodologies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yixu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Y/0/1/0/all/0/1\">Yan Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kexin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_C/0/1/0/all/0/1\">Chengqi Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xingjun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yingchun Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain of Thought with Explicit Evidence Reasoning for Few-shot Relation Extraction. (arXiv:2311.05922v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05922","description":"<p>Few-shot relation extraction involves identifying the type of relationship\nbetween two specific entities within a text, using a limited number of\nannotated samples. A variety of solutions to this problem have emerged by\napplying meta-learning and neural graph techniques which typically necessitate\na training process for adaptation. Recently, the strategy of in-context\nlearning has been demonstrating notable results without the need of training.\nFew studies have already utilized in-context learning for zero-shot information\nextraction. Unfortunately, the evidence for inference is either not considered\nor implicitly modeled during the construction of chain-of-thought prompts. In\nthis paper, we propose a novel approach for few-shot relation extraction using\nlarge language models, named CoT-ER, chain-of-thought with explicit evidence\nreasoning. In particular, CoT-ER first induces large language models to\ngenerate evidences using task-specific and concept-level knowledge. Then these\nevidences are explicitly incorporated into chain-of-thought prompting for\nrelation extraction. Experimental results demonstrate that our CoT-ER approach\n(with 0% training data) achieves competitive performance compared to the\nfully-supervised (with 100% training data) state-of-the-art approach on the\nFewRel1.0 and FewRel2.0 datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xilai Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based Models. (arXiv:2311.05928v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05928","description":"<p>In this study, we present an investigation into the anisotropy dynamics and\nintrinsic dimension of embeddings in transformer architectures, focusing on the\ndichotomy between encoders and decoders. Our findings reveal that the\nanisotropy profile in transformer decoders exhibits a distinct bell-shaped\ncurve, with the highest anisotropy concentrations in the middle layers. This\npattern diverges from the more uniformly distributed anisotropy observed in\nencoders. In addition, we found that the intrinsic dimension of embeddings\nincreases in the initial phases of training, indicating an expansion into\nhigher-dimensional space. Which is then followed by a compression phase towards\nthe end of training with dimensionality decrease, suggesting a refinement into\nmore compact representations. Our results provide fresh insights to the\nunderstanding of encoders and decoders embedding properties.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razzhigaev_A/0/1/0/all/0/1\">Anton Razzhigaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhalchuk_M/0/1/0/all/0/1\">Matvey Mikhalchuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goncharova_E/0/1/0/all/0/1\">Elizaveta Goncharova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1\">Ivan Oseledets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrov_D/0/1/0/all/0/1\">Denis Dimitrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznetsov_A/0/1/0/all/0/1\">Andrey Kuznetsov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Zero Shot Hypothesis Proposers. (arXiv:2311.05965v1 [cs.CL])","link":"http://arxiv.org/abs/2311.05965","description":"<p>Significant scientific discoveries have driven the progress of human\ncivilisation. The explosion of scientific literature and data has created\ninformation barriers across disciplines that have slowed the pace of scientific\ndiscovery. Large Language Models (LLMs) hold a wealth of global and\ninterdisciplinary knowledge that promises to break down these information\nbarriers and foster a new wave of scientific discovery. However, the potential\nof LLMs for scientific discovery has not been formally explored. In this paper,\nwe start from investigating whether LLMs can propose scientific hypotheses. To\nthis end, we construct a dataset consist of background knowledge and hypothesis\npairs from biomedical literature. The dataset is divided into training, seen,\nand unseen test sets based on the publication date to control visibility. We\nsubsequently evaluate the hypothesis generation capabilities of various\ntop-tier instructed models in zero-shot, few-shot, and fine-tuning settings,\nincluding both closed and open-source LLMs. Additionally, we introduce an\nLLM-based multi-agent cooperative framework with different role designs and\nexternal tools to enhance the capabilities related to generating hypotheses. We\nalso design four metrics through a comprehensive review to evaluate the\ngenerated hypotheses for both ChatGPT-based and human evaluations. Through\nexperiments and analyses, we arrive at the following findings: 1) LLMs\nsurprisingly generate untrained yet validated hypotheses from testing\nliterature. 2) Increasing uncertainty facilitates candidate generation,\npotentially enhancing zero-shot hypothesis generation capabilities. These\nfindings strongly support the potential of LLMs as catalysts for new scientific\ndiscoveries and guide further exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1\">Biqing Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoxiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_K/0/1/0/all/0/1\">Kai Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Sihang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhang-Ren Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences. (arXiv:2311.06025v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06025","description":"<p>Recently, the increasing demand for superior medical services has highlighted\nthe discrepancies in the medical infrastructure. With big data, especially\ntexts, forming the foundation of medical services, there is an exigent need for\neffective natural language processing (NLP) solutions tailored to the\nhealthcare domain. Conventional approaches leveraging pre-trained models\npresent promising results in this domain and current large language models\n(LLMs) offer advanced foundation for medical text processing. However, most\nmedical LLMs are trained only with supervised fine-tuning (SFT), even though it\nefficiently empowers LLMs to understand and respond to medical instructions but\nis ineffective in learning domain knowledge and aligning with human preference.\nAnother engineering barrier that prevents current medical LLM from better text\nprocessing ability is their restricted context length (e.g., 2,048 tokens),\nmaking it hard for the LLMs to process long context, which is frequently\nrequired in the medical domain. In this work, we propose ChiMed-GPT, a new\nbenchmark LLM designed explicitly for Chinese medical domain, with enlarged\ncontext length to 4,096 tokens and undergoes a comprehensive training regime\nwith pre-training, SFT, and RLHF. Evaluations on real-world tasks including\ninformation extraction, question answering, and dialogue generation demonstrate\nChiMed-GPT's superior performance over general domain LLMs. Furthermore, we\nanalyze possible biases through prompting ChiMed-GPT to perform attitude scales\nregarding discrimination of patients, so as to contribute to further\nresponsible development of LLMs in the medical domain. The code and model are\nreleased at https://github.com/synlp/ChiMed-GPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuanhe Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongdong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration. (arXiv:2311.06062v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06062","description":"<p>Membership Inference Attacks (MIA) aim to infer whether a target data record\nhas been utilized for model training or not. Prior attempts have quantified the\nprivacy risks of language models (LMs) via MIAs, but there is still no\nconsensus on whether existing MIA algorithms can cause remarkable privacy\nleakage on practical Large Language Models (LLMs). Existing MIAs designed for\nLMs can be classified into two categories: reference-free and reference-based\nattacks. They are both based on the hypothesis that training records\nconsistently strike a higher probability of being sampled. Nevertheless, this\nhypothesis heavily relies on the overfitting of target models, which will be\nmitigated by multiple regularization methods and the generalization of LLMs.\nThe reference-based attack seems to achieve promising effectiveness in LLMs,\nwhich measures a more reliable membership signal by comparing the probability\ndiscrepancy between the target model and the reference model. However, the\nperformance of reference-based attack is highly dependent on a reference\ndataset that closely resembles the training dataset, which is usually\ninaccessible in the practical scenario. Overall, existing MIAs are unable to\neffectively unveil privacy leakage over practical fine-tuned LLMs that are\noverfitting-free and private. We propose a Membership Inference Attack based on\nSelf-calibrated Probabilistic Variation (SPV-MIA). Specifically, since\nmemorization in LLMs is inevitable during the training process and occurs\nbefore overfitting, we introduce a more reliable membership signal,\nprobabilistic variation, which is based on memorization rather than\noverfitting. Furthermore, we introduce a self-prompt approach, which constructs\nthe dataset to fine-tune the reference model by prompting the target LLM\nitself. In this manner, the adversary can collect a dataset with a similar\ndistribution from public APIs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wenjie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huandong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chen Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guanghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tao Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making LLMs Worth Every Penny: Resource-Limited Text Classification in Banking. (arXiv:2311.06102v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06102","description":"<p>Standard Full-Data classifiers in NLP demand thousands of labeled examples,\nwhich is impractical in data-limited domains. Few-shot methods offer an\nalternative, utilizing contrastive learning techniques that can be effective\nwith as little as 20 examples per class. Similarly, Large Language Models\n(LLMs) like GPT-4 can perform effectively with just 1-5 examples per class.\nHowever, the performance-cost trade-offs of these methods remain underexplored,\na critical concern for budget-limited organizations. Our work addresses this\ngap by studying the aforementioned approaches over the Banking77 financial\nintent detection dataset, including the evaluation of cutting-edge LLMs by\nOpenAI, Cohere, and Anthropic in a comprehensive set of few-shot scenarios. We\ncomplete the picture with two additional methods: first, a cost-effective\nquerying method for LLMs based on retrieval-augmented generation (RAG), able to\nreduce operational costs multiple times compared to classic few-shot\napproaches, and second, a data augmentation method using GPT-4, able to improve\nperformance in data-limited scenarios. Finally, to inspire future research, we\nprovide a human expert's curated subset of Banking77, along with extensive\nerror analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loukas_L/0/1/0/all/0/1\">Lefteris Loukas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stogiannidis_I/0/1/0/all/0/1\">Ilias Stogiannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diamantopoulos_O/0/1/0/all/0/1\">Odysseas Diamantopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malakasiotis_P/0/1/0/all/0/1\">Prodromos Malakasiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassos_S/0/1/0/all/0/1\">Stavros Vassos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is it indeed bigger better? The comprehensive study of claim detection LMs applied for disinformation tackling. (arXiv:2311.06121v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06121","description":"<p>This study compares the performance of (1) fine-tuned models and (2)\nextremely large language models on the task of check-worthy claim detection.\nFor the purpose of the comparison we composed a multilingual and multi-topical\ndataset comprising texts of various sources and styles. Building on this, we\nperformed a benchmark analysis to determine the most general multilingual and\nmulti-topical claim detector.\n</p>\n<p>We chose three state-of-the-art models in the check-worthy claim detection\ntask and fine-tuned them. Furthermore, we selected three state-of-the-art\nextremely large language models without any fine-tuning. We made modifications\nto the models to adapt them for multilingual settings and through extensive\nexperimentation and evaluation. We assessed the performance of all the models\nin terms of accuracy, recall, and F1-score in in-domain and cross-domain\nscenarios. Our results demonstrate that despite the technological progress in\nthe area of natural language processing, the models fine-tuned for the task of\ncheck-worthy claim detection still outperform the zero-shot approaches in a\ncross-domain settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hyben_M/0/1/0/all/0/1\">Martin Hyben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kula_S/0/1/0/all/0/1\">Sebastian Kula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srba_I/0/1/0/all/0/1\">Ivan Srba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_R/0/1/0/all/0/1\">Robert Moro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simko_J/0/1/0/all/0/1\">Jakub Simko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models can be Logical Solvers. (arXiv:2311.06158v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06158","description":"<p>Logical reasoning is a fundamental aspect of human intelligence and a key\ncomponent of tasks like problem-solving and decision-making. Recent\nadvancements have enabled Large Language Models (LLMs) to potentially exhibit\nreasoning capabilities, but complex logical reasoning remains a challenge. The\nstate-of-the-art, solver-augmented language models, use LLMs to parse natural\nlanguage logical questions into symbolic representations first and then adopt\nexternal logical solvers to take in the symbolic representations and output the\nanswers. Despite their impressive performance, any parsing errors will\ninevitably result in the failure of the execution of the external logical\nsolver and no answer to the logical questions. In this paper, we introduce\nLoGiPT, a novel language model that directly emulates the reasoning processes\nof logical solvers and bypasses the parsing errors by learning to strict\nadherence to solver syntax and grammar. LoGiPT is fine-tuned on a newly\nconstructed instruction-tuning dataset derived from revealing and refining the\ninvisible reasoning process of deductive solvers. Experimental results on two\npublic deductive reasoning datasets demonstrate that LoGiPT outperforms\nstate-of-the-art solver-augmented LMs and few-shot prompting methods on\ncompetitive LLMs like ChatGPT or GPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiazhan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Junheng Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1\">Hiteshi Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntax-semantics interface: an algebraic model. (arXiv:2311.06189v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06189","description":"<p>We extend our formulation of Merge and Minimalism in terms of Hopf algebras\nto an algebraic model of a syntactic-semantic interface. We show that methods\nadopted in the formulation of renormalization (extraction of meaningful\nphysical values) in theoretical physics are relevant to describe the extraction\nof meaning from syntactic expressions. We show how this formulation relates to\ncomputational models of semantics and we answer some recent controversies about\nimplications for generative linguistics of the current functioning of large\nlanguage models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marcolli_M/0/1/0/all/0/1\">Matilde Marcolli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berwick_R/0/1/0/all/0/1\">Robert C. Berwick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chomsky_N/0/1/0/all/0/1\">Noam Chomsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BanglaBait: Semi-Supervised Adversarial Approach for Clickbait Detection on Bangla Clickbait Dataset. (arXiv:2311.06204v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06204","description":"<p>Intentionally luring readers to click on a particular content by exploiting\ntheir curiosity defines a title as clickbait. Although several studies focused\non detecting clickbait titles in English articles, low resource language like\nBangla has not been given adequate attention. To tackle clickbait titles in\nBangla, we have constructed the first Bangla clickbait detection dataset\ncontaining 15,056 labeled news articles and 65,406 unlabelled news articles\nextracted from clickbait dense news sites. Each article has been labeled by\nthree expert linguists and includes an article's title, body, and other\nmetadata. By incorporating labeled and unlabelled data, we finetune a\npretrained Bangla transformer model in an adversarial fashion using Semi\nSupervised Generative Adversarial Networks (SS GANs). The proposed model acts\nas a good baseline for this dataset, outperforming traditional neural network\nmodels (LSTM, GRU, CNN) and linguistic feature based models. We expect that\nthis dataset and the detailed analysis and comparison of these clickbait\ndetection models will provide a fundamental basis for future research into\ndetecting clickbait titles in Bengali articles. We have released the\ncorresponding code and dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mahtab_M/0/1/0/all/0/1\">Md. Motahar Mahtab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haque_M/0/1/0/all/0/1\">Monirul Haque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Mehedi Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadeque_F/0/1/0/all/0/1\">Farig Sadeque</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MultiIoT: Towards Large-scale Multisensory Learning for the Internet of Things. (arXiv:2311.06217v1 [cs.LG])","link":"http://arxiv.org/abs/2311.06217","description":"<p>The Internet of Things (IoT), the network integrating billions of smart\nphysical devices embedded with sensors, software, and communication\ntechnologies for the purpose of connecting and exchanging data with other\ndevices and systems, is a critical and rapidly expanding component of our\nmodern world. The IoT ecosystem provides a rich source of real-world modalities\nsuch as motion, thermal, geolocation, imaging, depth, sensors, video, and audio\nfor prediction tasks involving the pose, gaze, activities, and gestures of\nhumans as well as the touch, contact, pose, 3D of physical objects. Machine\nlearning presents a rich opportunity to automatically process IoT data at\nscale, enabling efficient inference for impact in understanding human\nwellbeing, controlling physical devices, and interconnecting smart cities. To\ndevelop machine learning technologies for IoT, this paper proposes MultiIoT,\nthe most expansive IoT benchmark to date, encompassing over 1.15 million\nsamples from 12 modalities and 8 tasks. MultiIoT introduces unique challenges\ninvolving (1) learning from many sensory modalities, (2) fine-grained\ninteractions across long temporal ranges, and (3) extreme heterogeneity due to\nunique structure and noise topologies in real-world sensors. We also release a\nset of strong modeling baselines, spanning modality and task-specific methods\nto multisensory and multitask models to encourage future research in\nmultisensory representation learning for IoT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mo_S/0/1/0/all/0/1\">Shentong Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Russ Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparison of Lexicon-Based and ML-Based Sentiment Analysis: Are There Outlier Words?. (arXiv:2311.06221v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06221","description":"<p>Lexicon-based approaches to sentiment analysis of text are based on each word\nor lexical entry having a pre-defined weight indicating its sentiment polarity.\nThese are usually manually assigned but the accuracy of these when compared\nagainst machine leaning based approaches to computing sentiment, are not known.\nIt may be that there are lexical entries whose sentiment values cause a\nlexicon-based approach to give results which are very different to a machine\nlearning approach. In this paper we compute sentiment for more than 150,000\nEnglish language texts drawn from 4 domains using the Hedonometer, a\nlexicon-based technique and Azure, a contemporary machine-learning based\napproach which is part of the Azure Cognitive Services family of APIs which is\neasy to use. We model differences in sentiment scores between approaches for\ndocuments in each domain using a regression and analyse the independent\nvariables (Hedonometer lexical entries) as indicators of each word's importance\nand contribution to the score differences. Our findings are that the importance\nof a word depends on the domain and there are no standout lexical entries which\nsystematically cause differences in sentiment scores.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mahajani_S/0/1/0/all/0/1\">Siddhant Jaydeep Mahajani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smeaton_A/0/1/0/all/0/1\">Alan F. Smeaton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Contamination Quiz: A Tool to Detect and Estimate Contamination in Large Language Models. (arXiv:2311.06233v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06233","description":"<p>We propose the Data Contamination Quiz, a simple and effective approach to\ndetect data contamination in large language models (LLMs) and estimate the\namount of it. Specifically, we frame data contamination detection as a series\nof multiple-choice questions. We devise a quiz format wherein three perturbed\nversions of each dataset instance are created. These changes only include\nword-level perturbations, replacing words with their contextual synonyms,\nensuring both the semantic and sentence structure remain exactly the same as\nthe original instance. Together with the original instance, these perturbed\nversions constitute the choices in the quiz. Given that the only distinguishing\nsignal among these choices is the exact wording, an LLM, when tasked with\nidentifying the original instance from the choices, opts for the original if it\nhas memorized it in its pre-training phase--a trait intrinsic to LLMs. A\ndataset partition is then marked as contaminated if the LLM's performance on\nthe quiz surpasses what random chance suggests. Our evaluation spans seven\ndatasets and their respective splits (train and test/validation) on two\nstate-of-the-art LLMs: GPT-4 and GPT-3.5. While lacking access to the\npre-training data, our results suggest that our approach not only enhances the\ndetection of data contamination but also provides an accurate estimation of its\nextent, even when the contamination signal is weak.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Golchin_S/0/1/0/all/0/1\">Shahriar Golchin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Surdeanu_M/0/1/0/all/0/1\">Mihai Surdeanu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild. (arXiv:2311.06237v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06237","description":"<p>Engaging in the deliberate generation of abnormal outputs from large language\nmodels (LLMs) by attacking them is a novel human activity. This paper presents\na thorough exposition of how and why people perform such attacks. Using a\nformal qualitative methodology, we interviewed dozens of practitioners from a\nbroad range of backgrounds, all contributors to this novel work of attempting\nto cause LLMs to fail. We relate and connect this activity between its\npractitioners' motivations and goals; the strategies and techniques they\ndeploy; and the crucial role the community plays. As a result, this paper\npresents a grounded theory of how and why people attack large language models:\nLLM red teaming in the wild.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Inie_N/0/1/0/all/0/1\">Nanna Inie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stray_J/0/1/0/all/0/1\">Jonathan Stray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Derczynski_L/0/1/0/all/0/1\">Leon Derczynski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Argumentation Element Annotation Modeling using XLNet. (arXiv:2311.06239v1 [cs.CL])","link":"http://arxiv.org/abs/2311.06239","description":"<p>This study demonstrates the effectiveness of XLNet, a transformer-based\nlanguage model, for annotating argumentative elements in persuasive essays.\nXLNet's architecture incorporates a recurrent mechanism that allows it to model\nlong-term dependencies in lengthy texts. Fine-tuned XLNet models were applied\nto three datasets annotated with different schemes - a proprietary dataset\nusing the Annotations for Revisions and Reflections on Writing (ARROW) scheme,\nthe PERSUADE corpus, and the Argument Annotated Essays (AAE) dataset. The XLNet\nmodels achieved strong performance across all datasets, even surpassing human\nagreement levels in some cases. This shows XLNet capably handles diverse\nannotation schemes and lengthy essays. Comparisons between the model outputs on\ndifferent datasets also revealed insights into the relationships between the\nannotation tags. Overall, XLNet's strong performance on modeling argumentative\nstructures across diverse datasets highlights its suitability for providing\nautomated feedback on essay organization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ormerod_C/0/1/0/all/0/1\">Christopher Ormerod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burkhardt_A/0/1/0/all/0/1\">Amy Burkhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_M/0/1/0/all/0/1\">Mackenzie Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lottridge_S/0/1/0/all/0/1\">Sue Lottridge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization. (arXiv:2311.06243v1 [cs.LG])","link":"http://arxiv.org/abs/2311.06243","description":"<p>Large foundation models are becoming ubiquitous, but training them from\nscratch is prohibitively expensive. Thus, efficiently adapting these powerful\nmodels to downstream tasks is increasingly important. In this paper, we study a\nprincipled finetuning paradigm -- Orthogonal Finetuning (OFT) -- for downstream\ntask adaptation. Despite demonstrating good generalizability, OFT still uses a\nfairly large number of trainable parameters due to the high dimensionality of\northogonal matrices. To address this, we start by examining OFT from an\ninformation transmission perspective, and then identify a few key desiderata\nthat enable better parameter-efficiency. Inspired by how the Cooley-Tukey fast\nFourier transform algorithm enables efficient information transmission, we\npropose an efficient orthogonal parameterization using butterfly structures. We\napply this parameterization to OFT, creating a novel parameter-efficient\nfinetuning method, called Orthogonal Butterfly (BOFT). By subsuming OFT as a\nspecial case, BOFT introduces a generalized orthogonal finetuning framework.\nFinally, we conduct an extensive empirical study of adapting large vision\ntransformers, large language models, and text-to-image diffusion models to\nvarious downstream tasks in vision and language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weiyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1\">Zeju Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiu_Y/0/1/0/all/0/1\">Yuliang Xiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yuxuan Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Longhui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Haiwen Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heo_J/0/1/0/all/0/1\">Juyeon Heo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Songyou Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yandong Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1\">Michael J. Black</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1\">Adrian Weller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Cognitive Architecture for Machine Consciousness and Artificial Superintelligence: Thought Is Structured by the Iterative Updating of Working Memory. (arXiv:2203.17255v4 [q-bio.NC] UPDATED)","link":"http://arxiv.org/abs/2203.17255","description":"<p>This article provides an analytical framework for how to simulate human-like\nthought processes within a computer. It describes how attention and memory\nshould be structured, updated, and used to search for associative additions to\nthe thought process. The working memory of mammals is made possible by two\nforms of persistent activity: sustained firing (preserving information on the\norder of seconds) and synaptic potentiation (preserving information on the\norder of minutes to hours). The article uses a series of over 40 original\nfigures to systematically demonstrate how the iterative updating of these\nworking memory stores provides dynamic, functional structure to thought and\nconsciousness. In an AI implementation, these two stores should be updated\ncontinuously and in an iterative fashion, meaning that, in the next state, some\nproportion of the coactive representations should always be retained. Thus, the\nset of concepts coactive in working memory will evolve gradually and\nincrementally over time. This makes each state a revised iteration of the\npreceding state and causes successive states to overlap and blend with respect\nto the set of representations they contain. It is argued that without this\noverlap, AI systems cannot achieve mental continuity or machine consciousness.\nPersistent activity spreads activation energy throughout the hierarchical\nnetwork to search for the next associative update. This search of long-term\nmemory locates the most appropriate representation to be added to the global\nworkspace. The result is a chain of associatively linked intermediate states\ncapable of advancing toward a solution or goal. Iterative updating is\nconceptualized here as an information processing strategy, a computational and\nneurophysiological determinant of the stream of thought, and an algorithm for\ndesigning and programming artificial general intelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Reser_J/0/1/0/all/0/1\">Jared Edward Reser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Pre-trained Language Model Fine-tuning with Noise Stability Regularization. (arXiv:2206.05658v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.05658","description":"<p>The advent of large-scale pre-trained language models has contributed greatly\nto the recent progress in natural language processing. Many state-of-the-art\nlanguage models are first trained on a large text corpus and then fine-tuned on\ndownstream tasks. Despite its recent success and wide adoption, fine-tuning a\npre-trained language model often suffers from overfitting, which leads to poor\ngeneralizability due to the extremely high complexity of the model and the\nlimited training samples from downstream tasks. To address this problem, we\npropose a novel and effective fine-tuning framework, named Layerwise Noise\nStability Regularization (LNSR). Specifically, we propose to inject the\nstandard Gaussian noise or In-manifold noise and regularize hidden\nrepresentations of the fine-tuned model. We first provide theoretical analyses\nto support the efficacy of our method. We then demonstrate the advantages of\nthe proposed method over other state-of-the-art algorithms including L2-SP,\nMixout and SMART. While these previous works only verify the effectiveness of\ntheir methods on relatively simple text classification tasks, we also verify\nthe effectiveness of our method on question answering tasks, where the target\nproblem is much more difficult and more training examples are available.\nFurthermore, extensive experimental results indicate that the proposed\nalgorithm can not only enhance the in-domain performance of the language models\nbut also improve the domain generalization performance on out-of-domain data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_H/0/1/0/all/0/1\">Hang Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingjian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1\">Dejing Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Cheng-Zhong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiebo Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"E2E Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v7 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2302.10186","description":"<p>In human-computer conversations, extracting entities such as names, street\naddresses and email addresses from speech is a challenging task. In this paper,\nwe study the impact of fine-tuning pre-trained speech encoders on extracting\nspoken entities in human-readable form directly from speech without the need\nfor text transcription. We illustrate that such a direct approach optimizes the\nencoder to transcribe only the entity relevant portions of speech ignoring the\nsuperfluous portions such as carrier phrases, or spell name entities. In the\ncontext of dialog from an enterprise virtual agent, we demonstrate that the\n1-step approach outperforms the typical 2-step approach which first generates\nlexical transcriptions followed by text-based entity extraction for identifying\nspoken entities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Singla_K/0/1/0/all/0/1\">Karan Singla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1\">Yeon-Jun Kim</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bangalore_S/0/1/0/all/0/1\">Srinivas Bangalore</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conceptual structure coheres in human cognition but not in large language models. (arXiv:2304.02754v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.02754","description":"<p>Neural network models of language have long been used as a tool for\ndeveloping hypotheses about conceptual representation in the mind and brain.\nFor many years, such use involved extracting vector-space representations of\nwords and using distances among these to predict or understand human behavior\nin various semantic tasks. Contemporary large language models (LLMs), however,\nmake it possible to interrogate the latent structure of conceptual\nrepresentations using experimental methods nearly identical to those commonly\nused with human participants. The current work utilizes three common techniques\nborrowed from cognitive psychology to estimate and compare the structure of\nconcepts in humans and a suite of LLMs. In humans, we show that conceptual\nstructure is robust to differences in culture, language, and method of\nestimation. Structures estimated from LLM behavior, while individually fairly\nconsistent with those estimated from human behavior, vary much more depending\nupon the particular task used to generate responses--across tasks, estimates of\nconceptual structure from the very same model cohere less with one another than\ndo human structure estimates. These results highlight an important difference\nbetween contemporary LLMs and human cognition, with implications for\nunderstanding some fundamental limitations of contemporary machine language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Siddharth Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_K/0/1/0/all/0/1\">Kushin Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xizheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei-Chun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padua_L/0/1/0/all/0/1\">Lisa Padua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_T/0/1/0/all/0/1\">Timothy T Rogers</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01219","description":"<p>The prompt-based learning paradigm, which bridges the gap between\npre-training and fine-tuning, achieves state-of-the-art performance on several\nNLP tasks, particularly in few-shot settings. Despite being widely applied,\nprompt-based learning is vulnerable to backdoor attacks. Textual backdoor\nattacks are designed to introduce targeted vulnerabilities into models by\npoisoning a subset of training samples through trigger injection and label\nmodification. However, they suffer from flaws such as abnormal natural language\nexpressions resulting from the trigger and incorrect labeling of poisoned\nsamples. In this study, we propose ProAttack, a novel and efficient method for\nperforming clean-label backdoor attacks based on the prompt, which uses the\nprompt itself as a trigger. Our method does not require external triggers and\nensures correct labeling of poisoned samples, improving the stealthy nature of\nthe backdoor attack. With extensive experiments on rich-resource and few-shot\ntext classification tasks, we empirically validate ProAttack's competitive\nperformance in textual backdoor attacks. Notably, in the rich-resource setting,\nProAttack achieves state-of-the-art attack success rates in the clean-label\nbackdoor attack benchmark without external triggers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jinming Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings. (arXiv:2305.02317v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02317","description":"<p>Recent advances in large language models elicit reasoning in a chain of\nthought that allows models to decompose problems in a human-like fashion.\nThough this paradigm improves multi-step reasoning ability in language models,\nit is limited by being unimodal and applied mainly to question-answering tasks.\nWe claim that incorporating visual augmentation into reasoning is essential,\nespecially for complex, imaginative tasks. Consequently, we introduce VCoT, a\nnovel method that leverages chain of thought prompting with vision-language\ngrounding to recursively bridge the logical gaps within sequential data. Our\nmethod uses visual guidance to generate synthetic multimodal infillings that\nadd consistent and novel information to reduce the logical gaps for downstream\ntasks that can benefit from temporal reasoning, as well as provide\ninterpretability into models' multi-step reasoning. We apply VCoT to the Visual\nStorytelling and WikiHow summarization datasets and demonstrate through human\nevaluation that VCoT offers novel and consistent synthetic data augmentation\nbeating chain of thought baselines, which can be used to enhance downstream\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rose_D/0/1/0/all/0/1\">Daniel Rose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Himakunthala_V/0/1/0/all/0/1\">Vaishnavi Himakunthala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_A/0/1/0/all/0/1\">Andy Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ryan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_A/0/1/0/all/0/1\">Alex Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonar_C/0/1/0/all/0/1\">Chinmay Sonar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirza_D/0/1/0/all/0/1\">Diba Mirza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning. (arXiv:2305.13971v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13971","description":"<p>Despite their impressive performance, large language models (LMs) still\nstruggle with reliably generating complex output structures when not finetuned\nto follow the required output format exactly. To address this issue,\ngrammar-constrained decoding (GCD) can be used to control the generation of\nLMs, guaranteeing that the output follows a given structure. Most existing GCD\nmethods are, however, limited to specific tasks, such as parsing or code\ngeneration. In this work, we demonstrate that formal grammars can describe the\noutput space for a much wider range of tasks and argue that GCD can serve as a\nunified framework for structured NLP tasks in general. For increased\nflexibility, we introduce input-dependent grammars, which allow the grammar to\ndepend on the input and thus enable the generation of different output\nstructures for different inputs. We then empirically demonstrate the power and\nflexibility of GCD-enhanced LMs on (1) information extraction, (2) entity\ndisambiguation, and (3) constituency parsing. Our results indicate that\ngrammar-constrained LMs substantially outperform unconstrained LMs or even beat\ntask-specific finetuned models. Grammar constraints thus hold great promise for\nharnessing off-the-shelf LMs for a wide range of structured NLP tasks,\nespecially where training data is scarce or finetuning is expensive. Code and\ndata: https://github.com/epfl-dlab/GCD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Saibo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation. (arXiv:2305.14016v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14016","description":"<p>Gender bias is a significant issue in machine translation, leading to ongoing\nresearch efforts in developing bias mitigation techniques. However, most works\nfocus on debiasing bilingual models without much consideration for multilingual\nsystems. In this paper, we specifically target the gender bias issue of\nmultilingual machine translation models for unambiguous cases where there is a\nsingle correct translation, and propose a bias mitigation method based on a\nnovel approach. Specifically, we propose Gender-Aware Contrastive Learning,\nGACL, which encodes contextual gender information into the representations of\nnon-explicit gender words. Our method is target language-agnostic and is\napplicable to pre-trained multilingual machine translation models via\nfine-tuning. Through multilingual evaluation, we show that our approach\nimproves gender accuracy by a wide margin without hampering translation\nperformance. We also observe that incorporated gender information transfers and\nbenefits other target languages regarding gender accuracy. Finally, we\ndemonstrate that our method is applicable and beneficial to models of various\nsizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_H/0/1/0/all/0/1\">Hyukhun Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kang-il Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyomin Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"M3Exam: A Multilingual, Multimodal, Multilevel Benchmark for Examining Large Language Models. (arXiv:2306.05179v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05179","description":"<p>Despite the existence of various benchmarks for evaluating natural language\nprocessing models, we argue that human exams are a more suitable means of\nevaluating general intelligence for large language models (LLMs), as they\ninherently demand a much wider range of abilities such as language\nunderstanding, domain knowledge, and problem-solving skills. To this end, we\nintroduce M3Exam, a novel benchmark sourced from real and official human exam\nquestions for evaluating LLMs in a multilingual, multimodal, and multilevel\ncontext. M3Exam exhibits three unique characteristics: (1) multilingualism,\nencompassing questions from multiple countries that require strong multilingual\nproficiency and cultural knowledge; (2) multimodality, accounting for the\nmultimodal nature of many exam questions to test the model's multimodal\nunderstanding capability; and (3) multilevel structure, featuring exams from\nthree critical educational periods to comprehensively assess a model's\nproficiency at different levels. In total, M3Exam contains 12,317 questions in\n9 diverse languages with three educational levels, where about 23\\% of the\nquestions require processing images for successful solving. We assess the\nperformance of top-performing LLMs on M3Exam and find that current models,\nincluding GPT-4, still struggle with multilingual text, particularly in\nlow-resource and non-Latin script languages. Multimodal LLMs also perform\npoorly with complex multimodal questions. We believe that M3Exam can be a\nvaluable resource for comprehensively evaluating LLMs by examining their\nmultilingual and multimodal abilities and tracking their development. Data and\nevaluation code is available at \\url{https://github.com/DAMO-NLP-SG/M3Exam}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aljunied_S/0/1/0/all/0/1\">Sharifah Mahani Aljunied</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chia_Y/0/1/0/all/0/1\">Yew Ken Chia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-based Text Selection for Addressing Class-Imbalanced Data in Classification. (arXiv:2307.14899v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.14899","description":"<p>This paper addresses the problem of selecting of a set of texts for\nannotation in text classification using retrieval methods when there are limits\non the number of annotations due to constraints on human resources. An\nadditional challenge addressed is dealing with binary categories that have a\nsmall number of positive instances, reflecting severe class imbalance. In our\nsituation, where annotation occurs over a long time period, the selection of\ntexts to be annotated can be made in batches, with previous annotations guiding\nthe choice of the next set. To address these challenges, the paper proposes\nleveraging SHAP to construct a quality set of queries for Elasticsearch and\nsemantic search, to try to identify optimal sets of texts for annotation that\nwill help with class imbalance. The approach is tested on sets of cue texts\ndescribing possible future events, constructed by participants involved in\nstudies aimed to help with the management of obesity and diabetes. We introduce\nan effective method for selecting a small set of texts for annotation and\nbuilding high-quality classifiers. We integrate vector search, semantic search,\nand machine learning classifiers to yield a good solution. Our experiments\ndemonstrate improved F1 scores for the minority classes in binary\nclassification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmadi_S/0/1/0/all/0/1\">Sareh Ahmadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Aditya Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_E/0/1/0/all/0/1\">Edward Fox</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Wordification: A New Way of Teaching English Spelling Patterns. (arXiv:2309.12981v2 [cs.OH] UPDATED)","link":"http://arxiv.org/abs/2309.12981","description":"<p>Literacy, or the ability to read and write, is a crucial indicator of success\nin life and greater society. It is estimated that 85% of people in juvenile\ndelinquent systems cannot adequately read or write, that more than half of\nthose with substance abuse issues have complications in reading or writing and\nthat two-thirds of those who do not complete high school lack proper literacy\nskills. Furthermore, young children who do not possess reading skills matching\ngrade level by the fourth grade are approximately 80% likely to not catch up at\nall. Many may believe that in a developed country such as the United States,\nliteracy fails to be an issue; however, this is a dangerous misunderstanding.\nGlobally an estimated 1.19 trillion dollars are lost every year due to issues\nin literacy; in the USA, the loss is an estimated 300 billion. To put it in\nmore shocking terms, one in five American adults still fail to comprehend basic\nsentences. Making matters worse, the only tools available now to correct a lack\nof reading and writing ability are found in expensive tutoring or other\nprograms that oftentimes fail to be able to reach the required audience. In\nthis paper, our team puts forward a new way of teaching English spelling and\nword recognitions to grade school students in the United States: Wordification.\nWordification is a web application designed to teach English literacy using\nprinciples of linguistics applied to the orthographic and phonological\nproperties of words in a manner not fully utilized previously in any\ncomputer-based teaching application.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Whalen_L/0/1/0/all/0/1\">Lexington Whalen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bickel_N/0/1/0/all/0/1\">Nathan Bickel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Comandur_S/0/1/0/all/0/1\">Shash Comandur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Craven_D/0/1/0/all/0/1\">Dalton Craven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubinsky_S/0/1/0/all/0/1\">Stanley Dubinsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valafar_H/0/1/0/all/0/1\">Homayoun Valafar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BRAINTEASER: Lateral Thinking Puzzles for Large Language Models. (arXiv:2310.05057v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05057","description":"<p>The success of language models has inspired the NLP community to attend to\ntasks that require implicit and complex reasoning, relying on human-like\ncommonsense mechanisms. While such vertical thinking tasks have been relatively\npopular, lateral thinking puzzles have received little attention. To bridge\nthis gap, we devise BRAINTEASER: a multiple-choice Question Answering task\ndesigned to test the model's ability to exhibit lateral thinking and defy\ndefault commonsense associations. We design a three-step procedure for creating\nthe first lateral thinking benchmark, consisting of data collection, distractor\ngeneration, and generation of adversarial examples, leading to 1,100 puzzles\nwith high-quality annotations. To assess the consistency of lateral reasoning\nby models, we enrich BRAINTEASER based on a semantic and contextual\nreconstruction of its questions. Our experiments with state-of-the-art\ninstruction- and commonsense language models reveal a significant gap between\nhuman and model performance, which is further widened when consistency across\nadversarial formats is considered. We make all of our code and data available\nto stimulate work on developing and evaluating lateral thinking models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yifan Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1\">Filip Ilievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kaixin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sourati_Z/0/1/0/all/0/1\">Zhivar Sourati</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated clinical coding using off-the-shelf large language models. (arXiv:2310.06552v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.06552","description":"<p>The task of assigning diagnostic ICD codes to patient hospital admissions is\ntypically performed by expert human coders. Efforts towards automated ICD\ncoding are dominated by supervised deep learning models. However, difficulties\nin learning to predict the large number of rare codes remain a barrier to\nadoption in clinical practice. In this work, we leverage off-the-shelf\npre-trained generative large language models (LLMs) to develop a practical\nsolution that is suitable for zero-shot and few-shot code assignment.\nUnsupervised pre-training alone does not guarantee precise knowledge of the ICD\nontology and specialist clinical coding task, therefore we frame the task as\ninformation extraction, providing a description of each coded concept and\nasking the model to retrieve related mentions. For efficiency, rather than\niterating over all codes, we leverage the hierarchical nature of the ICD\nontology to sparsely search for relevant codes. Then, in a second stage, which\nwe term 'meta-refinement', we utilise GPT-4 to select a subset of the relevant\nlabels as predictions. We validate our method using Llama-2, GPT-3.5 and GPT-4\non the CodiEsp dataset of ICD-coded clinical case documents. Our tree-search\nmethod achieves state-of-the-art performance on rarer classes, achieving the\nbest macro-F1 of 0.225, whilst achieving slightly lower micro-F1 of 0.157,\ncompared to 0.216 and 0.219 respectively from PLM-ICD. To the best of our\nknowledge, this is the first method for automated ICD coding requiring no\ntask-specific learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Boyle_J/0/1/0/all/0/1\">Joseph S. Boyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kascenas_A/0/1/0/all/0/1\">Antanas Kascenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lok_P/0/1/0/all/0/1\">Pat Lok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liakata_M/0/1/0/all/0/1\">Maria Liakata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ONeil_A/0/1/0/all/0/1\">Alison Q. O&#x27;Neil</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Financial Information Retrieval Model (ConFIRM). (arXiv:2310.13001v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2310.13001","description":"<p>With the exponential growth in large language models (LLMs), leveraging their\nemergent properties for specialized domains like finance merits exploration.\nHowever, regulated fields such as finance pose unique constraints, requiring\ndomain-optimized frameworks. We present ConFIRM, an LLM-based conversational\nfinancial information retrieval model tailored for query intent classification\nand knowledge base labeling.\n</p>\n<p>ConFIRM comprises two modules:\n</p>\n<p>1) a method to synthesize finance domain-specific question-answer pairs, and\n</p>\n<p>2) evaluation of parameter efficient fine-tuning approaches for the query\nclassification task. We generate a dataset of over 4000 samples, assessing\naccuracy on a separate test set.\n</p>\n<p>ConFIRM achieved over 90% accuracy, essential for regulatory compliance.\nConFIRM provides a data-efficient solution to extract precise query intent for\nfinancial dialog systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Stephen Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gazeley_W/0/1/0/all/0/1\">William Gazeley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1\">Siu Ho Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tingting Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rosetta Stone at the Arabic Reverse Dictionary Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15823","description":"<p>A Reverse Dictionary is a tool enabling users to discover a word based on its\nprovided definition, meaning, or description. Such a technique proves valuable\nin various scenarios, aiding language learners who possess a description of a\nword without its identity, and benefiting writers seeking precise terminology.\nThese scenarios often encapsulate what is referred to as the\n\"Tip-of-the-Tongue\" (TOT) phenomena. In this work, we present our winning\nsolution for the Arabic Reverse Dictionary shared task. This task focuses on\nderiving a vector representation of an Arabic word from its accompanying\ndescription. The shared task encompasses two distinct subtasks: the first\ninvolves an Arabic definition as input, while the second employs an English\ndefinition. For the first subtask, our approach relies on an ensemble of\nfinetuned Arabic BERT-based models, predicting the word embedding for a given\ndefinition. The final representation is obtained through averaging the output\nembeddings from each model within the ensemble. In contrast, the most effective\nsolution for the second subtask involves translating the English test\ndefinitions into Arabic and applying them to the finetuned models originally\ntrained for the first subtask. This straightforward method achieves the highest\nscore across both subtasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ElBakry_A/0/1/0/all/0/1\">Ahmed ElBakry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabr_M/0/1/0/all/0/1\">Mohamed Gabr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElNokrashy_M/0/1/0/all/0/1\">Muhammad ElNokrashy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InfoEntropy Loss to Mitigate Bias of Learning Difficulties for Generative Language Models. (arXiv:2310.19531v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19531","description":"<p>Generative language models are usually pretrained on large text corpus via\npredicting the next token (i.e., sub-word/word/phrase) given the previous ones.\nRecent works have demonstrated the impressive performance of large generative\nlanguage models on downstream tasks. However, existing generative language\nmodels generally neglect an inherent challenge in text corpus during training,\ni.e., the imbalance between frequent tokens and infrequent ones. It can lead a\nlanguage model to be dominated by common and easy-to-learn tokens, thereby\noverlooking the infrequent and difficult-to-learn ones. To alleviate that, we\npropose an Information Entropy Loss (InfoEntropy Loss) function. During\ntraining, it can dynamically assess the learning difficulty of a to-be-learned\ntoken, according to the information entropy of the corresponding predicted\nprobability distribution over the vocabulary. Then it scales the training loss\nadaptively, trying to lead the model to focus more on the difficult-to-learn\ntokens. On the Pile dataset, we train generative language models at different\nscales of 468M, 1.2B, and 6.7B parameters. Experiments reveal that models\nincorporating the proposed InfoEntropy Loss can gain consistent performance\nimprovement on downstream benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1\">Zhenpeng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xue Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zijia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1\">Guiguang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songlin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChineseWebText: Large-scale High-quality Chinese Web Text Extracted with Effective Evaluation Model. (arXiv:2311.01149v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.01149","description":"<p>During the development of large language models (LLMs), the scale and quality\nof the pre-training data play a crucial role in shaping LLMs' capabilities. To\naccelerate the research of LLMs, several large-scale datasets, such as C4 [1],\nPile [2], RefinedWeb [3] and WanJuan [4], have been released to the public.\nHowever, most of the released corpus focus mainly on English, and there is\nstill lack of complete tool-chain for extracting clean texts from web data.\nFurthermore, fine-grained information of the corpus, e.g. the quality of each\ntext, is missing. To address these challenges, we propose in this paper a new\ncomplete tool-chain EvalWeb to extract Chinese clean texts from noisy web data.\nFirst, similar to previous work, manually crafted rules are employed to discard\nexplicit noisy texts from the raw crawled web contents. Second, a well-designed\nevaluation model is leveraged to assess the remaining relatively clean data,\nand each text is assigned a specific quality score. Finally, we can easily\nutilize an appropriate threshold to select the high-quality pre-training data\nfor Chinese. Using our proposed approach, we release the largest and latest\nlarge-scale high-quality Chinese web text ChineseWebText, which consists of\n1.42 TB and each text is associated with a quality score, facilitating the LLM\nresearchers to choose the data according to the desired quality thresholds. We\nalso release a much cleaner subset of 600 GB Chinese data with the quality\nexceeding 90%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianghao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1\">Pu Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_T/0/1/0/all/0/1\">Tengxiao Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_D/0/1/0/all/0/1\">Dongyi Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1\">Qianlong Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chenglin Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1\">Guibo Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_C/0/1/0/all/0/1\">Chengqing Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinqiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FlashDecoding++: Faster Large Language Model Inference on GPUs. (arXiv:2311.01282v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2311.01282","description":"<p>As the Large Language Model (LLM) becomes increasingly important in various\ndomains. However, the following challenges still remain unsolved in\naccelerating LLM inference: (1) Synchronized partial softmax update. The\nsoftmax operation requires a synchronized update operation among each partial\nsoftmax result, leading to ~20% overheads for the attention computation in\nLLMs. (2) Under-utilized computation of flat GEMM. The shape of matrices\nperforming GEMM in LLM inference is flat, leading to under-utilized computation\nand &gt;50% performance loss after padding zeros in previous designs. (3)\nPerformance loss due to static dataflow. Kernel performance in LLM depends on\nvaried input data features, hardware configurations, etc. A single and static\ndataflow may lead to a 50.25% performance loss for GEMMs of different shapes in\nLLM inference.\n</p>\n<p>We present FlashDecoding++, a fast LLM inference engine supporting mainstream\nLLMs and hardware back-ends. To tackle the above challenges, FlashDecoding++\ncreatively proposes: (1) Asynchronized softmax with unified max value.\nFlashDecoding++ introduces a unified max value technique for different partial\nsoftmax computations to avoid synchronization. (2) Flat GEMM optimization with\ndouble buffering. FlashDecoding++ points out that flat GEMMs with different\nshapes face varied bottlenecks. Then, techniques like double buffering are\nintroduced. (3) Heuristic dataflow with hardware resource adaptation.\nFlashDecoding++ heuristically optimizes dataflow using different hardware\nresource considering input dynamics. Due to the versatility of optimizations in\nFlashDecoding++, FlashDecoding++ can achieve up to 4.86x and 2.18x speedup on\nboth NVIDIA and AMD GPUs compared to Hugging Face implementations.\nFlashDecoding++ also achieves an average speedup of 1.37x compared to\nstate-of-the-art LLM inference engines on mainstream LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_K/0/1/0/all/0/1\">Ke Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1\">Guohao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiaming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qiuli Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuhong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kangdi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuhan Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with Modality Collaboration. (arXiv:2311.04257v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04257","description":"<p>Multi-modal Large Language Models (MLLMs) have demonstrated impressive\ninstruction abilities across various open-ended tasks. However, previous\nmethods primarily focus on enhancing multi-modal capabilities. In this work, we\nintroduce a versatile multi-modal large language model, mPLUG-Owl2, which\neffectively leverages modality collaboration to improve performance in both\ntext and multi-modal tasks. mPLUG-Owl2 utilizes a modularized network design,\nwith the language decoder acting as a universal interface for managing\ndifferent modalities. Specifically, mPLUG-Owl2 incorporates shared functional\nmodules to facilitate modality collaboration and introduces a modality-adaptive\nmodule that preserves modality-specific features. Extensive experiments reveal\nthat mPLUG-Owl2 is capable of generalizing both text tasks and multi-modal\ntasks and achieving state-of-the-art performances with a single generic model.\nNotably, mPLUG-Owl2 is the first MLLM model that demonstrates the modality\ncollaboration phenomenon in both pure-text and multi-modal scenarios, setting a\npioneering path in the development of future multi-modal foundation models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinghao Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haiyang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiabo Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1\">Anwen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haowei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Q/0/1/0/all/0/1\">Qi Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NExT-Chat: An LMM for Chat, Detection and Segmentation. (arXiv:2311.04498v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2311.04498","description":"<p>The development of large language models (LLMs) has greatly advanced the\nfield of multimodal understanding, leading to the emergence of large multimodal\nmodels (LMMs). In order to enhance the level of visual comprehension, recent\nstudies have equipped LMMs with region-level understanding capabilities by\nrepresenting object bounding box coordinates as a series of text sequences\n(pixel2seq). In this paper, we introduce a novel paradigm for object location\nmodeling called pixel2emb method, where we ask the LMM to output the location\nembeddings and then decoded by different decoders. This paradigm allows for\ndifferent location formats (such as bounding boxes and masks) to be used in\nmultimodal conversations Furthermore, this kind of embedding based location\nmodeling enables the utilization of existing practices in localization tasks,\nsuch as detection and segmentation. In scenarios with limited resources, our\npixel2emb demonstrates superior performance compared to existing\nstate-of-the-art (SOTA) approaches in both the location input and output tasks\nunder fair comparison. Leveraging the proposed pixel2emb method, we train an\nLMM named NExT-Chat and demonstrate its capability of handling multiple tasks\nlike visual grounding, region caption, and grounded reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Ao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Chen-Wei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeepLearningBrasil@LT-EDI-2023: Exploring Deep Learning Techniques for Detecting Depression in Social Media Text. (arXiv:2311.05047v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2311.05047","description":"<p>In this paper, we delineate the strategy employed by our team,\nDeepLearningBrasil, which secured us the first place in the shared task\nDepSign-LT-EDI@RANLP-2023, achieving a 47.0% Macro F1-Score and a notable 2.4%\nadvantage. The task was to classify social media texts into three distinct\nlevels of depression - \"not depressed,\" \"moderately depressed,\" and \"severely\ndepressed.\" Leveraging the power of the RoBERTa and DeBERTa models, we further\npre-trained them on a collected Reddit dataset, specifically curated from\nmental health-related Reddit's communities (Subreddits), leading to an enhanced\nunderstanding of nuanced mental health discourse. To address lengthy textual\ndata, we used truncation techniques that retained the essence of the content by\nfocusing on its beginnings and endings. Our model was robust against unbalanced\ndata by incorporating sample weights into the loss. Cross-validation and\nensemble techniques were then employed to combine our k-fold trained models,\ndelivering an optimal solution. The accompanying code is made available for\ntransparency and further development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_E/0/1/0/all/0/1\">Eduardo Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomes_J/0/1/0/all/0/1\">Juliana Gomes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Junior_A/0/1/0/all/0/1\">Adalberto Barbosa J&#xfa;nior</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borges_C/0/1/0/all/0/1\">Cardeque Borges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_N/0/1/0/all/0/1\">N&#xe1;dia da Silva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-11-12T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}