{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-13T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"GenTKG: Generative Forecasting on Temporal Knowledge Graph. (arXiv:2310.07793v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07793","description":"<p>The rapid advancements in large language models (LLMs) have ignited interest\nin the temporal knowledge graph (tKG) domain, where conventional carefully\ndesigned embedding-based and rule-based models dominate. The question remains\nopen of whether pre-trained LLMs can understand structured temporal relational\ndata and replace them as the foundation model for temporal relational\nforecasting. Therefore, we bring temporal knowledge forecasting into the\ngenerative setting. However, challenges occur in the huge chasms between\ncomplex temporal graph data structure and sequential natural expressions LLMs\ncan handle, and between the enormous data sizes of tKGs and heavy computation\ncosts of finetuning LLMs. To address these challenges, we propose a novel\nretrieval augmented generation framework that performs generative forecasting\non tKGs named GenTKG, which combines a temporal logical rule-based retrieval\nstrategy and lightweight parameter-efficient instruction tuning. Extensive\nexperiments have shown that GenTKG outperforms conventional methods of temporal\nrelational forecasting under low computation resources. GenTKG also highlights\nremarkable transferability with exceeding performance on unseen datasets\nwithout re-training. Our work reveals the huge potential of LLMs in the tKG\ndomain and opens a new frontier for generative forecasting on tKGs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1\">Ruotong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1\">Xu Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunpu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ontology Enrichment for Effective Fine-grained Entity Typing. (arXiv:2310.07795v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07795","description":"<p>Fine-grained entity typing (FET) is the task of identifying specific entity\ntypes at a fine-grained level for entity mentions based on their contextual\ninformation. Conventional methods for FET require extensive human annotation,\nwhich is time-consuming and costly. Recent studies have been developing weakly\nsupervised or zero-shot approaches. We study the setting of zero-shot FET where\nonly an ontology is provided. However, most existing ontology structures lack\nrich supporting information and even contain ambiguous relations, making them\nineffective in guiding FET. Recently developed language models, though\npromising in various few-shot and zero-shot NLP tasks, may face challenges in\nzero-shot FET due to their lack of interaction with task-specific ontology. In\nthis study, we propose OnEFET, where we (1) enrich each node in the ontology\nstructure with two types of extra information: instance information for\ntraining sample augmentation and topic information to relate types to contexts,\nand (2) develop a coarse-to-fine typing algorithm that exploits the enriched\ninformation by training an entailment model with contrasting topics and\ninstance-based augmented training samples. Our experiments show that OnEFET\nachieves high-quality fine-grained entity typing without human annotation,\noutperforming existing zero-shot methods by a large margin and rivaling\nsupervised methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Siru Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pillai_P/0/1/0/all/0/1\">Pranav Pillai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A general mechanism of humor: reformulating the semantic overlap. (arXiv:2310.07803v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07803","description":"<p>This article proposes a cognitive mechanism of humour of general\napplicability, not restricted to verbal communication. It is indebted to\nRaskin's concept of script overlap, and conforms to the incongruity-resolution\ntheoretical framework, but it is built on the notion of constraint, an abstract\ncorrespondence between sets of data. Under this view, script overlap is an\noutcome of a more abstractly described phenomenon, constraint overlap. The\nimportant concept of the overlooked argument is introduced to characterise the\ntwo overlapping constraints -- overt and covert. Their inputs and outputs are\nnot directly encoded in utterances, but implicated by them, and their overlap\nresults in another overlap at the level of the communicated utterances, that\nthe incongruity reveals. Our hypothesis assumes as a given that the evocation\nof such constraints is a cognitive effect of the inferential process by which a\nhearer interprets utterances. We base this assumption on Hofstadter's theory of\nanalogy-making as the essence of human thought. By substituting \"stimuli\" of\nany kind for \"utterances\" in this model, we obtain a mechanism as easily\napplicable to non-verbal communication -- slapstick, cartoons -- and we propose\nit describes the necessary and sufficient conditions for a communicative act in\nany modality to carry humour.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_J/0/1/0/all/0/1\">Javier Mart&#xed;nez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models As Semantic Indexers. (arXiv:2310.07815v1 [cs.IR])","link":"http://arxiv.org/abs/2310.07815","description":"<p>Semantic identifier (ID) is an important concept in information retrieval\nthat aims to preserve the semantics of objects such as documents and items\ninside their IDs. Previous studies typically adopt a two-stage pipeline to\nlearn semantic IDs by first procuring embeddings using off-the-shelf text\nencoders and then deriving IDs based on the embeddings. However, each step\nintroduces potential information loss and there is usually an inherent mismatch\nbetween the distribution of embeddings within the latent space produced by text\nencoders and the anticipated distribution required for semantic indexing.\nNevertheless, it is non-trivial to design a method that can learn the\ndocument's semantic representations and its hierarchical structure\nsimultaneously, given that semantic IDs are discrete and sequentially\nstructured, and the semantic supervision is deficient. In this paper, we\nintroduce LMINDEXER, a self-supervised framework to learn semantic IDs with a\ngenerative language model. We tackle the challenge of sequential discrete ID by\nintroducing a semantic indexer capable of generating neural sequential discrete\nrepresentations with progressive training and contrastive learning. In response\nto the semantic supervision deficiency, we propose to train the model with a\nself-supervised document reconstruction objective. The learned semantic indexer\ncan facilitate various downstream tasks, such as recommendation and retrieval.\nWe conduct experiments on three tasks including recommendation, product search,\nand document retrieval on five datasets from various domains, where LMINDEXER\noutperforms competitive baselines significantly and consistently.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bowen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hansi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruirui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hanqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Suhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xianfeng Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Relationship between Analogy Identification and Sentence Structure Encoding in Large Language Models. (arXiv:2310.07818v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07818","description":"<p>Identifying analogies plays a pivotal role in human cognition and language\nproficiency. In the last decade, there has been extensive research on word\nanalogies in the form of ``A is to B as C is to D.'' However, there is a\ngrowing interest in analogies that involve longer text, such as sentences and\ncollections of sentences, which convey analogous meanings. While the current\nNLP research community evaluates the ability of Large Language Models (LLMs) to\nidentify such analogies, the underlying reasons behind these abilities warrant\ndeeper investigation. Furthermore, the capability of LLMs to encode both\nsyntactic and semantic structures of language within their embeddings has\ngarnered significant attention with the surge in their utilization. In this\nwork, we examine the relationship between the abilities of multiple LLMs to\nidentify sentence analogies, and their capacity to encode syntactic and\nsemantic structures. Through our analysis, we find that analogy identification\nability of LLMs is positively correlated with their ability to encode syntactic\nand semantic structures of sentences. Specifically, we find that the LLMs which\ncapture syntactic structures better, also have higher abilities in identifying\nsentence analogies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wijesiriwardene_T/0/1/0/all/0/1\">Thilini Wijesiriwardene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wickramarachchi_R/0/1/0/all/0/1\">Ruwan Wickramarachchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reganti_A/0/1/0/all/0/1\">Aishwarya Naresh Reganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Faithfulness Measurable Masked Language Models. (arXiv:2310.07819v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07819","description":"<p>A common approach to explain NLP models, is to use importance measures that\nexpress which tokens are important for a prediction. Unfortunately, such\nexplanations are often wrong despite being persuasive. Therefore, it is\nessential to measure their faithfulness. One such metric is if tokens are truly\nimportant, then masking them should result in worse model performance. However,\ntoken masking introduces out-of-distribution issues and existing solutions are\ncomputationally expensive and employ proxy-models. Furthermore, other metrics\nare very limited in scope. In this work, we propose an inherently faithfulness\nmeasurable model that addresses these challenges. This is achieved by using a\nnovel fine-tuning method that incorporates masking, such that masking tokens\nbecome in-distribution by design. This differs from existing approaches, which\nare completely model-agnostic but are inapplicable in practice. We demonstrate\nthe generality of our approach by applying it to various tasks and validate it\nusing statistical in-distribution tests. Additionally, because masking is\nin-distribution, importance measures which themselves use masking become more\nfaithful, thus our model becomes more explainable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1\">Andreas Madsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-autoregressive Text Editing with Copy-aware Latent Alignments. (arXiv:2310.07821v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07821","description":"<p>Recent work has witnessed a paradigm shift from Seq2Seq to Seq2Edit in the\nfield of text editing, with the aim of addressing the slow autoregressive\ninference problem posed by the former. Despite promising results, Seq2Edit\napproaches still face several challenges such as inflexibility in generation\nand difficulty in generalizing to other languages. In this work, we propose a\nnovel non-autoregressive text editing method to circumvent the above issues, by\nmodeling the edit process with latent CTC alignments. We make a crucial\nextension to CTC by introducing the copy operation into the edit space, thus\nenabling more efficient management of textual overlap in editing. We conduct\nextensive experiments on GEC and sentence fusion tasks, showing that our\nproposed method significantly outperforms existing Seq2Edit models and achieves\nsimilar or even better results than Seq2Seq with over $4\\times$ speedup.\nMoreover, it demonstrates good generalizability on German and Russian. In-depth\nanalyses reveal the strengths of our method in terms of the robustness under\nvarious scenarios and generating fluent and flexible outputs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_G/0/1/0/all/0/1\">Guohong Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Antarlekhaka: A Comprehensive Tool for Multi-task Natural Language Annotation. (arXiv:2310.07826v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07826","description":"<p>One of the primary obstacles in the advancement of Natural Language\nProcessing (NLP) technologies for low-resource languages is the lack of\nannotated datasets for training and testing machine learning models. In this\npaper, we present Antarlekhaka, a tool for manual annotation of a comprehensive\nset of tasks relevant to NLP. The tool is Unicode-compatible,\nlanguage-agnostic, Web-deployable and supports distributed annotation by\nmultiple simultaneous annotators. The system sports user-friendly interfaces\nfor 8 categories of annotation tasks. These, in turn, enable the annotation of\na considerably larger set of NLP tasks. The task categories include two\nlinguistic tasks not handled by any other tool, namely, sentence boundary\ndetection and deciding canonical word order, which are important tasks for text\nthat is in the form of poetry. We propose the idea of sequential annotation\nbased on small text units, where an annotator performs several tasks related to\na single text unit before proceeding to the next unit. The research\napplications of the proposed mode of multi-task annotation are also discussed.\nAntarlekhaka outperforms other annotation tools in objective evaluation. It has\nbeen also used for two real-life annotation tasks on two different languages,\nnamely, Sanskrit and Bengali. The tool is available at\nhttps://github.com/Antarlekhaka/code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Terdalkar_H/0/1/0/all/0/1\">Hrishikesh Terdalkar</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a> (1) ((1) Indian Institute of Technology Kanpur)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does Synthetic Data Make Large Language Models More Efficient?. (arXiv:2310.07830v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07830","description":"<p>Natural Language Processing (NLP) has undergone transformative changes with\nthe advent of deep learning methodologies. One challenge persistently\nconfronting researchers is the scarcity of high-quality, annotated datasets\nthat drive these models. This paper explores the nuances of synthetic data\ngeneration in NLP, with a focal point on template-based question generation. By\nassessing its advantages, including data augmentation potential and the\nintroduction of structured variety, we juxtapose these benefits against\ninherent limitations, such as the risk of overfitting and the constraints posed\nby pre-defined templates. Drawing from empirical evaluations, we demonstrate\nthe impact of template-based synthetic data on the performance of modern\ntransformer models. We conclude by emphasizing the delicate balance required\nbetween synthetic and real-world data, and the future trajectories of\nintegrating synthetic data in model training pipelines. The findings aim to\nguide NLP practitioners in harnessing synthetic data's potential, ensuring\noptimal model performance in diverse applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gholami_S/0/1/0/all/0/1\">Sia Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omar_M/0/1/0/all/0/1\">Marwan Omar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Framework for Question-Answering in Sanskrit through Automated Construction of Knowledge Graphs. (arXiv:2310.07848v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07848","description":"<p>Sanskrit (sa\\d{m}sk\\d{r}ta) enjoys one of the largest and most varied\nliterature in the whole world. Extracting the knowledge from it, however, is a\nchallenging task due to multiple reasons including complexity of the language\nand paucity of standard natural language processing tools. In this paper, we\ntarget the problem of building knowledge graphs for particular types of\nrelationships from sa\\d{m}sk\\d{r}ta texts. We build a natural language\nquestion-answering system in sa\\d{m}sk\\d{r}ta that uses the knowledge graph to\nanswer factoid questions. We design a framework for the overall system and\nimplement two separate instances of the system on human relationships from\nmah\\=abh\\=arata and r\\=am\\=aya\\d{n}a, and one instance on synonymous\nrelationships from bh\\=avaprak\\=a\\'sa nigha\\d{n}\\d{t}u, a technical text from\n\\=ayurveda. We show that about 50% of the factoid questions can be answered\ncorrectly by the system. More importantly, we analyse the shortcomings of the\nsystem in detail for each step, and discuss the possible ways forward.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Terdalkar_H/0/1/0/all/0/1\">Hrishikesh Terdalkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations. (arXiv:2310.07849v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07849","description":"<p>The collection and curation of high-quality training data is crucial for\ndeveloping text classification models with superior performance, but it is\noften associated with significant costs and time investment. Researchers have\nrecently explored using large language models (LLMs) to generate synthetic\ndatasets as an alternative approach. However, the effectiveness of the\nLLM-generated synthetic data in supporting model training is inconsistent\nacross different classification tasks. To better understand factors that\nmoderate the effectiveness of the LLM-generated synthetic data, in this study,\nwe look into how the performance of models trained on these synthetic data may\nvary with the subjectivity of classification. Our results indicate that\nsubjectivity, at both the task level and instance level, is negatively\nassociated with the performance of the model trained on synthetic data. We\nconclude by discussing the implications of our work on the potential and\nlimitations of leveraging LLM for synthetic data generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuoyan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hangxiao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhuoran Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Ming Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing Evaluation Metrics for Neural Test Oracle Generation. (arXiv:2310.07856v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07856","description":"<p>In this work, we revisit existing oracle generation studies plus ChatGPT to\nempirically investigate the current standing of their performance in both\nNLG-based and test adequacy metrics. Specifically, we train and run four\nstate-of-the-art test oracle generation models on five NLG-based and two test\nadequacy metrics for our analysis. We apply two different correlation analyses\nbetween these two different sets of metrics. Surprisingly, we found no\nsignificant correlation between the NLG-based metrics and test adequacy\nmetrics. For instance, oracles generated from ChatGPT on the project\nactivemq-artemis had the highest performance on all the NLG-based metrics among\nthe studied NOGs, however, it had the most number of projects with a decrease\nin test adequacy metrics compared to all the studied NOGs. We further conduct a\nqualitative analysis to explore the reasons behind our observations, we found\nthat oracles with high NLG-based metrics but low test adequacy metrics tend to\nhave complex or multiple chained method invocations within the oracle's\nparameters, making it hard for the model to generate completely, affecting the\ntest adequacy metrics. On the other hand, oracles with low NLG-based metrics\nbut high test adequacy metrics tend to have to call different assertion types\nor a different method that functions similarly to the ones in the ground truth.\nOverall, this work complements prior studies on test oracle generation with an\nextensive performance evaluation with both NLG and test adequacy metrics and\nprovides guidelines for better assessment of deep learning applications in\nsoftware test generation in the future.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jiho Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hemmati_H/0/1/0/all/0/1\">Hadi Hemmati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_M/0/1/0/all/0/1\">Moshi Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Song Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TabLib: A Dataset of 627M Tables with Context. (arXiv:2310.07875v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07875","description":"<p>It is well-established that large, diverse datasets play a pivotal role in\nthe performance of modern AI systems for text and image modalities. However,\nthere are no datasets for tabular data of comparable size and diversity to\nthose available for text and images. Thus we present \"TabLib'', a compilation\nof 627 million tables totaling 69 TiB, along with 867B tokens of context.\nTabLib was extracted from numerous file formats, including CSV, HTML, SQLite,\nPDF, Excel, and others, sourced from GitHub and Common Crawl. The size and\ndiversity of TabLib offer considerable promise in the table modality,\nreminiscent of the original promise of foundational datasets for text and\nimages, such as The Pile and LAION.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eggert_G/0/1/0/all/0/1\">Gus Eggert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_K/0/1/0/all/0/1\">Kevin Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biven_M/0/1/0/all/0/1\">Mike Biven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waugh_J/0/1/0/all/0/1\">Justin Waugh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LangNav: Language as a Perceptual Representation for Navigation. (arXiv:2310.07889v1 [cs.CV])","link":"http://arxiv.org/abs/2310.07889","description":"<p>We explore the use of language as a perceptual representation for\nvision-and-language navigation. Our approach uses off-the-shelf vision systems\n(for image captioning and object detection) to convert an agent's egocentric\npanoramic view at each time step into natural language descriptions. We then\nfinetune a pretrained language model to select an action, based on the current\nview and the trajectory history, that would best fulfill the navigation\ninstructions. In contrast to the standard setup which adapts a pretrained\nlanguage model to work directly with continuous visual features from pretrained\nvision models, our approach instead uses (discrete) language as the perceptual\nrepresentation. We explore two use cases of our language-based navigation\n(LangNav) approach on the R2R vision-and-language navigation benchmark:\ngenerating synthetic trajectories from a prompted large language model (GPT-4)\nwith which to finetune a smaller language model; and sim-to-real transfer where\nwe transfer a policy learned on a simulated environment (ALFRED) to a\nreal-world environment (R2R). Our approach is found to improve upon strong\nbaselines that rely on visual features in settings where only a few gold\ntrajectories (10-100) are available, demonstrating the potential of using\nlanguage as a perceptual representation for navigation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1\">Bowen Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1\">Rameswar Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">SouYoung Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliva_A/0/1/0/all/0/1\">Aude Oliva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1\">Phillip Isola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pit One Against Many: Leveraging Attention-head Embeddings for Parameter-efficient Multi-head Attention. (arXiv:2310.07911v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07911","description":"<p>Scaling pre-trained language models has resulted in large performance gains\nin various natural language processing tasks but comes with a large cost in\nmemory requirements. Inspired by the position embeddings in transformers, we\naim to simplify and reduce the memory footprint of the multi-head attention\n(MHA) mechanism. We propose an alternative module that uses only a single\nshared projection matrix and multiple head embeddings (MHE), i.e. one per head.\nWe empirically demonstrate that our MHE attention is substantially more memory\nefficient compared to alternative attention mechanisms while achieving high\npredictive performance retention ratio to vanilla MHA on several downstream\ntasks. MHE attention only requires a negligible fraction of additional\nparameters ($3nd$, where $n$ is the number of attention heads and $d$ the size\nof the head embeddings) compared to a single-head attention, while MHA requires\n$(3n^2-3n)d^2-3nd$ additional parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Huiyin Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Expresssive Power of Transformers with Chain of Thought. (arXiv:2310.07923v1 [cs.LG])","link":"http://arxiv.org/abs/2310.07923","description":"<p>Recent theoretical work has identified surprisingly simple reasoning\nproblems, such as checking if two nodes in a graph are connected or simulating\nfinite-state machines, that are provably unsolvable by standard transformers\nthat answer immediately after reading their input. However, in practice,\ntransformers' reasoning can be improved by allowing them to use a \"chain of\nthought\" or \"scratchpad\", i.e., generate and condition on a sequence of\nintermediate tokens before answering. Motivated by this, we ask: Does such\nintermediate generation fundamentally extend the computational power of a\ndecoder-only transformer? We show that the answer is yes, but the amount of\nincrease depends crucially on the amount of intermediate generation. For\ninstance, we find that transformer decoders with a logarithmic number of\ndecoding steps (w.r.t. the input length) push the limits of standard\ntransformers only slightly, while a linear number of decoding steps adds a\nclear new ability (under standard complexity conjectures): recognizing all\nregular languages. Our results also imply that linear steps keep transformer\ndecoders within context-sensitive languages, and polynomial steps make them\nrecognize exactly the class of polynomial-time solvable problems -- the first\nexact characterization of a type of transformers in terms of standard\ncomplexity classes. Together, our results provide a nuanced framework for\nunderstanding how the length of a transformer's chain of thought or scratchpad\nimpacts its reasoning power.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Crosslingual Structural Priming and the Pre-Training Dynamics of Bilingual Language Models. (arXiv:2310.07929v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07929","description":"<p>Do multilingual language models share abstract grammatical representations\nacross languages, and if so, when do these develop? Following Sinclair et al.\n(2022), we use structural priming to test for abstract grammatical\nrepresentations with causal effects on model outputs. We extend the approach to\na Dutch-English bilingual setting, and we evaluate a Dutch-English language\nmodel during pre-training. We find that crosslingual structural priming effects\nemerge early after exposure to the second language, with less than 1M tokens of\ndata in that language. We discuss implications for data contamination,\nlow-resource transfer, and how abstract grammatical representations emerge in\nmultilingual models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arnett_C/0/1/0/all/0/1\">Catherine Arnett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Tyler A. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michaelov_J/0/1/0/all/0/1\">James A. Michaelov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin K. Bergen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"D2 Pruning: Message Passing for Balancing Diversity and Difficulty in Data Pruning. (arXiv:2310.07931v1 [cs.LG])","link":"http://arxiv.org/abs/2310.07931","description":"<p>Analytical theories suggest that higher-quality data can lead to lower test\nerrors in models trained on a fixed data budget. Moreover, a model can be\ntrained on a lower compute budget without compromising performance if a dataset\ncan be stripped of its redundancies. Coreset selection (or data pruning) seeks\nto select a subset of the training data so as to maximize the performance of\nmodels trained on this subset, also referred to as coreset. There are two\ndominant approaches: (1) geometry-based data selection for maximizing data\ndiversity in the coreset, and (2) functions that assign difficulty scores to\nsamples based on training dynamics. Optimizing for data diversity leads to a\ncoreset that is biased towards easier samples, whereas, selection by difficulty\nranking omits easy samples that are necessary for the training of deep learning\nmodels. This demonstrates that data diversity and importance scores are two\ncomplementary factors that need to be jointly considered during coreset\nselection. We represent a dataset as an undirected graph and propose a novel\npruning algorithm, D2 Pruning, that uses forward and reverse message passing\nover this dataset graph for coreset selection. D2 Pruning updates the\ndifficulty scores of each example by incorporating the difficulty of its\nneighboring examples in the dataset graph. Then, these updated difficulty\nscores direct a graph-based sampling method to select a coreset that\nencapsulates both diverse and difficult regions of the dataset space. We\nevaluate supervised and self-supervised versions of our method on various\nvision and language datasets. Results show that D2 Pruning improves coreset\nselection over previous state-of-the-art methods for up to 70% pruning rates.\nAdditionally, we find that using D2 Pruning for filtering large multimodal\ndatasets leads to increased diversity in the dataset and improved\ngeneralization of pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maharana_A/0/1/0/all/0/1\">Adyasha Maharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1\">Prateek Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A New Approach Towards Autoformalization. (arXiv:2310.07957v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07957","description":"<p>Verifying mathematical proofs is difficult, but can be automated with the\nassistance of a computer. Autoformalization is the task of automatically\ntranslating natural language mathematics into a formal language that can be\nverified by a program. This is a challenging task, and especially for\nhigher-level mathematics found in research papers. Research paper mathematics\nrequires large amounts of background and context. In this paper, we propose an\navenue towards tackling autoformalization for research-level mathematics, by\nbreaking the task into easier and more approachable subtasks: unlinked\nformalization (formalization with unlinked definitions and theorems), entity\nlinking (linking to the proper theorems and definitions), and finally adjusting\ntypes so it passes the type checker. In addition, we present arXiv2Formal, a\nbenchmark dataset for unlinked formalization consisting of 50 theorems\nformalized for the Lean theorem prover sampled from papers on arXiv.org. We\nwelcome any contributions from the community to future versions of this\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1\">Nilay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flanigan_J/0/1/0/all/0/1\">Jeffrey Flanigan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1\">Rahul Saha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clustering of Spell Variations for Proper Nouns Transliterated from the other languages. (arXiv:2310.07962v1 [cs.CL])","link":"http://arxiv.org/abs/2310.07962","description":"<p>One of the prominent problems with processing and operating on text data is\nthe non uniformity of it. Due to the change in the dialects and languages, the\ncaliber of translation is low. This creates a unique problem while using NLP in\ntext data; which is the spell variation arising from the inconsistent\ntranslations and transliterations. This problem can also be further aggravated\nby the human error arising from the various ways to write a Proper Noun from an\nIndian language into its English equivalent. Translating proper nouns\noriginating from Indian languages can be complicated as some proper nouns are\nalso used as common nouns which might be taken literally. Applications of NLP\nthat require addresses, names and other proper nouns face this problem\nfrequently. We propose a method to cluster these spell variations for proper\nnouns using ML techniques and mathematical similarity equations. We aimed to\nuse Affinity Propagation to determine relative similarity between the tokens.\nThe results are augmented by filtering the token-variation pair by a similarity\nthreshold. We were able to reduce the spell variations by a considerable\namount. This application can significantly reduce the amount of human\nannotation efforts needed for data cleansing and formatting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pawar_P/0/1/0/all/0/1\">Prathamesh Pawar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Think, Act, and Ask: Open-World Interactive Personalized Robot Navigation. (arXiv:2310.07968v1 [cs.RO])","link":"http://arxiv.org/abs/2310.07968","description":"<p>Zero-Shot Object Navigation (ZSON) enables agents to navigate towards\nopen-vocabulary objects in unknown environments. The existing works of ZSON\nmainly focus on following individual instructions to find generic object\nclasses, neglecting the utilization of natural language interaction and the\ncomplexities of identifying user-specific objects. To address these\nlimitations, we introduce Zero-shot Interactive Personalized Object Navigation\n(ZIPON), where robots need to navigate to personalized goal objects while\nengaging in conversations with users. To solve ZIPON, we propose a new\nframework termed Open-woRld Interactive persOnalized Navigation (ORION), which\nuses Large Language Models (LLMs) to make sequential decisions to manipulate\ndifferent modules for perception, navigation and communication. Experimental\nresults show that the performance of interactive agents that can leverage user\nfeedback exhibits significant improvement. However, obtaining a good balance\nbetween task completion and the efficiency of navigation and interaction\nremains challenging for all methods. We further provide more findings on the\nimpact of diverse user feedback forms on the agents' performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yinpei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1\">Run Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sikai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_J/0/1/0/all/0/1\">Joyce Chai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing Large Language Models' Empathetic Response Generation Capabilities for Online Mental Health Counselling Support. (arXiv:2310.08017v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08017","description":"<p>Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious information-seeking and reasoning tasks. These computational systems\ndrive state-of-the-art dialogue systems, such as ChatGPT and Bard. They also\ncarry substantial promise in meeting the growing demands of mental health care,\nalbeit relatively unexplored. As such, this study sought to examine LLMs'\ncapability to generate empathetic responses in conversations that emulate those\nin a mental health counselling setting. We selected five LLMs: version 3.5 and\nversion 4 of the Generative Pre-training (GPT), Vicuna FastChat-T5, Pathways\nLanguage Model (PaLM) version 2, and Falcon-7B-Instruct. Based on a simple\ninstructional prompt, these models responded to utterances derived from the\nEmpatheticDialogues (ED) dataset. Using three empathy-related metrics, we\ncompared their responses to those from traditional response generation dialogue\nsystems, which were fine-tuned on the ED dataset, along with human-generated\nresponses. Notably, we discovered that responses from the LLMs were remarkably\nmore empathetic in most scenarios. We position our findings in light of\ncatapulting advancements in creating empathetic conversational systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loh_S/0/1/0/all/0/1\">Siyuan Brandon Loh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raamkumar_A/0/1/0/all/0/1\">Aravind Sesagiri Raamkumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Large Language Models for Multi-Modal Out-of-Distribution Detection. (arXiv:2310.08027v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08027","description":"<p>Out-of-distribution (OOD) detection is essential for reliable and trustworthy\nmachine learning. Recent multi-modal OOD detection leverages textual\ninformation from in-distribution (ID) class names for visual OOD detection, yet\nit currently neglects the rich contextual information of ID classes. Large\nlanguage models (LLMs) encode a wealth of world knowledge and can be prompted\nto generate descriptive features for each class. Indiscriminately using such\nknowledge causes catastrophic damage to OOD detection due to LLMs'\nhallucinations, as is observed by our analysis. In this paper, we propose to\napply world knowledge to enhance OOD detection performance through selective\ngeneration from LLMs. Specifically, we introduce a consistency-based\nuncertainty calibration method to estimate the confidence score of each\ngeneration. We further extract visual objects from each image to fully\ncapitalize on the aforementioned world knowledge. Extensive experiments\ndemonstrate that our method consistently outperforms the state-of-the-art.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_H/0/1/0/all/0/1\">Hao Lang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kaisheng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongbin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models. (arXiv:2310.08041v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08041","description":"<p>Large Language Models (LLMs) excel in NLP, but their demands hinder their\nwidespread deployment. While Quantization-Aware Training (QAT) offers a\nsolution, its extensive training costs make Post-Training Quantization (PTQ) a\nmore practical approach for LLMs. In existing studies, activation outliers in\nparticular channels are identified as the bottleneck to PTQ accuracy. They\npropose to transform the magnitudes from activations to weights, which however\noffers limited alleviation or suffers from unstable gradients, resulting in a\nsevere performance drop at low-bitwidth. In this paper, we propose QLLM, an\naccurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM\nintroduces an adaptive channel reassembly technique that reallocates the\nmagnitude of outliers to other channels, thereby mitigating their impact on the\nquantization range. This is achieved by channel disassembly and channel\nassembly, which first breaks down the outlier channels into several\nsub-channels to ensure a more balanced distribution of activation magnitudes.\nThen similar channels are merged to maintain the original channel number for\nefficiency. Additionally, an adaptive strategy is designed to autonomously\ndetermine the optimal number of sub-channels for channel disassembly. To\nfurther compensate for the performance loss caused by quantization, we propose\nan efficient tuning method that only learns a small number of low-rank weights\nwhile freezing the pre-trained quantized model. After training, these low-rank\nparameters can be fused into the frozen weights without affecting inference.\nExtensive experiments on LLaMA-1 and LLaMA-2 show that QLLM can obtain accurate\nquantized models efficiently. For example, QLLM quantizes the 4-bit LLaMA-2-70B\nwithin 10 hours on a single A100-80G GPU, outperforming the previous\nstate-of-the-art method by 7.89% on the average accuracy across five zero-shot\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiuying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zhiwei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1\">Bohan Zhuang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Negative Pairs in Code Search. (arXiv:2310.08069v1 [cs.SE])","link":"http://arxiv.org/abs/2310.08069","description":"<p>Recently, contrastive learning has become a key component in fine-tuning code\nsearch models for software development efficiency and effectiveness. It pulls\ntogether positive code snippets while pushing negative samples away given\nsearch queries. Among contrastive learning, InfoNCE is the most widely used\nloss function due to its better performance. However, the following problems in\nnegative samples of InfoNCE may deteriorate its representation learning: 1) The\nexistence of false negative samples in large code corpora due to duplications.\n2). The failure to explicitly differentiate between the potential relevance of\nnegative samples. As an example, a bubble sorting algorithm example is less\n``negative'' than a file saving function for the quick sorting algorithm query.\nIn this paper, we tackle the above problems by proposing a simple yet effective\nSoft-InfoNCE loss that inserts weight terms into InfoNCE. In our proposed loss\nfunction, we apply three methods to estimate the weights of negative pairs and\nshow that the vanilla InfoNCE loss is a special case of Soft-InfoNCE.\nTheoretically, we analyze the effects of Soft-InfoNCE on controlling the\ndistribution of learnt code representations and on deducing a more precise\nmutual information estimation. We furthermore discuss the superiority of\nproposed loss functions with other design alternatives. Extensive experiments\ndemonstrate the effectiveness of Soft-InfoNCE and weights estimation methods\nunder state-of-the-art code search models on a large-scale public dataset\nconsisting of six programming languages. Source code is available at\n\\url{https://github.com/Alex-HaochenLi/Soft-InfoNCE}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haochen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training Generative Question-Answering on Synthetic Data Obtained from an Instruct-tuned Mo. (arXiv:2310.08072v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08072","description":"<p>This paper presents a simple and cost-effective method for synthesizing data\nto train question-answering systems. For training, fine-tuning GPT models is a\ncommon practice in resource-rich languages like English, however, it becomes\nchallenging for non-English languages due to the scarcity of sufficient\nquestion-answer (QA) pairs. Existing approaches use question and answer\ngenerators trained on human-authored QA pairs, which involves substantial human\nexpenses. In contrast, we use an instruct-tuned model to generate QA pairs in a\nzero-shot or few-shot manner. We conduct experiments to compare various\nstrategies for obtaining QA pairs from the instruct-tuned model. The results\ndemonstrate that a model trained on our proposed synthetic data achieves\ncomparable performance to a model trained on manually curated datasets, without\nincurring human costs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_K/0/1/0/all/0/1\">Kosuke Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omi_T/0/1/0/all/0/1\">Takahiro Omi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arima_K/0/1/0/all/0/1\">Kosuke Arima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishigaki_T/0/1/0/all/0/1\">Tatsuya Ishigaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"To token or not to token: A Comparative Study of Text Representations for Cross-Lingual Transfer. (arXiv:2310.08078v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08078","description":"<p>Choosing an appropriate tokenization scheme is often a bottleneck in\nlow-resource cross-lingual transfer. To understand the downstream implications\nof text representation choices, we perform a comparative analysis on language\nmodels having diverse text representation modalities including 2\nsegmentation-based models (\\texttt{BERT}, \\texttt{mBERT}), 1 image-based model\n(\\texttt{PIXEL}), and 1 character-level model (\\texttt{CANINE}). First, we\npropose a scoring Language Quotient (LQ) metric capable of providing a weighted\nrepresentation of both zero-shot and few-shot evaluation combined. Utilizing\nthis metric, we perform experiments comprising 19 source languages and 133\ntarget languages on three tasks (POS tagging, Dependency parsing, and NER). Our\nanalysis reveals that image-based models excel in cross-lingual transfer when\nlanguages are closely related and share visually similar scripts. However, for\ntasks biased toward word meaning (POS, NER), segmentation-based models prove to\nbe superior. Furthermore, in dependency parsing tasks where word relationships\nplay a crucial role, models with their character-level focus, outperform\nothers. Finally, we propose a recommendation scheme based on our findings to\nguide model selection according to task and language requirements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Md Mushfiqur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakib_F/0/1/0/all/0/1\">Fardin Ahsan Sakib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Low-Resource Clickbait Spoiling for Indonesian via Question Answering. (arXiv:2310.08085v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08085","description":"<p>Clickbait spoiling aims to generate a short text to satisfy the curiosity\ninduced by a clickbait post. As it is a newly introduced task, the dataset is\nonly available in English so far. Our contributions include the construction of\nmanually labeled clickbait spoiling corpus in Indonesian and an evaluation on\nusing cross-lingual zero-shot question answering-based models to tackle\nclikcbait spoiling for low-resource language like Indonesian. We utilize\nselection of multilingual language models. The experimental results suggest\nthat XLM-RoBERTa (large) model outperforms other models for phrase and passage\nspoilers, meanwhile, mDeBERTa (base) model outperforms other models for\nmultipart spoilers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maharani_N/0/1/0/all/0/1\">Ni Putu Intan Maharani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purwarianti_A/0/1/0/all/0/1\">Ayu Purwarianti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using Natural Language Processing. (arXiv:2310.08099v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08099","description":"<p>Climate change's impact on human health poses unprecedented and diverse\nchallenges. Unless proactive measures based on solid evidence are implemented,\nthese threats will likely escalate and continue to endanger human well-being.\nThe escalating advancements in information and communication technologies have\nfacilitated the widespread availability and utilization of social media\nplatforms. Individuals utilize platforms such as Twitter and Facebook to\nexpress their opinions, thoughts, and critiques on diverse subjects,\nencompassing the pressing issue of climate change. The proliferation of climate\nchange-related content on social media necessitates comprehensive analysis to\nglean meaningful insights. This paper employs natural language processing (NLP)\ntechniques to analyze climate change discourse and quantify the sentiment of\nclimate change-related tweets. We use ClimateBERT, a pretrained model\nfine-tuned specifically for the climate change domain. The objective is to\ndiscern the sentiment individuals express and uncover patterns in public\nopinion concerning climate change. Analyzing tweet sentiments allows a deeper\ncomprehension of public perceptions, concerns, and emotions about this critical\nglobal challenge. The findings from this experiment unearth valuable insights\ninto public sentiment and the entities associated with climate change\ndiscourse. Policymakers, researchers, and organizations can leverage such\nanalyses to understand public perceptions, identify influential actors, and\ndevise informed strategies to address climate change challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+K%2E_A/0/1/0/all/0/1\">Ajay Krishnan T. K.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anoop_V/0/1/0/all/0/1\">V. S. Anoop</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Promptor: A Conversational and Autonomous Prompt Generation Agent for Intelligent Text Entry Techniques. (arXiv:2310.08101v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08101","description":"<p>Text entry is an essential task in our day-to-day digital interactions.\nNumerous intelligent features have been developed to streamline this process,\nmaking text entry more effective, efficient, and fluid. These improvements\ninclude sentence prediction and user personalization. However, as deep\nlearning-based language models become the norm for these advanced features, the\nnecessity for data collection and model fine-tuning increases. These challenges\ncan be mitigated by harnessing the in-context learning capability of large\nlanguage models such as GPT-3.5. This unique feature allows the language model\nto acquire new skills through prompts, eliminating the need for data collection\nand fine-tuning. Consequently, large language models can learn various text\nprediction techniques. We initially showed that, for a sentence prediction\ntask, merely prompting GPT-3.5 surpassed a GPT-2 backed system and is\ncomparable with a fine-tuned GPT-3.5 model, with the latter two methods\nrequiring costly data collection, fine-tuning and post-processing. However, the\ntask of prompting large language models to specialize in specific text\nprediction tasks can be challenging, particularly for designers without\nexpertise in prompt engineering. To address this, we introduce Promptor, a\nconversational prompt generation agent designed to engage proactively with\ndesigners. Promptor can automatically generate complex prompts tailored to meet\nspecific needs, thus offering a solution to this challenge. We conducted a user\nstudy involving 24 participants creating prompts for three intelligent text\nentry tasks, half of the participants used Promptor while the other half\ndesigned prompts themselves. The results show that Promptor-designed prompts\nresult in a 35% increase in similarity and 22% in coherence over those by\ndesigners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junxiao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudley_J/0/1/0/all/0/1\">John J. Dudley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jingyao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byrne_B/0/1/0/all/0/1\">Bill Byrne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kristensson_P/0/1/0/all/0/1\">Per Ola Kristensson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"QASiNa: Religious Domain Question Answering using Sirah Nabawiyah. (arXiv:2310.08102v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08102","description":"<p>Nowadays, Question Answering (QA) tasks receive significant research focus,\nparticularly with the development of Large Language Model (LLM) such as Chat\nGPT [1]. LLM can be applied to various domains, but it contradicts the\nprinciples of information transmission when applied to the Islamic domain. In\nIslam we strictly regulates the sources of information and who can give\ninterpretations or tafseer for that sources [2]. The approach used by LLM to\ngenerate answers based on its own interpretation is similar to the concept of\ntafseer, LLM is neither an Islamic expert nor a human which is not permitted in\nIslam. Indonesia is the country with the largest Islamic believer population in\nthe world [3]. With the high influence of LLM, we need to make evaluation of\nLLM in religious domain. Currently, there is only few religious QA dataset\navailable and none of them using Sirah Nabawiyah especially in Indonesian\nLanguage. In this paper, we propose the Question Answering Sirah Nabawiyah\n(QASiNa) dataset, a novel dataset compiled from Sirah Nabawiyah literatures in\nIndonesian language. We demonstrate our dataset by using mBERT [4], XLM-R [5],\nand IndoBERT [6] which fine-tuned with Indonesian translation of SQuAD v2.0\n[7]. XLM-R model returned the best performance on QASiNa with EM of 61.20,\nF1-Score of 75.94, and Substring Match of 70.00. We compare XLM-R performance\nwith Chat GPT-3.5 and GPT-4 [1]. Both Chat GPT version returned lower EM and\nF1-Score with higher Substring Match, the gap of EM and Substring Match get\nwider in GPT-4. The experiment indicate that Chat GPT tends to give excessive\ninterpretations as evidenced by its higher Substring Match scores compared to\nEM and F1-Score, even after providing instruction and context. This concludes\nChat GPT is unsuitable for question answering task in religious domain\nespecially for Islamic religion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rizqullah_M/0/1/0/all/0/1\">Muhammad Razif Rizqullah</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Purwarianti_A/0/1/0/all/0/1\">Ayu Purwarianti</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a> (2) ((1) Bandung Institute of Technology, (2) Mohamed bin Zayed University of Artificial Intelligence)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Voice Conversion for Stuttered Speech, Instruments, Unseen Languages and Textually Described Voices. (arXiv:2310.08104v1 [eess.AS])","link":"http://arxiv.org/abs/2310.08104","description":"<p>Voice conversion aims to convert source speech into a target voice using\nrecordings of the target speaker as a reference. Newer models are producing\nincreasingly realistic output. But what happens when models are fed with\nnon-standard data, such as speech from a user with a speech impairment? We\ninvestigate how a recent voice conversion model performs on non-standard\ndownstream voice conversion tasks. We use a simple but robust approach called\nk-nearest neighbors voice conversion (kNN-VC). We look at four non-standard\napplications: stuttered voice conversion, cross-lingual voice conversion,\nmusical instrument conversion, and text-to-voice conversion. The latter\ninvolves converting to a target voice specified through a text description,\ne.g. \"a young man with a high-pitched voice\". Compared to an established\nbaseline, we find that kNN-VC retains high performance in stuttered and\ncross-lingual voice conversion. Results are more mixed for the musical\ninstrument and text-to-voice conversion tasks. E.g., kNN-VC works well on some\ninstruments like drums but not on others. Nevertheless, this shows that voice\nconversion models - and kNN-VC in particular - are increasingly applicable in a\nrange of non-standard downstream tasks. But there are still limitations when\nsamples are very far from the training distribution. Code, samples, trained\nmodels: https://rf5.github.io/sacair2023-knnvc-demo/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Baas_M/0/1/0/all/0/1\">Matthew Baas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kamper_H/0/1/0/all/0/1\">Herman Kamper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Who Wrote it and Why? Prompting Large-Language Models for Authorship Verification. (arXiv:2310.08123v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08123","description":"<p>Authorship verification (AV) is a fundamental task in natural language\nprocessing (NLP) and computational linguistics, with applications in forensic\nanalysis, plagiarism detection, and identification of deceptive content.\nExisting AV techniques, including traditional stylometric and deep learning\napproaches, face limitations in terms of data requirements and lack of\nexplainability. To address these limitations, this paper proposes PromptAV, a\nnovel technique that leverages Large-Language Models (LLMs) for AV by providing\nstep-by-step stylometric explanation prompts. PromptAV outperforms\nstate-of-the-art baselines, operates effectively with limited training data,\nand enhances interpretability through intuitive explanations, showcasing its\npotential as an effective and interpretable solution for the AV task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hung_C/0/1/0/all/0/1\">Chia-Yu Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiqiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yujia Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Roy Ka-Wei Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-grained Conversational Decoding via Isotropic and Proximal Search. (arXiv:2310.08130v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08130","description":"<p>General-purpose text decoding approaches are usually adopted for dialogue\nresponse generation. Although the quality of the generated responses can be\nimproved with dialogue-specific encoding methods, conversational decoding\nmethods are still under-explored. Inspired by \\citet{wu2023learning} that a\ngood dialogue feature space should follow the rules of locality and isotropy,\nwe present a fine-grained conversational decoding method, termed\n\\textit{isotropic and proximal search (IPS)}. Our method is designed to\ngenerate the semantic-concentrated response, while still maintaining\ninformativeness and discrimination against the context. Experiments show that\nour approach outperforms existing decoding strategies in the dialogue field\nacross both automatic and human evaluation metrics. More in-depth analyses\nfurther confirm the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuxuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiling Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Relevance of Phoneme Duration Variability of Synthesized Training Data for Automatic Speech Recognition. (arXiv:2310.08132v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08132","description":"<p>Synthetic data generated by text-to-speech (TTS) systems can be used to\nimprove automatic speech recognition (ASR) systems in low-resource or domain\nmismatch tasks. It has been shown that TTS-generated outputs still do not have\nthe same qualities as real data. In this work we focus on the temporal\nstructure of synthetic data and its relation to ASR training. By using a novel\noracle setup we show how much the degradation of synthetic data quality is\ninfluenced by duration modeling in non-autoregressive (NAR) TTS. To get\nreference phoneme durations we use two common alignment methods, a hidden\nMarkov Gaussian-mixture model (HMM-GMM) aligner and a neural connectionist\ntemporal classification (CTC) aligner. Using a simple algorithm based on random\nwalks we shift phoneme duration distributions of the TTS system closer to real\ndurations, resulting in an improvement of an ASR system using synthetic data in\na semi-supervised setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1\">Nick Rossenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilmes_B/0/1/0/all/0/1\">Benedikt Hilmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context Compression for Auto-regressive Transformers with Sentinel Tokens. (arXiv:2310.08152v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08152","description":"<p>The quadratic complexity of the attention module makes it gradually become\nthe bulk of compute in Transformer-based LLMs during generation. Moreover, the\nexcessive key-value cache that arises when dealing with long inputs also brings\nsevere issues on memory footprint and inference latency. In this work, we\npropose a plug-and-play approach that is able to incrementally compress the\nintermediate activation of a specified span of tokens into compact ones,\nthereby reducing both memory and computational cost when processing subsequent\ncontext. Experiments on both in-domain language modeling and zero-shot\nopen-ended document generation demonstrate the advantage of our approach over\nsparse attention baselines in terms of fluency, n-gram matching, and semantic\nsimilarity. At last, we comprehensively profile the benefit of context\ncompression on improving the system throughout. Code is available at\nhttps://github.com/DRSY/KV_Compression.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Siyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Q/0/1/0/all/0/1\">Qi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ziya-VL: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning. (arXiv:2310.08166v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08166","description":"<p>Recent advancements enlarge the capabilities of large language models (LLMs)\nin zero-shot image-to-text generation and understanding by integrating\nmulti-modal inputs. However, such success is typically limited to English\nscenarios due to the lack of large-scale and high-quality non-English\nmulti-modal resources, making it extremely difficult to establish competitive\ncounterparts in other languages. In this paper, we introduce the Ziya-VL\nseries, a set of bilingual large-scale vision-language models (LVLMs) designed\nto incorporate visual semantics into LLM for multi-modal dialogue. Composed of\nZiya-VL-Base and Ziya-VL-Chat, our models adopt the Querying Transformer from\nBLIP-2, further exploring the assistance of optimization schemes such as\ninstruction tuning, multi-stage training and low-rank adaptation module for\nvisual-language alignment. In addition, we stimulate the understanding ability\nof GPT-4 in multi-modal scenarios, translating our gathered English image-text\ndatasets into Chinese and generating instruction-response through the\nin-context learning method. The experiment results demonstrate that compared to\nthe existing LVLMs, Ziya-VL achieves competitive performance across a wide\nrange of English-only tasks including zero-shot image-text retrieval, image\ncaptioning, and visual question answering. The evaluation leaderboard accessed\nby GPT-4 also indicates that our models possess satisfactory image-text\nunderstanding and generation capabilities in Chinese multi-modal scenario\ndialogues. Code, demo and models are available at\n~\\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dixiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaojun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pingjian Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiclass Classification of Policy Documents with Large Language Models. (arXiv:2310.08167v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08167","description":"<p>Classifying policy documents into policy issue topics has been a long-time\neffort in political science and communication disciplines. Efforts to automate\ntext classification processes for social science research purposes have so far\nachieved remarkable results, but there is still a large room for progress. In\nthis work, we test the prediction performance of an alternative strategy, which\nrequires human involvement much less than full manual coding. We use the GPT\n3.5 and GPT 4 models of the OpenAI, which are pre-trained instruction-tuned\nLarge Language Models (LLM), to classify congressional bills and congressional\nhearings into Comparative Agendas Project's 21 major policy issue topics. We\npropose three use-case scenarios and estimate overall accuracies ranging from\n%58-83 depending on scenario and GPT model employed. The three scenarios aims\nat minimal, moderate, and major human interference, respectively. Overall, our\nresults point towards the insufficiency of complete reliance on GPT with\nminimal human intervention, an increasing accuracy along with the human effort\nexerted, and a surprisingly high accuracy achieved in the most humanly\ndemanding use-case. However, the superior use-case achieved the %83 accuracy on\nthe %65 of the data in which the two models agreed, suggesting that a similar\napproach to ours can be relatively easily implemented and allow for mostly\nautomated coding of a majority of a given dataset. This could free up resources\nallowing manual human coding of the remaining %35 of the data to achieve an\noverall higher level of accuracy while reducing costs significantly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gunes_E/0/1/0/all/0/1\">Erkan Gunes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florczak_C/0/1/0/all/0/1\">Christoffer Koch Florczak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simplification. (arXiv:2310.08170v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08170","description":"<p>Automatic evaluation for sentence simplification remains a challenging\nproblem. Most popular evaluation metrics require multiple high-quality\nreferences -- something not readily available for simplification -- which makes\nit difficult to test performance on unseen domains. Furthermore, most existing\nmetrics conflate simplicity with correlated attributes such as fluency or\nmeaning preservation. We propose a new learned evaluation metric (SLE) which\nfocuses on simplicity, outperforming almost all existing metrics in terms of\ncorrelation with human judgements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cripwell_L/0/1/0/all/0/1\">Liam Cripwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legrand_J/0/1/0/all/0/1\">Jo&#xeb;l Legrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardent_C/0/1/0/all/0/1\">Claire Gardent</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Cognitive Knowledge Structure of Large Language Models: An Educational Diagnostic Assessment Approach. (arXiv:2310.08172v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08172","description":"<p>Large Language Models (LLMs) have not only exhibited exceptional performance\nacross various tasks, but also demonstrated sparks of intelligence. Recent\nstudies have focused on assessing their capabilities on human exams and\nrevealed their impressive competence in different domains. However, cognitive\nresearch on the overall knowledge structure of LLMs is still lacking. In this\npaper, based on educational diagnostic assessment method, we conduct an\nevaluation using MoocRadar, a meticulously annotated human test dataset based\non Bloom Taxonomy. We aim to reveal the knowledge structures of LLMs and gain\ninsights of their cognitive capabilities. This research emphasizes the\nsignificance of investigating LLMs' knowledge and understanding the disparate\ncognitive patterns of LLMs. By shedding light on models' knowledge, researchers\ncan advance development and utilization of LLMs in a more informed and\neffective manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EIPE-text: Evaluation-Guided Iterative Plan Extraction for Long-Form Narrative Text Generation. (arXiv:2310.08185v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08185","description":"<p>Plan-and-Write is a common hierarchical approach in long-form narrative text\ngeneration, which first creates a plan to guide the narrative writing.\nFollowing this approach, several studies rely on simply prompting large\nlanguage models for planning, which often yields suboptimal results. In this\npaper, we propose a new framework called Evaluation-guided Iterative Plan\nExtraction for long-form narrative text generation (EIPE-text), which extracts\nplans from the corpus of narratives and utilizes the extracted plans to\nconstruct a better planner. EIPE-text has three stages: plan extraction,\nlearning, and inference. In the plan extraction stage, it iteratively extracts\nand improves plans from the narrative corpus and constructs a plan corpus. We\npropose a question answer (QA) based evaluation mechanism to automatically\nevaluate the plans and generate detailed plan refinement instructions to guide\nthe iterative improvement. In the learning stage, we build a better planner by\nfine-tuning with the plan corpus or in-context learning with examples in the\nplan corpus. Finally, we leverage a hierarchical approach to generate long-form\nnarratives. We evaluate the effectiveness of EIPE-text in the domains of novels\nand storytelling. Both GPT-4-based evaluations and human evaluations\ndemonstrate that our method can generate more coherent and relevant long-form\nnarratives. Our code will be released in the future.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+You_W/0/1/0/all/0/1\">Wang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaobo Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shaoguang Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1\">Maosong Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yuzhe Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiduo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Question Generation in Bengali. (arXiv:2310.08187v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08187","description":"<p>The task of Visual Question Generation (VQG) is to generate human-like\nquestions relevant to the given image. As VQG is an emerging research field,\nexisting works tend to focus only on resource-rich language such as English due\nto the availability of datasets. In this paper, we propose the first Bengali\nVisual Question Generation task and develop a novel transformer-based\nencoder-decoder architecture that generates questions in Bengali when given an\nimage. We propose multiple variants of models - (i) image-only: baseline model\nof generating questions from images without additional information, (ii)\nimage-category and image-answer-category: guided VQG where we condition the\nmodel to generate questions based on the answer and the category of expected\nquestion. These models are trained and evaluated on the translated VQAv2.0\ndataset. Our quantitative and qualitative results establish the first state of\nthe art models for VQG task in Bengali and demonstrate that our models are\ncapable of generating grammatically correct and relevant questions. Our\nquantitative results show that our image-cat model achieves a BLUE-1 score of\n33.12 and BLEU-3 score of 7.56 which is the highest of the other two variants.\nWe also perform a human evaluation to assess the quality of the generation\ntasks. Human evaluation suggests that image-cat model is capable of generating\ngoal-driven and attribute-specific questions and also stays relevant to the\ncorresponding image.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Mahmud Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_L/0/1/0/all/0/1\">Labiba Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruma_J/0/1/0/all/0/1\">Jannatul Ferdous Ruma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayeesha_T/0/1/0/all/0/1\">Tasmiah Tahsin Mayeesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_R/0/1/0/all/0/1\">Rashedur M. Rahman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SimCKP: Simple Contrastive Learning of Keyphrase Representations. (arXiv:2310.08221v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08221","description":"<p>Keyphrase generation (KG) aims to generate a set of summarizing words or\nphrases given a source document, while keyphrase extraction (KE) aims to\nidentify them from the text. Because the search space is much smaller in KE, it\nis often combined with KG to predict keyphrases that may or may not exist in\nthe corresponding document. However, current unified approaches adopt sequence\nlabeling and maximization-based generation that primarily operate at a token\nlevel, falling short in observing and scoring keyphrases as a whole. In this\nwork, we propose SimCKP, a simple contrastive learning framework that consists\nof two stages: 1) An extractor-generator that extracts keyphrases by learning\ncontext-aware phrase-level representations in a contrastive manner while also\ngenerating keyphrases that do not appear in the document; 2) A reranker that\nadapts scores for each generated phrase by likewise aligning their\nrepresentations with the corresponding document. Experimental results on\nmultiple benchmark datasets demonstrate the effectiveness of our proposed\napproach, which outperforms the state-of-the-art models by a significant\nmargin.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gwak_C/0/1/0/all/0/1\">Chaeheon Gwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Si Hyeong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast Word Error Rate Estimation Using Self-Supervised Representations For Speech And Text. (arXiv:2310.08225v1 [eess.AS])","link":"http://arxiv.org/abs/2310.08225","description":"<p>The quality of automatic speech recognition (ASR) is typically measured by\nword error rate (WER). WER estimation is a task aiming to predict the WER of an\nASR system, given a speech utterance and a transcription. This task has gained\nincreasing attention while advanced ASR systems are trained on large amounts of\ndata. In this case, WER estimation becomes necessary in many scenarios, for\nexample, selecting training data with unknown transcription quality or\nestimating the testing performance of an ASR system without ground truth\ntranscriptions. Facing large amounts of data, the computation efficiency of a\nWER estimator becomes essential in practical applications. However, previous\nworks usually did not consider it as a priority. In this paper, a Fast WER\nestimator (Fe-WER) using self-supervised learning representation (SSLR) is\nintroduced. The estimator is built upon SSLR aggregated by average pooling. The\nresults show that Fe-WER outperformed the e-WER3 baseline relatively by 19.69%\nand 7.16% on Ted-Lium3 in both evaluation metrics of root mean square error and\nPearson correlation coefficient, respectively. Moreover, the estimation\nweighted by duration was 10.43% when the target was 10.88%. Lastly, the\ninference speed was about 4x in terms of a real-time factor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Park_C/0/1/0/all/0/1\">Chanho Park</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_C/0/1/0/all/0/1\">Chengsong Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_M/0/1/0/all/0/1\">Mingjie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hain_T/0/1/0/all/0/1\">Thomas Hain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models are Universal Embedders. (arXiv:2310.08232v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08232","description":"<p>In the large language model (LLM) revolution, embedding is a key component of\nvarious systems. For example, it is used to retrieve knowledge or memories for\nLLMs, to build content moderation filters, etc. As such cases span from English\nto other natural or programming languages, from retrieval to classification and\nbeyond, it is desirable to build a unified embedding model rather than\ndedicated ones for each scenario. In this work, we make an initial step towards\nthis goal, demonstrating that multiple languages (both natural and programming)\npre-trained transformer decoders can embed universally when finetuned on\nlimited English data. We provide a comprehensive practice with thorough\nevaluations. On English MTEB, our models achieve competitive performance on\ndifferent embedding tasks by minimal training data. On other benchmarks, such\nas multilingual classification and code search, our models (without any\nsupervision) perform comparably to, or even surpass heavily supervised\nbaselines and/or APIs. These results provide evidence of a promising path\ntowards building powerful unified embedders that can be applied across tasks\nand languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zehan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yanzhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_D/0/1/0/all/0/1\">Dingkun Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Meishan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Who Said That? Benchmarking Social Media AI Detection. (arXiv:2310.08240v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08240","description":"<p>AI-generated text has proliferated across various online platforms, offering\nboth transformative prospects and posing significant risks related to\nmisinformation and manipulation. Addressing these challenges, this paper\nintroduces SAID (Social media AI Detection), a novel benchmark developed to\nassess AI-text detection models' capabilities in real social media platforms.\nIt incorporates real AI-generate text from popular social media platforms like\nZhihu and Quora. Unlike existing benchmarks, SAID deals with content that\nreflects the sophisticated strategies employed by real AI users on the Internet\nwhich may evade detection or gain visibility, providing a more realistic and\nchallenging evaluation landscape. A notable finding of our study, based on the\nZhihu dataset, reveals that annotators can distinguish between AI-generated and\nhuman-generated texts with an average accuracy rate of 96.5%. This finding\nnecessitates a re-evaluation of human capability in recognizing AI-generated\ntext in today's widely AI-influenced environment. Furthermore, we present a new\nuser-oriented AI-text detection challenge focusing on the practicality and\neffectiveness of identifying AI-generated text based on user information and\nmultiple responses. The experimental results demonstrate that conducting\ndetection tasks on actual social media platforms proves to be more challenging\ncompared to traditional simulated AI-text detection, resulting in a decreased\naccuracy. On the other hand, user-oriented AI-generated text detection\nsignificantly improve the accuracy of detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1\">Wanyun Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linqiu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianle Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_S/0/1/0/all/0/1\">Shuyang Cai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Impact of Co-occurrence on Factual Knowledge of Large Language Models. (arXiv:2310.08256v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08256","description":"<p>Large language models (LLMs) often make factually incorrect responses despite\ntheir success in various applications. In this paper, we hypothesize that\nrelying heavily on simple co-occurrence statistics of the pre-training corpora\nis one of the main factors that cause factual errors. Our results reveal that\nLLMs are vulnerable to the co-occurrence bias, defined as preferring frequently\nco-occurred words over the correct answer. Consequently, LLMs struggle to\nrecall facts whose subject and object rarely co-occur in the pre-training\ndataset although they are seen during finetuning. We show that co-occurrence\nbias remains despite scaling up model sizes or finetuning. Therefore, we\nsuggest finetuning on a debiased dataset to mitigate the bias by filtering out\nbiased samples whose subject-object co-occurrence count is high. Although\ndebiased finetuning allows LLMs to memorize rare facts in the training set, it\nis not effective in recalling rare facts unseen during finetuning. Further\nresearch in mitigation will help build reliable language models by preventing\npotential errors. The code is available at\n\\url{https://github.com/CheongWoong/impact_of_cooccurrence}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_C/0/1/0/all/0/1\">Cheongwoong Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaesik Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08279","description":"<p>Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce\nand infer missing connections within knowledge graphs. Text-based approaches,\nlike SimKGC, have outperformed graph embedding methods, showcasing the promise\nof inductive KGC. However, the efficacy of text-based methods hinges on the\nquality of entity textual descriptions. In this paper, we identify the key\nissue of whether large language models (LLMs) can generate effective text. To\nmitigate hallucination in LLM-generated text in this paper, we introduce a\nconstraint-based prompt that utilizes the entity and its textual description as\ncontextual constraints to enhance data quality. Our Constrained-Prompt\nKnowledge Graph Completion (CP-KGC) method demonstrates effective inference\nunder low resource computing conditions and surpasses prior results on the\nWN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC\ntasks and provides new directions for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Rui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Li Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing Odia Braille Literacy: The Influence of Speed on Error Reduction and Enhanced Comprehension. (arXiv:2310.08280v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08280","description":"<p>This study aims to conduct an extensive detailed analysis of the Odia Braille\nreading comprehension among students with visual disability. Specifically, the\nstudy explores their reading speed and hand or finger movements. The study also\naims to investigate any comprehension difficulties and reading errors they may\nencounter. Six students from the 9th and 10th grades, aged between 14 and 16,\nparticipated in the study. We observed participants hand movements to\nunderstand how reading errors were connected to hand movement and identify the\nstudents reading difficulties. We also evaluated the participants Odia Braille\nreading skills, including their reading speed (in words per minute), errors,\nand comprehension. The average speed of Odia Braille reader is 17.64wpm.\nAccording to the study, there was a noticeable correlation between reading\nspeed and reading errors. As reading speed decreased, the number of reading\nerrors tended to increase. Moreover, the study established a link between\nreduced Braille reading errors and improved reading comprehension. In contrast,\nthe study found that better comprehension was associated with increased reading\nspeed. The researchers concluded with some interesting findings about preferred\nBraille reading patterns. These findings have important theoretical,\ndevelopmental, and methodological implications for instruction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parida_M/0/1/0/all/0/1\">Monnie Parida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_M/0/1/0/all/0/1\">Manjira Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1\">Anupam Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_P/0/1/0/all/0/1\">Pabitra Mitra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Expanding the Vocabulary of BERT for Knowledge Base Construction. (arXiv:2310.08291v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08291","description":"<p>Knowledge base construction entails acquiring structured information to\ncreate a knowledge base of factual and relational data, facilitating question\nanswering, information retrieval, and semantic understanding. The challenge\ncalled \"Knowledge Base Construction from Pretrained Language Models\" at\nInternational Semantic Web Conference 2023 defines tasks focused on\nconstructing knowledge base using language model. Our focus was on Track 1 of\nthe challenge, where the parameters are constrained to a maximum of 1 billion,\nand the inclusion of entity descriptions within the prompt is prohibited.\n</p>\n<p>Although the masked language model offers sufficient flexibility to extend\nits vocabulary, it is not inherently designed for multi-token prediction. To\naddress this, we present Vocabulary Expandable BERT for knowledge base\nconstruction, which expand the language model's vocabulary while preserving\nsemantic embeddings for newly added words. We adopt task-specific\nre-pre-training on masked language model to further enhance the language model.\n</p>\n<p>Through experimentation, the results show the effectiveness of our\napproaches. Our framework achieves F1 score of 0.323 on the hidden test set and\n0.362 on the validation set, both data set is provided by the challenge.\nNotably, our framework adopts a lightweight language model (BERT-base, 0.13\nbillion parameters) and surpasses the model using prompts directly on large\nlanguage model (Chatgpt-3, 175 billion parameters). Besides, Token-Recode\nachieves comparable performances as Re-pretrain. This research advances\nlanguage understanding models by enabling the direct embedding of multi-token\nentities, signifying a substantial step forward in link prediction task in\nknowledge graph and metadata completion in data management.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celebi_R/0/1/0/all/0/1\">Remzi Celebi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MProto: Multi-Prototype Network with Denoised Optimal Transport for Distantly Supervised Named Entity Recognition. (arXiv:2310.08298v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08298","description":"<p>Distantly supervised named entity recognition (DS-NER) aims to locate entity\nmentions and classify their types with only knowledge bases or gazetteers and\nunlabeled corpus. However, distant annotations are noisy and degrade the\nperformance of NER models. In this paper, we propose a noise-robust prototype\nnetwork named MProto for the DS-NER task. Different from previous\nprototype-based NER methods, MProto represents each entity type with multiple\nprototypes to characterize the intra-class variance among entity\nrepresentations. To optimize the classifier, each token should be assigned an\nappropriate ground-truth prototype and we consider such token-prototype\nassignment as an optimal transport (OT) problem. Furthermore, to mitigate the\nnoise from incomplete labeling, we propose a novel denoised optimal transport\n(DOT) algorithm. Specifically, we utilize the assignment result between Other\nclass tokens and all prototypes to distinguish unlabeled entity tokens from\ntrue negatives. Experiments on several DS-NER benchmarks demonstrate that our\nMProto achieves state-of-the-art performance. The source code is now available\non Github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuhui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yongliang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zeqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1\">Wenqi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jietian Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1\">Shiliang Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Weiming Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning. (arXiv:2310.08309v1 [cs.CL])","link":"http://arxiv.org/abs/2310.08309","description":"<p>Large Language Models (LLMs) have recently gained the In-Context Learning\n(ICL) ability with the models scaling up, allowing them to quickly adapt to\ndownstream tasks with only a few demonstration examples prepended in the input\nsequence. Nonetheless, the current practice of ICL treats all demonstration\nexamples equally, which still warrants improvement, as the quality of examples\nis usually uneven. In this paper, we investigate how to determine approximately\noptimal weights for demonstration examples and how to apply them during ICL. To\nassess the quality of weights in the absence of additional validation data, we\ndesign a masked self-prediction (MSP) score that exhibits a strong correlation\nwith the final ICL performance. To expedite the weight-searching process, we\ndiscretize the continuous weight space and adopt beam search. With\napproximately optimal weights obtained, we further propose two strategies to\napply them to demonstrations at different model positions. Experimental results\non 8 text classification tasks show that our approach outperforms conventional\nICL by a large margin. Our code are publicly available at\nhttps:github.com/Zhe-Young/WICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhe Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Defending Our Privacy With Backdoors. (arXiv:2310.08320v1 [cs.LG])","link":"http://arxiv.org/abs/2310.08320","description":"<p>The proliferation of large AI models trained on uncurated, often sensitive\nweb-scraped data has raised significant privacy concerns. One of the concerns\nis that adversaries can extract information about the training data using\nprivacy attacks. Unfortunately, the task of removing specific information from\nthe models without sacrificing performance is not straightforward and has\nproven to be challenging. We propose a rather easy yet effective defense based\non backdoor attacks to remove private information such as names of individuals\nfrom models, and focus in this work on text encoders. Specifically, through\nstrategic insertion of backdoors, we align the embeddings of sensitive phrases\nwith those of neutral terms-\"a person\" instead of the person's name. Our\nempirical results demonstrate the effectiveness of our backdoor-based defense\non CLIP by assessing its performance using a specialized privacy attack for\nzero-shot classifiers. Our approach provides not only a new \"dual-use\"\nperspective on backdoor attacks, but also presents a promising avenue to\nenhance the privacy of individuals within models trained on uncurated\nweb-scraped data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hintersdorf_D/0/1/0/all/0/1\">Dominik Hintersdorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Struppek_L/0/1/0/all/0/1\">Lukas Struppek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neider_D/0/1/0/all/0/1\">Daniel Neider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1\">Kristian Kersting</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mGPT: Few-Shot Learners Go Multilingual. (arXiv:2204.07580v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.07580","description":"<p>Recent studies report that autoregressive language models can successfully\nsolve many NLP tasks via zero- and few-shot learning paradigms, which opens up\nnew possibilities for using the pre-trained language models. This paper\nintroduces two autoregressive GPT-like models with 1.3 billion and 13 billion\nparameters trained on 60 languages from 25 language families using Wikipedia\nand Colossal Clean Crawled Corpus. We reproduce the GPT-3 architecture using\nGPT-2 sources and the sparse attention mechanism; Deepspeed and Megatron\nframeworks allow us to parallelize the training and inference steps\neffectively. The resulting models show performance on par with the recently\nreleased XGLM models by Facebook, covering more languages and enhancing NLP\npossibilities for low resource languages of CIS countries and Russian small\nnations. We detail the motivation for the choices of the architecture design,\nthoroughly describe the data preparation pipeline, and train five small\nversions of the model to choose the most optimal multilingual tokenization\nstrategy. We measure the model perplexity in all covered languages and evaluate\nit on the wide spectre of multilingual tasks, including classification,\ngenerative, sequence labeling and knowledge probing. The models were evaluated\nwith the zero-shot and few-shot methods. Furthermore, we compared the\nclassification tasks with the state-of-the-art multilingual model XGLM. source\ncode and the mGPT XL model are publicly released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shliazhko_O/0/1/0/all/0/1\">Oleh Shliazhko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fenogenova_A/0/1/0/all/0/1\">Alena Fenogenova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonova_M/0/1/0/all/0/1\">Maria Tikhonova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikhailov_V/0/1/0/all/0/1\">Vladislav Mikhailov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozlova_A/0/1/0/all/0/1\">Anastasia Kozlova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shavrina_T/0/1/0/all/0/1\">Tatiana Shavrina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Security Vulnerabilities of Text-to-SQL Models. (arXiv:2211.15363v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.15363","description":"<p>Although it has been demonstrated that Natural Language Processing (NLP)\nalgorithms are vulnerable to deliberate attacks, the question of whether such\nweaknesses can lead to software security threats is under-explored. To bridge\nthis gap, we conducted vulnerability tests on Text-to-SQL systems that are\ncommonly used to create natural language interfaces to databases. We showed\nthat the Text-to-SQL modules within six commercial applications can be\nmanipulated to produce malicious code, potentially leading to data breaches and\nDenial of Service attacks. This is the first demonstration that NLP models can\nbe exploited as attack vectors in the wild. In addition, experiments using four\nopen-source language models verified that straightforward backdoor attacks on\nText-to-SQL systems achieve a 100% success rate without affecting their\nperformance. The aim of this work is to draw the community's attention to\npotential software security issues associated with NLP algorithms and encourage\nexploration of methods to mitigate against them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xutan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jingfeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1\">Mark Stevenson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speculative Decoding with Big Little Decoder. (arXiv:2302.07863v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07863","description":"<p>The recent emergence of Large Language Models based on the Transformer\narchitecture has enabled dramatic advancements in the field of Natural Language\nProcessing. However, these models have long inference latency, which limits\ntheir deployment and makes them prohibitively expensive for various real-time\napplications. The inference latency is further exacerbated by autoregressive\ngenerative tasks, as models need to run iteratively to generate tokens\nsequentially without leveraging token-level parallelization. To address this,\nwe propose Big Little Decoder (BiLD), a framework that can improve inference\nefficiency and latency for a wide range of text generation applications. The\nBiLD framework contains two models with different sizes that collaboratively\ngenerate text. The small model runs autoregressively to generate text with a\nlow inference cost, and the large model is only invoked occasionally to refine\nthe small model's inaccurate predictions in a non-autoregressive manner. To\ncoordinate the small and large models, BiLD introduces two simple yet effective\npolicies: (1) the fallback policy that determines when to hand control over to\nthe large model; and (2) the rollback policy that determines when the large\nmodel needs to correct the small model's inaccurate predictions. To evaluate\nour framework across different tasks and models, we apply BiLD to various text\ngeneration scenarios encompassing machine translation on IWSLT 2017 De-En and\nWMT 2014 De-En, and summarization on XSUM and CNN/DailyMail. On an NVIDIA T4\nGPU, our framework achieves a speedup of up to 2.12x speedup with minimal\ngeneration quality degradation. Furthermore, our framework is fully\nplug-and-play and can be applied without any modifications in the training\nprocess or model architecture. Our code is open-sourced\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sehoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1\">Karttikeya Mangalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Suhong Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1\">Michael W. Mahoney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1\">Amir Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1\">Kurt Keutzer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Pre-trained Vision and Language Models Answer Visual Information-Seeking Questions?. (arXiv:2302.11713v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2302.11713","description":"<p>Pre-trained vision and language models have demonstrated state-of-the-art\ncapabilities over existing tasks involving images and texts, including visual\nquestion answering. However, it remains unclear whether these models possess\nthe capability to answer questions that are not only querying visual content\nbut knowledge-intensive and information-seeking. In this study, we introduce\nInfoSeek, a visual question answering dataset tailored for information-seeking\nquestions that cannot be answered with only common sense knowledge. Using\nInfoSeek, we analyze various pre-trained visual question answering models and\ngain insights into their characteristics. Our findings reveal that\nstate-of-the-art pre-trained multi-modal models (e.g., PaLI-X, BLIP2, etc.)\nface challenges in answering visual information-seeking questions, but\nfine-tuning on the InfoSeek dataset elicits models to use fine-grained\nknowledge that was learned during their pre-training. Furthermore, we show that\naccurate visual entity recognition can be used to improve performance on\nInfoSeek by retrieving relevant documents, showing a significant space for\nimprovement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_Y/0/1/0/all/0/1\">Yi Luan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haitian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Ming-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing And Editing Inner Mechanisms Of Backdoored Language Models. (arXiv:2302.12461v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.12461","description":"<p>Poisoning of data sets is a potential security threat to large language\nmodels that can lead to backdoored models. A description of the internal\nmechanisms of backdoored language models and how they process trigger inputs,\ne.g., when switching to toxic language, has yet to be found. In this work, we\nstudy the internal representations of transformer-based backdoored language\nmodels and determine early-layer MLP modules as most important for the backdoor\nmechanism in combination with the initial embedding projection. We use this\nknowledge to remove, insert, and modify backdoor mechanisms with engineered\nreplacements that reduce the MLP module outputs to essentials for the backdoor\nmechanism. To this end, we introduce PCP ablation, where we replace transformer\nmodules with low-rank matrices based on the principal components of their\nactivations. We demonstrate our results on backdoored toy, backdoored large,\nand non-backdoored open-source models. We show that we can improve the backdoor\nrobustness of large language models by locally constraining individual modules\nduring fine-tuning on potentially poisonous data sets.\n</p>\n<p>Trigger warning: Offensive language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lamparth_M/0/1/0/all/0/1\">Max Lamparth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuel_A/0/1/0/all/0/1\">Anka Reuel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language Models. (arXiv:2304.00457v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.00457","description":"<p>Large Language Models (LLMs) have revolutionized natural language processing\nand demonstrated impressive capabilities in various tasks. Unfortunately, they\nare prone to hallucinations, where the model exposes incorrect or false\ninformation in its responses, which renders diligent evaluation approaches\nmandatory. While LLM performance in specific knowledge fields is often\nevaluated based on question and answer (Q&amp;A) datasets, such evaluations usually\nreport only a single accuracy number for the dataset, which often covers an\nentire field. This field-based evaluation, is problematic with respect to\ntransparency and model improvement. A stratified evaluation could instead\nreveal subfields, where hallucinations are more likely to occur and thus help\nto better assess LLMs' risks and guide their further development. To support\nsuch stratified evaluations, we propose LLMMaps as a novel visualization\ntechnique that enables users to evaluate LLMs' performance with respect to Q&amp;A\ndatasets. LLMMaps provide detailed insights into LLMs' knowledge capabilities\nin different subfields, by transforming Q&amp;A datasets as well as LLM responses\ninto an internal knowledge structure. An extension for comparative\nvisualization furthermore, allows for the detailed comparison of multiple LLMs.\nTo assess LLMMaps we use them to conduct a comparative analysis of several\nstate-of-the-art LLMs, such as BLOOM, GPT-2, GPT-3, ChatGPT and LLaMa-13B, as\nwell as two qualitative user evaluations. All necessary source code and data\nfor generating LLMMaps to be used in scientific publications and elsewhere is\navailable on GitHub: https://github.com/viscom-ulm/LLMMaps\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1\">Patrik Puchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poonam_P/0/1/0/all/0/1\">Poonam Poonam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onzenoodt_C/0/1/0/all/0/1\">Christian van Onzenoodt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1\">Timo Ropinski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models. (arXiv:2304.11657v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11657","description":"<p>Large language models (LLMs) can achieve highly effective performance on\nvarious reasoning tasks by incorporating step-by-step chain-of-thought (CoT)\nprompting as demonstrations. However, the reasoning chains of demonstrations\ngenerated by LLMs are prone to errors, which can subsequently lead to incorrect\nreasoning during inference. Furthermore, inappropriate exemplars (overly\nsimplistic or complex), can affect overall performance among varying levels of\ndifficulty. We introduce Iter-CoT (Iterative bootstrapping in Chain-of-Thoughts\nPrompting), an iterative bootstrapping approach for selecting exemplars and\ngenerating reasoning chains. By utilizing iterative bootstrapping, our approach\nenables LLMs to autonomously rectify errors, resulting in more precise and\ncomprehensive reasoning chains. Simultaneously, our approach selects\nchallenging yet answerable questions accompanied by reasoning chains as\nexemplars with a moderate level of difficulty, which enhances the LLMs'\ngeneralizability across varying levels of difficulty. Experimental results\nindicate that Iter-CoT exhibits superiority, achieving competitive performance\nacross three distinct reasoning tasks on ten datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiashuo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jian Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (arXiv:2305.07375v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07375","description":"<p>Causal reasoning ability is crucial for numerous NLP applications. Despite\nthe impressive emerging ability of ChatGPT in various NLP tasks, it is unclear\nhow well ChatGPT performs in causal reasoning. In this paper, we conduct the\nfirst comprehensive evaluation of the ChatGPT's causal reasoning capabilities.\nExperiments show that ChatGPT is not a good causal reasoner, but a good causal\nexplainer. Besides, ChatGPT has a serious hallucination on causal reasoning,\npossibly due to the reporting biases between causal and non-causal\nrelationships in natural language, as well as ChatGPT's upgrading processes,\nsuch as RLHF. The In-Context Learning (ICL) and Chain-of-Thought (CoT)\ntechniques can further exacerbate such causal hallucination. Additionally, the\ncausal reasoning ability of ChatGPT is sensitive to the words used to express\nthe causal concept in prompts, and close-ended prompts perform better than\nopen-ended prompts. For events in sentences, ChatGPT excels at capturing\nexplicit causality rather than implicit causality, and performs better in\nsentences with lower event density and smaller lexical distance between events.\nThe code is available on https://github.com/ArrogantL/ChatGPT4CausalReasoning .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jinglong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Social Dimensions of Self-Presentation in Social Media Biographies with an Identity-based Approach. (arXiv:2305.09548v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09548","description":"<p>Social media users on sites like Twitter, Instagram, and Tiktok use the\nprofile description, or bio, field of user profiles to present themselves to\nthe world. In contrast to the ``offline'' world, where social context often\nencourages us to adopt a single identity, the profile description is a\nfree-text field in which users are encouraged to present the self using\nmultiple, sometimes conflicting, social identities. While sociologists, social\npsychologists, sociolinguists, and increasingly computational social\nscientists, have developed a large and growing array of methods to estimate the\nmeaning of individual social identities, little work has attended to the ways\nin which social meanings emerge from the collections of social identities\npresent in social media bios. The present work proposes and evaluate three\nnovel, identity-based methods to measure the social dimensions of meaning\nexpressed in Twitter bios. We show that these models outperform reasonable\nbaselines with respect to 1) predicting which sets of identities are more\nlikely to co-occur within a single biography and 2) quantifying perceptions of\nentire social media biographies along salient dimensions of social meaning on\nTwitter, in particular partisanship. We demonstrate the utility of our method\nin a computational social science setting by using model outputs to better\nunderstand how self presentation along dimensions of partisanship, religion,\nage, and gender are related to the sharing of URLs on Twitter from low versus\nhigh quality news sites.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madani_N/0/1/0/all/0/1\">Navid Madani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandyopadhyay_R/0/1/0/all/0/1\">Rabiraj Bandyopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swire_Thompson_B/0/1/0/all/0/1\">Briony Swire-Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoder_M/0/1/0/all/0/1\">Michael Miller Yoder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joseph_K/0/1/0/all/0/1\">Kenneth Joseph</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SatLM: Satisfiability-Aided Language Models Using Declarative Prompting. (arXiv:2305.09656v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09656","description":"<p>Prior work has combined chain-of-thought prompting in large language models\n(LLMs) with programmatic representations to perform effective and transparent\nreasoning. While such an approach works well for tasks that only require\nforward reasoning (e.g., straightforward arithmetic), it is less effective for\nconstraint solving problems that require more sophisticated planning and\nsearch. In this paper, we propose a new satisfiability-aided language modeling\n(SatLM) approach for improving the reasoning capabilities of LLMs. We use an\nLLM to generate a declarative task specification rather than an imperative\nprogram and leverage an off-the-shelf automated theorem prover to derive the\nfinal answer. This approach has two key advantages. The declarative\nspecification is closer to the problem description than the reasoning steps\nare, so the LLM can parse it out of the description more accurately.\nFurthermore, by offloading the actual reasoning task to an automated theorem\nprover, our approach can guarantee the correctness of the answer with respect\nto the parsed specification and avoid planning errors in the solving process.\nWe evaluate SATLM on 8 different datasets and show that it consistently\noutperforms program-aided LMs in the imperative paradigm. In particular, SATLM\noutperforms program-aided LMs by 23% on a challenging subset of the GSM\narithmetic reasoning dataset; SATLM also achieves a new SoTA on LSAT and\nBoardgameQA, surpassing previous models that are trained on the respective\ntraining sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xi Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qiaochu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dillig_I/0/1/0/all/0/1\">Isil Dillig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Factual Consistency of Summaries with Large Language Models. (arXiv:2305.14069v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14069","description":"<p>Detecting factual errors in summaries has been an important and challenging\nsubject in summarization research. Inspired by the emergent ability of large\nlanguage models (LLMs), we explore evaluating factual consistency of summaries\nby directly prompting LLMs. We present a comprehensive empirical study to\nassess the ability of LLMs as factual consistency evaluators, which consists of\n(1) analyzing different LLMs such as the GPT model series and Flan-T5; (2)\ninvestigating a variety of prompting methods including vanilla prompting,\nchain-of-thought prompting, and a sentence-by-sentence prompting method to\ntackle long summaries; and (3) evaluating on diverse summaries generated by\nmultiple summarization systems, ranging from pre-transformer methods to SOTA\npretrained models. Our experiments demonstrate that prompting LLMs is able to\noutperform the previous best factuality systems in all settings, by up to 12.2\nabsolute points in terms of the binary classification accuracy on inconsistency\ndetection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shiqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Siyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14259","description":"<p>Literature-Based Discovery (LBD) aims to discover new scientific knowledge by\nmining papers and generating hypotheses. Standard LBD is limited to predicting\npairwise relations between discrete concepts (e.g., drug-disease links), and\nignores critical contexts like experimental settings (e.g., a specific patient\npopulation where a drug is evaluated) and background motivations (e.g., to find\ndrugs without specific side effects). We address these limitations with a novel\nformulation of contextualized-LBD (C-LBD): generating scientific hypotheses in\nnatural language, while grounding them in a context that controls the\nhypothesis search space. We present a modeling framework using retrieval of\n``inspirations'' from past scientific papers. Our evaluations reveal that GPT-4\ntends to generate ideas with overall low technical depth and novelty, while our\ninspiration prompting approaches partially mitigate this issue. Our work\nrepresents a first step toward building language models that generate new ideas\nderived from scientific literature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingyun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Efficient Multilingual Language Model Compression through Vocabulary Trimming. (arXiv:2305.15020v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15020","description":"<p>Multilingual language model (LM) have become a powerful tool in NLP\nespecially for non-English languages. Nevertheless, model parameters of\nmultilingual LMs remain large due to the larger embedding matrix of the\nvocabulary covering tokens in different languages. On the contrary, monolingual\nLMs can be trained in a target language with the language-specific vocabulary\nonly, but this requires a large budget and availability of reliable corpora to\nachieve a high-quality LM from scratch. In this paper, we propose\nvocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a\ntarget language by deleting irrelevant tokens from its vocabulary. In theory,\nVT can compress any existing multilingual LM to build monolingual LMs in any\nlanguage covered by the multilingual LM. In our experiments, we show that VT\ncan retain the original performance of the multilingual LM, while being smaller\nin size (in general around 50% of the original vocabulary size is enough) than\nthe original multilingual LM. The evaluation is performed over four NLP tasks\n(two generative and two classification tasks) among four widely used\nmultilingual LMs in seven languages. Finally, we show that this methodology can\nkeep the best of both monolingual and multilingual worlds by keeping a small\nsize as monolingual models without the need for specifically retraining them,\nand even limiting potentially harmful social biases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ushio_A/0/1/0/all/0/1\">Asahi Ushio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Questioning the Survey Responses of Large Language Models. (arXiv:2306.07951v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.07951","description":"<p>As large language models increase in capability, researchers have started to\nconduct surveys of all kinds on these models with varying scientific\nmotivations. In this work, we examine what we can learn from language models'\nsurvey responses on the basis of the well-established American Community Survey\n(ACS) by the U.S. Census Bureau. Using a de-facto standard multiple-choice\nprompting technique and evaluating 40 different language models, hundreds of\nthousands of times each on questions from the ACS, we systematically establish\ntwo dominant patterns. First, models have significant position and labeling\nbiases, for example, towards survey responses labeled with the letter \"A\".\nSecond, when adjusting for labeling biases through randomized answer ordering,\nmodels across the board trend towards uniformly random survey responses. In\nfact, binary classifiers can almost perfectly differentiate between models'\nresponses to the ACS and the responses of the US census. Taken together, our\nfindings suggest caution in treating survey responses from language models as\nequivalent to those of human populations at present time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dominguez_Olmedo_R/0/1/0/all/0/1\">Ricardo Dominguez-Olmedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1\">Moritz Hardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendler_Dunner_C/0/1/0/all/0/1\">Celestine Mendler-D&#xfc;nner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.03135","description":"<p>Large vision-language models have achieved outstanding performance, but their\nsize and computational requirements make their deployment on\nresource-constrained devices and time-sensitive tasks impractical. Model\ndistillation, the process of creating smaller, faster models that maintain the\nperformance of larger models, is a promising direction towards the solution.\nThis paper investigates the distillation of visual representations in large\nteacher vision-language models into lightweight student models using a small-\nor mid-scale dataset. Notably, this study focuses on open-vocabulary\nout-of-distribution (OOD) generalization, a challenging problem that has been\noverlooked in previous model distillation literature. We propose two principles\nfrom vision and language modality perspectives to enhance student's OOD\ngeneralization: (1) by better imitating teacher's visual representation space,\nand carefully promoting better coherence in vision-language alignment with the\nteacher; (2) by enriching the teacher's language representations with\ninformative and finegrained semantic attributes to effectively distinguish\nbetween different labels. We propose several metrics and conduct extensive\nexperiments to investigate their techniques. The results demonstrate\nsignificant improvements in zero-shot and few-shot student performance on\nopen-vocabulary out-of-distribution classification, highlighting the\neffectiveness of our proposed approaches. Poster:\nhttps://xuanlinli17.github.io/pdfs/iccv23_large_vlm_distillation_poster.pdf\nCode: https://github.com/xuanlinli17/large_vlm_distillation_ood\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuanlin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yunhao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Minghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhuowen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hao Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CIDER: Context sensitive sentiment analysis for short-form text. (arXiv:2307.07864v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.07864","description":"<p>Researchers commonly perform sentiment analysis on large collections of short\ntexts like tweets, Reddit posts or newspaper headlines that are all focused on\na specific topic, theme or event. Usually, general purpose sentiment analysis\nmethods are used which perform well on average but miss the variation in\nmeaning that happens across different contexts, for example, the word \"active\"\nhas a very different intention and valence in the phrase \"active lifestyle\"\nversus \"active volcano\". This work presents a new approach, CIDER (Context\nInformed Dictionary and sEntiment Reasoner), which performs context sensitive\nsentiment analysis, where the valence of sentiment laden terms is inferred from\nthe whole corpus before being used to score the individual texts. In this paper\nwe detail the CIDER algorithm and demonstrate that it outperforms\nstate-of-the-art generalist sentiment analysis on a large collection of tweets\nabout the weather. We have made our implementation of CIDER available as a\npython package: https://pypi.org/project/ciderpolarity/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Young_J/0/1/0/all/0/1\">James C. Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_R/0/1/0/all/0/1\">Rudy Arthur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_H/0/1/0/all/0/1\">Hywel T.P. Williams</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring zero-shot capability of large language models in inferences from medical oncology notes. (arXiv:2308.03853v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.03853","description":"<p>Both medical care and observational studies in oncology require a thorough\nunderstanding of a patient's disease progression and treatment history, often\nelaborately documented in clinical notes. Despite their vital role, no current\noncology information representation and annotation schema fully encapsulates\nthe diversity of information recorded within these notes. Although large\nlanguage models (LLMs) have recently exhibited impressive performance on\nvarious medical natural language processing tasks, due to the current lack of\ncomprehensively annotated oncology datasets, an extensive evaluation of LLMs in\nextracting and reasoning with the complex rhetoric in oncology notes remains\nunderstudied. We developed a detailed schema for annotating textual oncology\ninformation, encompassing patient characteristics, tumor characteristics,\ntests, treatments, and temporality. Using a corpus of 40 de-identified breast\nand pancreatic cancer progress notes at University of California, San\nFrancisco, we applied this schema to assess the abilities of three\nrecently-released LLMs (GPT-4, GPT-3.5-turbo, and FLAN-UL2) to perform\nzero-shot extraction of detailed oncological history from two narrative\nsections of clinical progress notes. Our team annotated 9028 entities, 9986\nmodifiers, and 5312 relationships. The GPT-4 model exhibited overall best\nperformance, with an average BLEU score of 0.68, an average ROUGE score of\n0.71, and an average accuracy of 67% on complex tasks (expert manual evaluation\non subset). Notably, it was proficient in tumor characteristic and medication\nextraction, and demonstrated superior performance in advanced tasks of\ninferring symptoms due to cancer and considerations of future medications.\nGPT-4 may already be usable to extract important facts from cancer progress\nnotes needed for clinical research, complex population management, and\ndocumenting quality patient care.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sushil_M/0/1/0/all/0/1\">Madhumita Sushil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kennedy_V/0/1/0/all/0/1\">Vanessa E. Kennedy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandair_D/0/1/0/all/0/1\">Divneet Mandair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_B/0/1/0/all/0/1\">Brenda Y. Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zack_T/0/1/0/all/0/1\">Travis Zack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butte_A/0/1/0/all/0/1\">Atul J. Butte</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PlatoLM: Teaching LLMs via a Socratic Questioning User Simulator. (arXiv:2308.11534v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11534","description":"<p>The unparalleled performance of closed-sourced ChatGPT has sparked efforts\ntowards its democratization, with notable strides made by leveraging real user\nand ChatGPT conversations, as evidenced by Vicuna. However, due to challenges\nin gathering conversations involving human participation, current endeavors\nlike Baize and UltraChat aim to automatically generate conversational data.\nThey primarily rely on ChatGPT conducting roleplay to simulate human behaviors\nbased on instructions rather than genuine learning from humans, resulting in\nlimited scope, diminished diversity, and an absence of genuine multi-round\nconversational dynamics. To address the above issues, we target human questions\nextracted from genuine human-machine conversations as a learning goal and train\na user simulator called `Socratic' to produce a high-quality human-centric\nsynthetic conversation dataset. Subsequently, this dataset was used to train\nour assistant model, named `PlatoLM'. Experimentally, PlatoLM outpaces baseline\nmodels in both Vicuna-Bench and MT-Bench by pairwise comparison when\nconsidering equivalent training set sizes, and manual evaluation also shows\nthat our model is highly competitive. Impressively, when fine-tuned with the\nlatest LLaMA 2 model, PlatoLM achieves the SOTA performance among 7B models\n(including LLaMA-2-7B-chat and Vicuna-7B) in MT-Bench benchmark and in\nAlpaca-Eval benchmark, it ranks second among 7B models, even beating some\nlarger scale models (including LLaMA-2-13B-chat and GPT-3.5). Further in-depth\nanalysis demonstrates the scalability and transferability of our approach. The\ncode is available at https://github.com/FreedomIntelligence/PlatoLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kong_C/0/1/0/all/0/1\">Chuyi Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yaxin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StoryBench: A Multifaceted Benchmark for Continuous Story Visualization. (arXiv:2308.11606v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.11606","description":"<p>Generating video stories from text prompts is a complex task. In addition to\nhaving high visual quality, videos need to realistically adhere to a sequence\nof text prompts whilst being consistent throughout the frames. Creating a\nbenchmark for video generation requires data annotated over time, which\ncontrasts with the single caption used often in video datasets. To fill this\ngap, we collect comprehensive human annotations on three existing datasets, and\nintroduce StoryBench: a new, challenging multi-task benchmark to reliably\nevaluate forthcoming text-to-video models. Our benchmark includes three video\ngeneration tasks of increasing difficulty: action execution, where the next\naction must be generated starting from a conditioning video; story\ncontinuation, where a sequence of actions must be executed starting from a\nconditioning video; and story generation, where a video must be generated from\nonly text prompts. We evaluate small yet strong text-to-video baselines, and\nshow the benefits of training on story-like data algorithmically generated from\nexisting video captions. Finally, we establish guidelines for human evaluation\nof video stories, and reaffirm the need of better automatic metrics for video\ngeneration. StoryBench aims at encouraging future research efforts in this\nexciting new area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bugliarello_E/0/1/0/all/0/1\">Emanuele Bugliarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraldo_H/0/1/0/all/0/1\">Hernan Moraldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villegas_R/0/1/0/all/0/1\">Ruben Villegas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babaeizadeh_M/0/1/0/all/0/1\">Mohammad Babaeizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saffar_M/0/1/0/all/0/1\">Mohammad Taghi Saffar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erhan_D/0/1/0/all/0/1\">Dumitru Erhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrari_V/0/1/0/all/0/1\">Vittorio Ferrari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kindermans_P/0/1/0/all/0/1\">Pieter-Jan Kindermans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voigtlaender_P/0/1/0/all/0/1\">Paul Voigtlaender</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Where are We in Event-centric Emotion Analysis? Bridging Emotion Role Labeling and Appraisal-based Approaches. (arXiv:2309.02092v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02092","description":"<p>The term emotion analysis in text subsumes various natural language\nprocessing tasks which have in common the goal to enable computers to\nunderstand emotions. Most popular is emotion classification in which one or\nmultiple emotions are assigned to a predefined textual unit. While such setting\nis appropriate for identifying the reader's or author's emotion, emotion role\nlabeling adds the perspective of mentioned entities and extracts text spans\nthat correspond to the emotion cause. The underlying emotion theories agree on\none important point; that an emotion is caused by some internal or external\nevent and comprises several subcomponents, including the subjective feeling and\na cognitive evaluation. We therefore argue that emotions and events are related\nin two ways. (1) Emotions are events; and this perspective is the fundament in\nnatural language processing for emotion role labeling. (2) Emotions are caused\nby events; a perspective that is made explicit with research how to incorporate\npsychological appraisal theories in NLP models to interpret events. These two\nresearch directions, role labeling and (event-focused) emotion classification,\nhave by and large been tackled separately. In this paper, we contextualize both\nperspectives and discuss open research questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1\">Roman Klinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptTTS 2: Describing and Generating Voices with Text Prompt. (arXiv:2309.02285v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.02285","description":"<p>Speech conveys more information than text, as the same word can be uttered in\nvarious voices to convey diverse information. Compared to traditional\ntext-to-speech (TTS) methods relying on speech prompts (reference speech) for\nvoice variability, using text prompts (descriptions) is more user-friendly\nsince speech prompts can be hard to find or may not exist at all. TTS\napproaches based on the text prompt face two main challenges: 1) the\none-to-many problem, where not all details about voice variability can be\ndescribed in the text prompt, and 2) the limited availability of text prompt\ndatasets, where vendors and large cost of data labeling are required to write\ntext prompts for speech. In this work, we introduce PromptTTS 2 to address\nthese challenges with a variation network to provide variability information of\nvoice not captured by text prompts, and a prompt generation pipeline to utilize\nthe large language models (LLM) to compose high quality text prompts.\nSpecifically, the variation network predicts the representation extracted from\nthe reference speech (which contains full information about voice variability)\nbased on the text prompt representation. For the prompt generation pipeline, it\ngenerates text prompts for speech with a speech language understanding model to\nrecognize voice attributes (e.g., gender, speed) from speech and a large\nlanguage model to formulate text prompts based on the recognition results.\nExperiments on a large-scale (44K hours) speech dataset demonstrate that\ncompared to the previous works, PromptTTS 2 generates voices more consistent\nwith text prompts and supports the sampling of diverse voice variability,\nthereby offering users more choices on voice generation. Additionally, the\nprompt generation pipeline produces high-quality text prompts, eliminating the\nlarge labeling cost. The demo page of PromptTTS 2 is available online.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Leng_Y/0/1/0/all/0/1\">Yichong Leng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_Z/0/1/0/all/0/1\">Zhifang Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shen_K/0/1/0/all/0/1\">Kai Shen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ju_Z/0/1/0/all/0/1\">Zeqian Ju</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yanqing Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yufei Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_D/0/1/0/all/0/1\">Dongchao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1\">Leying Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/eess/1/au:+He_L/0/1/0/all/0/1\">Lei He</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1\">Xiang-Yang Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_S/0/1/0/all/0/1\">Sheng Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05173","description":"<p>Prompt tuning (PT), where a small amount of trainable soft (continuous)\nprompt vectors is affixed to the input of language models (LM), has shown\npromising results across various tasks and models for parameter-efficient\nfine-tuning (PEFT). PT stands out from other PEFT approaches because it\nmaintains competitive performance with fewer trainable parameters and does not\ndrastically scale up its parameters as the model size expands. However, PT\nintroduces additional soft prompt tokens, leading to longer input sequences,\nwhich significantly impacts training and inference time and memory usage due to\nthe Transformer's quadratic complexity. Particularly concerning for Large\nLanguage Models (LLMs) that face heavy daily querying. To address this issue,\nwe propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt\ninto a shorter soft prompt and a pair of low-rank matrices that are then\noptimised with two different learning rates. This allows DePT to achieve better\nperformance while saving over 20% memory and time costs compared to vanilla PT\nand its variants, without changing trainable parameter sizes. Through extensive\nexperiments on 23 natural language processing (NLP) and vision-language (VL)\ntasks, we demonstrate that DePT outperforms state-of-the-art PEFT approaches,\nincluding the full fine-tuning baseline in some scenarios. Additionally, we\nempirically show that DEPT grows more efficient as the model size increases.\nOur further study reveals that DePT integrates seamlessly with\nparameter-efficient transfer learning in the few-shot learning setting and\nhighlights its adaptability to various model architectures and sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MINT: Evaluating LLMs in Multi-turn Interaction with Tools and Language Feedback. (arXiv:2309.10691v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.10691","description":"<p>To solve complex tasks, large language models (LLMs) often require multiple\nrounds of interactions with the user, sometimes assisted by external tools.\nHowever, current evaluation protocols often emphasize benchmark performance\nwith single-turn exchanges, neglecting the nuanced interactions among the user,\nLLMs, and external tools, while also underestimating the importance of natural\nlanguage feedback from users. These oversights contribute to discrepancies\nbetween research benchmark evaluations and real-world use cases. We introduce\nMINT, a benchmark that evaluates LLMs' ability to solve tasks with multi-turn\ninteractions by (1) using tools and (2) leveraging natural language feedback.\nTo ensure reproducibility, we provide an evaluation framework where LLMs can\naccess tools by executing Python code and receive users' natural language\nfeedback simulated by GPT-4. We repurpose a diverse set of established\nevaluation datasets focusing on reasoning, coding, and decision-making and\ncarefully curate them into a compact subset for efficient evaluation. Our\nanalysis of 20 open- and closed-source LLMs offers intriguing findings. (a)\nLLMs generally benefit from tools and language feedback, with performance gains\n(absolute, same below) of 1-8% for each turn of tool use and 2-17% with natural\nlanguage feedback. (b) Better single-turn performance does not guarantee better\nmulti-turn performance. (c) Surprisingly, on the LLMs evaluated, supervised\ninstruction-finetuning (SIFT) and reinforcement learning from human feedback\n(RLHF) generally hurt multi-turn capabilities. We expect MINT can help measure\nprogress and incentivize research in improving LLMs' capabilities in multi-turn\ninteractions, especially for open-source communities where multi-turn human\nevaluation can be less accessible compared to commercial LLMs with a larger\nuser base.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiateng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lifan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.10966","description":"<p>Recent research in decoding methods for Natural Language Generation (NLG)\ntasks has shown that MAP decoding is not optimal, because model probabilities\ndo not always align with human preferences. Stronger decoding methods,\nincluding Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR)\ndecoding, have since been proposed to mitigate the model-perplexity-vs-quality\nmismatch. While these decoding methods achieve state-of-the-art performance,\nthey are prohibitively expensive to compute. In this work, we propose MBR\nfinetuning and QE finetuning which distill the quality gains from these\ndecoding methods at training time, while using an efficient decoding algorithm\nat inference time. Using the canonical NLG task of Neural Machine Translation\n(NMT), we show that even with self-training, these finetuning methods\nsignificantly outperform the base model. Moreover, when using an external LLM\nas a teacher model, these finetuning methods outperform finetuning on\nhuman-generated references. These findings suggest new ways to leverage\nmonolingual data to achieve improvements in model quality that are on par with,\nor even exceed, improvements from human-curated data, while maintaining maximum\nefficiency during decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Finkelstein_M/0/1/0/all/0/1\">Mara Finkelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naskar_S/0/1/0/all/0/1\">Subhajit Naskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirzazadeh_M/0/1/0/all/0/1\">Mehdi Mirzazadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Apurva Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1\">Markus Freitag</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AceGPT, Localizing Large Language Models in Arabic. (arXiv:2309.12053v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12053","description":"<p>This paper is devoted to the development of a localized Large Language Model\n(LLM) specifically for Arabic, a language imbued with unique cultural\ncharacteristics inadequately addressed by current mainstream models.\nSignificant concerns emerge when addressing cultural sensitivity and local\nvalues. To address this, the paper proposes a comprehensive solution that\nincludes further pre-training with Arabic texts, Supervised Fine-Tuning (SFT)\nutilizing native Arabic instructions, and GPT-4 responses in Arabic, alongside\nReinforcement Learning with AI Feedback (RLAIF) employing a reward model\nattuned to local culture and values. The goal is to cultivate culturally\ncognizant and value-aligned Arabic LLMs capable of accommodating the diverse,\napplication-specific needs of Arabic-speaking communities. Comprehensive\nevaluations reveal that the resulting model, dubbed 'AceGPT', sets the\nstate-of-the-art standard for open Arabic LLMs across various benchmarks,\nincluding the instruction-following benchmark (i.e., Arabic Vicuna-80 and\nArabic AlpacaEval), knowledge benchmark (i.e., Arabic MMLU and EXAMs), and the\nnewly introduced Arabic Cultural and Value Alignment benchmark. Notably, AceGPT\noutperforms Turbo in the popular Vicuna-80 benchmark when evaluated with GPT-4,\ndespite the benchmark's limited scale. Codes, data, and models are in\nhttps://github.com/FreedomIntelligence/AceGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Huang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jianqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xuening Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dingjie Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alharthi_A/0/1/0/all/0/1\">Abdulmohsen Alharthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Ziche Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianquan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoyu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiang Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinchao Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models. (arXiv:2309.16292v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2309.16292","description":"<p>Recent advancements in autonomous driving have relied on data-driven\napproaches, which are widely adopted but face challenges including dataset\nbias, overfitting, and uninterpretability. Drawing inspiration from the\nknowledge-driven nature of human driving, we explore the question of how to\ninstill similar capabilities into autonomous driving systems and summarize a\nparadigm that integrates an interactive environment, a driver agent, as well as\na memory component to address this question. Leveraging large language models\nwith emergent abilities, we propose the DiLu framework, which combines a\nReasoning and a Reflection module to enable the system to perform\ndecision-making based on common-sense knowledge and evolve continuously.\nExtensive experiments prove DiLu's capability to accumulate experience and\ndemonstrate a significant advantage in generalization ability over\nreinforcement learning-based methods. Moreover, DiLu is able to directly\nacquire experiences from real-world datasets which highlights its potential to\nbe deployed on practical autonomous driving systems. To the best of our\nknowledge, we are the first to instill knowledge-driven capability into\nautonomous driving systems from the perspective of how humans drive.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Licheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daocheng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xinyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1\">Pinlong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_M/0/1/0/all/0/1\">Min Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Botian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Liang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey of Document-level Relation Extraction (2016-2023). (arXiv:2309.16396v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16396","description":"<p>Document-level relation extraction (DocRE) is an active area of research in\nnatural language processing (NLP) concerned with identifying and extracting\nrelationships between entities beyond sentence boundaries. Compared to the more\ntraditional sentence-level relation extraction, DocRE provides a broader\ncontext for analysis and is more challenging because it involves identifying\nrelationships that may span multiple sentences or paragraphs. This task has\ngained increased interest as a viable solution to build and populate knowledge\nbases automatically from unstructured large-scale documents (e.g., scientific\npapers, legal contracts, or news articles), in order to have a better\nunderstanding of relationships between entities. This paper aims to provide a\ncomprehensive overview of recent advances in this field, highlighting its\ndifferent applications in comparison to sentence-level relation extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Delaunay_J/0/1/0/all/0/1\">Julien Delaunay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hanh Thi Hong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Gallardo_C/0/1/0/all/0/1\">Carlos-Emiliano Gonz&#xe1;lez-Gallardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordea_G/0/1/0/all/0/1\">Georgeta Bordea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidere_N/0/1/0/all/0/1\">Nicolas Sidere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Antoine Doucet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models. (arXiv:2310.00737v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2310.00737","description":"<p>Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)\nare marvels of technology; celebrated for their prowess in natural language\nprocessing and multimodal content generation, they promise a transformative\nfuture. But as with all powerful tools, they come with their shadows. Picture\nliving in a world where deepfakes are indistinguishable from reality, where\nsynthetic identities orchestrate malicious campaigns, and where targeted\nmisinformation or scams are crafted with unparalleled precision. Welcome to the\ndarker side of GenAI applications. This article is not just a journey through\nthe meanders of potential misuse of GenAI and LLMs, but also a call to\nrecognize the urgency of the challenges ahead. As we navigate the seas of\nmisinformation campaigns, malicious content generation, and the eerie creation\nof sophisticated malware, we'll uncover the societal implications that ripple\nthrough the GenAI revolution we are witnessing. From AI-powered botnets on\nsocial media platforms to the unnerving potential of AI to generate fabricated\nidentities, or alibis made of synthetic realities, the stakes have never been\nhigher. The lines between the virtual and the real worlds are blurring, and the\nconsequences of potential GenAI's nefarious applications impact us all. This\narticle serves both as a synthesis of rigorous research presented on the risks\nof GenAI and misuse of LLMs and as a thought-provoking vision of the different\ntypes of harmful GenAI applications we might encounter in the near future, and\nsome ways we can prepare for them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1\">Emilio Ferrara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ring Attention with Blockwise Transformers for Near-Infinite Context. (arXiv:2310.01889v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01889","description":"<p>Transformers have emerged as the architecture of choice for many\nstate-of-the-art AI models, showcasing exceptional performance across a wide\nrange of AI applications. However, the memory demands imposed by Transformers\nlimit their ability to handle long sequences, thereby creating challenges for\ntasks involving extended sequences or long-term dependencies. We present a\ndistinct approach, Ring Attention, which leverages blockwise computation of\nself-attention to distribute long sequences across multiple devices while\noverlapping the communication of key-value blocks with the computation of\nblockwise attention. Ring Attention enables training and inference of sequences\nthat are up to device count times longer than those of prior memory-efficient\nTransformers, effectively eliminating the memory constraints imposed by\nindividual devices. Extensive experiments on language modeling tasks\ndemonstrate the effectiveness of Ring Attention in allowing large sequence\ninput size and improving performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Evaluation Framework: Best Practices for Human Evaluation. (arXiv:2310.01917v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01917","description":"<p>Human evaluation plays a crucial role in Natural Language Processing (NLP) as\nit assesses the quality and relevance of developed systems, thereby\nfacilitating their enhancement. However, the absence of widely accepted human\nevaluation metrics in NLP hampers fair comparisons among different systems and\nthe establishment of universal assessment standards. Through an extensive\nanalysis of existing literature on human evaluation metrics, we identified\nseveral gaps in NLP evaluation methodologies. These gaps served as motivation\nfor developing our own hierarchical evaluation framework. The proposed\nframework offers notable advantages, particularly in providing a more\ncomprehensive representation of the NLP system's performance. We applied this\nframework to evaluate the developed Machine Reading Comprehension system, which\nwas utilized within a human-AI symbiosis model. The results highlighted the\nassociations between the quality of inputs and outputs, underscoring the\nnecessity to evaluate both components rather than solely focusing on outputs.\nIn future work, we will investigate the potential time-saving benefits of our\nproposed framework for evaluators assessing NLP systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bojic_I/0/1/0/all/0/1\">Iva Bojic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jessica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Si Yuan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_Q/0/1/0/all/0/1\">Qi Chwen Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Car_J/0/1/0/all/0/1\">Josip Car</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MetaTool Benchmark for Large Language Models: Deciding Whether to Use Tools and Which to Use. (arXiv:2310.03128v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2310.03128","description":"<p>Large language models (LLMs) have garnered significant attention due to their\nimpressive natural language processing (NLP) capabilities. Recently, many\nstudies have focused on the tool utilization ability of LLMs. They primarily\ninvestigated how LLMs effectively collaborate with given specific tools.\nHowever, in scenarios where LLMs serve as intelligent agents, as seen in\napplications like AutoGPT and MetaGPT, LLMs are expected to engage in intricate\ndecision-making processes that involve deciding whether to employ a tool and\nselecting the most suitable tool(s) from a collection of available tools to\nfulfill user requests. Therefore, in this paper, we introduce MetaTool, a\nbenchmark designed to evaluate whether LLMs have tool usage awareness and can\ncorrectly choose tools. Specifically, we create a dataset called ToolE within\nthe benchmark. This dataset contains various types of user queries in the form\nof prompts that trigger LLMs to use tools, including both single-tool and\nmulti-tool scenarios. Subsequently, we set the tasks for both tool usage\nawareness and tool selection. We define four subtasks from different\nperspectives in tool selection, including tool selection with similar choices,\ntool selection in specific scenarios, tool selection with possible reliability\nissues, and multi-tool selection. We conduct experiments involving nine popular\nLLMs and find that the majority of them still struggle to effectively select\ntools, highlighting the existing gaps between LLMs and genuine intelligent\nagents. However, through the error analysis, we found there is still\nsignificant room for improvement. Finally, we conclude with insights for tool\ndevelopers that follow ChatGPT to provide detailed descriptions that can\nenhance the tool selection performance of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiawen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Chenrui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Siyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qihui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effective Slogan Generation with Noise Perturbation. (arXiv:2310.04472v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04472","description":"<p>Slogans play a crucial role in building the brand's identity of the firm. A\nslogan is expected to reflect firm's vision and brand's value propositions in\nmemorable and likeable ways. Automating the generation of slogans with such\ncharacteristics is challenging. Previous studies developted and tested slogan\ngeneration with syntactic control and summarization models which are not\ncapable of generating distinctive slogans. We introduce a a novel apporach that\nleverages pre-trained transformer T5 model with noise perturbation on newly\nproposed 1:N matching pair dataset. This approach serves as a contributing\nfator in generting distinctive and coherent slogans. Turthermore, the proposed\napproach incorporates descriptions about the firm and brand into the generation\nof slogans. We evaluate generated slogans based on ROUGE1, ROUGEL and Cosine\nSimilarity metrics and also assess them with human subjects in terms of\nslogan's distinctiveness, coherence, and fluency. The results demonstrate that\nour approach yields better performance than baseline models and other\ntransformer-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jongeun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">MinChung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taehwan Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting. (arXiv:2310.04948v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.04948","description":"<p>The past decade has witnessed significant advances in time series modeling\nwith deep learning. While achieving state-of-the-art results, the\nbest-performing architectures vary highly across applications and domains.\nMeanwhile, for natural language processing, the Generative Pre-trained\nTransformer (GPT) has demonstrated impressive performance via training one\ngeneral-purpose model across various textual datasets. It is intriguing to\nexplore whether GPT-type architectures can be effective for time series,\ncapturing the intrinsic dynamic attributes and leading to significant accuracy\nimprovements. In this paper, we propose a novel framework, TEMPO, that can\neffectively learn time series representations. We focus on utilizing two\nessential inductive biases of the time series task for pre-trained models: (i)\ndecomposition of the complex interaction between trend, seasonal and residual\ncomponents; and (ii) introducing the selection-based prompts to facilitate\ndistribution adaptation in non-stationary time series. TEMPO expands the\ncapability for dynamically modeling real-world temporal phenomena from data\nwithin diverse domains. Our experiments demonstrate the superior performance of\nTEMPO over state-of-the-art methods on a number of time series benchmark\ndatasets. This performance gain is observed not only in standard supervised\nlearning settings but also in scenarios involving previously unseen datasets as\nwell as in scenarios with multi-modal inputs. This compelling finding\nhighlights TEMPO's potential to constitute a foundational model-building\nframework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1\">Defu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_F/0/1/0/all/0/1\">Furong Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback. (arXiv:2310.05199v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05199","description":"<p>Reinforcement learning from human feedback serves as a crucial bridge,\naligning large language models with human and societal values. This alignment\nrequires a vast corpus of human feedback to learn a reward model, which is\nsubsequently used to finetune language models. However, we have identified that\nthe reward model often finds shortcuts to bypass its intended objectives,\nmisleadingly assuming that humans prefer longer responses. The emergence of\nlength bias often induces the model to favor longer outputs, yet it doesn't\nequate to an increase in helpful information within these outputs. In this\npaper, we propose an innovative solution, applying the Product-of-Experts (PoE)\ntechnique to separate reward modeling from the influence of sequence length. In\nour framework, the main expert concentrates on understanding human intents,\nwhile the biased expert targets the identification and capture of length bias.\nTo further enhance the learning of bias, we introduce perturbations into the\nbias-focused expert, disrupting the flow of semantic information. Experimental\nresults validate the effectiveness of our approach, indicating that language\nmodel performance is improved, irrespective of sequence length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wenyu Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural Network. (arXiv:2310.06488v2 [cs.NE] UPDATED)","link":"http://arxiv.org/abs/2310.06488","description":"<p>Spiking neural networks (SNNs) have demonstrated the capability to achieve\ncomparable performance to deep neural networks (DNNs) in both visual and\nlinguistic domains while offering the advantages of improved energy efficiency\nand adherence to biological plausibility. However, the extension of such\nsingle-modality SNNs into the realm of multimodal scenarios remains an\nunexplored territory. Drawing inspiration from the concept of contrastive\nlanguage-image pre-training (CLIP), we introduce a novel framework, named\nSpikeCLIP, to address the gap between two modalities within the context of\nspike-based computing through a two-step recipe involving ``Alignment\nPre-training + Dual-Loss Fine-tuning\". Extensive experiments demonstrate that\nSNNs achieve comparable results to their DNN counterparts while significantly\nreducing energy consumption across a variety of datasets commonly used for\nmultimodal model evaluation. Furthermore, SpikeCLIP maintains robust\nperformance in image classification tasks that involve class labels not\npredefined within specific categories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Changze Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cenyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Muling Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Analysis on Large Language Models in Healthcare: A Case Study of BioBERT. (arXiv:2310.07282v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.07282","description":"<p>This paper conducts a comprehensive investigation into applying large\nlanguage models, particularly on BioBERT, in healthcare. It begins with\nthoroughly examining previous natural language processing (NLP) approaches in\nhealthcare, shedding light on the limitations and challenges these methods\nface. Following that, this research explores the path that led to the\nincorporation of BioBERT into healthcare applications, highlighting its\nsuitability for addressing the specific requirements of tasks related to\nbiomedical text mining. The analysis outlines a systematic methodology for\nfine-tuning BioBERT to meet the unique needs of the healthcare domain. This\napproach includes various components, including the gathering of data from a\nwide range of healthcare sources, data annotation for tasks like identifying\nmedical entities and categorizing them, and the application of specialized\npreprocessing techniques tailored to handle the complexities found in\nbiomedical texts. Additionally, the paper covers aspects related to model\nevaluation, with a focus on healthcare benchmarks and functions like processing\nof natural language in biomedical, question-answering, clinical document\nclassification, and medical entity recognition. It explores techniques to\nimprove the model's interpretability and validates its performance compared to\nexisting healthcare-focused language models. The paper thoroughly examines\nethical considerations, particularly patient privacy and data security. It\nhighlights the benefits of incorporating BioBERT into healthcare contexts,\nincluding enhanced clinical decision support and more efficient information\nretrieval. Nevertheless, it acknowledges the impediments and complexities of\nthis integration, encompassing concerns regarding data privacy, transparency,\nresource-intensive requirements, and the necessity for model customization to\nalign with diverse healthcare domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharaf_S/0/1/0/all/0/1\">Shyni Sharaf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anoop_V/0/1/0/all/0/1\">V. S. Anoop</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Typing to Listen at the Cocktail Party: Text-Guided Target Speaker Extraction. (arXiv:2310.07284v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2310.07284","description":"<p>Humans possess an extraordinary ability to selectively focus on the sound\nsource of interest amidst complex acoustic environments, commonly referred to\nas cocktail party scenarios. In an attempt to replicate this remarkable\nauditory attention capability in machines, target speaker extraction (TSE)\nmodels have been developed. These models leverage the pre-registered cues of\nthe target speaker to extract the sound source of interest. However, the\neffectiveness of these models is hindered in real-world scenarios due to the\nunreliable or even absence of pre-registered cues. To address this limitation,\nthis study investigates the integration of natural language description to\nenhance the feasibility, controllability, and performance of existing TSE\nmodels. Specifically, we propose a model named LLM-TSE, wherein a large\nlanguage model (LLM) to extract useful semantic cues from the user's typed text\ninput. These cues can serve as independent extraction cues, task selectors to\ncontrol the TSE process, or complement the pre-registered cues. Our\nexperimental results demonstrate competitive performance when only text-based\ncues are presented, the effectiveness of using input text as a task selector,\nand a new state-of-the-art when combining text-based cues with pre-registered\ncues. To our knowledge, this is the first study to successfully incorporate\nLLMs to guide target speaker extraction, which can be a cornerstone for\ncocktail party problem research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Hao_X/0/1/0/all/0/1\">Xiang Hao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Jibin Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yu_J/0/1/0/all/0/1\">Jianwei Yu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xu_C/0/1/0/all/0/1\">Chenglin Xu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tan_K/0/1/0/all/0/1\">Kay Chen Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking the BERT-like Pretraining for DNA Sequences. (arXiv:2310.07644v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.07644","description":"<p>With the success of large-scale pretraining in NLP, there is an increasing\ntrend of applying it to the domain of life sciences. In particular, pretraining\nmethods based on DNA sequences have garnered growing attention due to their\npotential to capture generic information about genes. However, existing\npretraining methods for DNA sequences largely rely on direct adoptions of BERT\npretraining from NLP, lacking a comprehensive understanding and a specifically\ntailored approach. To address this research gap, we first conducted a series of\nexploratory experiments and gained several insightful observations: 1) In the\nfine-tuning phase of downstream tasks, when using K-mer overlapping\ntokenization instead of K-mer non-overlapping tokenization, both overlapping\nand non-overlapping pretraining weights show consistent performance\nimprovement.2) During the pre-training process, using K-mer overlapping\ntokenization quickly produces clear K-mer embeddings and reduces the loss to a\nvery low level, while using K-mer non-overlapping tokenization results in less\ndistinct embeddings and continuously decreases the loss. 3) Using overlapping\ntokenization causes the self-attention in the intermediate layers of\npre-trained models to tend to overly focus on certain tokens, reflecting that\nthese layers are not adequately optimized. In summary, overlapping tokenization\ncan benefit the fine-tuning of downstream tasks but leads to inadequate\npretraining with fast convergence. To unleash the pretraining potential, we\nintroduce a novel approach called RandomMask, which gradually increases the\ntask difficulty of BERT-like pretraining by continuously expanding its mask\nboundary, forcing the model to learn more knowledge. RandomMask is simple but\neffective, achieving top-tier performance across 26 datasets of 28 datasets\nspanning 7 downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chaoqi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_W/0/1/0/all/0/1\">Weiqiang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1\">Lifeng Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuchen Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianle Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1\">Peng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hongliang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinzhu Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1\">Wangmeng Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1\">Wanli Ouyang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue. (arXiv:2310.07659v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07659","description":"<p>Accurate knowledge selection is critical in knowledge-grounded dialogue\nsystems. Towards a closer look at it, we offer a novel perspective to organize\nexisting literature, i.e., knowledge selection coupled with, after, and before\ngeneration. We focus on the third under-explored category of study, which can\nnot only select knowledge accurately in advance, but has the advantage to\nreduce the learning, adjustment, and interpretation burden of subsequent\nresponse generation models, especially LLMs. We propose GATE, a\ngenerator-agnostic knowledge selection method, to prepare knowledge for\nsubsequent response generation models by selecting context-related knowledge\namong different knowledge structures and variable knowledge requirements.\nExperimental results demonstrate the superiority of GATE, and indicate that\nknowledge selection before generation is a lightweight yet effective way to\nfacilitate LLMs (e.g., ChatGPT) to generate more informative responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hongru Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenglu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with Relation-Aware Score Calibration. (arXiv:2309.13869v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2309.13869","description":"<p>Document-level relation extraction (DocRE) aims to extract relations of all\nentity pairs in a document. A key challenge in DocRE is the cost of annotating\nsuch data which requires intensive human effort. Thus, we investigate the case\nof DocRE in a low-resource setting, and we find that existing models trained on\nlow data overestimate the NA (\"no relation\") label, causing limited\nperformance. In this work, we approach the problem from a calibration\nperspective and propose PRiSM, which learns to adapt logits based on relation\nsemantic information. We evaluate our method on three DocRE datasets and\ndemonstrate that integrating existing models with PRiSM improves performance by\nas much as 26.38 F1 score, while the calibration error drops as much as 36\ntimes when trained with about 3% of data. The code is publicly available at\nhttps://github.com/brightjade/PRiSM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_M/0/1/0/all/0/1\">Minseok Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1\">Hyesu Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1\">Jaegul Choo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jaynes Machine: The universal microstructure of deep neural networks. (arXiv:2310.06960v1 [cond-mat.stat-mech] CROSS LISTED)","link":"http://arxiv.org/abs/2310.06960","description":"<p>We present a novel theory of the microstructure of deep neural networks.\nUsing a theoretical framework called statistical teleodynamics, which is a\nconceptual synthesis of statistical thermodynamics and potential game theory,\nwe predict that all highly connected layers of deep neural networks have a\nuniversal microstructure of connection strengths that is distributed\nlognormally ($LN({\\mu}, {\\sigma})$). Furthermore, under ideal conditions, the\ntheory predicts that ${\\mu}$ and ${\\sigma}$ are the same for all layers in all\nnetworks. This is shown to be the result of an arbitrage equilibrium where all\nconnections compete and contribute the same effective utility towards the\nminimization of the overall loss function. These surprising predictions are\nshown to be supported by empirical data from six large-scale deep neural\nnetworks in real life. We also discuss how these results can be exploited to\nreduce the amount of data, time, and computational resources needed to train\nlarge deep neural networks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cond-mat/1/au:+Venkatasubramanian_V/0/1/0/all/0/1\">Venkat Venkatasubramanian</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Sanjeevrajan_N/0/1/0/all/0/1\">N. Sanjeevrajan</a>, <a href=\"http://arxiv.org/find/cond-mat/1/au:+Khandekar_M/0/1/0/all/0/1\">Manasi Khandekar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-12T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}