{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-24T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Orion-14B: Open-source Multilingual Large Language Models. (arXiv:2401.12246v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12246","description":"<p>In this study, we introduce Orion-14B, a collection of multilingual large\nlanguage models with 14 billion parameters. We utilize a data scheduling\napproach to train a foundational model on a diverse corpus of 2.5 trillion\ntokens, sourced from texts in English, Chinese, Japanese, Korean, and other\nlanguages. Additionally, we fine-tuned a series of models tailored for\nconversational applications and other specific use cases. Our evaluation\nresults demonstrate that Orion-14B achieves state-of-the-art performance across\na broad spectrum of tasks. We make the Orion-14B model family and its\nassociated code publicly accessible https://github.com/OrionStarAI/Orion,\naiming to inspire future research and practical applications in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Du Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yi Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaopu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongqiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1\">Haihui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Leichao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dacheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kun Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Ethics of Interaction: Mitigating Security Threats in LLMs. (arXiv:2401.12273v1 [cs.CR])","link":"http://arxiv.org/abs/2401.12273","description":"<p>This paper comprehensively explores the ethical challenges arising from\nsecurity threats to Language Learning Models (LLMs). These intricate digital\nrepositories are increasingly integrated into our daily lives, making them\nprime targets for attacks that can compromise their training data and the\nconfidentiality of their data sources. The paper delves into the nuanced\nethical repercussions of such security threats on society and individual\nprivacy. We scrutinize five major threats: prompt injection, jailbreaking,\nPersonal Identifiable Information (PII) exposure, sexually explicit content,\nand hate based content, going beyond mere identification to assess their\ncritical ethical consequences and the urgency they create for robust defensive\nstrategies. The escalating reliance on LLMs underscores the crucial need for\nensuring these systems operate within the bounds of ethical norms, particularly\nas their misuse can lead to significant societal and individual harm. We\npropose conceptualizing and developing an evaluative tool tailored for LLMs,\nwhich would serve a dual purpose, guiding developers and designers in\npreemptive fortification of backend systems and scrutinizing the ethical\ndimensions of LLM chatbot responses during the testing phase. By comparing LLM\nresponses with those expected from humans in a moral context, we aim to discern\nthe degree to which AI behaviors align with the ethical values held by a\nbroader society. Ultimately, this paper not only underscores the ethical\ntroubles presented by LLMs, it also highlights a path toward cultivating trust\nin these systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Ashutosh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sagarika Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murty_S/0/1/0/all/0/1\">Shiv Vignesh Murty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragupathy_S/0/1/0/all/0/1\">Swathy Ragupathy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GRATH: Gradual Self-Truthifying for Large Language Models. (arXiv:2401.12292v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12292","description":"<p>Truthfulness is paramount for large language models (LLMs) as they are\nincreasingly deployed in real-world applications. However, existing LLMs still\nstruggle with generating truthful answers and content, as evidenced by their\nmodest performance on benchmarks like TruthfulQA. To address this issue, we\npropose GRAdual self-truTHifying (GRATH), a novel post-processing method to\nenhance truthfulness of LLMs. GRATH utilizes out-of-domain question prompts to\ngenerate corresponding answers and adaptively optimizes the model via direct\npreference optimization (DPO). Note that during this process, GRATH learns\ntruthfulness in a self-supervised manner without requiring annotated answers.\nIn particular, GRATH first generates pairwise truthfulness training data by\nprompting the LLM itself, with each pair containing a question and its correct\nand incorrect answers. The model is then fine-tuned using DPO to learn from the\ndifference between answer pairs. Subsequently, GRATH iteratively refines the\ntruthfulness data and optimizes the model, leading to a gradual improvement in\nmodel truthfulness. Empirically, we evaluate GRATH using different 7B-LLMs and\ncompare with LLMs with similar or even larger sizes on benchmark datasets. Our\nresults show that GRATH effectively improves LLMs' truthfulness without\ncompromising other core capabilities. Notably, GRATH achieves state-of-the-art\nperformance on TruthfulQA, with MC1 accuracy as 54.71% and MC2 accuracy as\n69.10%, which even surpass those on larger-scale models, such as\nLlama2-Chat-70B, by 23.62% and 24.18%, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weixin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cheap Learning: Maximising Performance of Language Models for Social Data Science Using Minimal Data. (arXiv:2401.12295v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12295","description":"<p>The field of machine learning has recently made significant progress in\nreducing the requirements for labelled training data when building new models.\nThese `cheaper' learning techniques hold significant potential for the social\nsciences, where development of large labelled training datasets is often a\nsignificant practical impediment to the use of machine learning for analytical\ntasks. In this article we review three `cheap' techniques that have developed\nin recent years: weak supervision, transfer learning and prompt engineering.\nFor the latter, we also review the particular case of zero-shot prompting of\nlarge language models. For each technique we provide a guide of how it works\nand demonstrate its application across six different realistic social science\napplications (two different tasks paired with three different dataset makeups).\nWe show good performance for all techniques, and in particular we demonstrate\nhow prompting of large language models can achieve high accuracy at very low\ncost. Our results are accompanied by a code repository to make it easy for\nothers to duplicate our work and use it in their own research. Overall, our\narticle is intended to stimulate further uptake of these techniques in the\nsocial sciences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Castro_Gonzalez_L/0/1/0/all/0/1\">Leonardo Castro-Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1\">Yi-Ling Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannak Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1\">John Francis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williams_A/0/1/0/all/0/1\">Angus R. Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johansson_P/0/1/0/all/0/1\">Pica Johansson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bright_J/0/1/0/all/0/1\">Jonathan Bright</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuning Large Language Models for Multigenerator, Multidomain, and Multilingual Machine-Generated Text Detection. (arXiv:2401.12326v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12326","description":"<p>SemEval-2024 Task 8 introduces the challenge of identifying machine-generated\ntexts from diverse Large Language Models (LLMs) in various languages and\ndomains. The task comprises three subtasks: binary classification in\nmonolingual and multilingual (Subtask A), multi-class classification (Subtask\nB), and mixed text detection (Subtask C). This paper focuses on Subtask A &amp; B.\nEach subtask is supported by three datasets for training, development, and\ntesting. To tackle this task, two methods: 1) using traditional machine\nlearning (ML) with natural language preprocessing (NLP) for feature extraction,\nand 2) fine-tuning LLMs for text classification. The results show that\ntransformer models, particularly LoRA-RoBERTa, exceed traditional ML methods in\neffectiveness, with majority voting being particularly effective in\nmultilingual contexts for identifying machine-generated texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_F/0/1/0/all/0/1\">Feng Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markchom_T/0/1/0/all/0/1\">Thanet Markchom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Ziwei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1\">Subin Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ojha_V/0/1/0/all/0/1\">Varun Ojha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Huizhi Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Subgraph Extraction-based Feedback-guided Iterative Scheduling for HLS. (arXiv:2401.12343v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12343","description":"<p>This paper proposes ISDC, a novel feedback-guided iterative system of\ndifference constraints (SDC) scheduling algorithm for high-level synthesis\n(HLS). ISDC leverages subgraph extraction-based low-level feedback from\ndownstream tools like logic synthesizers to iteratively refine HLS scheduling.\nTechnical innovations include: (1) An enhanced SDC formulation that effectively\nintegrates low-level feedback into the linear-programming (LP) problem; (2) A\nfanout and window-based subgraph extraction mechanism driving the feedback\ncycle; (3) A no-human-in-loop ISDC flow compatible with a wide range of\ndownstream tools and process design kits (PDKs). Evaluation shows that ISDC\nreduces register usage by 28.5% against an industrial-strength open-source HLS\ntool.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hanchen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_D/0/1/0/all/0/1\">David Z. Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leary_C/0/1/0/all/0/1\">Chris Leary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Deming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaoqing Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Development of an NLP-driven computer-based test guide for visually impaired students. (arXiv:2401.12375v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12375","description":"<p>In recent years, advancements in Natural Language Processing (NLP) techniques\nhave revolutionized the field of accessibility and exclusivity of testing,\nparticularly for visually impaired students (VIS). CBT has shown in years back\nits relevance in terms of administering exams electronically, making the test\nprocess easier, providing quicker and more accurate results, and offering\ngreater flexibility and accessibility for candidates. Yet, its relevance was\nnot felt by the visually impaired students as they cannot access printed\ndocuments. Hence, in this paper, we present an NLP-driven Computer-Based Test\nguide for visually impaired students. It employs a speech technology\npre-trained methods to provide real-time assistance and support to visually\nimpaired students. The system utilizes NLP technologies to convert the\ntext-based questions and the associated options in a machine-readable format.\nSubsequently, the speech technology pre-trained model processes the converted\ntext enabling the VIS to comprehend and analyze the content. Furthermore, we\nvalidated that this pre-trained model is not perverse by testing for accuracy\nusing sample audio datasets labels (A, B, C, D, E, F, G) to compare with the\nvoice recordings obtained from 20 VIS which is been predicted by the system to\nattain values for precision, recall, and F1-scores. These metrics are used to\nassess the performance of the pre-trained model and have indicated that it is\nproficient enough to give its better performance to the evaluated system. The\nmethodology adopted for this system is Object Oriented Analysis and Design\nMethodology (OOADM) where Objects are discussed and built by modeling\nreal-world instances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nemieboka_T/0/1/0/all/0/1\">Tubo Faustinah Nemieboka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onyenwe_I/0/1/0/all/0/1\">Ikechukwu E. Onyenwe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asogwa_D/0/1/0/all/0/1\">Doris C. Asogwa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Longitudinal Sentiment Classification of Reddit Posts. (arXiv:2401.12382v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12382","description":"<p>We report results of a longitudinal sentiment classification of Reddit posts\nwritten by students of four major Canadian universities. We work with the texts\nof the posts, concentrating on the years 2020-2023. By finely tuning a\nsentiment threshold to a range of [-0.075,0.075], we successfully built\nclassifiers proficient in categorizing post sentiments into positive and\nnegative categories. Noticeably, our sentiment classification results are\nconsistent across the four university data sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nwaoha_F/0/1/0/all/0/1\">Fabian Nwaoha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaffar_Z/0/1/0/all/0/1\">Ziyad Gaffar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chun_H/0/1/0/all/0/1\">Ho Joon Chun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1\">Marina Sokolova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing In-context Learning via Linear Probe Calibration. (arXiv:2401.12406v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12406","description":"<p>In-context learning (ICL) is a new paradigm for natural language processing\nthat utilizes Generative Pre-trained Transformer (GPT)-like models. This\napproach uses prompts that include in-context demonstrations to generate the\ncorresponding output for a new query input. However, applying ICL in real cases\ndoes not scale with the number of samples, and lacks robustness to different\nprompt templates and demonstration permutations. In this paper, we first show\nthat GPT-like models using ICL result in unreliable predictions based on a new\nmetric based on Shannon entropy. Then, to solve this problem, we propose a new\ntechnique called the Linear Probe Calibration (LinC), a method that calibrates\nthe model's output probabilities, resulting in reliable predictions and\nimproved performance, while requiring only minimal additional samples (as few\nas five labeled data samples). LinC significantly enhances the ICL test\nperformance of GPT models on various benchmark datasets, with an average\nimprovement of up to 21%, and up to a 50% improvement in some cases, and\nsignificantly boosts the performance of PEFT methods, especially in the low\nresource regime. Moreover, LinC achieves lower expected calibration error, and\nis highly robust to varying label proportions, prompt templates, and\ndemonstration permutations. Our code is available at\n\\url{https://github.com/mominabbass/LinC}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abbas_M/0/1/0/all/0/1\">Momin Abbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_P/0/1/0/all/0/1\">Parikshit Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baracaldo_N/0/1/0/all/0/1\">Nathalie Baracaldo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samulowitz_H/0/1/0/all/0/1\">Horst Samulowitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salonidis_T/0/1/0/all/0/1\">Theodoros Salonidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual Translation via Tiny Multi-Parallel Data. (arXiv:2401.12413v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12413","description":"<p>Zero-shot translation is an open problem, aiming to translate between\nlanguage pairs unseen during training in Multilingual Machine Translation\n(MMT). A common, albeit resource-consuming, solution is to mine as many\ntranslation directions as possible to add to the parallel corpus. In this\npaper, we show that the zero-shot capability of an English-centric model can be\neasily enhanced by fine-tuning with a very small amount of multi-parallel data.\nFor example, on the EC30 dataset, we show that up to +21.7 ChrF non-English\noverall improvements (870 directions) can be achieved by using only 100\nmulti-parallel samples, meanwhile preserving capability in English-centric\ndirections. We further study the size effect of fine-tuning data and its\ntransfer capabilities. Surprisingly, our empirical analysis shows that\ncomparable overall improvements can be achieved even through fine-tuning in a\nsmall, randomly sampled direction set (10\\%). Also, the resulting non-English\nperformance is quite close to the upper bound (complete translation). Due to\nits high efficiency and practicality, we encourage the community 1) to consider\nthe use of the fine-tuning method as a strong baseline for zero-shot\ntranslation and 2) to construct more comprehensive and high-quality\nmulti-parallel data to cover real-world demand.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shaomu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yan Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stap_D/0/1/0/all/0/1\">David Stap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Neglected Tails of Vision-Language Models. (arXiv:2401.12425v1 [cs.CV])","link":"http://arxiv.org/abs/2401.12425","description":"<p>Vision-language models (VLMs) excel in zero-shot recognition but exhibit\ndrastically imbalanced performance across visual concepts. For example, CLIP,\ndespite an impressive mean zero-shot accuracy on ImageNet (72.7%), yields\n$&lt;$10% on ten concepts (e.g., gyromitra and night snake), presumably, because\nthese concepts are under-represented in VLMs' imbalanced pretraining data. Yet,\nassessing this imbalance is challenging as it is non-trivial to calculate the\nfrequency of specific concepts within VLMs' large-scale pretraining data. Our\nwork makes the first attempt to measure the concept frequency by analyzing\npretraining texts. We use off-the-shelf language models to help count relevant\ntexts that contain synonyms of the given concepts and resolve linguistic\nambiguity. We confirm that popular VLM datasets like LAION indeed exhibit\nlong-tailed concept distributions, which strongly correlate with per-class\naccuracies. Further, contemporary multimodal systems, e.g., visual chatbots and\ntext-to-image generators, also struggle with the rare concepts identified by\nour method. To mitigate VLMs' imbalanced performance in zero-shot recognition,\nwe propose REtrieval-Augmented Learning REAL. First, instead of prompting VLMs\nusing the original class names, REAL uses their most frequent synonyms found in\nVLMs' pretraining texts. This already outperforms human-engineered and\nLLM-generated prompts over nine benchmark datasets, likely because VLMs have\nseen more images associated with the frequently used synonyms. Second, REAL\nuses all the concept synonyms to retrieve a small, class-balanced set of\npretraining data to train a robust classifier. REAL surpasses the recent\nretrieval-augmented solution REACT, using 400x less storage and 10,000x less\ntraining time!\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parashar_S/0/1/0/all/0/1\">Shubham Parashar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhiqiu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiangjue Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1\">Deva Ramanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caverlee_J/0/1/0/all/0/1\">James Caverlee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1\">Shu Kong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CIM-MLC: A Multi-level Compilation Stack for Computing-In-Memory Accelerators. (arXiv:2401.12428v1 [cs.AR])","link":"http://arxiv.org/abs/2401.12428","description":"<p>In recent years, various computing-in-memory (CIM) processors have been\npresented, showing superior performance over traditional architectures. To\nunleash the potential of various CIM architectures, such as device precision,\ncrossbar size, and crossbar number, it is necessary to develop compilation\ntools that are fully aware of the CIM architectural details and implementation\ndiversity. However, due to the lack of architectural support in current popular\nopen-source compiling stacks, existing CIM designs either manually deploy\nnetworks or build their own compilers, which is time-consuming and\nlabor-intensive. Although some works expose the specific CIM device programming\ninterfaces to compilers, they are often bound to a fixed CIM architecture,\nlacking the flexibility to support the CIM architectures with different\ncomputing granularity. On the other hand, existing compilation works usually\nconsider the scheduling of limited operation types (such as crossbar-bound\nmatrix-vector multiplication). Unlike conventional processors, CIM accelerators\nare featured by their diverse architecture, circuit, and device, which cannot\nbe simply abstracted by a single level if we seek to fully explore the\nadvantages brought by CIM. Therefore, we propose CIM-MLC, a universal\nmulti-level compilation framework for general CIM architectures. We first\nestablish a general hardware abstraction for CIM architectures and computing\nmodes to represent various CIM accelerators. Based on the proposed abstraction,\nCIM-MLC can compile tasks onto a wide range of CIM accelerators having\ndifferent devices, architectures, and programming interfaces. More importantly,\ncompared with existing compilation work, CIM-MLC can explore the mapping and\nscheduling strategies across multiple architectural tiers, which form a\ntractable yet effective design space, to achieve better scheduling and\ninstruction generation results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1\">Songyun Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shixin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yintao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xuyi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ying Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast Adversarial Training against Textual Adversarial Attacks. (arXiv:2401.12461v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12461","description":"<p>Many adversarial defense methods have been proposed to enhance the\nadversarial robustness of natural language processing models. However, most of\nthem introduce additional pre-set linguistic knowledge and assume that the\nsynonym candidates used by attackers are accessible, which is an ideal\nassumption. We delve into adversarial training in the embedding space and\npropose a Fast Adversarial Training (FAT) method to improve the model\nrobustness in the synonym-unaware scenario from the perspective of single-step\nperturbation generation and perturbation initialization. Based on the\nobservation that the adversarial perturbations crafted by single-step and\nmulti-step gradient ascent are similar, FAT uses single-step gradient ascent to\ncraft adversarial examples in the embedding space to expedite the training\nprocess. Based on the observation that the perturbations generated on the\nidentical training sample in successive epochs are similar, FAT fully utilizes\nhistorical information when initializing the perturbation. Extensive\nexperiments demonstrate that FAT significantly boosts the robustness of BERT\nmodels in the synonym-unaware scenario, and outperforms the defense baselines\nunder various attacks with character-level and word-level modifications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yichen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Kun He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Learning in Distilled Models. (arXiv:2401.12472v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12472","description":"<p>Natural Language Processing models like BERT can provide state-of-the-art\nword embeddings for downstream NLP tasks. However, these models yet to perform\nwell on Semantic Textual Similarity, and may be too large to be deployed as\nlightweight edge applications. We seek to apply a suitable contrastive learning\nmethod based on the SimCSE paper, to a model architecture adapted from a\nknowledge distillation based model, DistilBERT, to address these two issues.\nOur final lightweight model DistilFace achieves an average of 72.1 in\nSpearman's correlation on STS tasks, a 34.2 percent improvement over BERT base.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lim_V/0/1/0/all/0/1\">Valerie Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_K/0/1/0/all/0/1\">Kai Wen Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_K/0/1/0/all/0/1\">Kenneth Lim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment. (arXiv:2401.12474v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12474","description":"<p>Considerable efforts have been invested in augmenting the role-playing\nproficiency of open-source large language models (LLMs) by emulating\nproprietary counterparts. Nevertheless, we posit that LLMs inherently harbor\nrole-play capabilities, owing to the extensive knowledge of characters and\npotential dialogues ingrained in their vast training corpora. Thus, in this\nstudy, we introduce Ditto, a self-alignment method for role-play. Ditto\ncapitalizes on character knowledge, encouraging an instruction-following LLM to\nsimulate role-play dialogues as a variant of reading comprehension. This method\ncreates a role-play training set comprising 4,000 characters, surpassing the\nscale of currently available datasets by tenfold regarding the number of roles.\nSubsequently, we fine-tune the LLM using this self-generated dataset to augment\nits role-playing capabilities. Upon evaluating our meticulously constructed and\nreproducible role-play benchmark and the roleplay subset of MT-Bench, Ditto, in\nvarious parameter scales, consistently maintains a consistent role identity and\nprovides accurate role-specific knowledge in multi-turn role-play\nconversations. Notably, it outperforms all open-source role-play baselines,\nshowcasing performance levels comparable to advanced proprietary chatbots.\nFurthermore, we present the first comprehensive cross-supervision alignment\nexperiment in the role-play domain, revealing that the intrinsic capabilities\nof LLMs confine the knowledge within role-play. Meanwhile, the role-play styles\ncan be easily acquired with the guidance of smaller models. We open-source\nrelated resources at https://github.com/OFA-Sys/Ditto.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Keming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bowen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing and Understanding Creativity in Large Language Models. (arXiv:2401.12491v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12491","description":"<p>In the field of natural language processing, the rapid development of large\nlanguage model (LLM) has attracted more and more attention. LLMs have shown a\nhigh level of creativity in various tasks, but the methods for assessing such\ncreativity are inadequate. The assessment of LLM creativity needs to consider\ndifferences from humans, requiring multi-dimensional measurement while\nbalancing accuracy and efficiency. This paper aims to establish an efficient\nframework for assessing the level of creativity in LLMs. By adapting the\nmodified Torrance Tests of Creative Thinking, the research evaluates the\ncreative performance of various LLMs across 7 tasks, emphasizing 4 criteria\nincluding Fluency, Flexibility, Originality, and Elaboration. In this context,\nwe develop a comprehensive dataset of 700 questions for testing and an\nLLM-based evaluation method. In addition, this study presents a novel analysis\nof LLMs' responses to diverse prompts and role-play situations. We found that\nthe creativity of LLMs primarily falls short in originality, while excelling in\nelaboration. Besides, the use of prompts and the role-play settings of the\nmodel significantly influence creativity. Additionally, the experimental\nresults also indicate that collaboration among multiple LLMs can enhance\noriginality. Notably, our findings reveal a consensus between human evaluations\nand LLMs regarding the personality traits that influence creativity. The\nfindings underscore the significant impact of LLM design on creativity and\nbridges artificial intelligence and human creativity, offering insights into\nLLMs' creativity and potential applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yunpu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Di Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiaming Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shaohui Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yifan Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuanbo Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xing Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1\">Zidong Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Ling Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunji Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?. (arXiv:2401.12492v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12492","description":"<p>Natural language processing has made progress in incorporating human context\ninto its models, but whether it is more effective to use group-wise attributes\n(e.g., over-45-year-olds) or model individuals remains open. Group attributes\nare technically easier but coarse: not all 45-year-olds write the same way. In\ncontrast, modeling individuals captures the complexity of each person's\nidentity. It allows for a more personalized representation, but we may have to\nmodel an infinite number of users and require data that may be impossible to\nget. We compare modeling human context via group attributes, individual users,\nand combined approaches. Combining group and individual features significantly\nbenefits user-level regression tasks like age estimation or personality\nassessment from a user's documents. Modeling individual users significantly\nimproves the performance of single document-level classification tasks like\nstance and topic detection. We also find that individual-user modeling does\nwell even without user's historical data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soni_N/0/1/0/all/0/1\">Nikita Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1\">H. Andrew Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1\">Dirk Hovy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Key Information Retrieval to Classify the Unstructured Data Content of Preferential Trade Agreements. (arXiv:2401.12520v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12520","description":"<p>With the rapid proliferation of textual data, predicting long texts has\nemerged as a significant challenge in the domain of natural language\nprocessing. Traditional text prediction methods encounter substantial\ndifficulties when grappling with long texts, primarily due to the presence of\nredundant and irrelevant information, which impedes the model's capacity to\ncapture pivotal insights from the text. To address this issue, we introduce a\nnovel approach to long-text classification and prediction. Initially, we employ\nembedding techniques to condense the long texts, aiming to diminish the\nredundancy therein. Subsequently,the Bidirectional Encoder Representations from\nTransformers (BERT) embedding method is utilized for text classification\ntraining. Experimental outcomes indicate that our method realizes considerable\nperformance enhancements in classifying long texts of Preferential Trade\nAgreements. Furthermore, the condensation of text through embedding methods not\nonly augments prediction accuracy but also substantially reduces computational\ncomplexity. Overall, this paper presents a strategy for long-text prediction,\noffering a valuable reference for researchers and engineers in the natural\nlanguage processing sphere.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiahui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Ziyi Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gordeev_S/0/1/0/all/0/1\">Stepan Gordeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zijie Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dongjin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinbach_S/0/1/0/all/0/1\">Sandro Steinbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Caiwen Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiTA: Bi-Directional Tuning for Lossless Acceleration in Large Language Models. (arXiv:2401.12522v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12522","description":"<p>Large language models (LLMs) commonly employ autoregressive generation during\ninference, leading to high memory bandwidth demand and consequently extended\nlatency. To mitigate this inefficiency, we present Bi-directional Tuning for\nlossless Acceleration (BiTA), an innovative method expediting LLMs via\nstreamlined semi-autoregressive generation and draft verification. Inspired by\nthe concept of prompt tuning, we enhance LLMs with a parameter-efficient design\ncalled bi-directional tuning for the capability in semi-autoregressive\ngeneration. Employing efficient tree-based decoding, the models perform draft\ncandidate generation and verification in parallel, ensuring outputs identical\nto their autoregressive counterparts under greedy sampling. BiTA serves as a\nlightweight plug-in module, seamlessly boosting the inference efficiency of\nexisting LLMs without requiring additional assistance models or incurring\nsignificant extra memory costs. Applying the proposed BiTA, LLaMA-2-70B-Chat\nachieves a 2.7$\\times$ speedup on the MT-Bench benchmark. Extensive experiments\nconfirm our method surpasses state-of-the-art acceleration techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Feng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_H/0/1/0/all/0/1\">Hanling Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaotian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1\">Guangming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Rong Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DREditor: An Time-efficient Approach for Building a Domain-specific Dense Retrieval Model. (arXiv:2401.12540v1 [cs.IR])","link":"http://arxiv.org/abs/2401.12540","description":"<p>Deploying dense retrieval models efficiently is becoming increasingly\nimportant across various industries. This is especially true for enterprise\nsearch services, where customizing search engines to meet the time demands of\ndifferent enterprises in different domains is crucial. Motivated by this, we\ndevelop a time-efficient approach called DREditor to edit the matching rule of\nan off-the-shelf dense retrieval model to suit a specific domain. This is\nachieved by directly calibrating the output embeddings of the model using an\nefficient and effective linear mapping. This mapping is powered by an edit\noperator that is obtained by solving a specially constructed least squares\nproblem. Compared to implicit rule modification via long-time finetuning, our\nexperimental results show that DREditor provides significant advantages on\ndifferent domain-specific datasets, dataset sources, retrieval models, and\ncomputing devices. It consistently enhances time efficiency by 100-300 times\nwhile maintaining comparable or even superior retrieval performance. In a\nbroader context, we take the first step to introduce a novel embedding\ncalibration approach for the retrieval task, filling the technical blank in the\ncurrent field of embedding calibration. This approach also paves the way for\nbuilding domain-specific dense retrieval models efficiently and inexpensively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1\">Duanyu Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenqiang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1\">Jiancheng Lv</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Fact-Checking of Climate Change Claims with Large Language Models. (arXiv:2401.12566v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12566","description":"<p>This paper presents Climinator, a novel AI-based tool designed to automate\nthe fact-checking of climate change claims. Utilizing an array of Large\nLanguage Models (LLMs) informed by authoritative sources like the IPCC reports\nand peer-reviewed scientific literature, Climinator employs an innovative\nMediator-Advocate framework. This design allows Climinator to effectively\nsynthesize varying scientific perspectives, leading to robust, evidence-based\nevaluations. Our model demonstrates remarkable accuracy when testing claims\ncollected from Climate Feedback and Skeptical Science. Notably, when\nintegrating an advocate with a climate science denial perspective in our\nframework, Climinator's iterative debate process reliably converges towards\nscientific consensus, underscoring its adeptness at reconciling diverse\nviewpoints into science-based, factual conclusions. While our research is\nsubject to certain limitations and necessitates careful interpretation, our\napproach holds significant potential. We hope to stimulate further research and\nencourage exploring its applicability in other contexts, including political\nfact-checking and legal domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Leippold_M/0/1/0/all/0/1\">Markus Leippold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaghefi_S/0/1/0/all/0/1\">Saeid Ashraf Vaghefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stammbach_D/0/1/0/all/0/1\">Dominik Stammbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muccione_V/0/1/0/all/0/1\">Veruska Muccione</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bingler_J/0/1/0/all/0/1\">Julia Bingler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jingwei Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colesanti_Senni_C/0/1/0/all/0/1\">Chiara Colesanti-Senni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wekhof_T/0/1/0/all/0/1\">Tobias Wekhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schimanski_T/0/1/0/all/0/1\">Tobias Schimanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gostlow_G/0/1/0/all/0/1\">Glen Gostlow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tingyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luterbacher_J/0/1/0/all/0/1\">Juerg Luterbacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huggel_C/0/1/0/all/0/1\">Christian Huggel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools. (arXiv:2401.12576v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12576","description":"<p>Interpretability tools that offer explanations in the form of a dialogue have\ndemonstrated their efficacy in enhancing users' understanding, as one-off\nexplanations may occasionally fall short in providing sufficient information to\nthe user. Current solutions for dialogue-based explanations, however, require\nmany dependencies and are not easily transferable to tasks they were not\ndesigned for. With LLMCheckup, we present an easily accessible tool that allows\nusers to chat with any state-of-the-art large language model (LLM) about its\nbehavior. We enable LLMs to generate all explanations by themselves and take\ncare of intent recognition without fine-tuning, by connecting them with a broad\nspectrum of Explainable AI (XAI) tools, e.g. feature attributions,\nembedding-based similarity, and prompting strategies for counterfactual and\nrationale generation. LLM (self-)explanations are presented as an interactive\ndialogue that supports follow-up questions and generates suggestions.\nLLMCheckup provides tutorials for operations available in the system, catering\nto individuals with varying levels of expertise in XAI and supports multiple\ninput modalities. We introduce a new parsing strategy called multi-prompt\nparsing substantially enhancing the parsing accuracy of LLMs. Finally, we\nshowcase the tasks of fact checking and commonsense question answering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anikina_T/0/1/0/all/0/1\">Tatiana Anikina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldhus_N/0/1/0/all/0/1\">Nils Feldhus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Genabith_J/0/1/0/all/0/1\">Josef van Genabith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennig_L/0/1/0/all/0/1\">Leonhard Hennig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moller_S/0/1/0/all/0/1\">Sebastian M&#xf6;ller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SLANG: New Concept Comprehension of Large Language Models. (arXiv:2401.12585v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12585","description":"<p>The dynamic nature of language, particularly evident in the realm of slang\nand memes on the Internet, poses serious challenges to the adaptability of\nlarge language models (LLMs). Traditionally anchored to static datasets, these\nmodels often struggle to keep up with the rapid linguistic evolution\ncharacteristic of online communities. This research addresses the critical need\nto bridge this gap, aiming to enhance LLMs' comprehension of evolving new\nconcepts on the internet, without the high cost and impracticality of continual\nretraining. To address this issue, we propose a new benchmark $\\textbf{SLANG}$\nto assess LLMs' proficiency in comprehending emerging linguistic trends and a\nbaseline approach $\\textbf{FOCUS}$, which uses causal inference to enhance LLMs\nto understand new phrases and usage patterns. This approach involves\nscrutinizing real-world instances of linguistic shifts, serving as contextual\nbeacons, to form more precise and contextually relevant connections between\nnewly emerging expressions and their intended meanings. The empirical analysis\nshows that our causal inference-based approach outperforms the traditional\nmodels in terms of precision and relevance in the interpretation of Internet\nslang and memes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mei_L/0/1/0/all/0/1\">Lingrui Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shenghua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1\">Baolong Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xueqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Reply to Makelov et al. (2023)'s \"Interpretability Illusion\" Arguments. (arXiv:2401.12631v1 [cs.LG])","link":"http://arxiv.org/abs/2401.12631","description":"<p>We respond to the recent paper by Makelov et al. (2023), which reviews\nsubspace interchange intervention methods like distributed alignment search\n(DAS; Geiger et al. 2023) and claims that these methods potentially cause\n\"interpretability illusions\". We first review Makelov et al. (2023)'s technical\nnotion of what an \"interpretability illusion\" is, and then we show that even\nintuitive and desirable explanations can qualify as illusions in this sense. As\na result, their method of discovering \"illusions\" can reject explanations they\nconsider \"non-illusory\". We then argue that the illusions Makelov et al. (2023)\nsee in practice are artifacts of their training and evaluation paradigms. We\nclose by emphasizing that, though we disagree with their core characterization,\nMakelov et al. (2023)'s examples and discussion have undoubtedly pushed the\nfield of interpretability forward.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhengxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1\">Atticus Geiger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Aryaman Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1\">Thomas Icard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context Matters: Pushing the Boundaries of Open-Ended Answer Generation with Graph-Structured Knowledge Context. (arXiv:2401.12671v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12671","description":"<p>In the continuously advancing AI landscape, crafting context-rich and\nmeaningful responses via Large Language Models (LLMs) is essential. Researchers\nare becoming more aware of the challenges that LLMs with fewer parameters\nencounter when trying to provide suitable answers to open-ended questions. To\naddress these hurdles, the integration of cutting-edge strategies, augmentation\nof rich external domain knowledge to LLMs, offers significant improvements.\nThis paper introduces a novel framework that combines graph-driven context\nretrieval in conjunction to knowledge graphs based enhancement, honing the\nproficiency of LLMs, especially in domain specific community question answering\nplatforms like AskUbuntu, Unix, and ServerFault. We conduct experiments on\nvarious LLMs with different parameter sizes to evaluate their ability to ground\nknowledge and determine factual accuracy in answers to open-ended questions.\nOur methodology GraphContextGen consistently outperforms dominant text-based\nretrieval systems, demonstrating its robustness and adaptability to a larger\nnumber of use cases. This advancement highlights the importance of pairing\ncontext rich data retrieval with LLMs, offering a renewed approach to knowledge\nsourcing and generation in AI systems. We also show that, due to rich\ncontextual data retrieval, the crucial entities, along with the generated\nanswer, remain factually coherent with the gold answer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1\">Somnath Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahoo_A/0/1/0/all/0/1\">Amruit Sahoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Layek_S/0/1/0/all/0/1\">Sayan Layek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1\">Avik Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1\">Rima Hazra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Energy-based Automated Model Evaluation. (arXiv:2401.12689v1 [cs.LG])","link":"http://arxiv.org/abs/2401.12689","description":"<p>The conventional evaluation protocols on machine learning models rely heavily\non a labeled, i.i.d-assumed testing dataset, which is not often present in real\nworld applications. The Automated Model Evaluation (AutoEval) shows an\nalternative to this traditional workflow, by forming a proximal prediction\npipeline of the testing performance without the presence of ground-truth\nlabels. Despite its recent successes, the AutoEval frameworks still suffer from\nan overconfidence issue, substantial storage and computational cost. In that\nregard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that\nallows the AutoEval framework to be both more efficient and effective. The core\nof the MDE is to establish a meta-distribution statistic, on the information\n(energy) associated with individual samples, then offer a smoother\nrepresentation enabled by energy-based learning. We further provide our\ntheoretical insights by connecting the MDE with the classification loss. We\nprovide extensive experiments across modalities, datasets and different\narchitectural backbones to validate MDE's validity, together with its\nsuperiority compared with prior approaches. We also prove MDE's versatility by\nshowing its seamless integration with large-scale models, and easy adaption to\nlearning scenarios with noisy- or imbalanced- labels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1\">Ru Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_H/0/1/0/all/0/1\">Heming Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yawen Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zenan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Unsupervised Abstractive Explanations for Rumour Verification. (arXiv:2401.12713v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12713","description":"<p>The task of rumour verification in social media concerns assessing the\nveracity of a claim on the basis of conversation threads that result from it.\nWhile previous work has focused on predicting a veracity label, here we\nreformulate the task to generate model-centric, free-text explanations of a\nrumour's veracity. We follow an unsupervised approach by first utilising\npost-hoc explainability methods to score the most important posts within a\nthread and then we use these posts to generate informative explanatory\nsummaries by employing template-guided summarisation. To evaluate the\ninformativeness of the explanatory summaries, we exploit the few-shot learning\ncapabilities of a large language model (LLM). Our experiments show that LLMs\ncan have similar agreement to humans in evaluating summaries. Importantly, we\nshow that explanatory abstractive summaries are more informative and better\nreflect the predicted rumour veracity than just using the highest ranking posts\nin the thread.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bilal_I/0/1/0/all/0/1\">Iman Munire Bilal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Procter_R/0/1/0/all/0/1\">Rob Procter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liakata_M/0/1/0/all/0/1\">Maria Liakata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive View of the Biases of Toxicity and Sentiment Analysis Methods Towards Utterances with African American English Expressions. (arXiv:2401.12720v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12720","description":"<p>Language is a dynamic aspect of our culture that changes when expressed in\ndifferent technologies/communities. Online social networks have enabled the\ndiffusion and evolution of different dialects, including African American\nEnglish (AAE). However, this increased usage is not without barriers. One\nparticular barrier is how sentiment (Vader, TextBlob, and Flair) and toxicity\n(Google's Perspective and the open-source Detoxify) methods present biases\ntowards utterances with AAE expressions. Consider Google's Perspective to\nunderstand bias. Here, an utterance such as ``All n*ggers deserve to die\nrespectfully. The police murder us.'' it reaches a higher toxicity than\n``African-Americans deserve to die respectfully. The police murder us.''. This\nscore difference likely arises because the tool cannot understand the\nre-appropriation of the term ``n*gger''. One explanation for this bias is that\nAI models are trained on limited datasets, and using such a term in training\ndata is more likely to appear in a toxic utterance. While this may be\nplausible, the tool will make mistakes regardless. Here, we study bias on two\nWeb-based (YouTube and Twitter) datasets and two spoken English datasets. Our\nanalysis shows how most models present biases towards AAE in most settings. We\nisolate the impact of AAE expression usage via linguistic control features from\nthe Linguistic Inquiry and Word Count (LIWC) software, grammatical control\nfeatures extracted via Part-of-Speech (PoS) tagging from Natural Language\nProcessing (NLP) models, and the semantic of utterances by comparing sentence\nembeddings from recent language models. We present consistent results on how a\nheavy usage of AAE expressions may cause the speaker to be considered\nsubstantially more toxic, even when speaking about nearly the same subject. Our\nstudy complements similar analyses focusing on small datasets and/or one method\nonly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Resende_G/0/1/0/all/0/1\">Guilherme H. Resende</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nery_L/0/1/0/all/0/1\">Luiz F. Nery</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benevenuto_F/0/1/0/all/0/1\">Fabr&#xed;cio Benevenuto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zannettou_S/0/1/0/all/0/1\">Savvas Zannettou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Figueiredo_F/0/1/0/all/0/1\">Flavio Figueiredo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition. (arXiv:2401.12756v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12756","description":"<p>The knowledge encapsulated in a model is the core factor determining its\nfinal performance on downstream tasks. Much research in NLP has focused on\nefficient methods for storing and adapting different types of knowledge, e.g.,\nin dedicated modularized structures, and on how to effectively combine these,\ne.g., by learning additional parameters. However, given the many possible\noptions, a thorough understanding of the mechanisms involved in these\ncompositions is missing, and hence it remains unclear which strategies to\nutilize. To address this research gap, we propose a novel framework for\nzero-shot module composition, which encompasses existing and some novel\nvariations for selecting, weighting, and combining parameter modules under a\nsingle unified notion. Focusing on the scenario of domain knowledge and adapter\nlayers, our framework provides a systematic unification of concepts, allowing\nus to conduct the first comprehensive benchmarking study of various zero-shot\nknowledge composition strategies. In particular, we test two module combination\nmethods and five selection and weighting strategies for their effectiveness and\nefficiency in an extensive experimental setup. Our results highlight the\nefficacy of ensembling but also hint at the power of simple though\noften-ignored weighting methods. Further in-depth analyses allow us to\nunderstand the role of weighting vs. top-k selection, and show that, to a\ncertain extent, the performance of adapter composition can even be predicted.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holtermann_C/0/1/0/all/0/1\">Carolin Holtermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frohmann_M/0/1/0/all/0/1\">Markus Frohmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1\">Navid Rekabsaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1\">Anne Lauscher</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual and Fully Non-Autoregressive ASR with Large Language Model Fusion: A Comprehensive Study. (arXiv:2401.12789v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12789","description":"<p>In the era of large models, the autoregressive nature of decoding often\nresults in latency serving as a significant bottleneck. We propose a\nnon-autoregressive LM-fused ASR system that effectively leverages the\nparallelization capabilities of accelerator hardware. Our approach combines the\nUniversal Speech Model (USM) and the PaLM 2 language model in per-segment\nscoring mode, achieving an average relative WER improvement across all\nlanguages of 10.8% on FLEURS and 3.6% on YouTube captioning. Furthermore, our\ncomprehensive ablation study analyzes key parameters such as LLM size, context\nlength, vocabulary size, fusion methodology. For instance, we explore the\nimpact of LLM size ranging from 128M to 340B parameters on ASR performance.\nThis study provides valuable insights into the factors influencing the\neffectiveness of practical large-scale LM-fused speech recognition systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">W. Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allauzen_C/0/1/0/all/0/1\">Cyril Allauzen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tongzhou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kilol Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1\">Ke Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">James Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shuo-Yiin Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking LLMs via Uncertainty Quantification. (arXiv:2401.12794v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12794","description":"<p>The proliferation of open-source Large Language Models (LLMs) from various\ninstitutions has highlighted the urgent need for comprehensive evaluation\nmethods. However, current evaluation platforms, such as the widely recognized\nHuggingFace open LLM leaderboard, neglect a crucial aspect -- uncertainty,\nwhich is vital for thoroughly assessing LLMs. To bridge this gap, we introduce\na new benchmarking approach for LLMs that integrates uncertainty\nquantification. Our examination involves eight LLMs (LLM series) spanning five\nrepresentative natural language processing tasks. Additionally, we introduce an\nuncertainty-aware evaluation metric, UAcc, which takes into account both\nprediction accuracy and prediction uncertainty. Our findings reveal that: I)\nLLMs with higher accuracy may exhibit lower certainty; II) Larger-scale LLMs\nmay display greater uncertainty compared to their smaller counterparts; and\nIII) Instruction-finetuning tends to increase the uncertainty of LLMs. By\ntaking uncertainty into account, our new UAcc metric can either amplify or\ndiminish the relative improvement of one LLM over another and may even change\nthe relative ranking of two LLMs. These results underscore the significance of\nincorporating uncertainty in the evaluation of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_F/0/1/0/all/0/1\">Fanghua Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Mingming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1\">Jianhui Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_E/0/1/0/all/0/1\">Emine Yilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient Flow of Energy: A General and Efficient Approach for Entity Alignment Decoding. (arXiv:2401.12798v1 [cs.IR])","link":"http://arxiv.org/abs/2401.12798","description":"<p>Entity alignment (EA), a pivotal process in integrating multi-source\nKnowledge Graphs (KGs), seeks to identify equivalent entity pairs across these\ngraphs. Most existing approaches regard EA as a graph representation learning\ntask, concentrating on enhancing graph encoders. However, the decoding process\nin EA - essential for effective operation and alignment accuracy - has received\nlimited attention and remains tailored to specific datasets and model\narchitectures, necessitating both entity and additional explicit relation\nembeddings. This specificity limits its applicability, particularly in\nGNN-based models. To address this gap, we introduce a novel, generalized, and\nefficient decoding approach for EA, relying solely on entity embeddings. Our\nmethod optimizes the decoding process by minimizing Dirichlet energy, leading\nto the gradient flow within the graph, to promote graph homophily. The\ndiscretization of the gradient flow produces a fast and scalable approach,\ntermed Triple Feature Propagation (TFP). TFP innovatively channels gradient\nflow through three views: entity-to-entity, entity-to-relation, and\nrelation-to-entity. This generalized gradient flow enables TFP to harness the\nmulti-view structural information of KGs. Rigorous experimentation on diverse\nreal-world datasets demonstrates that our approach significantly enhances\nvarious EA methods. Notably, the approach achieves these advancements with less\nthan 6 seconds of additional computational time, establishing a new benchmark\nin efficiency and adaptability for future EA methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haifeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1\">Qi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shaoling Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1\">Jianxin Liao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning. (arXiv:2401.12863v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12863","description":"<p>Large Language Models (LLMs) have demonstrated impressive performance in\nnatural language processing tasks by leveraging chain of thought (CoT) that\nenables step-by-step thinking. Extending LLMs with multimodal capabilities is\nthe recent interest, but incurs computational cost and requires substantial\nhardware resources. To address these challenges, we propose KAM-CoT a framework\nthat integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities\nfor a comprehensive understanding of multimodal tasks. KAM-CoT adopts a\ntwo-stage training process with KG grounding to generate effective rationales\nand answers. By incorporating external knowledge from KGs during reasoning, the\nmodel gains a deeper contextual understanding reducing hallucinations and\nenhancing the quality of answers. This knowledge-augmented CoT reasoning\nempowers the model to handle questions requiring external context, providing\nmore informed answers. Experimental findings show KAM-CoT outperforms the\nstate-of-the-art methods. On the ScienceQA dataset, we achieve an average\naccuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by\n10%. Remarkably, KAM-CoT achieves these results with only 280M trainable\nparameters at a time, demonstrating its cost-efficiency and effectiveness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mondal_D/0/1/0/all/0/1\">Debjyoti Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1\">Suraj Modi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_S/0/1/0/all/0/1\">Subhadarshi Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rituraj Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_G/0/1/0/all/0/1\">Godawari Sudhakar Rao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Machine Translation with Human Feedback: An Exploration of Quality Estimation as a Reward Model. (arXiv:2401.12873v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12873","description":"<p>Insufficient modeling of human preferences within the reward model is a major\nobstacle for leveraging human feedback to improve translation quality.\nFortunately, quality estimation (QE), which predicts the quality of a given\ntranslation without reference, has achieved impressive alignment with human\nevaluations in the last two years. In this work, we investigate the potential\nof employing the QE model as the reward model (the QE-based reward model) to\npredict human preferences for feedback training. We first identify the\noveroptimization problem during QE-based feedback training, manifested as an\nincrease in reward while translation quality declines. We examine the problem\nand argue that the vulnerability of the QE model might lead to high rewards for\nincorrect translations, resulting in overoptimization and error propagation. To\naddress the problem, we adopt a simple yet effective method that uses heuristic\nrules to detect the incorrect translations and assigns a penalty term to the\nQE-based rewards for the detected incorrect translations. Experimental results\nshow that the proposed QE-based feedback training achieves consistent and\nsignificant improvements across various settings, further verified through\nhuman preference studies. Our subsequent analysis demonstrates the high data\nefficiency of the proposed QE-based feedback training: the proposed approach\nusing a small amount of monolingual data can outperform systems using larger\nparallel corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Understanding to Utilization: A Survey on Explainability for Large Language Models. (arXiv:2401.12874v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12874","description":"<p>This survey paper delves into the burgeoning field of explainability for\nLarge Language Models (LLMs), a critical yet challenging aspect of natural\nlanguage processing. With LLMs playing a pivotal role in various applications,\ntheir \"black-box\" nature raises concerns about transparency and ethical use.\nThis paper emphasizes the necessity for enhanced explainability in LLMs,\naddressing both the general public's trust and the technical community's need\nfor a deeper understanding of these models. We concentrate on pre-trained\nTransformer-based LLMs, such as LLaMA, which present unique interpretability\nchallenges due to their scale and complexity. Our review categorizes existing\nexplainability methods and discusses their application in improving model\ntransparency and reliability. We also discuss representative evaluation\nmethods, highlighting their strengths and limitations. The goal of this survey\nis to bridge the gap between theoretical understanding and practical\napplication, offering insights for future research and development in the field\nof LLM explainability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haoyan Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1\">Lucia Specia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Red Teaming Visual Language Models. (arXiv:2401.12915v1 [cs.AI])","link":"http://arxiv.org/abs/2401.12915","description":"<p>VLMs (Vision-Language Models) extend the capabilities of LLMs (Large Language\nModels) to accept multimodal inputs. Since it has been verified that LLMs can\nbe induced to generate harmful or inaccurate content through specific test\ncases (termed as Red Teaming), how VLMs perform in similar scenarios,\nespecially with their combination of textual and visual inputs, remains a\nquestion. To explore this problem, we present a novel red teaming dataset\nRTVLM, which encompasses 10 subtasks (e.g., image misleading, multi-modal\njail-breaking, face fairness, etc) under 4 primary aspects (faithfulness,\nprivacy, safety, fairness). Our RTVLM is the first red-teaming dataset to\nbenchmark current VLMs in terms of these 4 different aspects. Detailed analysis\nshows that 10 prominent open-sourced VLMs struggle with the red teaming in\ndifferent degrees and have up to 31% performance gap with GPT-4V. Additionally,\nwe simply apply red teaming alignment to LLaVA-v1.5 with Supervised Fine-tuning\n(SFT) using RTVLM, and this bolsters the models' performance with 10% in RTVLM\ntest set, 13% in MM-Hal, and without noticeable decline in MM-Bench,\noverpassing other LLaVA-based models with regular alignment data. This reveals\nthat current open-sourced VLMs still lack red teaming alignment. Our code and\ndatasets will be open-source.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mukai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yuwei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Masood Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenguang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multicultural Name Recognition For Previously Unseen Names. (arXiv:2401.12941v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12941","description":"<p>State of the art Named Entity Recognition (NER) models have achieved an\nimpressive ability to extract common phrases from text that belong to labels\nsuch as location, organization, time, and person. However, typical NER systems\nthat rely on having seen a specific entity in their training data in order to\nlabel an entity perform poorly on rare or unseen entities ta in order to label\nan entity perform poorly on rare or unseen entities (Derczynski et al., 2017).\nThis paper attempts to improve recognition of person names, a diverse category\nthat can grow any time someone is born or changes their name. In order for\ndownstream tasks to not exhibit bias based on cultural background, a model\nshould perform well on names from a variety of backgrounds. In this paper I\nexperiment with the training data and input structure of an English Bi-LSTM\nname recognition model. I look at names from 103 countries to compare how well\nthe model performs on names from different cultures, specifically in the\ncontext of a downstream task where extracted names will be matched to\ninformation on file. I find that a model with combined character and word input\noutperforms word-only models and may improve on accuracy compared to classical\nNER models that are not geared toward identifying unseen entity values.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loessberg_Zahl_A/0/1/0/all/0/1\">Alexandra Loessberg-Zahl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-Based Models Are Not Yet Perfect At Learning to Emulate Structural Recursion. (arXiv:2401.12947v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12947","description":"<p>This paper investigates the ability of transformer-based models to learn\nstructural recursion from examples. Recursion is a universal concept in both\nnatural and formal languages. Structural recursion is central to the\nprogramming language and formal mathematics tasks where symbolic tools\ncurrently excel beyond neural models, such as inferring semantic relations\nbetween datatypes and emulating program behavior. We introduce a general\nframework that nicely connects the abstract concepts of structural recursion in\nthe programming language domain to concrete sequence modeling problems and\nlearned models' behavior. The framework includes a representation that captures\nthe general \\textit{syntax} of structural recursion, coupled with two different\nframeworks for understanding their \\textit{semantics} -- one that is more\nnatural from a programming languages perspective and one that helps bridge that\nperspective with a mechanistic understanding of the underlying transformer\narchitecture.\n</p>\n<p>With our framework as a powerful conceptual tool, we identify different\nissues under various set-ups. The models trained to emulate recursive\ncomputations cannot fully capture the recursion yet instead fit short-cut\nalgorithms and thus cannot solve certain edge cases that are under-represented\nin the training distribution. In addition, it is difficult for state-of-the-art\nlarge language models (LLMs) to mine recursive rules from in-context\ndemonstrations. Meanwhile, these LLMs fail in interesting ways when emulating\nreduction (step-wise computation) of the recursive function.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dylan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tigges_C/0/1/0/all/0/1\">Curt Tigges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zory Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biderman_S/0/1/0/all/0/1\">Stella Biderman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raginsky_M/0/1/0/all/0/1\">Maxim Raginsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringer_T/0/1/0/all/0/1\">Talia Ringer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta-Prompting: Enhancing Language Models with Task-Agnostic Scaffolding. (arXiv:2401.12954v1 [cs.CL])","link":"http://arxiv.org/abs/2401.12954","description":"<p>We introduce meta-prompting, an effective scaffolding technique designed to\nenhance the functionality of language models (LMs). This approach transforms a\nsingle LM into a multi-faceted conductor, adept at managing and integrating\nmultiple independent LM queries. By employing high-level instructions,\nmeta-prompting guides the LM to break down complex tasks into smaller, more\nmanageable subtasks. These subtasks are then handled by distinct \"expert\"\ninstances of the same LM, each operating under specific, tailored instructions.\nCentral to this process is the LM itself, in its role as the conductor, which\nensures seamless communication and effective integration of the outputs from\nthese expert models. It additionally employs its inherent critical thinking and\nrobust verification processes to refine and authenticate the end result. This\ncollaborative prompting approach empowers a single LM to simultaneously act as\na comprehensive orchestrator and a panel of diverse experts, significantly\nenhancing its performance across a wide array of tasks. The zero-shot,\ntask-agnostic nature of meta-prompting greatly simplifies user interaction by\nobviating the need for detailed, task-specific instructions. Furthermore, our\nresearch demonstrates the seamless integration of external tools, such as a\nPython interpreter, into the meta-prompting framework, thereby broadening its\napplicability and utility. Through rigorous experimentation with GPT-4, we\nestablish the superiority of meta-prompting over conventional scaffolding\nmethods: When averaged across all tasks, including the Game of 24,\nCheckmate-in-One, and Python Programming Puzzles, meta-prompting, augmented\nwith a Python interpreter functionality, surpasses standard prompting by 17.1%,\nexpert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suzgun_M/0/1/0/all/0/1\">Mirac Suzgun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents. (arXiv:2401.12963v1 [cs.RO])","link":"http://arxiv.org/abs/2401.12963","description":"<p>Foundation models that incorporate language, vision, and more recently\nactions have revolutionized the ability to harness internet scale data to\nreason about useful tasks. However, one of the key challenges of training\nembodied foundation models is the lack of data grounded in the physical world.\nIn this paper, we propose AutoRT, a system that leverages existing foundation\nmodels to scale up the deployment of operational robots in completely unseen\nscenarios with minimal human supervision. AutoRT leverages vision-language\nmodels (VLMs) for scene understanding and grounding, and further uses large\nlanguage models (LLMs) for proposing diverse and novel instructions to be\nperformed by a fleet of robots. Guiding data collection by tapping into the\nknowledge of foundation models enables AutoRT to effectively reason about\nautonomy tradeoffs and safety while significantly scaling up data collection\nfor robot learning. We demonstrate AutoRT proposing instructions to over 20\nrobots across multiple buildings and collecting 77k real robot episodes via\nboth teleoperation and autonomous robot policies. We experimentally show that\nsuch \"in-the-wild\" data collected by AutoRT is significantly more diverse, and\nthat AutoRT's use of LLMs allows for instruction following data collection\nrobots that can align to human preferences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahn_M/0/1/0/all/0/1\">Michael Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwibedi_D/0/1/0/all/0/1\">Debidatta Dwibedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arenas_M/0/1/0/all/0/1\">Montse Gonzalez Arenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Keerthana Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1\">Karol Hausman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1\">Brian Ichter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1\">Alex Irpan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Nikhil Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirmani_S/0/1/0/all/0/1\">Sean Kirmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_I/0/1/0/all/0/1\">Isabel Leal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1\">Edward Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_I/0/1/0/all/0/1\">Isabel Leal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddineni_S/0/1/0/all/0/1\">Sharath Maddineni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1\">Kanishka Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadigh_D/0/1/0/all/0/1\">Dorsa Sadigh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanketi_P/0/1/0/all/0/1\">Pannag Sanketi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1\">Pierre Sermanet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuong_Q/0/1/0/all/0/1\">Quan Vuong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welker_S/0/1/0/all/0/1\">Stefan Welker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Ted Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Steve Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhuo Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Generate Questions by Enhancing Text Generation with Sentence Selection. (arXiv:2212.12192v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.12192","description":"<p>We introduce an approach for the answer-aware question generation problem.\nInstead of only relying on the capability of strong pre-trained language\nmodels, we observe that the information of answers and questions can be found\nin some relevant sentences in the context. Based on that, we design a model\nwhich includes two modules: a selector and a generator. The selector forces the\nmodel to more focus on relevant sentences regarding an answer to provide\nimplicit local information. The generator generates questions by implicitly\ncombining local information from the selector and global information from the\nwhole context encoded by the encoder. The model is trained jointly to take\nadvantage of latent interactions between the two modules. Experimental results\non two benchmark datasets show that our model is better than strong pre-trained\nmodels for the question generation task. The code is also available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Quoc_Hung_P/0/1/0/all/0/1\">Pham Quoc-Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh-Tien Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_Tien_M/0/1/0/all/0/1\">Manh Tran-Tien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_X/0/1/0/all/0/1\">Xuan-Hieu Phan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v4 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2304.14391","description":"<p>Language is compositional; an instruction can express multiple relation\nconstraints to hold among objects in a scene that a robot is tasked to\nrearrange. Our focus in this work is an instructable scene-rearranging\nframework that generalizes to longer instructions and to spatial concept\ncompositions never seen at training time. We propose to represent\nlanguage-instructed spatial concepts with energy functions over relative object\narrangements. A language parser maps instructions to corresponding energy\nfunctions and an open-vocabulary visual-language model grounds their arguments\nto relevant objects in the scene. We generate goal scene configurations by\ngradient descent on the sum of energy functions, one per language predicate in\nthe instruction. Local vision-based policies then re-locate objects to the\ninferred goal locations. We test our model on established instruction-guided\nmanipulation benchmarks, as well as benchmarks of compositional instructions we\nintroduce. We show our model can execute highly compositional instructions\nzero-shot in simulation and in the real world. It outperforms\nlanguage-to-action reactive policies and Large Language Model planners by a\nlarge margin, especially for long instructions that involve compositions of\nmultiple spatial concepts. Simulation and real-world robot execution videos, as\nwell as our code and datasets are publicly available on our website:\nhttps://ebmplanner.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gkanatsios_N/0/1/0/all/0/1\">Nikolaos Gkanatsios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Ayush Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Z/0/1/0/all/0/1\">Zhou Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunchu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkeson_C/0/1/0/all/0/1\">Christopher Atkeson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1\">Katerina Fragkiadaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings. (arXiv:2305.02317v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02317","description":"<p>Recent advances in large language models elicit reasoning in a\nchain-of-thought that allows models to decompose problems in a human-like\nfashion. Though this paradigm improves multi-step reasoning ability in language\nmodels, it is limited by being unimodal and applied mainly to\nquestion-answering tasks. We claim that incorporating visual augmentation into\nreasoning is essential, especially for complex, imaginative tasks.\nConsequently, we introduce VCoT, a novel method that leverages chain-of-thought\nprompting with vision-language grounding to recursively bridge the logical gaps\nwithin sequential data. Our method uses visual guidance to generate synthetic\nmultimodal infillings that add consistent and novel information to reduce the\nlogical gaps for downstream tasks that can benefit from temporal reasoning, as\nwell as provide interpretability into models' multi-step reasoning. We apply\nVCoT to the Visual Storytelling and WikiHow summarization datasets and\ndemonstrate through human evaluation that VCoT offers novel and consistent\nsynthetic data augmentation beating chain-of-thought baselines, which can be\nused to enhance downstream performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rose_D/0/1/0/all/0/1\">Daniel Rose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Himakunthala_V/0/1/0/all/0/1\">Vaishnavi Himakunthala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_A/0/1/0/all/0/1\">Andy Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ryan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_A/0/1/0/all/0/1\">Alex Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonar_C/0/1/0/all/0/1\">Chinmay Sonar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mirza_D/0/1/0/all/0/1\">Diba Mirza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpecInfer: Accelerating Generative Large Language Model Serving with Tree-based Speculative Inference and Verification. (arXiv:2305.09781v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09781","description":"<p>This paper introduces SpecInfer, a system that accelerates generative large\nlanguage model (LLM) serving with tree-based speculative inference and\nverification. The key idea behind SpecInfer is leveraging small speculative\nmodels to predict the LLM's outputs; the predictions are organized as a token\ntree, whose nodes each represent a candidate token sequence. The correctness of\nall candidate token sequences represented by a token tree is verified against\nthe LLM in parallel using a novel tree-based parallel decoding mechanism.\nSpecInfer uses an LLM as a token tree verifier instead of an incremental\ndecoder, which significantly reduces the end-to-end latency and computational\nrequirement for serving generative LLMs while provably preserving model\nquality. Our evaluation shows that SpecInfer outperforms existing LLM serving\nsystems by 1.5-2.8x for distributed LLM inference and by 2.6-3.5x for\noffloading-based LLM inference, while preserving the same generative\nperformance. SpecInfer is publicly available at\nhttps://github.com/flexflow/FlexFlow/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Miao_X/0/1/0/all/0/1\">Xupeng Miao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliaro_G/0/1/0/all/0/1\">Gabriele Oliaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xinhao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zeyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1\">Rae Ying Yee Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_A/0/1/0/all/0/1\">Alan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lijie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaoxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chunan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuoming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arfeen_D/0/1/0/all/0/1\">Daiyaan Arfeen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abhyankar_R/0/1/0/all/0/1\">Reyna Abhyankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1\">Zhihao Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Generate Novel Scientific Directions with Contextualized Literature-based Discovery. (arXiv:2305.14259v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14259","description":"<p>Literature-Based Discovery (LBD) aims to discover new scientific knowledge by\nmining papers and generating hypotheses. Standard LBD is limited to predicting\npairwise relations between discrete concepts (e.g., drug-disease links), and\nignores critical contexts like experimental settings (e.g., a specific patient\npopulation where a drug is evaluated) and background motivations (e.g., to find\ndrugs without specific side effects). We address these limitations with a novel\nformulation of contextualized-LBD (C-LBD): generating scientific hypotheses in\nnatural language, while grounding them in a context that controls the\nhypothesis search space. We present a modeling framework using retrieval of\n``inspirations'' from past scientific papers. Our evaluations reveal that GPT-4\ntends to generate ideas with overall low technical depth and novelty, while our\ninspiration prompting approaches partially mitigate this issue. Our work\nrepresents a first step toward building language models that generate new ideas\nderived from scientific literature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingyun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OWQ: Lessons learned from activation outliers for weight quantization in large language models. (arXiv:2306.02272v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02272","description":"<p>Large language models (LLMs) with hundreds of billions of parameters require\npowerful server-grade GPUs for inference, limiting their practical deployment.\nTo address this challenge, we introduce the outlier-aware weight quantization\n(OWQ) method, which aims to minimize LLM's footprint through low-precision\nrepresentation. OWQ prioritizes a small subset of structured weights sensitive\nto quantization, storing them in high-precision, while applying highly tuned\nquantization to the remaining dense weights. This sensitivity-aware\nmixed-precision scheme reduces the quantization error notably, and extensive\nexperiments demonstrate that 3.1-bit models using OWQ perform comparably to\n4-bit models optimized by OPTQ. Furthermore, OWQ incorporates a\nparameter-efficient fine-tuning for task-specific adaptation, called weak\ncolumn tuning (WCT), enabling accurate task-specific LLM adaptation with\nminimal memory overhead in the optimized format. OWQ represents a notable\nadvancement in the flexibility, efficiency, and practicality of LLM\noptimization literature. The source code is available at\nhttps://github.com/xvyaward/owq\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Changhun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1\">Jungyu Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyungjun Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunhyeok Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-centered NLP Fact-checking: Co-Designing with Fact-checkers using Matchmaking for AI. (arXiv:2308.07213v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2308.07213","description":"<p>While many Natural Language Processing (NLP) techniques have been proposed\nfor fact-checking, both academic research and fact-checking organizations\nreport limited adoption of such NLP work due to poor alignment with\nfact-checker practices, values, and needs. To address this, we investigate a\nco-design method, Matchmaking for AI, to enable fact-checkers, designers, and\nNLP researchers to collaboratively identify what fact-checker needs should be\naddressed by technology, and to brainstorm ideas for potential solutions.\nCo-design sessions we conducted with 22 professional fact-checkers yielded a\nset of 11 design ideas that offer a \"north star\", integrating fact-checker\ncriteria into novel NLP design concepts. These concepts range from pre-bunking\nmisinformation, efficient and personalized monitoring misinformation,\nproactively reducing fact-checker potential biases, and collaborative writing\nfact-check reports. Our work provides new insights into both human-centered\nfact-checking research and practice and AI co-design research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Houjiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Anubrata Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boltz_A/0/1/0/all/0/1\">Alexander Boltz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Didi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinaroc_D/0/1/0/all/0/1\">Daisy Pinaroc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lease_M/0/1/0/all/0/1\">Matthew Lease</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Min Kyung Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12890","description":"<p>The emergence of generative Large Language Models (LLMs) emphasizes the need\nfor accurate and efficient prompting approaches. LLMs are often applied in\nFew-Shot Learning (FSL) contexts, where tasks are executed with minimal\ntraining data. FSL has become popular in many Artificial Intelligence (AI)\nsubdomains, including AI for health. Rare diseases affect a small fraction of\nthe population. Rare disease identification from clinical notes inherently\nrequires FSL techniques due to limited data availability. Manual data\ncollection and annotation is both expensive and time-consuming. In this paper,\nwe propose Models-Vote Prompting (MVP), a flexible prompting approach for\nimproving the performance of LLM queries in FSL settings. MVP works by\nprompting numerous LLMs to perform the same tasks and then conducting a\nmajority vote on the resulting outputs. This method achieves improved results\nto any one model in the ensemble on one-shot rare disease identification and\nclassification tasks. We also release a novel rare disease dataset for FSL,\navailable to those who signed the MIMIC-IV Data Use Agreement (DUA).\nFurthermore, in using MVP, each model is prompted multiple times, substantially\nincreasing the time needed for manual annotation, and to address this, we\nassess the feasibility of using JSON for automating generative LLM evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1\">David Oniani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1\">Jordan Hilsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_F/0/1/0/all/0/1\">Fengyi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Shiven Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanshan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models. (arXiv:2308.16692v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16692","description":"<p>Current speech large language models build upon discrete speech\nrepresentations, which can be categorized into semantic tokens and acoustic\ntokens. However, existing speech tokens are not specifically designed for\nspeech language modeling. To assess the suitability of speech tokens for\nbuilding speech language models, we established the first benchmark,\nSLMTokBench. Our results indicate that neither semantic nor acoustic tokens are\nideal for this purpose. Therefore, we propose SpeechTokenizer, a unified speech\ntokenizer for speech large language models. SpeechTokenizer adopts the\nEncoder-Decoder architecture with residual vector quantization (RVQ). Unifying\nsemantic and acoustic tokens, SpeechTokenizer disentangles different aspects of\nspeech information hierarchically across different RVQ layers. Furthermore, We\nconstruct a Unified Speech Language Model (USLM) leveraging SpeechTokenizer.\nExperiments show that SpeechTokenizer performs comparably to EnCodec in speech\nreconstruction and demonstrates strong performance on the SLMTokBench\nbenchmark. Also, USLM outperforms VALL-E in zero-shot Text-to-Speech tasks.\nCode and models are available at\nhttps://github.com/ZhangXInFD/SpeechTokenizer/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yaqian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiariST: Streaming Speech Translation with Speaker Diarization. (arXiv:2309.08007v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.08007","description":"<p>End-to-end speech translation (ST) for conversation recordings involves\nseveral under-explored challenges such as speaker diarization (SD) without\naccurate word time stamps and handling of overlapping speech in a streaming\nfashion. In this work, we propose DiariST, the first streaming ST and SD\nsolution. It is built upon a neural transducer-based streaming ST system and\nintegrates token-level serialized output training and t-vector, which were\noriginally developed for multi-talker speech recognition. Due to the absence of\nevaluation benchmarks in this area, we develop a new evaluation dataset,\nDiariST-AliMeeting, by translating the reference Chinese transcriptions of the\nAliMeeting corpus into English. We also propose new metrics, called\nspeaker-agnostic BLEU and speaker-attributed BLEU, to measure the ST quality\nwhile taking SD accuracy into account. Our system achieves a strong ST and SD\ncapability compared to offline systems based on Whisper, while performing\nstreaming inference for overlapping speech. To facilitate the research in this\nnew direction, we release the evaluation data, the offline baseline systems,\nand the evaluation code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_M/0/1/0/all/0/1\">Mu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1\">Naoyuki Kanda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jian Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yoshioka_T/0/1/0/all/0/1\">Takuya Yoshioka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Multitask Training Approach to Enhance Whisper with Contextual Biasing and Open-Vocabulary Keyword Spotting. (arXiv:2309.09552v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.09552","description":"<p>End-to-end automatic speech recognition (ASR) systems often struggle to\nrecognize rare name entities, such as personal names, organizations, and\nterminologies not frequently encountered in the training data. This paper\npresents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on\nOpenAI's Whisper model that can recognize user-defined name entities by\nperforming open-vocabulary keyword-spotting (OV-KWS) using the hidden states of\nWhisper encoder. The recognized entities are used as prompts for the Whisper\ndecoder. We first propose a multitask training approach with OV-KWS and ASR\ntasks to optimize the model. Experiments show that this approach substantially\nimproves the entity recalls compared to the original Whisper model on Chinese\nAishell hot word subsets and two internal code-switch test sets. However, we\nobserved a slight increase in mixed-error-rate (MER) on internal test sets due\nto catastrophic forgetting. To address this problem and use different sizes of\nthe Whisper model without finetuning, we propose to use OV-KWS as a separate\nmodule and construct a spoken form prompt to prevent hallucination. The OV-KWS\nmodule consistently improves MER and Entity Recall for whisper-small, medium,\nand large models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinglu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1\">Chang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1\">Mengxin Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_X/0/1/0/all/0/1\">Xiaosong Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaofeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piao_M/0/1/0/all/0/1\">Mengyao Piao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiawei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xinglin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Miaomiao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanqing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutomaTikZ: Text-Guided Synthesis of Scientific Vector Graphics with TikZ. (arXiv:2310.00367v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00367","description":"<p>Generating bitmap graphics from text has gained considerable attention, yet\nfor scientific figures, vector graphics are often preferred. Given that vector\ngraphics are typically encoded using low-level graphics primitives, generating\nthem directly is difficult. To address this, we propose the use of TikZ, a\nwell-known abstract graphics language that can be compiled to vector graphics,\nas an intermediate representation of scientific figures. TikZ offers\nhuman-oriented, high-level commands, thereby facilitating conditional language\nmodeling with any large language model. To this end, we introduce DaTikZ, the\nfirst large-scale TikZ dataset consisting of 120k TikZ drawings aligned with\ncaptions. We fine-tune LLaMA on DaTikZ, as well as our new model CLiMA, which\naugments LLaMA with multimodal CLIP embeddings. In both human and automatic\nevaluation, CLiMA and LLaMA outperform commercial GPT-4 and Claude 2 in terms\nof similarity to human-created figures, with CLiMA additionally improving\ntext-image alignment. Our detailed analysis shows that all models generalize\nwell and are not susceptible to memorization. GPT-4 and Claude 2, however, tend\nto generate more simplistic figures compared to both humans and our models. We\nmake our framework, AutomaTikZ, along with model weights and datasets, publicly\navailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belouadi_J/0/1/0/all/0/1\">Jonas Belouadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1\">Anne Lauscher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GenAI Against Humanity: Nefarious Applications of Generative Artificial Intelligence and Large Language Models. (arXiv:2310.00737v3 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2310.00737","description":"<p>Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)\nare marvels of technology; celebrated for their prowess in natural language\nprocessing and multimodal content generation, they promise a transformative\nfuture. But as with all powerful tools, they come with their shadows. Picture\nliving in a world where deepfakes are indistinguishable from reality, where\nsynthetic identities orchestrate malicious campaigns, and where targeted\nmisinformation or scams are crafted with unparalleled precision. Welcome to the\ndarker side of GenAI applications. This article is not just a journey through\nthe meanders of potential misuse of GenAI and LLMs, but also a call to\nrecognize the urgency of the challenges ahead. As we navigate the seas of\nmisinformation campaigns, malicious content generation, and the eerie creation\nof sophisticated malware, we'll uncover the societal implications that ripple\nthrough the GenAI revolution we are witnessing. From AI-powered botnets on\nsocial media platforms to the unnerving potential of AI to generate fabricated\nidentities, or alibis made of synthetic realities, the stakes have never been\nhigher. The lines between the virtual and the real worlds are blurring, and the\nconsequences of potential GenAI's nefarious applications impact us all. This\narticle serves both as a synthesis of rigorous research presented on the risks\nof GenAI and misuse of LLMs and as a thought-provoking vision of the different\ntypes of harmful GenAI applications we might encounter in the near future, and\nsome ways we can prepare for them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1\">Emilio Ferrara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval meets Long Context Large Language Models. (arXiv:2310.03025v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03025","description":"<p>Extending the context window of large language models (LLMs) is getting\npopular recently, while the solution of augmenting LLMs with retrieval has\nexisted for years. The natural questions are: i) Retrieval-augmentation versus\nlong context window, which one is better for downstream tasks? ii) Can both\nmethods be combined to get the best of both worlds? In this work, we answer\nthese questions by studying both solutions using two state-of-the-art\npretrained LLMs, i.e., a proprietary 43B GPT and Llama2-70B. Perhaps\nsurprisingly, we find that LLM with 4K context window using simple\nretrieval-augmentation at generation can achieve comparable performance to\nfinetuned LLM with 16K context window via positional interpolation on long\ncontext tasks, while taking much less computation. More importantly, we\ndemonstrate that retrieval can significantly improve the performance of LLMs\nregardless of their extended context window sizes. Our best model,\nretrieval-augmented Llama2-70B with 32K context window, outperforms\nGPT-3.5-turbo-16k and Davinci003 in terms of average score on nine long context\ntasks including question answering, query-based summarization, and in-context\nfew-shot learning tasks. It also outperforms its non-retrieval Llama2-70B-32k\nbaseline by a margin, while being much faster at generation. Our study provides\ngeneral insights on the choice of retrieval-augmentation versus long context\nextension of LLM for practitioners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xianchao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1\">Lawrence McAfee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chen Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_S/0/1/0/all/0/1\">Sandeep Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bakhturina_E/0/1/0/all/0/1\">Evelina Bakhturina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling. (arXiv:2310.04691v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04691","description":"<p>Neural language models are probabilistic models of human text. They are\npredominantly trained using maximum likelihood estimation (MLE), which is\nequivalent to minimizing the forward cross-entropy between the empirical data\ndistribution and the model distribution. However, various degeneration\nphenomena are still widely observed when decoding from the distributions\nlearned by such models. We establish that the forward cross-entropy is\nsuboptimal as a distance metric for aligning human and model distribution due\nto its (1) recall-prioritization (2) negative diversity ignorance and (3)\ntrain-test mismatch. In this paper, we propose Earth Mover Distance\nOptimization (EMO) for auto-regressive language modeling. EMO capitalizes on\nthe inherent properties of earth mover distance to address the aforementioned\nchallenges. Due to the high complexity of direct computation, we further\nintroduce a feasible upper bound for EMO to ease end-to-end training. Upon\nextensive evaluation of language models trained using EMO and MLE. We find that\nEMO demonstrates a consistently better language modeling performance than MLE\nacross domains. Moreover, EMO demonstrates noteworthy enhancements in\ndownstream performance with minimal fine-tuning on merely 25,000 sentences.\nThis highlights the tremendous potential of EMO as a lightweight calibration\nmethod for enhancing large-scale pre-trained language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Siyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Formally Specifying the High-Level Behavior of LLM-Based Agents. (arXiv:2310.08535v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.08535","description":"<p>Autonomous, goal-driven agents powered by LLMs have recently emerged as\npromising tools for solving challenging problems without the need for\ntask-specific finetuned models that can be expensive to procure. Currently, the\ndesign and implementation of such agents is ad hoc, as the wide variety of\ntasks that LLM-based agents may be applied to naturally means there can be no\none-size-fits-all approach to agent design. In this work we aim to alleviate\nthe difficulty of designing and implementing new agents by proposing a\nminimalistic generation framework that simplifies the process of building\nagents. The framework we introduce allows the user to define desired agent\nbehaviors in a high-level, declarative specification that is then used to\nconstruct a decoding monitor which guarantees the LLM will produce an output\nexhibiting the desired behavior. Our declarative approach, in which the\nbehavior is described without concern for how it should be implemented or\nenforced, enables rapid design, implementation, and experimentation with\ndifferent LLM-based agents. We demonstrate how the proposed framework can be\nused to implement recent LLM-based agents (e.g., ReACT), and show how the\nflexibility of our approach can be leveraged to define a new agent with more\ncomplex behavior, the Plan-Act-Summarize-Solve (PASS) agent. Lastly, we\ndemonstrate that our method outperforms other agents on multiple popular\nreasoning-centric question-answering benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Crouse_M/0/1/0/all/0/1\">Maxwell Crouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1\">Ibrahim Abdelaziz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1\">Ramon Astudillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_K/0/1/0/all/0/1\">Kinjal Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1\">Soham Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumaravel_S/0/1/0/all/0/1\">Sadhana Kumaravel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fokoue_A/0/1/0/all/0/1\">Achille Fokoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1\">Pavan Kapanipathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lastras_L/0/1/0/all/0/1\">Luis Lastras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Outlier Dimensions Encode Task-Specific Knowledge. (arXiv:2310.17715v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.17715","description":"<p>Representations from large language models (LLMs) are known to be dominated\nby a small subset of dimensions with exceedingly high variance. Previous works\nhave argued that although ablating these outlier dimensions in LLM\nrepresentations hurts downstream performance, outlier dimensions are\ndetrimental to the representational quality of embeddings. In this study, we\ninvestigate how fine-tuning impacts outlier dimensions and show that 1) outlier\ndimensions that occur in pre-training persist in fine-tuned models and 2) a\nsingle outlier dimension can complete downstream tasks with a minimal error\nrate. Our results suggest that outlier dimensions can encode crucial\ntask-specific knowledge and that the value of a representation in a single\noutlier dimension drives downstream model decisions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rudman_W/0/1/0/all/0/1\">William Rudman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Catherine Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1\">Carsten Eickhoff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Turing: A Comparative Analysis of Approaches for Detecting Machine-Generated Text. (arXiv:2311.12373v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.12373","description":"<p>Significant progress has been made on text generation by pre-trained language\nmodels (PLMs), yet distinguishing between human and machine-generated text\nposes an escalating challenge. This paper offers an in-depth evaluation of\nthree distinct methods used to address this task: traditional shallow learning,\nLanguage Model (LM) fine-tuning, and Multilingual Model fine-tuning. These\napproaches are rigorously tested on a wide range of machine-generated texts,\nproviding a benchmark of their competence in distinguishing between\nhuman-authored and machine-authored linguistic constructs. The results reveal\nconsiderable differences in performance across methods, thus emphasizing the\ncontinued need for advancement in this crucial area of NLP. This study offers\nvaluable insights and paves the way for future research aimed at creating\nrobust and highly discriminative models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adilazuarda_M/0/1/0/all/0/1\">Muhammad Farid Adilazuarda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A ripple in time: a discontinuity in American history. (arXiv:2312.01185v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.01185","description":"<p>In this note we use the State of the Union Address (SOTU) dataset from Kaggle\nto make some surprising (and some not so surprising) observations pertaining to\nthe general timeline of American history, and the character and nature of the\naddresses themselves. Our main approach is using vector embeddings, such as\nBERT (DistilBERT) and GPT-2.\n</p>\n<p>While it is widely believed that BERT (and its variations) is most suitable\nfor NLP classification tasks, we find out that GPT-2 in conjunction with\nnonlinear dimension reduction methods such as UMAP provide better separation\nand stronger clustering. This makes GPT-2 + UMAP an interesting alternative. In\nour case, no model fine-tuning is required, and the pre-trained out-of-the-box\nGPT-2 model is enough.\n</p>\n<p>We also used a fine-tuned DistilBERT model for classification detecting which\nPresident delivered which address, with very good results (accuracy 93% - 95%\ndepending on the run). An analogous task was performed to determine the year of\nwriting, and we were able to pin it down to about 4 years (which is a single\npresidential term).\n</p>\n<p>It is worth noting that SOTU addresses provide relatively small writing\nsamples (with about 8'000 words on average, and varying widely from under 2'000\nwords to more than 20'000), and that the number of authors is relatively large\n(we used SOTU addresses of 42 US presidents). This shows that the techniques\nemployed turn out to be rather efficient, while all the computations described\nin this note can be performed using a single GPU instance of Google Colab.\n</p>\n<p>The accompanying code is available on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kolpakov_A/0/1/0/all/0/1\">Alexander Kolpakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivin_I/0/1/0/all/0/1\">Igor Rivin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Text Watermarking in the Era of Large Language Models. (arXiv:2312.07913v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.07913","description":"<p>Text watermarking algorithms play a crucial role in the copyright protection\nof textual content, yet their capabilities and application scenarios have been\nlimited historically. The recent developments in large language models (LLMs)\nhave opened new opportunities for the advancement of text watermarking\ntechniques. LLMs not only enhance the capabilities of text watermarking\nalgorithms through their text understanding and generation abilities but also\nnecessitate the use of text watermarking algorithms for their own copyright\nprotection. This paper conducts a comprehensive survey of the current state of\ntext watermarking technology, covering four main aspects: (1) an overview and\ncomparison of different text watermarking techniques; (2) evaluation methods\nfor text watermarking algorithms, including their success rates, impact on text\nquality, robustness, and unforgeability; (3) potential application scenarios\nfor text watermarking technology; (4) current challenges and future directions\nfor development. This survey aims to provide researchers with a thorough\nunderstanding of text watermarking technology, thereby promoting its further\nadvancement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Aiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Leyi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yijian Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingjing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and Optimisation. (arXiv:2312.13010v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.13010","description":"<p>The advancement of natural language processing (NLP) has been significantly\nboosted by the development of transformer-based large language models (LLMs).\nThese models have revolutionized NLP tasks, particularly in code generation,\naiding developers in creating software with enhanced efficiency. Despite their\nadvancements, challenges in balancing code snippet generation with effective\ntest case generation and execution persist. To address these issues, this paper\nintroduces Multi-Agent Assistant Code Generation (AgentCoder), a novel solution\ncomprising a multi-agent framework with specialized agents: the programmer\nagent, the test designer agent, and the test executor agent. During the coding\nprocedure, the programmer agent will focus on the code generation and\nrefinement based on the test executor agent's feedback. The test designer agent\nwill generate test cases for the generated code, and the test executor agent\nwill run the code with the test cases and write the feedback to the programmer.\nThis collaborative system ensures robust code generation, surpassing the\nlimitations of single-agent models and traditional methodologies. Our extensive\nexperiments on 9 code generation models and 12 enhancement approaches showcase\nAgentCoder's superior performance over existing code generation models and\nprompt engineering techniques across various benchmarks. For example,\nAgentCoder achieves 77.4% and 89.1% pass@1 in HumanEval-ET and MBPP-ET with\nGPT-3.5, while SOTA baselines obtain only 69.5% and 63.0%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">Dong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bu_Q/0/1/0/all/0/1\">Qingwen Bu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jie M.Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luck_M/0/1/0/all/0/1\">Michael Luck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1\">Heming Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.02994","description":"<p>In conversational AI research, there's a noticeable trend towards developing\nmodels with a larger number of parameters, exemplified by models like ChatGPT.\nWhile these expansive models tend to generate increasingly better chat\nresponses, they demand significant computational resources and memory. This\nstudy explores a pertinent question: Can a combination of smaller models\ncollaboratively achieve comparable or enhanced performance relative to a\nsingular large model? We introduce an approach termed \"blending\", a\nstraightforward yet effective method of integrating multiple chat AIs. Our\nempirical evidence suggests that when specific smaller models are\nsynergistically blended, they can potentially outperform or match the\ncapabilities of much larger counterparts. For instance, integrating just three\nmodels of moderate size (6B/13B paramaeters) can rival or even surpass the\nperformance metrics of a substantially larger model like ChatGPT (175B+\nparamaters). This hypothesis is rigorously tested using A/B testing\nmethodologies with a large user base on the Chai research platform over a span\nof thirty days. The findings underscore the potential of the \"blending\"\nstrategy as a viable approach for enhancing chat AI efficacy without a\ncorresponding surge in computational demands.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaoding Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zongyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vyas Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mudupalli_V/0/1/0/all/0/1\">Vineet Mudupalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beauchamp_W/0/1/0/all/0/1\">William Beauchamp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue Systems. (arXiv:2401.04867v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04867","description":"<p>Establishing evaluation schemes for spoken dialogue systems is important, but\nit can also be challenging. While subjective evaluations are commonly used in\nuser experiments, objective evaluations are necessary for research comparison\nand reproducibility. To address this issue, we propose a framework for\nindirectly but objectively evaluating systems based on users' behaviors. In\nthis paper, to this end, we investigate the relationship between user behaviors\nand subjective evaluation scores in social dialogue tasks: attentive listening,\njob interview, and first-meeting conversation. The results reveal that in\ndialogue tasks where user utterances are primary, such as attentive listening\nand job interview, indicators like the number of utterances and words play a\nsignificant role in evaluation. Observing disfluency also can indicate the\neffectiveness of formal tasks, such as job interview. On the other hand, in\ndialogue tasks with high interactivity, such as first-meeting conversation,\nbehaviors related to turn-taking, like average switch pause length, become more\nimportant. These findings suggest that selecting appropriate user behaviors can\nprovide valuable insights for objective evaluation in each social dialogue\ntask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Koji Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lala_D/0/1/0/all/0/1\">Divesh Lala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochi_K/0/1/0/all/0/1\">Keiko Ochi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1\">Tatsuya Kawahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skantze_G/0/1/0/all/0/1\">Gabriel Skantze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning. (arXiv:2401.06827v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2401.06827","description":"<p>Pre-trained Vision-Language (V-L) models set the benchmark for generalization\nto downstream tasks among the noteworthy contenders. Many characteristics of\nthe V-L model have been explored in existing research including the challenge\nof the sensitivity to text input and the tuning process across multi-modal\nprompts. With the advanced utilization of the V-L model like CLIP, recent\napproaches deploy learnable prompts instead of hand-craft prompts to boost the\ngeneralization performance and address the aforementioned challenges. Inspired\nby layer-wise training, which is wildly used in image fusion, we note that\nusing a sequential training process to adapt different modalities branches of\nCLIP efficiently facilitates the improvement of generalization. In the context\nof addressing the multi-modal prompting challenge, we propose Token-wise\nAdaptive for Multi-modal Prompt Learning (APLe) for tuning both modalities\nprompts, vision and language, as tokens in a sequential manner. APLe addresses\nthe challenges in V-L models to promote prompt learning across both modalities,\nwhich indicates a competitive generalization performance in line with the\nstate-of-the-art. Preeminently, APLe shows robustness and favourable\nperformance in prompt-length experiments with an absolute advantage in adopting\nthe V-L models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cao_G/0/1/0/all/0/1\">Guiming Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1\">Kaize Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Hong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huaiwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guandong Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring. (arXiv:2401.08517v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2401.08517","description":"<p>Student commitment towards a learning recommendation is not separable from\ntheir understanding of the reasons it was recommended to them; and their\nability to modify it based on that understanding. Among explainability\napproaches, chatbots offer the potential to engage the student in a\nconversation, similar to a discussion with a peer or a mentor. The capabilities\nof chatbots, however, are still not sufficient to replace a human mentor,\ndespite the advancements of generative AI (GenAI) and large language models\n(LLM). Therefore, we propose an approach to utilize chatbots as mediators of\nthe conversation and sources of limited and controlled generation of\nexplanations, to harvest the potential of LLMs while reducing their potential\nrisks at the same time. The proposed LLM-based chatbot supports students in\nunderstanding learning-paths recommendations. We use a knowledge graph (KG) as\na human-curated source of information, to regulate the LLM's output through\ndefining its prompt's context. A group chat approach is developed to connect\nstudents with human mentors, either on demand or in cases that exceed the\nchatbot's pre-defined tasks. We evaluate the chatbot with a user study, to\nprovide a proof-of-concept and highlight the potential requirements and\nlimitations of utilizing chatbots in conversational explainability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abu_Rasheed_H/0/1/0/all/0/1\">Hasan Abu-Rasheed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulsalam_M/0/1/0/all/0/1\">Mohamad Hussam Abdulsalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1\">Christian Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fathi_M/0/1/0/all/0/1\">Madjid Fathi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Partial Diacritization: A Context-Contrastive Inference Approach. (arXiv:2401.08919v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.08919","description":"<p>Diacritization plays a pivotal role in improving readability and\ndisambiguating the meaning of Arabic texts. Efforts have so far focused on\nmarking every eligible character (Full Diacritization). Comparatively\noverlooked, Partial Diacritzation (PD) is the selection of a subset of\ncharacters to be marked to aid comprehension where needed. Research has\nindicated that excessive diacritic marks can hinder skilled readers--reducing\nreading speed and accuracy. We conduct a behavioral experiment and show that\npartially marked text is often easier to read than fully marked text, and\nsometimes easier than plain text. In this light, we introduce\nContext-Contrastive Partial Diacritization (CCPD)--a novel approach to PD which\nintegrates seamlessly with existing Arabic diacritization systems. CCPD\nprocesses each word twice, once with context and once without, and diacritizes\nonly the characters with disparities between the two inferences. Further, we\nintroduce novel indicators for measuring partial diacritization quality (SR,\nPDER, HDER, ERE), essential for establishing this as a machine learning task.\nLastly, we introduce TD2, a Transformer-variant of an established model which\noffers a markedly different performance profile on our proposed indicators\ncompared to all other known systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ElNokrashy_M/0/1/0/all/0/1\">Muhammad ElNokrashy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spatial-Temporal Large Language Model for Traffic Prediction. (arXiv:2401.10134v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2401.10134","description":"<p>Traffic prediction, a critical component for intelligent transportation\nsystems, endeavors to foresee future traffic at specific locations using\nhistorical data. Although existing traffic prediction models often emphasize\ndeveloping complex neural network structures, their accuracy has not seen\nimprovements accordingly. Recently, Large Language Models (LLMs) have shown\noutstanding capabilities in time series analysis. Differing from existing\nmodels, LLMs progress mainly through parameter expansion and extensive\npre-training while maintaining their fundamental structures. In this paper, we\npropose a Spatial-Temporal Large Language Model (ST-LLM) for traffic\nprediction. Specifically, ST-LLM redefines the timesteps at each location as\ntokens and incorporates a spatial-temporal embedding module to learn the\nspatial location and global temporal representations of tokens. Then these\nrepresentations are fused to provide each token with unified spatial and\ntemporal information. Furthermore, we propose a novel partially frozen\nattention strategy of the LLM, which is designed to capture spatial-temporal\ndependencies for traffic prediction. Comprehensive experiments on real traffic\ndatasets offer evidence that ST-LLM outperforms state-of-the-art models.\nNotably, the ST-LLM also exhibits robust performance in both few-shot and\nzero-shot prediction scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chenxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qianxiong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhishuai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1\">Cheng Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Rui Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatQA: Building GPT-4 Level Conversational QA Models. (arXiv:2401.10225v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.10225","description":"<p>In this work, we introduce ChatQA, a family of conversational question\nanswering (QA) models that obtain GPT-4 level accuracies. Specifically, we\npropose a two-stage instruction tuning method that can significantly improve\nthe zero-shot conversational QA results from large language models (LLMs). To\nhandle retrieval-augmented generation in conversational QA, we fine-tune a\ndense retriever on a multi-turn QA dataset, which provides comparable results\nto using the state-of-the-art query rewriting model while largely reducing\ndeployment cost. Notably, our ChatQA-70B can outperform GPT-4 in terms of\naverage score on 10 conversational QA datasets (54.14 vs. 53.90), without\nrelying on any synthetic data from OpenAI GPT models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rajarshi Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chankyu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual acoustic word embeddings for zero-resource languages. (arXiv:2401.10543v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2401.10543","description":"<p>This research addresses the challenge of developing speech applications for\nzero-resource languages that lack labelled data. It specifically uses acoustic\nword embedding (AWE) -- fixed-dimensional representations of variable-duration\nspeech segments -- employing multilingual transfer, where labelled data from\nseveral well-resourced languages are used for pertaining. The study introduces\na new neural network that outperforms existing AWE models on zero-resource\nlanguages. It explores the impact of the choice of well-resourced languages.\nAWEs are applied to a keyword-spotting system for hate speech detection in\nSwahili radio broadcasts, demonstrating robustness in real-world scenarios.\nAdditionally, novel semantic AWE models improve semantic query-by-example\nsearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Jacobs_C/0/1/0/all/0/1\">Christiaan Jacobs</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?. (arXiv:2401.11033v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.11033","description":"<p>The rapid evolution of Large Language Models (LLMs) underscores the critical\nimportance of ethical considerations and data integrity in AI development,\nemphasizing the role of FAIR (Findable, Accessible, Interoperable, Reusable)\ndata principles. While these principles have long been a cornerstone of ethical\ndata stewardship, their application in LLM training data is less prevalent, an\nissue our research aims to address. Our study begins with a review of existing\nliterature, highlighting the significance of FAIR principles in data management\nfor model training. Building on this foundation, we introduce a novel framework\nthat incorporates FAIR principles into the LLM training process. A key aspect\nof this approach is a comprehensive checklist, designed to assist researchers\nand developers in consistently applying FAIR data principles throughout the\nmodel development lifecycle. The practicality and effectiveness of our\nframework are demonstrated through a case study that involves creating a\nFAIR-compliant dataset to detect and reduce biases. This case study not only\nvalidates the usefulness of our framework but also establishes new benchmarks\nfor more equitable, transparent, and ethical practices in LLM training. We\noffer this framework to the community as a means to promote technologically\nadvanced, ethically sound, and socially responsible AI models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghuge_S/0/1/0/all/0/1\">Shardul Ghuge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandya_D/0/1/0/all/0/1\">Deval Pandya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.11624","description":"<p>Language models, especially pre-trained large language models, have showcased\nremarkable abilities as few-shot in-context learners (ICL), adept at adapting\nto new tasks with just a few demonstrations in the input context. However, the\nmodel's ability to perform ICL is sensitive to the choice of the few-shot\ndemonstrations. Instead of using a fixed set of demonstrations, one recent\ndevelopment is to retrieve demonstrations tailored to each input query. The\nimplementation of demonstration retrieval is relatively straightforward,\nleveraging existing databases and retrieval systems. This not only improves the\nefficiency and scalability of the learning process but also has been shown to\nreduce biases inherent in manual example selection. In light of the encouraging\nresults and growing research in ICL with retrieved demonstrations, we conduct\nan extensive review of studies in this area. In this survey, we discuss and\ncompare different design choices for retrieval models, retrieval training\nprocedures, and inference algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Man Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1\">Panupong Pasupat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_M/0/1/0/all/0/1\">Mehran Kazemi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Claim Detection for Automated Fact-checking: A Survey on Monolingual, Multilingual and Cross-Lingual Research. (arXiv:2401.11969v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.11969","description":"<p>Automated fact-checking has drawn considerable attention over the past few\ndecades due to the increase in the diffusion of misinformation on online\nplatforms. This is often carried out as a sequence of tasks comprising (i) the\ndetection of sentences circulating in online platforms which constitute claims\nneeding verification, followed by (ii) the verification process of those\nclaims. This survey focuses on the former, by discussing existing efforts\ntowards detecting claims needing fact-checking, with a particular focus on\nmultilingual data and methods. This is a challenging and fertile direction\nwhere existing methods are yet far from matching human performance due to the\nprofoundly challenging nature of the issue. Especially, the dissemination of\ninformation across multiple social platforms, articulated in multiple languages\nand modalities demands more generalized solutions for combating misinformation.\nFocusing on multilingual misinformation, we present a comprehensive survey of\nexisting multilingual claim detection research. We present state-of-the-art\nmultilingual claim detection research categorized into three key factors of the\nproblem, verifiability, priority, and similarity. Further, we present a\ndetailed overview of the existing multilingual datasets along with the\nchallenges and suggest possible future advancements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Panchendrarajan_R/0/1/0/all/0/1\">Rrubaa Panchendrarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Unsupervised and Supervised Training for Automatic Speech Recognition via Bilevel Optimization. (arXiv:2401.06980v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2401.06980","description":"<p>In this paper, we present a novel bilevel optimization-based training\napproach to training acoustic models for automatic speech recognition (ASR)\ntasks that we term {bi-level joint unsupervised and supervised training\n(BL-JUST)}. {BL-JUST employs a lower and upper level optimization with an\nunsupervised loss and a supervised loss respectively, leveraging recent\nadvances in penalty-based bilevel optimization to solve this challenging ASR\nproblem with affordable complexity and rigorous convergence guarantees.} To\nevaluate BL-JUST, extensive experiments on the LibriSpeech and TED-LIUM v2\ndatasets have been conducted. BL-JUST achieves superior performance over the\ncommonly used pre-training followed by fine-tuning strategy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saif_A/0/1/0/all/0/1\">A F M Saif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_X/0/1/0/all/0/1\">Xiaodong Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Han Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Songtao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1\">Brian Kingsbury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-23T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}