{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-11-07T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"ITEm: Unsupervised Image-Text Embedding Learning for eCommerce. (arXiv:2311.02084v1 [cs.CV])","link":"http://arxiv.org/abs/2311.02084","description":"<p>Product embedding serves as a cornerstone for a wide range of applications in\neCommerce. The product embedding learned from multiple modalities shows\nsignificant improvement over that from a single modality, since different\nmodalities provide complementary information. However, some modalities are more\ninformatively dominant than others. How to teach a model to learn embedding\nfrom different modalities without neglecting information from the less dominant\nmodality is challenging. We present an image-text embedding model (ITEm), an\nunsupervised learning method that is designed to better attend to image and\ntext modalities. We extend BERT by (1) learning an embedding from text and\nimage without knowing the regions of interest; (2) training a global\nrepresentation to predict masked words and to construct masked image patches\nwithout their individual representations. We evaluate the pre-trained ITEm on\ntwo tasks: the search for extremely similar products and the prediction of\nproduct categories, showing substantial gains compared to strong baseline\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozielski_M/0/1/0/all/0/1\">Michael Kozielski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewavitharana_S/0/1/0/all/0/1\">Sanjika Hewavitharana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jiangbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lancewicki_T/0/1/0/all/0/1\">Tomer Lancewicki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LlamaRec: Two-Stage Recommendation using Large Language Models for Ranking. (arXiv:2311.02089v1 [cs.IR])","link":"http://arxiv.org/abs/2311.02089","description":"<p>Recently, large language models (LLMs) have exhibited significant progress in\nlanguage understanding and generation. By leveraging textual features,\ncustomized LLMs are also applied for recommendation and demonstrate\nimprovements across diverse recommendation scenarios. Yet the majority of\nexisting methods perform training-free recommendation that heavily relies on\npretrained knowledge (e.g., movie recommendation). In addition, inference on\nLLMs is slow due to autoregressive generation, rendering existing methods less\neffective for real-time recommendation. As such, we propose a two-stage\nframework using large language models for ranking-based recommendation\n(LlamaRec). In particular, we use small-scale sequential recommenders to\nretrieve candidates based on the user interaction history. Then, both history\nand retrieved items are fed to the LLM in text via a carefully designed prompt\ntemplate. Instead of generating next-item titles, we adopt a verbalizer-based\napproach that transforms output logits into probability distributions over the\ncandidate items. Therefore, the proposed LlamaRec can efficiently rank items\nwithout generating long text. To validate the effectiveness of the proposed\nframework, we compare against state-of-the-art baseline methods on benchmark\ndatasets. Our experimental results demonstrate the performance of LlamaRec,\nwhich consistently achieves superior performance in both recommendation\nperformance and efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1\">Zhenrui Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabhi_S/0/1/0/all/0/1\">Sara Rabhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moreira_G/0/1/0/all/0/1\">Gabriel de Souza Pereira Moreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oldridge_E/0/1/0/all/0/1\">Even Oldridge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automating Governing Knowledge Commons and Contextual Integrity (GKC-CI) Privacy Policy Annotations with Large Language Models. (arXiv:2311.02192v1 [cs.CY])","link":"http://arxiv.org/abs/2311.02192","description":"<p>Identifying contextual integrity (CI) and governing knowledge commons (GKC)\nparameters in privacy policy texts can facilitate normative privacy analysis.\nHowever, GKC-CI annotation has heretofore required manual or crowdsourced\neffort. This paper demonstrates that high-accuracy GKC-CI parameter annotation\nof privacy policies can be performed automatically using large language models.\nWe fine-tune 18 open-source and proprietary models on 21,588 GKC-CI annotations\nfrom 16 ground truth privacy policies. Our best-performing model (fine-tuned\nGPT-3.5 Turbo with prompt engineering) has an accuracy of 86%, exceeding the\nperformance of prior crowdsourcing approaches despite the complexity of privacy\npolicy texts and the nuance of the GKC-CI annotation task. We apply our\nbest-performing model to privacy policies from 164 popular online services,\ndemonstrating the effectiveness of scaling GKC-CI annotation for data\nexploration. We make all annotated policies as well as the training data and\nscripts needed to fine-tune our best-performing model publicly available for\nfuture research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chanenson_J/0/1/0/all/0/1\">Jake Chanenson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pickering_M/0/1/0/all/0/1\">Madison Pickering</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apthorpe_N/0/1/0/all/0/1\">Noah Apthorpe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Introduction to Natural Language Processing Techniques and Framework for Clinical Implementation in Radiation Oncology. (arXiv:2311.02205v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02205","description":"<p>Natural Language Processing (NLP) is a key technique for developing Medical\nArtificial Intelligence (AI) systems that leverage Electronic Health Record\n(EHR) data to build diagnostic and prognostic models. NLP enables the\nconversion of unstructured clinical text into structured data that can be fed\ninto AI algorithms. The emergence of the transformer architecture and large\nlanguage models (LLMs) has led to remarkable advances in NLP for various\nhealthcare tasks, such as entity recognition, relation extraction, sentence\nsimilarity, text summarization, and question answering. In this article, we\nreview the major technical innovations that underpin modern NLP models and\npresent state-of-the-art NLP applications that employ LLMs in radiation\noncology research. However, these LLMs are prone to many errors such as\nhallucinations, biases, and ethical violations, which necessitate rigorous\nevaluation and validation before clinical deployment. As such, we propose a\ncomprehensive framework for assessing the NLP models based on their purpose and\nclinical fit, technical performance, bias and trust, legal and ethical\nimplications, and quality assurance, prior to implementation in clinical\nradiation oncology. Our article aims to provide guidance and insights for\nresearchers and clinicians who are interested in developing and using NLP\nmodels in clinical radiation oncology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khanmohammadi_R/0/1/0/all/0/1\">Reza Khanmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Mohammad M. Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verdecchia_K/0/1/0/all/0/1\">Kyle Verdecchia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_A/0/1/0/all/0/1\">Ahmed I. Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Luo Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chetty_I/0/1/0/all/0/1\">Indrin J. Chetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagher_Ebadian_H/0/1/0/all/0/1\">Hassan Bagher-Ebadian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiqui_F/0/1/0/all/0/1\">Farzan Siddiqui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elshaikh_M/0/1/0/all/0/1\">Mohamed Elshaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Movsas_B/0/1/0/all/0/1\">Benjamin Movsas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thind_K/0/1/0/all/0/1\">Kundan Thind</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data. (arXiv:2311.02216v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02216","description":"<p>Numbers are crucial for various real-world domains such as finance,\neconomics, and science. Thus, understanding and reasoning with numbers are\nessential skills for language models to solve different tasks. While different\nnumerical benchmarks have been introduced in recent years, they are limited to\nspecific numerical aspects mostly. In this paper, we propose a hierarchical\ntaxonomy for numerical reasoning skills with more than ten reasoning types\nacross four levels: representation, number sense, manipulation, and complex\nreasoning. We conduct a comprehensive evaluation of state-of-the-art models to\nidentify reasoning challenges specific to them. Henceforth, we develop a\ndiverse set of numerical probes employing a semi-automated approach. We focus\non the tabular Natural Language Inference (TNLI) task as a case study and\nmeasure models' performance shifts. Our results show that no model consistently\nexcels across all numerical reasoning types. Among the probed models, FlanT5\n(few-/zero-shot) and GPT-3.5 (few-shot) demonstrate strong overall numerical\nreasoning skills compared to other models. Label-flipping probes indicate that\nmodels often exploit dataset artifacts to predict the correct labels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Mubashara Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shankarampeta_A/0/1/0/all/0/1\">Abhilash Shankarampeta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vivek Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patil_A/0/1/0/all/0/1\">Arpit Patil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cocarascu_O/0/1/0/all/0/1\">Oana Cocarascu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simperl_E/0/1/0/all/0/1\">Elena Simperl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Fine-Tuning of Vision-Language Models for Domain Generalization. (arXiv:2311.02236v1 [cs.CV])","link":"http://arxiv.org/abs/2311.02236","description":"<p>Transfer learning enables the sharing of common knowledge among models for a\nvariety of downstream tasks, but traditional methods suffer in limited training\ndata settings and produce narrow models incapable of effectively generalizing\nunder distribution shifts. Foundation models have recently demonstrated\nimpressive zero-shot inference capabilities and robustness under distribution\nshifts. However, zero-shot evaluation for these models has been predominantly\nconfined to benchmarks with simple distribution shifts, limiting our\nunderstanding of their effectiveness under the more realistic shifts found in\npractice. Moreover, common fine-tuning methods for these models have yet to be\nevaluated against vision models in few-shot scenarios where training data is\nlimited. To address these gaps, we present a new recipe for few-shot\nfine-tuning of the popular vision-language foundation model CLIP and evaluate\nits performance on challenging benchmark datasets with realistic distribution\nshifts from the WILDS collection. Our experimentation demonstrates that, while\nzero-shot CLIP fails to match performance of trained vision models on more\ncomplex benchmarks, few-shot CLIP fine-tuning outperforms its vision-only\ncounterparts in terms of in-distribution and out-of-distribution accuracy at\nall levels of training data availability. This provides a strong incentive for\nadoption of foundation models within few-shot learning applications operating\nwith real-world data. Code is available at\nhttps://github.com/mit-ll/robust-vision-language-finetuning\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vogt_Lowell_K/0/1/0/all/0/1\">Kevin Vogt-Lowell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Noah Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiligkaridis_T/0/1/0/all/0/1\">Theodoros Tsiligkaridis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaillant_M/0/1/0/all/0/1\">Marc Vaillant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning. (arXiv:2311.02248v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02248","description":"<p>We present a data and cost efficient way of incorporating the speech modality\ninto a large language model (LLM). The resulting multi-modal LLM is a\nCOntextual Speech Model with Instruction-following/in-context-learning\nCapabilities - COSMIC. Speech comprehension test question-answer (SQA) pairs\nare generated using GPT-3.5 based on the speech transcriptions as a part of the\nsupervision for the instruction tuning. With fewer than 20M trainable\nparameters and as little as 450 hours of English speech data for SQA\ngeneration, COSMIC exhibits emergent instruction-following and in-context\nlearning capabilities in speech-to-text tasks. The model is able to follow the\ngiven text instructions to generate text response even on the unseen EN$\\to$X\nspeech-to-text translation (S2TT) task with zero-shot setting. We evaluate the\nmodel's in-context learning via various tasks such as EN$\\to$X S2TT and\nfew-shot domain adaptation. And instruction-following capabilities are\nevaluated through a contextual biasing benchmark. Our results demonstrate the\nefficacy of the proposed low cost recipe for building a speech LLM and that\nwith the new instruction-tuning data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_Y/0/1/0/all/0/1\">Yashesh Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivasankaran_S/0/1/0/all/0/1\">Sunit Sivasankaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs. (arXiv:2311.02262v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02262","description":"<p>In human-written articles, we often leverage the subtleties of text style,\nsuch as bold and italics, to guide the attention of readers. These textual\nemphases are vital for the readers to grasp the conveyed information. When\ninteracting with large language models (LLMs), we have a similar need -\nsteering the model to pay closer attention to user-specified information, e.g.,\nan instruction. Existing methods, however, are constrained to process plain\ntext and do not support such a mechanism. This motivates us to introduce PASTA\n- Post-hoc Attention STeering Approach, a method that allows LLMs to read text\nwith user-specified emphasis marks. To this end, PASTA identifies a small\nsubset of attention heads and applies precise attention reweighting on them,\ndirecting the model attention to user-specified parts. Like prompting, PASTA is\napplied at inference time and does not require changing any model parameters.\nExperiments demonstrate that PASTA can substantially enhance an LLM's ability\nto follow user instructions or integrate new knowledge from user inputs,\nleading to a significant performance improvement on a variety of tasks, e.g.,\nan average accuracy improvement of 22% for LLAMA-7B. Our code is publicly\navailable at https://github.com/QingruZhang/PASTA .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1\">Chandan Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not all layers are equally as important: Every Layer Counts BERT. (arXiv:2311.02265v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02265","description":"<p>This paper introduces a novel modification of the transformer architecture,\ntailored for the data-efficient pretraining of language models. This aspect is\nevaluated by participating in the BabyLM challenge, where our solution won both\nthe \\textsc{strict} and \\textsc{strict-small} tracks. Our approach allows each\ntransformer layer to select which outputs of previous layers to process. The\nempirical results verify the potential of this simple modification and show\nthat not all layers are equally as important.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Charpentier_L/0/1/0/all/0/1\">Lucas Georges Gabriel Charpentier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samuel_D/0/1/0/all/0/1\">David Samuel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization. (arXiv:2311.02271v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02271","description":"<p>Summaries of medical text shall be faithful by being consistent and factual\nwith source inputs, which is an important but understudied topic for safety and\nefficiency in healthcare. In this paper, we investigate and improve\nfaithfulness in summarization on a broad range of medical summarization tasks.\nOur investigation reveals that current summarization models often produce\nunfaithful outputs for medical input text. We then introduce FAMESUMM, a\nframework to improve faithfulness by fine-tuning pre-trained language models\nbased on medical knowledge. FAMESUMM performs contrastive learning on designed\nsets of faithful and unfaithful summaries, and it incorporates medical terms\nand their contexts to encourage faithful generation of medical terms. We\nconduct comprehensive experiments on three datasets in two languages: health\nquestion and radiology report summarization datasets in English, and a\npatient-doctor dialogue dataset in Chinese. Results demonstrate that FAMESUMM\nis flexible and effective by delivering consistent improvements over mainstream\nlanguage models such as BART, T5, mT5, and PEGASUS, yielding state-of-the-art\nperformances on metrics for faithfulness and general quality. Human evaluation\nby doctors also shows that FAMESUMM generates more faithful outputs. Our code\nis available at https: //github.com/psunlpgroup/FaMeSumm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Nan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yusen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_P/0/1/0/all/0/1\">Prasenjit Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs grasp morality in concept. (arXiv:2311.02294v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02294","description":"<p>Work in AI ethics and fairness has made much progress in regulating LLMs to\nreflect certain values, such as fairness, truth, and diversity. However, it has\ntaken the problem of how LLMs might 'mean' anything at all for granted. Without\naddressing this, it is not clear what imbuing LLMs with such values even means.\nIn response, we provide a general theory of meaning that extends beyond humans.\nWe use this theory to explicate the precise nature of LLMs as meaning-agents.\nWe suggest that the LLM, by virtue of its position as a meaning-agent, already\ngrasps the constructions of human society (e.g. morality, gender, and race) in\nconcept. Consequently, under certain ethical frameworks, currently popular\nmethods for model alignment are limited at best and counterproductive at worst.\nMoreover, unaligned models may help us better develop our moral and social\nphilosophy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pock_M/0/1/0/all/0/1\">Mark Pock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_A/0/1/0/all/0/1\">Andre Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1\">Jared Moore</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Narrowing the Gap between Zero- and Few-shot Machine Translation by Matching Styles. (arXiv:2311.02310v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02310","description":"<p>Large language models trained primarily in a monolingual setting have\ndemonstrated their ability to generalize to machine translation using zero- and\nfew-shot examples with in-context learning. However, even though zero-shot\ntranslations are relatively good, there remains a discernible gap comparing\ntheir performance with the few-shot setting. In this paper, we investigate the\nfactors contributing to this gap and find that this gap can largely be closed\n(for about 70%) by matching the writing styles of the target corpus.\nAdditionally, we explore potential approaches to enhance zero-shot baselines\nwithout the need for parallel demonstration examples, providing valuable\ninsights into how these methods contribute to improving translation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weiting Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuyue Stella Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1\">Kenton Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying Context-Dependent Translations for Evaluation Set Production. (arXiv:2311.02321v1 [cs.CL])","link":"http://arxiv.org/abs/2311.02321","description":"<p>A major impediment to the transition to context-aware machine translation is\nthe absence of good evaluation metrics and test sets. Sentences that require\ncontext to be translated correctly are rare in test sets, reducing the utility\nof standard corpus-level metrics such as COMET or BLEU. On the other hand,\ndatasets that annotate such sentences are also rare, small in scale, and\navailable for only a few languages. To address this, we modernize, generalize,\nand extend previous annotation pipelines to produce CTXPRO, a tool that\nidentifies subsets of parallel documents containing sentences that require\ncontext to correctly translate five phenomena: gender, formality, and animacy\nfor pronouns, verb phrase ellipsis, and ambiguous noun inflections. The input\nto the pipeline is a set of hand-crafted, per-language, linguistically-informed\nrules that select contextual sentence pairs using coreference, part-of-speech,\nand morphological features provided by state-of-the-art tools. We apply this\npipeline to seven languages pairs (EN into and out-of DE, ES, FR, IT, PL, PT,\nand RU) and two datasets (OpenSubtitles and WMT test sets), and validate its\nperformance using both overlap with previous work and its ability to\ndiscriminate a contextual MT system from a sentence-based one. We release the\nCTXPRO pipeline and data as open source.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wicks_R/0/1/0/all/0/1\">Rachel Wicks</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1\">Matt Post</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ProtoryNet - Interpretable Text Classification Via Prototype Trajectories. (arXiv:2007.01777v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2007.01777","description":"<p>We propose a novel interpretable deep neural network for text classification,\ncalled ProtoryNet, based on a new concept of prototype trajectories. Motivated\nby the prototype theory in modern linguistics, ProtoryNet makes a prediction by\nfinding the most similar prototype for each sentence in a text sequence and\nfeeding an RNN backbone with the proximity of each sentence to the\ncorresponding active prototype. The RNN backbone then captures the temporal\npattern of the prototypes, which we refer to as prototype trajectories.\nPrototype trajectories enable intuitive and fine-grained interpretation of the\nreasoning process of the RNN model, in resemblance to how humans analyze texts.\nWe also design a prototype pruning procedure to reduce the total number of\nprototypes used by the model for better interpretability. Experiments on\nmultiple public data sets show that ProtoryNet is more accurate than the\nbaseline prototype-based deep neural net and reduces the performance gap\ncompared to state-of-the-art black-box models. In addition, after prototype\npruning, the resulting ProtoryNet models only need less than or around 20\nprototypes for all datasets, which significantly benefits interpretability.\nFurthermore, we report a survey result indicating that human users find\nProtoryNet more intuitive and easier to understand than other prototype-based\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Dat Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1\">Stephen S. Baek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Composable Text Controls in Latent Space with ODEs. (arXiv:2208.00638v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.00638","description":"<p>Real-world text applications often involve composing a wide range of text\ncontrol operations, such as editing the text w.r.t. an attribute, manipulating\nkeywords and structure, and generating new text of desired properties. Prior\nwork typically learns/finetunes a language model (LM) to perform individual or\nspecific subsets of operations. Recent research has studied combining\noperations in a plug-and-play manner, often with costly search or optimization\nin the complex sequence space. This paper proposes a new efficient approach for\ncomposable text operations in the compact latent space of text. The\nlow-dimensionality and differentiability of the text latent vector allow us to\ndevelop an efficient sampler based on ordinary differential equations (ODEs)\ngiven arbitrary plug-in operators (e.g., attribute classifiers). By connecting\npretrained LMs (e.g., GPT2) to the latent space through efficient adaption, we\nthen decode the sampled vectors into desired text sequences. The flexible\napproach permits diverse control operators (sentiment, tense, formality,\nkeywords, etc.) acquired using any relevant data from different domains.\nExperiments show that composing those operators within our approach manages to\ngenerate or edit high-quality text, substantially improving over previous\nmethods in terms of generation quality and efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guangyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zeyu Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yuan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1\">Junwei Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Theory of Unsupervised Translation Motivated by Understanding Animal Communication. (arXiv:2211.11081v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11081","description":"<p>Neural networks are capable of translating between languages -- in some cases\neven between two languages where there is little or no access to parallel\ntranslations, in what is known as Unsupervised Machine Translation (UMT). Given\nthis progress, it is intriguing to ask whether machine learning tools can\nultimately enable understanding animal communication, particularly that of\nhighly intelligent animals. We propose a theoretical framework for analyzing\nUMT when no parallel translations are available and when it cannot be assumed\nthat the source and target corpora address related subject domains or posses\nsimilar linguistic structure. We exemplify this theory with two stylized models\nof language, for which our framework provides bounds on necessary sample\ncomplexity; the bounds are formally proven and experimentally verified on\nsynthetic data. These bounds show that the error rates are inversely related to\nthe language complexity and amount of common ground. This suggests that\nunsupervised translation of animal communication may be feasible if the\ncommunication system is sufficiently complex.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_S/0/1/0/all/0/1\">Shafi Goldwasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruber_D/0/1/0/all/0/1\">David F. Gruber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paradise_O/0/1/0/all/0/1\">Orr Paradise</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CiteBench: A benchmark for Scientific Citation Text Generation. (arXiv:2212.09577v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09577","description":"<p>Science progresses by building upon the prior body of knowledge documented in\nscientific publications. The acceleration of research makes it hard to stay\nup-to-date with the recent developments and to summarize the ever-growing body\nof prior work. To address this, the task of citation text generation aims to\nproduce accurate textual summaries given a set of papers-to-cite and the citing\npaper context. Due to otherwise rare explicit anchoring of cited documents in\nthe citing paper, citation text generation provides an excellent opportunity to\nstudy how humans aggregate and synthesize textual knowledge from sources. Yet,\nexisting studies are based upon widely diverging task definitions, which makes\nit hard to study this task systematically. To address this challenge, we\npropose CiteBench: a benchmark for citation text generation that unifies\nmultiple diverse datasets and enables standardized evaluation of citation text\ngeneration models across task designs and domains. Using the new benchmark, we\ninvestigate the performance of multiple strong baselines, test their\ntransferability between the datasets, and deliver new insights into the task\ndefinition and evaluation to guide future research in citation text generation.\nWe make the code for CiteBench publicly available at\nhttps://github.com/UKPLab/citebench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Funkquist_M/0/1/0/all/0/1\">Martin Funkquist</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznetsov_I/0/1/0/all/0/1\">Ilia Kuznetsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yufang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dissociating language and thought in large language models. (arXiv:2301.06627v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.06627","description":"<p>Large language models (LLMs) have come closest among all models to date to\nmastering human language, yet opinions about their linguistic and cognitive\ncapabilities remain split. Here, we evaluate LLMs using a distinction between\nformal linguistic competence--knowledge of linguistic rules and patterns--and\nfunctional linguistic competence--understanding and using language in the\nworld. We ground this distinction in human neuroscience, showing that formal\nand functional competence rely on different neural mechanisms. Although LLMs\nare surprisingly good at formal competence, their performance on functional\ncompetence tasks remains spotty and often requires specialized fine-tuning\nand/or coupling with external modules. In short, LLMs are good models of\nlanguage but incomplete models of human thought.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanova_A/0/1/0/all/0/1\">Anna A. Ivanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blank_I/0/1/0/all/0/1\">Idan A. Blank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanwisher_N/0/1/0/all/0/1\">Nancy Kanwisher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fedorenko_E/0/1/0/all/0/1\">Evelina Fedorenko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Neuron Interpretation Methods of NLP Models. (arXiv:2301.12608v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12608","description":"<p>Neuron Interpretation has gained traction in the field of interpretability,\nand have provided fine-grained insights into what a model learns and how\nlanguage knowledge is distributed amongst its different components. However,\nthe lack of evaluation benchmark and metrics have led to siloed progress within\nthese various methods, with very little work comparing them and highlighting\ntheir strengths and weaknesses. The reason for this discrepancy is the\ndifficulty of creating ground truth datasets, for example, many neurons within\na given model may learn the same phenomena, and hence there may not be one\ncorrect answer. Moreover, a learned phenomenon may spread across several\nneurons that work together -- surfacing these to create a gold standard\nchallenging. In this work, we propose an evaluation framework that measures the\ncompatibility of a neuron analysis method with other methods. We hypothesize\nthat the more compatible a method is with the majority of the methods, the more\nconfident one can be about its performance. We systematically evaluate our\nproposed framework and present a comparative analysis of a large set of neuron\ninterpretation methods. We make the evaluation framework available to the\ncommunity. It enables the evaluation of any new method using 20 concepts and\nacross three pre-trained models.The code is released at\nhttps://github.com/fdalvi/neuron-comparative-analysis\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yimin Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1\">Hassan Sajjad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages. (arXiv:2302.08956v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08956","description":"<p>Africa is home to over 2,000 languages from more than six language families\nand has the highest linguistic diversity among all continents. These include 75\nlanguages with at least one million speakers each. Yet, there is little NLP\nresearch conducted on African languages. Crucial to enabling such research is\nthe availability of high-quality annotated datasets. In this paper, we\nintroduce AfriSenti, a sentiment analysis benchmark that contains a total of\n&gt;110,000 tweets in 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo,\nKinyarwanda, Moroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo,\nSwahili, Tigrinya, Twi, Xitsonga, and Yor\\`ub\\'a) from four language families.\nThe tweets were annotated by native speakers and used in the AfriSenti-SemEval\nshared task (The AfriSenti Shared Task had over 200 participants. See website\nat https://afrisenti-semeval.github.io). We describe the data collection\nmethodology, annotation process, and the challenges we dealt with when curating\neach dataset. We further report baseline experiments conducted on the different\ndatasets and discuss their usefulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shamsuddeen Hassan Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulmumin_I/0/1/0/all/0/1\">Idris Abdulmumin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayele_A/0/1/0/all/0/1\">Abinew Ali Ayele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ousidhoum_N/0/1/0/all/0/1\">Nedjma Ousidhoum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yimam_S/0/1/0/all/0/1\">Seid Muhie Yimam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ibrahim Sa&#x27;id Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beloucif_M/0/1/0/all/0/1\">Meriem Beloucif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hourrane_O/0/1/0/all/0/1\">Oumaima Hourrane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brazdil_P/0/1/0/all/0/1\">Pavel Brazdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_F/0/1/0/all/0/1\">Felermino D&#xe1;rio M&#xe1;rio Ant&#xf3;nio Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_D/0/1/0/all/0/1\">Davis David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1\">Salomey Osei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_B/0/1/0/all/0/1\">Bello Shehu Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_F/0/1/0/all/0/1\">Falalu Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gwadabe_T/0/1/0/all/0/1\">Tajuddeen Gwadabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutunda_S/0/1/0/all/0/1\">Samuel Rutunda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belay_T/0/1/0/all/0/1\">Tadesse Belay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messelle_W/0/1/0/all/0/1\">Wendimu Baye Messelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balcha_H/0/1/0/all/0/1\">Hailu Beshada Balcha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chala_S/0/1/0/all/0/1\">Sisay Adugna Chala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gebremichael_H/0/1/0/all/0/1\">Hagos Tesfahun Gebremichael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opoku_B/0/1/0/all/0/1\">Bernard Opoku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_S/0/1/0/all/0/1\">Steven Arthur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"xCodeEval: A Large Scale Multilingual Multitask Benchmark for Code Understanding, Generation, Translation and Retrieval. (arXiv:2303.03004v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.03004","description":"<p>Recently, pre-trained large language models (LLMs) have shown impressive\nabilities in generating codes from natural language descriptions, repairing\nbuggy codes, translating codes between languages, and retrieving relevant code\nsegments. However, the evaluation of these models has often been performed in a\nscattered way on only one or two specific tasks, in a few languages, at a\npartial granularity (e.g., function) level, and in many cases without proper\ntraining data. Even more concerning is that in most cases the evaluation of\ngenerated codes has been done in terms of mere lexical overlap with a reference\ncode rather than actual execution. We introduce xCodeEval, the largest\nexecutable multilingual multitask benchmark to date consisting of $25$M\ndocument-level coding examples ($16.5$B tokens) from about $7.5$K unique\nproblems covering up to $11$ programming languages with execution-level\nparallelism. It features a total of $7$ tasks involving code understanding,\ngeneration, translation and retrieval. xCodeEval adopts an execution-based\nevaluation and offers a multilingual code execution engine, ExecEval that\nsupports unit test based execution in all the $11$ languages. To address the\nchallenge of balancing the distributions of text-code samples over multiple\nattributes in validation/test sets, we propose a novel data splitting and a\ndata selection schema based on the geometric mean and graph-theoretic\nprinciple. Our experiments with OpenAI's LLMs (zero-shot) and open-LLMs\n(zero-shot and fine-tuned) on the tasks and languages demonstrate **xCodeEval**\nto be quite challenging as per the current advancements in language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Abdullah Matin Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bari_M/0/1/0/all/0/1\">M Saiful Bari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_X/0/1/0/all/0/1\">Xuan Long Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weishi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parvez_M/0/1/0/all/0/1\">Md Rizwan Parvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can an Embodied Agent Find Your \"Cat-shaped Mug\"? LLM-Guided Exploration for Zero-Shot Object Navigation. (arXiv:2303.03480v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2303.03480","description":"<p>We present LGX (Language-guided Exploration), a novel algorithm for\nLanguage-Driven Zero-Shot Object Goal Navigation (L-ZSON), where an embodied\nagent navigates to a uniquely described target object in a previously unseen\nenvironment. Our approach makes use of Large Language Models (LLMs) for this\ntask by leveraging the LLM's commonsense reasoning capabilities for making\nsequential navigational decisions. Simultaneously, we perform generalized\ntarget object detection using a pre-trained Vision-Language grounding model. We\nachieve state-of-the-art zero-shot object navigation results on RoboTHOR with a\nsuccess rate (SR) improvement of over 27% over the current baseline of the\nOWL-ViT CLIP on Wheels (OWL CoW). Furthermore, we study the usage of LLMs for\nrobot navigation and present an analysis of various prompting strategies\naffecting the model output. Finally, we showcase the benefits of our approach\nvia \\textit{real-world} experiments that indicate the superior performance of\nLGX in detecting and navigating to visually unique objects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dorbala_V/0/1/0/all/0/1\">Vishnu Sashank Dorbala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullen_J/0/1/0/all/0/1\">James F. Mullen Jr.</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1\">Dinesh Manocha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining on Visual Language Understanding. (arXiv:2303.12513v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2303.12513","description":"<p>Most humans use visual imagination to understand and reason about language,\nbut models such as BERT reason about language using knowledge acquired during\ntext-only pretraining. In this work, we investigate whether vision-and-language\npretraining can improve performance on text-only tasks that involve implicit\nvisual reasoning, focusing primarily on zero-shot probing methods. We propose a\nsuite of visual language understanding (VLU) tasks for probing the visual\nreasoning abilities of text encoder models, as well as various non-visual\nnatural language understanding (NLU) tasks for comparison. We also contribute a\nnovel zero-shot knowledge probing method, Stroop probing, for applying models\nsuch as CLIP to text-only tasks without needing a prediction head such as the\nmasked language modelling head of models like BERT. We show that SOTA\nmultimodally trained text encoders outperform unimodally trained text encoders\non the VLU tasks while being underperformed by them on the NLU tasks, lending\nnew context to previously mixed results regarding the NLU capabilities of\nmultimodal models. We conclude that exposure to images during pretraining\naffords inherent visual reasoning knowledge that is reflected in language-only\ntasks that require implicit visual reasoning. Our findings bear importance in\nthe broader context of multimodal learning, providing principled guidelines for\nthe choice of text encoders used in such contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alper_M/0/1/0/all/0/1\">Morris Alper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fiman_M/0/1/0/all/0/1\">Michael Fiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1\">Hadar Averbuch-Elor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentiment Analysis Dataset in Moroccan Dialect: Bridging the Gap Between Arabic and Latin Scripted dialect. (arXiv:2303.15987v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.15987","description":"<p>Sentiment analysis, the automated process of determining emotions or opinions\nexpressed in text, has seen extensive exploration in the field of natural\nlanguage processing. However, one aspect that has remained underrepresented is\nthe sentiment analysis of the Moroccan dialect, which boasts a unique\nlinguistic landscape and the coexistence of multiple scripts. Previous works in\nsentiment analysis primarily targeted dialects employing Arabic script. While\nthese efforts provided valuable insights, they may not fully capture the\ncomplexity of Moroccan web content, which features a blend of Arabic and Latin\nscript. As a result, our study emphasizes the importance of extending sentiment\nanalysis to encompass the entire spectrum of Moroccan linguistic diversity.\nCentral to our research is the creation of the largest public dataset for\nMoroccan dialect sentiment analysis that incorporates not only Moroccan dialect\nwritten in Arabic script but also in Latin letters. By assembling a diverse\nrange of textual data, we were able to construct a dataset with a range of 20\n000 manually labeled text in Moroccan dialect and also publicly available lists\nof stop words in Moroccan dialect. To dive into sentiment analysis, we\nconducted a comparative study on multiple Machine learning models to assess\ntheir compatibility with our dataset. Experiments were performed using both raw\nand preprocessed data to show the importance of the preprocessing step. We were\nable to achieve 92% accuracy in our model and to further prove its liability we\ntested our model on smaller publicly available datasets of Moroccan dialect and\nthe results were favorable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jbel_M/0/1/0/all/0/1\">Mouad Jbel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hafidi_I/0/1/0/all/0/1\">Imad Hafidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metrane_A/0/1/0/all/0/1\">Abdulmutallib Metrane</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Safety Analysis in the Era of Large Language Models: A Case Study of STPA using ChatGPT. (arXiv:2304.01246v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01246","description":"<p>Can safety analysis make use of Large Language Models (LLMs)? A case study\nexplores Systems Theoretic Process Analysis (STPA) applied to Automatic\nEmergency Brake (AEB) and Electricity Demand Side Management (DSM) systems\nusing ChatGPT. We investigate how collaboration schemes, input semantic\ncomplexity, and prompt guidelines influence STPA results. Comparative results\nshow that using ChatGPT without human intervention may be inadequate due to\nreliability related issues, but with careful design, it may outperform human\nexperts. No statistically significant differences are found when varying the\ninput semantic complexity or using common prompt guidelines, which suggests the\nnecessity for developing domain-specific prompt engineering. We also highlight\nfuture challenges, including concerns about LLM trustworthiness and the\nnecessity for standardisation and regulation in this domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1\">Yi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xingyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khastgir_S/0/1/0/all/0/1\">Siddartha Khastgir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaowei Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Approximating CKY with Transformers. (arXiv:2305.02386v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02386","description":"<p>We investigate the ability of transformer models to approximate the CKY\nalgorithm, using them to directly predict a sentence's parse and thus avoid the\nCKY algorithm's cubic dependence on sentence length. We find that on standard\nconstituency parsing benchmarks this approach achieves competitive or better\nperformance than comparable parsers that make use of CKY, while being faster.\nWe also evaluate the viability of this approach for parsing under\n\\textit{random} PCFGs. Here we find that performance declines as the grammar\nbecomes more ambiguous, suggesting that the transformer is not fully capturing\nthe CKY computation. However, we also find that incorporating additional\ninductive bias is helpful, and we propose a novel approach that makes use of\ngradients with respect to chart representations in predicting the parse, in\nanalogy with the CKY algorithm being a subgradient of a partition function\nvariant with respect to the chart.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalighinejad_G/0/1/0/all/0/1\">Ghazal Khalighinejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_O/0/1/0/all/0/1\">Ollie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiseman_S/0/1/0/all/0/1\">Sam Wiseman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Space Grounded Weighted Decoding for Multi-Attribute Controllable Dialogue Generation. (arXiv:2305.02820v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02820","description":"<p>Controlling chatbot utterance generation with multiple attributes such as\npersonalities, emotions and dialogue acts is a practically useful but\nunder-studied problem. We propose a novel framework called DASC that possesses\nstrong controllability with a weighted decoding paradigm, while improving\ngeneration quality with the grounding in an attribute semantics space.\nGeneration with multiple attributes is then intuitively implemented with an\ninterpolation of multiple attribute embeddings, which results in substantial\nreduction in the model sizes. Experiments show that DASC can achieve high\ncontrol accuracy in generation task with the simultaneous control of 3 aspects\nwhile also producing interesting and reasonably sensible responses, even in an\nout-of-distribution robustness test.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiling Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mengyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RECKONING: Reasoning through Dynamic Knowledge Encoding. (arXiv:2305.06349v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06349","description":"<p>Recent studies on transformer-based language models show that they can answer\nquestions by reasoning over knowledge provided as part of the context (i.e.,\nin-context reasoning). However, since the available knowledge is often not\nfiltered for a particular question, in-context reasoning can be sensitive to\ndistractor facts, additional content that is irrelevant to a question but that\nmay be relevant for a different question (i.e., not necessarily random noise).\nIn these situations, the model fails to distinguish the knowledge that is\nnecessary to answer the question, leading to spurious reasoning and degraded\nperformance. This reasoning failure contrasts with the model's apparent ability\nto distinguish its contextual knowledge from all the knowledge it has memorized\nduring pre-training. Following this observation, we propose teaching the model\nto reason more robustly by folding the provided contextual knowledge into the\nmodel's parameters before presenting it with a question. Our method, RECKONING,\nis a bi-level learning algorithm that teaches language models to reason by\nupdating their parametric knowledge through back-propagation, allowing them to\nthen answer questions using the updated parameters. During training, the inner\nloop rapidly adapts a copy of the model weights to encode contextual knowledge\ninto its parameters. In the outer loop, the model learns to use the updated\nweights to reproduce and answer reasoning questions about the memorized\nknowledge. Our experiments on two multi-hop reasoning datasets show that\nRECKONING's performance improves over the in-context reasoning baseline (by up\nto 4.5%). We also find that compared to in-context reasoning, RECKONING\ngeneralizes better to longer reasoning chains unseen during training, is more\nrobust to distractors in the context, and is more computationally efficient\nwhen multiple questions are asked about the same knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1\">Eric Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. (arXiv:2305.08322v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08322","description":"<p>New NLP benchmarks are urgently needed to align with the rapid development of\nlarge language models (LLMs). We present C-Eval, the first comprehensive\nChinese evaluation suite designed to assess advanced knowledge and reasoning\nabilities of foundation models in a Chinese context. C-Eval comprises\nmultiple-choice questions across four difficulty levels: middle school, high\nschool, college, and professional. The questions span 52 diverse disciplines,\nranging from humanities to science and engineering. C-Eval is accompanied by\nC-Eval Hard, a subset of very challenging subjects in C-Eval that requires\nadvanced reasoning abilities to solve. We conduct a comprehensive evaluation of\nthe most advanced LLMs on C-Eval, including both English- and Chinese-oriented\nmodels. Results indicate that only GPT-4 could achieve an average accuracy of\nover 60%, suggesting that there is still significant room for improvement for\ncurrent LLMs. We anticipate C-Eval will help analyze important strengths and\nshortcomings of foundation models, and foster their development and growth for\nChinese users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuzhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuzhuo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zhihao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junlei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_T/0/1/0/all/0/1\">Tangjun Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junteng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Chuancheng Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1\">Jiayi Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal Document-Grounded Dialogue Pre-training. (arXiv:2305.10927v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10927","description":"<p>The goal of document-grounded dialogue (DocGD) is to generate a response by\ngrounding the evidence in a supporting document in accordance with the dialogue\ncontext. This process involves four variables that are causally connected.\nRecently, task-specific pre-training has greatly boosted performances on many\ndownstream tasks. Existing DocGD methods, however, continue to rely on general\npre-trained language models without a specifically tailored pre-training\napproach that explicitly captures the causal relationships. To tackle this\nissue, we are the first to present a causally-complete dataset construction\nstrategy for building million-level DocGD pre-training corpora. To better\ncapture causality, we further propose a causally-perturbed pre-training\nstrategy, which introduces causal perturbations on the variables and optimizes\nthe overall causal effect. Experiments on three benchmark datasets demonstrate\nthat our causal pre-training achieves considerable and consistent improvements\nunder fully-supervised, low-resource, few-shot, and zero-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yingxiu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bowen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haiyang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bowen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Nevin L. Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continually Improving Extractive QA via Human Feedback. (arXiv:2305.12473v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12473","description":"<p>We study continually improving an extractive question answering (QA) system\nvia human user feedback. We design and deploy an iterative approach, where\ninformation-seeking users ask questions, receive model-predicted answers, and\nprovide feedback. We conduct experiments involving thousands of user\ninteractions under diverse setups to broaden the understanding of learning from\nfeedback over time. Our experiments show effective improvement from user\nfeedback of extractive QA models over time across different data regimes,\nincluding significant potential for domain adaptation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hung-Ting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let's Think Frame by Frame with VIP: A Video Infilling and Prediction Dataset for Evaluating Video Chain-of-Thought. (arXiv:2305.13903v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13903","description":"<p>Despite exciting recent results showing vision-language systems' capacity to\nreason about images using natural language, their capacity for video reasoning\nremains under-explored. We motivate framing video reasoning as the sequential\nunderstanding of a small number of keyframes, thereby leveraging the power and\nrobustness of vision-language while alleviating the computational complexities\nof processing videos. To evaluate this novel application, we introduce VIP, an\ninference-time challenge dataset designed to explore models' reasoning\ncapabilities through video chain-of-thought. Inspired by visually descriptive\nscene plays, we propose two formats for keyframe description: unstructured\ndense captions and structured scene descriptions that identify the focus,\naction, mood, objects, and setting (FAMOuS) of the keyframe. To evaluate video\nreasoning, we propose two tasks: Video Infilling and Video Prediction, which\ntest abilities to generate multiple intermediate keyframes and predict future\nkeyframes, respectively. We benchmark GPT-4, GPT-3, and VICUNA on VIP,\ndemonstrate the performance gap in these complex video reasoning tasks, and\nencourage future work to prioritize language models for efficient and\ngeneralized video reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Himakunthala_V/0/1/0/all/0/1\">Vaishnavi Himakunthala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_A/0/1/0/all/0/1\">Andy Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rose_D/0/1/0/all/0/1\">Daniel Rose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ryan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_A/0/1/0/all/0/1\">Alex Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonar_C/0/1/0/all/0/1\">Chinmay Sonar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata. (arXiv:2305.14202v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14202","description":"<p>While large language models (LLMs) can answer many questions correctly, they\ncan also hallucinate and give wrong answers. Wikidata, with its over 12 billion\nfacts, can be used to ground LLMs to improve their factuality. This paper\npresents WikiWebQuestions, a high-quality question answering benchmark for\nWikidata. Ported over from WebQuestions for Freebase, it consists of real-world\ndata with SPARQL annotation. This paper presents a few-shot\nsequence-to-sequence semantic parser for Wikidata. We modify SPARQL to use the\nunique domain and property names instead of their IDs. We train the parser to\nuse either the results from an entity linker or mentions in the query. We\nfine-tune LLaMA by adding the few-shot training data to that used to fine-tune\nAlpaca. Our experimental results demonstrate the effectiveness of this\nmethodology, establishing a strong baseline of 76% and 65% answer accuracy in\nthe dev and test sets of WikiWebQuestions, respectively. By pairing our\nsemantic parser with GPT-3, we combine verifiable results with qualified GPT-3\nguesses to provide useful answers to 96% of the questions in dev. We also show\nthat our method outperforms the state-of-the-art for the QALD-7 Wikidata\ndataset by 3.6% in F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Silei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Culhane_T/0/1/0/all/0/1\">Theo Culhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pertseva_E/0/1/0/all/0/1\">Elizaveta Pertseva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Meng-Hsi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semnani_S/0/1/0/all/0/1\">Sina J. Semnani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1\">Monica S. Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LIMIT: Language Identification, Misidentification, and Translation using Hierarchical Models in 350+ Languages. (arXiv:2305.14263v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14263","description":"<p>Knowing the language of an input text/audio is a necessary first step for\nusing almost every NLP tool such as taggers, parsers, or translation systems.\nLanguage identification is a well-studied problem, sometimes even considered\nsolved; in reality, due to lack of data and computational challenges, current\nsystems cannot accurately identify most of the world's 7000 languages. To\ntackle this bottleneck, we first compile a corpus, MCS-350, of 50K multilingual\nand parallel children's stories in 350+ languages. MCS-350 can serve as a\nbenchmark for language identification of short texts and for 1400+ new\ntranslation directions in low-resource Indian and African languages. Second, we\npropose a novel misprediction-resolution hierarchical model, LIMIt, for\nlanguage identification that reduces error by 55% (from 0.71 to 0.32) on our\ncompiled children's stories dataset and by 40% (from 0.23 to 0.14) on the\nFLORES-200 benchmark. Our method can expand language identification coverage\ninto low-resource languages by relying solely on systemic misprediction\npatterns, bypassing the need to retrain large models from scratch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_M/0/1/0/all/0/1\">Milind Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Md Mahfuz Ibn Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large Language Models. (arXiv:2305.14323v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14323","description":"<p>Although large language models (LLMs) have achieved excellent performance in\na variety of evaluation benchmarks, they still struggle in complex reasoning\ntasks which require specific knowledge and multi-hop reasoning. To improve the\nreasoning abilities, we propose ChatCoT, a tool-augmented chain-of-thought\nreasoning framework for chat-based LLMs (e.g., ChatGPT). In ChatCoT, we model\nthe chain-of-thought (CoT) reasoning as multi-turn conversations, to utilize\ntools in a more natural way through chatting. At each turn, LLMs can either\ninteract with tools or perform the reasoning. Our approach can effectively\nleverage the multi-turn conversation ability of chat-based LLMs, and integrate\nthe thought chain following and tools manipulation in a unified way. Specially,\nwe initialize the early turns of the conversation by the knowledge about tools,\ntasks, and reasoning format, and propose an iterative tool-augmented reasoning\nstep to perform step-by-step tool-augmented reasoning. The experiment results\non two complex reasoning datasets (MATH and HotpotQA) have shown the\neffectiveness of ChatCoT on complex reasoning tasks, achieving a 7.9% relative\nimprovement over the state-of-the-art baseline. Our code and data are available\nat: \\url{https://github.com/RUCAIBOX/ChatCoT}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Beichen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zheng Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FOCUS: Effective Embedding Initialization for Monolingual Specialization of Multilingual Models. (arXiv:2305.14481v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14481","description":"<p>Using model weights pretrained on a high-resource language as a warm start\ncan reduce the need for data and compute to obtain high-quality language models\nfor other, especially low-resource, languages. However, if we want to use a new\ntokenizer specialized for the target language, we cannot transfer the source\nmodel's embedding matrix. In this paper, we propose FOCUS - Fast Overlapping\nToken Combinations Using Sparsemax, a novel embedding initialization method\nthat initializes the embedding matrix effectively for a new tokenizer based on\ninformation in the source model's embedding matrix. FOCUS represents newly\nadded tokens as combinations of tokens in the overlap of the source and target\nvocabularies. The overlapping tokens are selected based on semantic similarity\nin an auxiliary static token embedding space. We focus our study on using the\nmultilingual XLM-R as a source model and empirically show that FOCUS\noutperforms random initialization and previous work in language modeling and on\na range of downstream tasks (NLI, QA, and NER).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dobler_K/0/1/0/all/0/1\">Konstantin Dobler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1\">Gerard de Melo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Continuous and Discrete Spaces: Interpretable Sentence Representation Learning via Compositional Operations. (arXiv:2305.14599v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14599","description":"<p>Traditional sentence embedding models encode sentences into vector\nrepresentations to capture useful properties such as the semantic similarity\nbetween sentences. However, in addition to similarity, sentence semantics can\nalso be interpreted via compositional operations such as sentence fusion or\ndifference. It is unclear whether the compositional semantics of sentences can\nbe directly reflected as compositional operations in the embedding space. To\nmore effectively bridge the continuous embedding and discrete text spaces, we\nexplore the plausibility of incorporating various compositional properties into\nthe sentence embedding space that allows us to interpret embedding\ntransformations as compositional sentence operations. We propose InterSent, an\nend-to-end framework for learning interpretable sentence embeddings that\nsupports compositional sentence operations in the embedding space. Our method\noptimizes operator networks and a bottleneck encoder-decoder model to produce\nmeaningful and interpretable sentence embeddings. Experimental results\ndemonstrate that our method significantly improves the interpretability of\nsentence embeddings on four textual generation tasks over existing approaches\nwhile maintaining strong performance on traditional semantic similarity tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">James Y. Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Wenlin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaiqiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Language Models to Compress Contexts. (arXiv:2305.14788v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14788","description":"<p>Transformer-based language models (LMs) are powerful and widely-applicable\ntools, but their usefulness is constrained by a finite context window and the\nexpensive computational cost of processing long text documents. We propose to\nadapt pre-trained LMs into AutoCompressors. These language models are capable\nof compressing long contexts into compact summary vectors, which are then\naccessible to the model as soft prompts. Summary vectors are trained with an\nunsupervised objective, whereby long documents are processed in segments, and\nsummary vectors from all previous segments are used in language modeling. We\nfine-tune OPT and Llama-2 models on sequences of up to 30,720 tokens and show\nthat AutoCompressors can utilize long contexts to improve perplexity. We\nevaluate AutoCompressors on in-context learning by compressing task\ndemonstrations and find that summary vectors are good substitutes for\nplain-text demonstrations, increasing accuracy while reducing inference costs.\nFinally, we explore the benefits of pre-computing summary vectors for large\ncorpora by applying summary vectors to retrievalaugmented language modeling and\na passage re-ranking task. Overall, AutoCompressors emerge as a simple and\ninexpensive solution to extend the context window of LMs while speeding up\ninference over long contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chevalier_A/0/1/0/all/0/1\">Alexis Chevalier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wettig_A/0/1/0/all/0/1\">Alexander Wettig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1\">Anirudh Ajith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ClusterLLM: Large Language Models as a Guide for Text Clustering. (arXiv:2305.14871v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14871","description":"<p>We introduce ClusterLLM, a novel text clustering framework that leverages\nfeedback from an instruction-tuned large language model, such as ChatGPT.\nCompared with traditional unsupervised methods that builds upon \"small\"\nembedders, ClusterLLM exhibits two intriguing advantages: (1) it enjoys the\nemergent capability of LLM even if its embeddings are inaccessible; and (2) it\nunderstands the user's preference on clustering through textual instruction\nand/or a few annotated data. First, we prompt ChatGPT for insights on\nclustering perspective by constructing hard triplet questions &lt;does A better\ncorrespond to B than C&gt;, where A, B and C are similar data points that belong\nto different clusters according to small embedder. We empirically show that\nthis strategy is both effective for fine-tuning small embedder and\ncost-efficient to query ChatGPT. Second, we prompt ChatGPT for helps on\nclustering granularity by carefully designed pairwise questions &lt;do A and B\nbelong to the same category&gt;, and tune the granularity from cluster hierarchies\nthat is the most consistent with the ChatGPT answers. Extensive experiments on\n14 datasets show that ClusterLLM consistently improves clustering quality, at\nan average cost of ~$0.6 per dataset. The code will be available at\nhttps://github.com/zhang-yu-wei/ClusterLLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Frugal Prompting for Dialog Models. (arXiv:2305.14919v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14919","description":"<p>The use of large language models (LLMs) in natural language processing (NLP)\ntasks is rapidly increasing, leading to changes in how researchers approach\nproblems in the field. To fully utilize these models' abilities, a better\nunderstanding of their behavior for different input protocols is required. With\nLLMs, users can directly interact with the models through a text-based\ninterface to define and solve various tasks. Hence, understanding the\nconversational abilities of these LLMs, which may not have been specifically\ntrained for dialog modeling, is also important. This study examines different\napproaches for building dialog systems using LLMs by considering various\naspects of the prompt. As part of prompt tuning, we experiment with various\nways of providing instructions, exemplars, current query and additional\ncontext. The research also analyzes the representations of dialog history that\nhave the optimal usable-information density. Based on the findings, the paper\nsuggests more compact ways of providing dialog history information while\nensuring good performance and reducing model's inference-API costs. The\nresearch contributes to a better understanding of how LLMs can be effectively\nused for building interactive systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Santra_B/0/1/0/all/0/1\">Bishal Santra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basak_S/0/1/0/all/0/1\">Sakya Basak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1\">Abhinandan De</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"C-STS: Conditional Semantic Textual Similarity. (arXiv:2305.15093v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15093","description":"<p>Semantic textual similarity (STS), a cornerstone task in NLP, measures the\ndegree of similarity between a pair of sentences, and has broad application in\nfields such as information retrieval and natural language understanding.\nHowever, sentence similarity can be inherently ambiguous, depending on the\nspecific aspect of interest. We resolve this ambiguity by proposing a novel\ntask called Conditional STS (C-STS) which measures sentences' similarity\nconditioned on an feature described in natural language (hereon, condition). As\nan example, the similarity between the sentences \"The NBA player shoots a\nthree-pointer.\" and \"A man throws a tennis ball into the air to serve.\" is\nhigher for the condition \"The motion of the ball\" (both upward) and lower for\n\"The size of the ball\" (one large and one small). C-STS's advantages are\ntwo-fold: (1) it reduces the subjectivity and ambiguity of STS and (2) enables\nfine-grained language model evaluation through diverse natural language\nconditions. We put several state-of-the-art models to the test, and even those\nperforming well on STS (e.g. SimCSE, Flan-T5, and GPT-4) find C-STS\nchallenging; all with Spearman correlation scores below 50. To encourage a more\ncomprehensive evaluation of semantic similarity and natural language\nunderstanding, we make nearly 19K C-STS examples and code available for others\nto train and test their models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ameet Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_C/0/1/0/all/0/1\">Carlos E. Jimenez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Howard Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murahari_V/0/1/0/all/0/1\">Vishvak Murahari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Graf_V/0/1/0/all/0/1\">Victoria Graf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurohit_T/0/1/0/all/0/1\">Tanmay Rajpurohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1\">Ashwin Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples. (arXiv:2305.15269v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15269","description":"<p>Given the intractably large size of the space of proofs, any model that is\ncapable of general deductive reasoning must generalize to proofs of greater\ncomplexity. Recent studies have shown that large language models (LLMs) possess\nsome abstract deductive reasoning ability given chain-of-thought prompts.\nHowever, they have primarily been tested on proofs using modus ponens or of a\nspecific size, and from the same distribution as the in-context examples. To\nmeasure the general deductive reasoning ability of LLMs, we test on a broad set\nof deduction rules and measure their ability to generalize to more complex\nproofs from simpler demonstrations from multiple angles: depth-, width-, and\ncompositional generalization. To facilitate systematic exploration, we\nconstruct a new synthetic and programmable reasoning dataset that enables\ncontrol over deduction rules and proof complexity. Our experiments on four LLMs\nof various sizes and training objectives show that they are able to generalize\nto compositional proofs. However, they have difficulty generalizing to longer\nproofs, and they require explicit demonstrations to produce hypothetical\nsubproofs, specifically in proof by cases and proof by contradiction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saparov_A/0/1/0/all/0/1\">Abulhair Saparov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_V/0/1/0/all/0/1\">Vishakh Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Nitish Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_S/0/1/0/all/0/1\">Seyed Mehran Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective. (arXiv:2305.15408v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.15408","description":"<p>Recent studies have discovered that Chain-of-Thought prompting (CoT) can\ndramatically improve the performance of Large Language Models (LLMs),\nparticularly when dealing with complex tasks involving mathematics or\nreasoning. Despite the enormous empirical success, the underlying mechanisms\nbehind CoT and how it unlocks the potential of LLMs remain elusive. In this\npaper, we take a first step towards theoretically answering these questions.\nSpecifically, we examine the expressivity of LLMs with CoT in solving\nfundamental mathematical and decision-making problems. By using circuit\ncomplexity theory, we first give impossibility results showing that\nbounded-depth Transformers are unable to directly produce correct answers for\nbasic arithmetic/equation tasks unless the model size grows super-polynomially\nwith respect to the input length. In contrast, we then prove by construction\nthat autoregressive Transformers of constant size suffice to solve both tasks\nby generating CoT derivations using a commonly used math language format.\nMoreover, we show LLMs with CoT can handle a general class of decision-making\nproblems known as Dynamic Programming, thus justifying its power in tackling\ncomplex real-world tasks. Finally, an extensive set of experiments show that,\nwhile Transformers always fail to directly predict the answers, they can\nconsistently learn to generate correct solutions step-by-step given sufficient\nCoT demonstrations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1\">Guhao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bohang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuntian Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liwei Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Emotion Arcs Across Languages: Bridging the Global Divide in Sentiment Analysis. (arXiv:2306.02213v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02213","description":"<p>Emotion arcs capture how an individual (or a population) feels over time.\nThey are widely used in industry and research; however, there is little work on\nevaluating the automatically generated arcs. This is because of the difficulty\nof establishing the true (gold) emotion arc. Our work, for the first time,\nsystematically and quantitatively evaluates automatically generated emotion\narcs. We also compare two common ways of generating emotion arcs:\nMachine-Learning (ML) models and Lexicon-Only (LexO) methods. By running\nexperiments on 18 diverse datasets in 9 languages, we show that despite being\nmarkedly poor at instance level emotion classification, LexO methods are highly\naccurate at generating emotion arcs when aggregating information from hundreds\nof instances. We also show, through experiments on six indigenous African\nlanguages, as well as Arabic, and Spanish, that automatic translations of\nEnglish emotion lexicons can be used to generate high-quality emotion arcs in\nless-resource languages. This opens up avenues for work on emotions in\nlanguages from around the world; which is crucial for commerce, public policy,\nand health research in service of speakers often left behind. Code and\nresources: https://github.com/dteodore/EmotionArcs\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_D/0/1/0/all/0/1\">Daniela Teodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SciLit: A Platform for Joint Scientific Literature Discovery, Summarization and Citation Generation. (arXiv:2306.03535v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03535","description":"<p>Scientific writing involves retrieving, summarizing, and citing relevant\npapers, which can be time-consuming processes in large and rapidly evolving\nfields. By making these processes inter-operable, natural language processing\n(NLP) provides opportunities for creating end-to-end assistive writing tools.\nWe propose SciLit, a pipeline that automatically recommends relevant papers,\nextracts highlights, and suggests a reference sentence as a citation of a\npaper, taking into consideration the user-provided context and keywords. SciLit\nefficiently recommends papers from large databases of hundreds of millions of\npapers using a two-stage pre-fetching and re-ranking literature search system\nthat flexibly deals with addition and removal of a paper database. We provide a\nconvenient user interface that displays the recommended papers as extractive\nsummaries and that offers abstractively-generated citing sentences which are\naligned with the provided context and which mention the chosen keyword(s). Our\nassistive tool for literature discovery and scientific writing is available at\nhttps://scilit.vercel.app\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_N/0/1/0/all/0/1\">Nianlong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hahnloser_R/0/1/0/all/0/1\">Richard H.R. Hahnloser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Hybrid Linguistic Features for Turkish Text Readability. (arXiv:2306.03774v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03774","description":"<p>This paper presents the first comprehensive study on automatic readability\nassessment of Turkish texts. We combine state-of-the-art neural network models\nwith linguistic features at lexical, morphosyntactic, syntactic and discourse\nlevels to develop an advanced readability tool. We evaluate the effectiveness\nof traditional readability formulas compared to modern automated methods and\nidentify key linguistic features that determine the readability of Turkish\ntexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1\">Ahmet Yavuz Uluslu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1\">Gerold Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Foundation Models with Language-Model-as-an-Examiner. (arXiv:2306.04181v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.04181","description":"<p>Numerous benchmarks have been established to assess the performance of\nfoundation models on open-ended question answering, which serves as a\ncomprehensive test of a model's ability to understand and generate language in\na manner similar to humans. Most of these works focus on proposing new\ndatasets, however, we see two main issues within previous benchmarking\npipelines, namely testing leakage and evaluation automation. In this paper, we\npropose a novel benchmarking framework, Language-Model-as-an-Examiner, where\nthe LM serves as a knowledgeable examiner that formulates questions based on\nits knowledge and evaluates responses in a reference-free manner. Our framework\nallows for effortless extensibility as various LMs can be adopted as the\nexaminer, and the questions can be constantly updated given more diverse\ntrigger topics. For a more comprehensive and equitable evaluation, we devise\nthree strategies: (1) We instruct the LM examiner to generate questions across\na multitude of domains to probe for a broad acquisition, and raise follow-up\nquestions to engage in a more in-depth assessment. (2) Upon evaluation, the\nexaminer combines both scoring and ranking measurements, providing a reliable\nresult as it aligns closely with human annotations. (3) We additionally propose\na decentralized Peer-examination method to address the biases in a single\nexaminer. Our data and benchmarking results are available at:\n<a href=\"http://lmexam.xlore.cn.\">this http URL</a>\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yushi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_J/0/1/0/all/0/1\">Jiahao Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1\">Xin Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuze He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kaisheng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yijia Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1\">Haozhe Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiayin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models. (arXiv:2306.09869v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2306.09869","description":"<p>Despite the remarkable performance of text-to-image diffusion models in image\ngeneration tasks, recent studies have raised the issue that generated images\nsometimes cannot capture the intended semantic contents of the text prompts,\nwhich phenomenon is often called semantic misalignment. To address this, here\nwe present a novel energy-based model (EBM) framework for adaptive context\ncontrol by modeling the posterior of context vectors. Specifically, we first\nformulate EBMs of latent image representations and text embeddings in each\ncross-attention layer of the denoising autoencoder. Then, we obtain the\ngradient of the log posterior of context vectors, which can be updated and\ntransferred to the subsequent cross-attention layer, thereby implicitly\nminimizing a nested hierarchy of energy functions. Our latent EBMs further\nallow zero-shot compositional generation as a linear combination of\ncross-attention outputs from different contexts. Using extensive experiments,\nwe demonstrate that the proposed method is highly effective in handling various\nimage generation tasks, including multi-concept generation, text-guided image\ninpainting, and real and synthetic image editing. Code:\nhttps://github.com/EnergyAttention/Energy-Based-CrossAttention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_G/0/1/0/all/0/1\">Geon Yeong Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jeongsol Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1\">Beomsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang Wan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jong Chul Ye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sparse Modular Activation for Efficient Sequence Modeling. (arXiv:2306.11197v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.11197","description":"<p>Recent hybrid models combining Linear State Space Models (SSMs) with\nself-attention mechanisms have demonstrated impressive results across a range\nof sequence modeling tasks. However, current approaches apply attention modules\nstatically and uniformly to all elements in the input sequences, leading to\nsub-optimal quality-efficiency trade-offs. To address this limitation, we\nintroduce Sparse Modular Activation (SMA), a general mechanism enabling neural\nnetworks to sparsely and dynamically activate sub-modules for sequence elements\nin a differentiable manner. Through allowing each element to skip non-activated\nsub-modules, SMA reduces computation and memory consumption of neural networks\nat both training and inference stages. To validate the effectiveness of SMA on\nsequence modeling, we design a novel neural architecture, SeqBoat, which\nemploys SMA to sparsely activate a Gated Attention Unit (GAU) based on the\nstate representations learned from an SSM. By constraining the GAU to only\nconduct local attention on the activated inputs, SeqBoat can achieve linear\ninference complexity with theoretically infinite attention span, and provide\nsubstantially better quality-efficiency trade-off than the chunking-based\nmodels. With experiments on a wide range of tasks, including long sequence\nmodeling, speech classification and language modeling, SeqBoat brings new\nstate-of-the-art results among hybrid models with linear complexity, and\nreveals the amount of attention needed for each task through the learned sparse\nactivation patterns. Our code is publicly available at\nhttps://github.com/renll/SeqBoat.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1\">Liliang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.06775","description":"<p>Over the last decade, there has been a vast increase in eating disorder\ndiagnoses and eating disorder-attributed deaths, reaching their zenith during\nthe Covid-19 pandemic. This immense growth derived in part from the stressors\nof the pandemic but also from increased exposure to social media, which is rife\nwith content that promotes eating disorders. This study aimed to create a\nmultimodal deep learning model that can determine if a given social media post\npromotes eating disorders based on a combination of visual and textual data. A\nlabeled dataset of Tweets was collected from Twitter, recently rebranded as X,\nupon which twelve deep learning models were trained and evaluated. Based on\nmodel performance, the most effective deep learning model was the multimodal\nfusion of the RoBERTa natural language processing model and the MaxViT image\nclassification model, attaining accuracy and F1 scores of 95.9% and 0.959,\nrespectively. The RoBERTa and MaxViT fusion model, deployed to classify an\nunlabeled dataset of posts from the social media sites Tumblr and Reddit,\ngenerated results akin to those of previous research studies that did not\nemploy artificial intelligence-based techniques, indicating that deep learning\nmodels can develop insights congruent to those of researchers. Additionally,\nthe model was used to conduct a time-series analysis of yet unseen Tweets from\neight Twitter hashtags, uncovering that, since 2014, the relative abundance of\ncontent that promotes eating disorders has decreased drastically within those\ncommunities. Despite this reduction, by 2018, content that promotes eating\ndisorders had either stopped declining or increased in ampleness anew on those\nhashtags.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feldman_J/0/1/0/all/0/1\">Jonathan Feldman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AlpaGasus: Training A Better Alpaca with Fewer Data. (arXiv:2307.08701v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.08701","description":"<p>Large language models~(LLMs) strengthen instruction-following capability\nthrough instruction-finetuning (IFT) on supervised instruction/response data.\nHowever, widely used IFT datasets (e.g., Alpaca's 52k data) surprisingly\ncontain many low-quality instances with incorrect or irrelevant responses,\nwhich are misleading and detrimental to IFT. In this paper, we propose a simple\nand effective data selection strategy that automatically identifies and filters\nout low-quality data using a strong LLM (e.g., ChatGPT). To this end, we\nintroduce AlpaGasus, which is finetuned on only 9k high-quality data filtered\nfrom the 52k Alpaca data. AlpaGasus significantly outperforms the original\nAlpaca as evaluated by GPT-4 on multiple test sets and the controlled human\nevaluation. Its 13B variant matches $&gt;90\\%$ performance of its teacher LLM\n(i.e., Text-Davinci-003 generating the 52k data) on test tasks. It also\nprovides 5.7x faster training, reducing the training time for a 7B variant from\n80 minutes (for Alpaca) to 14 minutes. Moreover, the experiments prove the\nefficacy of our method across diverse datasets, base models, and LLM filters.\nOverall, AlpaGasus demonstrates a novel data-centric IFT paradigm that can be\ngenerally applied to instruction-tuning data, leading to faster training and\nbetter instruction-following models. Our project page is available at:\n\\url{https://lichang-chen.github.io/AlpaGasus/}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lichang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunaratna_K/0/1/0/all/0/1\">Kalpa Gunaratna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vikas Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1\">Vijay Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Heng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hongxia Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Understand and Can be Enhanced by Emotional Stimuli. (arXiv:2307.11760v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11760","description":"<p>Emotional intelligence significantly impacts our daily behaviors and\ninteractions. Although Large Language Models (LLMs) are increasingly viewed as\na stride toward artificial general intelligence, exhibiting impressive\nperformance in numerous tasks, it is still uncertain if LLMs can genuinely\ngrasp psychological emotional stimuli. Understanding and responding to\nemotional cues gives humans a distinct advantage in problem-solving. In this\npaper, we take the first step towards exploring the ability of LLMs to\nunderstand emotional stimuli. To this end, we first conduct automatic\nexperiments on 45 tasks using various LLMs, including Flan-T5-Large, Vicuna,\nLlama 2, BLOOM, ChatGPT, and GPT-4. Our tasks span deterministic and generative\napplications that represent comprehensive evaluation scenarios. Our automatic\nexperiments show that LLMs have a grasp of emotional intelligence, and their\nperformance can be improved with emotional prompts (which we call\n\"EmotionPrompt\" that combines the original prompt with emotional stimuli),\ne.g., 8.00% relative performance improvement in Instruction Induction and 115%\nin BIG-Bench. In addition to those deterministic tasks that can be\nautomatically evaluated using existing metrics, we conducted a human study with\n106 participants to assess the quality of generative tasks using both vanilla\nand emotional prompts. Our human study results demonstrate that EmotionPrompt\nsignificantly boosts the performance of generative tasks (10.9% average\nimprovement in terms of performance, truthfulness, and responsibility metrics).\nWe provide an in-depth discussion regarding why EmotionPrompt works for LLMs\nand the factors that may influence its performance. We posit that EmotionPrompt\nheralds a novel avenue for exploring interdisciplinary knowledge for human-LLMs\ninteraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Cheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_J/0/1/0/all/0/1\">Jianxun Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Fang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Turkish Native Language Identification. (arXiv:2307.14850v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.14850","description":"<p>In this paper, we present the first application of Native Language\nIdentification (NLI) for the Turkish language. NLI involves predicting the\nwriter's first language by analysing their writing in different languages.\nWhile most NLI research has focused on English, our study extends its scope to\nTurkish. We used the recently constructed Turkish Learner Corpus and employed a\ncombination of three syntactic features (CFG production rules, part-of-speech\nn-grams, and function words) with L2 texts to demonstrate their effectiveness\nin this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1\">Ahmet Yavuz Uluslu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1\">Gerold Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.15936","description":"<p>A major driver of AI products today is the fact that new skills emerge in\nlanguage models when their parameter set and training corpora are scaled up.\nThis phenomenon is poorly understood, and a mechanistic explanation via\nmathematical analysis of gradient-based training seems difficult. The current\npaper takes a different approach, analysing emergence using the famous (and\nempirical) Scaling Laws of LLMs and a simple statistical framework.\nContributions include: (a) A statistical framework that relates cross-entropy\nloss of LLMs to competence on the basic skills that underlie language tasks.\n(b) Mathematical analysis showing that the Scaling Laws imply a strong form of\ninductive bias that allows the pre-trained model to learn very efficiently. We\ninformally call this {\\em slingshot generalization} since naively viewed it\nappears to give competence levels at skills that violate usual generalization\ntheory. (c) A key example of slingshot generalization, that competence at\nexecuting tasks involving $k$-tuples of skills emerges essentially at the same\nscaling and same rate as competence on the elementary skills themselves.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sanjeev Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predictive Data Analytics with AI: assessing the need for post-editing of MT output by fine-tuning OpenAI LLMs. (arXiv:2308.00158v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.00158","description":"<p>Translation Quality Evaluation (TQE) is an essential step of the modern\ntranslation production process. TQE is critical in assessing both machine\ntranslation (MT) and human translation (HT) quality without reference\ntranslations. The ability to evaluate or even simply estimate the quality of\ntranslation automatically may open significant efficiency gains through process\noptimisation. This work examines whether the state-of-the-art large language\nmodels (LLMs) can be used for this purpose. We take OpenAI models as the best\nstate-of-the-art technology and approach TQE as a binary classification task.\nOn \\textbf{eight language pairs} including English to Italian, German, French,\nJapanese, Dutch, Portuguese, Turkish, and Chinese, our experimental results\nshow that fine-tuned \\textbf{\\textit{gpt3.5}} can demonstrate good performance\non translation quality prediction tasks, i.e. \\textit{whether the translation\nneeds to be edited}. Another finding is that simply increasing the sizes of\nLLMs does not lead to apparent better performances on this task by comparing\nthe performance of three different versions of OpenAI models:\n\\textbf{\\textit{curie}}, \\textbf{\\textit{davinci}}, and\n\\textbf{\\textit{gpt3.5}} with 13B, 175B, and 175B parameters, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gladkoff_S/0/1/0/all/0/1\">Serge Gladkoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erofeev_G/0/1/0/all/0/1\">Gleb Erofeev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lifeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?. (arXiv:2308.06032v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.06032","description":"<p>Large Language Models (LLMs) could enhance access to the legal system.\nHowever, empirical research on their effectiveness in conducting legal tasks is\nscant. We study securities cases involving cryptocurrencies as one of numerous\ncontexts where AI could support the legal process, studying LLMs' legal\nreasoning and drafting capabilities. We examine whether a) an LLM can\naccurately determine which laws are potentially being violated from a fact\npattern, and b) whether there is a difference in juror decision-making based on\ncomplaints written by a lawyer compared to an LLM. We feed fact patterns from\nreal-life cases to GPT-3.5 and evaluate its ability to determine correct\npotential violations from the scenario and exclude spurious violations. Second,\nwe had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's\nlegal reasoning skills proved weak, though we expect improvement in future\nmodels, particularly given the violations it suggested tended to be correct (it\nmerely missed additional, correct violations). GPT-3.5 performed better at\nlegal drafting, and jurors' decisions were not statistically significantly\nassociated with the author of the document upon which they based their\ndecisions. Because LLMs cannot satisfactorily conduct legal reasoning tasks,\nthey would be unable to replace lawyers at this stage. However, their drafting\nskills (though, perhaps, still inferior to lawyers), could provide access to\njustice for more individuals by reducing the cost of legal services. Our\nresearch is the first to systematically study LLMs' legal drafting and\nreasoning capabilities in litigation, as well as in securities law and\ncryptocurrency-related misconduct.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Trozze_A/0/1/0/all/0/1\">Arianna Trozze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davies_T/0/1/0/all/0/1\">Toby Davies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleinberg_B/0/1/0/all/0/1\">Bennett Kleinberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using Sentence Transformers and Reciprocal-Rank Fusion. (arXiv:2308.12877v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12877","description":"<p>This paper outlines the performance evaluation of a system for adverse drug\nevent normalization, developed by the Data Science for Digital Health (DS4DH)\ngroup for the Social Media Mining for Health Applications (SMM4H) 2023 shared\ntask 5. Shared task 5 targeted the normalization of adverse drug event mentions\nin Twitter to standard concepts of the Medical Dictionary for Regulatory\nActivities terminology. Our system hinges on a two-stage approach: BERT\nfine-tuning for entity recognition, followed by zero-shot normalization using\nsentence transformers and reciprocal-rank fusion. The approach yielded a\nprecision of 44.9%, recall of 40.5%, and an F1-score of 42.6%. It outperformed\nthe median performance in shared task 5 by 10% and demonstrated the highest\nperformance among all participants. These results substantiate the\neffectiveness of our approach and its potential application for adverse drug\nevent normalization in the realm of social media text mining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_A/0/1/0/all/0/1\">Anthony Yazdani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rouhizadeh_H/0/1/0/all/0/1\">Hossein Rouhizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_D/0/1/0/all/0/1\">David Vicente Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teodoro_D/0/1/0/all/0/1\">Douglas Teodoro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Language Model Attacks with Perplexity. (arXiv:2308.14132v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.14132","description":"<p>A novel hack involving Large Language Models (LLMs) has emerged, leveraging\nadversarial suffixes to trick models into generating perilous responses. This\nmethod has garnered considerable attention from reputable media outlets such as\nthe New York Times and Wired, thereby influencing public perception regarding\nthe security and safety of LLMs. In this study, we advocate the utilization of\nperplexity as one of the means to recognize such potential attacks. The\nunderlying concept behind these hacks revolves around appending an unusually\nconstructed string of text to a harmful query that would otherwise be blocked.\nThis maneuver confuses the protective mechanisms and tricks the model into\ngenerating a forbidden response. Such scenarios could result in providing\ndetailed instructions to a malicious user for constructing explosives or\norchestrating a bank heist. Our investigation demonstrates the feasibility of\nemploying perplexity, a prevalent natural language processing metric, to detect\nthese adversarial tactics before generating a forbidden response. By evaluating\nthe perplexity of queries with and without such adversarial suffixes using an\nopen-source LLM, we discovered that nearly 90 percent were above a perplexity\nof 1000. This contrast underscores the efficacy of perplexity for detecting\nthis type of exploit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alon_G/0/1/0/all/0/1\">Gabriel Alon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamfonas_M/0/1/0/all/0/1\">Michael Kamfonas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantifying and Analyzing Entity-level Memorization in Large Language Models. (arXiv:2308.15727v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.15727","description":"<p>Large language models (LLMs) have been proven capable of memorizing their\ntraining data, which can be extracted through specifically designed prompts. As\nthe scale of datasets continues to grow, privacy risks arising from\nmemorization have attracted increasing attention. Quantifying language model\nmemorization helps evaluate potential privacy risks. However, prior works on\nquantifying memorization require access to the precise original data or incur\nsubstantial computational overhead, making it difficult for applications in\nreal-world language models. To this end, we propose a fine-grained,\nentity-level definition to quantify memorization with conditions and metrics\ncloser to real-world scenarios. In addition, we also present an approach for\nefficiently extracting sensitive entities from autoregressive language models.\nWe conduct extensive experiments based on the proposed, probing language\nmodels' ability to reconstruct sensitive entities under different settings. We\nfind that language models have strong memorization at the entity level and are\nable to reproduce the training data even with partial leakages. The results\ndemonstrate that LLMs not only memorize their training data but also understand\nassociations between entities. These findings necessitate that trainers of LLMs\nexercise greater prudence regarding model memorization, adopting memorization\nmitigation techniques to preclude privacy violations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhenhong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1\">Jiuyang Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaomeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1\">Sen Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Topic Modeling for Determinants of Divergent Report Results Applied to Macular Degeneration Studies. (arXiv:2309.00312v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00312","description":"<p>Topic modeling and text mining are subsets of Natural Language Processing\n(NLP) with relevance for conducting meta-analysis (MA) and systematic review\n(SR). For evidence synthesis, the above NLP methods are conventionally used for\ntopic-specific literature searches or extracting values from reports to\nautomate essential phases of SR and MA. Instead, this work proposes a\ncomparative topic modeling approach to analyze reports of contradictory results\non the same general research question. Specifically, the objective is to\nidentify topics exhibiting distinct associations with significant results for\nan outcome of interest by ranking them according to their proportional\noccurrence in (and consistency of distribution across) reports of significant\neffects. The proposed method was tested on broad-scope studies addressing\nwhether supplemental nutritional compounds significantly benefit macular\ndegeneration (MD). Six compounds were identified as having a particular\nassociation with reports of significant results for benefiting MD. Four of\nthese were further supported in terms of effectiveness upon conducting a\nfollow-up literature search for validation (omega-3 fatty acids, copper,\nzeaxanthin, and nitrates). The two not supported by the follow-up literature\nsearch (niacin and molybdenum) also had the lowest scores under the proposed\nscoring system, suggesting that the proposed method's score for a given topic\nis a viable proxy for its degree of association with the outcome of interest\nand is helpful in the search for potentially causal relationships. These\nresults underpin the proposed methods potential to add specificity in\nunderstanding effects from broad-scope reports, elucidate topics of interest\nfor future research, and guide evidence synthesis in a systematic and scalable\nway.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacaruso_L/0/1/0/all/0/1\">Lucas Cassiel Jacaruso</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Base to Conversational: Japanese Instruction Dataset and Tuning Large Language Models. (arXiv:2309.03412v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03412","description":"<p>Instruction tuning is essential for large language models (LLMs) to become\ninteractive. While many instruction tuning datasets exist in English, there is\na noticeable lack in other languages. Also, their effectiveness has not been\nwell verified in non-English languages. We construct a Japanese instruction\ndataset by expanding and filtering existing datasets and apply the dataset to a\nJapanese pre-trained base model. We performed Low-Rank Adaptation (LoRA) tuning\non both Japanese and English existing models using our instruction dataset. We\nevaluated these models from both quantitative and qualitative perspectives. As\na result, the effectiveness of Japanese instruction datasets is confirmed. The\nresults also indicate that even with relatively small LLMs, performances in\ndownstream tasks would be improved through instruction tuning. Our instruction\ndataset, tuned models, and implementation are publicly available online.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1\">Masahiro Suzuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirano_M/0/1/0/all/0/1\">Masanori Hirano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaji_H/0/1/0/all/0/1\">Hiroki Sakaji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Flesch or Fumble? Evaluating Readability Standard Alignment of Instruction-Tuned Language Models. (arXiv:2309.05454v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05454","description":"<p>Readability metrics and standards such as Flesch Kincaid Grade Level (FKGL)\nand the Common European Framework of Reference for Languages (CEFR) exist to\nguide teachers and educators to properly assess the complexity of educational\nmaterials before administering them for classroom use. In this study, we select\na diverse set of open and closed-source instruction-tuned language models and\ninvestigate their performances in writing story completions and simplifying\nnarratives--tasks that teachers perform--using standard-guided prompts\ncontrolling text readability. Our extensive findings provide empirical proof of\nhow globally recognized models like ChatGPT may be considered less effective\nand may require more refined prompts for these generative tasks compared to\nother open-sourced models such as BLOOMZ and FlanT5--which have shown promising\nresults.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Imperial_J/0/1/0/all/0/1\">Joseph Marvin Imperial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madabushi_H/0/1/0/all/0/1\">Harish Tayyar Madabushi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards LogiGLUE: A Brief Survey and A Benchmark for Analyzing Logical Reasoning Capabilities of Language Models. (arXiv:2310.00836v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00836","description":"<p>Logical reasoning is fundamental for humans yet presents a substantial\nchallenge in the domain of Artificial Intelligence. Initially, researchers used\nKnowledge Representation and Reasoning (KR) systems that did not scale and\nrequired non trivial manual effort. Recently, the emergence of large language\nmodels (LLMs) has demonstrated the ability to overcome various limitations of\nformal Knowledge Representation (KR) systems. Consequently, there is a growing\ninterest in using LLMs for logical reasoning via natural language. This work\nstrives to understand the proficiency of LLMs in logical reasoning by offering\na brief review of the latest progress in this area; with a focus on the logical\nreasoning datasets, tasks, and the methods adopted to utilize LLMs for\nreasoning. To offer a thorough analysis, we have compiled a benchmark titled\nLogiGLUE. This includes 24 varied datasets encompassing deductive, abductive,\nand inductive reasoning. We have standardized these datasets into Seq2Seq tasks\nto facilitate straightforward training and evaluation for future research.\nUtilizing LogiGLUE as a foundation, we have trained an instruction fine tuned\nlanguage model, resulting in LogiT5. We study single task training, multi task\ntraining, and a chain of thought knowledge distillation fine tuning technique\nto assess the performance of model across the different logical reasoning\ncategories. By this comprehensive process, we aim to shed light on the\ncapabilities and potential pathways for enhancing logical reasoning proficiency\nin LLMs, paving the way for more advanced and nuanced developments in this\ncritical field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Man Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumbhar_S/0/1/0/all/0/1\">Shrinidhi Kumbhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+shen_M/0/1/0/all/0/1\">Ming shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1\">Mihir Parmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1\">Neeraj Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_P/0/1/0/all/0/1\">Pratyay Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aditya_S/0/1/0/all/0/1\">Somak Aditya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RA-DIT: Retrieval-Augmented Dual Instruction Tuning. (arXiv:2310.01352v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01352","description":"<p>Retrieval-augmented language models (RALMs) improve performance by accessing\nlong-tail and up-to-date knowledge from external data stores, but are\nchallenging to build. Existing approaches require either expensive\nretrieval-specific modifications to LM pre-training or use post-hoc integration\nof the data store that leads to suboptimal performance. We introduce\nRetrieval-Augmented Dual Instruction Tuning (RA-DIT), a lightweight fine-tuning\nmethodology that provides a third option by retrofitting any LLM with retrieval\ncapabilities. Our approach operates in two distinct fine-tuning steps: (1) one\nupdates a pre-trained LM to better use retrieved information, while (2) the\nother updates the retriever to return more relevant results, as preferred by\nthe LM. By fine-tuning over tasks that require both knowledge utilization and\ncontextual awareness, we demonstrate that each stage yields significant\nperformance improvements, and using both leads to additional gains. Our best\nmodel, RA-DIT 65B, achieves state-of-the-art performance across a range of\nknowledge-intensive zero- and few-shot learning benchmarks, significantly\noutperforming existing in-context RALM approaches by up to +8.9% in 0-shot\nsetting and +1.4% in 5-shot setting on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lomeli_M/0/1/0/all/0/1\">Maria Lomeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_R/0/1/0/all/0/1\">Rich James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1\">Pedro Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahn_J/0/1/0/all/0/1\">Jacob Kahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szilvasy_G/0/1/0/all/0/1\">Gergely Szilvasy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1\">Scott Yih</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform Generation. (arXiv:2310.01381v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2310.01381","description":"<p>Diffusion models have recently been shown to be relevant for high-quality\nspeech generation. Most work has been focused on generating spectrograms, and\nas such, they further require a subsequent model to convert the spectrogram to\na waveform (i.e., a vocoder). This work proposes a diffusion probabilistic\nend-to-end model for generating a raw speech waveform. The proposed model is\nautoregressive, generating overlapping frames sequentially, where each frame is\nconditioned on a portion of the previously generated one. Hence, our model can\neffectively synthesize an unlimited speech duration while preserving\nhigh-fidelity synthesis and temporal coherence. We implemented the proposed\nmodel for unconditional and conditional speech generation, where the latter can\nbe driven by an input sequence of phonemes, amplitudes, and pitch values.\nWorking on the waveform directly has some empirical advantages. Specifically,\nit allows the creation of local acoustic behaviors, like vocal fry, which makes\nthe overall waveform sounds more natural. Furthermore, the proposed diffusion\nmodel is stochastic and not deterministic; therefore, each inference generates\na slightly different waveform variation, enabling abundance of valid\nrealizations. Experiments show that the proposed model generates speech with\nsuperior quality compared with other state-of-the-art neural speech generation\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Benita_R/0/1/0/all/0/1\">Roi Benita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1\">Michael Elad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models. (arXiv:2310.04027v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04027","description":"<p>Financial sentiment analysis is critical for valuation and investment\ndecision-making. Traditional NLP models, however, are limited by their\nparameter size and the scope of their training datasets, which hampers their\ngeneralization capabilities and effectiveness in this field. Recently, Large\nLanguage Models (LLMs) pre-trained on extensive corpora have demonstrated\nsuperior performance across various NLP tasks due to their commendable\nzero-shot abilities. Yet, directly applying LLMs to financial sentiment\nanalysis presents challenges: The discrepancy between the pre-training\nobjective of LLMs and predicting the sentiment label can compromise their\npredictive performance. Furthermore, the succinct nature of financial news,\noften devoid of sufficient context, can significantly diminish the reliability\nof LLMs' sentiment analysis. To address these challenges, we introduce a\nretrieval-augmented LLMs framework for financial sentiment analysis. This\nframework includes an instruction-tuned LLMs module, which ensures LLMs behave\nas predictors of sentiment labels, and a retrieval-augmentation module which\nretrieves additional context from reliable external sources. Benchmarked\nagainst traditional models and LLMs like ChatGPT and LLaMA, our approach\nachieves 15\\% to 48\\% performance gain in accuracy and F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Boyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongyang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babar_A/0/1/0/all/0/1\">Ali Babar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao-Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback. (arXiv:2310.05199v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05199","description":"<p>Reinforcement learning from human feedback serves as a crucial bridge,\naligning large language models with human and societal values. This alignment\nrequires a vast corpus of human feedback to learn a reward model, which is\nsubsequently used to finetune language models. However, we have identified that\nthe reward model often finds shortcuts to bypass its intended objectives,\nmisleadingly assuming that humans prefer longer responses. The emergence of\nlength bias often induces the model to favor longer outputs, yet it doesn't\nequate to an increase in helpful information within these outputs. In this\npaper, we propose an innovative solution, applying the Product-of-Experts (PoE)\ntechnique to separate reward modeling from the influence of sequence length. In\nour framework, the main expert concentrates on understanding human intents,\nwhile the biased expert targets the identification and capture of length bias.\nTo further enhance the learning of bias, we introduce perturbations into the\nbias-focused expert, disrupting the flow of semantic information. Experimental\nresults validate the effectiveness of our approach, indicating that language\nmodel performance is improved, irrespective of sequence length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wenyu Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Rank Context for Named Entity Recognition Using a Synthetic Dataset. (arXiv:2310.10118v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10118","description":"<p>While recent pre-trained transformer-based models can perform named entity\nrecognition (NER) with great accuracy, their limited range remains an issue\nwhen applied to long documents such as whole novels. To alleviate this issue, a\nsolution is to retrieve relevant context at the document level. Unfortunately,\nthe lack of supervision for such a task means one has to settle for\nunsupervised approaches. Instead, we propose to generate a synthetic context\nretrieval training dataset using Alpaca, an instructiontuned large language\nmodel (LLM). Using this dataset, we train a neural context retriever based on a\nBERT model that is able to find relevant context for NER. We show that our\nmethod outperforms several retrieval baselines for the NER task on an English\nliterary dataset composed of the first chapter of 40 books.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amalvy_A/0/1/0/all/0/1\">Arthur Amalvy</a> (LIA), <a href=\"http://arxiv.org/find/cs/1/au:+Labatut_V/0/1/0/all/0/1\">Vincent Labatut</a> (LIA), <a href=\"http://arxiv.org/find/cs/1/au:+Dufour_R/0/1/0/all/0/1\">Richard Dufour</a> (LS2N - &#xe9;quipe TALN )"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VIBE: Topic-Driven Temporal Adaptation for Twitter Classification. (arXiv:2310.10191v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10191","description":"<p>Language features are evolving in real-world social media, resulting in the\ndeteriorating performance of text classification in dynamics. To address this\nchallenge, we study temporal adaptation, where models trained on past data are\ntested in the future. Most prior work focused on continued pretraining or\nknowledge updating, which may compromise their performance on noisy social\nmedia data. To tackle this issue, we reflect feature change via modeling latent\ntopic evolution and propose a novel model, VIBE: Variational Information\nBottleneck for Evolutions. Concretely, we first employ two Information\nBottleneck (IB) regularizers to distinguish past and future topics. Then, the\ndistinguished topics work as adaptive features via multi-task training with\ntimestamp and class label prediction. In adaptive learning, VIBE utilizes\nretrieved unlabeled data from online streams created posterior to training data\ntime. Substantial Twitter experiments on three classification tasks show that\nour model, with only 3% of data, significantly outperforms previous\nstate-of-the-art continued-pretraining methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V. (arXiv:2310.11441v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.11441","description":"<p>We present Set-of-Mark (SoM), a new visual prompting method, to unleash the\nvisual grounding abilities of large multimodal models (LMMs), such as GPT-4V.\nAs illustrated in Fig. 1 (right), we employ off-the-shelf interactive\nsegmentation models, such as SEEM/SAM, to partition an image into regions at\ndifferent levels of granularity, and overlay these regions with a set of marks\ne.g., alphanumerics, masks, boxes. Using the marked image as input, GPT-4V can\nanswer the questions that require visual grounding. We perform a comprehensive\nempirical study to validate the effectiveness of SoM on a wide range of\nfine-grained vision and multimodal tasks. For example, our experiments show\nthat GPT-4V with SoM in zero-shot setting outperforms the state-of-the-art\nfully-finetuned referring expression comprehension and segmentation model on\nRefCOCOg. Code for SoM prompting is made public at:\nhttps://github.com/microsoft/SoM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Feng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_X/0/1/0/all/0/1\">Xueyan Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation. (arXiv:2310.13505v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13505","description":"<p>Models for conversational question answering (ConvQA) over knowledge graphs\n(KGs) are usually trained and tested on benchmarks of gold QA pairs. This\nimplies that training is limited to surface forms seen in the respective\ndatasets, and evaluation is on a small set of held-out questions. Through our\nproposed framework REIGN, we take several steps to remedy this restricted\nlearning setup. First, we systematically generate reformulations of training\nquestions to increase robustness of models to surface form variations. This is\na particularly challenging problem, given the incomplete nature of such\nquestions. Second, we guide ConvQA models towards higher performance by feeding\nit only those reformulations that help improve their answering quality, using\ndeep reinforcement learning. Third, we demonstrate the viability of training\nmajor model components on one benchmark and applying them zero-shot to another.\nFinally, for a rigorous evaluation of robustness for trained models, we use and\nrelease large numbers of diverse reformulations generated by prompting GPT for\nbenchmark test sets (resulting in 20x increase in sizes). Our findings show\nthat ConvQA models with robust training via reformulations, significantly\noutperform those with standard training from gold QA pairs only.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaiser_M/0/1/0/all/0/1\">Magdalena Kaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rishiraj Saha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikum_G/0/1/0/all/0/1\">Gerhard Weikum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing Retrieval-augmented Reader Models via Token Elimination. (arXiv:2310.13682v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13682","description":"<p>Fusion-in-Decoder (FiD) is an effective retrieval-augmented language model\napplied across a variety of open-domain tasks, such as question answering, fact\nchecking, etc. In FiD, supporting passages are first retrieved and then\nprocessed using a generative model (Reader), which can cause a significant\nbottleneck in decoding time, particularly with long outputs. In this work, we\nanalyze the contribution and necessity of all the retrieved passages to the\nperformance of reader models, and propose eliminating some of the retrieved\ninformation, at the token level, that might not contribute essential\ninformation to the answer generation process. We demonstrate that our method\ncan reduce run-time by up to 62.2%, with only a 2% reduction in performance,\nand in some cases, even improve the performance results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berchansky_M/0/1/0/all/0/1\">Moshe Berchansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izsak_P/0/1/0/all/0/1\">Peter Izsak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1\">Avi Caciularu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasserblat_M/0/1/0/all/0/1\">Moshe Wasserblat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability. (arXiv:2310.14265v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14265","description":"<p>Neural network models are vulnerable to adversarial examples, and adversarial\ntransferability further increases the risk of adversarial attacks. Current\nmethods based on transferability often rely on substitute models, which can be\nimpractical and costly in real-world scenarios due to the unavailability of\ntraining data and the victim model's structural details. In this paper, we\npropose a novel approach that directly constructs adversarial examples by\nextracting transferable features across various tasks. Our key insight is that\nadversarial transferability can extend across different tasks. Specifically, we\ntrain a sequence-to-sequence generative model named CT-GAT using adversarial\nsample data collected from multiple tasks to acquire universal adversarial\nfeatures and generate adversarial examples for different tasks. We conduct\nexperiments on ten distinct datasets, and the results demonstrate that our\nmethod achieves superior attack performance with small cost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lv_M/0/1/0/all/0/1\">Minxuan Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_C/0/1/0/all/0/1\">Chengwei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songlin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TRAMS: Training-free Memory Selection for Long-range Language Modeling. (arXiv:2310.15494v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15494","description":"<p>The Transformer architecture is crucial for numerous AI models, but it still\nfaces challenges in long-range language modeling. Though several specific\ntransformer architectures have been designed to tackle issues of long-range\ndependencies, existing methods like Transformer-XL are plagued by a high\npercentage of ineffective memories. In this study, we present a plug-and-play\nstrategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens\nparticipating in attention calculation based on one simple metric. This\nstrategy allows us to keep tokens that are likely to have a high attention\nscore with the current queries and ignore the other ones. We have tested our\napproach on the word-level benchmark (WikiText-103) and the character-level\nbenchmark (enwik8), and the results indicate an improvement without having\nadditional training or adding additional parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haofei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GlotLID: Language Identification for Low-Resource Languages. (arXiv:2310.16248v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16248","description":"<p>Several recent papers have published good solutions for language\nidentification (LID) for about 300 high-resource and medium-resource languages.\nHowever, there is no LID available that (i) covers a wide range of low-resource\nlanguages, (ii) is rigorously evaluated and reliable and (iii) efficient and\neasy to use. Here, we publish GlotLID-M, an LID model that satisfies the\ndesiderata of wide coverage, reliability and efficiency. It identifies 1665\nlanguages, a large increase in coverage compared to prior work. In our\nexperiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and\nNLLB) when balancing F1 and false positive rate (FPR). We analyze the unique\nchallenges that low-resource LID poses: incorrect corpus metadata, leakage from\nhigh-resource languages, difficulty separating closely related languages,\nhandling of macrolanguage vs varieties and in general noisy data. We hope that\nintegrating GlotLID-M into dataset creation pipelines will improve quality and\nenhance accessibility of NLP technology for low-resource languages and\ncultures. GlotLID-M model, code, and list of data sources are available:\nhttps://github.com/cisnlp/GlotLID.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kargaran_A/0/1/0/all/0/1\">Amir Hossein Kargaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imani_A/0/1/0/all/0/1\">Ayyoob Imani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1\">Fran&#xe7;ois Yvon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing & Attribution in AI. (arXiv:2310.16787v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16787","description":"<p>The race to train language models on vast, diverse, and inconsistently\ndocumented datasets has raised pressing concerns about the legal and ethical\nrisks for practitioners. To remedy these practices threatening data\ntransparency and understanding, we convene a multi-disciplinary effort between\nlegal and machine learning experts to systematically audit and trace 1800+ text\ndatasets. We develop tools and standards to trace the lineage of these\ndatasets, from their source, creators, series of license conditions,\nproperties, and subsequent use. Our landscape analysis highlights the sharp\ndivides in composition and focus of commercially open vs closed datasets, with\nclosed datasets monopolizing important categories: lower resource languages,\nmore creative tasks, richer topic variety, newer and more synthetic training\ndata. This points to a deepening divide in the types of data that are made\navailable under different license conditions, and heightened implications for\njurisdictional legal interpretations of copyright and fair use. We also observe\nfrequent miscategorization of licenses on widely used dataset hosting sites,\nwith license omission of 70%+ and error rates of 50%+. This points to a crisis\nin misattribution and informed use of the most popular datasets driving many\nrecent breakthroughs. As a contribution to ongoing improvements in dataset\ntransparency and responsible use, we release our entire audit, with an\ninteractive UI, the Data Provenance Explorer, which allows practitioners to\ntrace and filter on data provenance for the most popular open source finetuning\ndata collections: www.dataprovenance.org.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Longpre_S/0/1/0/all/0/1\">Shayne Longpre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahari_R/0/1/0/all/0/1\">Robert Mahari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anthony Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Obeng_Marnu_N/0/1/0/all/0/1\">Naana Obeng-Marnu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sileo_D/0/1/0/all/0/1\">Damien Sileo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brannon_W/0/1/0/all/0/1\">William Brannon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muennighoff_N/0/1/0/all/0/1\">Niklas Muennighoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khazam_N/0/1/0/all/0/1\">Nathan Khazam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabbara_J/0/1/0/all/0/1\">Jad Kabbara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perisetla_K/0/1/0/all/0/1\">Kartik Perisetla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shippole_E/0/1/0/all/0/1\">Enrico Shippole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollacker_K/0/1/0/all/0/1\">Kurt Bollacker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Villa_L/0/1/0/all/0/1\">Luis Villa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pentland_S/0/1/0/all/0/1\">Sandy Pentland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers. (arXiv:2310.17369v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.17369","description":"<p>Research in psychopathology has shown that, at an aggregate level, the\npatterns of emotional change over time -- emotion dynamics -- are indicators of\none's mental health. One's patterns of emotion change have traditionally been\ndetermined through self-reports of emotions; however, there are known issues\nwith accuracy, bias, and ease of data collection. Recent approaches to\ndetermining emotion dynamics from one's everyday utterances addresses many of\nthese concerns, but it is not yet known whether these measures of utterance\nemotion dynamics (UED) correlate with mental health diagnoses. Here, for the\nfirst time, we study the relationship between tweet emotion dynamics and mental\nhealth disorders. We find that each of the UED metrics studied varied by the\nuser's self-disclosed diagnosis. For example: average valence was significantly\nhigher (i.e., more positive text) in the control group compared to users with\nADHD, MDD, and PTSD. Valence variability was significantly lower in the control\ngroup compared to ADHD, depression, bipolar disorder, MDD, PTSD, and OCD but\nnot PPD. Rise and recovery rates of valence also exhibited significant\ndifferences from the control. This work provides important early evidence for\nhow linguistic cues pertaining to emotion dynamics can play a crucial role as\nbiosocial markers for mental illnesses and aid in the understanding, diagnosis,\nand management of mental health disorders.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Teodorescu_D/0/1/0/all/0/1\">Daniela Teodorescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_T/0/1/0/all/0/1\">Tiffany Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fyshe_A/0/1/0/all/0/1\">Alona Fyshe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs. (arXiv:2310.18152v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18152","description":"<p>Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs\nsuch as citation networks, e-commerce networks and social networks has\nattracted considerable attention in the web community. Recently, large language\nmodels (LLMs) have demonstrated exceptional capabilities across a wide range of\ntasks. However, the existing works focus on harnessing the potential of LLMs\nsolely relying on prompts to convey graph structure information to LLMs, thus\nsuffering from insufficient understanding of the complex structural\nrelationships within TAGs. To address this problem, in this paper we present\nthe Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the\nreasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model\nincorporates graph structure information through tailored disentangled graph\nneural network (GNN) layers, enabling LLMs to capture the intricate\nrelationships hidden in text-attributed graphs from multiple structural\nfactors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing\ncomputational costs and allowing much more flexibility in combining with\ndifferent LLM models. Experimental evaluations demonstrate the effectiveness of\nthe proposed DGTL model on achieving superior or comparable performance over\nstate-of-the-art baselines. Additionally, we also demonstrate that our DGTL\nmodel can offer natural language explanations for predictions, thereby\nsignificantly enhancing model interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yijian Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenwu Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models. (arXiv:2310.18208v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18208","description":"<p>Existing deep-learning approaches to semantic column type annotation (CTA)\nhave important shortcomings: they rely on semantic types which are fixed at\ntraining time; require a large number of training samples per type and incur\nlarge run-time inference costs; and their performance can degrade when\nevaluated on novel datasets, even when types remain constant. Large language\nmodels have exhibited strong zero-shot classification performance on a wide\nrange of tasks and in this paper we explore their use for CTA. We introduce\nArcheType, a simple, practical method for context sampling, prompt\nserialization, model querying, and label remapping, which enables large\nlanguage models to solve CTA problems in a fully zero-shot manner. We ablate\neach component of our method separately, and establish that improvements to\ncontext sampling and label remapping provide the most consistent gains.\nArcheType establishes a new state-of-the-art performance on zero-shot CTA\nbenchmarks (including three new domain-specific benchmarks which we release\nalong with this paper), and when used in conjunction with classical CTA\ntechniques, it outperforms a SOTA DoDuo model on the fine-tuned SOTAB\nbenchmark. Our code is available at https://github.com/penfever/ArcheType.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feuer_B/0/1/0/all/0/1\">Benjamin Feuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yurong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hegde_C/0/1/0/all/0/1\">Chinmay Hegde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freire_J/0/1/0/all/0/1\">Juliana Freire</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PHD: Pixel-Based Language Modeling of Historical Documents. (arXiv:2310.18343v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18343","description":"<p>The digitisation of historical documents has provided historians with\nunprecedented research opportunities. Yet, the conventional approach to\nanalysing historical documents involves converting them from images to text\nusing OCR, a process that overlooks the potential benefits of treating them as\nimages and introduces high levels of noise. To bridge this gap, we take\nadvantage of recent advancements in pixel-based language models trained to\nreconstruct masked patches of pixels instead of predicting token distributions.\nDue to the scarcity of real historical scans, we propose a novel method for\ngenerating synthetic scans to resemble real historical documents. We then\npre-train our model, PHD, on a combination of synthetic scans and real\nhistorical newspapers from the 1700-1900 period. Through our experiments, we\ndemonstrate that PHD exhibits high proficiency in reconstructing masked image\npatches and provide evidence of our model's noteworthy language understanding\ncapabilities. Notably, we successfully apply our model to a historical QA task,\nhighlighting its usefulness in this domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Borenstein_N/0/1/0/all/0/1\">Nadav Borenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rust_P/0/1/0/all/0/1\">Phillip Rust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elliott_D/0/1/0/all/0/1\">Desmond Elliott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Building Real-World Meeting Summarization Systems using Large Language Models: A Practical Perspective. (arXiv:2310.19233v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19233","description":"<p>This paper studies how to effectively build meeting summarization systems for\nreal-world usage using large language models (LLMs). For this purpose, we\nconduct an extensive evaluation and comparison of various closed-source and\nopen-source LLMs, namely, GPT-4, GPT- 3.5, PaLM-2, and LLaMA-2. Our findings\nreveal that most closed-source LLMs are generally better in terms of\nperformance. However, much smaller open-source models like LLaMA- 2 (7B and\n13B) could still achieve performance comparable to the large closed-source\nmodels even in zero-shot scenarios. Considering the privacy concerns of\nclosed-source models for only being accessible via API, alongside the high cost\nassociated with using fine-tuned versions of the closed-source models, the\nopensource models that can achieve competitive performance are more\nadvantageous for industrial use. Balancing performance with associated costs\nand privacy concerns, the LLaMA-2-7B model looks more promising for industrial\nusage. In sum, this paper offers practical insights on using LLMs for\nreal-world business meeting summarization, shedding light on the trade-offs\nbetween performance and cost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1\">Md Tahmid Rahman Laskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1\">Xue-Yong Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+TN_S/0/1/0/all/0/1\">Shashi Bhushan TN</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing. (arXiv:2310.19975v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19975","description":"<p>To enhance the performance of large language models (LLMs) in biomedical\nnatural language processing (BioNLP) by introducing a domain-specific\ninstruction dataset and examining its impact when combined with multi-task\nlearning principles. We created the BioInstruct, comprising 25,005 instructions\nto instruction-tune LLMs(LLaMA 1 &amp; 2, 7B &amp; 13B version). The instructions were\ncreated by prompting the GPT-4 language model with three-seed samples randomly\ndrawn from an 80 human curated instructions. We employed Low-Rank\nAdaptation(LoRA) for parameter-efficient fine-tuning. We then evaluated these\ninstruction-tuned LLMs on several BioNLP tasks, which can be grouped into three\nmajor categories: question answering(QA), information extraction(IE), and text\ngeneration(GEN). We also examined whether categories(e.g., QA, IE, and\ngeneration) of instructions impact model performance. Comparing with LLMs\nwithout instruction-tuned, our instruction-tuned LLMs demonstrated marked\nperformance gains: 17.3% in QA, 5.7% in IE, and 96% in Generation tasks. Our\n7B-parameter instruction-tuned LLaMA 1 model was competitive or even surpassed\nother LLMs in the biomedical domain that were also fine-tuned from LLaMA 1 with\nvast domain-specific data or a variety of tasks. Our results also show that the\nperformance gain is significantly higher when instruction fine-tuning is\nconducted with closely related tasks. Our findings align with the observations\nof multi-task learning, suggesting the synergies between two tasks. The\nBioInstruct dataset serves as a valuable resource and instruction tuned LLMs\nlead to the best performing BioNLP applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hieu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.20195","description":"<p>The ability to process idiomatic or literal multiword expressions is a\ncrucial aspect of understanding and generating any language. The task of\ngenerating contextually relevant continuations for narratives containing\nidiomatic (or literal) expressions can allow us to test the ability of\ngenerative language models (LMs) in understanding nuanced language containing\nnon-compositional figurative text. We conduct a series of experiments using\ndatasets in two distinct languages (English and Portuguese) under three\ndifferent training settings (zero-shot, few-shot, and fine-tuned). Our results\nsuggest that the models are only slightly better at generating continuations\nfor literal contexts than idiomatic contexts, with exceedingly small margins.\nFurthermore, the models studied in this work perform equally well across both\nlanguages, indicating the robustness of generative models in performing this\ntask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pokharel_R/0/1/0/all/0/1\">Rhitabrat Pokharel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Ameeta Agrawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection. (arXiv:2310.20256v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.20256","description":"<p>Recent advances in large language models (LLMs), such as ChatGPT, have\nshowcased remarkable zero-shot performance across various NLP tasks. However,\nthe potential of LLMs in personality detection, which involves identifying an\nindividual's personality from their written texts, remains largely unexplored.\nDrawing inspiration from Psychological Questionnaires, which are carefully\ndesigned by psychologists to evaluate individual personality traits through a\nseries of targeted items, we argue that these items can be regarded as a\ncollection of well-structured chain-of-thought (CoT) processes. By\nincorporating these processes, LLMs can enhance their capabilities to make more\nreasonable inferences on personality from textual input. In light of this, we\npropose a novel personality detection method, called PsyCoT, which mimics the\nway individuals complete psychological questionnaires in a multi-turn dialogue\nmanner. In particular, we employ a LLM as an AI assistant with a specialization\nin text analysis. We prompt the assistant to rate individual items at each turn\nand leverage the historical rating results to derive a conclusive personality\npreference. Our experiments demonstrate that PsyCoT significantly improves the\nperformance and robustness of GPT-3.5 in personality detection, achieving an\naverage F1 score improvement of 4.23/10.63 points on two benchmark datasets\ncompared to the standard prompting method. Our code is available at\nhttps://github.com/TaoYang225/PsyCoT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1\">Tianyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bingzhe Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiaxiang Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Word Guessing Games to Assess the Intelligence of Large Language Models. (arXiv:2310.20499v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.20499","description":"<p>The automatic evaluation of LLM-based agent intelligence is critical in\ndeveloping advanced LLM-based agents. Although considerable effort has been\ndevoted to developing human-annotated evaluation datasets, such as AlpacaEval,\nexisting techniques are costly, time-consuming, and lack adaptability. In this\npaper, inspired by the popular language game ``Who is Spy'', we propose to use\nthe word guessing game to assess the intelligence performance of LLMs. Given a\nword, the LLM is asked to describe the word and determine its identity (spy or\nnot) based on its and other players' descriptions. Ideally, an advanced agent\nshould possess the ability to accurately describe a given word using an\naggressive description while concurrently maximizing confusion in the\nconservative description, enhancing its participation in the game. To this end,\nwe first develop DEEP to evaluate LLMs' expression and disguising abilities.\nDEEP requires LLM to describe a word in aggressive and conservative modes. We\nthen introduce SpyGame, an interactive multi-agent framework designed to assess\nLLMs' intelligence through participation in a competitive language-based board\ngame. Incorporating multi-agent interaction, SpyGame requires the target LLM to\npossess linguistic skills and strategic thinking, providing a more\ncomprehensive evaluation of LLMs' human-like cognitive abilities and\nadaptability in complex communication situations. The proposed evaluation\nframework is very easy to implement. We collected words from multiple sources,\ndomains, and languages and used the proposed evaluation framework to conduct\nexperiments. Extensive experiments demonstrate that the proposed DEEP and\nSpyGame effectively evaluate the capabilities of various LLMs, capturing their\nability to adapt to novel situations and engage in strategic communication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1\">Tian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jen-tse Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Support or Refute: Analyzing the Stance of Evidence to Detect Out-of-Context Mis- and Disinformation. (arXiv:2311.01766v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.01766","description":"<p>Mis- and disinformation online have become a major societal problem as major\nsources of online harms of different kinds. One common form of mis- and\ndisinformation is out-of-context (OOC) information, where different pieces of\ninformation are falsely associated, e.g., a real image combined with a false\ntextual caption or a misleading textual description. Although some past studies\nhave attempted to defend against OOC mis- and disinformation through external\nevidence, they tend to disregard the role of different pieces of evidence with\ndifferent stances. Motivated by the intuition that the stance of evidence\nrepresents a bias towards different detection results, we propose a stance\nextraction network (SEN) that can extract the stances of different pieces of\nmulti-modal evidence in a unified framework. Moreover, we introduce a\nsupport-refutation score calculated based on the co-occurrence relations of\nnamed entities into the textual SEN. Extensive experiments on a public\nlarge-scale dataset demonstrated that our proposed method outperformed the\nstate-of-the-art baselines, with the best model achieving a performance gain of\n3.2% in accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1\">Weidong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models to the Rescue: Reducing the Complexity in Scientific Workflow Development Using ChatGPT. (arXiv:2311.01825v2 [cs.DC] UPDATED)","link":"http://arxiv.org/abs/2311.01825","description":"<p>Scientific workflow systems are increasingly popular for expressing and\nexecuting complex data analysis pipelines over large datasets, as they offer\nreproducibility, dependability, and scalability of analyses by automatic\nparallelization on large compute clusters. However, implementing workflows is\ndifficult due to the involvement of many black-box tools and the deep\ninfrastructure stack necessary for their execution. Simultaneously,\nuser-supporting tools are rare, and the number of available examples is much\nlower than in classical programming languages. To address these challenges, we\ninvestigate the efficiency of Large Language Models (LLMs), specifically\nChatGPT, to support users when dealing with scientific workflows. We performed\nthree user studies in two scientific domains to evaluate ChatGPT for\ncomprehending, adapting, and extending workflows. Our results indicate that\nLLMs efficiently interpret workflows but achieve lower performance for\nexchanging components or purposeful workflow extensions. We characterize their\nlimitations in these challenging scenarios and suggest future research\ndirections.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sanger_M/0/1/0/all/0/1\">Mario S&#xe4;nger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mecquenem_N/0/1/0/all/0/1\">Ninon De Mecquenem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewinska_K/0/1/0/all/0/1\">Katarzyna Ewa Lewi&#x144;ska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bountris_V/0/1/0/all/0/1\">Vasilis Bountris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehmann_F/0/1/0/all/0/1\">Fabian Lehmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leser_U/0/1/0/all/0/1\">Ulf Leser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosch_T/0/1/0/all/0/1\">Thomas Kosch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-11-06T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}