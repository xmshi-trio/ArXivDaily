{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-05-24T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"A Novel Dataset Towards Extracting Virus-Host Interactions. (arXiv:2305.13317v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13317","description":"<p>We describe a novel dataset for the automated recognition of named taxonomic\nand other entities relevant to the association of viruses with their hosts. We\nfurther describe some initial results using pre-trained models on the\nnamed-entity recognition (NER) task on this novel dataset. We propose that our\ndataset of manually annotated abstracts now offers a Gold Standard Corpus for\ntraining future NER models in the automated extraction of host-pathogen\ndetection methods from scientific publications, and further explain how our\nwork makes first steps towards predicting the important human health-related\nconcept of viral spillover risk automatically from the scientific literature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alshawi_R/0/1/0/all/0/1\">Rasha Alshawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1\">Atriya Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Upham_N/0/1/0/all/0/1\">Nathan S. Upham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sterner_B/0/1/0/all/0/1\">Beckett Sterner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised ASR via Cross-Lingual Pseudo-Labeling. (arXiv:2305.13330v1 [eess.AS])","link":"http://arxiv.org/abs/2305.13330","description":"<p>Recent work has shown that it is possible to train an $\\textit{unsupervised}$\nautomatic speech recognition (ASR) system using only unpaired audio and text.\nExisting unsupervised ASR methods assume that no labeled data can be used for\ntraining. We argue that even if one does not have any labeled audio for a given\nlanguage, there is $\\textit{always}$ labeled data available for other\nlanguages. We show that it is possible to use character-level acoustic models\n(AMs) from other languages to bootstrap an $\\textit{unsupervised}$ AM in a new\nlanguage. Here, \"unsupervised\" means no labeled audio is available for the\n$\\textit{target}$ language. Our approach is based on two key ingredients: (i)\ngenerating pseudo-labels (PLs) of the $\\textit{target}$ language using some\n$\\textit{other}$ language AM and (ii) constraining these PLs with a\n$\\textit{target language model}$. Our approach is effective on Common Voice:\ne.g. transfer of English AM to Swahili achieves 18% WER. It also outperforms\ncharacter-based wav2vec-U 2.0 by 15% absolute WER on LJSpeech with 800h of\nlabeled German data instead of 60k hours of unlabeled English data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lugosch_L/0/1/0/all/0/1\">Loren Lugosch</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Collobert_R/0/1/0/all/0/1\">Ronan Collobert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning. (arXiv:2305.13331v1 [eess.AS])","link":"http://arxiv.org/abs/2305.13331","description":"<p>Aphasia is a language disorder that affects the speaking ability of millions\nof patients. This paper presents a new benchmark for Aphasia speech recognition\nand detection tasks using state-of-the-art speech recognition techniques with\nthe AphsiaBank dataset. Specifically, we introduce two multi-task learning\nmethods based on the CTC/Attention architecture to perform both tasks\nsimultaneously. Our system achieves state-of-the-art speaker-level detection\naccuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia\npatients. In addition, we demonstrate the generalizability of our approach by\napplying it to another disordered speech database, the DementiaBank Pitt\ncorpus. We will make our all-in-one recipes and pre-trained model publicly\navailable to facilitate reproducibility. Our standardized data preprocessing\npipeline and open-source recipes enable researchers to compare results\ndirectly, promoting progress in disordered speech processing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Tang_J/0/1/0/all/0/1\">Jiyang Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1\">William Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_X/0/1/0/all/0/1\">Xuankai Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/eess/1/au:+MacWhinney_B/0/1/0/all/0/1\">Brian MacWhinney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gene Set Summarization using Large Language Models. (arXiv:2305.13338v1 [q-bio.GN])","link":"http://arxiv.org/abs/2305.13338","description":"<p>Molecular biologists frequently interpret gene lists derived from\nhigh-throughput experiments and computational analysis. This is typically done\nas a statistical enrichment analysis that measures the over- or\nunder-representation of biological function terms associated with genes or\ntheir properties, based on curated assertions from a knowledge base (KB) such\nas the Gene Ontology (GO). Interpreting gene lists can also be framed as a\ntextual summarization task, enabling the use of Large Language Models (LLMs),\npotentially utilizing scientific texts directly and avoiding reliance on a KB.\n</p>\n<p>We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language\nDescriptions of Controlled Terms for Ontology Reporting), a method that uses\nGPT models to perform gene set function summarization as a complement to\nstandard enrichment analysis. This method can use different sources of gene\nfunctional information: (1) structured text derived from curated ontological KB\nannotations, (2) ontology-free narrative gene summaries, or (3) direct model\nretrieval.\n</p>\n<p>We demonstrate that these methods are able to generate plausible and\nbiologically valid summary GO term lists for gene sets. However, GPT-based\napproaches are unable to deliver reliable scores or p-values and often return\nterms that are not statistically significant. Crucially, these methods were\nrarely able to recapitulate the most precise and informative term from standard\nenrichment, likely due to an inability to generalize and reason using an\nontology. Results are highly nondeterministic, with minor variations in prompt\nresulting in radically different term lists. Our results show that at this\npoint, LLM-based methods are unsuitable as a replacement for standard term\nenrichment analysis and that manual curation of ontological assertions remains\nnecessary.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Joachimiak_M/0/1/0/all/0/1\">Marcin P. Joachimiak</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Caufield_J/0/1/0/all/0/1\">J. Harry Caufield</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Harris_N/0/1/0/all/0/1\">Nomi Harris</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Mungall_C/0/1/0/all/0/1\">Christopher J. Mungall</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Limitations of Simulating Active Learning. (arXiv:2305.13342v1 [cs.LG])","link":"http://arxiv.org/abs/2305.13342","description":"<p>Active learning (AL) is a human-and-model-in-the-loop paradigm that\niteratively selects informative unlabeled data for human annotation, aiming to\nimprove over random sampling. However, performing AL experiments with human\nannotations on-the-fly is a laborious and expensive process, thus unrealistic\nfor academic research. An easy fix to this impediment is to simulate AL, by\ntreating an already labeled and publicly available dataset as the pool of\nunlabeled data. In this position paper, we first survey recent literature and\nhighlight the challenges across all different steps within the AL loop. We\nfurther unveil neglected caveats in the experimental setup that can\nsignificantly affect the quality of AL research. We continue with an\nexploration of how the simulation setting can govern empirical findings,\narguing that it might be one of the answers behind the ever posed question\n``why do active learning algorithms sometimes fail to outperform random\nsampling?''. We argue that evaluating AL algorithms on available labeled\ndatasets might provide a lower bound as to their effectiveness in real data. We\nbelieve it is essential to collectively shape the best practices for AL\nresearch, particularly as engineering advancements in LLMs push the research\nfocus towards data-driven approaches (e.g., data efficiency, alignment,\nfairness). In light of this, we have developed guidelines for future work. Our\naim is to draw attention to these limitations within the community, in the hope\nof finding ways to address them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Margatina_K/0/1/0/all/0/1\">Katerina Margatina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can LLMs facilitate interpretation of pre-trained language models?. (arXiv:2305.13386v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13386","description":"<p>Work done to uncover the knowledge encoded within pre-trained language\nmodels, rely on annotated corpora or human-in-the-loop methods. However, these\napproaches are limited in terms of scalability and the scope of interpretation.\nWe propose using a large language model, ChatGPT, as an annotator to enable\nfine-grained interpretation analysis of pre-trained language models. We\ndiscover latent concepts within pre-trained language models by applying\nhierarchical clustering over contextualized representations and then annotate\nthese concepts using GPT annotations. Our findings demonstrate that ChatGPT\nproduces accurate and semantically richer annotations compared to\nhuman-annotated concepts. Additionally, we showcase how GPT-based annotations\nempower interpretation analysis methodologies of which we demonstrate two:\nprobing framework and neuron interpretation. To facilitate further exploration\nand experimentation in this field, we have made available a substantial\nConceptNet dataset comprising 39,000 annotated latent concepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mousi_B/0/1/0/all/0/1\">Basel Mousi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The neural dynamics of auditory word recognition and integration. (arXiv:2305.13388v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13388","description":"<p>Listeners recognize and integrate words in rapid and noisy everyday speech by\ncombining expectations about upcoming content with incremental sensory\nevidence. We present a computational model of word recognition which formalizes\nthis perceptual process in Bayesian decision theory. We fit this model to\nexplain scalp EEG signals recorded as subjects passively listened to a\nfictional story, revealing both the dynamics of the online auditory word\nrecognition process and the neural correlates of the recognition and\nintegration of words.\n</p>\n<p>The model reveals distinct neural processing of words depending on whether or\nnot they can be quickly recognized. While all words trigger a neural response\ncharacteristic of probabilistic integration -- voltage modulations predicted by\na word's surprisal in context -- these modulations are amplified for words\nwhich require more than roughly 100 ms of input to be recognized. We observe no\ndifference in the latency of these neural responses according to words'\nrecognition times.Our results support a two-part model of speech comprehension,\ncombining an eager and rapid process of word recognition with a temporally\nindependent process of word integration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gauthier_J/0/1/0/all/0/1\">Jon Gauthier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1\">Roger Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance. (arXiv:2305.13395v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13395","description":"<p>Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical\nliterature is paramount for public safety, but involves slow and costly manual\nlabor. We set out to improve drug safety monitoring (pharmacovigilance, PV)\nthrough the use of Natural Language Processing (NLP). We introduce BioDEX, a\nlarge-scale resource for Biomedical adverse Drug Event Extraction, rooted in\nthe historical output of drug safety reporting in the U.S. BioDEX consists of\n65k abstracts and 19k full-text biomedical papers with 256k associated\ndocument-level safety reports created by medical experts. The core features of\nthese reports include the reported weight, age, and biological sex of a\npatient, a set of drugs taken by the patient, the drug dosages, the reactions\nexperienced, and whether the reaction was life threatening. In this work, we\nconsider the task of predicting the core information of the report given its\noriginating paper. We estimate human performance to be 72.0% F1, whereas our\nbest model achieves 62.3% F1, indicating significant headroom on this task. We\nalso begin to explore ways in which these models could help professional PV\nreviewers. Our code and data are available: https://github.com/KarelDO/BioDEX.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DOosterlinck_K/0/1/0/all/0/1\">Karel D&#x27;Oosterlinck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Remy_F/0/1/0/all/0/1\">Fran&#xe7;ois Remy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1\">Johannes Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaporojets_K/0/1/0/all/0/1\">Klim Zaporojets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Aneiss Ghodsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellershaw_S/0/1/0/all/0/1\">Simon Ellershaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_J/0/1/0/all/0/1\">Jack Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A study of conceptual language similarity: comparison and evaluation. (arXiv:2305.13401v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13401","description":"<p>An interesting line of research in natural language processing (NLP) aims to\nincorporate linguistic typology to bridge linguistic diversity and assist the\nresearch of low-resource languages. While most works construct linguistic\nsimilarity measures based on lexical or typological features, such as word\norder and verbal inflection, recent work has introduced a novel approach to\ndefining language similarity based on how they represent basic concepts, which\nis complementary to existing similarity measures. In this work, we study the\nconceptual similarity in detail and evaluate it extensively on a binary\nclassification task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GATology for Linguistics: What Syntactic Dependencies It Knows. (arXiv:2305.13403v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13403","description":"<p>Graph Attention Network (GAT) is a graph neural network which is one of the\nstrategies for modeling and representing explicit syntactic knowledge and can\nwork with pre-trained models, such as BERT, in downstream tasks. Currently,\nthere is still a lack of investigation into how GAT learns syntactic knowledge\nfrom the perspective of model structure. As one of the strategies for modeling\nexplicit syntactic knowledge, GAT and BERT have never been applied and\ndiscussed in Machine Translation (MT) scenarios. We design a dependency\nrelation prediction task to study how GAT learns syntactic knowledge of three\nlanguages as a function of the number of attention heads and layers. We also\nuse a paired t-test and F1-score to clarify the differences in syntactic\ndependency prediction between GAT and BERT fine-tuned by the MT task (MT-B).\nThe experiments show that better performance can be achieved by appropriately\nincreasing the number of attention heads with two GAT layers. With more than\ntwo layers, learning suffers. Moreover, GAT is more competitive in training\nspeed and syntactic dependency prediction than MT-B, which may reveal a better\nincorporation of modeling explicit syntactic knowledge and the possibility of\ncombining GAT and BERT in the MT tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yuqian Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharoff_S/0/1/0/all/0/1\">Serge Sharoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamps_M/0/1/0/all/0/1\">Marc de Kamps</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules. (arXiv:2305.13406v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13406","description":"<p>Existing large language models (LLMs) that mainly focus on Standard American\nEnglish (SAE) often lead to significantly worse performance when being applied\nto other English dialects. While existing mitigations tackle discrepancies for\nindividual target dialects, they assume access to high-accuracy dialect\nidentification systems. The boundaries between dialects are inherently\nflexible, making it difficult to categorize language into discrete predefined\ncategories. In this paper, we propose DADA (Dialect Adaptation via Dynamic\nAggregation), a modular approach to imbue SAE-trained models with\nmulti-dialectal robustness by composing adapters which handle specific\nlinguistic features. The compositional architecture of DADA allows for both\ntargeted adaptation to specific dialect variants and simultaneous adaptation to\nvarious dialects. We show that DADA is effective for both single task and\ninstruction finetuned language models, offering an extensible and interpretable\nframework for adapting existing LLMs to different English dialects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_W/0/1/0/all/0/1\">William Held</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modular Domain Adaptation for Conformer-Based Streaming ASR. (arXiv:2305.13408v1 [eess.AS])","link":"http://arxiv.org/abs/2305.13408","description":"<p>Speech data from different domains has distinct acoustic and linguistic\ncharacteristics. It is common to train a single multidomain model such as a\nConformer transducer for speech recognition on a mixture of data from all\ndomains. However, changing data in one domain or adding a new domain would\nrequire the multidomain model to be retrained. To this end, we propose a\nframework called modular domain adaptation (MDA) that enables a single model to\nprocess multidomain data while keeping all parameters domain-specific, i.e.,\neach parameter is only trained by data from one domain. On a streaming\nConformer transducer trained only on video caption data, experimental results\nshow that an MDA-based model can reach similar performance as the multidomain\nmodel on other domains such as voice search and dictation by adding per-domain\nadapters and per-domain feed-forward networks in the Conformer encoder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1\">Qiujia Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hwang_D/0/1/0/all/0/1\">Dongseong Hwang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sainath_T/0/1/0/all/0/1\">Tara N. Sainath</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mengibar_P/0/1/0/all/0/1\">Pedro M. Mengibar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Element-aware Summarization with Large Language Models: Expert-aligned Evaluation and Chain-of-Thought Method. (arXiv:2305.13412v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13412","description":"<p>Automatic summarization generates concise summaries that contain key ideas of\nsource documents. As the most mainstream datasets for the news sub-domain,\nCNN/DailyMail and BBC XSum have been widely used for performance benchmarking.\nHowever, the reference summaries of those datasets turn out to be noisy, mainly\nin terms of factual hallucination and information redundancy. To address this\nchallenge, we first annotate new expert-writing Element-aware test sets\nfollowing the \"Lasswell Communication Model\" proposed by Lasswell (1948),\nallowing reference summaries to focus on more fine-grained news elements\nobjectively and comprehensively. Utilizing the new test sets, we observe the\nsurprising zero-shot summary ability of LLMs, which addresses the issue of the\ninconsistent results between human preference and automatic evaluation metrics\nof LLMs' zero-shot summaries in prior work. Further, we propose a Summary\nChain-of-Thought (SumCoT) technique to elicit LLMs to generate summaries step\nby step, which helps them integrate more fine-grained details of source\ndocuments into the final summaries that correlate with the human writing\nmindset. Experimental results show our method outperforms state-of-the-art\nfine-tuned PLMs and zero-shot LLMs by +4.33/+4.77 in ROUGE-L on the two\ndatasets, respectively. Dataset and code are publicly available at\nhttps://github.com/Alsace08/SumCoT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntactic Knowledge via Graph Attention with BERT in Machine Translation. (arXiv:2305.13413v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13413","description":"<p>Although the Transformer model can effectively acquire context features via a\nself-attention mechanism, deeper syntactic knowledge is still not effectively\nmodeled. To alleviate the above problem, we propose Syntactic knowledge via\nGraph attention with BERT (SGB) in Machine Translation (MT) scenarios. Graph\nAttention Network (GAT) and BERT jointly represent syntactic dependency feature\nas explicit knowledge of the source language to enrich source language\nrepresentations and guide target language generation. Our experiments use gold\nsyntax-annotation sentences and Quality Estimation (QE) model to obtain\ninterpretability of translation quality improvement regarding syntactic\nknowledge without being limited to a BLEU score. Experiments show that the\nproposed SGB engines improve translation quality across the three MT tasks\nwithout sacrificing BLEU scores. We investigate what length of source sentences\nbenefits the most and what dependencies are better identified by the SGB\nengines. We also find that learning of specific dependency relations by GAT can\nbe reflected in the translation quality containing such relations and that\nsyntax on the graph leads to new modeling of syntactic aspects of source\nsentences in the middle and bottom layers of BERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yuqian Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharoff_S/0/1/0/all/0/1\">Serge Sharoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamps_M/0/1/0/all/0/1\">Marc de Kamps</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpreting Transformer's Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT. (arXiv:2305.13417v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13417","description":"<p>Recent advances in interpretability suggest we can project weights and hidden\nstates of transformer-based language models (LMs) to their vocabulary, a\ntransformation that makes them human interpretable and enables us to assign\nsemantics to what was seen only as numerical vectors. In this paper, we\ninterpret LM attention heads and memory values, the vectors the models\ndynamically create and recall while processing a given input. By analyzing the\ntokens they represent through this projection, we identify patterns in the\ninformation flow inside the attention mechanism. Based on these discoveries, we\ncreate a tool to visualize a forward pass of Generative Pre-trained\nTransformers (GPTs) as an interactive flow graph, with nodes representing\nneurons or hidden states and edges representing the interactions between them.\nOur visualization simplifies huge amounts of data into easy-to-read plots that\nreflect why models output their results. We demonstrate the utility of our\nmodeling by identifying the effect LM components have on the intermediate\nprocessing in the model before outputting a prediction. For instance, we\ndiscover that layer norms are used as semantic filters and find neurons that\nact as regularization vectors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Katz_S/0/1/0/all/0/1\">Shahar Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"clembench: Using Game Play to Evaluate Chat-Optimized Language Models as Conversational Agents. (arXiv:2305.13455v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13455","description":"<p>Recent work has proposed a methodology for the systematic evaluation of\n\"Situated Language Understanding Agents\"-agents that operate in rich linguistic\nand non-linguistic contexts-through testing them in carefully constructed\ninteractive settings. Other recent work has argued that Large Language Models\n(LLMs), if suitably set up, can be understood as (simulators of) such agents. A\nconnection suggests itself, which this paper explores: Can LLMs be evaluated\nmeaningfully by exposing them to constrained game-like settings that are built\nto challenge specific capabilities? As a proof of concept, this paper\ninvestigates five interaction settings, showing that current chat-optimised\nLLMs are, to an extent, capable to follow game-play instructions. Both this\ncapability and the quality of the game play, measured by how well the\nobjectives of the different games are met, follows the development cycle, with\nnewer models performing better. The metrics even for the comparatively simple\nexample games are far from being saturated, suggesting that the proposed\ninstrument will remain to have diagnostic value. Our general framework for\nimplementing and evaluating games with LLMs is available at\nhttps://github.com/clp-research/clembench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chalamalasetti_K/0/1/0/all/0/1\">Kranti Chalamalasetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotze_J/0/1/0/all/0/1\">Jana G&#xf6;tze</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1\">Sherzod Hakimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madureira_B/0/1/0/all/0/1\">Brielen Madureira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadler_P/0/1/0/all/0/1\">Philipp Sadler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlangen_D/0/1/0/all/0/1\">David Schlangen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAILEX: Email Event and Argument Extraction. (arXiv:2305.13469v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13469","description":"<p>In this work, we present the first dataset, \\dataset, for performing event\nextraction from conversational email threads. To this end, we first proposed a\nnew taxonomy covering 10 event types and 76 arguments in the email domain. Our\nfinal dataset includes $\\sim$4K emails annotated with $\\sim$9K event instances.\nTo understand the task challenges, we conducted a series of experiments\ncomparing two commonly-seen lines of approaches for event extraction, i.e.,\nsequence labeling and generative end-to-end extraction (including few-shot\nGPT-3.5). Our results showed that the task of email event extraction is far\nfrom being addressed, due to challenges lying in, e.g., extracting\nnon-continuous, shared trigger spans, extracting non-named entity arguments,\nand modeling the email conversational history. Our work thus suggests more\ninvestigations in this domain-specific event extraction task in the\nfuture.\\footnote{The source code and dataset can be obtained from\n\\url{https://github.com/salokr/Email-Event-Extraction}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Saurabh Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gaurav Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_S/0/1/0/all/0/1\">Shou Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raz_A/0/1/0/all/0/1\">Ali Raz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_P/0/1/0/all/0/1\">Paulo Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poore_J/0/1/0/all/0/1\">Joshua Poore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Ziyu Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Look-back Decoding for Open-Ended Text Generation. (arXiv:2305.13477v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13477","description":"<p>Given a prefix (context), open-ended generation aims to decode texts that are\ncoherent, which don't abruptly drift from previous topics, and informative,\nwhich don't suffer from undesired repetitions. In this paper, we propose\nLook-back, an improved decoding algorithm that leverages the Kullback-Leibler\ndivergence to track the distribution distance between current and historical\ndecoding steps. Thus Look-back can automatically predict potential repetitive\nphrase and topic drift, and remove tokens that may cause the failure modes,\nrestricting the next token probability distribution within a plausible distance\nto the history. We perform decoding experiments on document continuation and\nstory generation, and demonstrate that Look-back is able to generate more\nfluent and coherent text, outperforming other strong decoding methods\nsignificantly in both automatic and human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Readability Assessment for Closely Related Languages. (arXiv:2305.13478v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13478","description":"<p>In recent years, the main focus of research on automatic readability\nassessment (ARA) has shifted towards using expensive deep learning-based\nmethods with the primary goal of increasing models' accuracy. This, however, is\nrarely applicable for low-resource languages where traditional handcrafted\nfeatures are still widely used due to the lack of existing NLP tools to extract\ndeeper linguistic representations. In this work, we take a step back from the\ntechnical component and focus on how linguistic aspects such as mutual\nintelligibility or degree of language relatedness can improve ARA in a\nlow-resource setting. We collect short stories written in three languages in\nthe Philippines-Tagalog, Bikol, and Cebuano-to train readability assessment\nmodels and explore the interaction of data and features in various\ncross-lingual setups. Our results show that the inclusion of CrossNGO, a novel\nspecialized feature exploiting n-gram overlap applied to languages with high\nmutual intelligibility, significantly improves the performance of ARA models\ncompared to the use of off-the-shelf large multilingual language models alone.\nConsequently, when both linguistic representations are combined, we achieve\nstate-of-the-art results for Tagalog and Cebuano, and baseline scores for ARA\nin Bikol.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Imperial_J/0/1/0/all/0/1\">Joseph Marvin Imperial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochmar_E/0/1/0/all/0/1\">Ekaterina Kochmar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference. (arXiv:2305.13484v1 [cs.DC])","link":"http://arxiv.org/abs/2305.13484","description":"<p>In the rapidly evolving field of deep learning, the performance of model\ninference has become a pivotal aspect as models become more complex and are\ndeployed in diverse applications. Among these, autoregressive models stand out\ndue to their state-of-the-art performance in numerous generative tasks. These\nmodels, by design, harness a temporal dependency structure, where the current\ntoken's probability distribution is conditioned on preceding tokens. This\ninherently sequential characteristic, however, adheres to the Markov Chain\nassumption and lacks temporal parallelism, which poses unique challenges.\nParticularly in industrial contexts where inference requests, following a\nPoisson time distribution, necessitate diverse response lengths, this absence\nof parallelism is more profound. Existing solutions, such as dynamic batching\nand concurrent model instances, nevertheless, come with severe overheads and a\nlack of flexibility, these coarse-grained methods fall short of achieving\noptimal latency and throughput. To address these shortcomings, we propose\nFlavor -- a temporal fusion framework for efficient inference in autoregressive\nmodels, eliminating the need for heuristic settings and applies to a wide range\nof inference scenarios. By providing more fine-grained parallelism on the\ntemporality of requests and employing an efficient memory shuffle algorithm,\nFlover achieves up to 11x faster inference on GPT models compared to the\ncutting-edge solutions provided by NVIDIA Triton FasterTransformer. Crucially,\nby leveraging the advanced tensor parallel technique, Flover proves efficacious\nacross diverse computational landscapes, from single-GPU setups to multi-node\nscenarios, thereby offering robust performance optimization that transcends\nhardware boundaries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jinghan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alnaasan_N/0/1/0/all/0/1\">Nawras Alnaasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafi_A/0/1/0/all/0/1\">Aamir Shafi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramoni_H/0/1/0/all/0/1\">Hari Subramoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+K%2E_D/0/1/0/all/0/1\">Dhabaleswar K.</a> (DK) <a href=\"http://arxiv.org/find/cs/1/au:+Panda/0/1/0/all/0/1\">Panda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Easily Updated General Purpose Text Representations with Adaptable Task-Specific Prefixes. (arXiv:2305.13499v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13499","description":"<p>Many real-world applications require making multiple predictions from the\nsame text. Fine-tuning a large pre-trained language model for each downstream\ntask causes computational burdens in the inference time due to several times of\nforward passes. To amortize the computational cost, freezing the language model\nand building lightweight models for downstream tasks based on fixed text\nrepresentations are common solutions. Accordingly, how to learn fixed but\ngeneral text representations that can generalize well to unseen downstream\ntasks becomes a challenge. Previous works have shown that the generalizability\nof representations can be improved by fine-tuning the pre-trained language\nmodel with some source tasks in a multi-tasking way. In this work, we propose a\nprefix-based method to learn the fixed text representations with source tasks.\nWe learn a task-specific prefix for each source task independently and combine\nthem to get the final representations. Our experimental results show that\nprefix-based training performs better than multi-tasking training and can\nupdate the text representations at a smaller computational cost than\nmulti-tasking training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Liang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1\">Amjad Almahairi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinott_R/0/1/0/all/0/1\">Ruty Rinott</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural Machine Translation for Code Generation. (arXiv:2305.13504v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13504","description":"<p>Neural machine translation (NMT) methods developed for natural language\nprocessing have been shown to be highly successful in automating translation\nfrom one natural language to another. Recently, these NMT methods have been\nadapted to the generation of program code. In NMT for code generation, the task\nis to generate output source code that satisfies constraints expressed in the\ninput. In the literature, a variety of different input scenarios have been\nexplored, including generating code based on natural language description,\nlower-level representations such as binary or assembly (neural decompilation),\npartial representations of source code (code completion and repair), and source\ncode in another language (code translation). In this paper we survey the NMT\nfor code generation literature, cataloging the variety of methods that have\nbeen explored according to input and output representations, model\narchitectures, optimization techniques used, data sets, and evaluation methods.\nWe discuss the limitations of existing methods and future research directions\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+KC_D/0/1/0/all/0/1\">Dharma KC</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morrison_C/0/1/0/all/0/1\">Clayton T. Morrison</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Automated Fact-Checking: A Survey. (arXiv:2305.13507v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13507","description":"<p>Misinformation, i.e. factually incorrect information, is often conveyed in\nmultiple modalities, e.g. an image accompanied by a caption. It is perceived as\nmore credible by humans, and spreads faster and wider than its text-only\ncounterparts. While an increasing body of research investigates automated\nfact-checking (AFC), previous surveys mostly focus on textual misinformation.\nIn this survey, we conceptualise a framework for AFC including subtasks unique\nto multimodal misinformation. Furthermore, we discuss related terminological\ndeveloped in different communities in the context of our framework. We focus on\nfour modalities prevalent in real-world fact-checking: text, image, audio, and\nvideo. We survey benchmarks and models, and discuss limitations and promising\ndirections for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mubashara_A/0/1/0/all/0/1\">Akhtar Mubashara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_S/0/1/0/all/0/1\">Schlichtkrull Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhijiang_G/0/1/0/all/0/1\">Guo Zhijiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oana_C/0/1/0/all/0/1\">Cocarascu Oana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elena_S/0/1/0/all/0/1\">Simperl Elena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_V/0/1/0/all/0/1\">Vlachos Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding. (arXiv:2305.13512v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13512","description":"<p>Recently, large pretrained language models have demonstrated strong language\nunderstanding capabilities. This is particularly reflected in their zero-shot\nand in-context learning abilities on downstream tasks through prompting. To\nassess their impact on spoken language understanding (SLU), we evaluate several\nsuch models like ChatGPT and OPT of different sizes on multiple benchmarks. We\nverify the emergent ability unique to the largest models as they can reach\nintent classification accuracy close to that of supervised models with zero or\nfew shots on various languages given oracle transcripts. By contrast, the\nresults for smaller models fitting a single GPU fall far behind. We note that\nthe error cases often arise from the annotation scheme of the dataset;\nresponses from ChatGPT are still reasonable. We show, however, that the model\nis worse at slot filling, and its performance is sensitive to ASR errors,\nsuggesting serious challenges for the application of those textual models on\nSLU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1\">Mutian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garner_P/0/1/0/all/0/1\">Philip N. Garner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Small Language Models Improve Giants by Rewriting Their Outputs. (arXiv:2305.13514v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13514","description":"<p>Large language models (LLMs) have demonstrated impressive few-shot learning\ncapabilities, but they often underperform compared to fine-tuned models on\nchallenging tasks. Furthermore, their large size and restricted access only\nthrough APIs make task-specific fine-tuning impractical. Moreover, LLMs are\nsensitive to different aspects of prompts (e.g., the selection and order of\ndemonstrations) and can thus require time-consuming prompt engineering. In this\nlight, we propose a method to correct LLM outputs without relying on their\nweights. First, we generate a pool of candidates by few-shot prompting an LLM.\nSecond, we refine the LLM-generated outputs using a smaller model, the\nLM-corrector (LMCor), which is trained to rank, combine and rewrite the\ncandidates to produce the final target output. Our experiments demonstrate that\neven a small LMCor model (250M) substantially improves the few-shot performance\nof LLMs (62B) across diverse tasks. Moreover, we illustrate that the LMCor\nexhibits robustness against different prompts, thereby minimizing the need for\nextensive prompt engineering. Finally, we showcase that the LMCor can be\nseamlessly integrated with different LLMs at inference time, serving as a\nplug-and-play module to improve their performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vernikos_G/0/1/0/all/0/1\">Giorgos Vernikos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brazinskas_A/0/1/0/all/0/1\">Arthur Bra&#x17e;inskas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adamek_J/0/1/0/all/0/1\">Jakub Adamek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mallinson_J/0/1/0/all/0/1\">Jonathan Mallinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Severyn_A/0/1/0/all/0/1\">Aliaksei Severyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malmi_E/0/1/0/all/0/1\">Eric Malmi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Speech Technology to 1,000+ Languages. (arXiv:2305.13516v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13516","description":"<p>Expanding the language coverage of speech technology has the potential to\nimprove access to information for many more people. However, current speech\ntechnology is restricted to about one hundred languages which is a small\nfraction of the over 7,000 languages spoken around the world. The Massively\nMultilingual Speech (MMS) project increases the number of supported languages\nby 10-40x, depending on the task. The main ingredients are a new dataset based\non readings of publicly available religious texts and effectively leveraging\nself-supervised learning. We built pre-trained wav2vec 2.0 models covering\n1,406 languages, a single multilingual automatic speech recognition model for\n1,107 languages, speech synthesis models for the same number of languages, as\nwell as a language identification model for 4,017 languages. Experiments show\nthat our multilingual speech recognition model more than halves the word error\nrate of Whisper on 54 languages of the FLEURS benchmark while being trained on\na small fraction of the labeled data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pratap_V/0/1/0/all/0/1\">Vineel Pratap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tjandra_A/0/1/0/all/0/1\">Andros Tjandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomasello_P/0/1/0/all/0/1\">Paden Tomasello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babu_A/0/1/0/all/0/1\">Arun Babu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1\">Sayani Kundu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elkahky_A/0/1/0/all/0/1\">Ali Elkahky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1\">Zhaoheng Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vyas_A/0/1/0/all/0/1\">Apoorv Vyas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fazel_Zarandi_M/0/1/0/all/0/1\">Maryam Fazel-Zarandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaohui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conneau_A/0/1/0/all/0/1\">Alexis Conneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CEO: Corpus-based Open-Domain Event Ontology Induction. (arXiv:2305.13521v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13521","description":"<p>Existing event-centric NLP models often only apply to the pre-defined\nontology, which significantly restricts their generalization capabilities. This\npaper presents CEO, a novel Corpus-based Event Ontology induction model to\nrelax the restriction imposed by pre-defined event ontologies. Without direct\nsupervision, CEO leverages distant supervision from available summary datasets\nto detect corpus-wise salient events and exploits external event knowledge to\nforce events within a short distance to have close embeddings. Experiments on\nthree popular event datasets show that the schema induced by CEO has better\ncoverage and higher accuracy than previous methods. Moreover, CEO is the first\nevent ontology induction model that can induce a hierarchical event ontology\nwith meaningful names on eleven open-domain corpora, making the induced schema\nmore trustworthy and easier to be further curated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianshu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study of Generative Large Language Model for Medical Research and Healthcare. (arXiv:2305.13523v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13523","description":"<p>There is enormous enthusiasm and concerns in using large language models\n(LLMs) in healthcare, yet current assumptions are all based on general-purpose\nLLMs such as ChatGPT. This study develops a clinical generative LLM,\nGatorTronGPT, using 277 billion words of mixed clinical and English text with a\nGPT-3 architecture of 20 billion parameters. GatorTronGPT improves biomedical\nnatural language processing for medical research. Synthetic NLP models trained\nusing GatorTronGPT generated text outperform NLP models trained using\nreal-world clinical text. Physicians Turing test using 1 (worst) to 9 (best)\nscale shows that there is no significant difference in linguistic readability\n(p = 0.22; 6.57 of GatorTronGPT compared with 6.93 of human) and clinical\nrelevance (p = 0.91; 7.0 of GatorTronGPT compared with 6.97 of human) and that\nphysicians cannot differentiate them (p &lt; 0.001). This study provides insights\non the opportunities and challenges of LLMs for medical research and\nhealthcare.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Cheng Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Aokun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1\">Kaleb E Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+PourNejatian_N/0/1/0/all/0/1\">Nima PourNejatian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_A/0/1/0/all/0/1\">Anthony B Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1\">Cheryl Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flores_M/0/1/0/all/0/1\">Mona G Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magoc_T/0/1/0/all/0/1\">Tanja Magoc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipori_G/0/1/0/all/0/1\">Gloria Lipori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_D/0/1/0/all/0/1\">Duane A Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ospina_N/0/1/0/all/0/1\">Naykky S Ospina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_M/0/1/0/all/0/1\">Mustafa M Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogan_W/0/1/0/all/0/1\">William R Hogan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenkman_E/0/1/0/all/0/1\">Elizabeth A Shenkman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning the Norwegian UD Treebank with Entity and Coreference Information. (arXiv:2305.13527v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13527","description":"<p>This paper presents a merged collection of entity and coreference annotated\ndata grounded in the Universal Dependencies (UD) treebanks for the two written\nforms of Norwegian: Bokm{\\aa}l and Nynorsk. The aligned and converted corpora\nare the \\textit{Norwegian Named Entities} (NorNE) and \\textit{Norwegian\nAnaphora Resolution Corpus} (NARC). While NorNE is aligned with an older\nversion of the treebank, NARC is misaligned and requires extensive\ntransformation from the original annotations to the UD structure and CoNLL-U\nformat. We here demonstrate the conversion and alignment processes, along with\nan analysis of discovered issues and errors in the data -- some of which\ninclude data split overlaps in the original treebank. These procedures and the\ndeveloped system may prove helpful for future corpus alignment and coreference\nannotation endeavors. The merged corpora comprise the first Norwegian UD\ntreebank enriched with named entities and coreference information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jorgensen_T/0/1/0/all/0/1\">Tollef Emil J&#xf8;rgensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaasen_A/0/1/0/all/0/1\">Andre K&#xe5;sen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transfer-Free Data-Efficient Multilingual Slot Labeling. (arXiv:2305.13528v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13528","description":"<p>Slot labeling (SL) is a core component of task-oriented dialogue (ToD)\nsystems, where slots and corresponding values are usually language-, task- and\ndomain-specific. Therefore, extending the system to any new\nlanguage-domain-task configuration requires (re)running an expensive and\nresource-intensive data annotation process. To mitigate the inherent data\nscarcity issue, current research on multilingual ToD assumes that sufficient\nEnglish-language annotated data are always available for particular tasks and\ndomains, and thus operates in a standard cross-lingual transfer setup. In this\nwork, we depart from this often unrealistic assumption. We examine challenging\nscenarios where such transfer-enabling English annotated data cannot be\nguaranteed, and focus on bootstrapping multilingual data-efficient slot\nlabelers in transfer-free scenarios directly in the target languages without\nany English-ready data. We propose a two-stage slot labeling approach (termed\nTWOSL) which transforms standard multilingual sentence encoders into effective\nslot labelers. In Stage 1, relying on SL-adapted contrastive learning with only\na handful of SL-annotated examples, we turn sentence encoders into\ntask-specific span encoders. In Stage 2, we recast SL from a token\nclassification into a simpler, less data-intensive span classification task.\nOur results on two standard multilingual TOD datasets and across diverse\nlanguages confirm the effectiveness and robustness of TWOSL. It is especially\neffective for the most challenging transfer-free few-shot setups, paving the\nway for quick and data-efficient bootstrapping of multilingual slot labelers\nfor ToD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razumovskaia_E/0/1/0/all/0/1\">Evgeniia Razumovskaia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian Language. (arXiv:2305.13530v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13530","description":"<p>This paper provides an overview of a text mining tool the StyloMetrix\ndeveloped initially for the Polish language and further extended for English\nand recently for Ukrainian. The StyloMetrix is built upon various metrics\ncrafted manually by computational linguists and researchers from literary\nstudies to analyze grammatical, stylistic, and syntactic patterns. The idea of\nconstructing the statistical evaluation of syntactic and grammar features is\nstraightforward and familiar for the languages like English, Spanish, German,\nand others; it is yet to be developed for low-resource languages like\nUkrainian. We describe the StyloMetrix pipeline and provide some experiments\nwith this tool for the text classification task. We also describe our package's\nmain limitations and the metrics' evaluation procedure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stetsenko_D/0/1/0/all/0/1\">Daria Stetsenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okulska_I/0/1/0/all/0/1\">Inez Okulska</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Open-world Semi-supervised Generalized Relation Discovery Aligned in a Real-world Setting. (arXiv:2305.13533v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13533","description":"<p>Open-world Relation Extraction (OpenRE) has recently garnered significant\nattention. However, existing approaches tend to oversimplify the problem by\nassuming that all unlabeled texts belong to novel classes, thereby limiting the\npracticality of these methods. We argue that the OpenRE setting should be more\naligned with the characteristics of real-world data. Specifically, we propose\ntwo key improvements: (a) unlabeled data should encompass known and novel\nclasses, including hard-negative instances; and (b) the set of novel classes\nshould represent long-tail relation types. Furthermore, we observe that popular\nrelations such as titles and locations can often be implicitly inferred through\nspecific patterns, while long-tail relations tend to be explicitly expressed in\nsentences. Motivated by these insights, we present a novel method called KNoRD\n(Known and Novel Relation Discovery), which effectively classifies explicitly\nand implicitly expressed relations from known and novel classes within\nunlabeled data. Experimental evaluations on several Open-world RE benchmarks\ndemonstrate that KNoRD consistently outperforms other existing methods,\nachieving significant performance gains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hogan_W/0/1/0/all/0/1\">William Hogan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiacheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Language Model Hallucinations Can Snowball. (arXiv:2305.13534v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13534","description":"<p>A major risk of using language models in practical applications is their\ntendency to hallucinate incorrect statements. Hallucinations are often\nattributed to knowledge gaps in LMs, but we hypothesize that in some cases,\nwhen justifying previously generated hallucinations, LMs output false claims\nthat they can separately recognize as incorrect. We construct three\nquestion-answering datasets where ChatGPT and GPT-4 often state an incorrect\nanswer and offer an explanation with at least one incorrect claim. Crucially,\nwe find that ChatGPT and GPT-4 can identify 67% and 87% of their own mistakes,\nrespectively. We refer to this phenomenon as hallucination snowballing: an LM\nover-commits to early mistakes, leading to more mistakes that it otherwise\nwould not make.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1\">Ofir Press</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1\">William Merrill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alisa Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Classifier Robustness through Active Generation of Pairwise Counterfactuals. (arXiv:2305.13535v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13535","description":"<p>Counterfactual Data Augmentation (CDA) is a commonly used technique for\nimproving robustness in natural language classifiers. However, one fundamental\nchallenge is how to discover meaningful counterfactuals and efficiently label\nthem, with minimal human labeling cost. Most existing methods either completely\nrely on human-annotated labels, an expensive process which limits the scale of\ncounterfactual data, or implicitly assume label invariance, which may mislead\nthe model with incorrect labels. In this paper, we present a novel framework\nthat utilizes counterfactual generative models to generate a large number of\ndiverse counterfactuals by actively sampling from regions of uncertainty, and\nthen automatically label them with a learned pairwise classifier. Our key\ninsight is that we can more correctly label the generated counterfactuals by\ntraining a pairwise classifier that interpolates the relationship between the\noriginal example and the counterfactual. We demonstrate that with a small\namount of human-annotated counterfactual data (10%), we can generate a\ncounterfactual augmentation dataset with learned labels, that provides an\n18-20% improvement in robustness and a 14-21% reduction in errors on 6\nout-of-domain datasets, comparable to that of a fully human-annotated\ncounterfactual dataset for both sentiment classification and question\nparaphrase tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Balashankar_A/0/1/0/all/0/1\">Ananth Balashankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Packer_B/0/1/0/all/0/1\">Ben Packer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thain_N/0/1/0/all/0/1\">Nithum Thain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1\">Ed H. Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1\">Alex Beutel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks. (arXiv:2305.13547v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13547","description":"<p>Text classification tasks often encounter few shot scenarios with limited\nlabeled data, and addressing data scarcity is crucial. Data augmentation with\nmixup has shown to be effective on various text classification tasks. However,\nmost of the mixup methods do not consider the varying degree of learning\ndifficulty in different stages of training and generate new samples with one\nhot labels, resulting in the model over confidence. In this paper, we propose a\nself evolution learning (SE) based mixup approach for data augmentation in text\nclassification, which can generate more adaptive and model friendly pesudo\nsamples for the model training. SE focuses on the variation of the model's\nlearning ability. To alleviate the model confidence, we introduce a novel\ninstance specific label smoothing approach, which linearly interpolates the\nmodel's output and one hot labels of the original samples to generate new soft\nfor label mixing up. Through experimental analysis, in addition to improving\nclassification accuracy, we demonstrate that SE also enhances the model's\ngeneralize ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Haoqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1\">Xin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EntRED: Benchmarking Relation Extraction with Fewer Shortcuts. (arXiv:2305.13551v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13551","description":"<p>Entity names play an effective role in relation extraction (RE) and often\ninfluence model performance. As a result, the entity names in the benchmarks'\ntest sets significantly influence the evaluation of RE models. In this work, we\nfind that the standard RE benchmarks' datasets have a large portion of\nincorrect entity annotations, low entity name diversity, and are prone to have\nshortcuts from entity names to ground-truth relations. These issues make the\nstandard benchmarks far from reflecting the real-world scenarios. Hence, in\nthis work, we present EntRED, a challenging RE benchmark with reduced shortcuts\nand higher diversity of entities. To build EntRED, we propose an end-to-end\nentity replacement pipeline based on causal inference (CI): ERIC. ERIC performs\ntype-constrained replacements on entities to reduce the shortcuts from entity\nbias to ground-truth relations. ERIC applies CI in two aspects: 1) targeting\nthe instances that need entity replacements, and 2) determining the candidate\nentities for replacements. We apply ERIC on TACRED to produce EntRED. Our\nEntRED evaluates whether the RE model can correctly extract the relations from\nthe text instead of relying on entity bias. Empirical results reveal that even\nthe strong RE model has a significant performance drop on EntRED, which\nmemorizes entity name patterns instead of reasoning from the textual context.\nWe release ERIC's source code and the EntRED benchmark at\nhttps://github.com/wangywUST/ENTRED.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yujun Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuxuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jing Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_M/0/1/0/all/0/1\">Manjuan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings. (arXiv:2305.13571v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13571","description":"<p>The use of positional embeddings in transformer language models is widely\naccepted. However, recent research has called into question the necessity of\nsuch embeddings. We further extend this inquiry by demonstrating that a\nrandomly initialized and frozen transformer language model, devoid of\npositional embeddings, inherently encodes strong positional information through\nthe shrinkage of self-attention variance. To quantify this variance, we derive\nthe underlying distribution of each step within a transformer layer. Through\nempirical validation using a fully pretrained model, we show that the variance\nshrinkage effect still persists after extensive gradient updates. Our findings\nserve to justify the decision to discard positional embeddings and thus\nfacilitate more efficient pretraining of transformer language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1\">Ta-Chung Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Ting-Han Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li-Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander I. Rudnicky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramadge_P/0/1/0/all/0/1\">Peter J. Ramadge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Better Low-Resource Entity Recognition Through Translation and Annotation Fusion. (arXiv:2305.13582v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13582","description":"<p>Pre-trained multilingual language models have enabled significant\nadvancements in cross-lingual transfer. However, these models often exhibit a\nperformance disparity when transferring from high-resource languages to\nlow-resource languages, especially for languages that are underrepresented or\nnot in the pre-training data. Motivated by the superior performance of these\nmodels on high-resource languages compared to low-resource languages, we\nintroduce a Translation-and-fusion framework, which translates low-resource\nlanguage text into a high-resource language for annotation using fully\nsupervised models before fusing the annotations back into the low-resource\nlanguage. Based on this framework, we present TransFusion, a model trained to\nfuse predictions from a high-resource language to make robust predictions on\nlow-resource languages. We evaluate our methods on two low-resource named\nentity recognition (NER) datasets, MasakhaNER2.0 and LORELEI NER, covering 25\nlanguages, and show consistent improvement up to +16 F$_1$ over English\nfine-tuning systems, achieving state-of-the-art performance compared to\nTranslate-train systems. Our analysis depicts the unique advantages of the\nTransFusion method which is robust to translation errors and source language\nprediction errors, and complimentary to adapted multilingual language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1\">Vedaant Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Attention is Not Enough: Incongruity-Aware Multimodal Sentiment Analysis and Emotion Recognition. (arXiv:2305.13583v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13583","description":"<p>Fusing multiple modalities for affective computing tasks has proven effective\nfor performance improvement. However, how multimodal fusion works is not well\nunderstood, and its use in the real world usually results in large model sizes.\nIn this work, on sentiment and emotion analysis, we first analyze how the\nsalient affective information in one modality can be affected by the other in\ncrossmodal attention. We find that inter-modal incongruity exists at the latent\nlevel due to crossmodal attention. Based on this finding, we propose a\nlightweight model via Hierarchical Crossmodal Transformer with Modality Gating\n(HCT-MG), which determines a primary modality according to its contribution to\nthe target task and then hierarchically incorporates auxiliary modalities to\nalleviate inter-modal incongruity and reduce information redundancy. The\nexperimental evaluation on three benchmark datasets: CMU-MOSI, CMU-MOSEI, and\nIEMOCAP verifies the efficacy of our approach, showing that it: 1) outperforms\nmajor prior work by achieving competitive results and can successfully\nrecognize hard samples; 2) mitigates the inter-modal incongruity at the latent\nlevel when modalities have mismatched affective tendencies; 3) reduces model\nsize to less than 1M parameters while outperforming existing models of similar\nsizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaoting Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bell_P/0/1/0/all/0/1\">Peter Bell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Catherine Lai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query Structure Modeling for Inductive Logical Reasoning Over Knowledge Graphs. (arXiv:2305.13585v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13585","description":"<p>Logical reasoning over incomplete knowledge graphs to answer complex logical\nqueries is a challenging task. With the emergence of new entities and relations\nin constantly evolving KGs, inductive logical reasoning over KGs has become a\ncrucial problem. However, previous PLMs-based methods struggle to model the\nlogical structures of complex queries, which limits their ability to generalize\nwithin the same structure. In this paper, we propose a structure-modeled\ntextual encoding framework for inductive logical reasoning over KGs. It encodes\nlinearized query structures and entities using pre-trained language models to\nfind answers. For structure modeling of complex queries, we design stepwise\ninstructions that implicitly prompt PLMs on the execution order of geometric\noperations in each query. We further separately model different geometric\noperations (i.e., projection, intersection, and union) on the representation\nspace using a pre-trained encoder with additional attention and maxout layers\nto enhance structured modeling. We conduct experiments on two inductive logical\nreasoning datasets and three transductive datasets. The results demonstrate the\neffectiveness of our method on logical reasoning over KGs in both inductive and\ntransductive settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhongyu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1\">Meng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1\">Zhihao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Haijun Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of Implied Social Biases. (arXiv:2305.13589v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13589","description":"<p>Toxicity annotators and content moderators often default to mental shortcuts\nwhen making decisions. This can lead to subtle toxicity being missed, and\nseemingly toxic but harmless content being over-detected. We introduce BiasX, a\nframework that enhances content moderation setups with free-text explanations\nof statements' implied social biases, and explore its effectiveness through a\nlarge-scale crowdsourced user study. We show that indeed, participants\nsubstantially benefit from explanations for correctly identifying subtly\n(non-)toxic content. The quality of explanations is critical: imperfect\nmachine-generated explanations (+2.4% on hard toxic examples) help less\ncompared to expert-written human explanations (+7.2%). Our results showcase the\npromise of using free-text explanations to encourage more thoughtful toxicity\nmoderation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanduri_S/0/1/0/all/0/1\">Sravani Nanduri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Programs by Exploiting (Fuzzing) Test Cases. (arXiv:2305.13592v1 [cs.LG])","link":"http://arxiv.org/abs/2305.13592","description":"<p>Semantic understanding of programs has attracted great attention in the\ncommunity. Inspired by recent successes of large language models (LLMs) in\nnatural language understanding, tremendous progress has been made by treating\nprogramming language as another sort of natural language and training LLMs on\ncorpora of program code. However, programs are essentially different from texts\nafter all, in a sense that they are normally heavily structured and\nsyntax-strict. In particular, programs and their basic units (i.e., functions\nand subroutines) are designed to demonstrate a variety of behaviors and/or\nprovide possible outputs, given different inputs. The relationship between\ninputs and possible outputs/behaviors represents the functions/subroutines and\nprofiles the program as a whole. Therefore, we propose to incorporate such a\nrelationship into learning, for achieving a deeper semantic understanding of\nprograms. To obtain inputs that are representative enough to trigger the\nexecution of most part of the code, we resort to fuzz testing and propose fuzz\ntuning to boost the performance of program understanding and code\nrepresentation learning, given a pre-trained LLM. The effectiveness of the\nproposed method is verified on two program understanding tasks including code\nclone detection and code classification, and it outperforms current\nstate-of-the-arts by large margins. Code is available at\nhttps://github.com/rabbitjy/FuzzTuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jianyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1\">Yuyang Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiwen Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yifeng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decoupled Rationalization with Asymmetric Learning Rates: A Flexible Lipshitz Restraint. (arXiv:2305.13599v1 [cs.LG])","link":"http://arxiv.org/abs/2305.13599","description":"<p>A self-explaining rationalization model is generally constructed by a\ncooperative game where a generator selects the most human-intelligible pieces\nfrom the input text as rationales, followed by a predictor that makes\npredictions based on the selected rationales. However, such a cooperative game\nmay incur the degeneration problem where the predictor overfits to the\nuninformative pieces generated by a not yet well-trained generator and in turn,\nleads the generator to converge to a sub-optimal model that tends to select\nsenseless pieces. In this paper, we theoretically bridge degeneration with the\npredictor's Lipschitz continuity. Then, we empirically propose a simple but\neffective method named DR, which can naturally and flexibly restrain the\nLipschitz constant of the predictor, to address the problem of degeneration.\nThe main idea of DR is to decouple the generator and predictor to allocate them\nwith asymmetric learning rates. A series of experiments conducted on two widely\nused benchmarks have verified the effectiveness of the proposed method. Codes:\n\\href{https://github.com/jugechengzi/Rationalization-DR}{https://github.com/jugechengzi/Rationalization-DR}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">YuanKai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jie Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yixiong Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue. (arXiv:2305.13602v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13602","description":"<p>Incorporating visual knowledge into text-only dialogue systems has become a\npotential direction to imitate the way humans think, imagine, and communicate.\nHowever, existing multimodal dialogue systems are either confined by the scale\nand quality of available datasets or the coarse concept of visual knowledge. To\naddress these issues, we provide a new paradigm of constructing multimodal\ndialogues as well as two datasets extended from text-only dialogues under such\nparadigm (ReSee-WoW, ReSee-DD). We propose to explicitly split the visual\nknowledge into finer granularity (``turn-level'' and ``entity-level''). To\nfurther boost the accuracy and diversity of augmented visual information, we\nretrieve them from the Internet or a large image dataset. To demonstrate the\nsuperiority and universality of the provided visual knowledge, we propose a\nsimple but effective framework ReSee to add visual representation into vanilla\ndialogue models by modality concatenations. We also conduct extensive\nexperiments and ablations w.r.t. different model configurations and visual\nknowledge settings. Empirical, encouraging results not only demonstrate the\neffectiveness of introducing visual knowledge at both entity and turn level but\nalso verify the proposed model ReSee outperforms several state-of-the-art\nmethods on automatic and human evaluations. By leveraging text and vision\nknowledge, ReSee can produce informative responses with real-world visual\nconcepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_H/0/1/0/all/0/1\">Haoqin Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yitong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhongliang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-empowered Chatbots for Psychiatrist and Patient Simulation: Application and Evaluation. (arXiv:2305.13614v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13614","description":"<p>Empowering chatbots in the field of mental health is receiving increasing\namount of attention, while there still lacks exploration in developing and\nevaluating chatbots in psychiatric outpatient scenarios. In this work, we focus\non exploring the potential of ChatGPT in powering chatbots for psychiatrist and\npatient simulation. We collaborate with psychiatrists to identify objectives\nand iteratively develop the dialogue system to closely align with real-world\nscenarios. In the evaluation experiments, we recruit real psychiatrists and\npatients to engage in diagnostic conversations with the chatbots, collecting\ntheir ratings for assessment. Our findings demonstrate the feasibility of using\nChatGPT-powered chatbots in psychiatric scenarios and explore the impact of\nprompt designs on chatbot behavior and user experience.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Siyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Mengyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_K/0/1/0/all/0/1\">Kunyao Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiling Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Lyuchun Cui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13617","description":"<p>Event-centric structured prediction involves predicting structured outputs of\nevents. In most NLP cases, event structures are complex with manifold\ndependency, and it is challenging to effectively represent these complicated\nstructured events. To address these issues, we propose Structured Prediction\nwith Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex\ndependency among event structured components with energy-based modeling, and\nrepresents event classes with simple but effective hyperspheres. Experiments on\ntwo unified-annotated event datasets indicate that SPEECH is predominant in\nevent detection and event-relation extraction tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shengyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Validating Multimedia Content Moderation Software via Semantic Fusion. (arXiv:2305.13623v1 [cs.SE])","link":"http://arxiv.org/abs/2305.13623","description":"<p>The exponential growth of social media platforms, such as Facebook and\nTikTok, has revolutionized communication and content publication in human\nsociety. Users on these platforms can publish multimedia content that delivers\ninformation via the combination of text, audio, images, and video. Meanwhile,\nthe multimedia content release facility has been increasingly exploited to\npropagate toxic content, such as hate speech, malicious advertisements, and\npornography. To this end, content moderation software has been widely deployed\non these platforms to detect and blocks toxic content. However, due to the\ncomplexity of content moderation models and the difficulty of understanding\ninformation across multiple modalities, existing content moderation software\ncan fail to detect toxic content, which often leads to extremely negative\nimpacts.\n</p>\n<p>We introduce Semantic Fusion, a general, effective methodology for validating\nmultimedia content moderation software. Our key idea is to fuse two or more\nexisting single-modal inputs (e.g., a textual sentence and an image) into a new\ninput that combines the semantics of its ancestors in a novel manner and has\ntoxic nature by construction. This fused input is then used for validating\nmultimedia content moderation software. We realized Semantic Fusion as DUO, a\npractical content moderation software testing tool. In our evaluation, we\nemploy DUO to test five commercial content moderation software and two\nstate-of-the-art models against three kinds of toxic content. The results show\nthat DUO achieves up to 100% error finding rate (EFR) when testing moderation\nsoftware. In addition, we leverage the test cases generated by DUO to retrain\nthe two models we explored, which largely improves model robustness while\nmaintaining the accuracy on the original test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jingyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiazhen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Weibin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pinjia He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael Lyu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting and Evaluating Large Language Models for Proactive Dialogues: Clarification, Target-guided, and Non-collaboration. (arXiv:2305.13626v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13626","description":"<p>Conversational systems based on Large Language Models (LLMs), such as\nChatGPT, show exceptional proficiency in context understanding and response\ngeneration. However, despite their impressive capabilities, they still possess\nlimitations, such as providing randomly-guessed answers to ambiguous queries or\nfailing to refuse users' requests, both of which are considered aspects of a\nconversational agent's proactivity. This raises the question of whether\nLLM-based conversational systems are equipped to handle proactive dialogue\nproblems. In this work, we conduct a comprehensive analysis of LLM-based\nconversational systems, specifically focusing on three aspects of proactive\ndialogue systems: clarification, target-guided, and non-collaborative\ndialogues. To trigger the proactivity of LLMs, we propose the Proactive\nChain-of-Thought prompting scheme, which augments LLMs with the goal planning\ncapability over descriptive reasoning chains. Empirical findings are discussed\nto promote future studies on LLM-based proactive dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1\">Wenqiang Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1\">Lizi Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction. (arXiv:2305.13627v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13627","description":"<p>Instruction-tuned large language models (LLMs) have shown remarkable\ngeneralization capability over multiple tasks in multiple languages.\nNevertheless, their generalization towards different languages varies\nespecially to underrepresented languages or even to unseen languages. Prior\nworks on adapting new languages to LLMs find that naively adapting new\nlanguages to instruction-tuned LLMs will result in catastrophic forgetting,\nwhich in turn causes the loss of multitasking ability in these LLMs. To tackle\nthis, we propose the Instruct-Align a.k.a (IA)$^1$ framework, which enables\ninstruction-tuned LLMs to learn cross-lingual alignment between unseen and\npreviously learned languages via alignment-based cross-lingual\ninstruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)$^1$\nis able to learn a new language effectively with only a limited amount of\nparallel data and at the same time prevent catastrophic forgetting by applying\ncontinual instruction-tuning through experience replay. Our work contributes to\nthe progression of language adaptation methods for instruction-tuned LLMs and\nopens up the possibility of adapting underrepresented low-resource languages\ninto existing instruction-tuned LLMs. Our code will be publicly released upon\nacceptance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning. (arXiv:2305.13628v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13628","description":"<p>In cross-lingual named entity recognition (NER), self-training is commonly\nused to bridge the linguistic gap by training on pseudo-labeled target-language\ndata. However, due to sub-optimal performance on target languages, the pseudo\nlabels are often noisy and limit the overall performance. In this work, we aim\nto improve self-training for cross-lingual NER by combining representation\nlearning and pseudo label refinement in one coherent framework. Our proposed\nmethod, namely ContProto mainly comprises two components: (1) contrastive\nself-training and (2) prototype-based pseudo-labeling. Our contrastive\nself-training facilitates span classification by separating clusters of\ndifferent classes, and enhances cross-lingual transferability by producing\nclosely-aligned representations between the source and target language.\nMeanwhile, prototype-based pseudo-labeling effectively improves the accuracy of\npseudo labels during training. We evaluate ContProto on multiple transfer\npairs, and experimental results show our method brings in substantial\nimprovements over current state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1\">Ran Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1\">Erik Cambria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1\">Chunyan Miao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EDIS: Entity-Driven Image Search over Multimodal Web Content. (arXiv:2305.13631v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13631","description":"<p>Making image retrieval methods practical for real-world search applications\nrequires significant progress in dataset scales, entity comprehension, and\nmultimodal information fusion. In this work, we introduce\n\\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch (EDIS), a\nchallenging dataset for cross-modal image search in the news domain. EDIS\nconsists of 1 million web images from actual search engine results and curated\ndatasets, with each image paired with a textual description. Unlike datasets\nthat assume a small set of single-modality candidates, EDIS reflects real-world\nweb image search scenarios by including a million multimodal image-text pairs\nas candidates. EDIS encourages the development of retrieval models that\nsimultaneously address cross-modal information fusion and matching. To achieve\naccurate ranking results, a model must: 1) understand named entities and events\nfrom text queries, 2) ground entities onto images or text descriptions, and 3)\neffectively fuse textual and visual representations. Our experimental results\nshow that EDIS challenges state-of-the-art methods with dense entities and a\nlarge-scale candidate set. The ablation study also proves that fusing textual\nfeatures with visual features is critical in improving retrieval results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Weixi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting and Mitigating Hallucinations in Multilingual Summarisation. (arXiv:2305.13632v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13632","description":"<p>Hallucinations pose a significant challenge to the reliability of neural\nmodels for abstractive summarisation. While automatically generated summaries\nmay be fluent, they often lack faithfulness to the original document. This\nissue becomes even more pronounced in low-resource settings, such as\ncross-lingual transfer. With the existing faithful metrics focusing on English,\neven measuring the extent of this phenomenon in cross-lingual settings is hard.\nTo address this, we first develop a novel metric, mFACT, evaluating the\nfaithfulness of non-English summaries, leveraging translation-based transfer\nfrom multiple English faithfulness metrics. We then propose a simple but\neffective method to reduce hallucinations with a cross-lingual transfer, which\nweighs the loss of each training example by its faithfulness score. Through\nextensive experiments in multiple languages, we demonstrate that mFACT is the\nmetric that is most suited to detect hallucinations. Moreover, we find that our\nproposed loss weighting method drastically increases both performance and\nfaithfulness according to both automatic and human evaluation when compared to\nstrong baselines for cross-lingual transfer such as MAD-X. Our code and dataset\nare available at https://github.com/yfqiu-nlp/mfact-summ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yifu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziser_Y/0/1/0/all/0/1\">Yftah Ziser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo M. Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IdEALS: Idiomatic Expressions for Advancement of Language Skills. (arXiv:2305.13637v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13637","description":"<p>Although significant progress has been made in developing methods for\nGrammatical Error Correction (GEC), addressing word choice improvements has\nbeen notably lacking and enhancing sentence expressivity by replacing phrases\nwith advanced expressions is an understudied aspect. In this paper, we focus on\nthis area and present our investigation into the task of incorporating the\nusage of idiomatic expressions in student writing. To facilitate our study, we\ncurate extensive training sets and expert-annotated testing sets using\nreal-world data and evaluate various approaches and compare their performance\nagainst human experts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ri_N/0/1/0/all/0/1\">Narutatsu Ri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Bill Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Davidson_S/0/1/0/all/0/1\">Sam Davidson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AxomiyaBERTa: A Phonologically-aware Transformer Model for Assamese. (arXiv:2305.13641v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13641","description":"<p>Despite their successes in NLP, Transformer-based language models still\nrequire extensive computing resources and suffer in low-resource or low-compute\nsettings. In this paper, we present AxomiyaBERTa, a novel BERT model for\nAssamese, a morphologically-rich low-resource language (LRL) of Eastern India.\nAxomiyaBERTa is trained only on the masked language modeling (MLM) task,\nwithout the typical additional next sentence prediction (NSP) objective, and\nour results show that in resource-scarce settings for very low-resource\nlanguages like Assamese, MLM alone can be successfully leveraged for a range of\ntasks. AxomiyaBERTa achieves SOTA on token-level tasks like Named Entity\nRecognition and also performs well on \"longer-context\" tasks like Cloze-style\nQA and Wiki Title Prediction, with the assistance of a novel embedding\ndisperser and phonological signals respectively. Moreover, we show that\nAxomiyaBERTa can leverage phonological signals for even more challenging tasks,\nsuch as a novel cross-document coreference task on a translated version of the\nECB+ corpus, where we present a new SOTA result for an LRL. Our source code and\nevaluation scripts may be found at https://github.com/csu-signal/axomiyaberta.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nath_A/0/1/0/all/0/1\">Abhijnan Nath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mannan_S/0/1/0/all/0/1\">Sheikh Mannan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnaswamy_N/0/1/0/all/0/1\">Nikhil Krishnaswamy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mPMR: A Multilingual Pre-trained Machine Reader at Scale. (arXiv:2305.13645v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13645","description":"<p>We present multilingual Pre-trained Machine Reader (mPMR), a novel method for\nmultilingual machine reading comprehension (MRC)-style pre-training. mPMR aims\nto guide multilingual pre-trained language models (mPLMs) to perform natural\nlanguage understanding (NLU) including both sequence classification and span\nextraction in multiple languages. To achieve cross-lingual generalization when\nonly source-language fine-tuning data is available, existing mPLMs solely\ntransfer NLU capability from a source language to target languages. In\ncontrast, mPMR allows the direct inheritance of multilingual NLU capability\nfrom the MRC-style pre-training to downstream tasks. Therefore, mPMR acquires\nbetter NLU capability for target languages. mPMR also provides a unified solver\nfor tackling cross-lingual span extraction and sequence classification, thereby\nenabling the extraction of rationales to explain the sentence-pair\nclassification process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weiwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine Translation. (arXiv:2305.13648v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13648","description":"<p>Non-parametric, k-nearest-neighbor algorithms have recently made inroads to\nassist generative models such as language models and machine translation\ndecoders. We explore whether such non-parametric models can improve machine\ntranslation models at the fine-tuning stage by incorporating statistics from\nthe kNN predictions to inform the gradient updates for a baseline translation\nmodel. There are multiple methods which could be used to incorporate kNN\nstatistics and we investigate gradient scaling by a gating mechanism, the kNN's\nground truth probability, and reinforcement learning. For four standard\nin-domain machine translation datasets, compared with classic fine-tuning, we\nreport consistent improvements of all of the three methods by as much as 1.45\nBLEU and 1.28 BLEU for German-English and English-German translations\nrespectively. Through qualitative analysis, we found particular improvements\nwhen it comes to translating grammatical relations or function words, which\nresults in increased fluency of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiayi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Ke Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1\">Pontus Stenetorp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-lingual Knowledge Transfer and Iterative Pseudo-labeling for Low-Resource Speech Recognition with Transducers. (arXiv:2305.13652v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13652","description":"<p>Voice technology has become ubiquitous recently. However, the accuracy, and\nhence experience, in different languages varies significantly, which makes the\ntechnology not equally inclusive. The availability of data for different\nlanguages is one of the key factors affecting accuracy, especially in training\nof all-neural end-to-end automatic speech recognition systems.\n</p>\n<p>Cross-lingual knowledge transfer and iterative pseudo-labeling are two\ntechniques that have been shown to be successful for improving the accuracy of\nASR systems, in particular for low-resource languages, like Ukrainian.\n</p>\n<p>Our goal is to train an all-neural Transducer-based ASR system to replace a\nDNN-HMM hybrid system with no manually annotated training data. We show that\nthe Transducer system trained using transcripts produced by the hybrid system\nachieves 18% reduction in terms of word error rate. However, using a\ncombination of cross-lingual knowledge transfer from related languages and\niterative pseudo-labeling, we are able to achieve 35% reduction of the error\nrate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Silovsky_J/0/1/0/all/0/1\">Jan Silovsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1\">Liuhui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Argueta_A/0/1/0/all/0/1\">Arturo Argueta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arvizo_T/0/1/0/all/0/1\">Tresi Arvizo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsiao_R/0/1/0/all/0/1\">Roger Hsiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuznietsov_S/0/1/0/all/0/1\">Sasha Kuznietsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yiu-Chang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xiaoqiang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanyuan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding and Mitigating Spurious Correlations in Text Classification. (arXiv:2305.13654v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13654","description":"<p>Recent work has shown that deep learning models are prone to exploit spurious\ncorrelations that are present in the training set, yet may not hold true in\ngeneral. A sentiment classifier may erroneously learn that the token spielberg\nis always tied to positive movie reviews. Relying on spurious correlations may\nlead to significant degradation in generalizability and should be avoided. In\nthis paper, we propose a neighborhood analysis framework to explain how exactly\nlanguage models exploit spurious correlations. Driven by the analysis, we\npropose a family of regularization methods, NFL (do Not Forget your Language)\nto prevent the situation. Experiments on two text classification tasks show\nthat NFL brings a significant improvement over standard fine-tuning in terms of\nrobustness without sacrificing in-distribution accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chew_O/0/1/0/all/0/1\">Oscar Chew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kuan-Hao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hsuan-Tien Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT as your Personal Data Scientist. (arXiv:2305.13657v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13657","description":"<p>The rise of big data has amplified the need for efficient, user-friendly\nautomated machine learning (AutoML) tools. However, the intricacy of\nunderstanding domain-specific data and defining prediction tasks necessitates\nhuman intervention making the process time-consuming while preventing full\nautomation. Instead, envision an intelligent agent capable of assisting users\nin conducting AutoML tasks through intuitive, natural conversations without\nrequiring in-depth knowledge of the underlying machine learning (ML) processes.\nThis agent's key challenge is to accurately comprehend the user's prediction\ngoals and, consequently, formulate precise ML tasks, adjust data sets and model\nparameters accordingly, and articulate results effectively. In this paper, we\ntake a pioneering step towards this ambitious goal by introducing a\nChatGPT-based conversational data-science framework to act as a \"personal data\nscientist\". Precisely, we utilize Large Language Models (ChatGPT) to build a\nnatural interface between the users and the ML models (Scikit-Learn), which in\nturn, allows us to approach this ambitious problem with a realistic solution.\n</p>\n<p>Our model pivots around four dialogue states: Data Visualization, Task\nFormulation, Prediction Engineering, and Result Summary and Recommendation.\nEach state marks a unique conversation phase, impacting the overall user-system\ninteraction. Multiple LLM instances, serving as \"micro-agents\", ensure a\ncohesive conversation flow, granting us granular control over the\nconversation's progression. In summary, we developed an end-to-end system that\nnot only proves the viability of the novel concept of conversational data\nscience but also underscores the potency of LLMs in solving complex tasks.\nInterestingly, its development spotlighted several critical weaknesses in the\ncurrent LLMs (ChatGPT) and highlighted substantial opportunities for\nimprovement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1\">Md Mahadi Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knipper_A/0/1/0/all/0/1\">Alex Knipper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker Santu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding compositional data augmentation in automatic morphological inflection. (arXiv:2305.13658v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13658","description":"<p>Data augmentation techniques are widely used in low-resource automatic\nmorphological inflection to address the issue of data sparsity. However, the\nfull implications of these techniques remain poorly understood. In this study,\nwe aim to shed light on the theoretical aspects of the data augmentation\nstrategy StemCorrupt, a method that generates synthetic examples by randomly\nsubstituting stem characters in existing gold standard training examples. Our\nanalysis uncovers that StemCorrupt brings about fundamental changes in the\nunderlying data distribution, revealing inherent compositional concatenative\nstructure. To complement our theoretical analysis, we investigate the\ndata-efficiency of StemCorrupt. Through evaluation across a diverse set of\nseven typologically distinct languages, we demonstrate that selecting a subset\nof datapoints with both high diversity and high predictive uncertainty\nsignificantly enhances the data-efficiency of StemCorrupt compared to\ncompetitive baselines. Furthermore, we explore the impact of typological\nfeatures on the choice of augmentation strategy and find that languages\nincorporating non-concatenativity, such as morphonological alternations, derive\nless benefit from synthetic examples with high predictive uncertainty. We\nattribute this effect to phonotactic violations induced by StemCorrupt,\nemphasizing the need for further research to ensure optimal performance across\nthe entire spectrum of natural language morphology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Samir_F/0/1/0/all/0/1\">Farhan Samir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silfverberg_M/0/1/0/all/0/1\">Miikka Silfverberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning. (arXiv:2305.13660v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13660","description":"<p>Planning for goal-oriented dialogue often requires simulating future dialogue\ninteractions and estimating task progress. Many approaches thus consider\ntraining neural networks to perform look-ahead search algorithms such as A*\nsearch and Monte Carlo Tree Search (MCTS). However, this training often require\nabundant annotated data, which creates challenges when faced with noisy\nannotations or low-resource settings. We introduce GDP-Zero, an approach using\nOpen-Loop MCTS to perform goal-oriented dialogue policy planning without any\nmodel training. GDP-Zero prompts a large language model to act as a policy\nprior, value function, user simulator, and system model during the tree search.\nWe evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that\nits responses are preferred over ChatGPT up to 59.32% of the time, and are\nrated more persuasive than ChatGPT during interactive evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Maximillian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Risk of Misinformation Pollution with Large Language Models. (arXiv:2305.13661v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13661","description":"<p>In this paper, we comprehensively investigate the potential misuse of modern\nLarge Language Models (LLMs) for generating credible-sounding misinformation\nand its subsequent impact on information-intensive applications, particularly\nOpen-Domain Question Answering (ODQA) systems. We establish a threat model and\nsimulate potential misuse scenarios, both unintentional and intentional, to\nassess the extent to which LLMs can be utilized to produce misinformation. Our\nstudy reveals that LLMs can act as effective misinformation generators, leading\nto a significant degradation in the performance of ODQA systems. To mitigate\nthe harm caused by LLM-generated misinformation, we explore three defense\nstrategies: prompting, misinformation detection, and majority voting. While\ninitial results show promising trends for these defensive strategies, much more\nwork needs to be done to address the challenge of misinformation pollution. Our\nwork highlights the need for further research and interdisciplinary\ncollaboration to address LLM-generated misinformation and to promote\nresponsible use of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yikang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing Non-Autoregressive Transformers with Contrastive Learning. (arXiv:2305.13667v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13667","description":"<p>Non-autoregressive Transformers (NATs) reduce the inference latency of\nAutoregressive Transformers (ATs) by predicting words all at once rather than\nin sequential order. They have achieved remarkable progress in machine\ntranslation as well as many other applications. However, a long-standing\nchallenge for NATs is the learning of multi-modality data distribution, which\nis the main cause of the performance gap between NATs and ATs. In this paper,\nwe propose to ease the difficulty of modality learning via sampling from the\nmodel distribution instead of the data distribution. We derive contrastive\nconstraints to stabilize the training process and integrate this resulting\nobjective with the state-of-the-art NAT architecture DA-Transformer. Our model\n\\method is examined on 3 different tasks, including machine translation, text\nsummarization, and paraphrasing with 5 benchmarks. Results show that our\napproach outperforms previous non-autoregressive baselines by a significant\nmargin and establishes new state-of-the-art results for non-autoregressive\ntransformers on all the benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_C/0/1/0/all/0/1\">Chenxin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiangtao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_x/0/1/0/all/0/1\">xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grounding and Distinguishing Conceptual Vocabulary Through Similarity Learning in Embodied Simulations. (arXiv:2305.13668v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13668","description":"<p>We present a novel method for using agent experiences gathered through an\nembodied simulation to ground contextualized word vectors to object\nrepresentations. We use similarity learning to make comparisons between\ndifferent object types based on their properties when interacted with, and to\nextract common features pertaining to the objects' behavior. We then use an\naffine transformation to calculate a projection matrix that transforms\ncontextualized word vectors from different transformer-based language models\ninto this learned space, and evaluate whether new test instances of transformed\ntoken vectors identify the correct concept in the object embedding space. Our\nresults expose properties of the embedding spaces of four different transformer\nmodels and show that grounding object token vectors is usually more helpful to\ngrounding verb and attribute token vectors than the reverse, which reflects\nearlier conclusions in the analogical reasoning and psycholinguistic\nliterature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghaffari_S/0/1/0/all/0/1\">Sadaf Ghaffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnaswamy_N/0/1/0/all/0/1\">Nikhil Krishnaswamy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment. (arXiv:2305.13669v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13669","description":"<p>Despite the remarkable recent advances in language models, they still\nstruggle with the hallucination problem and can generate misleading and\nunsupported responses. A common approach to mitigate the hallucination issue is\nretrieving and incorporating supporting evidence from a knowledge base.\nHowever, user questions usually do not align well with the stored knowledge, as\nthey are unaware of the information available before asking questions. This\nmisalignment can limit the language model's ability to locate and utilize the\nknowledge, potentially forcing it to hallucinate by ignoring or overriding the\nretrieved evidence. To address this issue, we introduce MixAlign, a framework\nthat interacts with both the user and the knowledge base to obtain and\nintegrate clarifications on how the user question relates to the stored\ninformation. MixAlign employs a language model to achieve automatic\nquestion-knowledge alignment and, if necessary, further enhances this alignment\nthrough human user clarifications. Experimental results demonstrate significant\nimprovements over state-of-the-art methods, showcasing the effectiveness of\nMixAlign in mitigating language model hallucination.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junzhou Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13673","description":"<p>We design experiments to study $\\textit{how}$ generative language models,\nlike GPT, learn context-free grammars (CFGs) -- diverse language systems with a\ntree-like structure capturing many aspects of natural languages, programs, and\nhuman logics. CFGs are as hard as pushdown automata, and can be ambiguous so\nthat verifying if a string satisfies the rules requires dynamic programming. We\nconstruct synthetic data and demonstrate that even for very challenging CFGs,\npre-trained transformers can learn to generate sentences with near-perfect\naccuracy and remarkable $\\textit{diversity}$.\n</p>\n<p>More importantly, we delve into the $\\textit{physical principles}$ behind how\ntransformers learns CFGs. We discover that the hidden states within the\ntransformer implicitly and $\\textit{precisely}$ encode the CFG structure (such\nas putting tree node information exactly on the subtree boundary), and learn to\nform \"boundary to boundary\" attentions that resemble dynamic programming. We\nalso cover some extension of CFGs as well as the robustness aspect of\ntransformers against grammar mistakes. Overall, our research provides a\ncomprehensive and empirical understanding of how transformers learn CFGs, and\nreveals the physical mechanisms utilized by transformers to capture the\nstructure and rules of languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1\">Zeyuan Allen-Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Polyglot or Not? Measuring Multilingual Encyclopedic Knowledge Retrieval from Foundation Language Models. (arXiv:2305.13675v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13675","description":"<p>In this work, we evaluate the capacity for foundation models to retrieve\nencyclopedic knowledge across a wide range of languages, topics, and contexts.\nTo support this effort, we 1) produce a new dataset containing 303k factual\nassociations in 20 different languages, 2) formulate a new counterfactual\nknowledge assessment, Polyglot or Not, and 3) benchmark 5 foundation models in\na multilingual setting and a diverse set of 20 models in an English-only\nsetting. We observed significant accuracy differences in models of interest,\nwith Meta's LLaMA topping both the multilingual and English-only assessments.\nError analysis reveals a significant deficiency in LLaMA's ability to retrieve\nfacts in languages written in the Cyrillic script and gaps in its understanding\nof facts based on the location and gender of entailed subjects. Ultimately, we\nargue that the promise of utilizing foundation language models as bonafide\npolyglots is greatly diminished when they are tasked with retrieving\ninformation in languages other than English. Supporting code\n(https://github.com/daniel-furman/Polyglot-or-Not) and dataset\n(https://huggingface.co/datasets/Polyglot-or-Not/Fact-Completion) are openly\nreleased.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schott_T/0/1/0/all/0/1\">Tim Schott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furman_D/0/1/0/all/0/1\">Daniel Furman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1\">Shreshta Bhat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Legally Enforceable Hate Speech Detection for Public Forums. (arXiv:2305.13677v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13677","description":"<p>Hate speech is a serious issue on public forums, and proper enforcement of\nhate speech laws is key for protecting groups of people against harmful and\ndiscriminatory language. However, determining what constitutes hate speech is a\ncomplex task that is highly open to subjective interpretations. Existing works\ndo not align their systems with enforceable definitions of hate speech, which\ncan make their outputs inconsistent with the goals of regulators. Our work\nintroduces a new task for enforceable hate speech detection centred around\nlegal definitions, and a dataset annotated on violations of eleven possible\ndefinitions by legal experts. Given the challenge of identifying clear, legally\nenforceable instances of hate speech, we augment the dataset with\nexpert-generated samples and an automatically mined challenge set. We\nexperiment with grounding the model decision in these definitions using\nzero-shot and few-shot prompting. We then report results on several large\nlanguage models (LLMs). With this task definition, automatic hate speech\ndetection can be more closely aligned to enforceable laws, and hence assist in\nmore rigorous enforcement of legal protections against harmful speech in public\nforums.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1\">Chu Fei Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhambhoria_R/0/1/0/all/0/1\">Rohan Bhambhoria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dahan_S/0/1/0/all/0/1\">Samuel Dahan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Error Detection for Text-to-SQL Semantic Parsing. (arXiv:2305.13683v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13683","description":"<p>Despite remarkable progress in text-to-SQL semantic parsing in recent years,\nthe performance of existing parsers is still far from perfect. At the same\ntime, modern deep learning based text-to-SQL parsers are often over-confident\nand thus casting doubt on their trustworthiness when deployed for real use. To\nthat end, we propose to build a parser-independent error detection model for\ntext-to-SQL semantic parsing. The proposed model is based on pre-trained\nlanguage model of code and is enhanced with structural features learned by\ngraph neural networks. We train our model on realistic parsing errors collected\nfrom a cross-domain setting. Experiments with three strong text-to-SQL parsers\nfeaturing different decoding mechanisms show that our approach outperforms\nparser-dependent uncertainty metrics and could effectively improve the\nperformance and usability of text-to-SQL semantic parsers regardless of their\narchitectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziru Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mPLM-Sim: Unveiling Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models. (arXiv:2305.13684v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13684","description":"<p>Recent multilingual pretrained language models (mPLMs) have been shown to\nencode strong language-specific signals, which are not explicitly provided\nduring pretraining. It remains an open question whether it is feasible to\nemploy mPLMs to measure language similarity, and subsequently use the\nsimilarity results to select source languages for boosting cross-lingual\ntransfer. To investigate this, we propose mPLM-Sim, a new language similarity\nmeasure that induces the similarities across languages from mPLMs using\nmulti-parallel corpora. Our study shows that mPLM-Sim exhibits moderately high\ncorrelations with linguistic similarity measures, such as lexicostatistics,\ngenealogical language family, and geographical sprachbund. We also conduct a\ncase study on languages with low correlation and observe that mPLM-Sim yields\nmore accurate similarity results. Additionally, we find that similarity results\nvary across different mPLMs and different layers within an mPLM. We further\ninvestigate whether mPLM-Sim is effective for zero-shot cross-lingual transfer\nby conducting experiments on both low-level syntactic tasks and high-level\nsemantic tasks. The experimental results demonstrate that mPLM-Sim is capable\nof selecting better source languages than linguistic measures, resulting in a\n1%-2% improvement in zero-shot cross-lingual transfer performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Peiqin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chengzhi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal Intervention for Abstractive Related Work Generation. (arXiv:2305.13685v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13685","description":"<p>Abstractive related work generation has attracted increasing attention in\ngenerating coherent related work that better helps readers grasp the background\nin the current research. However, most existing abstractive models ignore the\ninherent causality of related work generation, leading to low quality of\ngenerated related work and spurious correlations that affect the models'\ngeneralizability. In this study, we argue that causal intervention can address\nthese limitations and improve the quality and coherence of the generated\nrelated works. To this end, we propose a novel Causal Intervention Module for\nRelated Work Generation (CaM) to effectively capture causalities in the\ngeneration process and improve the quality and coherence of the generated\nrelated works. Specifically, we first model the relations among sentence order,\ndocument relation, and transitional content in related work generation using a\ncausal graph. Then, to implement the causal intervention and mitigate the\nnegative impact of spurious correlations, we use do-calculus to derive ordinary\nconditional probabilities and identify causal effects through CaM. Finally, we\nsubtly fuse CaM with Transformer to obtain an end-to-end generation model.\nExtensive experiments on two real-world datasets show that causal interventions\nin CaM can effectively promote the model to learn causal relations and produce\nrelated work of higher quality and coherence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiachang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Chongyang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naseem_U/0/1/0/all/0/1\">Usman Naseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shoujin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor Tsang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Asking Clarification Questions for Information Seeking on Task-Oriented Dialogues. (arXiv:2305.13690v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13690","description":"<p>Task-oriented dialogue systems aim at providing users with task-specific\nservices. Users of such systems often do not know all the information about the\ntask they are trying to accomplish, requiring them to seek information about\nthe task. To provide accurate and personalized task-oriented information\nseeking results, task-oriented dialogue systems need to address two potential\nissues: 1) users' inability to describe their complex information needs in\ntheir requests; and 2) ambiguous/missing information the system has about the\nusers. In this paper, we propose a new Multi-Attention Seq2Seq Network, named\nMAS2S, which can ask questions to clarify the user's information needs and the\nuser's profile in task-oriented information seeking. We also extend an existing\ndataset for task-oriented information seeking, leading to the \\ourdataset which\ncontains about 100k task-oriented information seeking dialogues that are made\npublicly available\\footnote{Dataset and code is available at\n\\href{https://github.com/sweetalyssum/clarit}{https://github.com/sweetalyssum/clarit}.}.\nExperimental results on \\ourdataset show that MAS2S outperforms baselines on\nboth clarification question generation and answer prediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yue Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_H/0/1/0/all/0/1\">Hossein A. Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yilmaz_E/0/1/0/all/0/1\">Emine Yilmaz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Open Domain Multi-Hop Question Answering with Few-Shot Data Synthesis. (arXiv:2305.13691v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13691","description":"<p>Few-shot learning for open domain multi-hop question answering typically\nrelies on large language models (LLMs). While powerful, LLMs are inefficient at\nthe inference time. We propose a data synthesis framework for multi-hop\nquestion answering that allows for improving smaller language models with less\nthan 10 human-annotated question answer pairs. The framework is built upon the\ndata generation functions parameterized by LLMs and prompts, which requires\nminimal hand-crafted features. Empirically, we synthesize millions of multi-hop\nquestions and claims. After finetuning language models on the synthetic data,\nwe evaluate the models on popular benchmarks on multi-hop question answering\nand fact verification. Our experimental results show that finetuning on the\nsynthetic data improves model performance significantly, allowing our finetuned\nmodels to be competitive with prior models while being almost one-third the\nsize in terms of parameter counts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingda Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Metrics for Medical Multi-Document Summarization Disagree with Human Evaluations. (arXiv:2305.13693v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13693","description":"<p>Evaluating multi-document summarization (MDS) quality is difficult. This is\nespecially true in the case of MDS for biomedical literature reviews, where\nmodels must synthesize contradicting evidence reported across different\ndocuments. Prior work has shown that rather than performing the task, models\nmay exploit shortcuts that are difficult to detect using standard n-gram\nsimilarity metrics such as ROUGE. Better automated evaluation metrics are\nneeded, but few resources exist to assess metrics when they are proposed.\nTherefore, we introduce a dataset of human-assessed summary quality facets and\npairwise preferences to encourage and support the development of better\nautomated evaluation methods for literature review MDS. We take advantage of\ncommunity submissions to the Multi-document Summarization for Literature Review\n(MSLR) shared task to compile a diverse and representative sample of generated\nsummaries. We analyze how automated summarization evaluation metrics correlate\nwith lexical features of generated summaries, to other automated metrics\nincluding several we propose in this work, and to aspects of human-assessed\nsummary quality. We find that not only do automated metrics fail to capture\naspects of quality as assessed by humans, in many cases the system rankings\nproduced by these metrics are anti-correlated with rankings according to human\nannotators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lucy Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otmakhova_Y/0/1/0/all/0/1\">Yulia Otmakhova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeYoung_J/0/1/0/all/0/1\">Jay DeYoung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truong_T/0/1/0/all/0/1\">Thinh Hung Truong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuehl_B/0/1/0/all/0/1\">Bailey E. Kuehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bransom_E/0/1/0/all/0/1\">Erin Bransom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Abstractive Text Summarization Using the BRIO Training Paradigm. (arXiv:2305.13696v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13696","description":"<p>Summary sentences produced by abstractive summarization models may be\ncoherent and comprehensive, but they lack control and rely heavily on reference\nsummaries. The BRIO training paradigm assumes a non-deterministic distribution\nto reduce the model's dependence on reference summaries, and improve model\nperformance during inference. This paper presents a straightforward but\neffective technique to improve abstractive summaries by fine-tuning pre-trained\nlanguage models, and training them with the BRIO paradigm. We build a text\nsummarization dataset for Vietnamese, called VieSum. We perform experiments\nwith abstractive summarization models trained with the BRIO paradigm on the\nCNNDM and the VieSum datasets. The results show that the models, trained on\nbasic hardware, outperform all existing abstractive summarization models,\nespecially for Vietnamese.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lam_K/0/1/0/all/0/1\">Khang Nhut Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doan_T/0/1/0/all/0/1\">Thieu Gia Doan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_K/0/1/0/all/0/1\">Khang Thua Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UNIMO-3: Multi-granularity Interaction for Vision-Language Representation Learning. (arXiv:2305.13697v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13697","description":"<p>Vision-and-language (VL) pre-training, which aims to learn a general\nrepresentation of image-text pairs that can be transferred to various\nvision-and-language tasks. Compared with modeling uni-modal data, the main\nchallenge of the VL model is: how to learn the cross-modal interaction from\nmultimodal data, especially the fine-grained interaction. Existing works have\nshown that fully transformer-based models that adopt attention mechanisms to\nlearn in-layer cross-model interaction can demonstrate impressive performance\non various cross-modal downstream tasks. However, they ignored that the\nsemantic information of the different modals at the same layer was not uniform,\nwhich leads to the cross-modal interaction collapsing into a limited\nmulti-modal semantic information interaction. In this work, we propose the\nUNIMO-3 model, which has the capacity to simultaneously learn the multimodal\nin-layer interaction and cross-layer interaction. UNIMO-3 model can establish\neffective connections between different layers in a cross-modal encoder, and\nadaptively capture the interaction between two modalities at different levels.\nThe experimental results show that our model achieves state-of-the-art\nperformance in various downstream tasks, and through ablation study can prove\nthat effective cross-layer learning improves the model's ability of multimodal\nrepresentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Can Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hao L&#xed;u</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinyan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Large Language Models for Classical Philology. (arXiv:2305.13698v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13698","description":"<p>Recent advances in NLP have led to the creation of powerful language models\nfor many languages including Ancient Greek and Latin. While prior work on\nClassical languages unanimously uses BERT, in this work we create four language\nmodels for Ancient Greek that vary along two dimensions to study their\nversatility for tasks of interest for Classical languages: we explore (i)\nencoder-only and encoder-decoder architectures using RoBERTa and T5 as strong\nmodel types, and create for each of them (ii) a monolingual Ancient Greek and a\nmultilingual instance that includes Latin and English. We evaluate all models\non morphological and syntactic tasks, including lemmatization, which\ndemonstrates the added value of T5's decoding abilities. We further define two\nprobing tasks to investigate the knowledge acquired by models pre-trained on\nClassical texts. Our experiments provide the first benchmarking analysis of\nexisting models of Ancient Greek. Results show that our models provide\nsignificant improvements over the SoTA. The systematic analysis of model types\ncan inform future research in designing language models for Classical\nlanguages, including the development of novel generative tasks. We make all our\nmodels available as community resources, along with a large curated\npre-training corpus for Ancient Greek, to support the creation of a larger,\ncomparable model zoo for Classical Philology. Our models and resources are\navailable at https://github.com/Heidelberg-NLP/ancient-language-models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Riemenschneider_F/0/1/0/all/0/1\">Frederick Riemenschneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MemeCap: A Dataset for Captioning and Interpreting Memes. (arXiv:2305.13703v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13703","description":"<p>Memes are a widely popular tool for web users to express their thoughts using\nvisual metaphors. Understanding memes requires recognizing and interpreting\nvisual metaphors with respect to the text inside or around the meme, often\nwhile employing background knowledge and reasoning abilities. We present the\ntask of meme captioning and release a new dataset, MemeCap. Our dataset\ncontains 6.3K memes along with the title of the post containing the meme, the\nmeme captions, the literal image caption, and the visual metaphors. Despite the\nrecent success of vision and language (VL) models on tasks such as image\ncaptioning and visual question answering, our extensive experiments using\nstate-of-the-art VL models show that they still struggle with visual metaphors,\nand perform substantially worse than humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hwang_E/0/1/0/all/0/1\">EunJeong Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. (arXiv:2305.13707v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13707","description":"<p>Language models have graduated from being research prototypes to\ncommercialized products offered as web APIs, and recent works have highlighted\nthe multilingual capabilities of these products. The API vendors charge their\nusers based on usage, more specifically on the number of ``tokens'' processed\nor generated by the underlying language models. What constitutes a token,\nhowever, is training data and model dependent with a large variance in the\nnumber of tokens required to convey the same information in different\nlanguages. In this work, we analyze the effect of this non-uniformity on the\nfairness of an API's pricing policy across languages. We conduct a systematic\nanalysis of the cost and utility of OpenAI's language model API on multilingual\nbenchmarks in 22 typologically diverse languages. We show evidence that\nspeakers of a large number of the supported languages are overcharged while\nobtaining poorer results. These speakers tend to also come from regions where\nthe APIs are less affordable to begin with. Through these analyses, we aim to\nincrease transparency around language model APIs' pricing policies and\nencourage the vendors to make them more equitable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahia_O/0/1/0/all/0/1\">Orevaoghene Ahia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sachin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonen_H/0/1/0/all/0/1\">Hila Gonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mortensen_D/0/1/0/all/0/1\">David R. Mortensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Textual Interface to Align External Knowledge for End-to-End Task-Oriented Dialogue Systems. (arXiv:2305.13710v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13710","description":"<p>Traditional end-to-end task-oriented dialogue systems have been built with a\nmodularized design. However, such design often causes misalignment between the\nagent response and external knowledge, due to inadequate representation of\ninformation. Furthermore, its evaluation metrics emphasize assessing the\nagent's pre-lexicalization response, neglecting the quality of the completed\nresponse. In this work, we propose a novel paradigm that uses a textual\ninterface to align external knowledge and eliminate redundant processes. We\ndemonstrate our paradigm in practice through MultiWOZ-Remake, including an\ninteractive textual interface built for the MultiWOZ database and a\ncorrespondingly re-processed dataset. We train an end-to-end dialogue system to\nevaluate this new dataset. The experimental results show that our approach\ngenerates more natural final responses and achieves a greater task success rate\ncompared to the previous models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alnuhait_D/0/1/0/all/0/1\">Deema Alnuhait</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Derek Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models. (arXiv:2305.13711v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13711","description":"<p>We propose LLM-Eval, a unified multi-dimensional automatic evaluation method\nfor open-domain conversations with large language models (LLMs). Existing\nevaluation methods often rely on human annotations, ground-truth responses, or\nmultiple LLM prompts, which can be expensive and time-consuming. To address\nthese issues, we design a single prompt-based evaluation method that leverages\na unified evaluation schema to cover multiple dimensions of conversation\nquality in a single model call. We extensively evaluate the performance of\nLLM-Eval on various benchmark datasets, demonstrating its effectiveness,\nefficiency, and adaptability compared to state-of-the-art evaluation methods.\nOur analysis also highlights the importance of choosing suitable LLMs and\ndecoding strategies for accurate evaluation results. LLM-Eval offers a\nversatile and robust solution for evaluating open-domain conversation systems,\nstreamlining the evaluation process and providing consistent performance across\ndiverse scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yen-Ting Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Nung Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models. (arXiv:2305.13712v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13712","description":"<p>This paper investigates the capabilities of Large Language Models (LLMs) in\nthe context of understanding their own knowledge and measuring their\nuncertainty. We argue this is an important feature for mitigating\nhallucinations. Specifically, we focus on addressing \\textit{known-unknown}\nquestions, characterized by high uncertainty due to the absence of definitive\nanswers. To facilitate our study, we collect a dataset with new Known-Unknown\nQuestions (KUQ) and propose a novel categorization scheme to elucidate the\nsources of uncertainty. Subsequently, we assess the LLMs' ability to\ndifferentiate between known and unknown questions and classify them\naccordingly. Moreover, we evaluate the quality of their answers in an\nOpen-Ended QA setting. To quantify the uncertainty expressed in the answers, we\ncreate a semantic evaluation method that measures the model's accuracy in\nexpressing uncertainty between known vs unknown questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amayuelas_A/0/1/0/all/0/1\">Alfonso Amayuelas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling and Attentive Listening in Customer Center. (arXiv:2305.13713v1 [cs.SD])","link":"http://arxiv.org/abs/2305.13713","description":"<p>We present CALLS, a Japanese speech corpus that considers phone calls in a\ncustomer center as a new domain of empathetic spoken dialogue. The existing\nSTUDIES corpus covers only empathetic dialogue between a teacher and student in\na school. To extend the application range of empathetic dialogue speech\nsynthesis (EDSS), we designed our corpus to include the same female speaker as\nthe STUDIES teacher, acting as an operator in simulated phone calls. We\ndescribe a corpus construction methodology and analyze the recorded speech. We\nalso conduct EDSS experiments using the CALLS and STUDIES corpora to\ninvestigate the effect of domain differences. The results show that mixing the\ntwo corpora during training causes biased improvements in the quality of\nsynthetic speech due to the different degrees of expressiveness. Our project\npage of the corpus is <a href=\"http://sython.org/Corpus/STUDIES-2.\">this http URL</a>\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1\">Yuki Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iimori_E/0/1/0/all/0/1\">Eiji Iimori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takamichi_S/0/1/0/all/0/1\">Shinnosuke Takamichi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tachibana_K/0/1/0/all/0/1\">Kentaro Tachibana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saruwatari_H/0/1/0/all/0/1\">Hiroshi Saruwatari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR. (arXiv:2305.13716v1 [cs.SD])","link":"http://arxiv.org/abs/2305.13716","description":"<p>The recently proposed serialized output training (SOT) simplifies\nmulti-talker automatic speech recognition (ASR) by generating speaker\ntranscriptions separated by a special token. However, frequent speaker changes\ncan make speaker change prediction difficult. To address this, we propose\nboundary-aware serialized output training (BA-SOT), which explicitly\nincorporates boundary knowledge into the decoder via a speaker change detection\ntask and boundary constraint loss. We also introduce a two-stage connectionist\ntemporal classification (CTC) strategy that incorporates token-level SOT CTC to\nrestore temporal context information. Besides typical character error rate\n(CER), we introduce utterance-dependent character error rate (UD-CER) to\nfurther measure the precision of speaker change prediction. Compared to\noriginal SOT, BA-SOT reduces CER/UD-CER by 5.1%/14.0%, and leveraging a\npre-trained ASR model for BA-SOT model initialization further reduces\nCER/UD-CER by 8.4%/19.9%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuhao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1\">Fan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangze Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1\">Pengcheng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lei Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LogicLLM: Exploring Self-supervised Logic-enhanced Training for Large Language Models. (arXiv:2305.13718v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13718","description":"<p>Existing efforts to improve logical reasoning ability of language models have\npredominantly relied on supervised fine-tuning, hindering generalization to new\ndomains and/or tasks. The development of Large Langauge Models (LLMs) has\ndemonstrated the capacity of compressing abundant knowledge into a single\nproxy, enabling them to tackle multiple tasks effectively. Our preliminary\nexperiments, nevertheless, show that LLMs do not show capability on logical\nreasoning. The performance of LLMs on logical reasoning benchmarks is far\nbehind the existing state-of-the-art baselines. In this paper, we make the\nfirst attempt to investigate the feasibility of incorporating logical knowledge\nthrough self-supervised post-training, and activating it via in-context\nlearning, which we termed as LogicLLM. Specifically, we devise an\nauto-regressive objective variant of MERIt and integrate it with two LLM\nseries, i.e., FLAN-T5 and LLaMA, with parameter size ranging from 3 billion to\n13 billion. The results on two challenging logical reasoning benchmarks\ndemonstrate the effectiveness of LogicLLM. Besides, we conduct extensive\nablation studies to analyze the key factors in designing logic-oriented proxy\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiao_F/0/1/0/all/0/1\">Fangkai Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1\">Zhiyang Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bosheng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Dialogue State Tracking via Example-Guided Question Answering. (arXiv:2305.13721v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13721","description":"<p>Dialogue systems are frequently updated to accommodate new services, but\nnaively updating them by continually training with data for new services in\ndiminishing performance on previously learnt services. Motivated by the insight\nthat dialogue state tracking (DST), a crucial component of dialogue systems\nthat estimates the user's goal as a conversation proceeds, is a simple natural\nlanguage understanding task, we propose reformulating it as a bundle of\ngranular example-guided question answering tasks to minimize the task shift\nbetween services and thus benefit continual learning. Our approach alleviates\nservice-specific memorization and teaches a model to contextualize the given\nquestion and example to extract the necessary information from the\nconversation. We find that a model with just 60M parameters can achieve a\nsignificant boost by learning to learn from in-context examples retrieved by a\nretriever trained to identify turns with similar dialogue state changes.\nCombining our method with dialogue-level memory replay, our approach attains\nstate of the art performance on DST continual learning metrics without relying\non any complex regularization or parameter expansion methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyundong Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1\">Satwik Kottur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankar_C/0/1/0/all/0/1\">Chinnadhurai Sankar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptClass: Weakly-Supervised Text Classification with Prompting Enhanced Noise-Robust Self-Training. (arXiv:2305.13723v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13723","description":"<p>Recently proposed weakly-supervised text classification settings train a\nclassifier using the label name of each target class as the only supervision.\nSuch weakly-supervised settings have been gaining increasing attention since\nthey can largely reduce human annotation efforts compared to fully-supervised\nand semi-supervised settings. Most existing methods follow the strategy that\nfirst uses the label names as static features to generate pseudo labels, which\nare then used for classifier training. While reasonable, such a commonly\nadopted framework suffers from two limitations: (1) words can have different\nmeanings in different contexts, so using label names for context-free matching\ncan induce very noisy pseudo labels; and (2) the errors made in the pseudo\nlabel generation stage will directly propagate to the classifier training stage\nwithout a chance of being corrected. In this paper, we propose a new method,\nPromptClass, consisting of two modules: (1) a pseudo label acquisition module\nthat uses zero-shot prompting of pre-trained language models (PLM) to get\npseudo labels based on contextualized text understanding, and (2) a\nnoise-robust self-training module that iteratively trains the classifier and\nupdates pseudo labels by utilizing two PLM fine-tuning strategies that\nregularize each other. Extensive experiments show that PromptClass achieves\noverall better performance than existing strong baselines on four benchmark\ndatasets and even achieves similar performance to fully-supervised classifiers\non sentiment classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from ChatGPT-derived Context Word Embeddings. (arXiv:2305.13724v1 [cs.SD])","link":"http://arxiv.org/abs/2305.13724","description":"<p>We propose ChatGPT-EDSS, an empathetic dialogue speech synthesis (EDSS)\nmethod using ChatGPT for extracting dialogue context. ChatGPT is a chatbot that\ncan deeply understand the content and purpose of an input prompt and\nappropriately respond to the user's request. We focus on ChatGPT's reading\ncomprehension and introduce it to EDSS, a task of synthesizing speech that can\nempathize with the interlocutor's emotion. Our method first gives chat history\nto ChatGPT and asks it to generate three words representing the intention,\nemotion, and speaking style for each line in the chat. Then, it trains an EDSS\nmodel using the embeddings of ChatGPT-derived context words as the conditioning\nfeatures. The experimental results demonstrate that our method performs\ncomparably to ones using emotion labels or neural network-derived context\nembeddings learned from chat histories. The collected ChatGPT-derived context\ninformation is available at\nhttps://sarulab-speech.github.io/demo_ChatGPT_EDSS/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1\">Yuki Saito</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takamichi_S/0/1/0/all/0/1\">Shinnosuke Takamichi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iimori_E/0/1/0/all/0/1\">Eiji Iimori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tachibana_K/0/1/0/all/0/1\">Kentaro Tachibana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saruwatari_H/0/1/0/all/0/1\">Hiroshi Saruwatari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Recommendation as Retrieval: A Simple, Strong Baseline. (arXiv:2305.13725v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13725","description":"<p>Conversational recommendation systems (CRS) aim to recommend suitable items\nto users through natural language conversation. However, most CRS approaches do\nnot effectively utilize the signal provided by these conversations. They rely\nheavily on explicit external knowledge e.g., knowledge graphs to augment the\nmodels' understanding of the items and attributes, which is quite hard to\nscale. To alleviate this, we propose an alternative information retrieval\n(IR)-styled approach to the CRS item recommendation task, where we represent\nconversations as queries and items as documents to be retrieved. We expand the\ndocument representation used for retrieval with conversations from the training\nset. With a simple BM25-based retriever, we show that our task formulation\ncompares favorably with much more complex baselines using complex external\nknowledge on a popular CRS benchmark. We demonstrate further improvements using\nuser-centric modeling and data augmentation to counter the cold start problem\nfor CRSs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Raghav Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aksitov_R/0/1/0/all/0/1\">Renat Aksitov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phatale_S/0/1/0/all/0/1\">Samrat Phatale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_S/0/1/0/all/0/1\">Simral Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Harrison Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1\">Abhinav Rastogi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker. (arXiv:2305.13729v1 [cs.IR])","link":"http://arxiv.org/abs/2305.13729","description":"<p>Re-rankers, which order retrieved documents with respect to the relevance\nscore on the given query, have gained attention for the information retrieval\n(IR) task. Rather than fine-tuning the pre-trained language model (PLM), the\nlarge-scale language model (LLM) is utilized as a zero-shot re-ranker with\nexcellent results. While LLM is highly dependent on the prompts, the impact and\nthe optimization of the prompts for the zero-shot re-ranker are not explored\nyet. Along with highlighting the impact of optimization on the zero-shot\nre-ranker, we propose a novel discrete prompt optimization method, Constrained\nPrompt generation (Co-Prompt), with the metric estimating the optimum for\nre-ranking. Co-Prompt guides the generated texts from PLM toward optimal\nprompts based on the metric without parameter update. The experimental results\ndemonstrate that Co-Prompt leads to outstanding re-ranking performance against\nthe baselines. Also, Co-Prompt generates more interpretable prompts for humans\nagainst other prompt optimization methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sukmin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Soyeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jeongyeon Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong C. Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Critique Prompting with Large Language Models for Inductive Instructions. (arXiv:2305.13733v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13733","description":"<p>Numerous works are proposed to improve or evaluate the capabilities of Large\nlanguage models (LLMs) to fulfill user instructions. However, they neglect the\npossibility that user inputs may inherently contain incorrect information due\nto users' false beliefs or malicious intents. In this way, blindly adhering to\nusers' false content will cause deception and harm. To address this problem, we\npropose a challenging benchmark consisting of Inductive Instructions (INDust)\nto evaluate whether LLMs could resist these instructions. The INDust includes\n15K instructions across three categories: Fact-Checking Instructions, Questions\nbased on False Premises, and Creative Instructions based on False Premises. Our\nexperiments on several strong LLMs reveal that current LLMs can be easily\ndeceived by INDust into generating misleading and malicious statements. Hence\nwe employ Self-Critique prompting to encourage LLMs to not only critique\nthemselves like in previous works but also the users, which show remarkable\nimprovement in handling inductive instructions under both zero-shot and\nfew-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Large Language Models through Synthetic Feedback. (arXiv:2305.13735v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13735","description":"<p>Aligning large language models (LLMs) to human values has become increasingly\nimportant as it enables sophisticated steering of LLMs, e.g., making them\nfollow given instructions while keeping them less toxic. However, it requires a\nsignificant amount of human demonstrations and feedback. Recently, open-sourced\nmodels have attempted to replicate the alignment learning process by distilling\ndata from already aligned LLMs like InstructGPT or ChatGPT. While this process\nreduces human efforts, constructing these datasets has a heavy dependency on\nthe teacher models. In this work, we propose a novel framework for alignment\nlearning with almost no human labor and no dependency on pre-aligned LLMs.\nFirst, we perform reward modeling (RM) with synthetic feedback by contrasting\nresponses from vanilla LLMs with various sizes and prompts. Then, we use the RM\nfor simulating high-quality demonstrations to train a supervised policy and for\nfurther optimizing the model with reinforcement learning. Our resulting model,\nAligned Language Model with Synthetic Training dataset (ALMoST), outperforms\nopen-sourced models, including Alpaca, Dolly, and OpenAssistant, which are\ntrained on the outputs of InstructGPT or human-annotated instructions. Our\n7B-sized model outperforms the 12-13B models in the A/B tests using GPT-4 as\nthe judge with about 75% winning rate on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Sanghwan Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Soyoung Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwak_D/0/1/0/all/0/1\">Donghyun Kwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_K/0/1/0/all/0/1\">Kang Min Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"i-Code Studio: A Configurable and Composable Framework for Integrative AI. (arXiv:2305.13738v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13738","description":"<p>Artificial General Intelligence (AGI) requires comprehensive understanding\nand generation capabilities for a variety of tasks spanning different\nmodalities and functionalities. Integrative AI is one important direction to\napproach AGI, through combining multiple models to tackle complex multimodal\ntasks. However, there is a lack of a flexible and composable platform to\nfacilitate efficient and effective model composition and coordination. In this\npaper, we propose the i-Code Studio, a configurable and composable framework\nfor Integrative AI. The i-Code Studio orchestrates multiple pre-trained models\nin a finetuning-free fashion to conduct complex multimodal tasks. Instead of\nsimple model composition, the i-Code Studio provides an integrative, flexible,\nand composable setting for developers to quickly and easily compose\ncutting-edge services and technologies tailored to their specific requirements.\nThe i-Code Studio achieves impressive results on a variety of zero-shot\nmultimodal tasks, such as video-to-text retrieval, speech-to-speech\ntranslation, and visual question answering. We also demonstrate how to quickly\nbuild a multimodal agent based on the i-Code Studio that can communicate and\npersonalize for users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khademi_M/0/1/0/all/0/1\">Mahmoud Khademi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yao Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoshioka_T/0/1/0/all/0/1\">Takuya Yoshioka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuedong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TeCS: A Dataset and Benchmark for Tense Consistency of Machine Translation. (arXiv:2305.13740v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13740","description":"<p>Tense inconsistency frequently occurs in machine translation. However, there\nare few criteria to assess the model's mastery of tense prediction from a\nlinguistic perspective. In this paper, we present a parallel tense test set,\ncontaining French-English 552 utterances. We also introduce a corresponding\nbenchmark, tense prediction accuracy. With the tense test set and the\nbenchmark, researchers are able to measure the tense consistency performance of\nmachine translation systems for the first time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ai_Y/0/1/0/all/0/1\">Yiming Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1\">Kai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Goal-Driven Explainable Clustering via Language Descriptions. (arXiv:2305.13749v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13749","description":"<p>Unsupervised clustering is widely used to explore large corpora, but existing\nformulations neither consider the users' goals nor explain clusters' meanings.\nWe propose a new task formulation, \"Goal-Driven Clustering with Explanations\"\n(GoalEx), which represents both the goal and the explanations as free-form\nlanguage descriptions. For example, to categorize the errors made by a\nsummarization system, the input to GoalEx is a corpus of annotator-written\ncomments for system-generated summaries and a goal description \"cluster the\ncomments based on why the annotators think the summary is imperfect.''; the\noutputs are text clusters each with an explanation (\"this cluster mentions that\nthe summary misses important context information.\"), which relates to the goal\nand precisely explain which comments should (not) belong to a cluster. To\ntackle GoalEx, we prompt a language model with \"[corpus subset] + [goal] +\nBrainstorm a list of explanations each representing a cluster.\"; then we\nclassify whether each sample belongs to a cluster based on its explanation;\nfinally, we use integer linear programming to select a subset of candidate\nclusters to cover most samples while minimizing overlaps. We apply GoalEx\nhierarchically to produce trees of progressively finer-grained clusters,\ninducing taxonomies over debate arguments, customer complaints, and model\nerrors. We release our data and implementation at\nhttps://github.com/ZihanWangKi/GoalEx.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenges in Context-Aware Neural Machine Translation. (arXiv:2305.13751v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13751","description":"<p>Context-aware neural machine translation involves leveraging information\nbeyond sentence-level context to resolve inter-sentential discourse\ndependencies and improve document-level translation quality, and has given rise\nto a number of recent techniques. However, despite well-reasoned intuitions,\nmost context-aware translation models show only modest improvements over\nsentence-level systems. In this work, we investigate several challenges that\nimpede progress within this field, relating to discourse phenomena, context\nusage, model architectures, and document-level evaluation. To address these\nproblems, we propose a more realistic setting for document-level translation,\ncalled paragraph-to-paragraph (para2para) translation, and collect a new\ndataset of Chinese-English novels to promote future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Linghao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jacqueline He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic-driven Distant Supervision Framework for Macro-level Discourse Parsing. (arXiv:2305.13755v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13755","description":"<p>Discourse parsing, the task of analyzing the internal rhetorical structure of\ntexts, is a challenging problem in natural language processing. Despite the\nrecent advances in neural models, the lack of large-scale, high-quality corpora\nfor training remains a major obstacle. Recent studies have attempted to\novercome this limitation by using distant supervision, which utilizes results\nfrom other NLP tasks (e.g., sentiment polarity, attention matrix, and\nsegmentation probability) to parse discourse trees. However, these methods do\nnot take into account the differences between in-domain and out-of-domain\ntasks, resulting in lower performance and inability to leverage the\nhigh-quality in-domain data for further improvement. To address these issues,\nwe propose a distant supervision framework that leverages the relations between\ntopic structure and rhetorical structure. Specifically, we propose two\ndistantly supervised methods, based on transfer learning and the\nteacher-student model, that narrow the gap between in-domain and out-of-domain\ntasks through label mapping and oracle annotation. Experimental results on the\nMCDTB and RST-DT datasets show that our methods achieve the best performance in\nboth distant-supervised and supervised scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1\">Feng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Longwang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qiaoming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Concept-aware Training Improves In-context Learning Ability of Language Models. (arXiv:2305.13775v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13775","description":"<p>Many recent language models (LMs) of Transformers family exhibit so-called\nin-context learning (ICL) ability, manifested in the LMs' ability to modulate\ntheir function by a task described in a natural language input. Previous work\ncurating these models assumes that ICL emerges from vast over-parametrization\nor the scale of multi-task training. However, a complementary branch of recent\ntheoretical work attributes ICL emergence to specific properties of training\ndata and creates functional in-context learners in small-scale, synthetic\nsettings.\n</p>\n<p>Inspired by recent findings on data properties driving the emergence of ICL,\nwe propose a method to create LMs able to better utilize the in-context\ninformation, by constructing training scenarios where it is beneficial for the\nLM to capture the analogical reasoning concepts. We measure that data sampling\nof Concept-aware Training (CoAT) consistently improves models' reasoning\nability. As a result, the in-context learners trained with CoAT on only two\ndatasets of a single (QA) task perform comparably to larger models trained on\n1600+ tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stefanik_M/0/1/0/all/0/1\">Michal &#x160;tef&#xe1;nik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kadlcik_M/0/1/0/all/0/1\">Marek Kadl&#x10d;&#xed;k</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation. (arXiv:2305.13776v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13776","description":"<p>Counterspeech has been demonstrated to be an efficacious approach for\ncombating hate speech. While various conventional and controlled approaches\nhave been studied in recent years to generate counterspeech, a counterspeech\nwith a certain intent may not be sufficient in every scenario. Due to the\ncomplex and multifaceted nature of hate speech, utilizing multiple forms of\ncounter-narratives with varying intents may be advantageous in different\ncircumstances. In this paper, we explore intent-conditioned counterspeech\ngeneration. At first, we develop IntentCONAN, a diversified intent-specific\ncounterspeech dataset with 6831 counterspeeches conditioned on five intents,\ni.e., informative, denouncing, question, positive, and humour. Subsequently, we\npropose QUARC, a two-stage framework for intent-conditioned counterspeech\ngeneration. QUARC leverages vector-quantized representations learned for each\nintent category along with PerFuMe, a novel fusion module to incorporate\nintent-specific information into the model. Our evaluation demonstrates that\nQUARC outperforms several baselines by an average of 10% across evaluation\nmetrics. An extensive human evaluation supplements our hypothesis of better and\nmore appropriate responses than comparative systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rishabh Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desai_S/0/1/0/all/0/1\">Shaily Desai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_M/0/1/0/all/0/1\">Manvi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandhakavi_A/0/1/0/all/0/1\">Anil Bandhakavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md. Shad Akhtar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Images in Language Space: Exploring the Suitability of Large Language Models for Vision & Language Tasks. (arXiv:2305.13782v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13782","description":"<p>Large language models have demonstrated robust performance on various\nlanguage tasks using zero-shot or few-shot learning paradigms. While being\nactively researched, multimodal models that can additionally handle images as\ninput have yet to catch up in size and generality with language-only models. In\nthis work, we ask whether language-only models can be utilised for tasks that\nrequire visual input -- but also, as we argue, often require a strong reasoning\ncomponent. Similar to some recent related work, we make visual information\naccessible to the language model using separate verbalisation models.\nSpecifically, we investigate the performance of open-source, open-access\nlanguage models against GPT-3 on five vision-language tasks when given\ntextually-encoded visual information. Our results suggest that language models\nare effective for solving vision-language tasks even with limited samples. This\napproach also enhances the interpretability of a model's output by providing a\nmeans of tracing the output back through the verbalised image content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1\">Sherzod Hakimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlangen_D/0/1/0/all/0/1\">David Schlangen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation. (arXiv:2305.13785v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13785","description":"<p>Training or finetuning large-scale language models (LLMs) such as GPT-3\nrequires substantial computation resources, motivating recent efforts to\nexplore parameter-efficient adaptation to downstream tasks. One practical area\nof research is to treat these models as black boxes and interact with them\nthrough their inference APIs. In this paper, we investigate how to optimize\nfew-shot text classification without accessing the gradients of the LLMs. To\nachieve this, we treat the black-box model as a feature extractor and train a\nclassifier with the augmented text data. Data augmentation is performed using\nprompt-based finetuning on an auxiliary language model with a much smaller\nparameter size than the black-box model. Through extensive experiments on eight\ntext classification datasets, we show that our approach, dubbed BT-Classifier,\nsignificantly outperforms state-of-the-art black-box few-shot learners and\nperforms on par with methods that rely on full-model tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1\">Danqing Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiahui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Infer and Disagree Like Humans?. (arXiv:2305.13788v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13788","description":"<p>Large Language Models (LLMs) have shown stellar achievements in solving a\nbroad range of tasks. When generating text, it is common to sample tokens from\nthese models: whether LLMs closely align with the human disagreement\ndistribution has not been well-studied, especially within the scope of Natural\nLanguage Inference (NLI). In this paper, we evaluate the performance and\nalignment of LLM distribution with humans using two different techniques: Monte\nCarlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a\nresult, we show LLMs exhibit limited ability in solving NLI tasks and\nsimultaneously fail to capture human disagreement distribution, raising\nconcerns about their natural language understanding (NLU) ability and their\nrepresentativeness of human users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Noah Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_N/0/1/0/all/0/1\">Na Min An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personalized Predictive ASR for Latency Reduction in Voice Assistants. (arXiv:2305.13794v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13794","description":"<p>Streaming Automatic Speech Recognition (ASR) in voice assistants can utilize\nprefetching to partially hide the latency of response generation. Prefetching\ninvolves passing a preliminary ASR hypothesis to downstream systems in order to\nprefetch and cache a response. If the final ASR hypothesis after endpoint\ndetection matches the preliminary one, the cached response can be delivered to\nthe user, thus saving latency. In this paper, we extend this idea by\nintroducing predictive automatic speech recognition, where we predict the full\nutterance from a partially observed utterance, and prefetch the response based\non the predicted utterance. We introduce two personalization approaches and\ninvestigate the tradeoff between potential latency gains from successful\npredictions and the cost increase from failed predictions. We evaluate our\nmethods on an internal voice assistant dataset as well as the public SLURP\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schwarz_A/0/1/0/all/0/1\">Andreas Schwarz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Di He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segbroeck_M/0/1/0/all/0/1\">Maarten Van Segbroeck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hethnawi_M/0/1/0/all/0/1\">Mohammed Hethnawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1\">Ariya Rastrow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Zero-shot Relation Extraction in Web Mining: A Multimodal Approach with Relative XML Path. (arXiv:2305.13805v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13805","description":"<p>The rapid growth of web pages and the increasing complexity of their\nstructure poses a challenge for web mining models. Web mining models are\nrequired to understand the semi-structured web pages, particularly when little\nis known about the subject or template of a new page. Current methods migrate\nlanguage models to the web mining by embedding the XML source code into the\ntransformer or encoding the rendered layout with graph neural networks.\nHowever, these approaches do not take into account the relationships between\ntext nodes within and across pages. In this paper, we propose a new approach,\nReXMiner, for zero-shot relation extraction in web mining. ReXMiner encodes the\nshortest relative paths in the Document Object Model (DOM) tree which is a more\naccurate and efficient signal for key-value pair extraction within a web page.\nIt also incorporates the popularity of each text node by counting the\noccurrence of the same text node across different web pages. We use the\ncontrastive learning to address the issue of sparsity in relation extraction.\nExtensive experiments on public benchmarks show that our method, ReXMiner,\noutperforms the state-of-the-art baselines in the task of zero-shot relation\nextraction in web mining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Asking Clarification Questions to Handle Ambiguity in Open-Domain QA. (arXiv:2305.13808v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13808","description":"<p>Ambiguous questions persist in open-domain question answering, because\nformulating a precise question with a unique answer is often challenging.\nPreviously, Min et al. (2020) have tackled this issue by generating\ndisambiguated questions for all possible interpretations of the ambiguous\nquestion. This can be effective, but not ideal for providing an answer to the\nuser. Instead, we propose to ask a clarification question, where the user's\nresponse will help identify the interpretation that best aligns with the user's\nintention. We first present CAMBIGNQ, a dataset consisting of 5,654 ambiguous\nquestions, each with relevant passages, possible answers, and a clarification\nquestion. The clarification questions were efficiently created by generating\nthem using InstructGPT and manually revising them as necessary. We then define\na pipeline of tasks and design appropriate evaluation metrics. Lastly, we\nachieve 61.3 F1 on ambiguity detection and 40.5 F1 on clarification-based QA,\nproviding strong baselines for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongryeol Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Segwang Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hwanhee Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Joonsuk Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Woo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyomin Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for Improved Vision-Language Compositionality. (arXiv:2305.13812v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13812","description":"<p>Contrastively trained vision-language models have achieved remarkable\nprogress in vision and language representation learning, leading to\nstate-of-the-art models for various downstream multimodal tasks. However,\nrecent research has highlighted severe limitations of these models in their\nability to perform compositional reasoning over objects, attributes, and\nrelations. Scene graphs have emerged as an effective way to understand images\ncompositionally. These are graph-structured semantic representations of images\nthat contain objects, their attributes, and relations with other objects in a\nscene. In this work, we consider the scene graph parsed from text as a proxy\nfor the image scene graph and propose a graph decomposition and augmentation\nframework along with a coarse-to-fine contrastive learning objective between\nimages and text that aligns sentences of various complexities to the same\nimage. Along with this, we propose novel negative mining techniques in the\nscene graph space for improving attribute binding and relation understanding.\nThrough extensive experiments, we demonstrate the effectiveness of our approach\nthat significantly improves attribute binding, relation understanding,\nsystematic generalization, and productivity on multiple recently proposed\nbenchmarks (For example, improvements upto $18\\%$ for systematic\ngeneralization, $16.5\\%$ for relation understanding over a strong baseline),\nwhile achieving similar or better performance than CLIP on various general\nmultimodal tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_H/0/1/0/all/0/1\">Harman Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pengchuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengjiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jingfei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting automatically the layout of clinical documents to enhance the performances of downstream natural language processing. (arXiv:2305.13817v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13817","description":"<p>Objective:Develop and validate an algorithm for analyzing the layout of PDF\nclinical documents to improve the performance of downstream natural language\nprocessing tasks. Materials and Methods: We designed an algorithm to process\nclinical PDF documents and extract only clinically relevant text. The algorithm\nconsists of several steps: initial text extraction using a PDF parser, followed\nby classification into categories such as body text, left notes, and footers\nusing a Transformer deep neural network architecture, and finally an\naggregation step to compile the lines of a given label in the text. We\nevaluated the technical performance of the body text extraction algorithm by\napplying it to a random sample of documents that were annotated. Medical\nperformance was evaluated by examining the extraction of medical concepts of\ninterest from the text in their respective sections. Finally, we tested an\nend-to-end system on a medical use case of automatic detection of acute\ninfection described in the hospital report. Results:Our algorithm achieved\nper-line precision, recall, and F1 score of 98.4, 97.0, and 97.7, respectively,\nfor body line extraction. The precision, recall, and F1 score per document for\nthe acute infection detection algorithm were 82.54 (95CI 72.86-91.60), 85.24\n(95CI 76.61-93.70), 83.87 (95CI 76, 92-90.08) with exploitation of the results\nof the advanced body extraction algorithm, respectively. Conclusion:We have\ndeveloped and validated a system for extracting body text from clinical\ndocuments in PDF format by identifying their layout. We were able to\ndemonstrate that this preprocessing allowed us to obtain better performances\nfor a common downstream task, i.e., the extraction of medical concepts in their\nrespective sections, thus proving the interest of this method on a clinical use\ncase.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gerardin_C/0/1/0/all/0/1\">Christel G&#xe9;rardin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wajsburt_P/0/1/0/all/0/1\">Perceval Wajsb&#xfc;rt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dura_B/0/1/0/all/0/1\">Basile Dura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calliger_A/0/1/0/all/0/1\">Alice Calliger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moucher_A/0/1/0/all/0/1\">Alexandre Moucher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tannier_X/0/1/0/all/0/1\">Xavier Tannier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bey_R/0/1/0/all/0/1\">Romain Bey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Open Dataset and Model for Language Identification. (arXiv:2305.13820v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13820","description":"<p>Language identification (LID) is a fundamental step in many natural language\nprocessing pipelines. However, current LID systems are far from perfect,\nparticularly on lower-resource languages. We present a LID model which achieves\na macro-average F1 score of 0.93 and a false positive rate of 0.033 across 201\nlanguages, outperforming previous work. We achieve this by training on a\ncurated dataset of monolingual data, the reliability of which we ensure by\nauditing a sample from each source and each language manually. We make both the\nmodel and the dataset available to the research community. Finally, we carry\nout detailed analysis into our model's performance, both in comparison to\nexisting open models and by language class.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burchell_L/0/1/0/all/0/1\">Laurie Burchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogoychev_N/0/1/0/all/0/1\">Nikolay Bogoychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heafield_K/0/1/0/all/0/1\">Kenneth Heafield</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Is the Pope Catholic?\" Applying Chain-of-Thought Reasoning to Understanding Conversational Implicatures. (arXiv:2305.13826v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13826","description":"<p>Conversational implicatures are pragmatic inferences that require listeners\nto deduce the intended meaning conveyed by a speaker from their explicit\nutterances. Although such inferential reasoning is fundamental to human\ncommunication, recent research indicates that large language models struggle to\ncomprehend these implicatures as effectively as the average human. This paper\ndemonstrates that by incorporating Grice's Four Maxims into the model through\nchain-of-thought prompting, we can significantly enhance its performance,\nsurpassing even the average human performance on this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_Z/0/1/0/all/0/1\">Zae Myung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_D/0/1/0/all/0/1\">David E. Taylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learn from Mistakes through Cooperative Interaction with Study Assistant. (arXiv:2305.13829v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13829","description":"<p>Large language models have demonstrated their ability to self-reflect and\nrefine their generation, which can further improve their performance. However,\nthis feedback mechanism faces challenges such as no guarantee of correctness\nand the lack of global insight into the model's weaknesses. In this paper, we\npropose a novel framework, Study Assistant for Large Language Model (SALAM), to\naid LLMs in the reflection and refinement process. Motivated by the human study\nassistant, this framework grades previous responses with the ground truth and\ncollects mistakes in the training phase. During inference, it identifies common\nmisunderstandings based on the mistake collections and provides guidelines for\nthe model to help the model avoid similar mistakes during inference. SALAM is a\nmodel-agnostic framework, focusing on providing general feedback and can adapt\nto any base model. Our evaluation of SALAM on two challenging benchmarks\ndemonstrated a significant improvement over various baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Danqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech Synthesis with Diffusion and Style-based Models. (arXiv:2305.13831v1 [cs.SD])","link":"http://arxiv.org/abs/2305.13831","description":"<p>Emotional Text-To-Speech (TTS) is an important task in the development of\nsystems (e.g., human-like dialogue agents) that require natural and emotional\nspeech. Existing approaches, however, only aim to produce emotional TTS for\nseen speakers during training, without consideration of the generalization to\nunseen speakers. In this paper, we propose ZET-Speech, a zero-shot adaptive\nemotion-controllable TTS model that allows users to synthesize any speaker's\nemotional speech using only a short, neutral speech segment and the target\nemotion label. Specifically, to enable a zero-shot adaptive TTS model to\nsynthesize emotional speech, we propose domain adversarial learning and\nguidance methods on the diffusion model. Experimental results demonstrate that\nZET-Speech successfully synthesizes natural and emotional speech with the\ndesired emotion for both seen and unseen speakers. Samples are at\nhttps://ZET-Speech.github.io/ZET-Speech-Demo/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wooseok Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eunho Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reducing Sensitivity on Speaker Names for Text Generation from Dialogues. (arXiv:2305.13833v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13833","description":"<p>Changing speaker names consistently throughout a dialogue should not affect\nits meaning and corresponding outputs for text generation from dialogues.\nHowever, pre-trained language models, serving as the backbone for\ndialogue-processing tasks, have shown to be sensitive to nuances. This may\nresult in unfairness in real-world applications. No comprehensive analysis of\nthis problem has been done in the past. In this work, we propose to\nquantitatively measure a model's sensitivity on speaker names, and\ncomprehensively evaluate a number of known methods for reducing speaker name\nsensitivity, including a novel approach of our own. Extensive experiments on\nmultiple datasets provide a benchmark for this problem and show the favorable\nperformance of our approach in sensitivity reduction and quality of generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Q/0/1/0/all/0/1\">Qi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haifeng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Arukikata Travelogue Dataset with Geographic Entity Mention, Coreference, and Link Annotation. (arXiv:2305.13844v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13844","description":"<p>Geoparsing is a fundamental technique for analyzing geo-entity information in\ntext. We focus on document-level geoparsing, which considers geographic\nrelatedness among geo-entity mentions, and presents a Japanese travelogue\ndataset designed for evaluating document-level geoparsing systems. Our dataset\ncomprises 200 travelogue documents with rich geo-entity information: 12,171\nmentions, 6,339 coreference clusters, and 2,551 geo-entities linked to\ngeo-database entries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Higashiyama_S/0/1/0/all/0/1\">Shohei Higashiyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouchi_H/0/1/0/all/0/1\">Hiroki Ouchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teranishi_H/0/1/0/all/0/1\">Hiroki Teranishi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Otomo_H/0/1/0/all/0/1\">Hiroyuki Otomo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ide_Y/0/1/0/all/0/1\">Yusuke Ide</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamamoto_A/0/1/0/all/0/1\">Aitaro Yamamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shindo_H/0/1/0/all/0/1\">Hiroyuki Shindo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuda_Y/0/1/0/all/0/1\">Yuki Matsuda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wakamiya_S/0/1/0/all/0/1\">Shoko Wakamiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inoue_N/0/1/0/all/0/1\">Naoya Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamada_I/0/1/0/all/0/1\">Ikuya Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1\">Taro Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document. (arXiv:2305.13850v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13850","description":"<p>Visual relation extraction (VRE) aims to extract relations between entities\nfrom visuallyrich documents. Existing methods usually predict relations for\neach entity pair independently based on entity features but ignore the global\nstructure information, i.e., dependencies between entity pairs. The absence of\nglobal structure information may make the model struggle to learn long-range\nrelations and easily predict conflicted results. To alleviate such limitations,\nwe propose a GlObal Structure knowledgeguided relation Extraction (GOSE)\nframework, which captures dependencies between entity pairs in an iterative\nmanner. Given a scanned image of the document, GOSE firstly generates\npreliminary relation predictions on entity pairs. Secondly, it mines global\nstructure knowledge based on prediction results of the previous iteration and\nfurther incorporates global structure knowledge into entity representations.\nThis \"generate-capture-incorporate\" schema is performed multiple times so that\nentity representations and global structure knowledge can mutually reinforce\neach other. Extensive experiments show that GOSE not only outperforms previous\nmethods on the standard fine-tuning setting but also shows promising\nsuperiority in cross-lingual learning; even yields stronger data-efficient\nperformance in the low-resource setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangnan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juncheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1\">Duo Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Q/0/1/0/all/0/1\">Qian Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revealing User Familiarity Bias in Task-Oriented Dialogue via Interactive Evaluation. (arXiv:2305.13857v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13857","description":"<p>Most task-oriented dialogue (TOD) benchmarks assume users that know exactly\nhow to use the system by constraining the user behaviors within the system's\ncapabilities via strict user goals, namely \"user familiarity\" bias. This data\nbias deepens when it combines with data-driven TOD systems, as it is impossible\nto fathom the effect of it with existing static evaluations. Hence, we conduct\nan interactive user study to unveil how vulnerable TOD systems are against\nrealistic scenarios. In particular, we compare users with 1) detailed goal\ninstructions that conform to the system boundaries (closed-goal) and 2) vague\ngoal instructions that are often unsupported but realistic (open-goal). Our\nstudy reveals that conversations in open-goal settings lead to catastrophic\nfailures of the system, in which 92% of the dialogues had significant issues.\nMoreover, we conduct a thorough analysis to identify distinctive features\nbetween the two settings through error annotation. From this, we discover a\nnovel \"pretending\" behavior, in which the system pretends to handle the user\nrequests even though they are beyond the system's capabilities. We discuss its\ncharacteristics and toxicity while emphasizing transparency and a fallback\nstrategy for robust TOD systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Takyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Ho Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Sanghwan Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study. (arXiv:2305.13860v1 [cs.SE])","link":"http://arxiv.org/abs/2305.13860","description":"<p>Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential\nbut also introduce challenges related to content constraints and potential\nmisuse. Our study investigates three key research questions: (1) the number of\ndifferent prompt types that can jailbreak LLMs, (2) the effectiveness of\njailbreak prompts in circumventing LLM constraints, and (3) the resilience of\nChatGPT against these jailbreak prompts. Initially, we develop a classification\nmodel to analyze the distribution of existing prompts, identifying ten distinct\npatterns and three categories of jailbreak prompts. Subsequently, we assess the\njailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a\ndataset of 3,120 jailbreak questions across eight prohibited scenarios.\nFinally, we evaluate the resistance of ChatGPT against jailbreak prompts,\nfinding that the prompts can consistently evade the restrictions in 40 use-case\nscenarios. The study underscores the importance of prompt structures in\njailbreaking LLMs and discusses the challenges of robust jailbreak prompt\ngeneration and prevention.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_G/0/1/0/all/0/1\">Gelei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhengzi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuekang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yaowen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ying Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lida Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Trip Towards Fairness: Bias and De-Biasing in Large Language Models. (arXiv:2305.13862v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13862","description":"<p>An outbreak in the popularity of transformer-based Language Models (such as\nGPT (Brown et al., 2020) and PaLM (Chowdhery et al., 2022)) has opened the\ndoors to new Machine Learning applications. In particular, in Natural Language\nProcessing and how pre-training from large text, corpora is essential in\nachieving remarkable results in downstream tasks. However, these Language\nModels seem to have inherent biases toward certain demographics reflected in\ntheir training data. While research has attempted to mitigate this problem,\nexisting methods either fail to remove bias altogether, degrade performance, or\nare expensive. This paper examines the bias produced by promising Language\nModels when varying parameters and pre-training data. Finally, we propose a\nde-biasing technique that produces robust de-bias models that maintain\nperformance on downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ranaldi_L/0/1/0/all/0/1\">Leonardo Ranaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruzzetti_E/0/1/0/all/0/1\">Elena Sofia Ruzzetti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venditti_D/0/1/0/all/0/1\">Davide Venditti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onorati_D/0/1/0/all/0/1\">Dario Onorati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanzotto_F/0/1/0/all/0/1\">Fabio Massimo Zanzotto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing Brain Context-Sensitivity with Masked-Attention Generation. (arXiv:2305.13863v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13863","description":"<p>Two fundamental questions in neurolinguistics concerns the brain regions that\nintegrate information beyond the lexical level, and the size of their window of\nintegration. To address these questions we introduce a new approach named\nmasked-attention generation. It uses GPT-2 transformers to generate word\nembeddings that capture a fixed amount of contextual information. We then\ntested whether these embeddings could predict fMRI brain activity in humans\nlistening to naturalistic text. The results showed that most of the cortex\nwithin the language network is sensitive to contextual information, and that\nthe right hemisphere is more sensitive to longer contexts than the left.\nMasked-attention generation supports previous analyses of context-sensitivity\nin the brain, and complements them by quantifying the window size of context\nintegration per voxel.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pasquiou_A/0/1/0/all/0/1\">Alexandre Pasquiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakretz_Y/0/1/0/all/0/1\">Yair Lakretz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thirion_B/0/1/0/all/0/1\">Bertrand Thirion</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pallier_C/0/1/0/all/0/1\">Christophe Pallier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Narrative XL: A Large-scale Dataset For Long-Term Memory Models. (arXiv:2305.13877v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13877","description":"<p>Despite their tremendous successes, most large language models do not have\nany long-term memory mechanisms, which restricts their applications. Overcoming\nthis limitation would not only require changes to the typical transformer\narchitectures or training procedures, but also a dataset on which these new\nmodels could be trained and evaluated. We argue that existing resources lack a\nfew key properties, and that at present, there are no naturalistic datasets of\nsufficient scale to train (and not only evaluate) long-term memory language\nmodels. We then present our solution that capitalizes on the advances in\nshort-term memory language models to create such a dataset. Using GPT 3.5, we\nsummarized each scene in 1500 hand-curated books from Project Gutenberg, which\nresulted in approximately 150 scene-level summaries per book. We then created a\nnumber of reading comprehension questions based on these summaries, including\nthree types of multiple-choice scene recognition questions, as well as\nfree-form narrative reconstruction questions. Each book is thus associated with\nmore than 500 reading comprehension questions. Crucially, most questions have a\nknown ``retention demand'', indicating how long-term of a memory is needed to\nanswer it, which should aid long-term memory performance evaluation. We\nvalidate our data in three small-scale experiments: one with human labelers,\nand two with existing language models. We show that our questions 1) adequately\nrepresent the source material 2) can be used to diagnose the model's memory\ncapacity 3) are not trivial for modern language models even when the memory\ndemand does not exceed those models' context lengths. Lastly, we provide our\ncode which can be used to further expand the dataset in an automated manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moskvichev_A/0/1/0/all/0/1\">Arseny Moskvichev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mai_K/0/1/0/all/0/1\">Ky-Vinh Mai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PaD: Program-aided Distillation Specializes Large Models in Reasoning. (arXiv:2305.13888v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13888","description":"<p>While Large Language Models (LLMs) excel in several natural language\nprocessing tasks, their size and inaccessibility present challenges for\nextensive practical application. Previous studies acquire specialized skills\nthrough distillation on LLMs, which result in trading generic abilities, called\nmodel specialization. As for reasoning ability, chain-of-thought was\nsynthesized to subsequent distillation. However, due to hallucination,\nsynthetic chain-of-thought from LLMs contains faulty reasoning. These incorrect\nreasoning steps damage the reasoning capability. To tackle above issues, we\npropose Program-aided Distillation (PaD), which distills LLMs to obtain\nspecialized small models in reasoning tasks. In PaD, we strengthen specialized\nmodels with program-aided reasoning, and help them overcome faulty reasoning\nsteps with automated error checking. Experimental results demonstrate that, on\nthe GSM8K benchmark, a 0.06B model using PaD can not only outperform certain\nLLMs (e.g., LLaMA), but also achieves a 10% improvement over baselines with a\nsignificantly smaller scale of parameters and data. Data pruning analysis\nreveals that PaD possesses higher training efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xuekai Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_B/0/1/0/all/0/1\">Biqing Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_X/0/1/0/all/0/1\">Xingwei Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Bowen Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sequence-Level Knowledge Distillation for Class-Incremental End-to-End Spoken Language Understanding. (arXiv:2305.13899v1 [eess.AS])","link":"http://arxiv.org/abs/2305.13899","description":"<p>The ability to learn new concepts sequentially is a major weakness for modern\nneural networks, which hinders their use in non-stationary environments. Their\npropensity to fit the current data distribution to the detriment of the past\nacquired knowledge leads to the catastrophic forgetting issue. In this work we\ntackle the problem of Spoken Language Understanding applied to a continual\nlearning setting. We first define a class-incremental scenario for the SLURP\ndataset. Then, we propose three knowledge distillation (KD) approaches to\nmitigate forgetting for a sequence-to-sequence transformer model: the first KD\nmethod is applied to the encoder output (audio-KD), and the other two work on\nthe decoder output, either directly on the token-level (tok-KD) or on the\nsequence-level (seq-KD) distributions. We show that the seq-KD substantially\nimproves all the performance metrics, and its combination with the audio-KD\nfurther decreases the average WER and enhances the entity prediction metric.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Cappellazzo_U/0/1/0/all/0/1\">Umberto Cappellazzo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_M/0/1/0/all/0/1\">Muqiao Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Falavigna_D/0/1/0/all/0/1\">Daniele Falavigna</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Brutti_A/0/1/0/all/0/1\">Alessio Brutti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let's Think Frame by Frame: Evaluating Video Chain of Thought with Video Infilling and Prediction. (arXiv:2305.13903v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13903","description":"<p>Despite constituting 65% of all internet traffic in 2023, video content is\nunderrepresented in generative AI research. Meanwhile, recent large language\nmodels (LLMs) have become increasingly integrated with capabilities in the\nvisual modality. Integrating video with LLMs is a natural next step, so how can\nthis gap be bridged? To advance video reasoning, we propose a new research\ndirection of VideoCOT on video keyframes, which leverages the multimodal\ngenerative abilities of vision-language models to enhance video reasoning while\nreducing the computational complexity of processing hundreds or thousands of\nframes. We introduce VIP, an inference-time dataset that can be used to\nevaluate VideoCOT, containing 1) a variety of real-life videos with keyframes\nand corresponding unstructured and structured scene descriptions, and 2) two\nnew video reasoning tasks: video infilling and scene prediction. We benchmark\nvarious vision-language models on VIP, demonstrating the potential to use\nvision-language models and LLMs to enhance video chain of thought reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Himakunthala_V/0/1/0/all/0/1\">Vaishnavi Himakunthala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_A/0/1/0/all/0/1\">Andy Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rose_D/0/1/0/all/0/1\">Daniel Rose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ryan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_A/0/1/0/all/0/1\">Alex Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sonar_C/0/1/0/all/0/1\">Chinmay Sonar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EfficientSpeech: An On-Device Text to Speech Model. (arXiv:2305.13905v1 [eess.AS])","link":"http://arxiv.org/abs/2305.13905","description":"<p>State of the art (SOTA) neural text to speech (TTS) models can generate\nnatural-sounding synthetic voices. These models are characterized by large\nmemory footprints and substantial number of operations due to the long-standing\nfocus on speech quality with cloud inference in mind. Neural TTS models are\ngenerally not designed to perform standalone speech syntheses on\nresource-constrained and no Internet access edge devices. In this work, an\nefficient neural TTS called EfficientSpeech that synthesizes speech on an ARM\nCPU in real-time is proposed. EfficientSpeech uses a shallow non-autoregressive\npyramid-structure transformer forming a U-Network. EfficientSpeech has 266k\nparameters and consumes 90 MFLOPS only or about 1% of the size and amount of\ncomputation in modern compact models such as Mixer-TTS. EfficientSpeech\nachieves an average mel generation real-time factor of 104.3 on an RPi4. Human\nevaluation shows only a slight degradation in audio quality as compared to\nFastSpeech2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Atienza_R/0/1/0/all/0/1\">Rowel Atienza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DAPR: A Benchmark on Document-Aware Passage Retrieval. (arXiv:2305.13915v1 [cs.IR])","link":"http://arxiv.org/abs/2305.13915","description":"<p>Recent neural retrieval mainly focuses on ranking short texts and is\nchallenged with long documents. Existing work mainly evaluates either ranking\npassages or whole documents. However, there are many cases where the users want\nto find a relevant passage within a long document from a huge corpus, e.g.\nlegal cases, research papers, etc. In this scenario, the passage often provides\nlittle document context and thus challenges the current approaches to finding\nthe correct document and returning accurate results. To fill this gap, we\npropose and name this task Document-Aware Passage Retrieval (DAPR) and build a\nbenchmark including multiple datasets from various domains, covering both DAPR\nand whole-document retrieval. In experiments, we extend the state-of-the-art\nneural passage retrievers with document-level context via different approaches\nincluding prepending document summary, pooling over passage representations,\nand hybrid retrieval with BM25. The hybrid-retrieval systems, the overall best,\ncan only improve on the DAPR tasks marginally while significantly improving on\nthe document-retrieval tasks. This motivates further research in developing\nbetter retrieval systems for the new task. The code and the data are available\nat https://github.com/kwang2049/dapr\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kexin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reimers_N/0/1/0/all/0/1\">Nils Reimers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Data for Symbolic Language with Large Language Models. (arXiv:2305.13917v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13917","description":"<p>While large language models (LLMs) bring not only performance but also\ncomplexity, recent work has started to turn LLMs into data generators rather\nthan task inferencers, where another affordable task model is trained for\nefficient deployment and inference. However, such an approach has primarily\nbeen applied to natural language tasks and has not yet been explored for\nsymbolic language tasks with complex structured outputs (e.g., semantic parsing\nand code generation). In this paper, we propose SymGen which utilizes LLMs for\ngenerating various annotation-expensive symbolic language data. SymGen consists\nof an informative prompt to steer generation and an agreement-based verifier to\nimprove data correctness. We conduct extensive experiments on six symbolic\nlanguage tasks across various settings. Compared with the LLMs, we demonstrate\nthe 1\\%-sized task model can achieve comparable or better performance, largely\ncutting inference and deployment costs. We also show that generated data with\nonly a few human demonstrations can be as effective as over 10 times the amount\nof human-annotated data when training the task model, saving a considerable\namount of annotation effort. SymGen sheds new light on data generation for\ncomplex tasks, and we release the code at\n\\href{https://github.com/HKUNLP/SymGen}{https://github.com/HKUNLP/SymGen}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiacheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengzu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Acquiring Frame Element Knowledge with Deep Metric Learning for Semantic Frame Induction. (arXiv:2305.13944v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13944","description":"<p>The semantic frame induction tasks are defined as a clustering of words into\nthe frames that they evoke, and a clustering of their arguments according to\nthe frame element roles that they should fill. In this paper, we address the\nlatter task of argument clustering, which aims to acquire frame element\nknowledge, and propose a method that applies deep metric learning. In this\nmethod, a pre-trained language model is fine-tuned to be suitable for\ndistinguishing frame element roles through the use of frame-annotated data, and\nargument clustering is performed with embeddings obtained from the fine-tuned\nmodel. Experimental results on FrameNet demonstrate that our method achieves\nsubstantially better performance than existing methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamada_K/0/1/0/all/0/1\">Kosuke Yamada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sasano_R/0/1/0/all/0/1\">Ryohei Sasano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takeda_K/0/1/0/all/0/1\">Koichi Takeda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Instruction Optimization for Large Language Models with Distribution Shifts. (arXiv:2305.13954v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13954","description":"<p>Large Language Models have demonstrated significant ability in accomplishing\na wide range of Natural Language Processing (NLP) tasks. However, their\nperformance is highly sensitive to the even minor changes in the phrasing of\nthe task instructions, leading to a line of research in automatic instruction\noptimization towards better performance for NLP tasks. Unfortunately, existing\nmethods for instruction optimization fail to consider the distribution shift\nbetween the seen training data and the unseen test data, where testing on\nunseen group of data with a different distribution could potentially lead to\nperformance drop. In this paper, we take an initial step of investigating the\nproblem of LLM instruction optimization across data groups with distribution\nshifts. We find that the optimal instructions do encounter performance drops on\nLLM under certain distribution shifts. To this end, we propose a framework to\nderive more robust optimal instructions that improve the performance on the\nunseen data group without large sacrifice on the seen data group. Experimental\nresults demonstrate the effectiveness of our proposed framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Moxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jizhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Flexible Grammar-Based Constrained Decoding for Language Models. (arXiv:2305.13971v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13971","description":"<p>LLMs have shown impressive few-shot performance across many tasks. However,\nthey still struggle when it comes to generating complex output structures, such\nas those required for Information Extraction. This limitation stems from the\nfact that LLMs, without finetuning, tend to generate free text rather than\nprecise structures that follow a specific grammar. In this work, we propose to\nenrich the decoding step with formal grammar constraints. During beam search,\nonly valid token continuations compliant with the grammar production rules are\nconsidered. This enforces the generation of valid sequences exclusively. Our\nframework is highly general and flexible, allowing any Context-Free Grammar\n(CFG) to be integrated into our custom constrained beam search implementation.\nWe demonstrate that the outputs of many NLP tasks can be represented as formal\nlanguages, making them suitable for direct use in our framework. For task where\nthe output space is dependent on the input, we propose input-dependent grammars\nto constrain the generation. We conducted experiments with two challenging\ntasks involving large alphabets in their grammar (Wikidata entities and\nrelations): information extraction and entity disambiguation. Our results with\nLLaMA models clearly indicate that grammar-constrained decoding outperforms\nfew-shot prompting without constraints, and even competes with task-specific\nfinetuned models. These findings suggest that integrating grammar-based\nconstraints during decoding holds great promise in making LLMs reliably produce\nstructured outputs, especially in setting where training data is scarce and\nfinetuning is expensive.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Saibo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josifosky_M/0/1/0/all/0/1\">Martin Josifosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Make a Choice! Knowledge Base Question Answering with In-Context Learning. (arXiv:2305.13972v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13972","description":"<p>Question answering over knowledge bases (KBQA) aims to answer factoid\nquestions with a given knowledge base (KB). Due to the large scale of KB,\nannotated data is impossible to cover all fact schemas in KB, which poses a\nchallenge to the generalization ability of methods that require a sufficient\namount of annotated data. Recently, LLMs have shown strong few-shot performance\nin many NLP tasks. We expect LLM can help existing methods improve their\ngeneralization ability, especially in low-resource situations. In this paper,\nwe present McL-KBQA, a framework that incorporates the few-shot ability of LLM\ninto the KBQA method via ICL-based multiple choice and then improves the\neffectiveness of the QA tasks. Experimental results on two KBQA datasets\ndemonstrate the competitive performance of McL-KBQA with strong improvements in\ngeneralization. We expect to explore a new way to QA tasks from KBQA in\nconjunction with LLM, how to generate answers normatively and correctly with\nstrong generalization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanyuan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuehe Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wenbiao Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenliang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effortless Integration of Memory Management into Open-Domain Conversation Systems. (arXiv:2305.13973v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13973","description":"<p>Open-domain conversation systems integrate multiple conversation skills into\na single system through a modular approach. One of the limitations of the\nsystem, however, is the absence of management capability for external memory.\nIn this paper, we propose a simple method to improve BlenderBot3 by integrating\nmemory management ability into it. Since no training data exists for this\npurpose, we propose an automating dataset creation for memory management. Our\nmethod 1) requires little cost for data construction, 2) does not affect\nperformance in other tasks, and 3) reduces external memory. We show that our\nproposed model BlenderBot3-M^3, which is multi-task trained with memory\nmanagement, outperforms BlenderBot3 with a relative 4% performance gain in\nterms of F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunbi Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+On_K/0/1/0/all/0/1\">Kyoung-Woon On</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1\">Gunsoo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungwoong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nam_D/0/1/0/all/0/1\">Daniel Wontae Nam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jo_D/0/1/0/all/0/1\">Daejin Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rho_S/0/1/0/all/0/1\">Seung Eun Rho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taehwan Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction. (arXiv:2305.13981v1 [cs.CL])","link":"http://arxiv.org/abs/2305.13981","description":"<p>The robustness to distribution changes ensures that NLP models can be\nsuccessfully applied in the realistic world, especially for information\nextraction tasks. However, most prior evaluation benchmarks have been devoted\nto validating pairwise matching correctness, ignoring the crucial measurement\nof robustness. In this paper, we present the first benchmark that simulates the\nevaluation of open information extraction models in the real world, where the\nsyntactic and expressive distributions under the same knowledge meaning may\ndrift variously. We design and annotate a large-scale testbed in which each\nexample is a knowledge-invariant clique that consists of sentences with\nstructured knowledge of the same meaning but with different syntactic and\nexpressive forms. By further elaborating the robustness metric, a model is\njudged to be robust if its performance is consistently accurate on the overall\ncliques. We perform experiments on typical models published in the last decade\nas well as a popular large language model, the results show that the existing\nsuccessful models exhibit a frustrating degradation, with a maximum drop of\n23.43 F1 score. Our resources and code will be publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Ji Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chuchun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaozhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_K/0/1/0/all/0/1\">Kaisheng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiuding Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuxiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+How_L/0/1/0/all/0/1\">Lei How</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextualized Semantic Distance between Highly Overlapped Texts. (arXiv:2110.01176v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.01176","description":"<p>Overlapping frequently occurs in paired texts in natural language processing\ntasks like text editing and semantic similarity evaluation. Better evaluation\nof the semantic distance between the overlapped sentences benefits the language\nsystem's understanding and guides the generation. Since conventional semantic\nmetrics are based on word representations, they are vulnerable to the\ndisturbance of overlapped components with similar representations. This paper\naims to address the issue with a mask-and-predict strategy. We take the words\nin the longest common sequence (LCS) as neighboring words and use masked\nlanguage modeling (MLM) from pre-trained language models (PLMs) to predict the\ndistributions on their positions. Our metric, Neighboring Distribution\nDivergence (NDD), represent the semantic distance by calculating the divergence\nbetween distributions in the overlapped parts. Experiments on Semantic Textual\nSimilarity show NDD to be more sensitive to various semantic differences,\nespecially on highly overlapped paired texts. Based on the discovery, we\nfurther implement an unsupervised and training-free method for text\ncompression, leading to a significant improvement on the previous\nperplexity-based method. The high scalability of our method even enables NDD to\noutperform the supervised state-of-the-art in domain adaption by a huge margin.\nFurther experiments on syntax and semantics analyses verify the awareness of\ninternal sentence structures, indicating the high potential of NDD for further\nstudies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Letian Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zuchao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Principled Paraphrase Generation with Parallel Corpora. (arXiv:2205.12213v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12213","description":"<p>Round-trip Machine Translation (MT) is a popular choice for paraphrase\ngeneration, which leverages readily available parallel corpora for supervision.\nIn this paper, we formalize the implicit similarity function induced by this\napproach, and show that it is susceptible to non-paraphrase pairs sharing a\nsingle ambiguous translation. Based on these insights, we design an alternative\nsimilarity metric that mitigates this issue by requiring the entire translation\ndistribution to match, and implement a relaxation of it through the Information\nBottleneck method. Our approach incorporates an adversarial term into MT\ntraining in order to learn representations that encode as much information\nabout the reference translation as possible, while keeping as little\ninformation about the input as possible. Paraphrases can be generated by\ndecoding back to the source from this representation, without having to\ngenerate pivot translations. In addition to being more principled and efficient\nthan round-trip MT, our approach offers an adjustable parameter to control the\nfidelity-diversity trade-off, and obtains better results in our experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ormazabal_A/0/1/0/all/0/1\">Aitor Ormazabal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soroa_A/0/1/0/all/0/1\">Aitor Soroa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labaka_G/0/1/0/all/0/1\">Gorka Labaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling. (arXiv:2209.07634v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.07634","description":"<p>Transformer encoder-decoder models have achieved great performance in\ndialogue generation tasks, however, their inability to process long dialogue\nhistory often leads to truncation of the context To address this problem, we\npropose a novel memory-augmented transformer that is compatible with existing\npre-trained encoder-decoder models and enables efficient preservation of the\ndialogue history information. By incorporating a separate memory module\nalongside the pre-trained transformer, the model can effectively interchange\ninformation between the memory states and the current input context. We\nevaluate our model on three dialogue datasets and two language modeling\ndatasets. Experimental results show that our method has achieved superior\nefficiency and performance compared to other pre-trained Transformer baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zemi: Learning Zero-Shot Semi-Parametric Language Models from Multiple Tasks. (arXiv:2210.00185v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.00185","description":"<p>Although large language models have achieved impressive zero-shot ability,\nthe huge model size generally incurs high cost. Recently, semi-parametric\nlanguage models, which augment a smaller language model with an external\nretriever, have demonstrated promising language modeling capabilities. However,\nit remains unclear whether such semi-parametric language models can perform\ncompetitively well as their fully-parametric counterparts on zero-shot\ngeneralization to downstream tasks. In this work, we introduce $\\text{Zemi}$, a\nzero-shot semi-parametric language model. To our best knowledge, this is the\nfirst semi-parametric language model that can demonstrate strong zero-shot\nperformance on a wide range of held-out unseen tasks. We train $\\text{Zemi}$\nwith a novel semi-parametric multitask prompted training paradigm, which shows\nsignificant improvement compared with the parametric multitask training as\nproposed by T0. Specifically, we augment the multitask training and zero-shot\nevaluation with retrieval from a large-scale task-agnostic unlabeled corpus. In\norder to incorporate multiple potentially noisy retrieved augmentations, we\nfurther propose a novel $\\text{augmentation fusion}$ module leveraging\nperceiver resampler and gated cross-attention. Notably, our proposed\n$\\text{Zemi}_\\text{LARGE}$ outperforms T0-3B by 16% on all seven evaluation\ntasks while being 3.9x smaller in model size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenhailong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiaoman Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dian Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jianshu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on the Efficiency and Generalization of Light Hybrid Retrievers. (arXiv:2210.01371v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2210.01371","description":"<p>Hybrid retrievers can take advantage of both sparse and dense retrievers.\nPrevious hybrid retrievers leverage indexing-heavy dense retrievers. In this\nwork, we study \"Is it possible to reduce the indexing memory of hybrid\nretrievers without sacrificing performance\"? Driven by this question, we\nleverage an indexing-efficient dense retriever (i.e. DrBoost) and introduce a\nLITE retriever that further reduces the memory of DrBoost. LITE is jointly\ntrained on contrastive learning and knowledge distillation from DrBoost. Then,\nwe integrate BM25, a sparse retriever, with either LITE or DrBoost to form\nlight hybrid retrievers. Our Hybrid-LITE retriever saves 13X memory while\nmaintaining 98.0% performance of the hybrid retriever of BM25 and DPR. In\naddition, we study the generalization capacity of our light hybrid retrievers\non out-of-domain dataset and a set of adversarial attacks datasets. Experiments\nshowcase that light hybrid retrievers achieve better generalization performance\nthan individual sparse and dense retrievers. Nevertheless, our analysis shows\nthat there is a large room to improve the robustness of retrievers, suggesting\na new research direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Man Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shashank Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Anchit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Einolghozati_A/0/1/0/all/0/1\">Arash Einolghozati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_D/0/1/0/all/0/1\">Debojeet Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_P/0/1/0/all/0/1\">Peyman Heidari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WavSpA: Wavelet Space Attention for Boosting Transformers' Long Sequence Learning Ability. (arXiv:2210.01989v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.01989","description":"<p>Transformer and its variants are fundamental neural architectures in deep\nlearning. Recent works show that learning attention in the Fourier space can\nimprove the long sequence learning capability of Transformers. We argue that\nwavelet transform shall be a better choice because it captures both position\nand frequency information with linear time complexity. Therefore, in this\npaper, we systematically study the synergy between wavelet transform and\nTransformers. We propose Wavelet Space Attention (WavSpA) that facilitates\nattention learning in a learnable wavelet coefficient space which replaces the\nattention in Transformers by (1) applying forward wavelet transform to project\nthe input sequences to multi-resolution bases, (2) conducting attention\nlearning in the wavelet coefficient space, and (3) reconstructing the\nrepresentation in input space via backward wavelet transform. Extensive\nexperiments on the Long Range Arena demonstrate that learning attention in the\nwavelet space using either fixed or adaptive wavelets can consistently improve\nTransformer's performance and also significantly outperform learning in Fourier\nspace. We further show our method can enhance Transformer's reasoning\nextrapolation capability over distance on the LEGO chain-of-reasoning task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yufan Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_F/0/1/0/all/0/1\">Fangbo Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring and Narrowing the Compositionality Gap in Language Models. (arXiv:2210.03350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03350","description":"<p>We investigate the ability of language models to perform compositional\nreasoning tasks where the overall solution depends on correctly composing the\nanswers to sub-problems. We measure how often models can correctly answer all\nsub-problems but not generate the overall solution, a ratio we call the\ncompositionality gap. We evaluate this ratio by asking multi-hop questions with\nanswers that require composing multiple facts unlikely to have been observed\ntogether during pretraining. In the GPT-3 family of models, as model size\nincreases we show that the single-hop question answering performance improves\nfaster than the multi-hop performance does, therefore the compositionality gap\ndoes not decrease. This surprising result suggests that while more powerful\nmodels memorize and recall more factual knowledge, they show no corresponding\nimprovement in their ability to perform this kind of compositional reasoning.\n</p>\n<p>We then demonstrate how elicitive prompting (such as chain of thought)\nnarrows the compositionality gap by reasoning explicitly instead of implicitly.\nWe present a new method, self-ask, that further improves on chain of thought.\nIn our method, the model explicitly asks itself (and then answers) follow-up\nquestions before answering the initial question. We finally show that\nself-ask's structured prompting lets us easily plug in a search engine to\nanswer the follow-up questions, which additionally improves accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1\">Ofir Press</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Muru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-Aware Specialization for Efficient and Robust Dense Retrieval for Open-Domain Question Answering. (arXiv:2210.05156v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.05156","description":"<p>Given its effectiveness on knowledge-intensive natural language processing\ntasks, dense retrieval models have become increasingly popular. Specifically,\nthe de-facto architecture for open-domain question answering uses two\nisomorphic encoders that are initialized from the same pretrained model but\nseparately parameterized for questions and passages. This bi-encoder\narchitecture is parameter-inefficient in that there is no parameter sharing\nbetween encoders. Further, recent studies show that such dense retrievers\nunderperform BM25 in various settings. We thus propose a new architecture,\nTask-aware Specialization for dense Retrieval (TASER), which enables parameter\nsharing by interleaving shared and specialized blocks in a single encoder. Our\nexperiments on five question answering datasets show that TASER can achieve\nsuperior accuracy, surpassing BM25, while using about 60% of the parameters as\nbi-encoder dense retrievers. In out-of-domain evaluations, TASER is also\nempirically more robust than bi-encoder dense retrievers. Our code is available\nat https://github.com/microsoft/taser.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Train and Test-Time Augmentations for Audio-Language Learning. (arXiv:2210.17143v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2210.17143","description":"<p>In this paper, we aim to unveil the impact of data augmentation in\naudio-language multi-modal learning, which has not been explored despite its\nimportance. We explore various augmentation methods at not only train-time but\nalso test-time and find out that proper data augmentation can lead to\nsubstantial improvements. Specifically, applying our proposed audio-language\npaired augmentation PairMix, which is the first multi-modal audio-language\naugmentation method, outperforms the baselines for both automated audio\ncaptioning and audio-text retrieval tasks. To fully take advantage of data\naugmentation, we also present multi-level test-time augmentation (Multi-TTA)\nfor the test-time. We successfully incorporate the two proposed methods and\nuni-modal augmentations and achieve 47.5 SPIDEr on audio captioning, which is\nan 18.2% relative increase over the baseline. In audio-text retrieval, the\nproposed methods also show an improvement in performance as well.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1\">Eungbeom Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jinhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yoori Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kyungsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1\">Minju Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_J/0/1/0/all/0/1\">Jaeheon Sim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinwoo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kyogu Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chinese CLIP: Contrastive Vision-Language Pretraining in Chinese. (arXiv:2211.01335v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.01335","description":"<p>The tremendous success of CLIP (Radford et al., 2021) has promoted the\nresearch and application of contrastive learning for vision-language\npretraining. In this work, we construct a large-scale dataset of image-text\npairs in Chinese, where most data are retrieved from publicly available\ndatasets, and we pretrain Chinese CLIP models on the new dataset. We develop 5\nChinese CLIP models of multiple sizes, spanning from 77 to 958 million\nparameters. Furthermore, we propose a two-stage pretraining method, where the\nmodel is first trained with the image encoder frozen and then trained with all\nparameters being optimized, to achieve enhanced model performance. Our\ncomprehensive experiments demonstrate that Chinese CLIP can achieve the\nstate-of-the-art performance on MUGE, Flickr30K-CN, and COCO-CN in the setups\nof zero-shot learning and finetuning, and it is able to achieve competitive\nperformance in zero-shot image classification based on the evaluation on the\nELEVATER benchmark (Li et al., 2022). We have released our codes, models, and\ndemos in https://github.com/OFA-Sys/Chinese-CLIP\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junshu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"miCSE: Mutual Information Contrastive Learning for Low-shot Sentence Embeddings. (arXiv:2211.04928v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.04928","description":"<p>This paper presents miCSE, a mutual information-based contrastive learning\nframework that significantly advances the state-of-the-art in few-shot sentence\nembedding. The proposed approach imposes alignment between the attention\npattern of different views during contrastive learning. Learning sentence\nembeddings with miCSE entails enforcing the structural consistency across\naugmented views for every sentence, making contrastive self-supervised learning\nmore sample efficient. As a result, the proposed approach shows strong\nperformance in the few-shot learning domain. While it achieves superior results\ncompared to state-of-the-art methods on multiple benchmarks in few-shot\nlearning, it is comparable in the full-shot scenario. This study opens up\navenues for efficient self-supervised learning methods that are more robust\nthan current contrastive methods for sentence embedding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klein_T/0/1/0/all/0/1\">Tassilo Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nabi_M/0/1/0/all/0/1\">Moin Nabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UGIF: UI Grounded Instruction Following. (arXiv:2211.07615v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.07615","description":"<p>Smartphone users often find it difficult to navigate myriad menus to perform\ncommon tasks such as \"How to block calls from unknown numbers?\". Currently,\nhelp documents with step-by-step instructions are manually written to aid the\nuser. The user experience can be further enhanced by grounding the instructions\nin the help document to the UI and overlaying a tutorial on the phone UI. To\nbuild such tutorials, several natural language processing components including\nretrieval, parsing, and grounding are necessary, but there isn't any relevant\ndataset for such a task. Thus, we introduce UGIF-DataSet, a multi-lingual,\nmulti-modal UI grounded dataset for step-by-step task completion on the\nsmartphone containing 4,184 tasks across 8 languages. As an initial approach to\nthis problem, we propose retrieving the relevant instruction steps based on the\nuser's query and parsing the steps using Large Language Models (LLMs) to\ngenerate macros that can be executed on-device. The instruction steps are often\navailable only in English, so the challenge includes cross-modal, cross-lingual\nretrieval of English how-to pages from user queries in many languages and\nmapping English instruction steps to UI in a potentially different language. We\ncompare the performance of different LLMs including PaLM and GPT-3 and find\nthat the end-to-end task completion rate is 48% for English UI but the\nperformance drops to 32% for other languages. We analyze the common failure\nmodes of existing models on this task and point out areas for improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1\">Sagar Gubbi Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1\">Srini Narayanan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-sample Curriculum Learning by Sequence Completion for Natural Language Generation. (arXiv:2211.11297v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11297","description":"<p>Curriculum learning has shown promising improvements in multiple domains by\ntraining machine learning models from easy samples to hard ones. Previous works\nwhich either design rules or train models for scoring the difficulty highly\nrely on task-specific expertise, and cannot generalize. Inspired by the\n\"easy-to-hard\" intuition, we propose to do in-sample curriculum learning for\nnatural language generation tasks. Our learning strategy starts training the\nmodel to generate the last few words, i.e., do sequence completion, and\ngradually extends to generate the whole output sequence. Comprehensive\nexperiments show that it generalizes well to different tasks and achieves\nsignificant improvements over strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Q/0/1/0/all/0/1\">Qi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yizhu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haifeng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompted Opinion Summarization with GPT-3.5. (arXiv:2211.15914v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.15914","description":"<p>Large language models have shown impressive performance across a wide variety\nof tasks, including text summarization. In this paper, we show that this strong\nperformance extends to opinion summarization. We explore several pipeline\nmethods for applying GPT-3.5 to summarize a large collection of user reviews in\na prompted fashion. To handle arbitrarily large numbers of user reviews, we\nexplore recursive summarization as well as methods for selecting salient\ncontent to summarize through supervised clustering or extraction. On two\ndatasets, an aspect-oriented summarization dataset of hotel reviews (SPACE) and\na generic summarization dataset of Amazon and Yelp reviews (FewSum), we show\nthat GPT-3.5 models achieve very strong performance in human evaluation. We\nargue that standard evaluation metrics do not reflect this, and introduce three\nnew metrics targeting faithfulness, factuality, and genericity to contrast\nthese different methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhaskar_A/0/1/0/all/0/1\">Adithya Bhaskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander R. Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning. (arXiv:2211.16773v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.16773","description":"<p>In task-oriented dialogs, an informative and successful system response needs\nto include key information such as the phone number of a hotel. Therefore, we\nhypothesize that a model can achieve better overall performance by focusing on\ncorrectly generating key quantities. In this paper, we propose a new training\nalgorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), that\nutilizes Reinforcement Learning but avoids the time-consuming auto-regressive\ngeneration, and a fine-grained per-token reward function to help the model\nlearn keywords generation more robustly. Empirical results show that the KRLS\nalgorithm can achieve state-of-the-art performance on the inform, success, and\ncombined score on the MultiWoZ benchmark dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robustness of Learning from Task Instructions. (arXiv:2212.03813v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.03813","description":"<p>Traditional supervised learning mostly works on individual tasks and requires\ntraining on a large set of task-specific examples. This paradigm seriously\nhinders the development of task generalization since preparing a task-specific\nexample set is costly. To build a system that can quickly and easily generalize\nto new tasks, task instructions have been adopted as an emerging trend of\nsupervision recently. These instructions give the model the definition of the\ntask and allow the model to output the appropriate answer based on the\ninstructions and inputs. However, task instructions are often expressed in\ndifferent forms, which can be interpreted from two threads: first, some\ninstructions are short sentences and are pretrained language model (PLM)\noriented, such as prompts, while other instructions are paragraphs and are\nhuman-oriented, such as those in Amazon MTurk; second, different end-users very\nlikely explain the same task with instructions of different textual\nexpressions. A robust system for task generalization should be able to handle\nany new tasks regardless of the variability of instructions.\n</p>\n<p>However, the system robustness in dealing with instruction-driven task\ngeneralization is still unexplored. This work investigates the system\nrobustness when the instructions of new tasks are (i) manipulated, (ii)\nparaphrased, or (iii) from different levels of conciseness. To our knowledge,\nthis is the first work that systematically studies how robust a PLM is when it\nis supervised by instructions with different factors of variability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiasheng Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hanzi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Liangyu Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1\">Hongyuan Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal Contributions in Vision and Language Models & Tasks. (arXiv:2212.08158v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2212.08158","description":"<p>Vision and language models (VL) are known to exploit unrobust indicators in\nindividual modalities (e.g., introduced by distributional biases) instead of\nfocusing on relevant information in each modality. That a unimodal model\nachieves similar accuracy on a VL task to a multimodal one, indicates that\nso-called unimodal collapse occurred. However, accuracy-based tests fail to\ndetect e.g., when the model prediction is wrong, while the model used relevant\ninformation from a modality. Instead, we propose MM-SHAP, a\nperformance-agnostic multimodality score based on Shapley values that reliably\nquantifies in which proportions a multimodal model uses individual modalities.\nWe apply MM-SHAP in two ways: (1) to compare models for their average degree of\nmultimodality, and (2) to measure for individual models the contribution of\nindividual modalities for different tasks and datasets. Experiments with six VL\nmodels -- LXMERT, CLIP and four ALBEF variants -- on four VL tasks highlight\nthat unimodal collapse can occur to different degrees and in different\ndirections, contradicting the wide-spread assumption that unimodal collapse is\none-sided. Based on our results, we recommend MM-SHAP for analysing multimodal\ntasks, to diagnose and guide progress towards multimodal integration. Code\navailable at \\url{https://github.com/Heidelberg-NLP/MM-SHAP}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parcalabescu_L/0/1/0/all/0/1\">Letitia Parcalabescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The KITMUS Test: Evaluating Knowledge Integration from Multiple Sources in Natural Language Understanding Systems. (arXiv:2212.08192v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08192","description":"<p>Many state-of-the-art natural language understanding (NLU) models are based\non pretrained neural language models. These models often make inferences using\ninformation from multiple sources. An important class of such inferences are\nthose that require both background knowledge, presumably contained in a model's\npretrained parameters, and instance-specific information that is supplied at\ninference time. However, the integration and reasoning abilities of NLU models\nin the presence of multiple knowledge sources have been largely understudied.\nIn this work, we propose a test suite of coreference resolution subtasks that\nrequire reasoning over multiple facts. These subtasks differ in terms of which\nknowledge sources contain the relevant facts. We also introduce subtasks where\nknowledge is present only at inference time using fictional knowledge. We\nevaluate state-of-the-art coreference resolution models on our dataset. Our\nresults indicate that several models struggle to reason on-the-fly over\nknowledge observed both at pretrain time and at inference time. However, with\ntask-specific training, a subset of models demonstrates the ability to\nintegrate certain knowledge types from multiple sources. Still, even the best\nperforming models seem to have difficulties with reliably integrating knowledge\npresented only at inference time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arodi_A/0/1/0/all/0/1\">Akshatha Arodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pomsl_M/0/1/0/all/0/1\">Martin P&#xf6;msl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suleman_K/0/1/0/all/0/1\">Kaheer Suleman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trischler_A/0/1/0/all/0/1\">Adam Trischler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olteanu_A/0/1/0/all/0/1\">Alexandra Olteanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_J/0/1/0/all/0/1\">Jackie Chi Kit Cheung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-View Knowledge Distillation from Crowd Annotations for Out-of-Domain Generalization. (arXiv:2212.09409v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09409","description":"<p>Selecting an effective training signal for tasks in natural language\nprocessing is difficult: expert annotations are expensive, and crowd-sourced\nannotations may not be reliable. At the same time, recent work in NLP has\ndemonstrated that learning from a distribution over labels acquired from crowd\nannotations can be effective. However, there are many ways to acquire such a\ndistribution, and the performance allotted by any one method can fluctuate\nbased on the task and the amount of available crowd annotations, making it\ndifficult to know a priori which distribution is best. This paper\nsystematically analyzes this in the out-of-domain setting, adding to the NLP\nliterature which has focused on in-domain evaluation, and proposes new methods\nfor acquiring soft-labels from crowd-annotations by aggregating the\ndistributions produced by existing methods. In particular, we propose to\naggregate multiple-views of crowd annotations via temperature scaling and\nfinding their Jensen-Shannon centroid. We demonstrate that these aggregation\nmethods lead to the most consistent performance across four NLP tasks on\nout-of-domain test sets, mitigating fluctuations in performance from the\nindividual distributions. Additionally, aggregation results in the most\nconsistently well-calibrated uncertainty estimation. We argue that aggregating\ndifferent views of crowd-annotations is an effective and minimal intervention\nto acquire soft-labels which induce robust classifiers despite the\ninconsistency of the individual soft-labeling methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wright_D/0/1/0/all/0/1\">Dustin Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Better Reasoners with Self-Verification. (arXiv:2212.09561v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2212.09561","description":"<p>Recently, with the chain of thought (CoT) prompting, large language models\n(LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural\nlanguage processing tasks such as arithmetic, commonsense, and logical\nreasoning. However, LLMs with CoT require multi-step prompting and multi-token\nprediction, which is highly sensitive to individual mistakes and vulnerable to\nerror accumulation. The above issues make the LLMs need the ability to verify\nthe answers. In fact, after inferring conclusions in some thinking decision\ntasks, people often check them by re-verifying steps to avoid some mistakes. In\nthis paper, we propose and prove that LLMs also have similar self-verification\nabilities. We take the conclusion obtained by CoT as one of the conditions for\nsolving the original problem. By taking turns masking the original conditions\nand predicting their results, we calculate an explainable answer verification\nscore based on whether the re-predicted conditions are correct. Experimental\nresults demonstrate that the proposed method can improve the reasoning\nperformance on various arithmetic, commonsense, and logical reasoning datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1\">Yixuan Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minjun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shizhu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Words as Gatekeepers: Measuring Discipline-specific Terms and Meanings in Scholarly Publications. (arXiv:2212.09676v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09676","description":"<p>Scholarly text is often laden with jargon, or specialized language that can\nfacilitate efficient in-group communication within fields but hinder\nunderstanding for out-groups. In this work, we develop and validate an\ninterpretable approach for measuring scholarly jargon from text. Expanding the\nscope of prior work which focuses on word types, we use word sense induction to\nalso identify words that are widespread but overloaded with different meanings\nacross fields. We then estimate the prevalence of these discipline-specific\nwords and senses across hundreds of subfields, and show that word senses\nprovide a complementary, yet unique view of jargon alongside word types. We\ndemonstrate the utility of our metrics for science of science and computational\nsociolinguistics by highlighting two key social implications. First, though\nmost fields reduce their use of jargon when writing for general-purpose venues,\nand some fields (e.g., biological sciences) do so less than others. Second, the\ndirection of correlation between jargon and citation rates varies among fields,\nbut jargon is nearly always negatively correlated with interdisciplinary\nimpact. Broadly, our findings suggest that though multidisciplinary venues\nintend to cater to more general audiences, some fields' writing norms may act\nas barriers rather than bridges, and thus impede the dispersion of scholarly\nideas.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lucy_L/0/1/0/all/0/1\">Li Lucy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodge_J/0/1/0/all/0/1\">Jesse Dodge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamman_D/0/1/0/all/0/1\">David Bamman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keith_K/0/1/0/all/0/1\">Katherine A. Keith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models. (arXiv:2212.10474v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10474","description":"<p>State-of-the-art poetry generation systems are often complex. They either\nconsist of task-specific model pipelines, incorporate prior knowledge in the\nform of manually created constraints, or both. In contrast, end-to-end models\nwould not suffer from the overhead of having to model prior knowledge and could\nlearn the nuances of poetry from data alone, reducing the degree of human\nsupervision required. In this work, we investigate end-to-end poetry generation\nconditioned on styles such as rhyme, meter, and alliteration. We identify and\naddress lack of training data and mismatching tokenization algorithms as\npossible limitations of past attempts. In particular, we successfully pre-train\nByGPT5, a new token-free decoder-only language model, and fine-tune it on a\nlarge custom corpus of English and German quatrains annotated with our styles.\nWe show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2 and\nChatGPT, while also being more parameter efficient and performing favorably\ncompared to humans. In addition, we analyze its runtime performance and\ndemonstrate that it is not prone to memorization. We make our code, models, and\ndatasets publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belouadi_J/0/1/0/all/0/1\">Jonas Belouadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?. (arXiv:2212.10784v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10784","description":"<p>Two key obstacles in biomedical relation extraction (RE) are the scarcity of\nannotations and the prevalence of instances without explicitly pre-defined\nlabels due to low annotation coverage. Existing approaches, which treat\nbiomedical RE as a multi-class classification task, often result in poor\ngeneralization in low-resource settings and do not have the ability to make\nselective prediction on unknown cases but give a guess from seen relations,\nhindering the applicability of those approaches. We present NBR, which converts\nbiomedical RE as natural language inference formulation through indirect\nsupervision. By converting relations to natural language hypotheses, NBR is\ncapable of exploiting semantic cues to alleviate annotation scarcity. By\nincorporating a ranking-based loss that implicitly calibrates abstinent\ninstances, NBR learns a clearer decision boundary and is instructed to abstain\non uncertain instances. Extensive experiments on three widely-used biomedical\nRE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in\nboth full-set and low-resource regimes. Our analysis demonstrates that indirect\nsupervision benefits biomedical RE even when a domain gap exists, and combining\nNLI knowledge with biomedical knowledge leads to the best performance gains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiashu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyu Derek Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semi-Structured Object Sequence Encoders. (arXiv:2301.01015v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2301.01015","description":"<p>In this paper we explore the task of modeling semi-structured object\nsequences; in particular, we focus our attention on the problem of developing a\nstructure-aware input representation for such sequences. Examples of such data\ninclude user activity on websites, machine logs, and many others. This type of\ndata is often represented as a sequence of sets of key-value pairs over time\nand can present modeling challenges due to an ever-increasing sequence length.\nWe propose a two-part approach, which first considers each key independently\nand encodes a representation of its values over time; we then self-attend over\nthese value-aware key representations to accomplish a downstream task. This\nallows us to operate on longer object sequences than existing methods. We\nintroduce a novel shared-attention-head architecture between the two modules\nand present an innovative training schedule that interleaves the training of\nboth modules with shared weights for some attention heads. Our experiments on\nmultiple prediction tasks using real-world data demonstrate that our approach\noutperforms a unified network with hierarchical encoding, as well as other\nmethods including a record-centric representation and a flattened\nrepresentation of the sequence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1\">Riyaz Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gunasekara_C/0/1/0/all/0/1\">Chulaka Gunasekara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1\">Siva Sankalp Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1\">Hui Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhamecha_T/0/1/0/all/0/1\">Tejas Indulal Dhamecha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contractor_D/0/1/0/all/0/1\">Danish Contractor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danilevsky_M/0/1/0/all/0/1\">Marina Danilevsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Replug: Retrieval-augmented black-box language models. (arXiv:2301.12652v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12652","description":"<p>We introduce REPLUG, a retrieval-augmented language modeling framework that\ntreats the language model (LM) as a black box and augments it with a tuneable\nretrieval model. Unlike prior retrieval-augmented LMs that train language\nmodels with special cross attention mechanisms to encode the retrieved text,\nREPLUG simply prepends retrieved documents to the input for the frozen\nblack-box LM. This simple design can be easily applied to any existing\nretrieval and language models. Furthermore, we show that the LM can be used to\nsupervise the retrieval model, which can then find documents that help the LM\nmake better predictions. Our experiments demonstrate that REPLUG with the tuned\nretriever significantly improves the performance of GPT-3 (175B) on language\nmodeling by 6.3%, as well as the performance of Codex on five-shot MMLU by\n5.1%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_R/0/1/0/all/0/1\">Rich James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using In-Context Learning to Improve Dialogue Safety. (arXiv:2302.00871v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.00871","description":"<p>While large neural-based conversational models have become increasingly\nproficient dialogue agents, recent work has highlighted safety issues with\nthese systems. For example, these systems can be goaded into generating toxic\ncontent, which often perpetuates social biases or stereotypes. We investigate a\nretrieval-based method for reducing bias and toxicity in responses from\nchatbots. It uses in-context learning to steer a model towards safer\ngenerations. Concretely, to generate a response to an unsafe dialogue context,\nwe retrieve demonstrations of safe responses to similar dialogue contexts. We\nfind our method performs competitively with strong baselines without requiring\ntraining. For instance, using automatic evaluation, we find our best fine-tuned\nbaseline only generates safe responses to unsafe dialogue contexts from\nDiaSafety 4.04% more than our approach. Finally, we also propose a re-ranking\nprocedure which can further improve response safeness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meade_N/0/1/0/all/0/1\">Nicholas Meade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gella_S/0/1/0/all/0/1\">Spandana Gella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-T&#xfc;r</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reanalyzing L2 Preposition Learning with Bayesian Mixed Effects and a Pretrained Language Model. (arXiv:2302.08150v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08150","description":"<p>We use both Bayesian and neural models to dissect a data set of Chinese\nlearners' pre- and post-interventional responses to two tests measuring their\nunderstanding of English prepositions. The results mostly replicate previous\nfindings from frequentist analyses and newly reveal crucial interactions\nbetween student ability, task type, and stimulus sentence. Given the sparsity\nof the data as well as high diversity among learners, the Bayesian method\nproves most useful; but we also see potential in using language model\nprobabilities as predictors of grammaticality and learnability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prange_J/0/1/0/all/0/1\">Jakob Prange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_M/0/1/0/all/0/1\">Man Ho Ivy Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.10724","description":"<p>OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and\nrevolutionized the approach in artificial intelligence to human-model\ninteraction. Several publications on ChatGPT evaluation test its effectiveness\non well-known natural language processing (NLP) tasks. However, the existing\nstudies are mostly non-automated and tested on a very limited scale. In this\nwork, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks,\nmost of them subjective even to humans, such as sentiment analysis, emotion\nrecognition, offensiveness, and stance detection. In contrast, the other tasks\nrequire more objective reasoning like word sense disambiguation, linguistic\nacceptability, and question answering. We also evaluated GPT-4 model on five\nselected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process\nand analyzed more than 49k responses. Our comparison of its results with\navailable State-of-the-Art (SOTA) solutions showed that the average loss in\nquality of the ChatGPT model was about 25% for zero-shot and few-shot\nevaluation. For GPT-4 model, a loss for semantic tasks is significantly lower\nthan for ChatGPT. We showed that the more difficult the task (lower SOTA\nperformance), the higher the ChatGPT loss. It especially refers to pragmatic\nNLP problems like emotion recognition. We also tested the ability to\npersonalize ChatGPT responses for selected subjective tasks via Random\nContextual Few-Shot Personalization, and we obtained significantly better\nuser-based predictions. Additional qualitative analysis revealed a ChatGPT\nbias, most likely due to the rules imposed on human trainers by OpenAI. Our\nresults provide the basis for a fundamental discussion of whether the high\nquality of recent predictive NLP models can indicate a tool's usefulness to\nsociety and how the learning and validation procedures for such systems should\nbe established.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocon_J/0/1/0/all/0/1\">Jan Koco&#x144;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cichecki_I/0/1/0/all/0/1\">Igor Cichecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaszyca_O/0/1/0/all/0/1\">Oliwier Kaszyca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kochanek_M/0/1/0/all/0/1\">Mateusz Kochanek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szydlo_D/0/1/0/all/0/1\">Dominika Szyd&#x142;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baran_J/0/1/0/all/0/1\">Joanna Baran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bielaniewicz_J/0/1/0/all/0/1\">Julita Bielaniewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruza_M/0/1/0/all/0/1\">Marcin Gruza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Janz_A/0/1/0/all/0/1\">Arkadiusz Janz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanclerz_K/0/1/0/all/0/1\">Kamil Kanclerz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocon_A/0/1/0/all/0/1\">Anna Koco&#x144;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koptyra_B/0/1/0/all/0/1\">Bart&#x142;omiej Koptyra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mieleszczenko_Kowszewicz_W/0/1/0/all/0/1\">Wiktoria Mieleszczenko-Kowszewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milkowski_P/0/1/0/all/0/1\">Piotr Mi&#x142;kowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oleksy_M/0/1/0/all/0/1\">Marcin Oleksy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piasecki_M/0/1/0/all/0/1\">Maciej Piasecki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radlinski_L/0/1/0/all/0/1\">&#x141;ukasz Radli&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wojtasik_K/0/1/0/all/0/1\">Konrad Wojtasik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wozniak_S/0/1/0/all/0/1\">Stanis&#x142;aw Wo&#x17a;niak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazienko_P/0/1/0/all/0/1\">Przemys&#x142;aw Kazienko</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Prompting with Chain-of-Thought for Large Language Models. (arXiv:2302.12246v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.12246","description":"<p>The increasing scale of large language models (LLMs) brings emergent\nabilities to various complex tasks requiring reasoning, such as arithmetic and\ncommonsense reasoning. It is known that the effective design of task-specific\nprompts is critical for LLMs' ability to produce high-quality answers. In\nparticular, an effective approach for complex question-and-answer tasks is\nexample-based prompting with chain-of-thought (CoT) reasoning, which\nsignificantly improves the performance of LLMs. However, current CoT methods\nrely on a fixed set of human-annotated exemplars, which are not necessarily the\nmost effective examples for different tasks. This paper proposes a new method,\nActive-Prompt, to adapt LLMs to different tasks with task-specific example\nprompts (annotated with human-designed CoT reasoning). For this purpose, we\npropose a solution to the key problem of determining which questions are the\nmost important and helpful ones to annotate from a pool of task-specific\nqueries. By borrowing ideas from the related problem of uncertainty-based\nactive learning, we introduce several metrics to characterize the uncertainty\nso as to select the most uncertain questions for annotation. Experimental\nresults demonstrate the superiority of our proposed method, achieving\nstate-of-the-art on eight complex reasoning tasks. Further analyses of\ndifferent uncertainty metrics, pool sizes, zero-shot learning, and\naccuracy-uncertainty relationship demonstrate the effectiveness of our method.\nOur code will be available at https://github.com/shizhediao/active-prompt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Diao_S/0/1/0/all/0/1\">Shizhe Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengcheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MUX-PLMs: Data Multiplexing for High-throughput Language Models. (arXiv:2302.12441v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.12441","description":"<p>The widespread adoption of large language models such as ChatGPT and Bard has\nled to unprecedented demand for these technologies. The burgeoning cost of\ninference for ever-increasing model sizes coupled with hardware shortages has\nlimited affordable access and poses a pressing need for efficiency approaches\ngeared towards high throughput and performance. Multi-input multi-output (MIMO)\nalgorithms such as data multiplexing, offer a promising solution with a\nmany-fold increase in throughput by performing inference for multiple inputs at\nthe cost of a single input. Yet these approaches are not currently performant\nenough to be deployed in modern systems. We change that by developing MUX-PLMs,\na class of high throughput pre-trained language models (PLMs) trained with data\nmultiplexing, that can be fine-tuned for any downstream task to yield\nhigh-throughput high-performance. Our novel multiplexing and demultiplexing\nmodules proficiently entangle and disentangle inputs, and enable\nhigh-performance high throughput \\muxplms{} that are competitive with vanilla\nPLMs while achieving 2x/5x inference speedup with only a $1-4\\%$ drop on a\nbroad suite of tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Murahari_V/0/1/0/all/0/1\">Vishvak Murahari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ameet Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_C/0/1/0/all/0/1\">Carlos E. Jimenez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafran_I/0/1/0/all/0/1\">Izhak Shafran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingqiu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeltaScore: Story Evaluation with Perturbations. (arXiv:2303.08991v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.08991","description":"<p>Numerous evaluation metrics have been developed for natural language\ngeneration tasks but their effectiveness in evaluating stories is limited as\nthey are not specifically tailored to assess intricate story aspects such as\nfluency and interestingness. In this paper, we propose Deltascore, an approach\nthat utilizes perturbation to evaluate fine-grained story aspects. Our core\nhypothesis is that the better the story performs in a specific aspect (e.g.,\nfluency), the more it will be affected by a particular perturbation (e.g.,\nintroducing typos). To measure the impact, we calculate the \\textit{likelihood\ndifference} between the pre- and post-perturbation using large pre-trained\nlanguage models. We evaluate Deltascore against a suite of current metrics\nacross two story domains, and investigate its correlation with human judgments\non five fine-grained story aspects: fluency, coherence, relatedness,\nlogicality, and interestingness. Deltascore performs very strongly, with a\nsurprise observation that one particular perturbation works very well for\ncapturing multiple aspects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhuohan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Miao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1\">Trevor Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_J/0/1/0/all/0/1\">Jey Han Lau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube. (arXiv:2303.16281v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2303.16281","description":"<p>Contrary to Google Search's mission of delivering information from \"many\nangles so you can form your own understanding of the world,\" we find that\nGoogle and its most prominent returned results - Wikipedia and YouTube - simply\nreflect a narrow set of cultural stereotypes tied to the search language for\ncomplex topics like \"Buddhism,\" \"Liberalism,\" \"colonization,\" \"Iran\" and\n\"America.\" Simply stated, they present, to varying degrees, distinct\ninformation across the same search in different languages, a phenomenon we call\n'language bias.' This paper presents evidence and analysis of language bias and\ndiscusses its larger social implications. Instead of presenting a global\npicture of a complex topic, our online searches and emerging tools like ChatGPT\nturn us into the proverbial blind person touching a small portion of an\nelephant, ignorant of the existence of other cultural perspectives. Piecing\ntogether a genuine depiction of the elephant is a challenging and important\nendeavor that will require collaborative efforts from scholars in both the\nhumanities and technology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Q/0/1/0/all/0/1\">Queenie Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puett_M/0/1/0/all/0/1\">Michael J. Puett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Michael D. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking the Role of Token Retrieval in Multi-Vector Retrieval. (arXiv:2304.01982v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01982","description":"<p>Multi-vector retrieval models such as ColBERT [Khattab and Zaharia, 2020]\nallow token-level interactions between queries and documents, and hence achieve\nstate of the art on many information retrieval benchmarks. However, their\nnon-linear scoring function cannot be scaled to millions of documents,\nnecessitating a three-stage process for inference: retrieving initial\ncandidates via token retrieval, accessing all token vectors, and scoring the\ninitial candidate documents. The non-linear scoring function is applied over\nall token vectors of each candidate document, making the inference process\ncomplicated and slow. In this paper, we aim to simplify the multi-vector\nretrieval by rethinking the role of token retrieval. We present XTR,\nConteXtualized Token Retriever, which introduces a simple, yet novel, objective\nfunction that encourages the model to retrieve the most important document\ntokens first. The improvement to token retrieval allows XTR to rank candidates\nonly using the retrieved tokens rather than all tokens in the document, and\nenables a newly designed scoring stage that is two-to-three orders of magnitude\ncheaper than that of ColBERT. On the popular BEIR benchmark, XTR advances the\nstate-of-the-art by 2.8 nDCG@10 without any distillation. Detailed analysis\nconfirms our decision to revisit the token retrieval stage, as XTR demonstrates\nmuch better recall of the token retrieval stage compared to ColBERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinhyuk Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1\">Zhuyun Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duddu_S/0/1/0/all/0/1\">Sai Meher Karthik Duddu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1\">Tao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naim_I/0/1/0/all/0/1\">Iftekhar Naim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Ming-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_V/0/1/0/all/0/1\">Vincent Y. Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Affect as a proxy for literary mood. (arXiv:2304.02894v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.02894","description":"<p>We propose to use affect as a proxy for mood in literary texts. In this\nstudy, we explore the differences in computationally detecting tone versus\ndetecting mood. Methodologically we utilize affective word embeddings to look\nat the affective distribution in different text segments. We also present a\nsimple yet efficient and effective method of enhancing emotion lexicons to take\nboth semantic shift and the domain of the text into account producing\nreal-world congruent results closely matching both contemporary and modern\nqualitative analyses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ohman_E/0/1/0/all/0/1\">Emily &#xd6;hman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Riikka Rossi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large language models effectively leverage document-level context for literary translation, but critical errors persist. (arXiv:2304.03245v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03245","description":"<p>Large language models (LLMs) are competitive with the state of the art on a\nwide range of sentence-level translation datasets. However, their ability to\ntranslate paragraphs and documents remains unexplored because evaluation in\nthese settings is costly and difficult. We show through a rigorous human\nevaluation that asking the Gpt-3.5 (text-davinci-003) LLM to translate an\nentire literary paragraph (e.g., from a novel) at once results in\nhigher-quality translations than standard sentence-by-sentence translation\nacross 18 linguistically-diverse language pairs (e.g., translating into and out\nof Japanese, Polish, and English). Our evaluation, which took approximately 350\nhours of effort for annotation and analysis, is conducted by hiring translators\nfluent in both the source and target language and asking them to provide both\nspan-level error annotations as well as preference judgments of which system's\ntranslations are better. We observe that discourse-level LLM translators commit\nfewer mistranslations, grammar errors, and stylistic inconsistencies than\nsentence-level approaches. With that said, critical errors still abound,\nincluding occasional content omissions, and a human translator's intervention\nremains necessary to ensure that the author's voice remains intact. We publicly\nrelease our dataset and error annotations to spur future research on evaluation\nof document-level literary translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Karpinska_M/0/1/0/all/0/1\">Marzena Karpinska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11090","description":"<p>The release of ChatGPT, Bard, and other large language model (LLM)-based\nchatbots has drawn huge attention on foundations models worldwide. There is a\ngrowing trend that foundation models will serve as the fundamental building\nblocks for most of the future AI systems. However, incorporating foundation\nmodels in AI systems raises significant concerns about responsible AI due to\ntheir black box nature and rapidly advancing super-intelligence. Additionally,\nthe foundation model's growing capabilities can eventually absorb the other\ncomponents of AI systems, introducing the moving boundary and interface\nevolution challenges in architecture design. To address these challenges, this\npaper proposes a pattern-oriented responsible-AI-by-design reference\narchitecture for designing foundation model-based AI systems. Specially, the\npaper first presents an architecture evolution of AI systems in the era of\nfoundation models, from \"foundation-model-as-a-connector\" to\n\"foundation-model-as-a-monolithic architecture\". The paper then identifies the\nkey design decision points and proposes a pattern-oriented reference\narchitecture to provide reusable responsible-AI-by-design architectural\nsolutions to address the new architecture evolution and responsible AI\nchallenges. The patterns can be embedded as product features of foundation\nmodel-based AI systems and can enable organisations to capitalise on the\npotential of foundation models while minimising associated risks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qinghua Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Liming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whittle_J/0/1/0/all/0/1\">Jon Whittle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted Medical Education and Decision Making in Radiation Oncology. (arXiv:2304.11957v3 [physics.med-ph] UPDATED)","link":"http://arxiv.org/abs/2304.11957","description":"<p>The potential of large language models in medicine for education and decision\nmaking purposes has been demonstrated as they achieve decent scores on medical\nexams such as the United States Medical Licensing Exam (USMLE) and the MedQA\nexam. In this work, we evaluate the performance of ChatGPT-4 in the specialized\nfield of radiation oncology using the 38th American College of Radiology (ACR)\nradiation oncology in-training (TXIT) exam and the 2022 Red Journal gray zone\ncases. For the TXIT exam, ChatGPT-3.5 and ChatGPT-4 have achieved the scores of\n63.65% and 74.57%, respectively, highlighting the advantage of the latest\nChatGPT-4 model. Based on the TXIT exam, ChatGPT-4's strong and weak areas in\nradiation oncology are identified to some extent. Specifically, ChatGPT-4\ndemonstrates good knowledge of statistics, CNS &amp; eye, pediatrics, biology, and\nphysics but has limitations in bone &amp; soft tissue and gynecology, as per the\nACR knowledge domain. Regarding clinical care paths, ChatGPT-4 performs well in\ndiagnosis, prognosis, and toxicity but lacks proficiency in topics related to\nbrachytherapy and dosimetry, as well as in-depth questions from clinical\ntrials. For the gray zone cases, ChatGPT-4 is able to suggest a personalized\ntreatment approach to each case with high correctness and comprehensiveness.\nMost importantly, it provides novel treatment aspects for many cases, which are\nnot suggested by any human experts. Both evaluations demonstrate the potential\nof ChatGPT-4 in medical education for the general public and cancer patients,\nas well as the potential to aid clinical decision-making, while acknowledging\nits limitations in certain domains. Because of the risk of hallucination, facts\nprovided by ChatGPT always need to be verified.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Huang_Y/0/1/0/all/0/1\">Yixing Huang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gomaa_A/0/1/0/all/0/1\">Ahmed Gomaa</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Semrau_S/0/1/0/all/0/1\">Sabine Semrau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Haderlein_M/0/1/0/all/0/1\">Marlen Haderlein</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Lettmaier_S/0/1/0/all/0/1\">Sebastian Lettmaier</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Weissmann_T/0/1/0/all/0/1\">Thomas Weissmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Grigo_J/0/1/0/all/0/1\">Johanna Grigo</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Tkhayat_H/0/1/0/all/0/1\">Hassen Ben Tkhayat</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Frey_B/0/1/0/all/0/1\">Benjamin Frey</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gaipl_U/0/1/0/all/0/1\">Udo S. Gaipl</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Distel_L/0/1/0/all/0/1\">Luitpold V. Distel</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Fietkau_R/0/1/0/all/0/1\">Rainer Fietkau</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Bert_C/0/1/0/all/0/1\">Christoph Bert</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Putz_F/0/1/0/all/0/1\">Florian Putz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.13007","description":"<p>Modern systems for multi-hop question answering (QA) typically break\nquestions into a sequence of reasoning steps, termed chain-of-thought (CoT),\nbefore arriving at a final answer. Often, multiple chains are sampled and\naggregated through a voting mechanism over the final answers, but the\nintermediate steps themselves are discarded. While such approaches improve\nperformance, they do not consider the relations between intermediate steps\nacross chains and do not provide a unified explanation for the predicted\nanswer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts\nlarge language models to meta-reason over multiple chains of thought, rather\nthan aggregating their answers. MCR examines different reasoning chains, mixes\ninformation between them and selects the most relevant facts in generating an\nexplanation and predicting the answer. MCR outperforms strong baselines on 7\nmulti-hop QA datasets. Moreover, our analysis reveals that MCR explanations\nexhibit high quality, enabling humans to verify its answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoran_O/0/1/0/all/0/1\">Ori Yoran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolfson_T/0/1/0/all/0/1\">Tomer Wolfson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogin_B/0/1/0/all/0/1\">Ben Bogin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_U/0/1/0/all/0/1\">Uri Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deutch_D/0/1/0/all/0/1\">Daniel Deutch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v4 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.02783","description":"<p>The recent improvement in code generation capabilities due to the use of\nlarge language models has mainly benefited general purpose programming\nlanguages. Domain specific languages, such as the ones used for IT Automation,\nhave received far less attention, despite involving many active developers and\nbeing an essential component of modern cloud platforms. This work focuses on\nthe generation of Ansible-YAML, a widely used markup language for IT\nAutomation. We present Ansible Wisdom, a natural-language to Ansible-YAML code\ngeneration tool, aimed at improving IT automation productivity. Ansible Wisdom\nis a transformer-based model, extended by training with a new dataset\ncontaining Ansible-YAML. We also develop two novel performance metrics for YAML\nand Ansible to capture the specific characteristics of this domain. Results\nshow that Ansible Wisdom can accurately generate Ansible script from natural\nlanguage prompts with performance comparable or better than existing state of\nthe art code generation models. In few-shot settings we asses the impact of\ntraining with Ansible, YAML data and compare with different baselines including\nCodex-Davinci-002. We also show that after finetuning, our Ansible specific\nmodel (BLEU: 66.67) can outperform a much larger Codex-Davinci-002 (BLEU: 50.4)\nmodel, which was evaluated in few shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pujar_S/0/1/0/all/0/1\">Saurabh Pujar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buratti_L/0/1/0/all/0/1\">Luca Buratti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xiaojie Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dupuis_N/0/1/0/all/0/1\">Nicolas Dupuis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_B/0/1/0/all/0/1\">Burn Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suneja_S/0/1/0/all/0/1\">Sahil Suneja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sood_A/0/1/0/all/0/1\">Atin Sood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nalawade_G/0/1/0/all/0/1\">Ganesh Nalawade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1\">Matthew Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morari_A/0/1/0/all/0/1\">Alessandro Morari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puri_R/0/1/0/all/0/1\">Ruchir Puri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements. (arXiv:2305.03695v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03695","description":"<p>Despite the much discussed capabilities of today's language models, they are\nstill prone to silly and unexpected commonsense failures. We consider a\nretrospective verification approach that reflects on the correctness of LM\noutputs, and introduce Vera, a general-purpose model that estimates the\nplausibility of declarative statements based on commonsense knowledge. Trained\non ~7M commonsense statements created from 19 QA datasets and two large-scale\nknowledge bases, and with a combination of three training objectives, Vera is a\nversatile model that effectively separates correct from incorrect statements\nacross diverse commonsense domains. When applied to solving commonsense\nproblems in the verification format, Vera substantially outperforms existing\nmodels that can be repurposed for commonsense verification, and it further\nexhibits generalization capabilities to unseen tasks and provides\nwell-calibrated outputs. We find that Vera excels at filtering LM-generated\ncommonsense knowledge and is useful in detecting erroneous commonsense\nstatements generated by models like ChatGPT in real-world settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiacheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenya Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dianzhuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MGR: Multi-generator based Rationalization. (arXiv:2305.04492v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.04492","description":"<p>Rationalization is to employ a generator and a predictor to construct a\nself-explaining NLP model in which the generator selects a subset of\nhuman-intelligible pieces of the input text to the following predictor.\nHowever, rationalization suffers from two key challenges, i.e., spurious\ncorrelation and degeneration, where the predictor overfits the spurious or\nmeaningless pieces solely selected by the not-yet well-trained generator and in\nturn deteriorates the generator. Although many studies have been proposed to\naddress the two challenges, they are usually designed separately and do not\ntake both of them into account. In this paper, we propose a simple yet\neffective method named MGR to simultaneously solve the two problems. The key\nidea of MGR is to employ multiple generators such that the occurrence stability\nof real pieces is improved and more meaningful pieces are delivered to the\npredictor. Empirically, we show that MGR improves the F1 score by up to 20.9%\nas compared to state-of-the-art methods. Codes are available at\nhttps://github.com/jugechengzi/Rationalization-MGR .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuankai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yang Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Putting Natural in Natural Language Processing. (arXiv:2305.04572v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04572","description":"<p>Human language is firstly spoken and only secondarily written. Text, however,\nis a very convenient and efficient representation of language, and modern\ncivilization has made it ubiquitous. Thus the field of NLP has overwhelmingly\nfocused on processing written rather than spoken language. Work on spoken\nlanguage, on the other hand, has been siloed off within the largely separate\nspeech processing community which has been inordinately preoccupied with\ntranscribing speech into text. Recent advances in deep learning have led to a\nfortuitous convergence in methods between speech processing and mainstream NLP.\nArguably, the time is ripe for a unification of these two fields, and for\nstarting to take spoken language seriously as the primary mode of human\ncommunication. Truly natural language processing could lead to better\nintegration with the rest of language science and could lead to systems which\nare more data-efficient and more human-like, and which can communicate beyond\nthe textual modality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chrupala_G/0/1/0/all/0/1\">Grzegorz Chrupa&#x142;a</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RECKONING: Reasoning through Dynamic Knowledge Encoding. (arXiv:2305.06349v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06349","description":"<p>Recent studies on transformer-based language models show that they can answer\nquestions by reasoning over knowledge provided as part of the context (i.e.,\nin-context reasoning). However, since the available knowledge is often not\nfiltered for a particular question, in-context reasoning can be sensitive to\ndistractor facts, additional content that is irrelevant to a question but that\nmay be relevant for a different question (i.e., not necessarily random noise).\nIn these situations, the model fails to distinguish the knowledge that is\nnecessary to answer the question, leading to spurious reasoning and degraded\nperformance. This reasoning failure contrasts with the model's apparent ability\nto distinguish its contextual knowledge from all the knowledge it has memorized\nduring pre-training. Following this observation, we propose teaching the model\nto reason more robustly by folding the provided contextual knowledge into the\nmodel's parameters before presenting it with a question. Our method, RECKONING,\nis a bi-level learning algorithm that teaches language models to reason by\nupdating their parametric knowledge through back-propagation, allowing them to\nthen answer questions using the updated parameters. During training, the inner\nloop rapidly adapts a copy of the model weights to encode contextual knowledge\ninto its parameters. In the outer loop, the model learns to use the updated\nweights to reproduce and answer reasoning questions about the memorized\nknowledge. Our experiments on two multi-hop reasoning datasets show that\nRECKONING's performance improves over the in-context reasoning baseline (by up\nto 4.5%). We also find that compared to in-context reasoning, RECKONING\ngeneralizes better to longer reasoning chains unseen during training, is more\nrobust to distractors in the context, and is more computationally efficient\nwhen multiple questions are asked about the same knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1\">Gail Weiss</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1\">Eric Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When the Majority is Wrong: Modeling Annotator Disagreement for Subjective Tasks. (arXiv:2305.06626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06626","description":"<p>Though majority vote among annotators is typically used for ground truth\nlabels in natural language processing, annotator disagreement in tasks such as\nhate speech detection may reflect differences in opinion across groups, not\nnoise. Thus, a crucial problem in hate speech detection is determining whether\na statement is offensive to the demographic group that it targets, when that\ngroup may constitute a small fraction of the annotator pool. We construct a\nmodel that predicts individual annotator ratings on potentially offensive text\nand combines this information with the predicted target group of the text to\nmodel the opinions of target group members. We show gains across a range of\nmetrics, including raising performance over the baseline by 22% at predicting\nindividual annotators' ratings and by 33% at predicting variance among\nannotators, which provides a metric for model uncertainty downstream. We find\nthat annotator ratings can be predicted using their demographic information and\nopinions on online content, without the need to track identifying annotator IDs\nthat link each annotator to their ratings. We also find that use of\nnon-invasive survey questions on annotators' online experiences helps to\nmaximize privacy and minimize unnecessary collection of demographic information\nwhen predicting annotators' opinions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fleisig_E/0/1/0/all/0/1\">Eve Fleisig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abebe_R/0/1/0/all/0/1\">Rediet Abebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WebCPM: Interactive Web Search for Chinese Long-form Question Answering. (arXiv:2305.06849v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06849","description":"<p>Long-form question answering (LFQA) aims at answering complex, open-ended\nquestions with detailed, paragraph-length responses. The de facto paradigm of\nLFQA necessitates two procedures: information retrieval, which searches for\nrelevant supporting facts, and information synthesis, which integrates these\nfacts into a coherent answer. In this paper, we introduce WebCPM, the first\nChinese LFQA dataset. One unique feature of WebCPM is that its information\nretrieval is based on interactive web search, which engages with a search\nengine in real time. Following WebGPT, we develop a web search interface. We\nrecruit annotators to search for relevant information using our interface and\nthen answer questions. Meanwhile, the web search behaviors of our annotators\nwould be recorded. In total, we collect 5,500 high-quality question-answer\npairs, together with 14,315 supporting facts and 121,330 web search actions. We\nfine-tune pre-trained language models to imitate human behaviors for web search\nand to generate answers based on the collected facts. Our LFQA pipeline, built\non these fine-tuned models, generates answers that are no worse than\nhuman-written ones in 32.5% and 47.5% of the cases on our dataset and DuReader,\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zihan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Dian Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1\">Lan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shihao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kunlun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Ning Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huadong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LeXFiles and LegalLAMA: Facilitating English Multinational Legal Language Model Development. (arXiv:2305.07507v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07507","description":"<p>In this work, we conduct a detailed analysis on the performance of\nlegal-oriented pre-trained language models (PLMs). We examine the interplay\nbetween their original objective, acquired knowledge, and legal language\nunderstanding capacities which we define as the upstream, probing, and\ndownstream performance, respectively. We consider not only the models' size but\nalso the pre-training corpora used as important dimensions in our study. To\nthis end, we release a multinational English legal corpus (LeXFiles) and a\nlegal knowledge probing benchmark (LegalLAMA) to facilitate training and\ndetailed analysis of legal-oriented PLMs. We release two new legal PLMs trained\non LeXFiles and evaluate them alongside others on LegalLAMA and LexGLUE. We\nfind that probing performance strongly correlates with upstream performance in\nrelated legal topics. On the other hand, downstream performance is mainly\ndriven by the model's size and prior legal knowledge which can be estimated by\nupstream and probing performance. Based on these findings, we can conclude that\nboth dimensions are important for those seeking the development of\ndomain-specific PLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chalkidis_I/0/1/0/all/0/1\">Ilias Chalkidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garneau_N/0/1/0/all/0/1\">Nicolas Garneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goanta_C/0/1/0/all/0/1\">Catalina Goanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_D/0/1/0/all/0/1\">Daniel Martin Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Video Is Worth 4096 Tokens: Verbalize Story Videos To Understand Them In Zero Shot. (arXiv:2305.09758v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.09758","description":"<p>Multimedia content, such as advertisements and story videos, exhibit a rich\nblend of creativity and multiple modalities. They incorporate elements like\ntext, visuals, audio, and storytelling techniques, employing devices like\nemotions, symbolism, and slogans to convey meaning. While previous research in\nmultimedia understanding has focused mainly on videos with specific actions\nlike cooking, there is a dearth of large annotated training datasets, hindering\nthe development of supervised learning models with satisfactory performance for\nreal-world applications. However, the rise of large language models (LLMs) has\nwitnessed remarkable zero-shot performance in various natural language\nprocessing (NLP) tasks, such as emotion classification, question-answering, and\ntopic classification. To bridge this performance gap in multimedia\nunderstanding, we propose verbalizing story videos to generate their\ndescriptions in natural language and then performing video-understanding tasks\non the generated story as opposed to the original video. Through extensive\nexperiments on five video-understanding tasks, we demonstrate that our method,\ndespite being zero-shot, achieves significantly better results than supervised\nbaselines for video understanding. Further, alleviating a lack of story\nunderstanding benchmarks, we publicly release the first dataset on a crucial\ntask in computational social science, persuasion strategy identification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Aanisha Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman K Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Symbol Prompting Elicits Planning in Large Langauge Models. (arXiv:2305.10276v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10276","description":"<p>In this paper, we take the initiative to investigate the performance of LLMs\non complex planning tasks that require LLMs to understand a virtual spatial\nenvironment simulated via natural language and act correspondingly in text. We\npropose a benchmark named Natural Language Planning (NLP) composed of a set of\nnovel tasks: Brick World, NLVR-based Manipulations, and Natural Language\nNavigation. We found that current popular LLMs such as ChatGPT still lack\nabilities in complex planning. This arises a question -- do the LLMs have a\ngood understanding of the environments described in natural language, or maybe\nother alternatives such as symbolic representations are neater and hence better\nto be understood by LLMs? To this end, we propose a novel method called CoS\n(Chain-of-Symbol Prompting) that represents the complex environments with\ncondensed symbolic spatial representations during the chained intermediate\nthinking steps. CoS is easy to use and does not need additional training on\nLLMs. Extensive experiments indicate that CoS clearly surpasses the performance\nof the Chain-of-Thought (CoT) Prompting in all three planning tasks with even\nfewer tokens used in the inputs compared with CoT on ChatGPT and InstructGPT.\nThe performance gain is strong, by up to 60.8% accuracy (from 31.8% to 92.6%)\non Brick World for ChatGPT. CoS also reduces the number of tokens in the prompt\nobviously, by up to 65.8% of the tokens (from 407 to 139) for the intermediate\nsteps from demonstrations on Brick World.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hanxu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huajian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Object Hallucination in Large Vision-Language Models. (arXiv:2305.10355v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.10355","description":"<p>Inspired by the superior language abilities of large language models (LLM),\nlarge vision-language models (LVLM) have been recently explored by integrating\npowerful LLMs for improving the performance on complex multimodal tasks.\nDespite the promising progress on LVLMs, we find that LVLMs suffer from the\nhallucination problem, i.e. they tend to generate objects that are inconsistent\nwith the target images in the descriptions. To investigate it, this work\npresents the first systematic study on object hallucination of LVLMs. We\nconduct the evaluation experiments on several representative LVLMs, and show\nthat they mostly suffer from severe object hallucination issue. We further\ndiscuss that the visual instructions may influence the hallucination, and find\nthat: objects that frequently occur in the visual instructions or co-occur with\nthe image objects, are obviously prone to be hallucinated by LVLMs. Besides, we\nfind that existing evaluation methods might be affected by the input\ninstructions and generation styles of LVLMs. Thus, we further design an\nimproved evaluation method for object hallucination by proposing a\npolling-based query method called POPE. Experiment results demonstrate that our\nPOPE can evaluate the object hallucination in a more stable and flexible way.\nOur codes and data are publicly available at https://github.com/RUCAIBox/POPE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yifan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Better Way to Do Masked Language Model Scoring. (arXiv:2305.10588v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10588","description":"<p>Estimating the log-likelihood of a given sentence under an autoregressive\nlanguage model is straightforward: one can simply apply the chain rule and sum\nthe log-likelihood values for each successive token. However, for masked\nlanguage models (MLMs), there is no direct way to estimate the log-likelihood\nof a sentence. To address this issue, Salazar et al. (2020) propose to estimate\nsentence pseudo-log-likelihood (PLL) scores, computed by successively masking\neach sentence token, retrieving its score using the rest of the sentence as\ncontext, and summing the resulting values. Here, we demonstrate that the\noriginal PLL method yields inflated scores for out-of-vocabulary words and\npropose an adapted metric, in which we mask not only the target token, but also\nall within-word tokens to the right of the target. We show that our adapted\nmetric (PLL-word-l2r) outperforms both the original PLL metric and a PLL metric\nin which all within-word tokens are masked. In particular, it better satisfies\ntheoretical desiderata and better correlates with scores from autoregressive\nmodels. Finally, we show that the choice of metric affects even tightly\ncontrolled, minimal pair evaluation benchmarks (such as BLiMP), underscoring\nthe importance of selecting an appropriate scoring metric for evaluating MLM\nproperties.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kauf_C/0/1/0/all/0/1\">Carina Kauf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivanova_A/0/1/0/all/0/1\">Anna Ivanova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models Meet World Models: Embodied Experiences Enhance Language Models. (arXiv:2305.10626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10626","description":"<p>While large language models (LMs) have shown remarkable capabilities across\nnumerous tasks, they often struggle with simple reasoning and planning in\nphysical environments, such as understanding object permanence or planning\nhousehold activities. The limitation arises from the fact that LMs are trained\nonly on written text and miss essential embodied knowledge and skills. In this\npaper, we propose a new paradigm of enhancing LMs by finetuning them with world\nmodels, to gain diverse embodied knowledge while retaining their general\nlanguage capabilities. Our approach deploys an embodied agent in a world model,\nparticularly a simulator of the physical world (VirtualHome), and acquires a\ndiverse set of embodied experiences through both goal-oriented planning and\nrandom exploration. These experiences are then used to finetune LMs to teach\ndiverse abilities of reasoning and acting in the physical world, e.g., planning\nand completing goals, object permanence and tracking, etc. Moreover, it is\ndesirable to preserve the generality of LMs during finetuning, which\nfacilitates generalizing the embodied knowledge across tasks rather than being\ntied to specific simulations. We thus further introduce the classical elastic\nweight consolidation (EWC) for selective weight updates, combined with low-rank\nadapters (LoRA) for training efficiency. Extensive experiments show our\napproach substantially improves base LMs on 18 downstream tasks by 64.28% on\naverage. In particular, the small LMs (1.3B and 6B) enhanced by our approach\nmatch or even outperform much larger LMs (e.g., ChatGPT).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1\">Jiannan Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_T/0/1/0/all/0/1\">Tianhua Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yi Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1\">Tianmin Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zirui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning In-context Learning for Named Entity Recognition. (arXiv:2305.11038v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11038","description":"<p>Named entity recognition in real-world applications suffers from the\ndiversity of entity types, the emergence of new entity types, and the lack of\nhigh-quality annotations. To address the above problems, this paper proposes an\nin-context learning-based NER approach, which can effectively inject in-context\nNER ability into PLMs and recognize entities of novel types on-the-fly using\nonly a few demonstrative instances. Specifically, we model PLMs as a\nmeta-function $\\mathcal{ \\lambda_ {\\text{instruction, demonstrations, text}}.\nM}$, and a new entity extractor can be implicitly constructed by applying new\ninstruction and demonstrations to PLMs, i.e., $\\mathcal{ (\\lambda . M)\n}$(instruction, demonstrations) $\\to$ $\\mathcal{F}$ where $\\mathcal{F}$ will be\na new entity extractor, i.e., $\\mathcal{F}$: text $\\to$ entities. To inject the\nabove in-context NER ability into PLMs, we propose a meta-function pre-training\nalgorithm, which pre-trains PLMs by comparing the (instruction,\ndemonstration)-initialized extractor with a surrogate golden extractor.\nExperimental results on 4 few-shot NER datasets show that our method can\neffectively inject in-context NER ability into PLMs and significantly\noutperforms the PLMs+fine-tuning counterparts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiawei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaojie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jie Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1\">Wei Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Dai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1\">Boxi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Separating form and meaning: Using self-consistency to quantify task understanding across multiple senses. (arXiv:2305.11662v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11662","description":"<p>At the staggering pace with which the capabilities of large language models\n(LLMs) are increasing, creating future-proof evaluation sets to assess their\nunderstanding becomes more and more challenging. In this paper, we propose a\nnovel paradigm for evaluating LLMs which leverages the idea that correct world\nunderstanding should be consistent across different (Fregean) senses of the\nsame meaning. Accordingly, we measure understanding not in terms of correctness\nbut by evaluating consistency across multiple senses that are generated by the\nmodel itself. We showcase our approach by instantiating a test where the\ndifferent senses are different languages, hence using multilingual\nself-consistency as a litmus test for the model's understanding and\nsimultaneously addressing the important topic of multilingualism. Taking one of\nthe latest versions of ChatGPT as our object of study, we evaluate multilingual\nconsistency for two different tasks across three different languages. We show\nthat its multilingual consistency is still lacking, and that its task and world\nunderstanding are thus not language-independent. As our approach does not\nrequire any static evaluation corpora in languages other than English, it can\neasily and cheaply be extended to different languages and tasks and could\nbecome an integral part of future benchmarking efforts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ohmer_X/0/1/0/all/0/1\">Xenia Ohmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1\">Elia Bruni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings. (arXiv:2305.11853v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11853","description":"<p>Large language models (LLMs) with in-context learning have demonstrated\nremarkable capability in the text-to-SQL task. Previous research has prompted\nLLMs with various demonstration-retrieval strategies and intermediate reasoning\nsteps to enhance the performance of LLMs. However, those works often employ\nvaried strategies when constructing the prompt text for text-to-SQL inputs,\nsuch as databases and demonstration examples. This leads to a lack of\ncomparability in both the prompt constructions and their primary contributions.\nFurthermore, selecting an effective prompt construction has emerged as a\npersistent problem for future research. To address this limitation, we\ncomprehensively investigate the impact of prompt constructions across various\nsettings and provide insights for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shuaichen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fosler_Lussier_E/0/1/0/all/0/1\">Eric Fosler-Lussier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hedges in Bidirectional Translations of Publicity-Oriented Documents. (arXiv:2305.12146v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12146","description":"<p>Hedges are widely studied across registers and disciplines, yet research on\nthe translation of hedges in political texts is extremely limited. This\ncontrastive study is dedicated to investigating whether there is a diachronic\nchange in the frequencies of hedging devices in the target texts, to what\nextent the changing frequencies of translated hedges through years are\nattributed to the source texts, and what translation strategies are adopted to\ndeal with them. For the purposes of this research, two types of official\npolitical texts and their translations from China and the United Nations were\ncollected to form three sub-corpora. Results show that hedges tend to appear\nmore frequently in English political texts, be it original English or\ntranslated English. In addition, directionality seems to play an important role\nin influencing both the frequencies and translation strategies regarding the\nuse of hedges. A noticeable diachronic increase of hedging devices is also\nobserved in our corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhaokun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Performance of Large Language Models on GAOKAO Benchmark. (arXiv:2305.12474v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12474","description":"<p>Large language models have demonstrated remarkable performance across various\nnatural language processing tasks; however, their efficacy in more challenging\nand domain-specific tasks remains less explored. This paper introduces the\nGAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions\nfrom the Chinese Gaokao examination as test samples for evaluating large\nlanguage models.In order to align the evaluation results with humans as much as\npossible, we designed a method based on zero-shot prompts to analyze the\naccuracy and scoring rate of the model by dividing the questions into\nsubjective and objective types. We evaluated the ChatGPT model on\nGAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels\nin tackling objective questions, while also shedding light on its shortcomings\nand areas for improvement. To further scrutinize the model's responses, we\nincorporate human evaluations.In conclusion, this research contributes a robust\nevaluation benchmark for future large-scale language models and offers valuable\ninsights into the limitations of such models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_Y/0/1/0/all/0/1\">Yi Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_Z/0/1/0/all/0/1\">Zhengyu Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Liang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Simplification of Medical Texts. (arXiv:2305.12532v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12532","description":"<p>Automated text simplification aims to produce simple versions of complex\ntexts. This task is especially useful in the medical domain, where the latest\nmedical findings are typically communicated via complex and technical articles.\nThis creates barriers for laypeople seeking access to up-to-date medical\nfindings, consequently impeding progress on health literacy. Most existing work\non medical text simplification has focused on monolingual settings, with the\nresult that such evidence would be available only in just one language (most\noften, English). This work addresses this limitation via multilingual\nsimplification, i.e., directly simplifying complex texts into simplified texts\nin multiple languages. We introduce MultiCochrane, the first sentence-aligned\nmultilingual text simplification dataset for the medical domain in four\nlanguages: English, Spanish, French, and Farsi. We evaluate fine-tuned and\nzero-shot models across these languages, with extensive human assessments and\nanalyses. Although models can now generate viable simplified texts, we identify\noutstanding challenges that this dataset might be used to address.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joseph_S/0/1/0/all/0/1\">Sebastian Joseph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazanas_K/0/1/0/all/0/1\">Kathryn Kazanas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reina_K/0/1/0/all/0/1\">Keziah Reina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_V/0/1/0/all/0/1\">Vishnesh J. Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Words: A Comprehensive Survey of Sentence Representations. (arXiv:2305.12641v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12641","description":"<p>Sentence representations have become a critical component in natural language\nprocessing applications, such as retrieval, question answering, and text\nclassification. They capture the semantics and meaning of a sentence, enabling\nmachines to understand and reason over human language. In recent years,\nsignificant progress has been made in developing methods for learning sentence\nrepresentations, including unsupervised, supervised, and transfer learning\napproaches. In this paper, we provide an overview of the different methods for\nsentence representation learning, including both traditional and deep\nlearning-based techniques. We provide a systematic organization of the\nliterature on sentence representation learning, highlighting the key\ncontributions and challenges in this area. Overall, our review highlights the\nprogress made in sentence representation learning, the importance of this area\nin natural language processing, and the challenges that remain. We conclude\nwith directions for future research, suggesting potential avenues for improving\nthe quality and efficiency of sentence representations in NLP applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kashyap_A/0/1/0/all/0/1\">Abhinav Ramesh Kashyap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thanh-Tung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schlegel_V/0/1/0/all/0/1\">Viktor Schlegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winkler_S/0/1/0/all/0/1\">Stefan Winkler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_S/0/1/0/all/0/1\">See-Kiong Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-SW3: An Autoregressive Language Model for the Nordic Languages. (arXiv:2305.12987v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12987","description":"<p>This paper details the process of developing the first native large\ngenerative language model for the Nordic languages, GPT-SW3. We cover all parts\nof the development process, from data collection and processing, training\nconfiguration and instruction finetuning, to evaluation and considerations for\nrelease strategies. We hope that this paper can serve as a guide and reference\nfor other researchers that undertake the development of large generative models\nfor smaller languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ekgren_A/0/1/0/all/0/1\">Ariel Ekgren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gyllensten_A/0/1/0/all/0/1\">Amaru Cuba Gyllensten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stollenwerk_F/0/1/0/all/0/1\">Felix Stollenwerk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ohman_J/0/1/0/all/0/1\">Joey &#xd6;hman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isbister_T/0/1/0/all/0/1\">Tim Isbister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gogoulou_E/0/1/0/all/0/1\">Evangelia Gogoulou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carlsson_F/0/1/0/all/0/1\">Fredrik Carlsson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heiman_A/0/1/0/all/0/1\">Alice Heiman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casademont_J/0/1/0/all/0/1\">Judit Casademont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahlgren_M/0/1/0/all/0/1\">Magnus Sahlgren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly Generating Predictions and Natural Language Explanations. (arXiv:2305.13235v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13235","description":"<p>Explaining the decisions of neural models is crucial for ensuring their\ntrustworthiness at deployment time. Using Natural Language Explanations (NLEs)\nto justify a model's predictions has recently gained increasing interest.\nHowever, this approach usually demands large datasets of human-written NLEs for\nthe ground-truth answers, which are expensive and potentially infeasible for\nsome applications. For models to generate high-quality NLEs when only a few\nNLEs are available, the fine-tuning of Pre-trained Language Models (PLMs) in\nconjunction with prompt-based learning recently emerged. However, PLMs\ntypically have billions of parameters, making fine-tuning expensive. We propose\nSparseFit, a sparse few-shot fine-tuning strategy that leverages discrete\nprompts to jointly generate predictions and NLEs. We experiment with SparseFit\non the T5 model and four datasets and compare it against state-of-the-art\nparameter-efficient fine-tuning techniques. We perform automatic and human\nevaluations to assess the quality of the model-generated NLEs, finding that\nfine-tuning only 6.8% of the model parameters leads to competitive results for\nboth the task performance and the quality of the NLEs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Solano_J/0/1/0/all/0/1\">Jesus Solano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camburu_O/0/1/0/all/0/1\">Oana-Maria Camburu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1\">Pasquale Minervini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate Speech Detection. (arXiv:2305.13276v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13276","description":"<p>Hate speech is a severe issue that affects many online platforms. So far,\nseveral studies have been performed to develop robust hate speech detection\nsystems. Large language models like ChatGPT have recently shown a great promise\nin performing several tasks, including hate speech detection. However, it is\ncrucial to comprehend the limitations of these models to build robust hate\nspeech detection systems. To bridge this gap, our study aims to evaluate the\nstrengths and weaknesses of the ChatGPT model in detecting hate speech at a\ngranular level across 11 languages. Our evaluation employs a series of\nfunctionality tests that reveals various intricate failures of the model which\nthe aggregate metrics like macro F1 or accuracy are not able to unfold. In\naddition, we investigate the influence of complex emotions, such as the use of\nemojis in hate speech, on the performance of the ChatGPT model. Our analysis\nhighlights the shortcomings of the generative models in detecting certain types\nof hate speech and highlighting the need for further research and improvements\nin the workings of these models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1\">Mithun Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_S/0/1/0/all/0/1\">Saurabh Kumar Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models. (arXiv:2210.04325v3 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2210.04325","description":"<p>Data-to-text generation is challenging due to the great variety of the input\ndata in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse\npredicates). Recent end-to-end neural methods thus require substantial training\nexamples to learn to disambiguate and describe the data. Yet, real-world\ndata-to-text problems often suffer from various data-scarce issues: one may\nhave access to only a handful of or no training examples, and/or have to rely\non examples in a different domain or schema. To fill this gap, we propose\nAny-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse\nsettings by making efficient use of any given (or no) examples. ASDOT consists\nof two steps, data disambiguation and sentence fusion, both of which are\namenable to be solved with off-the-shelf pretrained language models (LMs) with\noptional finetuning. In the data disambiguation stage, we employ the prompted\nGPT-3 model to understand possibly ambiguous triples from the input data and\nconvert each into a short sentence with reduced ambiguity. The sentence fusion\nstage then uses an LM like T5 to fuse all the resulting sentences into a\ncoherent paragraph as the final description. We evaluate extensively on various\ndatasets in different scenarios, including the zero-/few-/full-shot settings,\nand generalization to unseen predicates and out-of-domain data. Experimental\nresults show that ASDOT consistently achieves significant improvement over\nbaselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot\nsetting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiang_J/0/1/0/all/0/1\">Jiannan Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yucheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-05-23T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}