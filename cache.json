{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-11-01T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v1 [cs.CL])","link":"http://arxiv.org/abs/2310.19923","description":"<p>Text embedding models have emerged as powerful tools for transforming\nsentences into fixed-sized feature vectors that encapsulate semantic\ninformation. While these models are essential for tasks like information\nretrieval, semantic clustering, and text re-ranking, most existing open-source\nmodels, especially those built on architectures like BERT, struggle to\nrepresent lengthy documents and often resort to truncation. One common approach\nto mitigate this challenge involves splitting documents into smaller paragraphs\nfor embedding. However, this strategy results in a much larger set of vectors,\nconsequently leading to increased memory consumption and computationally\nintensive vector searches with elevated latency.\n</p>\n<p>To address these challenges, we introduce Jina Embeddings 2, an open-source\ntext embedding model capable of accommodating up to 8192 tokens. This model is\ndesigned to transcend the conventional 512-token limit and adeptly process long\ndocuments. Jina Embeddings 2 not only achieves state-of-the-art performance on\na range of embedding-related tasks in the MTEB benchmark but also matches the\nperformance of OpenAI's proprietary ada-002 model. Additionally, our\nexperiments indicate that an extended context can enhance performance in tasks\nsuch as NarrativeQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gunther_M/0/1/0/all/0/1\">Michael G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_J/0/1/0/all/0/1\">Jackmin Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohr_I/0/1/0/all/0/1\">Isabelle Mohr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdessalem_A/0/1/0/all/0/1\">Alaeddine Abdessalem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abel_T/0/1/0/all/0/1\">Tanguy Abel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akram_M/0/1/0/all/0/1\">Mohammad Kalim Akram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guzman_S/0/1/0/all/0/1\">Susana Guzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mastrapas_G/0/1/0/all/0/1\">Georgios Mastrapas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sturua_S/0/1/0/all/0/1\">Saba Sturua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werk_M/0/1/0/all/0/1\">Maximilian Werk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Han Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Split-NER: Named Entity Recognition via Two Question-Answering-based Classifications. (arXiv:2310.19942v1 [cs.CL])","link":"http://arxiv.org/abs/2310.19942","description":"<p>In this work, we address the NER problem by splitting it into two logical\nsub-tasks: (1) Span Detection which simply extracts entity mention spans\nirrespective of entity type; (2) Span Classification which classifies the spans\ninto their entity types. Further, we formulate both sub-tasks as\nquestion-answering (QA) problems and produce two leaner models which can be\noptimized separately for each sub-task. Experiments with four cross-domain\ndatasets demonstrate that this two-step approach is both effective and time\nefficient. Our system, SplitNER outperforms baselines on OntoNotes5.0, WNUT17\nand a cybersecurity dataset and gives on-par performance on BioNLP13CG. In all\ncases, it achieves a significant reduction in training time compared to its QA\nbaseline counterpart. The effectiveness of our system stems from fine-tuning\nthe BERT model twice, separately for span detection and classification. The\nsource code can be found at https://github.com/c3sr/split-ner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_J/0/1/0/all/0/1\">Jatin Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1\">Youngja Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Impact of Depth and Width on Transformer Language Model Generalization. (arXiv:2310.19956v1 [cs.CL])","link":"http://arxiv.org/abs/2310.19956","description":"<p>To process novel sentences, language models (LMs) must generalize\ncompositionally -- combine familiar elements in new ways. What aspects of a\nmodel's structure promote compositional generalization? Focusing on\ntransformers, we test the hypothesis, motivated by recent theoretical and\nempirical work, that transformers generalize more compositionally when they are\ndeeper (have more layers). Because simply adding layers increases the total\nnumber of parameters, confounding depth and size, we construct three classes of\nmodels which trade off depth for width such that the total number of parameters\nis kept constant (41M, 134M and 374M parameters). We pretrain all models as LMs\nand fine-tune them on tasks that test for compositional generalization. We\nreport three main conclusions: (1) after fine-tuning, deeper models generalize\nbetter out-of-distribution than shallower models do, but the relative benefit\nof additional layers diminishes rapidly; (2) within each family, deeper models\nshow better language modeling performance, but returns are similarly\ndiminishing; (3) the benefits of depth for compositional generalization cannot\nbe attributed solely to better performance on language modeling or on\nin-distribution data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petty_J/0/1/0/all/0/1\">Jackson Petty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steenkiste_S/0/1/0/all/0/1\">Sjoerd van Steenkiste</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1\">Ishita Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sha_F/0/1/0/all/0/1\">Fei Sha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrette_D/0/1/0/all/0/1\">Dan Garrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linzen_T/0/1/0/all/0/1\">Tal Linzen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Strategies to Harness the Transformers' Potential: UNSL at eRisk 2023. (arXiv:2310.19970v1 [cs.CL])","link":"http://arxiv.org/abs/2310.19970","description":"<p>The CLEF eRisk Laboratory explores solutions to different tasks related to\nrisk detection on the Internet. In the 2023 edition, Task 1 consisted of\nsearching for symptoms of depression, the objective of which was to extract\nuser writings according to their relevance to the BDI Questionnaire symptoms.\nTask 2 was related to the problem of early detection of pathological gambling\nrisks, where the participants had to detect users at risk as quickly as\npossible. Finally, Task 3 consisted of estimating the severity levels of signs\nof eating disorders. Our research group participated in the first two tasks,\nproposing solutions based on Transformers. For Task 1, we applied different\napproaches that can be interesting in information retrieval tasks. Two\nproposals were based on the similarity of contextualized embedding vectors, and\nthe other one was based on prompting, an attractive current technique of\nmachine learning. For Task 2, we proposed three fine-tuned models followed by\ndecision policy according to criteria defined by an early detection framework.\nOne model presented extended vocabulary with important words to the addressed\ndomain. In the last task, we obtained good performances considering the\ndecision-based metrics, ranking-based metrics, and runtime. In this work, we\nexplore different ways to deploy the predictive potential of Transformers in\neRisk tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thompson_H/0/1/0/all/0/1\">Horacio Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cagnina_L/0/1/0/all/0/1\">Leticia Cagnina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Errecalde_M/0/1/0/all/0/1\">Marcelo Errecalde</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioInstruct: Instruction Tuning of Large Language Models for Biomedical Natural Language Processing. (arXiv:2310.19975v1 [cs.CL])","link":"http://arxiv.org/abs/2310.19975","description":"<p>Large language models (LLMs) has achieved a great success in many natural\nlanguage processing (NLP) tasks. This is achieved by pretraining of LLMs on\nvast amount of data and then instruction tuning to specific domains. However,\nonly a few instructions in the biomedical domain have been published. To\naddress this issue, we introduce BioInstruct, a customized task-specific\ninstruction dataset containing more than 25,000 examples. This dataset was\ngenerated attractively by prompting a GPT-4 language model with a\nthree-seed-sample of 80 human-curated instructions. By fine-tuning LLMs using\nthe BioInstruct dataset, we aim to optimize the LLM's performance in biomedical\nnatural language processing (BioNLP). We conducted instruction tuning on the\nLLaMA LLMs (1\\&amp;2, 7B\\&amp;13B) and evaluated them on BioNLP applications, including\ninformation extraction, question answering, and text generation. We also\nevaluated how instructions contributed to model performance using multi-tasking\nlearning principles.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hieu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative retrieval-augmented ontologic graph and multi-agent strategies for interpretive large language model-based materials design. (arXiv:2310.19998v1 [cs.CL])","link":"http://arxiv.org/abs/2310.19998","description":"<p>Transformer neural networks show promising capabilities, in particular for\nuses in materials analysis, design and manufacturing, including their capacity\nto work effectively with both human language, symbols, code, and numerical\ndata. Here we explore the use of large language models (LLMs) as a tool that\ncan support engineering analysis of materials, applied to retrieving key\ninformation about subject areas, developing research hypotheses, discovery of\nmechanistic relationships across disparate areas of knowledge, and writing and\nexecuting simulation codes for active knowledge generation based on physical\nground truths. When used as sets of AI agents with specific features,\ncapabilities, and instructions, LLMs can provide powerful problem solution\nstrategies for applications in analysis and design problems. Our experiments\nfocus on using a fine-tuned model, MechGPT, developed based on training data in\nthe mechanics of materials domain. We first affirm how finetuning endows LLMs\nwith reasonable understanding of domain knowledge. However, when queried\noutside the context of learned matter, LLMs can have difficulty to recall\ncorrect information. We show how this can be addressed using\nretrieval-augmented Ontological Knowledge Graph strategies that discern how the\nmodel understands what concepts are important and how they are related.\nIllustrated for a use case of relating distinct areas of knowledge - here,\nmusic and proteins - such strategies can also provide an interpretable graph\nstructure with rich information at the node, edge and subgraph level. We\ndiscuss nonlinear sampling strategies and agent-based modeling applied to\ncomplex question answering, code generation and execution in the context of\nautomated force field development from actively learned Density Functional\nTheory (DFT) modeling, and data analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Early Detection of Depression and Eating Disorders in Spanish: UNSL at MentalRiskES 2023. (arXiv:2310.20003v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20003","description":"<p>MentalRiskES is a novel challenge that proposes to solve problems related to\nearly risk detection for the Spanish language. The objective is to detect, as\nsoon as possible, Telegram users who show signs of mental disorders considering\ndifferent tasks. Task 1 involved the users' detection of eating disorders, Task\n2 focused on depression detection, and Task 3 aimed at detecting an unknown\ndisorder. These tasks were divided into subtasks, each one defining a\nresolution approach. Our research group participated in subtask A for Tasks 1\nand 2: a binary classification problem that evaluated whether the users were\npositive or negative. To solve these tasks, we proposed models based on\nTransformers followed by a decision policy according to criteria defined by an\nearly detection framework. One of the models presented an extended vocabulary\nwith important words for each task to be solved. In addition, we applied a\ndecision policy based on the history of predictions that the model performs\nduring user evaluation. For Tasks 1 and 2, we obtained the second-best\nperformance according to rankings based on classification and latency,\ndemonstrating the effectiveness and consistency of our approaches for solving\nearly detection problems in the Spanish language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thompson_H/0/1/0/all/0/1\">Horacio Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Errecalde_M/0/1/0/all/0/1\">Marcelo Errecalde</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Imitation Edit Feedback for Factual Alignment in Clinical Summarization. (arXiv:2310.20033v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20033","description":"<p>Large Language Models (LLMs) like the GPT and LLaMA families have\ndemonstrated exceptional capabilities in capturing and condensing critical\ncontextual information and achieving state-of-the-art performance in the\nsummarization task. However, community concerns about these models'\nhallucination issues continue to rise. LLMs sometimes generate factually\nhallucinated summaries, which can be extremely harmful in the clinical domain\nNLP tasks (e.g., clinical note summarization), where factually incorrect\nstatements can lead to critically erroneous diagnoses. Fine-tuning LLMs using\nhuman feedback has shown the promise of aligning LLMs to be factually\nconsistent during generation, but such training procedure requires high-quality\nhuman-annotated data, which can be extremely expensive to get in the clinical\ndomain. In this work, we propose a new pipeline using ChatGPT instead of human\nexperts to generate high-quality feedback data for improving factual\nconsistency in the clinical note summarization task. We focus specifically on\nedit feedback because recent work discusses the shortcomings of human alignment\nvia preference feedback in complex situations (such as clinical NLP tasks that\nrequire extensive expert knowledge), as well as some advantages of collecting\nedit feedback from domain experts. In addition, although GPT has reached the\nexpert level in many clinical NLP tasks (e.g., USMLE QA), there is not much\nprevious work discussing whether GPT can generate expert-level edit feedback\nfor LMs in the clinical note summarization task. We hope to fill this gap.\nFinally, our evaluations demonstrate the potential use of GPT edits in human\nalignment, especially from a factuality perspective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Prakamya Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuwei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Beining Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mittal_R/0/1/0/all/0/1\">Rohan Mittal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Which Examples to Annotate for In-Context Learning? Towards Effective and Efficient Selection. (arXiv:2310.20046v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20046","description":"<p>Large Language Models (LLMs) can adapt to new tasks via in-context learning\n(ICL). ICL is efficient as it does not require any parameter updates to the\ntrained LLM, but only few annotated examples as input for the LLM. In this\nwork, we investigate an active learning approach for ICL, where there is a\nlimited budget for annotating examples. We propose a model-adaptive\noptimization-free algorithm, termed AdaICL, which identifies examples that the\nmodel is uncertain about, and performs semantic diversity-based example\nselection. Diversity-based sampling improves overall effectiveness, while\nuncertainty sampling improves budget efficiency and helps the LLM learn new\ninformation. Moreover, AdaICL poses its sampling strategy as a Maximum Coverage\nproblem, that dynamically adapts based on the model's feedback and can be\napproximately solved via greedy algorithms. Extensive experiments on nine\ndatasets and seven LLMs show that AdaICL improves performance by 4.4% accuracy\npoints over SOTA (7.7% relative improvement), is up to 3x more budget-efficient\nthan performing annotations uniformly at random, while it outperforms SOTA with\n2x fewer ICL examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mavromatis_C/0/1/0/all/0/1\">Costas Mavromatis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balasubramaniam Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhengyuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiani Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1\">Huzefa Rangwala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faloutsos_C/0/1/0/all/0/1\">Christos Faloutsos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">George Karypis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Evaluation of Generative Models with Instruction Tuning. (arXiv:2310.20072v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20072","description":"<p>Automatic evaluation of natural language generation has long been an elusive\ngoal in NLP.A recent paradigm fine-tunes pre-trained language models to emulate\nhuman judgements for a particular task and evaluation criterion. Inspired by\nthe generalization ability of instruction-tuned models, we propose a learned\nmetric based on instruction tuning. To test our approach, we collected HEAP, a\ndataset of human judgements across various NLG tasks and evaluation criteria.\nOur findings demonstrate that instruction tuning language models on HEAP yields\ngood performance on many evaluation tasks, though some criteria are less\ntrivial to learn than others. Further, jointly training on multiple tasks can\nyield additional performance improvements, which can be beneficial for future\ntasks with little to no human annotated data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mehri_S/0/1/0/all/0/1\">Shuhaib Mehri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Partial Tensorized Transformers for Natural Language Processing. (arXiv:2310.20077v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20077","description":"<p>The transformer architecture has revolutionized Natural Language Processing\n(NLP) and other machine-learning tasks, due to its unprecedented accuracy.\nHowever, their extensive memory and parameter requirements often hinder their\npractical applications. In this work, we study the effect of tensor-train\ndecomposition to improve the accuracy and compress transformer vision-language\nneural networks, namely BERT and ViT. We focus both on embedding-layer\ncompression and partial tensorization of neural networks (PTNN) through an\nalgorithmic approach. Our novel PTNN approach significantly improves the\naccuracy of existing models by up to 5%, all without the need for post-training\nadjustments, breaking new ground in the field of tensor decomposition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vadlamannati_S/0/1/0/all/0/1\">Subhadra Vadlamannati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solgi_R/0/1/0/all/0/1\">Ryan Solgi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Summarization and Retrieval for Enhanced Personalization via Large Language Models. (arXiv:2310.20081v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20081","description":"<p>Personalization, the ability to tailor a system to individual users, is an\nessential factor in user experience with natural language processing (NLP)\nsystems. With the emergence of Large Language Models (LLMs), a key question is\nhow to leverage these models to better personalize user experiences. To\npersonalize a language model's output, a straightforward approach is to\nincorporate past user data into the language model prompt, but this approach\ncan result in lengthy inputs exceeding limitations on input length and\nincurring latency and cost issues. Existing approaches tackle such challenges\nby selectively extracting relevant user data (i.e. selective retrieval) to\nconstruct a prompt for downstream tasks. However, retrieval-based methods are\nlimited by potential information loss, lack of more profound user\nunderstanding, and cold-start challenges. To overcome these limitations, we\npropose a novel summary-augmented approach by extending retrieval-augmented\npersonalization with task-aware user summaries generated by LLMs. The summaries\ncan be generated and stored offline, enabling real-world systems with runtime\nconstraints like voice assistants to leverage the power of LLMs. Experiments\nshow our method with 75% less of retrieved user data is on-par or outperforms\nretrieval augmentation on most tasks in the LaMP personalization benchmark. We\ndemonstrate that offline summarization via LLMs and runtime retrieval enables\nbetter performance for personalization on a range of tasks under practical\nconstraints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Richardson_C/0/1/0/all/0/1\">Chris Richardson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillespie_K/0/1/0/all/0/1\">Kellen Gillespie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kar_S/0/1/0/all/0/1\">Sudipta Kar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Arshdeep Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raeesy_Z/0/1/0/all/0/1\">Zeynab Raeesy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_O/0/1/0/all/0/1\">Omar Zia Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sethy_A/0/1/0/all/0/1\">Abhinav Sethy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Keyword-optimized Template Insertion for Clinical Information Extraction via Prompt-based Learning. (arXiv:2310.20089v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20089","description":"<p>Clinical note classification is a common clinical NLP task. However,\nannotated data-sets are scarse. Prompt-based learning has recently emerged as\nan effective method to adapt pre-trained models for text classification using\nonly few training examples. A critical component of prompt design is the\ndefinition of the template (i.e. prompt text). The effect of template position,\nhowever, has been insufficiently investigated. This seems particularly\nimportant in the clinical setting, where task-relevant information is usually\nsparse in clinical notes. In this study we develop a keyword-optimized template\ninsertion method (KOTI) and show how optimizing position can improve\nperformance on several clinical tasks in a zero-shot and few-shot training\nsetting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alleva_E/0/1/0/all/0/1\">Eugenia Alleva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landi_I/0/1/0/all/0/1\">Isotta Landi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaw_L/0/1/0/all/0/1\">Leslee J Shaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bottinger_E/0/1/0/all/0/1\">Erwin B&#xf6;ttinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuchs_T/0/1/0/all/0/1\">Thomas J Fuchs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ensari_I/0/1/0/all/0/1\">Ipek Ensari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Neural Language Models as Cognitive Models of Language Acquisition. (arXiv:2310.20093v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20093","description":"<p>The success of neural language models (LMs) on many technological tasks has\nbrought about their potential relevance as scientific theories of language\ndespite some clear differences between LM training and child language\nacquisition. In this paper we argue that some of the most prominent benchmarks\nfor evaluating the syntactic capacities of LMs may not be sufficiently\nrigorous. In particular, we show that the template-based benchmarks lack the\nstructural diversity commonly found in the theoretical and psychological\nstudies of language. When trained on small-scale data modeling child language\nacquisition, the LMs can be readily matched by simple baseline models. We\nadvocate for the use of the readily available, carefully curated datasets that\nhave been evaluated for gradient acceptability by large pools of native\nspeakers and are designed to probe the structural basis of grammar\nspecifically. On one such dataset, the LI-Adger dataset, LMs evaluate sentences\nin a way inconsistent with human language users. We conclude with suggestions\nfor better connecting LMs with the empirical study of child language\nacquisition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_H/0/1/0/all/0/1\">H&#xe9;ctor Javier V&#xe1;zquez Mart&#xed;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heuser_A/0/1/0/all/0/1\">Annika Lea Heuser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Charles Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kodner_J/0/1/0/all/0/1\">Jordan Kodner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Classification of Student Help Requests in Programming Courses Using Large Language Models. (arXiv:2310.20105v1 [cs.CY])","link":"http://arxiv.org/abs/2310.20105","description":"<p>The accurate classification of student help requests with respect to the type\nof help being sought can enable the tailoring of effective responses.\nAutomatically classifying such requests is non-trivial, but large language\nmodels (LLMs) appear to offer an accessible, cost-effective solution. This\nstudy evaluates the performance of the GPT-3.5 and GPT-4 models for classifying\nhelp requests from students in an introductory programming class. In zero-shot\ntrials, GPT-3.5 and GPT-4 exhibited comparable performance on most categories,\nwhile GPT-4 outperformed GPT-3.5 in classifying sub-categories for requests\nrelated to debugging. Fine-tuning the GPT-3.5 model improved its performance to\nsuch an extent that it approximated the accuracy and consistency across\ncategories observed between two human raters. Overall, this study demonstrates\nthe feasibility of using LLMs to enhance educational systems through the\nautomated classification of student needs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Savelka_J/0/1/0/all/0/1\">Jaromir Savelka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1\">Paul Denny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liffiton_M/0/1/0/all/0/1\">Mark Liffiton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheese_B/0/1/0/all/0/1\">Brad Sheese</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making Large Language Models Better Data Creators. (arXiv:2310.20111v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20111","description":"<p>Although large language models (LLMs) have advanced the state-of-the-art in\nNLP significantly, deploying them for downstream applications is still\nchallenging due to cost, responsiveness, control, or concerns around privacy\nand security. As such, trainable models are still the preferred option in some\ncases. However, these models still require human-labeled data for optimal\nperformance, which is expensive and time-consuming to obtain. In order to\naddress this issue, several techniques to reduce human effort involve labeling\nor generating data using LLMs. Although these methods are effective for certain\napplications, in practice they encounter difficulties in real-world scenarios.\nLabeling data requires careful data selection, while generating data\nnecessitates task-specific prompt engineering. In this paper, we propose a\nunified data creation pipeline that requires only a single formatting example,\nand which is applicable to a broad range of tasks, including traditionally\nproblematic ones with semantically devoid label spaces. In our experiments we\ndemonstrate that instruction-following LLMs are highly cost-effective data\ncreators, and that models trained with these data exhibit performance better\nthan those trained with human-labeled data (by up to 17.5%) on\nout-of-distribution evaluation, while maintaining comparable performance on\nin-distribution tasks. These results have important implications for the\nrobustness of NLP systems deployed in the real-world.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dong-Ho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujara_J/0/1/0/all/0/1\">Jay Pujara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sewak_M/0/1/0/all/0/1\">Mohit Sewak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_R/0/1/0/all/0/1\">Ryen W. White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jauhar_S/0/1/0/all/0/1\">Sujay Kumar Jauhar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ling-CL: Understanding NLP Models through Linguistic Curricula. (arXiv:2310.20121v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20121","description":"<p>We employ a characterization of linguistic complexity from psycholinguistic\nand language acquisition research to develop data-driven curricula to\nunderstand the underlying linguistic knowledge that models learn to address NLP\ntasks. The novelty of our approach is in the development of linguistic\ncurricula derived from data, existing knowledge about linguistic complexity,\nand model behavior during training. By analyzing several benchmark NLP\ndatasets, our curriculum learning approaches identify sets of linguistic\nmetrics (indices) that inform the challenges and reasoning required to address\neach task. Our work will inform future research in all NLP areas, allowing\nlinguistic complexity to be considered early in the research and development\nprocess. In addition, our work prompts an examination of gold standards and\nfair evaluation in NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elgaar_M/0/1/0/all/0/1\">Mohamed Elgaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amiri_H/0/1/0/all/0/1\">Hadi Amiri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Prompt Tuning with Learned Prompting Layers. (arXiv:2310.20127v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20127","description":"<p>Prompt tuning prepends a soft prompt to the input embeddings or hidden states\nand only optimizes the prompt to adapt pretrained models (PTMs) to downstream\ntasks. The previous work manually selects prompt layers which are far from\noptimal and failed to exploit the potential of prompt tuning. In this work, we\npropose a novel framework, \\underline{S}elective \\underline{P}rompt\n\\underline{T}uning (SPT), that learns to select the proper prompt layers by\ninserting a prompt controlled by a learnable probabilistic gate at each\nintermediate layer. We further propose a novel bi-level optimization framework,\nSPT-DARTS, that can better optimize the learnable gates and improve the final\nprompt tuning performances of the learned prompt layer settings. We conduct\nextensive experiments with ten benchmark datasets under the full-data and\nfew-shot scenarios. The results demonstrate that our SPT framework can perform\nbetter than the previous state-of-the-art PETuning baselines with comparable or\nfewer tunable parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1\">Ming Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models. (arXiv:2310.20138v1 [cs.CR])","link":"http://arxiv.org/abs/2310.20138","description":"<p>Large language models pretrained on a huge amount of data capture rich\nknowledge and information in the training data. The ability of data\nmemorization and regurgitation in pretrained language models, revealed in\nprevious studies, brings the risk of data leakage. In order to effectively\nreduce these risks, we propose a framework DEPN to Detect and Edit Privacy\nNeurons in pretrained language models, partially inspired by knowledge neurons\nand model editing. In DEPN, we introduce a novel method, termed as privacy\nneuron detector, to locate neurons associated with private information, and\nthen edit these detected privacy neurons by setting their activations to zero.\nFurthermore, we propose a privacy neuron aggregator dememorize private\ninformation in a batch processing manner. Experimental results show that our\nmethod can significantly and efficiently reduce the exposure of private data\nleakage without deteriorating the performance of the model. Additionally, we\nempirically demonstrate the relationship between model memorization and privacy\nneurons, from multiple perspectives, including model size, training time,\nprompts, privacy neuron distribution, illustrating the robustness of our\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xinwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junzhuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Minghui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1\">Weilong Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_C/0/1/0/all/0/1\">Chao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EELBERT: Tiny Models through Dynamic Embeddings. (arXiv:2310.20144v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20144","description":"<p>We introduce EELBERT, an approach for compression of transformer-based models\n(e.g., BERT), with minimal impact on the accuracy of downstream tasks. This is\nachieved by replacing the input embedding layer of the model with dynamic, i.e.\non-the-fly, embedding computations. Since the input embedding layer accounts\nfor a significant fraction of the model size, especially for the smaller BERT\nvariants, replacing this layer with an embedding computation function helps us\nreduce the model size significantly. Empirical evaluation on the GLUE benchmark\nshows that our BERT variants (EELBERT) suffer minimal regression compared to\nthe traditional BERT models. Through this approach, we are able to develop our\nsmallest model UNO-EELBERT, which achieves a GLUE score within 4% of fully\ntrained BERT-tiny, while being 15x smaller (1.2 MB) in size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cohn_G/0/1/0/all/0/1\">Gabrielle Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_R/0/1/0/all/0/1\">Rishika Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_D/0/1/0/all/0/1\">Deepanshu Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwardhan_S/0/1/0/all/0/1\">Siddharth Patwardhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unlearn What You Want to Forget: Efficient Unlearning for LLMs. (arXiv:2310.20150v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20150","description":"<p>Large language models (LLMs) have achieved significant progress from\npre-training on and memorizing a wide range of textual data, however, this\nprocess might suffer from privacy issues and violations of data protection\nregulations. As a result, the ability to easily remove data related to\nindividual users from such models while not deteriorating their predictive\nquality after the removal becomes increasingly important. To address these\nissues, in this work, we propose an efficient unlearning framework that could\nefficiently update LLMs without having to retrain the whole model after data\nremovals, by introducing lightweight unlearning layers learned with a selective\nteacher-student objective into the transformers. In addition, we introduce a\nfusion mechanism to effectively combine different unlearning layers that learns\nto forget different sets of data to handle a sequence of forgetting operations.\nExperiments on classification and generation tasks demonstrate the\neffectiveness of our proposed methods compared to the state-of-the-art\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Agent Consensus Seeking via Large Language Models. (arXiv:2310.20151v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20151","description":"<p>Multi-agent systems driven by large language models (LLMs) have shown\npromising abilities for solving complex tasks in a collaborative manner. This\nwork considers a fundamental problem in multi-agent collaboration: consensus\nseeking. When multiple agents work together, we are interested in how they can\nreach a consensus through inter-agent negotiation. To that end, this work\nstudies a consensus-seeking task where the state of each agent is a numerical\nvalue and they negotiate with each other to reach a consensus value. It is\nrevealed that when not explicitly directed on which strategy should be adopted,\nthe LLM-driven agents primarily use the average strategy for consensus seeking\nalthough they may occasionally use some other strategies. Moreover, this work\nanalyzes the impact of the agent number, agent personality, and network\ntopology on the negotiation process. The findings reported in this work can\npotentially lay the foundations for understanding the behaviors of LLM-driven\nmulti-agent systems for solving more complex tasks. Furthermore, LLM-driven\nconsensus seeking is applied to a multi-robot aggregation task. This\napplication demonstrates the potential of LLM-driven agents to achieve\nzero-shot autonomous planning for multi-robot collaboration tasks. Project\nwebsite: westlakeintelligentrobotics.github.io/ConsensusLLM/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huaben Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wenkang Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Lufeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shiyu Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision. (arXiv:2310.20153v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20153","description":"<p>Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious tasks. However, their suitability for domain-specific tasks, is limited\ndue to their immense scale at deployment, susceptibility to misinformation, and\nmore importantly, high data annotation costs. We propose a novel Interactive\nMulti-Fidelity Learning (IMFL) framework for the cost-effective development of\nsmall domain-specific LMs under limited annotation budgets. Our approach\nformulates the domain-specific fine-tuning process as a multi-fidelity learning\nproblem, focusing on identifying the optimal acquisition strategy that balances\nbetween low-fidelity automatic LLM annotations and high-fidelity human\nannotations to maximize model performance. We further propose an\nexploration-exploitation query strategy that enhances annotation diversity and\ninformativeness, incorporating two innovative designs: 1) prompt retrieval that\nselects in-context examples from human-annotated samples to improve LLM\nannotation, and 2) variable batch size that controls the order for choosing\neach fidelity to facilitate knowledge distillation, ultimately enhancing\nannotation quality. Extensive experiments on financial and medical tasks\ndemonstrate that IMFL achieves superior performance compared with single\nfidelity annotations. Given a limited budget of human annotation, IMFL\nsignificantly outperforms the human annotation baselines in all four tasks and\nachieves very close performance as human annotations on two of the tasks. These\npromising results suggest that the high human annotation costs in\ndomain-specific tasks can be significantly reduced by employing IMFL, which\nutilizes fewer human annotations, supplemented with cheaper and faster LLM\n(e.g., GPT-3.5) annotations to achieve comparable performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuohang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_K/0/1/0/all/0/1\">Kamalika Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sricharan Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GAR-meets-RAG Paradigm for Zero-Shot Information Retrieval. (arXiv:2310.20158v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20158","description":"<p>Given a query and a document corpus, the information retrieval (IR) task is\nto output a ranked list of relevant documents. Combining large language models\n(LLMs) with embedding-based retrieval models, recent work shows promising\nresults on the zero-shot retrieval problem, i.e., no access to labeled data\nfrom the target domain. Two such popular paradigms are generation-augmented\nretrieval or GAR (generate additional context for the query and then retrieve),\nand retrieval-augmented generation or RAG (retrieve relevant documents as\ncontext and then generate answers). The success of these paradigms hinges on\n(i) high-recall retrieval models, which are difficult to obtain in the\nzero-shot setting, and (ii) high-precision (re-)ranking models which typically\nneed a good initialization. In this work, we propose a novel GAR-meets-RAG\nrecurrence formulation that overcomes the challenges of existing paradigms. Our\nmethod iteratively improves retrieval (via GAR) and rewrite (via RAG) stages in\nthe zero-shot setting. A key design principle is that the rewrite-retrieval\nstages improve the recall of the system and a final re-ranking stage improves\nthe precision. We conduct extensive experiments on zero-shot passage retrieval\nbenchmarks, BEIR and TREC-DL. Our method establishes a new state-of-the-art in\nthe BEIR benchmark, outperforming previous best results in Recall@100 and\nnDCG@10 metrics on 6 out of 8 datasets, with up to 17% relative gains over the\nprevious best.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_D/0/1/0/all/0/1\">Daman Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kini_A/0/1/0/all/0/1\">Anush Kini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Sayak Ray Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Natarajan_N/0/1/0/all/0/1\">Nagarajan Natarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_G/0/1/0/all/0/1\">Gaurav Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain Question Answering over Knowledge Base and Text. (arXiv:2310.20170v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20170","description":"<p>Large Language Models (LLMs) have exhibited impressive generation\ncapabilities, but they suffer from hallucinations when solely relying on their\ninternal knowledge, especially when answering questions that require less\ncommonly known information. Retrieval-augmented LLMs have emerged as a\npotential solution to ground LLMs in external knowledge. Nonetheless, recent\napproaches have primarily emphasized retrieval from unstructured text corpora,\nowing to its seamless integration into prompts. When using structured data such\nas knowledge graphs, most methods simplify it into natural text, neglecting the\nunderlying structures. Moreover, a significant gap in the current landscape is\nthe absence of a realistic benchmark for evaluating the effectiveness of\ngrounding LLMs on heterogeneous knowledge sources (e.g., knowledge base and\ntext). To fill this gap, we have curated a comprehensive dataset that poses two\nunique challenges: (1) Two-hop multi-source questions that require retrieving\ninformation from both open-domain structured and unstructured knowledge\nsources; retrieving information from structured knowledge sources is a critical\ncomponent in correctly answering the questions. (2) The generation of symbolic\nqueries (e.g., SPARQL for Wikidata) is a key requirement, which adds another\nlayer of challenge. Our dataset is created using a combination of automatic\ngeneration through predefined reasoning chains and human annotation. We also\nintroduce a novel approach that leverages multiple retrieval tools, including\ntext passage retrieval and symbolic language-assisted retrieval. Our model\noutperforms previous approaches by a significant margin, demonstrating its\neffectiveness in addressing the above-mentioned reasoning challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wenting Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1\">Tong Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Continuations in Multilingual Idiomatic Contexts. (arXiv:2310.20195v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20195","description":"<p>The ability to process idiomatic or literal multiword expressions is a\ncrucial aspect of understanding and generating any language. The task of\ngenerating contextually relevant continuations for narratives containing\nidiomatic (or literal) expressions can allow us to test the ability of\ngenerative language models (LMs) in understanding nuanced language containing\nnon-compositional figurative text. We conduct a series of experiments using\ndatasets in two distinct languages (English and Portuguese) under three\ndifferent training settings (zero-shot, few-shot, and fine-tuned). Our results\nsuggest that the models are only slightly better at generating continuations\nfor literal contexts than idiomatic contexts, with exceedingly small margins.\nFurthermore, the models studied in this work perform equally well across both\nlanguages, indicating the robustness of generative models in performing this\ntask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pokharel_R/0/1/0/all/0/1\">Rhitabrat Pokharel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Ameeta Agrawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Video-Helpful Multimodal Machine Translation. (arXiv:2310.20201v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20201","description":"<p>Existing multimodal machine translation (MMT) datasets consist of images and\nvideo captions or instructional video subtitles, which rarely contain\nlinguistic ambiguity, making visual information ineffective in generating\nappropriate translations. Recent work has constructed an ambiguous subtitles\ndataset to alleviate this problem but is still limited to the problem that\nvideos do not necessarily contribute to disambiguation. We introduce EVA\n(Extensive training set and Video-helpful evaluation set for Ambiguous\nsubtitles translation), an MMT dataset containing 852k Japanese-English (Ja-En)\nparallel subtitle pairs, 520k Chinese-English (Zh-En) parallel subtitle pairs,\nand corresponding video clips collected from movies and TV episodes. In\naddition to the extensive training set, EVA contains a video-helpful evaluation\nset in which subtitles are ambiguous, and videos are guaranteed helpful for\ndisambiguation. Furthermore, we propose SAFA, an MMT model based on the\nSelective Attention model with two novel methods: Frame attention loss and\nAmbiguity augmentation, aiming to use videos in EVA for disambiguation fully.\nExperiments on EVA show that visual information and the proposed methods can\nboost translation performance, and our model performs significantly better than\nexisting MMT models. The EVA dataset and the SAFA model are available at:\nhttps://github.com/ku-nlp/video-helpful-MMT.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yihang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1\">Shuichiro Shimizu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"General-Purpose Retrieval-Enhanced Medical Prediction Model Using Near-Infinite History. (arXiv:2310.20204v1 [cs.LG])","link":"http://arxiv.org/abs/2310.20204","description":"<p>Developing clinical prediction models (e.g., mortality prediction) based on\nelectronic health records (EHRs) typically relies on expert opinion for feature\nselection and adjusting observation window size. This burdens experts and\ncreates a bottleneck in the development process. We propose Retrieval-Enhanced\nMedical prediction model (REMed) to address such challenges. REMed can\nessentially evaluate an unlimited number of clinical events, select the\nrelevant ones, and make predictions. This approach effectively eliminates the\nneed for manual feature selection and enables an unrestricted observation\nwindow. We verified these properties through experiments on 27 clinical tasks\nand two independent cohorts from publicly available EHR datasets, where REMed\noutperformed other contemporary architectures that aim to handle as many events\nas possible. Notably, we found that the preferences of REMed align closely with\nthose of medical experts. We expect our approach to significantly expedite the\ndevelopment of EHR prediction models by minimizing clinicians' need for manual\ninvolvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shim_C/0/1/0/all/0/1\">Chaeeun Shim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bosco Seong Kyu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Im_C/0/1/0/all/0/1\">Chami Im</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Sung Yoon Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1\">Han-Gil Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does GPT-4 Pass the Turing Test?. (arXiv:2310.20216v1 [cs.AI])","link":"http://arxiv.org/abs/2310.20216","description":"<p>We evaluated GPT-4 in a public online Turing Test. The best-performing GPT-4\nprompt passed in 41% of games, outperforming baselines set by ELIZA (27%) and\nGPT-3.5 (14%), but falling short of chance and the baseline set by human\nparticipants (63%). Participants' decisions were based mainly on linguistic\nstyle (35%) and socio-emotional traits (27%), supporting the idea that\nintelligence is not sufficient to pass the Turing Test. Participants'\ndemographics, including education and familiarity with LLMs, did not predict\ndetection rate, suggesting that even those who understand systems deeply and\ninteract with them frequently may be susceptible to deception. Despite known\nlimitations as a test of intelligence, we argue that the Turing Test continues\nto be relevant as an assessment of naturalistic communication and deception. AI\nmodels with the ability to masquerade as humans could have widespread societal\nconsequences, and we analyse the effectiveness of different strategies and\ncriteria for judging humanlikeness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jones_C/0/1/0/all/0/1\">Cameron Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin Bergen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamically Updating Event Representations for Temporal Relation Classification with Multi-category Learning. (arXiv:2310.20236v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20236","description":"<p>Temporal relation classification is a pair-wise task for identifying the\nrelation of a temporal link (TLINK) between two mentions, i.e. event, time, and\ndocument creation time (DCT). It leads to two crucial limits: 1) Two TLINKs\ninvolving a common mention do not share information. 2) Existing models with\nindependent classifiers for each TLINK category (E2E, E2T, and E2D) hinder from\nusing the whole data. This paper presents an event centric model that allows to\nmanage dynamic event representations across multiple TLINKs. Our model deals\nwith three TLINK categories with multi-task learning to leverage the full size\nof data. The experimental results show that our proposal outperforms\nstate-of-the-art models and two transfer learning baselines on both the English\nand Japanese data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asahara_M/0/1/0/all/0/1\">Masayuki Asahara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kobayashi_I/0/1/0/all/0/1\">Ichiro Kobayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations. (arXiv:2310.20246v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20246","description":"<p>Existing research predominantly focuses on developing powerful language\nlearning models (LLMs) for mathematical reasoning within monolingual languages,\nwith few explorations in preserving efficacy in a multilingual context. To\nbridge this gap, this paper pioneers exploring and training powerful\nMultilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we\nconstruct the first multilingual math reasoning instruction dataset,\nMGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue\nof training data scarcity in xMR tasks. Based on the collected dataset, we\npropose different training strategies to build powerful xMR LLMs, named\nMathOctopus, notably outperform conventional open-source LLMs and exhibit\nsuperiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B\nreaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond\nremarkable results, we unearth several pivotal observations and insights from\nextensive experiments: (1) When extending the rejection sampling strategy to\nthe multilingual context, it proves effective for model performances, albeit\nlimited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)\nacross multiple languages not only significantly enhances model performance\nmultilingually but also elevates their monolingual performance. This indicates\nthat crafting multilingual corpora can be regarded as a vital strategy for\nenhancing model performance in a specific language, especially in mathematical\nreasoning tasks. For instance, MathOctopus-7B improves its counterparts that\ntrained on English from 42.2% to 50.8% on GSM8K testset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zinan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Ning Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1\">Linjun Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Ming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PsyCoT: Psychological Questionnaire as Powerful Chain-of-Thought for Personality Detection. (arXiv:2310.20256v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20256","description":"<p>Recent advances in large language models (LLMs), such as ChatGPT, have\nshowcased remarkable zero-shot performance across various NLP tasks. However,\nthe potential of LLMs in personality detection, which involves identifying an\nindividual's personality from their written texts, remains largely unexplored.\nDrawing inspiration from Psychological Questionnaires, which are carefully\ndesigned by psychologists to evaluate individual personality traits through a\nseries of targeted items, we argue that these items can be regarded as a\ncollection of well-structured chain-of-thought (CoT) processes. By\nincorporating these processes, LLMs can enhance their capabilities to make more\nreasonable inferences on personality from textual input. In light of this, we\npropose a novel personality detection method, called PsyCoT, which mimics the\nway individuals complete psychological questionnaires in a multi-turn dialogue\nmanner. In particular, we employ a LLM as an AI assistant with a specialization\nin text analysis. We prompt the assistant to rate individual items at each turn\nand leverage the historical rating results to derive a conclusive personality\npreference. Our experiments demonstrate that PsyCoT significantly improves the\nperformance and robustness of GPT-3.5 in personality detection, achieving an\naverage F1 score improvement of 4.23/10.63 points on two benchmark datasets\ncompared to the standard prompting method. Our code is available at\nhttps://github.com/TaoYang225/PsyCoT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1\">Tianyuan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bingzhe Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiaxiang Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Play Chess from Textbooks (LEAP): a Corpus for Evaluating Chess Moves based on Sentiment Analysis. (arXiv:2310.20260v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20260","description":"<p>Learning chess strategies has been investigated widely, with most studies\nfocussing on learning from previous games using search algorithms. Chess\ntextbooks encapsulate grandmaster knowledge, explain playing strategies and\nrequire a smaller search space compared to traditional chess agents. This paper\nexamines chess textbooks as a new knowledge source for enabling machines to\nlearn how to play chess -- a resource that has not been explored previously. We\ndeveloped the LEAP corpus, a first and new heterogeneous dataset with\nstructured (chess move notations and board states) and unstructured data\n(textual descriptions) collected from a chess textbook containing 1164\nsentences discussing strategic moves from 91 games. We firstly labelled the\nsentences based on their relevance, i.e., whether they are discussing a move.\nEach relevant sentence was then labelled according to its sentiment towards the\ndescribed move. We performed empirical experiments that assess the performance\nof various transformer-based baseline models for sentiment analysis. Our\nresults demonstrate the feasibility of employing transformer-based sentiment\nanalysis models for evaluating chess moves, with the best performing model\nobtaining a weighted micro F_1 score of 68%. Finally, we synthesised the LEAP\ncorpus to create a larger dataset, which can be used as a solution to the\nlimited textual resource in the chess domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alrdahi_H/0/1/0/all/0/1\">Haifa Alrdahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batista_Navarro_R/0/1/0/all/0/1\">Riza Batista-Navarro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extracting Entities of Interest from Comparative Product Reviews. (arXiv:2310.20274v1 [cs.IR])","link":"http://arxiv.org/abs/2310.20274","description":"<p>This paper presents a deep learning based approach to extract product\ncomparison information out of user reviews on various e-commerce websites. Any\ncomparative product review has three major entities of information: the names\nof the products being compared, the user opinion (predicate) and the feature or\naspect under comparison. All these informing entities are dependent on each\nother and bound by the rules of the language, in the review. We observe that\ntheir inter-dependencies can be captured well using LSTMs. We evaluate our\nsystem on existing manually labeled datasets and observe out-performance over\nthe existing Semantic Role Labeling (SRL) framework popular for this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_J/0/1/0/all/0/1\">Jatin Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Sumit Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pathak_S/0/1/0/all/0/1\">Sayan Pathak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Theory of Mind in Large Language Models: Examining Performance of 11 State-of-the-Art models vs. Children Aged 7-10 on Advanced Tests. (arXiv:2310.20320v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20320","description":"<p>To what degree should we ascribe cognitive capacities to Large Language\nModels (LLMs), such as the ability to reason about intentions and beliefs known\nas Theory of Mind (ToM)? Here we add to this emerging debate by (i) testing 11\nbase- and instruction-tuned LLMs on capabilities relevant to ToM beyond the\ndominant false-belief paradigm, including non-literal language usage and\nrecursive intentionality; (ii) using newly rewritten versions of standardized\ntests to gauge LLMs' robustness; (iii) prompting and scoring for open besides\nclosed questions; and (iv) benchmarking LLM performance against that of\nchildren aged 7-10 on the same tasks. We find that instruction-tuned LLMs from\nthe GPT family outperform other models, and often also children. Base-LLMs are\nmostly unable to solve ToM tasks, even with specialized prompting. We suggest\nthat the interlinked evolution and development of language and ToM may help\nexplain what instruction-tuning adds: rewarding cooperative communication that\ntakes into account interlocutor and context. We conclude by arguing for a\nnuanced perspective on ToM in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Duijn_M/0/1/0/all/0/1\">Max J. van Duijn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijk_B/0/1/0/all/0/1\">Bram M.A. van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouwenhoven_T/0/1/0/all/0/1\">Tom Kouwenhoven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valk_W/0/1/0/all/0/1\">Werner de Valk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco R. Spruit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putten_P/0/1/0/all/0/1\">Peter van der Putten</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FA Team at the NTCIR-17 UFO Task. (arXiv:2310.20322v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20322","description":"<p>The FA team participated in the Table Data Extraction (TDE) and Text-to-Table\nRelationship Extraction (TTRE) tasks of the NTCIR-17 Understanding of\nNon-Financial Objects in Financial Reports (UFO). This paper reports our\napproach to solving the problems and discusses the official results. We\nsuccessfully utilized various enhancement techniques based on the ELECTRA\nlanguage model to extract valuable data from tables. Our efforts resulted in an\nimpressive TDE accuracy rate of 93.43 %, positioning us in second place on the\nLeaderboard rankings. This outstanding achievement is a testament to our\nproposed approach's effectiveness. In the TTRE task, we proposed the rule-based\nmethod to extract meaningful relationships between the text and tables task and\nconfirmed the performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Okumura_Y/0/1/0/all/0/1\">Yuki Okumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujitake_M/0/1/0/all/0/1\">Masato Fujitake</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Erato: Automatizing Poetry Evaluation. (arXiv:2310.20326v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20326","description":"<p>We present Erato, a framework designed to facilitate the automated evaluation\nof poetry, including that generated by poetry generation systems. Our framework\nemploys a diverse set of features, and we offer a brief overview of Erato's\ncapabilities and its potential for expansion. Using Erato, we compare and\ncontrast human-authored poetry with automatically-generated poetry,\ndemonstrating its effectiveness in identifying key differences. Our\nimplementation code and software are freely available under the GNU GPLv3\nlicense.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agirrezabal_M/0/1/0/all/0/1\">Manex Agirrezabal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1\">Hugo Gon&#xe7;alo Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ormazabal_A/0/1/0/all/0/1\">Aitor Ormazabal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChiSCor: A Corpus of Freely Told Fantasy Stories by Dutch Children for Computational Linguistics and Cognitive Science. (arXiv:2310.20328v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20328","description":"<p>In this resource paper we release ChiSCor, a new corpus containing 619\nfantasy stories, told freely by 442 Dutch children aged 4-12. ChiSCor was\ncompiled for studying how children render character perspectives, and\nunravelling language and cognition in development, with computational tools.\nUnlike existing resources, ChiSCor's stories were produced in natural contexts,\nin line with recent calls for more ecologically valid datasets. ChiSCor hosts\ntext, audio, and annotations for character complexity and linguistic\ncomplexity. Additional metadata (e.g. education of caregivers) is available for\none third of the Dutch children. ChiSCor also includes a small set of 62\nEnglish stories. This paper details how ChiSCor was compiled and shows its\npotential for future work with three brief case studies: i) we show that the\nsyntactic complexity of stories is strikingly stable across children's ages;\nii) we extend work on Zipfian distributions in free speech and show that\nChiSCor obeys Zipf's law closely, reflecting its social context; iii) we show\nthat even though ChiSCor is relatively small, the corpus is rich enough to\ntrain informative lemma vectors that allow us to analyse children's language\nuse. We end with a reflection on the value of narrative datasets in\ncomputational linguistics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dijk_B/0/1/0/all/0/1\">Bram M.A. van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duijn_M/0/1/0/all/0/1\">Max J. van Duijn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verberne_S/0/1/0/all/0/1\">Suzan Verberne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco R. Spruit</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructCoder: Empowering Language Models for Code Editing. (arXiv:2310.20329v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20329","description":"<p>Code editing encompasses a variety of pragmatic tasks that developers deal\nwith daily. Despite its relevance and practical usefulness, automatic code\nediting remains an underexplored area in the evolution of deep learning models,\npartly due to data scarcity. In this work, we explore the use of large language\nmodels (LLMs) to edit code based on user instructions, covering a broad range\nof implicit tasks such as comment insertion, code optimization, and code\nrefactoring. To facilitate this, we introduce InstructCoder, the first dataset\ndesigned to adapt LLMs for general-purpose code editing, containing\nhighdiversity code-editing tasks. It consists of over 114,000\ninstruction-input-output triplets and covers multiple distinct code editing\nscenarios. The dataset is systematically expanded through an iterative process\nthat commences with code editing data sourced from GitHub commits as seed\ntasks. Seed and generated tasks are used subsequently to prompt ChatGPT for\nmore task data. Our experiments demonstrate that open-source LLMs fine-tuned on\nInstructCoder can edit code correctly based on users' instructions most of the\ntime, exhibiting unprecedented code-editing performance levels. Such results\nsuggest that proficient instruction-finetuning can lead to significant\namelioration in code editing abilities. The dataset and the source code are\navailable at https://github.com/qishenghu/CodeInstruct.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1\">Qisheng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kaixin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tiedong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qizhe Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Generators for a Family of Matrix Multiplication Routines with Apache TVM. (arXiv:2310.20347v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20347","description":"<p>We explore the utilization of the Apache TVM open source framework to\nautomatically generate a family of algorithms that follow the approach taken by\npopular linear algebra libraries, such as GotoBLAS2, BLIS and OpenBLAS, in\norder to obtain high-performance blocked formulations of the general matrix\nmultiplication (GEMM). % In addition, we fully automatize the generation\nprocess, by also leveraging the Apache TVM framework to derive a complete\nvariety of the processor-specific micro-kernels for GEMM. This is in contrast\nwith the convention in high performance libraries, which hand-encode a single\nmicro-kernel per architecture using Assembly code. % In global, the combination\nof our TVM-generated blocked algorithms and micro-kernels for GEMM 1)~improves\nportability, maintainability and, globally, streamlines the software life\ncycle; 2)~provides high flexibility to easily tailor and optimize the solution\nto different data types, processor architectures, and matrix operand shapes,\nyielding performance on a par (or even superior for specific matrix shapes)\nwith that of hand-tuned libraries; and 3)~features a small memory footprint.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alaejos_G/0/1/0/all/0/1\">Guillermo Alaejos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castello_A/0/1/0/all/0/1\">Adri&#xe1;n Castell&#xf3;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alonso_Jorda_P/0/1/0/all/0/1\">Pedro Alonso-Jord&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Igual_F/0/1/0/all/0/1\">Francisco D. Igual</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinez_H/0/1/0/all/0/1\">H&#xe9;ctor Mart&#xed;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quintana_Orti_E/0/1/0/all/0/1\">Enrique S. Quintana-Ort&#xed;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AMERICANO: Argument Generation with Discourse-driven Decomposition and Agent Interaction. (arXiv:2310.20352v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20352","description":"<p>Argument generation is a challenging task in natural language processing,\nwhich requires rigorous reasoning and proper content organization. Inspired by\nrecent chain-of-thought prompting that breaks down a complex task into\nintermediate steps, we propose Americano, a novel framework with agent\ninteraction for argument generation. Our approach decomposes the generation\nprocess into sequential actions grounded on argumentation theory, which first\nexecutes actions sequentially to generate argumentative discourse components,\nand then produces a final argument conditioned on the components. To further\nmimic the human writing process and improve the left-to-right generation\nparadigm of current autoregressive language models, we introduce an argument\nrefinement module which automatically evaluates and refines argument drafts\nbased on feedback received. We evaluate our framework on the task of\ncounterargument generation using a subset of Reddit/CMV dataset. The results\nshow that our method outperforms both end-to-end and chain-of-thought prompting\nmethods and can generate more coherent and persuasive arguments with diverse\nand rich contents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhe Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1\">Hou Pong Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yu Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do large language models solve verbal analogies like children do?. (arXiv:2310.20384v1 [cs.CL])","link":"http://arxiv.org/abs/2310.20384","description":"<p>Analogy-making lies at the heart of human cognition. Adults solve analogies\nsuch as \\textit{Horse belongs to stable like chicken belongs to ...?} by\nmapping relations (\\textit{kept in}) and answering \\textit{chicken coop}. In\ncontrast, children often use association, e.g., answering \\textit{egg}. This\npaper investigates whether large language models (LLMs) solve verbal analogies\nin A:B::C:? form using associations, similar to what children do. We use verbal\nanalogies extracted from an online adaptive learning environment, where 14,002\n7-12 year-olds from the Netherlands solved 622 analogies in Dutch. The six\ntested Dutch monolingual and multilingual LLMs performed around the same level\nas children, with MGPT performing worst, around the 7-year-old level, and XLM-V\nand GPT-3 the best, slightly above the 11-year-old level. However, when we\ncontrol for associative processes this picture changes and each model's\nperformance level drops 1-2 years. Further experiments demonstrate that\nassociative processes often underlie correctly solved analogies. We conclude\nthat the LLMs we tested indeed tend to solve verbal analogies by association\nwith C like children do.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stevenson_C/0/1/0/all/0/1\">Claire E. Stevenson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veen_M/0/1/0/all/0/1\">Mathilde ter Veen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choenni_R/0/1/0/all/0/1\">Rochelle Choenni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maas_H/0/1/0/all/0/1\">Han L. J. van der Maas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1\">Ekaterina Shutova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BERT WEAVER: Using WEight AVERaging to enable lifelong learning for transformer-based models in biomedical semantic search engines. (arXiv:2202.10101v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.10101","description":"<p>Recent developments in transfer learning have boosted the advancements in\nnatural language processing tasks. The performance is, however, dependent on\nhigh-quality, manually annotated training data. Especially in the biomedical\ndomain, it has been shown that one training corpus is not enough to learn\ngeneric models that are able to efficiently predict on new data. Therefore, in\norder to be used in real world applications state-of-the-art models need the\nability of lifelong learning to improve performance as soon as new data are\navailable - without the need of re-training the whole model from scratch. We\npresent WEAVER, a simple, yet efficient post-processing method that infuses old\nknowledge into the new model, thereby reducing catastrophic forgetting. We show\nthat applying WEAVER in a sequential manner results in similar word embedding\ndistributions as doing a combined training on all data at once, while being\ncomputationally more efficient. Because there is no need of data sharing, the\npresented method is also easily applicable to federated learning settings and\ncan for example be beneficial for the mining of electronic health records from\ndifferent clinics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kuhnel_L/0/1/0/all/0/1\">Lisa K&#xfc;hnel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_A/0/1/0/all/0/1\">Alexander Schulz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1\">Barbara Hammer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fluck_J/0/1/0/all/0/1\">Juliane Fluck</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Impact of Cross-Lingual Adjustment of Contextual Word Representations on Zero-Shot Transfer. (arXiv:2204.06457v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.06457","description":"<p>Large multilingual language models such as mBERT or XLM-R enable zero-shot\ncross-lingual transfer in various IR and NLP tasks. Cao et al. (2020) proposed\na data- and compute-efficient method for cross-lingual adjustment of mBERT that\nuses a small parallel corpus to make embeddings of related words across\nlanguages similar to each other. They showed it to be effective in NLI for five\nEuropean languages. In contrast we experiment with a typologically diverse set\nof languages (Spanish, Russian, Vietnamese, and Hindi) and extend their\noriginal implementations to new tasks (XSR, NER, and QA) and an additional\ntraining regime (continual learning). Our study reproduced gains in NLI for\nfour languages, showed improved NER, XSR, and cross-lingual QA results in three\nlanguages (though some cross-lingual QA gains were not statistically\nsignificant), while mono-lingual QA performance never improved and sometimes\ndegraded. Analysis of distances between contextualized embeddings of related\nand unrelated words (across languages) showed that fine-tuning leads to\n\"forgetting\" some of the cross-lingual alignment information. Based on this\nobservation, we further improved NLI performance using continual learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Efimov_P/0/1/0/all/0/1\">Pavel Efimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boytsov_L/0/1/0/all/0/1\">Leonid Boytsov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arslanova_E/0/1/0/all/0/1\">Elena Arslanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Braslavski_P/0/1/0/all/0/1\">Pavel Braslavski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Born for Auto-Tagging: Faster and better with new objective functions. (arXiv:2206.07264v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.07264","description":"<p>Keyword extraction is a task of text mining. It is applied to increase search\nvolume in SEO and ads. Implemented in auto-tagging, it makes tagging on a mass\nscale of online articles and photos efficiently and accurately. BAT is invented\nfor auto-tagging which served as awoo's AI marketing platform (AMP). awoo AMP\nnot only provides service as a customized recommender system but also increases\nthe converting rate in E-commerce. The strength of BAT converges faster and\nbetter than other SOTA models, as its 4-layer structure achieves the best F\nscores at 50 epochs. In other words, it performs better than other models which\nrequire deeper layers at 100 epochs. To generate rich and clean tags, awoo\ncreates new objective functions to maintain similar ${\\rm F_1}$ scores with\ncross-entropy while enhancing ${\\rm F_2}$ scores simultaneously. To assure the\neven better performance of F scores awoo revamps the learning rate strategy\nproposed by Transformer \\cite{Transformer} to increase ${\\rm F_1}$ and ${\\rm\nF_2}$ scores at the same time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chiung-ju Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shieh_H/0/1/0/all/0/1\">Huang-Ting Shieh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language with Vision: a Study on Grounded Word and Sentence Embeddings. (arXiv:2206.08823v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.08823","description":"<p>Grounding language in vision is an active field of research seeking to\nconstruct cognitively plausible word and sentence representations by\nincorporating perceptual knowledge from vision into text-based representations.\nDespite many attempts at language grounding, achieving an optimal equilibrium\nbetween textual representations of the language and our embodied experiences\nremains an open field. Some common concerns are the following. Is visual\ngrounding advantageous for abstract words, or is its effectiveness restricted\nto concrete words? What is the optimal way of bridging the gap between text and\nvision? To what extent is perceptual knowledge from images advantageous for\nacquiring high-quality embeddings? Leveraging the current advances in machine\nlearning and natural language processing, the present study addresses these\nquestions by proposing a simple yet very effective computational grounding\nmodel for pre-trained word embeddings. Our model effectively balances the\ninterplay between language and vision by aligning textual embeddings with\nvisual information while simultaneously preserving the distributional\nstatistics that characterize word usage in text corpora. By applying a learned\nalignment, we are able to indirectly ground unseen words including abstract\nwords. A series of evaluations on a range of behavioural datasets shows that\nvisual grounding is beneficial not only for concrete words but also for\nabstract words, lending support to the indirect theory of abstract concepts.\nMoreover, our approach offers advantages for contextualized embeddings, such as\nthose generated by BERT, but only when trained on corpora of modest,\ncognitively plausible sizes. Code and grounded embeddings for English are\navailable at https://github.com/Hazel1994/Visually_Grounded_Word_Embeddings_2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahmohammadi_H/0/1/0/all/0/1\">Hassan Shahmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heitmeier_M/0/1/0/all/0/1\">Maria Heitmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafaei_Bajestan_E/0/1/0/all/0/1\">Elnaz Shafaei-Bajestan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lensch_H/0/1/0/all/0/1\">Hendrik P. A. Lensch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_H/0/1/0/all/0/1\">Harald Baayen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How direct is the link between words and images?. (arXiv:2206.15381v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.15381","description":"<p>Current word embedding models despite their success, still suffer from their\nlack of grounding in the real world. In this line of research, Gunther et al.\n2022 proposed a behavioral experiment to investigate the relationship between\nwords and images. In their setup, participants were presented with a target\nnoun and a pair of images, one chosen by their model and another chosen\nrandomly. Participants were asked to select the image that best matched the\ntarget noun. In most cases, participants preferred the image selected by the\nmodel. Gunther et al., therefore, concluded the possibility of a direct link\nbetween words and embodied experience. We took their experiment as a point of\ndeparture and addressed the following questions. 1. Apart from utilizing\nvisually embodied simulation of given images, what other strategies might\nsubjects have used to solve this task? To what extent does this setup rely on\nvisual information from images? Can it be solved using purely textual\nrepresentations? 2. Do current visually grounded embeddings explain subjects'\nselection behavior better than textual embeddings? 3. Does visual grounding\nimprove the semantic representations of both concrete and abstract words? To\naddress these questions, we designed novel experiments by using pre-trained\ntextual and visually grounded word embeddings. Our experiments reveal that\nsubjects' selection behavior is explained to a large extent based on purely\ntext-based embeddings and word-based similarities, suggesting a minor\ninvolvement of active embodied experiences. Visually grounded embeddings\noffered modest advantages over textual embeddings only in certain cases. These\nfindings indicate that the experiment by Gunther et al. may not be well suited\nfor tapping into the perceptual experience of participants, and therefore the\nextent to which it measures visually grounded knowledge is unclear.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahmohammadi_H/0/1/0/all/0/1\">Hassan Shahmohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heitmeier_M/0/1/0/all/0/1\">Maria Heitmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafaei_Bajestan_E/0/1/0/all/0/1\">Elnaz Shafaei-Bajestan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lensch_H/0/1/0/all/0/1\">Hendrik P. A. Lensch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_H/0/1/0/all/0/1\">Harald Baayen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EffEval: A Comprehensive Evaluation of Efficiency for MT Evaluation Metrics. (arXiv:2209.09593v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.09593","description":"<p>Efficiency is a key property to foster inclusiveness and reduce environmental\ncosts, especially in an era of LLMs. In this work, we provide a comprehensive\nevaluation of efficiency for MT evaluation metrics. Our approach involves\nreplacing computation-intensive transformers with lighter alternatives and\nemploying linear and quadratic approximations for alignment algorithms on top\nof LLM representations. We evaluate six (reference-free and reference-based)\nmetrics across three MT datasets and examine 16 lightweight transformers. In\naddition, we look into the training efficiency of metrics like COMET by\nutilizing adapters. Our results indicate that (a) TinyBERT provides the optimal\nbalance between quality and efficiency, (b) CPU speed-ups are more substantial\nthan those on GPU; (c) WMD approximations yield no efficiency gains while\nreducing quality and (d) adapters enhance training efficiency (regarding\nbackward pass speed and memory requirements) as well as, in some cases, metric\nquality. These findings can help to strike a balance between evaluation speed\nand quality, which is essential for effective NLG systems. Furthermore, our\nresearch contributes to the ongoing efforts to optimize NLG evaluation metrics\nwith minimal impact on performance. To our knowledge, ours is the most\ncomprehensive analysis of different aspects of efficiency for MT metrics\nconducted so far.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Larionov_D/0/1/0/all/0/1\">Daniil Larionov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grunwald_J/0/1/0/all/0/1\">Jens Gr&#xfc;nwald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leiter_C/0/1/0/all/0/1\">Christoph Leiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conceptor-Aided Debiasing of Large Language Models. (arXiv:2211.11087v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11087","description":"<p>Pre-trained large language models (LLMs) reflect the inherent social biases\nof their training corpus. Many methods have been proposed to mitigate this\nissue, but they often fail to debias or they sacrifice model accuracy. We use\nconceptors--a soft projection method--to identify and remove the bias subspace\nin LLMs such as BERT and GPT. We propose two methods of applying conceptors (1)\nbias subspace projection by post-processing by the conceptor NOT operation; and\n(2) a new architecture, conceptor-intervened BERT (CI-BERT), which explicitly\nincorporates the conceptor projection into all layers during training. We find\nthat conceptor post-processing achieves state-of-the-art (SoTA) debiasing\nresults while maintaining LLMs' performance on the GLUE benchmark. Further, it\nis robust in various scenarios and can mitigate intersectional bias efficiently\nby its AND operation on the existing bias subspaces. Although CI-BERT's\ntraining takes all layers' bias into account and can beat its post-processing\ncounterpart in bias mitigation, CI-BERT reduces the language model accuracy. We\nalso show the importance of carefully constructing the bias subspace. The best\nresults are obtained by removing outliers from the list of biased words,\ncombining them (via the OR operation), and computing their embeddings using the\nsentences from a cleaner corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yifei_L/0/1/0/all/0/1\">Li S. Yifei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1\">Lyle Ungar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1\">Jo&#xe3;o Sedoc</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Vision-free Baseline for Multimodal Grammar Induction. (arXiv:2212.10564v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10564","description":"<p>Past work has shown that paired vision-language signals substantially improve\ngrammar induction in multimodal datasets such as MSCOCO. We investigate whether\nadvancements in large language models (LLMs) that are only trained with text\ncould provide strong assistance for grammar induction in multimodal settings.\nWe find that our text-only approach, an LLM-based C-PCFG (LC-PCFG), outperforms\nprevious multi-modal methods, and achieves state-of-the-art grammar induction\nperformance for various multimodal datasets. Compared to image-aided grammar\ninduction, LC-PCFG outperforms the prior state-of-the-art by 7.9 Corpus-F1\npoints, with an 85% reduction in parameter count and 1.7x faster training\nspeed. Across three video-assisted grammar induction benchmarks, LC-PCFG\noutperforms prior state-of-the-art by up to 7.7 Corpus-F1, with 8.8x faster\ntraining. These results shed light on the notion that text-only language models\nmight include visually grounded cues that aid in grammar induction in\nmultimodal contexts. Moreover, our results emphasize the importance of\nestablishing a robust vision-free baseline when evaluating the benefit of\nmultimodal approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corona_R/0/1/0/all/0/1\">Rodolfo Corona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1\">Karttikeya Mangalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Catherine Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flaherty_D/0/1/0/all/0/1\">Daniel Flaherty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1\">Serge Belongie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning List-Level Domain-Invariant Representations for Ranking. (arXiv:2212.10764v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2212.10764","description":"<p>Domain adaptation aims to transfer the knowledge learned on (data-rich)\nsource domains to (low-resource) target domains, and a popular method is\ninvariant representation learning, which matches and aligns the data\ndistributions on the feature space. Although this method is studied extensively\nand applied on classification and regression problems, its adoption on ranking\nproblems is sporadic, and the few existing implementations lack theoretical\njustifications. This paper revisits invariant representation learning for\nranking. Upon reviewing prior work, we found that they implement what we call\nitem-level alignment, which aligns the distributions of the items being ranked\nfrom all lists in aggregate but ignores their list structure. However, the list\nstructure should be leveraged, because it is intrinsic to ranking problems\nwhere the data and the metrics are defined and computed on lists, not the items\nby themselves. To close this discrepancy, we propose list-level alignment --\nlearning domain-invariant representations at the higher level of lists. The\nbenefits are twofold: it leads to the first domain adaptation generalization\nbound for ranking, in turn providing theoretical support for the proposed\nmethod, and it achieves better empirical transfer performance for unsupervised\ndomain adaptation on ranking tasks, including passage reranking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xian_R/0/1/0/all/0/1\">Ruicheng Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_H/0/1/0/all/0/1\">Honglei Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Ji Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_K/0/1/0/all/0/1\">Kai Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Han Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuanhui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GLEN: General-Purpose Event Detection for Thousands of Types. (arXiv:2303.09093v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09093","description":"<p>The progress of event extraction research has been hindered by the absence of\nwide-coverage, large-scale datasets. To make event extraction systems more\naccessible, we build a general-purpose event detection dataset GLEN, which\ncovers 205K event mentions with 3,465 different types, making it more than 20x\nlarger in ontology than today's largest event dataset. GLEN is created by\nutilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes and\nPropBank rolesets. This enables us to use the abundant existing annotation for\nPropBank as distant supervision. In addition, we also propose a new multi-stage\nevent detection model CEDAR specifically designed to handle the large ontology\nsize in GLEN. We show that our model exhibits superior performance compared to\na range of baselines including InstructGPT. Finally, we perform error analysis\nand show that label noise is still the largest challenge for improving\nperformance for this new dataset. Our dataset, code, and models are released at\n\\url{https://github.com/ZQS1943/GLEN}.}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Q/0/1/0/all/0/1\">Qiusi Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conger_K/0/1/0/all/0/1\">Kathryn Conger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1\">Martha Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning. (arXiv:2304.01295v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01295","description":"<p>Cross-lingual transfer of language models trained on high-resource languages\nlike English has been widely studied for many NLP tasks, but focus on\nconversational tasks has been rather limited. This is partly due to the high\ncost of obtaining non-English conversational data, which results in limited\ncoverage. In this work, we introduce XSGD for cross-lingual alignment\npretraining, a parallel and large-scale multilingual conversation dataset that\nwe created by translating the English-only Schema-Guided Dialogue (SGD) dataset\n(Rastogi et al., 2020) into 105 other languages. XSGD contains approximately\n330k utterances per language. To facilitate aligned cross-lingual\nrepresentations, we develop an efficient prompt-tuning-based method for\nlearning alignment prompts. We also investigate two different classifiers:\nNLI-based and vanilla classifiers, and test cross-lingual capability enabled by\nthe aligned prompts. We evaluate our model's cross-lingual generalization\ncapabilities on two conversation tasks: slot-filling and intent classification.\nOur results demonstrate the strong and efficient modeling ability of NLI-based\nclassifiers and the large cross-lingual transfer improvements achieved by our\naligned prompts, particularly in few-shot settings. In addition, we highlight\nthe nice results of our approach compared to LLMs such as text-davinci-003 and\nChatGPT in both zero-shot and few-shot settings. While LLMs exhibit impressive\nperformance in English, their cross-lingual capabilities in other languages,\nparticularly low-resource languages, are limited.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_L/0/1/0/all/0/1\">Lifu Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_J/0/1/0/all/0/1\">Jin Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Pareto Front of Multilingual Neural Machine Translation. (arXiv:2304.03216v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03216","description":"<p>In this work, we study how the performance of a given direction changes with\nits sampling ratio in Multilingual Neural Machine Translation (MNMT). By\ntraining over 200 multilingual models with various model sizes, data sizes, and\nlanguage directions, we find it interesting that the performance of certain\ntranslation direction does not always improve with the increase of its weight\nin the multi-task optimization objective. Accordingly, scalarization method\nleads to a multitask trade-off front that deviates from the traditional Pareto\nfront when there exists data imbalance in the training corpus, which poses a\ngreat challenge to improve the overall performance of all directions. Based on\nour observations, we propose the Double Power Law to predict the unique\nperformance trade-off front in MNMT, which is robust across various languages,\ndata adequacy, and the number of tasks. Finally, we formulate the sample ratio\nselection problem in MNMT as an optimization problem based on the Double Power\nLaw. In our experiments, it achieves better performance than temperature\nsearching and gradient manipulation methods with only 1/5 to 1/2 of the total\ntraining budget. We release the code at\nhttps://github.com/pkunlp-icler/ParetoMNMT for reproduction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Retrieval to Generation: Efficient and Effective Entity Set Expansion. (arXiv:2304.03531v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03531","description":"<p>Entity Set Expansion (ESE) is a critical task aiming at expanding entities of\nthe target semantic class described by seed entities. Most existing ESE methods\nare retrieval-based frameworks that need to extract contextual features of\nentities and calculate the similarity between seed entities and candidate\nentities. To achieve the two purposes, they iteratively traverse the corpus and\nthe entity vocabulary, resulting in poor efficiency and scalability.\nExperimental results indicate that the time consumed by the retrieval-based ESE\nmethods increases linearly with entity vocabulary and corpus size. In this\npaper, we firstly propose Generative Entity Set Expansion (GenExpan) framework,\nwhich utilizes a generative pre-trained auto-regressive language model to\naccomplish ESE task. Specifically, a prefix tree is employed to guarantee the\nvalidity of entity generation, and automatically generated class names are\nadopted to guide the model to generate target entities. Moreover, we propose\nKnowledge Calibration and Generative Ranking to further bridge the gap between\ngeneric knowledge of the language model and the goal of ESE task. For\nefficiency, expansion time consumed by GenExpan is independent of entity\nvocabulary and corpus size, and GenExpan achieves an average 600% speedup\ncompared to strong baselines. For expansion effectiveness, our framework\noutperforms previous state-of-the-art ESE methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shulin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shirong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Ying Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenAssistant Conversations -- Democratizing Large Language Model Alignment. (arXiv:2304.07327v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.07327","description":"<p>Aligning large language models (LLMs) with human preferences has proven to\ndrastically improve usability and has driven rapid adoption as demonstrated by\nChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and\nreinforcement learning from human feedback (RLHF) greatly reduce the required\nskill and domain knowledge to effectively harness the capabilities of LLMs,\nincreasing their accessibility and utility across various domains. However,\nstate-of-the-art alignment techniques like RLHF rely on high-quality human\nfeedback data, which is expensive to create and often remains proprietary. In\nan effort to democratize research on large-scale alignment, we release\nOpenAssistant Conversations, a human-generated, human-annotated assistant-style\nconversation corpus consisting of 161,443 messages in 35 different languages,\nannotated with 461,292 quality ratings, resulting in over 10,000 complete and\nfully annotated conversation trees. The corpus is a product of a worldwide\ncrowd-sourcing effort involving over 13,500 volunteers. Models trained on\nOpenAssistant Conversations show consistent improvements on standard benchmarks\nover respective base models. We release our code and data under a fully\npermissive licence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kopf_A/0/1/0/all/0/1\">Andreas K&#xf6;pf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kilcher_Y/0/1/0/all/0/1\">Yannic Kilcher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutte_D/0/1/0/all/0/1\">Dimitri von R&#xfc;tte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anagnostidis_S/0/1/0/all/0/1\">Sotiris Anagnostidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_Z/0/1/0/all/0/1\">Zhi-Rui Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_K/0/1/0/all/0/1\">Keith Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barhoum_A/0/1/0/all/0/1\">Abdullah Barhoum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duc_N/0/1/0/all/0/1\">Nguyen Minh Duc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanley_O/0/1/0/all/0/1\">Oliver Stanley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagyfi_R/0/1/0/all/0/1\">Rich&#xe1;rd Nagyfi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ES_S/0/1/0/all/0/1\">Shahul ES</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suri_S/0/1/0/all/0/1\">Sameer Suri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glushkov_D/0/1/0/all/0/1\">David Glushkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dantuluri_A/0/1/0/all/0/1\">Arnav Dantuluri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maguire_A/0/1/0/all/0/1\">Andrew Maguire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuhmann_C/0/1/0/all/0/1\">Christoph Schuhmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Huu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattick_A/0/1/0/all/0/1\">Alexander Mattick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlling keywords and their positions in text generation. (arXiv:2304.09516v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09516","description":"<p>One of the challenges in text generation is to control text generation as\nintended by the user. Previous studies proposed specifying the keywords that\nshould be included in the generated text. However, this approach is\ninsufficient to generate text that reflect the user's intent. For example,\nplacing an important keyword at the beginning of the text would help attract\nthe reader's attention; however, existing methods do not enable such flexible\ncontrol. In this paper, we tackle a novel task of controlling not only keywords\nbut also the position of each keyword in the text generation. To this end, we\npropose a task-independent method that uses special tokens to control the\nrelative position of keywords. Experimental results on summarization and story\ngeneration tasks show that the proposed method can control keywords and their\npositions. The experimental results also demonstrate that controlling the\nkeyword positions can generate summary texts that are closer to the user's\nintent than baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sasazawa_Y/0/1/0/all/0/1\">Yuichi Sasazawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morishita_T/0/1/0/all/0/1\">Terufumi Morishita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozaki_H/0/1/0/all/0/1\">Hiroaki Ozaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imaichi_O/0/1/0/all/0/1\">Osamu Imaichi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogawa_Y/0/1/0/all/0/1\">Yasuhiro Sogawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models. (arXiv:2304.09842v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09842","description":"<p>Large language models (LLMs) have achieved remarkable progress in solving\nvarious natural language processing tasks due to emergent reasoning abilities.\nHowever, LLMs have inherent limitations as they are incapable of accessing\nup-to-date information (stored on the Web or in task-specific knowledge bases),\nusing external tools, and performing precise mathematical and logical\nreasoning. In this paper, we present Chameleon, an AI system that mitigates\nthese limitations by augmenting LLMs with plug-and-play modules for\ncompositional reasoning. Chameleon synthesizes programs by composing various\ntools (e.g., LLMs, off-the-shelf vision models, web search engines, Python\nfunctions, and heuristic-based modules) for accomplishing complex reasoning\ntasks. At the heart of Chameleon is an LLM-based planner that assembles a\nsequence of tools to execute to generate the final response. We showcase the\neffectiveness of Chameleon on two multi-modal knowledge-intensive reasoning\ntasks: ScienceQA and TabMWP. Chameleon, powered by GPT-4, achieves an 86.54%\noverall accuracy on ScienceQA, improving the best published few-shot result by\n11.37%. On TabMWP, GPT-4-powered Chameleon improves the accuracy by 17.0%,\nlifting the state of the art to 98.78%. Our analysis also shows that the\nGPT-4-powered planner exhibits more consistent and rational tool selection via\ninferring potential constraints from instructions, compared to a\nChatGPT-powered planner. The project is available at\nhttps://chameleon-llm.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Ying Nian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Reason and Memorize with Self-Notes. (arXiv:2305.00833v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.00833","description":"<p>Large language models have been shown to struggle with multi-step reasoning,\nand do not retain previous reasoning steps for future use. We propose a simple\nmethod for solving both of these problems by allowing the model to take\nSelf-Notes. Unlike recent chain-of-thought or scratchpad approaches, the model\ncan deviate from the input context at any time to explicitly think and write\ndown its thoughts. This allows the model to perform reasoning on the fly as it\nreads the context and even integrate previous reasoning steps, thus enhancing\nits memory with useful information and enabling multi-step reasoning.\nExperiments across a wide variety of tasks demonstrate that our method can\noutperform chain-of-thought and scratchpad methods by taking Self-Notes that\ninterleave the input text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lanchantin_J/0/1/0/all/0/1\">Jack Lanchantin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toshniwal_S/0/1/0/all/0/1\">Shubham Toshniwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1\">Arthur Szlam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation. (arXiv:2305.01210v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.01210","description":"<p>Program synthesis has been long studied with recent approaches focused on\ndirectly using the power of Large Language Models (LLMs) to generate code.\nProgramming benchmarks, with curated synthesis problems and test-cases, are\nused to measure the performance of various LLMs on code synthesis. However,\nthese test-cases can be limited in both quantity and quality for fully\nassessing the functional correctness of the generated code. Such limitation in\nthe existing benchmarks begs the following question: In the era of LLMs, is the\ncode generated really correct? To answer this, we propose EvalPlus -- a code\nsynthesis evaluation framework to rigorously benchmark the functional\ncorrectness of LLM-synthesized code. EvalPlus augments a given evaluation\ndataset with large amounts of test-cases newly produced by an automatic test\ninput generator, powered by both LLM- and mutation-based strategies. While\nEvalPlus is general, we extend the test-cases of the popular HumanEval\nbenchmark by 80x to build HumanEval+. Our extensive evaluation across 26\npopular LLMs (e.g., GPT-4 and ChatGPT) demonstrates that HumanEval+ is able to\ncatch significant amounts of previously undetected wrong code synthesized by\nLLMs, reducing the pass@k by up-to 19.3-28.9%. We also surprisingly found that\ntest insufficiency can lead to mis-ranking. For example, both\nWizardCoder-CodeLlama and Phind-CodeLlama now outperform ChatGPT on HumanEval+,\nwhile none of them could on HumanEval. Our work not only indicates that prior\npopular code synthesis evaluation results do not accurately reflect the true\nperformance of LLMs for code synthesis, but also opens up a new direction to\nimprove such programming benchmarks through automated testing. We have\nopen-sourced our tools, enhanced datasets as well as all LLM-generated code at\nhttps://github.com/evalplus/evalplus to facilitate and accelerate future\nLLM-for-code research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiawei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1\">Chunqiu Steven Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingming Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unlimiformer: Long-Range Transformers with Unlimited Length Input. (arXiv:2305.01625v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01625","description":"<p>Since the proposal of transformers, these models have been limited to bounded\ninput lengths, because of their need to attend to every token in the input. In\nthis work, we propose Unlimiformer: a general approach that wraps any existing\npretrained encoder-decoder transformer, and offloads the cross-attention\ncomputation to a single k-nearest-neighbor (kNN) index, while the returned kNN\ndistances are the attention dot-product scores. This kNN index can be kept on\neither the GPU or CPU memory and queried in sub-linear time; this way, we can\nindex practically unlimited input sequences, while every attention head in\nevery decoder layer retrieves its top-k keys, instead of attending to every\nkey. We evaluate Unlimiformer on several long-document and book-summarization\nbenchmarks, showing that it can process even 500k token-long inputs from the\nBookSum dataset, without any input truncation at test time. We demonstrate that\nUnlimiformer improves pretrained models such as BART and Longformer by\nextending them to unlimited inputs without additional learned weights and\nwithout modifying their code. We make our code and models publicly available at\nhttps://github.com/abertsch72/unlimiformer .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bertsch_A/0/1/0/all/0/1\">Amanda Bertsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alon_U/0/1/0/all/0/1\">Uri Alon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gormley_M/0/1/0/all/0/1\">Matthew R. Gormley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive loose optimization for robust question answering. (arXiv:2305.03971v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03971","description":"<p>Question answering methods are well-known for leveraging data bias, such as\nthe language prior in visual question answering and the position bias in\nmachine reading comprehension (extractive question answering). Current\ndebiasing methods often come at the cost of significant in-distribution\nperformance to achieve favorable out-of-distribution generalizability, while\nnon-debiasing methods sacrifice a considerable amount of out-of-distribution\nperformance in order to obtain high in-distribution performance. Therefore, it\nis challenging for them to deal with the complicated changing real-world\nsituations. In this paper, we propose a simple yet effective novel loss\nfunction with adaptive loose optimization, which seeks to make the best of both\nworlds for question answering. Our main technical contribution is to reduce the\nloss adaptively according to the ratio between the previous and current\noptimization state on mini-batch training data. This loose optimization can be\nused to prevent non-debiasing methods from overlearning data bias while\nenabling debiasing methods to maintain slight bias learning. Experiments on the\nvisual question answering datasets, including VQA v2, VQA-CP v1, VQA-CP v2,\nGQA-OOD, and the extractive question answering dataset SQuAD demonstrate that\nour approach enables QA methods to obtain state-of-the-art in- and\nout-of-distribution performance in most cases. The source code has been\nreleased publicly in \\url{https://github.com/reml-group/ALO}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jie Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pinghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zewei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Dechen Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Min Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Ting Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings. (arXiv:2305.11554v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11554","description":"<p>Augmenting large language models (LLMs) with external tools has emerged as a\npromising approach to solving complex problems. However, traditional methods,\nwhich finetune LLMs with tool demonstration data, can be both costly and\nrestricted to a predefined set of tools. Recent in-context learning paradigm\nalleviates these issues, but the limited context length only allows for a few\nshots of demonstrations, leading to suboptimal understandings of the tools.\nMoreover, when there are numerous tools to choose from, in-context learning\ncould completely fail to work. In this paper, we propose an alternative\napproach, $\\textbf{ToolkenGPT}$, which combines the benefits of both sides. Our\napproach represents each $\\underline{tool}$ as a to$\\underline{ken}$\n($\\textit{toolken}$) and learns an embedding for it, enabling tool calls in the\nsame way as generating a regular word token. Once a toolken is triggered, the\nLLM is prompted to complete arguments for the tool to execute. ToolkenGPT\noffers the flexibility to plug in an arbitrary number of tools by expanding the\nset of toolkens on the fly. In addition, it improves tool use by allowing\nextensive demonstration data for learning the toolken embeddings. In diverse\ndomains, including numerical reasoning, knowledge-based question answering, and\nembodied plan generation, our approach effectively augments LLMs with tools and\nsubstantially outperforms various latest baselines. ToolkenGPT demonstrates the\npromising ability to use relevant tools from a large tool set in complex\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_S/0/1/0/all/0/1\">Shibo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning. (arXiv:2305.13971v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13971","description":"<p>Despite their impressive performance, large language models (LMs) still\nstruggle with reliably generating complex output structures when not finetuned\nto follow the required output format exactly. To address this issue,\ngrammar-constrained decoding (GCD) can be used to control the generation of\nLMs, guaranteeing that the output follows a given structure. Most existing GCD\nmethods are, however, limited to specific tasks, such as parsing or code\ngeneration. In this work, we demonstrate that formal grammars can describe the\noutput space for a much wider range of tasks and argue that GCD can serve as a\nunified framework for structured NLP tasks in general. For increased\nflexibility, we introduce input-dependent grammars, which allow the grammar to\ndepend on the input and thus enable the generation of different output\nstructures for different inputs. We then empirically demonstrate the power and\nflexibility of GCD-enhanced LMs on (1) information extraction, (2) entity\ndisambiguation, and (3) constituency parsing. Our results indicate that\ngrammar-constrained LMs substantially outperform unconstrained LMs or even beat\ntask-specific finetuned models. Grammar constraints thus hold great promise for\nharnessing off-the-shelf LMs for a wide range of structured NLP tasks,\nespecially where training data is scarce or finetuning is expensive. Code and\ndata: https://github.com/epfl-dlab/GCD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Saibo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josifoski_M/0/1/0/all/0/1\">Martin Josifoski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Counterfactual Augmentation for Multimodal Learning Under Presentation Bias. (arXiv:2305.14083v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.14083","description":"<p>In real-world machine learning systems, labels are often derived from user\nbehaviors that the system wishes to encourage. Over time, new models must be\ntrained as new training examples and features become available. However,\nfeedback loops between users and models can bias future user behavior, inducing\na presentation bias in the labels that compromises the ability to train new\nmodels. In this paper, we propose counterfactual augmentation, a novel causal\nmethod for correcting presentation bias using generated counterfactual labels.\nOur empirical evaluations demonstrate that counterfactual augmentation yields\nbetter downstream performance compared to both uncorrected models and existing\nbias-correction methods. Model analyses further indicate that the generated\ncounterfactuals align closely with true counterfactuals in an oracle setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_V/0/1/0/all/0/1\">Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitriadis_D/0/1/0/all/0/1\">Dimitrios Dimitriadis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Srinagesh Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training Language Models for Comparative Reasoning. (arXiv:2305.14457v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14457","description":"<p>Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mengxia Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enabling Large Language Models to Generate Text with Citations. (arXiv:2305.14627v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14627","description":"<p>Large language models (LLMs) have emerged as a widely-used tool for\ninformation seeking, but their generated outputs are prone to hallucination. In\nthis work, our aim is to allow LLMs to generate text with citations, improving\ntheir factual correctness and verifiability. Existing work mainly relies on\ncommercial search engines and human evaluation, making it challenging to\nreproduce and compare different modeling approaches. We propose ALCE, the first\nbenchmark for Automatic LLMs' Citation Evaluation. ALCE collects a diverse set\nof questions and retrieval corpora and requires building end-to-end systems to\nretrieve supporting evidence and generate answers with citations. We develop\nautomatic metrics along three dimensions -- fluency, correctness, and citation\nquality -- and demonstrate their strong correlation with human judgements. Our\nexperiments with state-of-the-art LLMs and novel prompting strategies show that\ncurrent systems have considerable room for improvement -- For example, on the\nELI5 dataset, even the best models lack complete citation support 50% of the\ntime. Our analyses further highlight promising future directions, including\ndeveloping better retrievers, advancing long-context LLMs, and improving the\nability to synthesize information from multiple sources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yen_H/0/1/0/all/0/1\">Howard Yen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jiatong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Reliable Misinformation Mitigation: Generalization, Uncertainty, and GPT-4. (arXiv:2305.14928v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14928","description":"<p>Misinformation poses a critical societal challenge, and current approaches\nhave yet to produce an effective solution. We propose focusing on\ngeneralization, uncertainty, and how to leverage recent large language models,\nin order to create more practical tools to evaluate information veracity in\ncontexts where perfect classification is impossible. We first demonstrate that\nGPT-4 can outperform prior methods in multiple settings and languages. Next, we\nexplore generalization, revealing that GPT-4 and RoBERTa-large exhibit\ndifferences in failure modes. Third, we propose techniques to handle\nuncertainty that can detect impossible examples and strongly improve outcomes.\nWe also discuss results on other language models, temperature, prompting,\nversioning, explainability, and web retrieval, each one providing practical\ninsights and directions for future research. Finally, we publish the LIAR-New\ndataset with novel paired English and French misinformation data and\nPossibility labels that indicate if there is sufficient context for veracity\nevaluation. Overall, this research lays the groundwork for future tools that\ncan drive real-world progress to combat misinformation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pelrine_K/0/1/0/all/0/1\">Kellin Pelrine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imouza_A/0/1/0/all/0/1\">Anne Imouza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thibault_C/0/1/0/all/0/1\">Camille Thibault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reksoprodjo_M/0/1/0/all/0/1\">Meilina Reksoprodjo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Caleb Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christoph_J/0/1/0/all/0/1\">Joel Christoph</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Godbout_J/0/1/0/all/0/1\">Jean-Fran&#xe7;ois Godbout</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rabbany_R/0/1/0/all/0/1\">Reihaneh Rabbany</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Predictable Are Large Language Model Capabilities? A Case Study on BIG-bench. (arXiv:2305.14947v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14947","description":"<p>We investigate the predictability of large language model (LLM) capabilities:\ngiven records of past experiments using different model families, numbers of\nparameters, tasks, and numbers of in-context examples, can we accurately\npredict LLM performance on new experiment configurations? Answering this\nquestion has practical implications for LLM users (e.g., deciding which models\nto try), developers (e.g., prioritizing evaluation on representative tasks),\nand the research community (e.g., identifying hard-to-predict capabilities that\nwarrant further investigation).\n</p>\n<p>We study the performance prediction problem on experiment records from\nBIG-bench. On a random train-test split, an MLP-based predictor achieves an\n$R^2$ score greater than 95%, indicating the presence of learnable patterns\nwithin the experiment records. We then formulate the problem of searching for\n\"small-bench,\" an informative subset of BIG-bench tasks from which the\nperformance on the full set can be maximally recovered. We find a subset as\ninformative as BIG-bench Hard for evaluating new model families, while being\n$3\\times$ smaller. Additionally, we find competitive subsets by clustering task\nrepresentations learned by our MLP-based predictor and selecting tasks close to\ncluster centroids, highlighting the importance of task diversity in\nconstructing \"small-bench.\"\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qinyuan Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1\">Harvey Yiyun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Table-to-Text Generation Capabilities of LLMs in Real-World Information Seeking Scenarios. (arXiv:2305.14987v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14987","description":"<p>Tabular data is prevalent across various industries, necessitating\nsignificant time and effort for users to understand and manipulate for their\ninformation-seeking purposes. The advancements in large language models (LLMs)\nhave shown enormous potential to improve user efficiency. However, the adoption\nof LLMs in real-world applications for table information seeking remains\nunderexplored. In this paper, we investigate the table-to-text capabilities of\ndifferent LLMs using four datasets within two real-world information seeking\nscenarios. These include the LogicNLG and our newly-constructed LoTNLG datasets\nfor data insight generation, along with the FeTaQA and our newly-constructed\nF2WTQ datasets for query-based generation. We structure our investigation\naround three research questions, evaluating the performance of LLMs in\ntable-to-text generation, automated evaluation, and feedback generation,\nrespectively. Experimental results indicate that the current high-performing\nLLM, specifically GPT-4, can effectively serve as a table-to-text generator,\nevaluator, and feedback generator, facilitating users' information seeking\npurposes in real-world scenarios. However, a significant performance gap still\nexists between other open-sourced LLMs (e.g., Tulu and LLaMA-2) and GPT-4\nmodels. Our data and code are publicly available at\nhttps://github.com/yale-nlp/LLM-T2T.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yilun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haowei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Shengyun Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nan_L/0/1/0/all/0/1\">Linyong Nan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Diffusion Models Vision-And-Language Reasoners?. (arXiv:2305.16397v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.16397","description":"<p>Text-conditioned image generation models have recently shown immense\nqualitative success using denoising diffusion processes. However, unlike\ndiscriminative vision-and-language models, it is a non-trivial task to subject\nthese diffusion-based generative models to automatic fine-grained quantitative\nevaluation of high-level phenomena such as compositionality. Towards this goal,\nwe perform two innovations. First, we transform diffusion-based models (in our\ncase, Stable Diffusion) for any image-text matching (ITM) task using a novel\nmethod called DiffusionITM. Second, we introduce the Generative-Discriminative\nEvaluation Benchmark (GDBench) benchmark with 7 complex vision-and-language\ntasks, bias evaluation and detailed analysis. We find that Stable Diffusion +\nDiffusionITM is competitive on many tasks and outperforms CLIP on compositional\ntasks like like CLEVR and Winoground. We further boost its compositional\nperformance with a transfer setup by fine-tuning on MS-COCO while retaining\ngenerative capabilities. We also measure the stereotypical bias in diffusion\nmodels, and find that Stable Diffusion 2.1 is, for the most part, less biased\nthan Stable Diffusion 1.5. Overall, our results point in an exciting direction\nbringing discriminative and generative model evaluation closer. We will release\ncode and benchmark setup soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krojer_B/0/1/0/all/0/1\">Benno Krojer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poole_Dayan_E/0/1/0/all/0/1\">Elinor Poole-Dayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voleti_V/0/1/0/all/0/1\">Vikram Voleti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1\">Christopher Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Tuning Language Models with Just Forward Passes. (arXiv:2305.17333v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.17333","description":"<p>Fine-tuning language models (LMs) has yielded success on diverse downstream\ntasks, but as LMs grow in size, backpropagation requires a prohibitively large\namount of memory. Zeroth-order (ZO) methods can in principle estimate gradients\nusing only two forward passes but are theorized to be catastrophically slow for\noptimizing large models. In this work, we propose a memory-efficient\nzerothorder optimizer (MeZO), adapting the classical ZO-SGD method to operate\nin-place, thereby fine-tuning LMs with the same memory footprint as inference.\nFor example, with a single A100 80GB GPU, MeZO can train a 30-billion parameter\nmodel, whereas fine-tuning with backpropagation can train only a 2.7B LM with\nthe same budget. We conduct comprehensive experiments across model types\n(masked and autoregressive LMs), model scales (up to 66B), and downstream tasks\n(classification, multiple-choice, and generation). Our results demonstrate that\n(1) MeZO significantly outperforms in-context learning and linear probing; (2)\nMeZO achieves comparable performance to fine-tuning with backpropagation across\nmultiple tasks, with up to 12x memory reduction and up to 2x GPU-hour reduction\nin our implementation; (3) MeZO is compatible with both full-parameter and\nparameter-efficient tuning techniques such as LoRA and prefix tuning; (4) MeZO\ncan effectively optimize non-differentiable objectives (e.g., maximizing\naccuracy or F1). We support our empirical findings with theoretical insights,\nhighlighting how adequate pre-training and task prompts enable MeZO to\nfine-tune huge models, despite classical ZO analyses suggesting otherwise.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malladi_S/0/1/0/all/0/1\">Sadhika Malladi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nichani_E/0/1/0/all/0/1\">Eshaan Nichani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damian_A/0/1/0/all/0/1\">Alex Damian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sanjeev Arora</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Emotion Valence is a Joint Deep Learning Task. (arXiv:2305.17422v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17422","description":"<p>The valence analysis of speakers' utterances or written posts helps to\nunderstand the activation and variations of the emotional state throughout the\nconversation. More recently, the concept of Emotion Carriers (EC) has been\nintroduced to explain the emotion felt by the speaker and its manifestations.\nIn this work, we investigate the natural inter-dependency of valence and ECs\nvia a multi-task learning approach. We experiment with Pre-trained Language\nModels (PLM) for single-task, two-step, and joint settings for the valence and\nEC prediction tasks. We compare and evaluate the performance of generative\n(GPT-2) and discriminative (BERT) architectures in each setting. We observed\nthat providing the ground truth label of one task improves the prediction\nperformance of the models in the other task. We further observed that the\ndiscriminative model achieves the best trade-off of valence and EC prediction\ntasks in the joint prediction setting. As a result, we attain a single model\nthat performs both tasks, thus, saving computation resources at training and\ninference times.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roccabruna_G/0/1/0/all/0/1\">Gabriel Roccabruna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1\">Seyed Mahed Mousavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riccardi_G/0/1/0/all/0/1\">Giuseppe Riccardi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Faith and Fate: Limits of Transformers on Compositionality. (arXiv:2305.18654v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18654","description":"<p>Transformer large language models (LLMs) have sparked admiration for their\nexceptional performance on tasks that demand intricate multi-step reasoning.\nYet, these models simultaneously show failures on surprisingly trivial\nproblems. This begs the question: Are these errors incidental, or do they\nsignal more substantial limitations? In an attempt to demystify transformer\nLLMs, we investigate the limits of these models across three representative\ncompositional tasks -- multi-digit multiplication, logic grid puzzles, and a\nclassic dynamic programming problem. These tasks require breaking problems down\ninto sub-steps and synthesizing these steps into a precise answer. We formulate\ncompositional tasks as computation graphs to systematically quantify the level\nof complexity, and break down reasoning steps into intermediate sub-procedures.\nOur empirical findings suggest that transformer LLMs solve compositional tasks\nby reducing multi-step compositional reasoning into linearized subgraph\nmatching, without necessarily developing systematic problem-solving skills. To\nround off our empirical study, we provide theoretical arguments on abstract\nmulti-step reasoning problems that highlight how autoregressive generations'\nperformance can rapidly decay with\\,increased\\,task\\,complexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dziri_N/0/1/0/all/0/1\">Nouha Dziri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclar_M/0/1/0/all/0/1\">Melanie Sclar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lorraine Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanyal_S/0/1/0/all/0/1\">Soumya Sanyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ettinger_A/0/1/0/all/0/1\">Allyson Ettinger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harchaoui_Z/0/1/0/all/0/1\">Zaid Harchaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Transformer Programs. (arXiv:2306.01128v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.01128","description":"<p>Recent research in mechanistic interpretability has attempted to\nreverse-engineer Transformer models by carefully inspecting network weights and\nactivations. However, these approaches require considerable manual effort and\nstill fall short of providing complete, faithful descriptions of the underlying\nalgorithms. In this work, we introduce a procedure for training Transformers\nthat are mechanistically interpretable by design. We build on RASP [Weiss et\nal., 2021], a programming language that can be compiled into Transformer\nweights. Instead of compiling human-written programs into Transformers, we\ndesign a modified Transformer that can be trained using gradient-based\noptimization and then automatically converted into a discrete, human-readable\nprogram. We refer to these models as Transformer Programs. To validate our\napproach, we learn Transformer Programs for a variety of problems, including an\nin-context learning task, a suite of algorithmic problems (e.g. sorting,\nrecognizing Dyck languages), and NLP tasks including named entity recognition\nand text classification. The Transformer Programs can automatically find\nreasonable solutions, performing on par with standard Transformers of\ncomparable size; and, more importantly, they are easy to interpret. To\ndemonstrate these advantages, we convert Transformers into Python programs and\nuse off-the-shelf code analysis tools to debug model errors and identify the\n\"circuits\" used to solve different sub-problems. We hope that Transformer\nPrograms open a new path toward the goal of intrinsically interpretable machine\nlearning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Friedman_D/0/1/0/all/0/1\">Dan Friedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wettig_A/0/1/0/all/0/1\">Alexander Wettig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structural Similarities Between Language Models and Neural Response Measurements. (arXiv:2306.01930v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.01930","description":"<p>Large language models (LLMs) have complicated internal dynamics, but induce\nrepresentations of words and phrases whose geometry we can study. Human\nlanguage processing is also opaque, but neural response measurements can\nprovide (noisy) recordings of activation during listening or reading, from\nwhich we can extract similar representations of words and phrases. Here we\nstudy the extent to which the geometries induced by these representations,\nshare similarities in the context of brain decoding. We find that the larger\nneural language models get, the more their representations are structurally\nsimilar to neural response measurements from brain imaging. Code is available\nat \\url{https://github.com/coastalcph/brainlm}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karamolegkou_A/0/1/0/all/0/1\">Antonia Karamolegkou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kementchedjhieva_Y/0/1/0/all/0/1\">Yova Kementchedjhieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdou_M/0/1/0/all/0/1\">Mostafa Abdou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehmann_S/0/1/0/all/0/1\">Sune Lehmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1\">Anders S&#xf8;gaard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Fusion Interactions: A Study of Human and Automatic Quantification. (arXiv:2306.04125v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.04125","description":"<p>In order to perform multimodal fusion of heterogeneous signals, we need to\nunderstand their interactions: how each modality individually provides\ninformation useful for a task and how this information changes in the presence\nof other modalities. In this paper, we perform a comparative study of how\nhumans annotate two categorizations of multimodal interactions: (1) partial\nlabels, where different annotators annotate the label given the first, second,\nand both modalities, and (2) counterfactual labels, where the same annotator\nannotates the label given the first modality before asking them to explicitly\nreason about how their answer changes when given the second. We further propose\nan alternative taxonomy based on (3) information decomposition, where\nannotators annotate the degrees of redundancy: the extent to which modalities\nindividually and together give the same predictions, uniqueness: the extent to\nwhich one modality enables a prediction that the other does not, and synergy:\nthe extent to which both modalities enable one to make a prediction that one\nwould not otherwise make using individual modalities. Through experiments and\nannotations, we highlight several opportunities and limitations of each\napproach and propose a method to automatically convert annotations of partial\nand counterfactual labels to information decomposition, yielding an accurate\nand efficient method for quantifying multimodal interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yun Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Imperfect Surrogates for Downstream Inference: Design-based Supervised Learning for Social Science Applications of Large Language Models. (arXiv:2306.04746v2 [stat.ME] UPDATED)","link":"http://arxiv.org/abs/2306.04746","description":"<p>In computational social science (CSS), researchers analyze documents to\nexplain social and political phenomena. In most scenarios, CSS researchers\nfirst obtain labels for documents and then explain labels using interpretable\nregression analyses in the second step. One increasingly common way to annotate\ndocuments cheaply at scale is through large language models (LLMs). However,\nlike other scalable ways of producing annotations, such surrogate labels are\noften imperfect and biased. We present a new algorithm for using imperfect\nannotation surrogates for downstream statistical analyses while guaranteeing\nstatistical properties -- like asymptotic unbiasedness and proper uncertainty\nquantification -- which are fundamental to CSS research. We show that direct\nuse of surrogate labels in downstream statistical analyses leads to substantial\nbias and invalid confidence intervals, even with high surrogate accuracy of\n80--90\\%. To address this, we build on debiased machine learning to propose the\ndesign-based supervised learning (DSL) estimator. DSL employs a doubly-robust\nprocedure to combine surrogate labels with a smaller number of high-quality,\ngold-standard labels. Our approach guarantees valid inference for downstream\nstatistical analyses, even when surrogates are arbitrarily biased and without\nrequiring stringent assumptions, by controlling the probability of sampling\ndocuments for gold-standard labeling. Both our theoretical analysis and\nexperimental results show that DSL provides valid statistical inference while\nachieving root mean squared errors comparable to existing alternatives that\nfocus only on prediction without inferential guarantees.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Egami_N/0/1/0/all/0/1\">Naoki Egami</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Hinck_M/0/1/0/all/0/1\">Musashi Hinck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Stewart_B/0/1/0/all/0/1\">Brandon M. Stewart</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Wei_H/0/1/0/all/0/1\">Hanying Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources. (arXiv:2306.04751v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.04751","description":"<p>In this work we explore recent advances in instruction-tuning language models\non a range of open instruction-following datasets. Despite recent claims that\nopen models can be on par with state-of-the-art proprietary models, these\nclaims are often accompanied by limited evaluation, making it difficult to\ncompare models across the board and determine the utility of various resources.\nWe provide a large set of instruction-tuned models from 6.7B to 65B parameters\nin size, trained on 12 instruction datasets ranging from manually curated\n(e.g., OpenAssistant) to synthetic and distilled (e.g., Alpaca) and\nsystematically evaluate them on their factual knowledge, reasoning,\nmultilinguality, coding, and open-ended instruction following abilities through\na collection of automatic, model-based, and human-based metrics. We further\nintroduce T\\\"ulu, our best performing instruction-tuned model suite finetuned\non a combination of high-quality open resources. Our experiments show that\ndifferent instruction-tuning datasets can uncover or enhance specific skills,\nwhile no single dataset (or combination) provides the best performance across\nall evaluations. Interestingly, we find that model and human preference-based\nevaluations fail to reflect differences in model capabilities exposed by\nbenchmark-based evaluations, suggesting the need for the type of systemic\nevaluation performed in this work. Our evaluations show that the best model in\nany given evaluation reaches on average 87% of ChatGPT performance, and 73% of\nGPT-4 performance, suggesting that further investment in building better base\nmodels and instruction-tuning data is required to close the gap. We release our\ninstruction-tuned models, including a fully finetuned 65B T\\\"ulu, along with\nour code, data, and evaluation framework at\nhttps://github.com/allenai/open-instruct to facilitate future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ivison_H/0/1/0/all/0/1\">Hamish Ivison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dasigi_P/0/1/0/all/0/1\">Pradeep Dasigi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Raghavi Chandu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1\">David Wadden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacMillan_K/0/1/0/all/0/1\">Kelsey MacMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FACTIFY3M: A Benchmark for Multimodal Fact Verification with Explainability through 5W Question-Answering. (arXiv:2306.05523v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05523","description":"<p>Combating disinformation is one of the burning societal crises -- about 67%\nof the American population believes that disinformation produces a lot of\nuncertainty, and 10% of them knowingly propagate disinformation. Evidence shows\nthat disinformation can manipulate democratic processes and public opinion,\ncausing disruption in the share market, panic and anxiety in society, and even\ndeath during crises. Therefore, disinformation should be identified promptly\nand, if possible, mitigated. With approximately 3.2 billion images and 720,000\nhours of video shared online daily on social media platforms, scalable\ndetection of multimodal disinformation requires efficient fact verification.\nDespite progress in automatic text-based fact verification (e.g., FEVER, LIAR),\nthe research community lacks substantial effort in multimodal fact\nverification. To address this gap, we introduce FACTIFY 3M, a dataset of 3\nmillion samples that pushes the boundaries of the domain of fact verification\nvia a multimodal fake news dataset, in addition to offering explainability\nthrough the concept of 5W question-answering. Salient features of the dataset\ninclude: (i) textual claims, (ii) ChatGPT-generated paraphrased claims, (iii)\nassociated images, (iv) stable diffusion-generated additional images (i.e.,\nvisual paraphrases), (v) pixel-level image heatmap to foster image-text\nexplainability of the claim, (vi) 5W QA pairs, and (vii) adversarial fake news\nstories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Megha Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pahwa_K/0/1/0/all/0/1\">Khushbu Pahwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_S/0/1/0/all/0/1\">Shreyas Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalal_D/0/1/0/all/0/1\">Dwip Dalal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dave_H/0/1/0/all/0/1\">Harshit Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_R/0/1/0/all/0/1\">Ritvik G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurumurthy_P/0/1/0/all/0/1\">Preethi Gurumurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahor_A/0/1/0/all/0/1\">Adarsh Mahor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Samahriti Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pakala_A/0/1/0/all/0/1\">Aditya Pakala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_I/0/1/0/all/0/1\">Ishan Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_J/0/1/0/all/0/1\">Janvita Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_A/0/1/0/all/0/1\">Arghya Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sensharma_K/0/1/0/all/0/1\">Kinjal Sensharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit P. Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Effectiveness of ChatGPT in Mathematical Reasoning and Problem Solving: Evidence from the Vietnamese National High School Graduation Examination. (arXiv:2306.06331v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.06331","description":"<p>This study offers a complete analysis of ChatGPT's mathematics abilities in\nresponding to multiple-choice questions for the Vietnamese National High School\nGraduation Examination (VNHSGE) on a range of subjects and difficulty levels.\nThe dataset included 250 questions divided into four levels: knowledge (K),\ncomprehension (C), application (A), and high application (H), and it included\nten themes that covered diverse mathematical concepts. The outcomes demonstrate\nthat ChatGPT's performance varies depending on the difficulty level and\nsubject. It performed best on questions at Level (K), with an accuracy rate of\n$83\\%$; but, as the difficulty level rose, it scored poorly, with an accuracy\nrate of $10\\%$. The study has also shown that ChatGPT significantly succeeds in\nproviding responses to questions on subjects including exponential and\nlogarithmic functions, geometric progression, and arithmetic progression. The\nstudy found that ChatGPT had difficulty correctly answering questions on topics\nincluding derivatives and applications, spatial geometry, and Oxyz spatial\ncalculus. Additionally, this study contrasted ChatGPT outcomes with Vietnamese\nstudents in VNHSGE and in other math competitions. ChatGPT dominated in the SAT\nMath competition with a success rate of $70\\%$, followed by VNHSGE mathematics\n($58.8\\%)$. However, its success rates were lower on other exams, such as AP\nStatistics, the GRE Quantitative, AMC 10, AMC 12, and AP Calculus BC. These\nresults suggest that ChatGPT has the potential to be an effective teaching tool\nfor mathematics, but more work is needed to enhance its handling of graphical\ndata and address the challenges presented by questions that are getting more\nchallenging.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dao_X/0/1/0/all/0/1\">Xuan-Quy Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngoc-Bich Le</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models. (arXiv:2306.06815v3 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2306.06815","description":"<p>Large Language Models (LLMs) are progressively being utilized as machine\nlearning services and interface tools for various applications. However, the\nsecurity implications of LLMs, particularly in relation to adversarial and\nTrojan attacks, remain insufficiently examined. In this paper, we propose\nTrojLLM, an automatic and black-box framework to effectively generate universal\nand stealthy triggers. When these triggers are incorporated into the input\ndata, the LLMs' outputs can be maliciously manipulated. Moreover, the framework\nalso supports embedding Trojans within discrete prompts, enhancing the overall\neffectiveness and precision of the triggers' attacks. Specifically, we propose\na trigger discovery algorithm for generating universal triggers for various\ninputs by querying victim LLM-based APIs using few-shot data samples.\nFurthermore, we introduce a novel progressive Trojan poisoning algorithm\ndesigned to generate poisoned prompts that retain efficacy and transferability\nacross a diverse range of models. Our experiments and results demonstrate\nTrojLLM's capacity to effectively insert Trojans into text prompts in\nreal-world black-box LLM APIs including GPT-3.5 and GPT-4, while maintaining\nexceptional performance on clean test sets. Our work sheds light on the\npotential security risks in current models and offers a potential defensive\napproach. The source code of TrojLLM is available at\nhttps://github.com/UCF-ML-Research/TrojLLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jiaqi Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mengxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_T/0/1/0/all/0/1\">Ting Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yilin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yepeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boloni_L/0/1/0/all/0/1\">Ladislau Boloni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Q/0/1/0/all/0/1\">Qian Lou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Propagating Knowledge Updates to LMs Through Distillation. (arXiv:2306.09306v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09306","description":"<p>Modern language models have the capacity to store and use immense amounts of\nknowledge about real-world entities, but it remains unclear how to update such\nknowledge stored in model parameters. While prior methods for updating\nknowledge in LMs successfully inject atomic facts, updated LMs fail to make\ninferences based on injected facts. In this work, we demonstrate that a context\ndistillation-based approach can both impart knowledge about entities and\npropagate that knowledge to enable broader inferences. Our approach consists of\ntwo stages: transfer set generation and distillation on the transfer set. We\nfirst generate a transfer set by prompting a language model to generate\ncontinuations from the entity definition. Then, we update the model parameters\nso that the distribution of the LM (the student) matches the distribution of\nthe LM conditioned on the definition (the teacher) on the transfer set. Our\nexperiments demonstrate that this approach is more effective at propagating\nknowledge updates than fine-tuning and other gradient-based knowledge-editing\nmethods. Moreover, it does not compromise performance in other contexts, even\nwhen injecting the definitions of up to 150 entities at once.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Padmanabhan_S/0/1/0/all/0/1\">Shankar Padmanabhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1\">Yasumasa Onoe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Michael J.Q. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2306.17256","description":"<p>Recommender systems play a crucial role in helping users discover information\nthat aligns with their interests based on their past behaviors. However,\ndeveloping personalized recommendation systems becomes challenging when\nhistorical records of user-item interactions are unavailable, leading to what\nis known as the system cold-start recommendation problem. This issue is\nparticularly prominent in start-up businesses or platforms with insufficient\nuser engagement history. Previous studies focus on user or item cold-start\nscenarios, where systems could make recommendations for new users or items but\nare still trained with historical user-item interactions in the same domain,\nwhich cannot solve our problem. To bridge the gap, our research introduces an\ninnovative and effective approach, capitalizing on the capabilities of\npre-trained language models. We transform the recommendation process into\nsentiment analysis of natural languages containing information of user profiles\nand item attributes, where the sentiment polarity is predicted with prompt\nlearning. By harnessing the extensive knowledge housed within language models,\nthe prediction can be made without historical user-item interaction records. A\nbenchmark is also introduced to evaluate the proposed method under the\ncold-start setting, and the results demonstrate the effectiveness of our\nmethod. To the best of our knowledge, this is the first study to tackle the\nsystem cold-start recommendation problem. The benchmark and implementation of\nthe method are available at https://github.com/JacksonWuxs/PromptRec.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xuansheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huachi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yucheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Wenlin Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How is ChatGPT's behavior changing over time?. (arXiv:2307.09009v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09009","description":"<p>GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nseveral diverse tasks: 1) math problems, 2) sensitive/dangerous questions, 3)\nopinion surveys, 4) multi-hop knowledge-intensive questions, 5) generating\ncode, 6) US Medical License tests, and 7) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\nFor example, GPT-4 (March 2023) was reasonable at identifying prime vs.\ncomposite numbers (84% accuracy) but GPT-4 (June 2023) was poor on these same\nquestions (51% accuracy). This is partly explained by a drop in GPT-4's amenity\nto follow chain-of-thought prompting. Interestingly, GPT-3.5 was much better in\nJune than in March in this task. GPT-4 became less willing to answer sensitive\nquestions and opinion survey questions in June than in March. GPT-4 performed\nbetter at multi-hop questions in June than in March, while GPT-3.5's\nperformance dropped on this task. Both GPT-4 and GPT-3.5 had more formatting\nmistakes in code generation in June than in March. We provide evidence that\nGPT-4's ability to follow user instructions has decreased over time, which is\none common factor behind the many behavior drifts. Overall, our findings show\nthat the behavior of the \"same\" LLM service can change substantially in a\nrelatively short amount of time, highlighting the need for continuous\nmonitoring of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lingjiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Document Page Classification: Design, Datasets, and Challenges. (arXiv:2308.12896v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.12896","description":"<p>This paper highlights the need to bring document classification benchmarking\ncloser to real-world applications, both in the nature of data tested ($X$:\nmulti-channel, multi-paged, multi-industry; $Y$: class distributions and label\nset variety) and in classification tasks considered ($f$: multi-page document,\npage stream, and document bundle classification, ...). We identify the lack of\npublic multi-page document classification datasets, formalize different\nclassification tasks arising in application scenarios, and motivate the value\nof targeting efficient multi-page document representations. An experimental\nstudy on proposed multi-page document classification datasets demonstrates that\ncurrent benchmarks have become irrelevant and need to be updated to evaluate\ncomplete documents, as they naturally occur in practice. This reality check\nalso calls for more mature evaluation methodologies, covering calibration\nevaluation, inference complexity (time-memory), and a range of realistic\ndistribution shifts (e.g., born-digital vs. scanning noise, shifting page\norder). Our study ends on a hopeful note by recommending concrete avenues for\nfuture improvements.}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Landeghem_J/0/1/0/all/0/1\">Jordy Van Landeghem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sanket Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1\">Matthew B. Blaschko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering Trends across Diverse Platforms. (arXiv:2309.05961v2 [cs.SI] UPDATED)","link":"http://arxiv.org/abs/2309.05961","description":"<p>Community Question Answering (CQA) platforms steadily gain popularity as they\nprovide users with fast responses to their queries. The swiftness of these\nresponses is contingent on a mixture of query-specific and user-related\nelements. This paper scrutinizes these contributing factors within the context\nof six highly popular CQA platforms, identified through their standout\nanswering speed. Our investigation reveals a correlation between the time taken\nto yield the first response to a question and several variables: the metadata,\nthe formulation of the questions, and the level of interaction among users.\nAdditionally, by employing conventional machine learning models to analyze\nthese metadata and patterns of user interaction, we endeavor to predict which\nqueries will receive their initial responses promptly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hazra_R/0/1/0/all/0/1\">Rima Hazra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Agnik Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_S/0/1/0/all/0/1\">Somnath Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"D-Separation for Causal Self-Explanation. (arXiv:2309.13391v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.13391","description":"<p>Rationalization is a self-explaining framework for NLP models. Conventional\nwork typically uses the maximum mutual information (MMI) criterion to find the\nrationale that is most indicative of the target label. However, this criterion\ncan be influenced by spurious features that correlate with the causal rationale\nor the target label. Instead of attempting to rectify the issues of the MMI\ncriterion, we propose a novel criterion to uncover the causal rationale, termed\nthe Minimum Conditional Dependence (MCD) criterion, which is grounded on our\nfinding that the non-causal features and the target label are\n\\emph{d-separated} by the causal rationale. By minimizing the dependence\nbetween the unselected parts of the input and the target label conditioned on\nthe selected rationale candidate, all the causes of the label are compelled to\nbe selected. In this study, we employ a simple and practical measure of\ndependence, specifically the KL-divergence, to validate our proposed MCD\ncriterion. Empirically, we demonstrate that MCD improves the F1 score by up to\n$13.7\\%$ compared to previous state-of-the-art MMI-based methods. Our code is\navailable at: \\url{https://github.com/jugechengzi/Rationalization-MCD}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhiying Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">YuanKai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yang Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COCO-Counterfactuals: Automatically Constructed Counterfactual Examples for Image-Text Pairs. (arXiv:2309.14356v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.14356","description":"<p>Counterfactual examples have proven to be valuable in the field of natural\nlanguage processing (NLP) for both evaluating and improving the robustness of\nlanguage models to spurious correlations in datasets. Despite their\ndemonstrated utility for NLP, multimodal counterfactual examples have been\nrelatively unexplored due to the difficulty of creating paired image-text data\nwith minimal counterfactual changes. To address this challenge, we introduce a\nscalable framework for automatic generation of counterfactual examples using\ntext-to-image diffusion models. We use our framework to create\nCOCO-Counterfactuals, a multimodal counterfactual dataset of paired image and\ntext captions based on the MS-COCO dataset. We validate the quality of\nCOCO-Counterfactuals through human evaluations and show that existing\nmultimodal models are challenged by our counterfactual image-text pairs.\nAdditionally, we demonstrate the usefulness of COCO-Counterfactuals for\nimproving out-of-domain generalization of multimodal vision-language models via\ntraining data augmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Tiep Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_V/0/1/0/all/0/1\">Vasudev Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howard_P/0/1/0/all/0/1\">Phillip Howard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeBERTinha: A Multistep Approach to Adapt DebertaV3 XSmall for Brazilian Portuguese Natural Language Processing Task. (arXiv:2309.16844v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16844","description":"<p>This paper presents an approach for adapting the DebertaV3 XSmall model\npre-trained in English for Brazilian Portuguese natural language processing\n(NLP) tasks. A key aspect of the methodology involves a multistep training\nprocess to ensure the model is effectively tuned for the Portuguese language.\nInitial datasets from Carolina and BrWac are preprocessed to address issues\nlike emojis, HTML tags, and encodings. A Portuguese-specific vocabulary of\n50,000 tokens is created using SentencePiece. Rather than training from\nscratch, the weights of the pre-trained English model are used to initialize\nmost of the network, with random embeddings, recognizing the expensive cost of\ntraining from scratch. The model is fine-tuned using the replaced token\ndetection task in the same format of DebertaV3 training. The adapted model,\ncalled DeBERTinha, demonstrates effectiveness on downstream tasks like named\nentity recognition, sentiment analysis, and determining sentence relatedness,\noutperforming BERTimbau-Large in two tasks despite having only 40M parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Campiotti_I/0/1/0/all/0/1\">Israel Campiotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Matheus Rodrigues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albuquerque_Y/0/1/0/all/0/1\">Yuri Albuquerque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azevedo_R/0/1/0/all/0/1\">Rafael Azevedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrade_A/0/1/0/all/0/1\">Alyson Andrade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Embeddings for Measuring Text Relatedness: Unveiling Sentiments and Relationships in Online Comments. (arXiv:2310.05964v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05964","description":"<p>After the COVID-19 pandemic caused internet usage to grow by 70%, there has\nbeen an increased number of people all across the world using social media.\nApplications like Twitter, Meta Threads, YouTube, and Reddit have become\nincreasingly pervasive, leaving almost no digital space where public opinion is\nnot expressed. This paper investigates sentiment and semantic relationships\namong comments across various social media platforms, as well as discusses the\nimportance of shared opinions across these different media platforms, using\nword embeddings to analyze components in sentences and documents. It allows\nresearchers, politicians, and business representatives to trace a path of\nshared sentiment among users across the world. This research paper presents\nmultiple approaches that measure the relatedness of text extracted from user\ncomments on these popular online platforms. By leveraging embeddings, which\ncapture semantic relationships between words and help analyze sentiments across\nthe web, we can uncover connections regarding public opinion as a whole. The\nstudy utilizes pre-existing datasets from YouTube, Reddit, Twitter, and more.\nWe made use of popular natural language processing models like Bidirectional\nEncoder Representations from Transformers (BERT) to analyze sentiments and\nexplore relationships between comment embeddings. Additionally, we aim to\nutilize clustering and Kl-divergence to find semantic relationships within\nthese comment embeddings across various social media platforms. Our analysis\nwill enable a deeper understanding of the interconnectedness of online comments\nand will investigate the notion of the internet functioning as a large\ninterconnected brain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Olakangil_A/0/1/0/all/0/1\">Anthony Olakangil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cindy Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_J/0/1/0/all/0/1\">Justin Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qunbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jethwa_K/0/1/0/all/0/1\">Kaavya Jethwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jason Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narendra_A/0/1/0/all/0/1\">Aryan Narendra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1\">Nishk Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajaram_A/0/1/0/all/0/1\">Arjun Rajaram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Language Models to Hallucinate Less with Synthetic Tasks. (arXiv:2310.06827v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06827","description":"<p>Large language models (LLMs) frequently hallucinate on abstractive\nsummarization tasks such as document-based question-answering, meeting\nsummarization, and clinical report generation, even though all necessary\ninformation is included in context. However, optimizing LLMs to hallucinate\nless on these tasks is challenging, as hallucination is hard to efficiently\nevaluate at each optimization step. In this work, we show that reducing\nhallucination on a synthetic task can also reduce hallucination on real-world\ndownstream tasks. Our method, SynTra, first designs a synthetic task where\nhallucinations are easy to elicit and measure. It next optimizes the LLM's\nsystem message via prefix-tuning on the synthetic task, and finally transfers\nthe system message to realistic, hard-to-optimize tasks. Across three realistic\nabstractive summarization tasks, SynTra reduces hallucination for two\n13B-parameter LLMs using only a synthetic retrieval task for supervision. We\nalso find that optimizing the system message rather than the model weights can\nbe critical; fine-tuning the entire model on the synthetic task can\ncounterintuitively increase hallucination. Overall, SynTra demonstrates that\nthe extra flexibility of working with synthetic data can help mitigate\nundesired behaviors in practice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jones_E/0/1/0/all/0/1\">Erik Jones</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palangi_H/0/1/0/all/0/1\">Hamid Palangi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simoes_C/0/1/0/all/0/1\">Clarisse Sim&#xf5;es</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekaran_V/0/1/0/all/0/1\">Varun Chandrasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1\">Subhabrata Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_A/0/1/0/all/0/1\">Arindam Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamar_E/0/1/0/all/0/1\">Ece Kamar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ziya-Visual: Bilingual Large Vision-Language Model via Multi-Task Instruction Tuning. (arXiv:2310.08166v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08166","description":"<p>Recent advancements enlarge the capabilities of large language models (LLMs)\nin zero-shot image-to-text generation and understanding by integrating\nmulti-modal inputs. However, such success is typically limited to English\nscenarios due to the lack of large-scale and high-quality non-English\nmulti-modal resources, making it extremely difficult to establish competitive\ncounterparts in other languages. In this paper, we introduce the Ziya-Visual\nseries, a set of bilingual large-scale vision-language models (LVLMs) designed\nto incorporate visual semantics into LLM for multi-modal dialogue. Composed of\nZiya-Visual-Base and Ziya-Visual-Chat, our models adopt the Querying\nTransformer from BLIP-2, further exploring the assistance of optimization\nschemes such as instruction tuning, multi-stage training and low-rank\nadaptation module for visual-language alignment. In addition, we stimulate the\nunderstanding ability of GPT-4 in multi-modal scenarios, translating our\ngathered English image-text datasets into Chinese and generating\ninstruction-response through the in-context learning method. The experiment\nresults demonstrate that compared to the existing LVLMs, Ziya-Visual achieves\ncompetitive performance across a wide range of English-only tasks including\nzero-shot image-text retrieval, image captioning, and visual question\nanswering. The evaluation leaderboard accessed by GPT-4 also indicates that our\nmodels possess satisfactory image-text understanding and generation\ncapabilities in Chinese multi-modal scenario dialogues. Code, demo and models\nare available at\n~\\url{https://huggingface.co/IDEA-CCNL/Ziya-BLIP2-14B-Visual-v1}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dixiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaojun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xinyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yan Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pingjian Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards a Better Understanding of Variations in Zero-Shot Neural Machine Translation Performance. (arXiv:2310.10385v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10385","description":"<p>Multilingual Neural Machine Translation (MNMT) facilitates knowledge sharing\nbut often suffers from poor zero-shot (ZS) translation qualities. While prior\nwork has explored the causes of overall low ZS performance, our work introduces\na fresh perspective: the presence of high variations in ZS performance. This\nsuggests that MNMT does not uniformly exhibit poor ZS capability; instead,\ncertain translation directions yield reasonable results. Through systematic\nexperimentation involving 1,560 language directions spanning 40 languages, we\nidentify three key factors contributing to high variations in ZS NMT\nperformance: 1) target side translation capability 2) vocabulary overlap 3)\nlinguistic properties. Our findings highlight that the target side translation\nquality is the most influential factor, with vocabulary overlap consistently\nimpacting ZS performance. Additionally, linguistic properties, such as language\nfamily and writing system, play a role, particularly with smaller models.\nFurthermore, we suggest that the off-target issue is a symptom of inadequate ZS\nperformance, emphasizing that zero-shot translation challenges extend beyond\naddressing the off-target problem. We release the data and models serving as a\nbenchmark to study zero-shot for future research at\nhttps://github.com/Smu-Tan/ZS-NMT-Variations\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shaomu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quality-Diversity through AI Feedback. (arXiv:2310.13032v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13032","description":"<p>In many text-generation problems, users may prefer not only a single\nresponse, but a diverse range of high-quality outputs from which to choose.\nQuality-diversity (QD) search algorithms aim at such outcomes, by continually\nimproving and diversifying a population of candidates. However, the\napplicability of QD to qualitative domains, like creative writing, has been\nlimited by the difficulty of algorithmically specifying measures of quality and\ndiversity. Interestingly, recent developments in language models (LMs) have\nenabled guiding search through AI feedback, wherein LMs are prompted in natural\nlanguage to evaluate qualitative aspects of text. Leveraging this development,\nwe introduce Quality-Diversity through AI Feedback (QDAIF), wherein an\nevolutionary algorithm applies LMs to both generate variation and evaluate the\nquality and diversity of candidate text. When assessed on creative writing\ndomains, QDAIF covers more of a specified search space with high-quality\nsamples than do non-QD controls. Further, human evaluation of QDAIF-generated\ncreative texts validates reasonable agreement between AI and human evaluation.\nOur results thus highlight the potential of AI feedback to guide open-ended\nsearch for creative and original solutions, providing a recipe that seemingly\ngeneralizes to many domains and modalities. In this way, QDAIF is a step\ntowards AI systems that can independently search, diversify, evaluate, and\nimprove, which are among the core skills underlying human society's capacity\nfor innovation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bradley_H/0/1/0/all/0/1\">Herbie Bradley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teufel_H/0/1/0/all/0/1\">Hannah Teufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jenny Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oostermeijer_K/0/1/0/all/0/1\">Koen Oostermeijer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellagente_M/0/1/0/all/0/1\">Marco Bellagente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1\">Jeff Clune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1\">Kenneth Stanley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schott_G/0/1/0/all/0/1\">Gr&#xe9;gory Schott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1\">Joel Lehman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models. (arXiv:2310.13673v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13673","description":"<p>Large Language Models (LLMs) have been observed to encode and perpetuate\nharmful associations present in the training data. We propose a theoretically\ngrounded framework called StereoMap to gain insights into their perceptions of\nhow demographic groups have been viewed by society. The framework is grounded\nin the Stereotype Content Model (SCM); a well-established theory from\npsychology. According to SCM, stereotypes are not all alike. Instead, the\ndimensions of Warmth and Competence serve as the factors that delineate the\nnature of stereotypes. Based on the SCM theory, StereoMap maps LLMs'\nperceptions of social groups (defined by socio-demographic features) using the\ndimensions of Warmth and Competence. Furthermore, the framework enables the\ninvestigation of keywords and verbalizations of reasoning of LLMs' judgments to\nuncover underlying factors influencing their perceptions. Our results show that\nLLMs exhibit a diverse range of perceptions towards these groups, characterized\nby mixed evaluations along the dimensions of Warmth and Competence.\nFurthermore, analyzing the reasonings of LLMs, our findings indicate that LLMs\ndemonstrate an awareness of social disparities, often stating statistical data\nand research findings to support their reasoning. This study contributes to the\nunderstanding of how LLMs perceive and represent social groups, shedding light\non their potential biases and the perpetuation of harmful associations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeoung_S/0/1/0/all/0/1\">Sullam Jeoung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yubin Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diesner_J/0/1/0/all/0/1\">Jana Diesner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Pre-trained Transformer for Vietnamese Community-based COVID-19 Question Answering. (arXiv:2310.14602v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.14602","description":"<p>Recent studies have provided empirical evidence of the wide-ranging potential\nof Generative Pre-trained Transformer (GPT), a pretrained language model, in\nthe field of natural language processing. GPT has been effectively employed as\na decoder within state-of-the-art (SOTA) question answering systems, yielding\nexceptional performance across various tasks. However, the current research\nlandscape concerning GPT's application in Vietnamese remains limited. This\npaper aims to address this gap by presenting an implementation of GPT-2 for\ncommunity-based question answering specifically focused on COVID-19 related\nqueries in Vietnamese. We introduce a novel approach by conducting a\ncomparative analysis of different Transformers vs SOTA models in the\ncommunity-based COVID-19 question answering dataset. The experimental findings\ndemonstrate that the GPT-2 models exhibit highly promising outcomes,\noutperforming other SOTA models as well as previous community-based COVID-19\nquestion answering models developed for Vietnamese.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vo_T/0/1/0/all/0/1\">Tam Minh Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1\">Khiem Vinh Tran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. (arXiv:2310.15421v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15421","description":"<p>Theory of mind (ToM) evaluations currently focus on testing models using\npassive narratives that inherently lack interactivity. We introduce FANToM, a\nnew benchmark designed to stress-test ToM within information-asymmetric\nconversational contexts via question answering. Our benchmark draws upon\nimportant theoretical requisites from psychology and necessary empirical\nconsiderations when evaluating large language models (LLMs). In particular, we\nformulate multiple types of questions that demand the same underlying reasoning\nto identify illusory or false sense of ToM capabilities in LLMs. We show that\nFANToM is challenging for state-of-the-art LLMs, which perform significantly\nworse than humans even with chain-of-thought reasoning or fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclar_M/0/1/0/all/0/1\">Melanie Sclar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Correction with Backtracking Reduces Hallucination in Summarization. (arXiv:2310.16176v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16176","description":"<p>Abstractive summarization aims at generating natural language summaries of a\nsource document that are succinct while preserving the important elements.\nDespite recent advances, neural text summarization models are known to be\nsusceptible to hallucinating (or more correctly confabulating), that is to\nproduce summaries with details that are not grounded in the source document. In\nthis paper, we introduce a simple yet efficient technique, CoBa, to reduce\nhallucination in abstractive summarization. The approach is based on two steps:\nhallucination detection and mitigation. We show that the former can be achieved\nthrough measuring simple statistics about conditional word probabilities and\ndistance to context words. Further, we demonstrate that straight-forward\nbacktracking is surprisingly effective at mitigation. We thoroughly evaluate\nthe proposed method with prior art on three benchmark datasets for text\nsummarization. The results show that CoBa is effective and efficient in\nreducing hallucination, and offers great adaptability and flexibility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhenzhen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_C/0/1/0/all/0/1\">Chao Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kishore_V/0/1/0/all/0/1\">Varsha Kishore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jin Peng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Minmin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FormaT5: Abstention and Examples for Conditional Table Formatting with Natural Language. (arXiv:2310.17306v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.17306","description":"<p>Formatting is an important property in tables for visualization,\npresentation, and analysis. Spreadsheet software allows users to automatically\nformat their tables by writing data-dependent conditional formatting (CF)\nrules. Writing such rules is often challenging for users as it requires them to\nunderstand and implement the underlying logic. We present FormaT5, a\ntransformer-based model that can generate a CF rule given the target table and\na natural language description of the desired formatting logic. We find that\nuser descriptions for these tasks are often under-specified or ambiguous,\nmaking it harder for code generation systems to accurately learn the desired\nrule in a single step. To tackle this problem of under-specification and\nminimise argument errors, FormaT5 learns to predict placeholders though an\nabstention objective. These placeholders can then be filled by a second model\nor, when examples of rows that should be formatted are available, by a\nprogramming-by-example system. To evaluate FormaT5 on diverse and real\nscenarios, we create an extensive benchmark of 1053 CF tasks, containing\nreal-world descriptions collected from four different sources. We release our\nbenchmarks to encourage research in this area. Abstention and filling allow\nFormaT5 to outperform 8 different neural approaches on our benchmarks, both\nwith and without examples. Our results illustrate the value of building\ndomain-specific learning systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mukul Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambronero_J/0/1/0/all/0/1\">Jos&#xe9; Cambronero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1\">Sumit Gulwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negreanu_C/0/1/0/all/0/1\">Carina Negreanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nouri_E/0/1/0/all/0/1\">Elnaz Nouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raza_M/0/1/0/all/0/1\">Mohammad Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbruggen_G/0/1/0/all/0/1\">Gust Verbruggen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CodeFusion: A Pre-trained Diffusion Model for Code Generation. (arXiv:2310.17680v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2310.17680","description":"<p>Imagine a developer who can only change their last line of code, how often\nwould they have to start writing a function from scratch before it is correct?\nAuto-regressive models for code generation from natural language have a similar\nlimitation: they do not easily allow reconsidering earlier tokens generated. We\nintroduce CodeFusion, a pre-trained diffusion code generation model that\naddresses this limitation by iteratively denoising a complete program\nconditioned on the encoded natural language. We evaluate CodeFusion on the task\nof natural language to code generation for Bash, Python, and Microsoft Excel\nconditional formatting (CF) rules. Experiments show that CodeFusion (75M\nparameters) performs on par with state-of-the-art auto-regressive systems\n(350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and\ntop-5 accuracy due to its better balance in diversity versus quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1\">Mukul Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cambronero_J/0/1/0/all/0/1\">Jos&#xe9; Cambronero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1\">Sumit Gulwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1\">Vu Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negreanu_C/0/1/0/all/0/1\">Carina Negreanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verbruggen_G/0/1/0/all/0/1\">Gust Verbruggen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting. (arXiv:2310.17811v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.17811","description":"<p>Automatically generated reports from medical images promise to improve the\nworkflow of radiologists. Existing methods consider an image-to-report modeling\ntask by directly generating a fully-fledged report from an image. However, this\nconflates the content of the report (e.g., findings and their attributes) with\nits style (e.g., format and choice of words), which can lead to clinically\ninaccurate reports. To address this, we propose a two-step approach for\nradiology report generation. First, we extract the content from an image; then,\nwe verbalize the extracted content into a report that matches the style of a\nspecific radiologist. For this, we leverage RadGraph -- a graph representation\nof reports -- together with large language models (LLMs). In our quantitative\nevaluations, we find that our approach leads to beneficial performance. Our\nhuman evaluation with clinical raters highlights that the AI-generated reports\nare indistinguishably tailored to the style of individual radiologist despite\nleveraging only a few examples as context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Benjamin Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_D/0/1/0/all/0/1\">David E. Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adithan_S/0/1/0/all/0/1\">Subathra Adithan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reis_E/0/1/0/all/0/1\">Eduardo Pontes Reis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1\">Stephen Kwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venugopal_V/0/1/0/all/0/1\">Vasantha Kumar Venugopal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OConnell_C/0/1/0/all/0/1\">Chloe P. O&#x27;Connell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenz_A/0/1/0/all/0/1\">Agustina Saenz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurkar_P/0/1/0/all/0/1\">Pranav Rajpurkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moor_M/0/1/0/all/0/1\">Michael Moor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TarGEN: Targeted Data Generation with Large Language Models. (arXiv:2310.17876v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.17876","description":"<p>The rapid advancement of large language models (LLMs) has sparked interest in\ndata synthesis techniques, aiming to generate diverse and high-quality\nsynthetic datasets. However, these synthetic datasets often suffer from a lack\nof diversity and added noise. In this paper, we present TarGEN, a multi-step\nprompting strategy for generating high-quality synthetic datasets utilizing a\nLLM. An advantage of TarGEN is its seedless nature; it does not require\nspecific task instances, broadening its applicability beyond task replication.\nWe augment TarGEN with a method known as self-correction empowering LLMs to\nrectify inaccurately labeled instances during dataset creation, ensuring\nreliable labels. To assess our technique's effectiveness, we emulate 8 tasks\nfrom the SuperGLUE benchmark and finetune various language models, including\nencoder-only, encoder-decoder, and decoder-only models on both synthetic and\noriginal training sets. Evaluation on the original test set reveals that models\ntrained on datasets generated by TarGEN perform approximately 1-2% points\nbetter than those trained on original datasets (82.84% via syn. vs. 81.12% on\nog. using Flan-T5). When incorporating instruction tuning, the performance\nincreases to 84.54% on synthetic data vs. 81.49% on original data by Flan-T5. A\ncomprehensive analysis of the synthetic dataset compared to the original\ndataset reveals that the synthetic dataset demonstrates similar or higher\nlevels of dataset complexity and diversity. Furthermore, the synthetic dataset\ndisplays a bias level that aligns closely with the original dataset. Finally,\nwhen pre-finetuned on our synthetic SuperGLUE dataset, T5-3B yields impressive\nresults on the OpenLLM leaderboard, surpassing the model trained on the\nSelf-Instruct dataset by 4.14% points. We hope that TarGEN can be helpful for\nquality data generation and reducing the human efforts to create complex\nbenchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1\">Himanshu Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaria_K/0/1/0/all/0/1\">Kevin Scaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anantheswaran_U/0/1/0/all/0/1\">Ujjwala Anantheswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Shreyas Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1\">Mihir Parmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sawant_S/0/1/0/all/0/1\">Saurabh Arjun Sawant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AllTogether: Investigating the Efficacy of Spliced Prompt for Web Navigation using Large Language Models. (arXiv:2310.18331v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18331","description":"<p>Large Language Models (LLMs) have emerged as promising agents for web\nnavigation tasks, interpreting objectives and interacting with web pages.\nHowever, the efficiency of spliced prompts for such tasks remains\nunderexplored. We introduces AllTogether, a standardized prompt template that\nenhances task context representation, thereby improving LLMs' performance in\nHTML-based web navigation. We evaluate the efficacy of this approach through\nprompt learning and instruction finetuning based on open-source Llama-2 and\nAPI-accessible GPT models. Our results reveal that models like GPT-4 outperform\nsmaller models in web navigation tasks. Additionally, we find that the length\nof HTML snippet and history trajectory significantly influence performance, and\nprior step-by-step instructions prove less effective than real-time\nenvironmental feedback. Overall, we believe our work provides valuable insights\nfor future research in LLM-driven web agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiarun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wentao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chunhong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoRAShear: Efficient Large Language Model Structured Pruning and Knowledge Recovery. (arXiv:2310.18356v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.18356","description":"<p>Large Language Models (LLMs) have transformed the landscape of artificial\nintelligence, while their enormous size presents significant challenges in\nterms of computational costs. We introduce LoRAShear, a novel efficient\napproach to structurally prune LLMs and recover knowledge. Given general LLMs,\nLoRAShear at first creates the dependency graphs over LoRA modules to discover\nminimally removal structures and analyze the knowledge distribution. It then\nproceeds progressive structured pruning on LoRA adaptors and enables inherent\nknowledge transfer to better preserve the information in the redundant\nstructures. To recover the lost knowledge during pruning, LoRAShear\nmeticulously studies and proposes a dynamic fine-tuning schemes with dynamic\ndata adaptors to effectively narrow down the performance gap to the full\nmodels. Numerical results demonstrate that by only using one GPU within a\ncouple of GPU days, LoRAShear effectively reduced footprint of LLMs by 20% with\nonly 1.0% performance degradation and significantly outperforms\nstate-of-the-arts. The source code will be available at\nhttps://github.com/microsoft/lorashear.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Tianyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1\">Tianyu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_B/0/1/0/all/0/1\">Badal Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zharkov_I/0/1/0/all/0/1\">Ilya Zharkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Luming Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TeacherLM: Teaching to Fish Rather Than Giving the Fish, Language Modeling Likewise. (arXiv:2310.19019v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19019","description":"<p>Large Language Models (LLMs) exhibit impressive reasoning and data\naugmentation capabilities in various NLP tasks. However, what about small\nmodels? In this work, we propose TeacherLM-7.1B, capable of annotating relevant\nfundamentals, chain of thought, and common mistakes for most NLP samples, which\nmakes annotation more than just an answer, thus allowing other models to learn\n\"why\" instead of just \"what\". The TeacherLM-7.1B model achieved a zero-shot\nscore of 52.3 on MMLU, surpassing most models with over 100B parameters. Even\nmore remarkable is its data augmentation ability. Based on TeacherLM-7.1B, we\naugmented 58 NLP datasets and taught various student models with different\nparameters from OPT and BLOOM series in a multi-task setting. The experimental\nresults indicate that the data augmentation provided by TeacherLM has brought\nsignificant benefits. We will release the TeacherLM series of models and\naugmented datasets as open-source.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_N/0/1/0/all/0/1\">Nan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_H/0/1/0/all/0/1\">Hanyu Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1\">Zirui Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Junting Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1\">Ruoyu Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Ruofan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunchen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Gangming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhaohui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shaoqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Ding Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_M/0/1/0/all/0/1\">Mingjie Zhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BERT Lost Patience Won't Be Robust to Adversarial Slowdown. (arXiv:2310.19152v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.19152","description":"<p>In this paper, we systematically evaluate the robustness of multi-exit\nlanguage models against adversarial slowdown. To audit their robustness, we\ndesign a slowdown attack that generates natural adversarial text bypassing\nearly-exit points. We use the resulting WAFFLE attack as a vehicle to conduct a\ncomprehensive evaluation of three multi-exit mechanisms with the GLUE benchmark\nagainst adversarial slowdown. We then show our attack significantly reduces the\ncomputational savings provided by the three methods in both white-box and\nblack-box settings. The more complex a mechanism is, the more vulnerable it is\nto adversarial slowdown. We also perform a linguistic analysis of the perturbed\ntext inputs, identifying common perturbation patterns that our attack\ngenerates, and comparing them with standard adversarial text attacks. Moreover,\nwe show that adversarial training is ineffective in defeating our slowdown\nattack, but input sanitization with a conversational model, e.g., ChatGPT, can\nremove perturbations effectively. This result suggests that future work is\nneeded for developing efficient yet robust multi-exit models. Our code is\navailable at: https://github.com/ztcoalson/WAFFLE\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Coalson_Z/0/1/0/all/0/1\">Zachary Coalson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_G/0/1/0/all/0/1\">Gabriel Ritter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bobba_R/0/1/0/all/0/1\">Rakesh Bobba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Sanghyun Hong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constituency Parsing using LLMs. (arXiv:2310.19462v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19462","description":"<p>Constituency parsing is a fundamental yet unsolved natural language\nprocessing task. In this paper, we explore the potential of recent large\nlanguage models (LLMs) that have exhibited remarkable performance across\nvarious domains and tasks to tackle this task. We employ three linearization\nstrategies to transform output trees into symbol sequences, such that LLMs can\nsolve constituency parsing by generating linearized trees. We conduct\nexperiments using a diverse range of LLMs, including ChatGPT, GPT-4, OPT,\nLLaMA, and Alpaca, comparing their performance against the state-of-the-art\nconstituency parsers. Our experiments encompass zero-shot, few-shot, and\nfull-training learning settings, and we evaluate the models on one in-domain\nand five out-of-domain test datasets. Our findings reveal insights into LLMs'\nperformance, generalization abilities, and challenges in constituency parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1\">Xuefeng Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMaAA: Making Large Language Models as Active Annotators. (arXiv:2310.19596v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19596","description":"<p>Prevalent supervised learning methods in natural language processing (NLP)\nare notoriously data-hungry, which demand large amounts of high-quality\nannotated data. In practice, acquiring such data is a costly endeavor.\nRecently, the superior few-shot performance of large language models (LLMs) has\npropelled the development of dataset generation, where the training data are\nsolely synthesized from LLMs. However, such an approach usually suffers from\nlow-quality issues, and requires orders of magnitude more labeled data to\nachieve satisfactory performance. To fully exploit the potential of LLMs and\nmake use of massive unlabeled data, we propose LLMaAA, which takes LLMs as\nannotators and puts them into an active learning loop to determine what to\nannotate efficiently. To learn robustly with pseudo labels, we optimize both\nthe annotation and training processes: (1) we draw k-NN examples from a small\ndemonstration pool as in-context examples, and (2) we adopt the example\nreweighting technique to assign training samples with learnable weights.\nCompared with previous approaches, LLMaAA features both efficiency and\nreliability. We conduct experiments and analysis on two classic NLP tasks,\nnamed entity recognition and relation extraction. With LLMaAA, task-specific\nmodels trained from LLM-generated labels can outperform the teacher within only\nhundreds of annotated examples, which is much more cost-effective than other\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruoyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanzeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yongliang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Ming Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_L/0/1/0/all/0/1\">Lei Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models: The Need for Nuance in Current Debates and a Pragmatic Perspective on Understanding. (arXiv:2310.19671v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19671","description":"<p>Current Large Language Models (LLMs) are unparalleled in their ability to\ngenerate grammatically correct, fluent text. LLMs are appearing rapidly, and\ndebates on LLM capacities have taken off, but reflection is lagging behind.\nThus, in this position paper, we first zoom in on the debate and critically\nassess three points recurring in critiques of LLM capacities: i) that LLMs only\nparrot statistical patterns in the training data; ii) that LLMs master formal\nbut not functional language competence; and iii) that language learning in LLMs\ncannot inform human language learning. Drawing on empirical and theoretical\narguments, we show that these points need more nuance. Second, we outline a\npragmatic perspective on the issue of `real' understanding and intentionality\nin LLMs. Understanding and intentionality pertain to unobservable mental states\nwe attribute to other humans because they have pragmatic value: they allow us\nto abstract away from complex underlying mechanics and predict behaviour\neffectively. We reflect on the circumstances under which it would make sense\nfor humans to similarly attribute mental states to LLMs, thereby outlining a\npragmatic philosophical context for LLMs as an increasingly prominent\ntechnology in society.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dijk_B/0/1/0/all/0/1\">Bram M.A. van Dijk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouwenhoven_T/0/1/0/all/0/1\">Tom Kouwenhoven</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1\">Marco R. Spruit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duijn_M/0/1/0/all/0/1\">Max J. van Duijn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MoCa: Measuring Human-Language Model Alignment on Causal and Moral Judgment Tasks. (arXiv:2310.19677v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19677","description":"<p>Human commonsense understanding of the physical and social world is organized\naround intuitive theories. These theories support making causal and moral\njudgments. When something bad happens, we naturally ask: who did what, and why?\nA rich literature in cognitive science has studied people's causal and moral\nintuitions. This work has revealed a number of factors that systematically\ninfluence people's judgments, such as the violation of norms and whether the\nharm is avoidable or inevitable. We collected a dataset of stories from 24\ncognitive science papers and developed a system to annotate each story with the\nfactors they investigated. Using this dataset, we test whether large language\nmodels (LLMs) make causal and moral judgments about text-based scenarios that\nalign with those of human participants. On the aggregate level, alignment has\nimproved with more recent LLMs. However, using statistical analyses, we find\nthat LLMs weigh the different factors quite differently from human\nparticipants. These results show how curated, challenge datasets combined with\ninsights from cognitive science can help us go beyond comparisons based merely\non aggregate metrics: we uncover LLMs implicit tendencies and show to what\nextent these align with human intuitions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nie_A/0/1/0/all/0/1\">Allen Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amdekar_A/0/1/0/all/0/1\">Atharva Amdekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piech_C/0/1/0/all/0/1\">Chris Piech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstenberg_T/0/1/0/all/0/1\">Tobias Gerstenberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Combining Language Models For Specialized Domains: A Colorful Approach. (arXiv:2310.19708v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19708","description":"<p>General purpose language models (LMs) encounter difficulties when processing\ndomain-specific jargon and terminology, which are frequently utilized in\nspecialized fields such as medicine or industrial settings. Moreover, they\noften find it challenging to interpret mixed speech that blends general\nlanguage with specialized jargon. This poses a challenge for automatic speech\nrecognition systems operating within these specific domains. In this work, we\nintroduce a novel approach that integrates domain-specific or secondary LM into\ngeneral-purpose LM. This strategy involves labeling, or ``coloring'', each word\nto indicate its association with either the general or the domain-specific LM.\nWe develop an optimized algorithm that enhances the beam search algorithm to\neffectively handle inferences involving colored words. Our evaluations indicate\nthat this approach is highly effective in integrating jargon into language\ntasks. Notably, our method substantially lowers the error rate for\ndomain-specific words without compromising performance in the general domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eitan_D/0/1/0/all/0/1\">Daniel Eitan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pirchi_M/0/1/0/all/0/1\">Menachem Pirchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glazer_N/0/1/0/all/0/1\">Neta Glazer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meital_S/0/1/0/all/0/1\">Shai Meital</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayach_G/0/1/0/all/0/1\">Gil Ayach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shamsian_A/0/1/0/all/0/1\">Aviv Shamsian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1\">Aviv Navon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hetz_G/0/1/0/all/0/1\">Gil Hetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keshet_J/0/1/0/all/0/1\">Joseph Keshet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Large Language Models: A Comprehensive Survey. (arXiv:2310.19736v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.19736","description":"<p>Large language models (LLMs) have demonstrated remarkable capabilities across\na broad spectrum of tasks. They have attracted significant attention and been\ndeployed in numerous downstream applications. Nevertheless, akin to a\ndouble-edged sword, LLMs also present potential risks. They could suffer from\nprivate data leaks or yield inappropriate, harmful, or misleading content.\nAdditionally, the rapid progress of LLMs raises concerns about the potential\nemergence of superintelligent systems without adequate safeguards. To\neffectively capitalize on LLM capacities as well as ensure their safe and\nbeneficial development, it is critical to conduct a rigorous and comprehensive\nevaluation of LLMs.\n</p>\n<p>This survey endeavors to offer a panoramic perspective on the evaluation of\nLLMs. We categorize the evaluation of LLMs into three major groups: knowledge\nand capability evaluation, alignment evaluation and safety evaluation. In\naddition to the comprehensive review on the evaluation methodologies and\nbenchmarks on these three aspects, we collate a compendium of evaluations\npertaining to LLMs' performance in specialized domains, and discuss the\nconstruction of comprehensive evaluation platforms that cover LLM evaluations\non capabilities, alignment, safety, and applicability.\n</p>\n<p>We hope that this comprehensive overview will stimulate further research\ninterests in the evaluation of LLMs, with the ultimate goal of making\nevaluation serve as a cornerstone in guiding the responsible development of\nLLMs. We envision that this will channel their evolution into a direction that\nmaximizes societal benefit while minimizing potential risks. A curated list of\nrelated papers has been publicly available at\nhttps://github.com/tjunlp-lab/Awesome-LLMs-Evaluation-Papers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zishan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Renren Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yufei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Dan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Supryadi/0/1/0/all/0/1\">Supryadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Linhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiaxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1\">Bojian Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-31T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/"}}]}]}