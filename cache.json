{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2022-12-21T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Human-in-the-loop Abstractive Dialogue Summarization. (arXiv:2212.09750v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09750","description":"<p>Abstractive dialogue summarization has received increasing attention\nrecently. Despite the fact that most of the current dialogue summarization\nsystems are trained to maximize the likelihood of human-written summaries and\nhave achieved significant results, there is still a huge gap in generating\nhigh-quality summaries as determined by humans, such as coherence and\nfaithfulness, partly due to the misalignment in maximizing a single\nhuman-written summary. To this end, we propose to incorporate different levels\nof human feedback into the training process. This will enable us to guide the\nmodels to capture the behaviors humans care about for summaries. Specifically,\nwe ask humans to highlight the salient information to be included in summaries\nto provide the local feedback , and to make overall comparisons among summaries\nin terms of coherence, accuracy, coverage, concise and overall quality, as the\nglobal feedback. We then combine both local and global feedback to fine-tune\nthe dialog summarization policy with Reinforcement Learning. Experiments\nconducted on multiple datasets demonstrate the effectiveness and generalization\nof our methods over the state-of-the-art supervised baselines, especially in\nterms of human judgments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodda_M/0/1/0/all/0/1\">Mohan Dodda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training Trajectories of Language Models Across Scales. (arXiv:2212.09803v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09803","description":"<p>Scaling up language models has led to unprecedented performance gains, but\nlittle is understood about how the training dynamics change as models get\nlarger. How do language models of different sizes learn during pre-training?\nWhy do larger language models demonstrate more desirable behaviors? In this\npaper, we analyze the intermediate training checkpoints of differently sized\nOPT models (Zhang et al.,2022)--from 125M to 175B parameters--on next-token\nprediction, sequence-level generation, and downstream tasks. We find that 1) at\na given perplexity and independent of model sizes, a similar subset of training\ntokens see the most significant reduction in loss, with the rest stagnating or\nshowing double-descent behavior; 2) early in training, all models learn to\nreduce the perplexity of grammatical sequences that contain hallucinations,\nwith small models halting at this suboptimal distribution and larger ones\neventually learning to assign these sequences lower probabilities; 3)\nperplexity is a strong predictor of in-context learning performance on 74\nmultiple-choice tasks from BIG-Bench, and this holds independent of the model\nsize. Together, these results show that perplexity is more predictive of model\nbehaviors than model size or training computation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mengzhou Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1\">Ramakanth Pasunuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Ves Stoyanov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model. (arXiv:2212.09811v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09811","description":"<p>Compared to conventional bilingual translation systems, massively\nmultilingual machine translation is appealing because a single model can\ntranslate into multiple languages and benefit from knowledge transfer for low\nresource languages. On the other hand, massively multilingual models suffer\nfrom the curse of multilinguality, unless scaling their size massively, which\nincreases their training and inference costs. Sparse Mixture-of-Experts models\nare a way to drastically increase model capacity without the need for a\nproportional amount of computing. The recently released NLLB-200 is an example\nof such a model. It covers 202 languages but requires at least four 32GB GPUs\njust for inference. In this work, we propose a pruning method that allows the\nremoval of up to 80\\% of experts with a negligible loss in translation quality,\nwhich makes it feasible to run the model on a single 32GB GPU. Further analysis\nsuggests that our pruning metrics allow to identify language-specific experts\nand prune non-relevant experts for a given language pair.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koishekenov_Y/0/1/0/all/0/1\">Yeskendir Koishekenov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikoulina_V/0/1/0/all/0/1\">Vassilina Nikoulina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berard_A/0/1/0/all/0/1\">Alexandre Berard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What to Read in a Contract? Party-Specific Summarization of Important Obligations, Entitlements, and Prohibitions in Legal Documents. (arXiv:2212.09825v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09825","description":"<p>Legal contracts, such as employment or lease agreements, are important\ndocuments as they govern the obligations and entitlements of the various\ncontracting parties. However, these documents are typically long and written in\nlegalese resulting in lots of manual hours spent in understanding them. In this\npaper, we address the task of summarizing legal contracts for each of the\ncontracting parties, to enable faster reviewing and improved understanding of\nthem. Specifically, we collect a dataset consisting of pairwise importance\ncomparison annotations by legal experts for ~293K sentence pairs from lease\nagreements. We propose a novel extractive summarization system to automatically\nproduce a summary consisting of the most important obligations, entitlements,\nand prohibitions in a contract. It consists of two modules: (1) a content\ncategorize to identify sentences containing each of the categories (i.e.,\nobligation, entitlement, and prohibition) for a party, and (2) an importance\nranker to compare the importance among sentences of each category for a party\nto obtain a ranked list. The final summary is produced by selecting the most\nimportant sentences of a category for each of the parties. We demonstrate the\neffectiveness of our proposed system by comparing it against several text\nranking baselines via automatic and human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sancheti_A/0/1/0/all/0/1\">Abhilasha Sancheti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garimella_A/0/1/0/all/0/1\">Aparna Garimella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balaji Vasan Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudinger_R/0/1/0/all/0/1\">Rachel Rudinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental Health Status on Social Media. (arXiv:2212.09839v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09839","description":"<p>In recent years, there has been a surge of interest in research on automatic\nmental health detection (MHD) from social media data leveraging advances in\nnatural language processing and machine learning techniques. While significant\nprogress has been achieved in this interdisciplinary research area, the vast\nmajority of work has treated MHD as a binary classification task. The\nmulticlass classification setup is, however, essential if we are to uncover the\nsubtle differences among the statistical patterns of language use associated\nwith particular mental health conditions. Here, we report on experiments aimed\nat predicting six conditions (anxiety, attention deficit hyperactivity\ndisorder, bipolar disorder, post-traumatic stress disorder, depression, and\npsychological stress) from Reddit social media posts. We explore and compare\nthe performance of hybrid and ensemble models leveraging transformer-based\narchitectures (BERT and RoBERTa) and BiLSTM neural networks trained on\nwithin-text distributions of a diverse set of linguistic features. This set\nencompasses measures of syntactic complexity, lexical sophistication and\ndiversity, readability, and register-specific ngram frequencies, as well as\nsentiment and emotion lexicons. In addition, we conduct feature ablation\nexperiments to investigate which types of features are most indicative of\nparticular mental health conditions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zanwar_S/0/1/0/all/0/1\">Sourabh Zanwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiechmann_D/0/1/0/all/0/1\">Daniel Wiechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1\">Elma Kerz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"(Psycho-)Linguistic Features Meet Transformer Models for Improved Explainable and Controllable Text Simplification. (arXiv:2212.09848v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09848","description":"<p>State-of-the-art text simplification (TS) systems adopt end-to-end neural\nnetwork models to directly generate the simplified version of the input text,\nand usually function as a blackbox. Moreover, TS is usually treated as an\nall-purpose generic task under the assumption of homogeneity, where the same\nsimplification is suitable for all. In recent years, however, there has been\nincreasing recognition of the need to adapt the simplification techniques to\nthe specific needs of different target groups. In this work, we aim to advance\ncurrent research on explainable and controllable TS in two ways: First,\nbuilding on recently proposed work to increase the transparency of TS systems,\nwe use a large set of (psycho-)linguistic features in combination with\npre-trained language models to improve explainable complexity prediction.\nSecond, based on the results of this preliminary task, we extend a\nstate-of-the-art Seq2Seq TS model, ACCESS, to enable explicit control of ten\nattributes. The results of experiments show (1) that our approach improves the\nperformance of state-of-the-art models for predicting explainable complexity\nand (2) that explicitly conditioning the Seq2Seq model on ten attributes leads\nto a significant improvement in performance in both within-domain and\nout-of-domain settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaofei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiechmann_D/0/1/0/all/0/1\">Daniel Wiechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1\">Elma Kerz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dataless Knowledge Fusion by Merging Weights of Language Models. (arXiv:2212.09849v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09849","description":"<p>Fine-tuning pre-trained language models has become the prevalent paradigm for\nbuilding downstream NLP models. Oftentimes fine-tuned models are readily\navailable but their training data is not, due to data privacy or intellectual\nproperty concerns. This creates a barrier to fusing knowledge across individual\nmodels to yield a better single model. In this paper, we study the problem of\nmerging individual models built on different training data sets to obtain a\nsingle model that performs well both across all data set domains and can\ngeneralize on out-of-domain data. We propose a dataless knowledge fusion method\nthat merges models in their parameter space, guided by weights that minimize\nprediction differences between the merged model and the individual models. Over\na battery of evaluation settings, we show that the proposed method\nsignificantly outperforms baselines such as Fisher-weighted averaging or model\nensembling. Further, we find that our method is a promising alternative to\nmulti-task learning that can preserve or sometimes improve over the individual\nmodels without access to the training data. Finally, model merging is more\nefficient than training a multi-task model, thus making it applicable to a\nwider set of scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xisen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preotiuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pengxiang Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MANTIS at TSAR-2022 Shared Task: Improved Unsupervised Lexical Simplification with Pretrained Encoders. (arXiv:2212.09855v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09855","description":"<p>In this paper we present our contribution to the TSAR-2022 Shared Task on\nLexical Simplification of the EMNLP 2022 Workshop on Text Simplification,\nAccessibility, and Readability. Our approach builds on and extends the\nunsupervised lexical simplification system with pretrained encoders (LSBert)\nsystem in the following ways: For the subtask of simplification candidate\nselection, it utilizes a RoBERTa transformer language model and expands the\nsize of the generated candidate list. For subsequent substitution ranking, it\nintroduces a new feature weighting scheme and adopts a candidate filtering\nmethod based on textual entailment to maximize semantic similarity between the\ntarget word and its simplification. Our best-performing system improves LSBert\nby 5.9% accuracy and achieves second place out of 33 ranked solutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaofei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiechmann_D/0/1/0/all/0/1\">Daniel Wiechmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerz_E/0/1/0/all/0/1\">Elma Kerz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continuous Semi-Supervised Nonnegative Matrix Factorization. (arXiv:2212.09858v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09858","description":"<p>Nonnegative matrix factorization can be used to automatically detect topics\nwithin a corpus in an unsupervised fashion. The technique amounts to an\napproximation of a nonnegative matrix as the product of two nonnegative\nmatrices of lower rank. In this paper, we show this factorization can be\ncombined with regression on a continuous response variable. In practice, the\nmethod performs better than regression done after topics are identified and\nretrains interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lindstrom_M/0/1/0/all/0/1\">Michael R. Lindstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiaofu Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Feng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somayajula_A/0/1/0/all/0/1\">Anand Somayajula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Needell_D/0/1/0/all/0/1\">Deanna Needell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Pre-Training Tasks for Neural Machine Translation. (arXiv:2212.09864v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09864","description":"<p>Pre-training is an effective technique for ensuring robust performance on a\nvariety of machine learning tasks. It typically depends on large-scale crawled\ncorpora that can result in toxic or biased models. Such data can also be\nproblematic with respect to copyright, attribution, and privacy. Pre-training\nwith synthetic tasks and data is a promising way of alleviating such concerns\nsince no real-world information is ingested by the model. Our goal in this\npaper is to understand what makes for a good pre-trained model when using\nsynthetic resources. We answer this question in the context of neural machine\ntranslation by considering two novel approaches to translation model\npre-training. Our first approach studies the effect of pre-training on\nobfuscated data derived from a parallel corpus by mapping words to a vocabulary\nof 'nonsense' tokens. Our second approach explores the effect of pre-training\non procedurally generated synthetic parallel data that does not depend on any\nreal human language corpus. Our empirical evaluation on multiple language pairs\nshows that, to a surprising degree, the benefits of pre-training can be\nrealized even with obfuscated or purely synthetic parallel data. In our\nanalysis, we consider the extent to which obfuscated and synthetic pre-training\ntechniques can be used to mitigate the issue of hallucinated model toxicity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zexue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blackwood_G/0/1/0/all/0/1\">Graeme Blackwood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1\">Rameswar Panda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations. (arXiv:2212.09865v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09865","description":"<p>Although large language models can be prompted for both zero- and few-shot\nlearning, performance drops significantly when no demonstrations are available.\nIn this paper, we introduce Z-ICL, a new zero-shot method that closes the gap\nby constructing pseudo-demonstrations for a given test input using a raw text\ncorpus. Concretely, pseudo-demonstrations are constructed by (1) finding the\nnearest neighbors to the test input from the corpus and pairing them with\nrandom task labels, and (2) applying a set of techniques to reduce the amount\nof direct copying the model does from the resulting demonstrations. Evaluation\non nine classification datasets shows that Z-ICL outperforms previous zero-shot\nmethods by a significant margin, and is on par with in-context learning with\nlabeled training data in the few-shot setting. Overall, Z-ICL provides a\nsignificantly higher estimate of the zero-shot performance levels of a model,\nand supports future efforts to develop better pseudo-demonstrations that\nfurther improve zero-shot results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xinxi Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beltagy_I/0/1/0/all/0/1\">Iz Beltagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting Contradictory COVID-19 Drug Efficacy Claims from Biomedical Literature. (arXiv:2212.09867v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09867","description":"<p>The COVID-19 pandemic created a deluge of questionable and contradictory\nscientific claims about drug efficacy -- an \"infodemic\" with lasting\nconsequences for science and society. In this work, we argue that NLP models\ncan help domain experts distill and understand the literature in this complex,\nhigh-stakes area. Our task is to automatically identify contradictory claims\nabout COVID-19 drug efficacy. We frame this as a natural language inference\nproblem and offer a new NLI dataset created by domain experts. The NLI framing\nallows us to create curricula combining existing datasets and our own. The\nresulting models are useful investigative tools. We provide a case study of how\nthese models help a domain expert summarize and assess evidence concerning\nremdisivir and hydroxychloroquine.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sosa_D/0/1/0/all/0/1\">Daniel N. Sosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_M/0/1/0/all/0/1\">Malavika Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altman_R/0/1/0/all/0/1\">Russ B. Altman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models. (arXiv:2212.09873v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09873","description":"<p>There is growing interest in incorporating eye-tracking data and other\nimplicit measures of human language processing into natural language processing\n(NLP) pipelines. The data from human language processing contain unique insight\ninto human linguistic understanding that could be exploited by language models.\nHowever, many unanswered questions remain about the nature of this data and how\nit can best be utilized in downstream NLP tasks. In this paper, we present\neyeStyliency, an eye-tracking dataset for human processing of stylistic text\n(e.g., politeness). We develop a variety of methods to derive style saliency\nscores over text using the collected eye dataset. We further investigate how\nthis saliency data compares to both human annotation methods and model-based\ninterpretability metrics. We find that while eye-tracking data is unique, it\nalso intersects with both human annotations and model-based importance scores,\nproviding a possible bridge between human- and machine-based perspectives. In\ndownstream few-shot learning tasks, adding salient words to prompts generally\nimproved style classification, with eye-tracking-based and annotation-based\nsalient words achieving the highest accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Langis_K/0/1/0/all/0/1\">Karin de Langis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsigned Play by Milan Kundera? An Authorship Attribution Study. (arXiv:2212.09879v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09879","description":"<p>In addition to being a widely recognised novelist, Milan Kundera has also\nauthored three pieces for theatre: The Owners of the Keys (Majitel\\'e\nkl\\'i\\v{c}\\r{u}, 1961), The Blunder (Pt\\'akovina, 1967), and Jacques and his\nMaster (Jakub a jeho p\\'an, 1971). In recent years, however, the hypothesis has\nbeen raised that Kundera is the true author of a fourth play: Juro\nJ\\'ano\\v{s}\\'ik, first performed in a 1974 production under the name of Karel\nSteigerwald, who was Kundera's student at the time. In this study, we make use\nof supervised machine learning to settle the question of authorship attribution\nin the case of Juro J\\'ano\\v{s}\\'ik, with results strongly supporting the\nhypothesis of Kundera's authorship.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jungmannova_L/0/1/0/all/0/1\">Lenka Jungmannov&#xe1;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plechac_P/0/1/0/all/0/1\">Petr Plech&#xe1;&#x10d;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Asking Clarification Questions for Code Generation in General-Purpose Programming Language. (arXiv:2212.09885v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09885","description":"<p>Code generation from text requires understanding the user's intent from a\nnatural language description (NLD) and generating an executable program code\nsnippet that satisfies this intent. While recent pretrained language models\n(PLMs) demonstrate remarkable performance for this task, these models fail when\nthe given NLD is ambiguous due to the lack of enough specifications for\ngenerating a high-quality code snippet. In this work, we introduce a novel and\nmore realistic setup for this task. We hypothesize that ambiguities in the\nspecifications of an NLD are resolved by asking clarification questions (CQs).\nTherefore, we collect and introduce a new dataset named CodeClarQA containing\nNLD-Code pairs with created CQAs. We evaluate the performance of PLMs for code\ngeneration on our dataset. The empirical results support our hypothesis that\nclarifications result in more precise generated code, as shown by an\nimprovement of 17.52 in BLEU, 12.72 in CodeBLEU, and 7.7\\% in the exact match.\nAlongside this, our task and dataset introduce new challenges to the community,\nincluding when and what CQs should be asked.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haau-Sing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mesgar_M/0/1/0/all/0/1\">Mohsen Mesgar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Long-Form Spoken Language Translation with Large Language Models. (arXiv:2212.09895v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09895","description":"<p>A challenge in spoken language translation is that plenty of spoken content\nis long-form, but short units are necessary for obtaining high-quality\ntranslations. To address this mismatch, we fine-tune a general-purpose, large\nlanguage model to split long ASR transcripts into segments that can be\nindependently translated so as to maximize the overall translation quality. We\ncompare to several segmentation strategies and find that our approach improves\nBLEU score on three languages by an average of 2.7 BLEU overall compared to an\nautomatic punctuation baseline. Further, we demonstrate the effectiveness of\ntwo constrained decoding strategies to improve well-formedness of the model\noutput from above 99% to 100%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McCarthy_A/0/1/0/all/0/1\">Arya D. McCarthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shankar Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stahlberg_F/0/1/0/all/0/1\">Felix Stahlberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1\">Axel H. Ng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inducing Character-level Structure in Subword-based Language Models with Type-level Interchange Intervention Training. (arXiv:2212.09897v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09897","description":"<p>Language tasks involving character-level manipulations (e.g., spelling\ncorrection, many word games) are challenging for models based in subword\ntokenization. To address this, we adapt the interchange intervention training\nmethod of Geiger et al. (2021) to operate on type-level variables over\ncharacters. This allows us to encode robust, position-independent\ncharacter-level information in the internal representations of subword-based\nmodels. We additionally introduce a suite of character-level tasks that\nsystematically vary in their dependence on meaning and sequence-level context.\nWhile simple character-level tokenization approaches still perform best on\npurely form-based tasks like string reversal, our method is superior for more\ncomplex tasks that blend form, meaning, and context, such as spelling\ncorrection in context and word search games. Our approach also leads to\nsubword-based models with human-intepretable internal representations of\ncharacters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhengxuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks. (arXiv:2212.09912v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09912","description":"<p>Generative models have been widely applied to solve extractive tasks, where\nparts of the input is extracted to form the desired output, and achieved\nsignificant success. For example, in extractive question answering (QA),\ngenerative models have constantly yielded state-of-the-art results. In this\nwork, we identify the issue of tokenization inconsistency that is commonly\nneglected in training these models. This issue damages the extractive nature of\nthese tasks after the input and output are tokenized inconsistently by the\ntokenizer, and thus leads to performance drop as well as hallucination. We\npropose a simple yet effective fix to this issue and conduct a case study on\nextractive QA. We show that, with consistent tokenization, the model performs\nbetter in both in-domain and out-of-domain datasets, with a notable average of\n+1.7 F2 gain when a BART model is trained on SQuAD and evaluated on 8 QA\ndatasets. Further, the model converges faster, and becomes less likely to\ngenerate out-of-context answers. With these findings, we would like to call for\nmore attention on how tokenization should be done when solving extractive tasks\nand recommend applying consistent tokenization during training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1\">Kaiser Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1\">Peng Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiheng Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inverse Reinforcement Learning for Text Summarization. (arXiv:2212.09917v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09917","description":"<p>Current state-of-the-art summarization models are trained with either maximum\nlikelihood estimation (MLE) or reinforcement learning (RL). In this study, we\ninvestigate the third training paradigm and argue that inverse reinforcement\nlearning (IRL) may be more suitable for text summarization. IRL focuses on\nestimating the reward function of an agent, given a set of observations of that\nagent's behavior. Generally, IRL provides advantages in situations where the\nreward function is not explicitly known or where it is difficult to define or\ninteract with the environment directly. These situations are exactly what we\nobserve in summarization. Thus, we introduce inverse reinforcement learning\ninto text summarization and define a suite of sub-rewards that are important\nfor summarization optimization. By simultaneously estimating the reward\nfunction and optimizing the summarization agent with expert demonstrations, we\nshow that the model trained with IRL produces summaries that closely follow\nhuman behavior, in terms of better ROUGE, coverage, novelty, compression ratio\nand factuality when compared to the baselines trained with MLE and RL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yu Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yue Dong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving the Robustness of Summarization Models by Detecting and Removing Input Noise. (arXiv:2212.09928v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09928","description":"<p>The evaluation of abstractive summarization models typically uses test data\nthat is identically distributed as training data. In real-world practice,\ndocuments to be summarized may contain input noise caused by text extraction\nartifacts or data pipeline bugs. The robustness of model performance under\ndistribution shift caused by such noise is relatively under-studied. We present\na large empirical study quantifying the sometimes severe loss in performance\n(up to 12 ROUGE-1 points) from different types of input noise for a range of\ndatasets and model sizes. We then propose a light-weight method for detecting\nand removing such noise in the input during model inference without requiring\nany extra training, auxiliary models, or even prior knowledge of the type of\nnoise. Our proposed approach effectively mitigates the loss in performance,\nrecovering a large fraction of the performance drop, sometimes as large as 11\nROUGE-1 points.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_K/0/1/0/all/0/1\">Kundan Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Jie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1\">Balaji Lakshminarayanan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiaming Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_M/0/1/0/all/0/1\">Mohammad Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peter J. Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AnyTOD: A Programmable Task-Oriented Dialog System. (arXiv:2212.09939v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09939","description":"<p>We propose AnyTOD, an end-to-end task-oriented dialog (TOD) system with\nzero-shot capability for unseen tasks. We view TOD as a program executed by a\nlanguage model (LM), where program logic and ontology is provided by a designer\nin the form of a schema. To enable generalization onto unseen schemas and\nprograms without prior training, AnyTOD adopts a neuro-symbolic approach. A\nneural LM keeps track of events that occur during a conversation, and a\nsymbolic program implementing the dialog policy is executed to recommend next\nactions AnyTOD should take. This approach drastically reduces data annotation\nand model training requirements, addressing a long-standing challenge in TOD\nresearch: rapidly adapting a TOD system to unseen tasks and domains. We\ndemonstrate state-of-the-art results on the STAR and ABCD benchmarks, as well\nas AnyTOD's strong zero-shot transfer capability in low-resource settings. In\naddition, we release STARv2, an updated version of the STAR dataset with richer\ndata annotations, for benchmarking zero-shot end-to-end TOD models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jeffrey Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Raghav Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Harrison Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1\">Abhinav Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingqiu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soltau_H/0/1/0/all/0/1\">Hagen Soltau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafran_I/0/1/0/all/0/1\">Izhak Shafran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yonghui Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialog2API: Task-Oriented Dialogue with API Description and Example Programs. (arXiv:2212.09946v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09946","description":"<p>Functionality and dialogue experience are two important factors of\ntask-oriented dialogue systems. Conventional approaches with closed schema\n(e.g., conversational semantic parsing) often fail as both the functionality\nand dialogue experience are strongly constrained by the underlying schema. We\nintroduce a new paradigm for task-oriented dialogue - Dialog2API - to greatly\nexpand the functionality and provide seamless dialogue experience. The\nconversational model interacts with the environment by generating and executing\nprograms triggering a set of pre-defined APIs. The model also manages the\ndialogue policy and interact with the user through generating appropriate\nnatural language responses. By allowing generating free-form programs,\nDialog2API supports composite goals by combining different APIs, whereas\nunrestricted program revision provides natural and robust dialogue experience.\nTo facilitate Dialog2API, the core model is provided with API documents, an\nexecution environment and optionally some example dialogues annotated with\nprograms. We propose an approach tailored for the Dialog2API, where the\ndialogue states are represented by a stack of programs, with most recently\nmentioned program on the top of the stack. Dialog2API can work with many\napplication scenarios such as software automation and customer service. In this\npaper, we construct a dataset for AWS S3 APIs and present evaluation results of\nin-context learning baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shu_R/0/1/0/all/0/1\">Raphael Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansimov_E/0/1/0/all/0/1\">Elman Mansimov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhouli_T/0/1/0/all/0/1\">Tamer Alkhouli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pappas_N/0/1/0/all/0/1\">Nikolaos Pappas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romeo_S/0/1/0/all/0/1\">Salvatore Romeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Arshit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansour_S/0/1/0/all/0/1\">Saab Mansour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Future Sight: Dynamic Story Generation with Large Pretrained Language Models. (arXiv:2212.09947v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09947","description":"<p>Recent advances in deep learning research, such as transformers, have\nbolstered the ability for automated agents to generate creative texts similar\nto those that a human would write. By default, transformer decoders can only\ngenerate new text with respect to previously generated text. The output\ndistribution of candidate tokens at any position is conditioned on previously\nselected tokens using a self-attention mechanism to emulate the property of\nautoregression. This is inherently limiting for tasks such as controllable\nstory generation where it may be necessary to condition on future plot events\nwhen writing a story. In this work, we propose Future Sight, a method for\nfinetuning a pretrained generative transformer on the task of future\nconditioning. Transformer decoders are typically pretrained on the task of\ncompleting a context, one token at a time, by means of self-attention. Future\nSight additionally enables a decoder to attend to an encoded future plot event.\nThis motivates the decoder to expand on the context in a way that logically\nconcludes with the provided future. During inference, the future plot event can\nbe written by a human author to steer the narrative being generated in a\ncertain direction. We evaluate the efficacy of our approach on a story\ngeneration task with human evaluators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zimmerman_B/0/1/0/all/0/1\">Brian D. Zimmerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechtomova_O/0/1/0/all/0/1\">Olga Vechtomova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of Faithfulness Metrics. (arXiv:2212.09955v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09955","description":"<p>The proliferation of automatic faithfulness metrics for summarization has\nproduced a need for benchmarks to evaluate them. While existing benchmarks\nmeasure the correlation with human judgements of faithfulness on\nmodel-generated summaries, they are insufficient for diagnosing whether metrics\nare: 1) consistent, i.e., decrease as errors are introduced into a summary, 2)\neffective on human-written texts, and 3) sensitive to different error types (as\nsummaries can contain multiple errors). To address these needs, we present a\nbenchmark of unfaithful minimal pairs (BUMP), a dataset of 889 human-written,\nminimally different summary pairs, where a single error (from an ontology of 7\ntypes) is introduced to a summary from the CNN/DailyMail dataset to produce an\nunfaithful summary. We find BUMP complements existing benchmarks in a number of\nways: 1) the summaries in BUMP are harder to discriminate and less probable\nunder SOTA summarization models, 2) BUMP enables measuring the consistency of\nmetrics, and reveals that the most discriminative metrics tend not to be the\nmost consistent, 3) BUMP enables the measurement of metrics' performance on\nindividual error types and highlights areas of weakness for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Liang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Shuyang Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Logan_R/0/1/0/all/0/1\">Robert L. Logan IV</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">Di Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ran_S/0/1/0/all/0/1\">Shihao Ran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Ke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tetreault_J/0/1/0/all/0/1\">Joel Tetreault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahill_A/0/1/0/all/0/1\">Aoife Cahill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaimes_A/0/1/0/all/0/1\">Alejandro Jaimes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Improving Summarization Factual Consistency from Natural Language Feedback. (arXiv:2212.09968v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09968","description":"<p>Despite the recent progress in language generation models, their outputs may\nnot always meet user expectations. In this work, we study whether informational\nfeedback in natural language can be leveraged to improve generation quality and\nuser preference alignment. To this end, we consider factual consistency in\nsummarization, the quality that the summary should only contain information\nsupported by the input documents, for user preference alignment. We collect a\nhigh-quality dataset, DeFacto, containing human demonstrations and\ninformational feedback in natural language consisting of corrective\ninstructions, edited summaries, and explanations with respect to the factual\nconsistency of the summary. Using our dataset, we study two natural language\ngeneration tasks: 1) editing a summary using the human feedback, and 2)\ngenerating human feedback from the original summary. Using the two tasks, we\nfurther evaluate if models can automatically correct factual inconsistencies in\ngenerated summaries. We show that the human-edited summaries we collected are\nmore factually consistent, and pre-trained language models can leverage our\ndataset to improve the factual consistency of original system-generated\nsummaries in our proposed generation tasks. We make the DeFacto dataset\npublicly available at https://github.com/microsoft/DeFacto.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1\">Budhaditya Deb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teruel_M/0/1/0/all/0/1\">Milagro Teruel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halfaker_A/0/1/0/all/0/1\">Aaron Halfaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed H. Awadallah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Speech Transcription and Translation: Pseudo-Labeling with Out-of-Distribution Data. (arXiv:2212.09982v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09982","description":"<p>Self-training has been shown to be helpful in addressing data scarcity for\nmany domains, including vision, speech, and language. Specifically,\nself-training, or pseudo-labeling, labels unsupervised data and adds that to\nthe training pool. In this work, we investigate and use pseudo-labeling for a\nrecently proposed novel setup: joint transcription and translation of speech,\nwhich suffers from an absence of sufficient data resources. We show that under\nsuch data-deficient circumstances, the unlabeled data can significantly vary in\ndomain from the supervised data, which results in pseudo-label quality\ndegradation. We investigate two categories of remedies that require no\nadditional supervision and target the domain mismatch: pseudo-label filtering\nand data augmentation. We show that pseudo-label analysis and processing as\nsuch results in additional gains on top of the vanilla pseudo-labeling setup\nresulting in total improvements of up to 0.6% absolute WER and 2.2 BLEU points.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gheini_M/0/1/0/all/0/1\">Mozhdeh Gheini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1\">Tatiana Likhomanenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperber_M/0/1/0/all/0/1\">Matthias Sperber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Setiawan_H/0/1/0/all/0/1\">Hendra Setiawan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Robustness of Text-to-SQL Models Against Natural and Realistic Adversarial Table Perturbation. (arXiv:2212.09994v1 [cs.CL])","link":"http://arxiv.org/abs/2212.09994","description":"<p>The robustness of Text-to-SQL parsers against adversarial perturbations plays\na crucial role in delivering highly reliable applications. Previous studies\nalong this line primarily focused on perturbations in the natural language\nquestion side, neglecting the variability of tables. Motivated by this, we\npropose the Adversarial Table Perturbation (ATP) as a new attacking paradigm to\nmeasure the robustness of Text-to-SQL models. Following this proposition, we\ncurate ADVETA, the first robustness evaluation benchmark featuring natural and\nrealistic ATPs. All tested state-of-the-art models experience dramatic\nperformance drops on ADVETA, revealing models' vulnerability in real-world\npractices. To defend against ATP, we build a systematic adversarial training\nexample generation framework tailored for better contextualization of tabular\ndata. Experiments show that our approach not only brings the best robustness\nimprovement against table-side perturbations but also substantially empowers\nmodels against NL-side perturbations. We release our benchmark and code at:\nhttps://github.com/microsoft/ContextualSP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pi_X/0/1/0/all/0/1\">Xinyu Pi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jiaqi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of What Matters. (arXiv:2212.10001v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10001","description":"<p>Chain-of-Thought (CoT) prompting can dramatically improve the multi-step\nreasoning abilities of large language models (LLMs). CoT explicitly encourages\nthe LLM to generate intermediate rationales for solving a problem, by providing\na series of reasoning steps in the demonstrations. Despite its success, there\nis still little understanding of what makes CoT prompting effective and which\naspects of the demonstrated reasoning steps contribute to its performance. In\nthis paper, we show that CoT reasoning is possible even with invalid\ndemonstrations - prompting with invalid reasoning steps can achieve over 80-90%\nof the performance obtained using CoT under various metrics, while still\ngenerating coherent lines of reasoning during inference. Further experiments\nshow that other aspects of the rationales, such as being relevant to the query\nand correctly ordering the reasoning steps, are much more important for\neffective CoT reasoning. Overall, these findings both deepen our understanding\nof CoT prompting, and open up new questions regarding LLMs' capability to learn\nto reason in context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boshi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jiaming Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">You Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Defending Against Poisoning Attacks in Open-Domain Question Answering. (arXiv:2212.10002v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10002","description":"<p>Recent work in open-domain question answering (ODQA) has shown that\nadversarial poisoning of the input contexts can cause large drops in accuracy\nfor production systems. However, little to no work has proposed methods to\ndefend against these attacks. To do so, we introduce a new method that uses\nquery augmentation to search for a diverse set of retrieved passages that could\nanswer the original question. We integrate these new passages into the model\nthrough the design of a novel confidence method, comparing the predicted answer\nto its appearance in the retrieved contexts (what we call Confidence from\nAnswer Redundancy, e.g. CAR). Together these methods allow for a simple but\neffective way to defend against poisoning attacks and provide gains of 5-20%\nexact match across varying levels of data poisoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weller_O/0/1/0/all/0/1\">Orion Weller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Aleem Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weir_N/0/1/0/all/0/1\">Nathaniel Weir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrie_D/0/1/0/all/0/1\">Dawn Lawrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"(QA)$^2$: Question Answering with Questionable Assumptions. (arXiv:2212.10003v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10003","description":"<p>Naturally-occurring information-seeking questions often contain questionable\nassumptions -- assumptions that are false or unverifiable. Questions containing\nquestionable assumptions are challenging because they require a distinct answer\nstrategy that deviates from typical answers to information-seeking questions.\nFor instance, the question \"When did Marie Curie discover Uranium?\" cannot be\nanswered as a typical when question without addressing the false assumption\n\"Marie Curie discovered Uranium\". In this work, we propose (QA)$^2$ (Question\nAnswering with Questionable Assumptions), an open-domain evaluation dataset\nconsisting of naturally-occurring search engine queries that may or may not\ncontain questionable assumptions. To be successful on (QA)$^2$, systems must be\nable to detect questionable assumptions and also be able to produce adequate\nresponses for both typical information-seeking questions and ones with\nquestionable assumptions. We find that current models do struggle with handling\nquestionable assumptions -- the best performing model achieves 59% human rater\nacceptability on abstractive QA with (QA)$^2$ questions, leaving substantial\nheadroom for progress.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Htut_P/0/1/0/all/0/1\">Phu Mon Htut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petty_J/0/1/0/all/0/1\">Jackson Petty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file Context. (arXiv:2212.10007v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10007","description":"<p>While pre-trained language models (LM) for code have achieved great success\nin code completion, they generate code conditioned only on the contents within\nthe file, i.e., in-file context, but ignore the rich semantics in other files\nwithin the same project, i.e., cross-file context, a critical source of\ninformation that is especially useful in modern modular software development.\nSuch overlooking constrains code language models' capacity in code completion,\nleading to unexpected behaviors such as generating hallucinated class member\nfunctions or function calls with unexpected arguments. In this work, we develop\na cross-file context finder tool, CCFINDER, that effectively locates and\nretrieves the most relevant cross-file context. We propose CoCoMIC, a framework\nthat incorporates cross-file context to learn the in-file and cross-file\ncontext jointly on top of pretrained code LMs. CoCoMIC successfully improves\nthe existing code LM with a 19.30% relative increase in exact match and a\n15.41% relative increase in identifier matching for code completion when the\ncross-file context is provided.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yangruibo Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_M/0/1/0/all/0/1\">Murali Krishna Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallapati_R/0/1/0/all/0/1\">Ramesh Nallapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_P/0/1/0/all/0/1\">Parminder Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog. (arXiv:2212.10008v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10008","description":"<p>Many efforts have been made to construct dialog systems for different types\nof conversations, such as task-oriented dialog (TOD) and open-domain dialog\n(ODD). To better mimic human-level conversations that usually fuse various\ndialog modes, it is essential to build a system that can effectively handle\nboth TOD and ODD and access different knowledge sources. To address the lack of\navailable data for the fused task, we propose a framework for automatically\ngenerating dialogues that combine knowledge-grounded ODDs and TODs in various\nsettings. Additionally, we introduce a unified model PivotBot that is capable\nof appropriately adopting TOD and ODD modes and accessing different knowledge\nsources in order to effectively tackle the fused task. Evaluation results\ndemonstrate the superior ability of the proposed model to switch seamlessly\nbetween TOD and ODD tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Miaoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PLUE: Language Understanding Evaluation Benchmark for Privacy Policies in English. (arXiv:2212.10011v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10011","description":"<p>Privacy policies provide individuals with information about their rights and\nhow their personal information is handled. Natural language understanding (NLU)\ntechnologies can support individuals and practitioners to understand better\nprivacy practices described in lengthy and complex documents. However, existing\nefforts that use NLU technologies are limited by processing the language in a\nway exclusive to a single task focusing on certain privacy practices. To this\nend, we introduce the Privacy Policy Language Understanding Evaluation (PLUE)\nbenchmark, a multi-task benchmark for evaluating the privacy policy language\nunderstanding across various tasks. We also collect a large corpus of privacy\npolicies to enable privacy policy domain-specific language model pre-training.\nWe demonstrate that domain-specific pre-training offers performance\nimprovements across all tasks. We release the benchmark to encourage future\nresearch in this domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1\">Jianfeng Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Modeling with Latent Situations. (arXiv:2212.10012v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10012","description":"<p>Language models (LMs) often generate incoherent outputs: they refer to events\nand entity states that are incompatible with the state of the world described\nin their inputs. We introduce SituationSupervision, a family of approaches for\nimproving coherence in LMs by training them to construct and condition on\nexplicit representations of entities and their states. SituationSupervision has\ntwo components: an auxiliary situation modeling task that trains models to\npredict state representations in context, and a latent state inference\nprocedure that imputes these states from partially annotated training data.\nSituationSupervision can be applied to both fine-tuning (by supervising LMs to\nencode state variables in their hidden representations) and prompting (by\ninducing LMs to interleave textual descriptions of entity states with output\ntext). In both cases, SituationSupervision requires only a small number of\nstate annotations to produce major coherence improvements (between 4-11%),\nshowing that standard LMs can be sample-efficiently trained to model not just\nlanguage but the situations it describes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Belinda Z. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1\">Maxwell Nye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DocAsRef: A Pilot Empirical Study on Repurposing Reference-Based Summary Quality Metrics Reference-Freely. (arXiv:2212.10013v1 [cs.AI])","link":"http://arxiv.org/abs/2212.10013","description":"<p>Summary quality assessment metrics have two categories: reference-based and\nreference-free. Reference-based metrics are theoretically more accurate but are\nlimited by the availability and quality of the human-written references, which\nare both difficulty to ensure. This inspires the development of reference-free\nmetrics, which are independent from human-written references, in the past few\nyears. However, existing reference-free metrics cannot be both zero-shot and\naccurate. In this paper, we propose a zero-shot but accurate reference-free\napproach in a sneaky way: feeding documents, based upon which summaries\ngenerated, as references into reference-based metrics. Experimental results\nshow that this zero-shot approach can give us the best-performing\nreference-free metrics on nearly all aspects on several recently-released\ndatasets, even beating reference-free metrics specifically trained for this\ntask sometimes. We further investigate what reference-based metrics can benefit\nfrom such repurposing and whether our additional tweaks help.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1\">Forrest Sheng Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_R/0/1/0/all/0/1\">Ruixuan Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1\">Ge Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Spatial Relationships in Text-to-Image Generation. (arXiv:2212.10015v1 [cs.CV])","link":"http://arxiv.org/abs/2212.10015","description":"<p>Spatial understanding is a fundamental aspect of computer vision and integral\nfor human-level reasoning about images, making it an important component for\ngrounded language understanding. While recent large-scale text-to-image\nsynthesis (T2I) models have shown unprecedented improvements in photorealism,\nit is unclear whether they have reliable spatial understanding capabilities. We\ninvestigate the ability of T2I models to generate correct spatial relationships\namong objects and present VISOR, an evaluation metric that captures how\naccurately the spatial relationship described in text is generated in the\nimage. To benchmark existing models, we introduce a large-scale challenge\ndataset SR2D that contains sentences describing two objects and the spatial\nrelationship between them. We construct and harness an automated evaluation\npipeline that employs computer vision to recognize objects and their spatial\nrelationships, and we employ it in a large-scale evaluation of T2I models. Our\nexperiments reveal a surprising finding that, although recent state-of-the-art\nT2I models exhibit high image quality, they are severely limited in their\nability to generate multiple objects or the specified spatial relations such as\nleft/right/above/below. Our analyses demonstrate several biases and artifacts\nof T2I models such as the difficulty with generating multiple objects, a bias\ntowards generating the first object mentioned, spatially inconsistent outputs\nfor equivalent relationships, and a correlation between object co-occurrence\nand spatial understanding capabilities. We conduct a human study that shows the\nalignment between VISOR and human judgment about spatial understanding. We\noffer the SR2D dataset and the VISOR metric to the community in support of T2I\nspatial reasoning research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_T/0/1/0/all/0/1\">Tejas Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palangi_H/0/1/0/all/0/1\">Hamid Palangi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nushi_B/0/1/0/all/0/1\">Besmira Nushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vineet_V/0/1/0/all/0/1\">Vibhav Vineet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamar_E/0/1/0/all/0/1\">Ece Kamar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yezhou Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DIONYSUS: A Pre-trained Model for Low-Resource Dialogue Summarization. (arXiv:2212.10018v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10018","description":"<p>Dialogue summarization has recently garnered significant attention due to its\nwide range of applications. However, existing methods for summarizing dialogues\nare suboptimal because they do not take into account the inherent structure of\ndialogue and rely heavily on labeled data, which can lead to poor performance\nin new domains. In this work, we propose DIONYSUS (dynamic input optimization\nin pre-training for dialogue summarization), a pre-trained encoder-decoder\nmodel for summarizing dialogues in any new domain. To pre-train DIONYSUS, we\ncreate two pseudo summaries for each dialogue example: one is produced by a\nfine-tuned summarization model, and the other is a collection of dialogue turns\nthat convey important information. We then choose one of these pseudo summaries\nbased on the difference in information distribution across different types of\ndialogues. This selected pseudo summary serves as the objective for\npre-training DIONYSUS using a self-supervised approach on a large dialogue\ncorpus. Our experiments show that DIONYSUS outperforms existing methods on six\ndatasets, as demonstrated by its ROUGE scores in zero-shot and few-shot\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Do Decompositions Help for Machine Reading?. (arXiv:2212.10019v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10019","description":"<p>Answering complex questions often requires multi-step reasoning in order to\nobtain the final answer. Most research into decompositions of complex questions\ninvolves open-domain systems, which have shown success in using these\ndecompositions for improved retrieval. In the machine reading setting, however,\nwork to understand when decompositions are helpful is understudied. We conduct\nexperiments on decompositions in machine reading to unify recent work in this\nspace, using a range of models and datasets. We find that decompositions can be\nhelpful in the few-shot case, giving several points of improvement in exact\nmatch scores. However, we also show that when models are given access to\ndatasets with around a few hundred or more examples, decompositions are not\nhelpful (and can actually be detrimental). Thus, our analysis implies that\nmodels can learn decompositions implicitly even with limited data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_K/0/1/0/all/0/1\">Kangda Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrie_D/0/1/0/all/0/1\">Dawn Lawrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weller_O/0/1/0/all/0/1\">Orion Weller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Blind Spots of Model-Based Evaluation Metrics for Text Generation. (arXiv:2212.10020v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10020","description":"<p>In this work, we explore a useful but often neglected methodology for\nrobustness analysis of text generation evaluation metrics: stress tests with\nsynthetic data. Basically, we design and synthesize a wide range of potential\nerrors and check whether they result in a commensurate drop in the metric\nscores. We examine a range of recently proposed evaluation metrics based on\npretrained language models, for the tasks of open-ended generation,\ntranslation, and summarization. Our experiments reveal interesting\ninsensitivities, biases, or even loopholes in existing metrics. For example, we\nfind that BERTScore ignores truncation errors in summarization, and MAUVE\n(built on top of GPT-2) is insensitive to errors at the beginning of\ngenerations. Further, we investigate the reasons behind these blind spots and\nsuggest practical workarounds for a more reliable evaluation of text\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianle Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sachin Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Federated Learning Meets Pre-trained Language Models' Parameter-Efficient Tuning Methods. (arXiv:2212.10025v1 [cs.LG])","link":"http://arxiv.org/abs/2212.10025","description":"<p>With increasing privacy concerns on data, recent studies have made\nsignificant progress using federated learning (FL) on privacy-sensitive natural\nlanguage processing (NLP) tasks. Much literature suggests fully fine-tuning\npre-trained language models (PLMs) in the FL paradigm can mitigate the data\nheterogeneity problem and close the performance gap with centralized training.\nHowever, large PLMs bring the curse of prohibitive communication overhead and\nlocal model adaptation costs for the FL system. To this end, we introduce\nvarious parameter-efficient tuning (PETuning) methods into federated learning.\nSpecifically, we provide a holistic empirical study of representative PLMs\ntuning methods in FL. The experimental results cover the analysis of data\nheterogeneity levels, data scales, and different FL scenarios. Overall\ncommunication overhead can be significantly reduced by locally tuning and\nglobally aggregating lightweight model parameters while maintaining acceptable\nperformance in various FL settings. To facilitate the research of PETuning in\nFL, we also develop a federated tuning framework FedPETuning, which allows\npractitioners to exploit different PETuning methods under the FL training\nparadigm conveniently. The source code is available at\n\\url{https://github.com/iezhuozhuo/FedETuning/tree/deltaTuning}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuanhang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Lizhen Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do language models have coherent mental models of everyday things?. (arXiv:2212.10029v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10029","description":"<p>When people think of everyday things like an \"egg,\" they typically have a\nmental image associated with it. This commonsense knowledge helps us understand\nhow these everyday things work and how to interact with them. For example, when\nsomeone tries to make a fried egg, they know that it has a shell and that it\ncan be cracked open to reveal the egg white and yolk inside. However, if a\nsystem does not have a coherent picture of such everyday things, thinking that\nthe egg yolk surrounds the shell, then it might have to resort to ridiculous\napproaches such as trying to scrape the egg yolk off the shell into the pan. Do\nlanguage models have a coherent picture of such everyday things? To investigate\nthis, we propose a benchmark dataset consisting of 100 everyday things, their\nparts, and the relationships between these parts. We observe that\nstate-of-the-art pre-trained language models (LMs) like GPT-3 and Macaw have\nfragments of knowledge about these entities, but they fail to produce\nconsistent parts mental models. We propose a simple extension to these LMs\nwhere we apply a constraint satisfaction layer on top of raw predictions from\nLMs to produce more consistent and accurate parts mental models of everyday\nthings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuling Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1\">Bhavana Dalvi Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Twitter BERT Approach for Offensive Language Detection in Marathi. (arXiv:2212.10039v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10039","description":"<p>Automated offensive language detection is essential in combating the spread\nof hate speech, particularly in social media. This paper describes our work on\nOffensive Language Identification in low resource Indic language Marathi. The\nproblem is formulated as a text classification task to identify a tweet as\noffensive or non-offensive. We evaluate different mono-lingual and\nmulti-lingual BERT models on this classification task, focusing on BERT models\npre-trained with social media datasets. We compare the performance of MuRIL,\nMahaTweetBERT, MahaTweetBERT-Hateful, and MahaBERT on the HASOC 2022 test set.\nWe also explore external data augmentation from other existing Marathi hate\nspeech corpus HASOC 2021 and L3Cube-MahaHate. The MahaTweetBERT, a BERT model,\npre-trained on Marathi tweets when fine-tuned on the combined dataset (HASOC\n2021 + HASOC 2022 + MahaHate), outperforms all models with an F1 score of 98.43\non the HASOC 2022 test set. With this, we also provide a new state-of-the-art\nresult on HASOC 2022 / MOLD v2 test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chavan_T/0/1/0/all/0/1\">Tanmay Chavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patankar_S/0/1/0/all/0/1\">Shantanu Patankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kane_A/0/1/0/all/0/1\">Aditya Kane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokhale_O/0/1/0/all/0/1\">Omkar Gokhale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Augmentation Strategy for Visually Rich Documents. (arXiv:2212.10047v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10047","description":"<p>Many business workflows require extracting important fields from form-like\ndocuments (e.g. bank statements, bills of lading, purchase orders, etc.).\nRecent techniques for automating this task work well only when trained with\nlarge datasets. In this work we propose a novel data augmentation technique to\nimprove performance when training data is scarce, e.g. 10-250 documents. Our\ntechnique, which we call FieldSwap, works by swapping out the key phrases of a\nsource field with the key phrases of a target field to generate new synthetic\nexamples of the target field for use in training. We demonstrate that this\napproach can yield 1-7 F1 point improvements in extraction performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wendt_J/0/1/0/all/0/1\">James B. Wendt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yichao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebner_S/0/1/0/all/0/1\">Seth Ebner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tata_S/0/1/0/all/0/1\">Sandeep Tata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Framework of Customer Review Analysis Using the Aspect-Based Opinion Mining Approach. (arXiv:2212.10051v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10051","description":"<p>Opinion mining is the branch of computation that deals with opinions,\nappraisals, attitudes, and emotions of people and their different aspects. This\nfield has attracted substantial research interest in recent years. Aspect-level\n(called aspect-based opinion mining) is often desired in practical applications\nas it provides detailed opinions or sentiments about different aspects of\nentities and entities themselves, which are usually required for action. Aspect\nextraction and entity extraction are thus two core tasks of aspect-based\nopinion mining. his paper has presented a framework of aspect-based opinion\nmining based on the concept of transfer learning. on real-world customer\nreviews available on the Amazon website. The model has yielded quite\nsatisfactory results in its task of aspect-based opinion mining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1\">Subhasis Dasgupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_J/0/1/0/all/0/1\">Jaydip Sen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WeCheck: Strong Factual Consistency Checker via Weakly Supervised Learning. (arXiv:2212.10057v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10057","description":"<p>A crucial issue of current text generation models is that they often\nuncontrollably generate factually inconsistent text with respective of their\ninputs. Limited by the lack of annotated data, existing works in evaluating\nfactual consistency directly transfer the reasoning ability of models trained\non other data-rich upstream tasks like question answering (QA) and natural\nlanguage inference (NLI) without any further adaptation. As a result, they\nperform poorly on the real generated text and are biased heavily by their\nsingle-source upstream tasks. To alleviate this problem, we propose a weakly\nsupervised framework that aggregates multiple resources to train a precise and\nefficient factual metric, namely WeCheck. WeCheck first utilizes a generative\nmodel to accurately label a real generated sample by aggregating its weak\nlabels, which are inferred from multiple resources. Then, we train the target\nmetric model with the weak supervision while taking noises into consideration.\nComprehensive experiments on a variety of tasks demonstrate the strong\nperformance of WeCheck, which achieves a 3.4\\% absolute improvement over\nprevious state-of-the-art methods on TRUE benchmark on average.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenhao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinyan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiachen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sujian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1\">Yajuan Lv</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An AI Dungeon Master's Guide: Learning to Converse and Guide with Intents and Theory-of-Mind in Dungeons and Dragons. (arXiv:2212.10060v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10060","description":"<p>We propose a novel task, G4C (Goal-driven Guidance Generation in Grounded\nCommunication), for studying goal-driven and grounded natural language\ninteractions. Specifically, we choose Dungeons and Dragons (D&amp;D) -- a\nrole-playing game consisting of multiple player characters and a Dungeon Master\n(DM) who collaborate to achieve a set of goals that are beneficial to the\nplayers -- as a testbed for this task. Here, each of the player characters is a\nstudent, with their own personas and abilities, and the DM is the teacher, an\narbitrator of the rules of the world and responsible for assisting and guiding\nthe students towards a global goal. We propose a theory-of-mind-inspired\nmethodology for training such a DM with reinforcement learning (RL), where a\nDM: (1) learns to predict how the players will react to its utterances using a\ndataset of D&amp;D dialogue transcripts; and (2) uses this prediction as a reward\nfunction providing feedback on how effective these utterances are at guiding\nthe players towards a goal. Human and automated evaluations show that a DM\ntrained with RL to generate guidance by incorporating a theory-of-mind of the\nplayers significantly improves the players' ability to achieve goals grounded\nin their shared world.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_A/0/1/0/all/0/1\">Andrew Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jennifer Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujara_J/0/1/0/all/0/1\">Jay Pujara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ammanabrolu_P/0/1/0/all/0/1\">Prithviraj Ammanabrolu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Are Reasoning Teachers. (arXiv:2212.10071v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10071","description":"<p>Language models (LMs) have demonstrated remarkable performance on downstream\ntasks, using in-context exemplars or human instructions. Recent works have\nshown that chain-of-thought (CoT) prompting can elicit models to solve complex\nreasoning tasks, step-by-step. However, the efficacy of prompt-based CoT\nmethods is restricted to very large LMs such as GPT-3 (175B), thus limiting\ndeployability. In this paper, we revisit the fine-tuning approach to enable\ncomplex reasoning in smaller LMs, optimized to efficiently perform a specific\ntask. We propose Fine-tune-CoT, a method that leverages the capabilities of\nvery large LMs to generate reasoning samples and teach smaller models via\nfine-tuning. We evaluate our method on publicly available LMs across a wide\nrange of complex tasks and model sizes. We find that Fine-tune-CoT enables\nsubstantial reasoning capability in small models, whereas previous prompt-based\nbaselines exhibit near-random performance. Student models can even outperform\nthe teacher in some tasks while reducing model size requirements by several\norders of magnitude. We conduct extensive ablations and sample studies to\nunderstand the reasoning capabilities of student models. We also identify\nseveral important nuances that have been overlooked in concurrent fine-tuning\nworks on CoT and address them in our analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ho_N/0/1/0/all/0/1\">Namgyu Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_L/0/1/0/all/0/1\">Laura Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1\">Se-Young Yun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DOC: Improving Long Story Coherence With Detailed Outline Control. (arXiv:2212.10077v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10077","description":"<p>We propose the Detailed Outline Control (DOC) framework for improving\nlong-range plot coherence when automatically generating\nseveral-thousand-word-long stories. DOC consists of two complementary\ncomponents: a detailed outliner and a detailed controller. The detailed\noutliner creates a more detailed, hierarchically structured outline, shifting\ncreative burden from the main drafting procedure to the planning stage. The\ndetailed controller ensures the more detailed outline is still respected during\ngeneration by controlling story passages to align with outline details. In\nhuman evaluations of automatically generated stories, DOC substantially\noutperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5%\nabsolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans\nalso judged DOC to be much more controllable in an interactive generation\nsetting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Pretrained Language Models for Neural Code Intelligence. (arXiv:2212.10079v1 [cs.SE])","link":"http://arxiv.org/abs/2212.10079","description":"<p>As the complexity of modern software continues to escalate, software\nengineering has become an increasingly daunting and error-prone endeavor. In\nrecent years, the field of Neural Code Intelligence (NCI) has emerged as a\npromising solution, leveraging the power of deep learning techniques to tackle\nanalytical tasks on source code with the goal of improving programming\nefficiency and minimizing human errors within the software industry. Pretrained\nlanguage models have become a dominant force in NCI research, consistently\ndelivering state-of-the-art results across a wide range of tasks, including\ncode summarization, generation, and translation. In this paper, we present a\ncomprehensive survey of the NCI domain, including a thorough review of\npretraining techniques, tasks, datasets, and model architectures. We hope this\npaper will serve as a bridge between the natural language and programming\nlanguage communities, offering insights for future research in this rapidly\nevolving field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanqiao Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rumour detection using graph neural network and oversampling in benchmark Twitter dataset. (arXiv:2212.10080v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10080","description":"<p>Recently, online social media has become a primary source for new information\nand misinformation or rumours. In the absence of an automatic rumour detection\nsystem the propagation of rumours has increased manifold leading to serious\nsocietal damages. In this work, we propose a novel method for building\nautomatic rumour detection system by focusing on oversampling to alleviating\nthe fundamental challenges of class imbalance in rumour detection task. Our\noversampling method relies on contextualised data augmentation to generate\nsynthetic samples for underrepresented classes in the dataset. The key idea\nexploits selection of tweets in a thread for augmentation which can be achieved\nby introducing a non-random selection criteria to focus the augmentation\nprocess on relevant tweets. Furthermore, we propose two graph neural\nnetworks(GNN) to model non-linear conversations on a thread. To enhance the\ntweet representations in our method we employed a custom feature selection\ntechnique based on state-of-the-art BERTweet model. Experiments of three\npublicly available datasets confirm that 1) our GNN models outperform the the\ncurrent state-of-the-art classifiers by more than 20%(F1-score); 2) our\noversampling technique increases the model performance by more than\n9%;(F1-score) 3) focusing on relevant tweets for data augmentation via\nnon-random selection criteria can further improve the results; and 4) our\nmethod has superior capabilities to detect rumours at very early stage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patel_S/0/1/0/all/0/1\">Shaswat Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_P/0/1/0/all/0/1\">Prince Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaur_P/0/1/0/all/0/1\">Preeti Kaur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hybrid Rule-Neural Coreference Resolution System based on Actor-Critic Learning. (arXiv:2212.10087v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10087","description":"<p>A coreference resolution system is to cluster all mentions that refer to the\nsame entity in a given context. All coreference resolution systems need to\ntackle two main tasks: one task is to detect all of the potential mentions, and\nthe other is to learn the linking of an antecedent for each possible mention.\nIn this paper, we propose a hybrid rule-neural coreference resolution system\nbased on actor-critic learning, such that it can achieve better coreference\nperformance by leveraging the advantages from both the heuristic rules and a\nneural conference model. This end-to-end system can also perform both mention\ndetection and resolution by leveraging a joint training algorithm. We\nexperiment on the BERT model to generate input span representations. Our model\nwith the BERT span representation achieves the state-of-the-art performance\namong the models on the CoNLL-2012 Shared Task English Test Set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hongxia Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward a Unified Framework for Unsupervised Complex Tabular Reasoning. (arXiv:2212.10097v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10097","description":"<p>Structured tabular data exist across nearly all fields. Reasoning task over\nthese data aims to answer questions or determine the truthiness of hypothesis\nsentences by understanding the semantic meaning of a table. While previous\nworks have devoted significant efforts to the tabular reasoning task, they\nalways assume there are sufficient labeled data. However, constructing\nreasoning samples over tables (and related text) is labor-intensive, especially\nwhen the reasoning process is complex. When labeled data is insufficient, the\nperformance of models will suffer an unendurable decline. In this paper, we\npropose a unified framework for unsupervised complex tabular reasoning (UCTR),\nwhich generates sufficient and diverse synthetic data with complex logic for\ntabular reasoning tasks, assuming no human-annotated data at all. We first\nutilize a random sampling strategy to collect diverse programs of different\ntypes and execute them on tables based on a \"Program-Executor\" module. To\nbridge the gap between the programs and natural language sentences, we design a\npowerful \"NL-Generator\" module to generate natural language sentences with\ncomplex logic from these programs. Since a table often occurs with its\nsurrounding texts, we further propose novel \"Table-to-Text\" and \"Text-to-Table\"\noperators to handle joint table-text reasoning scenarios. This way, we can\nadequately exploit the unlabeled table resources to obtain a well-performed\nreasoning model under an unsupervised setting. Our experiments cover different\ntasks (question answering and fact verification) and different domains (general\nand specific), showing that our unsupervised methods can achieve at most 93%\nperformance compared to supervised models. We also find that it can\nsubstantially boost the supervised performance in low-resourced domains as a\ndata augmentation technique. Our code is available at\nhttps://github.com/leezythu/UCTR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiuxing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1\">Zhichao Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bowen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ning Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianyong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"True Detective: A Challenging Benchmark for Deep Abductive Reasoning \\\\in Foundation Models. (arXiv:2212.10114v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10114","description":"<p>Large language models (LLMs) have demonstrated strong performance in\nzero-shot reasoning tasks, including abductive reasoning. This is reflected in\ntheir ability to perform well on current benchmarks in this area. However, to\ntruly test the limits of LLMs in abductive reasoning, a more challenging\nbenchmark is needed. In this paper, we present such a benchmark, consisting of\n191 long-form mystery stories, each approximately 1200 words in length and\npresented in the form of detective puzzles. Each puzzle includes a\nmultiple-choice question for evaluation sourced from the \"5 Minute Mystery\"\nplatform. Our results show that state-of-the-art GPT models perform\nsignificantly worse than human solvers on this benchmark, with an accuracy of\n28\\% compared to 47\\% for humans. This indicates that there is still a\nsignificant gap in the abductive reasoning abilities of LLMs and highlights the\nneed for further research in this area. Our work provides a challenging\nbenchmark for future studies on reasoning in language models and contributes to\na better understanding of the limits of LLMs' abilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Del_M/0/1/0/all/0/1\">Maksym Del</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fishel_M/0/1/0/all/0/1\">Mark Fishel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tackling Ambiguity with Images: Improved Multimodal Machine Translation and Contrastive Evaluation. (arXiv:2212.10140v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10140","description":"<p>One of the major challenges of machine translation (MT) is ambiguity, which\ncan in some cases be resolved by accompanying context such as an image.\nHowever, recent work in multimodal MT (MMT) has shown that obtaining\nimprovements from images is challenging, limited not only by the difficulty of\nbuilding effective cross-modal representations but also by the lack of specific\nevaluation and training data. We present a new MMT approach based on a strong\ntext-only MT model, which uses neural adapters and a novel guided\nself-attention mechanism and which is jointly trained on both visual masking\nand MMT. We also release CoMMuTE, a Contrastive Multilingual Multimodal\nTranslation Evaluation dataset, composed of ambiguous sentences and their\npossible translations, accompanied by disambiguating images corresponding to\neach translation. Our approach obtains competitive results over strong\ntext-only models on standard English-to-French benchmarks and outperforms these\nbaselines and state-of-the-art MMT systems with a large margin on our\ncontrastive test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Futeral_M/0/1/0/all/0/1\">Matthieu Futeral</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_C/0/1/0/all/0/1\">Cordelia Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laptev_I/0/1/0/all/0/1\">Ivan Laptev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagot_B/0/1/0/all/0/1\">Beno&#xee;t Sagot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bawden_R/0/1/0/all/0/1\">Rachel Bawden</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quirk or Palmer: A Comparative Study of Modal Verb Frameworks with Annotated Datasets. (arXiv:2212.10152v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10152","description":"<p>Modal verbs, such as \"can\", \"may\", and \"must\", are commonly used in daily\ncommunication to convey the speaker's perspective related to the likelihood\nand/or mode of the proposition. They can differ greatly in meaning depending on\nhow they're used and the context of a sentence (e.g. \"They 'must' help each\nother out.\" vs. \"They 'must' have helped each other out.\") Despite their\npractical importance in natural language understanding, linguists have yet to\nagree on a single, prominent framework for the categorization of modal verb\nsenses. This lack of agreement stems from high degrees of flexibility and\npolysemy from the modal verbs, making it more difficult for researchers to\nincorporate insights from this family of words into their work. This work\npresents Moverb dataset, which consists of 27,240 annotations of modal verb\nsenses over 4,540 utterances containing one or more sentences from social\nconversations. Each utterance is annotated by three annotators using two\ndifferent theoretical frameworks (i.e., Quirk and Palmer) of modal verb senses.\nWe observe that both frameworks have similar inter-annotator agreements,\ndespite having different numbers of sense types (8 for Quirk and 3 for Palmer).\nWith the RoBERTa-based classifiers fine-tuned on \\dataset, we achieve F1 scores\nof 82.2 and 78.3 on Quirk and Palmer, respectively, showing that modal verb\nsense disambiguation is not a trivial task. Our dataset will be publicly\navailable with our final version.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Owan_R/0/1/0/all/0/1\">Risako Owan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gini_M/0/1/0/all/0/1\">Maria Gini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-Guided Fair Classification for Natural Language Processing. (arXiv:2212.10154v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10154","description":"<p>Text classifiers have promising applications in high-stake tasks such as\nresume screening and content moderation. These classifiers must be fair and\navoid discriminatory decisions by being invariant to perturbations of sensitive\nattributes such as gender or ethnicity. However, there is a gap between human\nintuition about these perturbations and the formal similarity specifications\ncapturing them. While existing research has started to address this gap,\ncurrent methods are based on hardcoded word replacements, resulting in\nspecifications with limited expressivity or ones that fail to fully align with\nhuman intuition (e.g., in cases of asymmetric counterfactuals). This work\nproposes novel methods for bridging this gap by discovering expressive and\nintuitive individual fairness specifications. We show how to leverage\nunsupervised style transfer and GPT-3's zero-shot capabilities to automatically\ngenerate expressive candidate pairs of semantically similar sentences that\ndiffer along sensitive attributes. We then validate the generated pairs via an\nextensive crowdsourcing study, which confirms that a lot of these pairs align\nwith human intuition about fairness in the context of toxicity classification.\nFinally, we show how limited amounts of human feedback can be leveraged to\nlearn a similarity specification that can be used to train downstream\nfairness-aware models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dorner_F/0/1/0/all/0/1\">Florian E.Dorner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peychev_M/0/1/0/all/0/1\">Momchil Peychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1\">Nikola Konstantinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goel_N/0/1/0/all/0/1\">Naman Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ash_E/0/1/0/all/0/1\">Elliott Ash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vechev_M/0/1/0/all/0/1\">Martin Vechev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Naamapadam: A Large-Scale Named Entity Annotated Data for Indic Languages. (arXiv:2212.10168v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10168","description":"<p>We present, Naamapadam, the largest publicly available Named Entity\nRecognition (NER) dataset for the 11 major Indian languages from two language\nfamilies. In each language, it contains more than 400k sentences annotated with\na total of at least 100k entities from three standard entity categories\n(Person, Location and Organization) for 9 out of the 11 languages. The training\ndataset has been automatically created from the Samanantar parallel corpus by\nprojecting automatically tagged entities from an English sentence to the\ncorresponding Indian language sentence. We also create manually annotated\ntestsets for 8 languages containing approximately 1000 sentences per language.\nWe demonstrate the utility of the obtained dataset on existing testsets and the\nNaamapadam-test data for 8 Indic languages. We also release IndicNER, a\nmultilingual mBERT model fine-tuned on the Naamapadam training set. IndicNER\nachieves the best F1 on the Naamapadam-test set compared to an mBERT model\nfine-tuned on existing datasets. IndicNER achieves an F1 score of more than 80\nfor 7 out of 11 Indic languages. The dataset and models are available under\nopen-source licenses at https://ai4bharat.iitm.ac.in/naamapadam.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mhaske_A/0/1/0/all/0/1\">Arnav Mhaske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kedia_H/0/1/0/all/0/1\">Harshit Kedia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doddapaneni_S/0/1/0/all/0/1\">Sumanth Doddapaneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document-level Relation Extraction with Relation Correlations. (arXiv:2212.10171v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10171","description":"<p>Document-level relation extraction faces two overlooked challenges: long-tail\nproblem and multi-label problem. Previous work focuses mainly on obtaining\nbetter contextual representations for entity pairs, hardly address the above\nchallenges. In this paper, we analyze the co-occurrence correlation of\nrelations, and introduce it into DocRE task for the first time. We argue that\nthe correlations can not only transfer knowledge between data-rich relations\nand data-scarce ones to assist in the training of tailed relations, but also\nreflect semantic distance guiding the classifier to identify semantically close\nrelations for multi-label entity pairs. Specifically, we use relation embedding\nas a medium, and propose two co-occurrence prediction sub-tasks from both\ncoarse- and fine-grained perspectives to capture relation correlations.\nFinally, the learned correlation-aware embeddings are used to guide the\nextraction of relational facts. Substantial experiments on two popular DocRE\ndatasets are conducted, and our method achieves superior results compared to\nbaselines. Insightful analysis also demonstrates the potential of relation\ncorrelations to address the above challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1\">Ridong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_T/0/1/0/all/0/1\">Tao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiang Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Role of Parallel Data in Cross-lingual Transfer Learning. (arXiv:2212.10173v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10173","description":"<p>While prior work has established that the use of parallel data is conducive\nfor cross-lingual learning, it is unclear if the improvements come from the\ndata itself, or if it is the modeling of parallel interactions that matters.\nExploring this, we examine the usage of unsupervised machine translation to\ngenerate synthetic parallel data, and compare it to supervised machine\ntranslation and gold parallel data. We find that even model generated parallel\ndata can be useful for downstream tasks, in both a general setting (continued\npretraining) as well as the task-specific setting (translate-train), although\nour best results are still obtained using real parallel data. Our findings\nsuggest that existing multilingual models do not exploit the full potential of\nmonolingual data, and prompt the community to reconsider the traditional\ncategorization of cross-lingual learning approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reid_M/0/1/0/all/0/1\">Machel Reid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Human-Like Evaluation for Natural Language Generation with Error Analysis. (arXiv:2212.10179v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10179","description":"<p>The state-of-the-art language model-based automatic metrics, e.g. BARTScore,\nbenefiting from large-scale contextualized pre-training, have been successfully\nused in a wide range of natural language generation (NLG) tasks, including\nmachine translation, text summarization, and data-to-text. Recent studies show\nthat considering both major errors (e.g. mistranslated tokens) and minor errors\n(e.g. imperfections in fluency) can produce high-quality human judgments. This\ninspires us to approach the final goal of the evaluation metrics (human-like\nevaluations) by automatic error analysis. To this end, we augment BARTScore by\nincorporating the human-like error analysis strategies, namely BARTScore++,\nwhere the final score consists of both the evaluations of major errors and\nminor errors. Experimental results show that BARTScore++ can consistently\nimprove the performance of vanilla BARTScore and outperform existing\ntop-scoring metrics in 20 out of 25 test settings. We hope our technique can\nalso be extended to other pre-trained model-based metrics. We will release our\ncode and scripts to facilitate the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qingyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Liping Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kanjian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1\">Derek F. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages. (arXiv:2212.10180v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10180","description":"<p>The rapid growth of machine translation (MT) systems has necessitated\ncomprehensive studies to meta-evaluate evaluation metrics being used, which\nenables a better selection of metrics that best reflect MT quality.\nUnfortunately, most of the research focuses on high-resource languages, mainly\nEnglish, the observations for which may not always apply to other languages.\nIndian languages, having over a billion speakers, are linguistically different\nfrom English, and to date, there has not been a systematic study of evaluating\nMT systems from English into Indian languages. In this paper, we fill this gap\nby creating an MQM dataset consisting of 7000 fine-grained annotations,\nspanning 5 Indian languages and 7 MT systems, and use it to establish\ncorrelations between annotator scores and scores obtained using existing\nautomatic metrics. Our results show that pre-trained metrics, such as COMET,\nhave the highest correlations with annotator scores. Additionally, we find that\nthe metrics do not adequately capture fluency-based errors in Indian languages,\nand there is a need to develop metrics focused on Indian languages. We hope\nthat our dataset and analysis will help promote further research in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sai_A/0/1/0/all/0/1\">Ananya B. Sai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagarajan_V/0/1/0/all/0/1\">Vignesh Nagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixit_T/0/1/0/all/0/1\">Tanay Dixit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabre_R/0/1/0/all/0/1\">Raj Dabre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do I have the Knowledge to Answer? Investigating Answerability of Knowledge Base Questions. (arXiv:2212.10189v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10189","description":"<p>When answering natural language questions over knowledge bases (KBs),\nincompleteness in the KB can naturally lead to many questions being\nunanswerable. While answerability has been explored in other QA settings, it\nhas not been studied for QA over knowledge bases (KBQA). We first identify\nvarious forms of KB incompleteness that can result in a question being\nunanswerable. We then propose GrailQAbility, a new benchmark dataset, which\nsystematically modifies GrailQA (a popular KBQA dataset) to represent all these\nincompleteness issues. Testing two state-of-the-art KBQA models (trained on\noriginal GrailQA as well as our GrailQAbility), we find that both models\nstruggle to detect unanswerable questions, or sometimes detect them for the\nwrong reasons. Consequently, both models suffer significant loss in\nperformance, underscoring the need for further research in making KBQA systems\nrobust to unanswerability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patidar_M/0/1/0/all/0/1\">Mayur Patidar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Avinash Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faldu_P/0/1/0/all/0/1\">Prayushi Faldu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1\">Lovekesh Vig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_I/0/1/0/all/0/1\">Indrajit Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pay Attention to Your Tone: Introducing a New Dataset for Polite Language Rewrite. (arXiv:2212.10190v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10190","description":"<p>We introduce \\textsc{PoliteRewrite} -- a dataset for polite language rewrite\nwhich is a novel sentence rewrite task. Compared with previous text style\ntransfer tasks that can be mostly addressed by slight token- or phrase-level\nedits, polite language rewrite requires deep understanding and extensive\nsentence-level edits over an offensive and impolite sentence to deliver the\nsame message euphemistically and politely, which is more challenging -- not\nonly for NLP models but also for human annotators to rewrite with effort. To\nalleviate the human effort for efficient annotation, we first propose a novel\nannotation paradigm by a collaboration of human annotators and GPT-3.5 to\nannotate \\textsc{PoliteRewrite}. The released dataset has 10K polite sentence\nrewrites annotated collaboratively by GPT-3.5 and human, which can be used as\ngold standard for training, validation and test; and 100K high-quality polite\nsentence rewrites by GPT-3.5 without human review. We wish this work (The\ndataset (10K+100K) will be released soon) could contribute to the research on\nmore challenging sentence rewrite, and provoke more thought in future on\nresource annotation paradigm with the help of the large-scaled pretrained\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_A/0/1/0/all/0/1\">Allen Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuki Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Qing Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emotion Selectable End-to-End Text-based Speech Editing. (arXiv:2212.10191v1 [cs.SD])","link":"http://arxiv.org/abs/2212.10191","description":"<p>Text-based speech editing allows users to edit speech by intuitively cutting,\ncopying, and pasting text to speed up the process of editing speech. In the\nprevious work, CampNet (context-aware mask prediction network) is proposed to\nrealize text-based speech editing, significantly improving the quality of\nedited speech. This paper aims at a new task: adding emotional effect to the\nediting speech during the text-based speech editing to make the generated\nspeech more expressive. To achieve this task, we propose Emo-CampNet (emotion\nCampNet), which can provide the option of emotional attributes for the\ngenerated speech in text-based speech editing and has the one-shot ability to\nedit unseen speakers' speech. Firstly, we propose an end-to-end\nemotion-selectable text-based speech editing model. The key idea of the model\nis to control the emotion of generated speech by introducing additional emotion\nattributes based on the context-aware mask prediction network. Secondly, to\nprevent the emotion of the generated speech from being interfered by the\nemotional components in the original speech, a neutral content generator is\nproposed to remove the emotion from the original speech, which is optimized by\nthe generative adversarial framework. Thirdly, two data augmentation methods\nare proposed to enrich the emotional and pronunciation information in the\ntraining set, which can enable the model to edit the unseen speaker's speech.\nThe experimental results that 1) Emo-CampNet can effectively control the\nemotion of the generated speech in the process of text-based speech editing;\nAnd can edit unseen speakers' speech. 2) Detailed ablation experiments further\nprove the effectiveness of emotional selectivity and data augmentation methods.\nThe demo page is available at https://hairuo55.github.io/Emo-CampNet/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jiangyan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1\">Ruibo Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zhengqi Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chu Yuan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adam: Dense Retrieval Distillation with Adaptive Dark Examples. (arXiv:2212.10192v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10192","description":"<p>To improve the performance of the dual-encoder retriever, one effective\napproach is knowledge distillation from the cross-encoder ranker. Existing\nworks construct the candidate passages following the supervised learning\nsetting where a query is paired with a positive passage and a batch of\nnegatives. However, through empirical observation, we find that even the hard\nnegatives from advanced methods are still too trivial for the teacher to\ndistinguish, preventing the teacher from transferring abundant dark knowledge\nto the student through its soft label. To alleviate this issue, we propose\nADAM, a knowledge distillation framework that can better transfer the dark\nknowledge held in the teacher with Adaptive Dark exAMples. Different from\nprevious works that only rely on one positive and hard negatives as candidate\npassages, we create dark examples that all have moderate relevance to the query\nthrough mixing-up and masking in discrete space. Furthermore, as the quality of\nknowledge held in different training instances varies as measured by the\nteacher's confidence score, we propose a self-paced distillation strategy that\nadaptively concentrates on a subset of high-quality instances to conduct our\ndark-example-based knowledge distillation to help the student learn better. We\nconduct experiments on two widely-used benchmarks and verify the effectiveness\nof our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chongyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiubo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Can Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_B/0/1/0/all/0/1\">Binxing Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EIT: Enhanced Interactive Transformer. (arXiv:2212.10197v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10197","description":"<p>In this paper, we propose a novel architecture, the Enhanced Interactive\nTransformer (EIT), to address the issue of head degradation in self-attention\nmechanisms. Our approach replaces the traditional multi-head self-attention\nmechanism with the Enhanced Multi-Head Attention (EMHA) mechanism, which\nrelaxes the one-to-one mapping constraint among queries and keys, allowing each\nquery to attend to multiple keys. Furthermore, we introduce two interaction\nmodels, Inner-Subspace Interaction and Cross-Subspace Interaction, to fully\nutilize the many-to-many mapping capabilities of EMHA. Extensive experiments on\na wide range of tasks (e.g. machine translation, abstractive summarization,\ngrammar correction, language modelling and brain disease automatic diagnosis)\nshow its superiority with a very modest increase in model size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1\">Huiwen Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GanLM: Encoder-Decoder Pre-training with an Auxiliary Discriminator. (arXiv:2212.10218v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10218","description":"<p>Pre-trained models have achieved remarkable success in natural language\nprocessing (NLP). However, existing pre-training methods underutilize the\nbenefits of language understanding for generation. Inspired by the idea of\nGenerative Adversarial Networks (GANs), we propose a GAN-style model for\nencoder-decoder pre-training by introducing an auxiliary discriminator,\nunifying the ability of language understanding and generation in a single\nmodel. Our model, named as GanLM, is trained with two pre-training objectives:\nreplaced token detection and replaced token denoising. Specifically, given\nmasked source sentences, the generator outputs the target distribution and the\ndiscriminator predicts whether the target sampled tokens from distribution are\nincorrect. The target sentence is replaced with misclassified tokens to\nconstruct noisy previous context, which is used to generate the gold sentence.\nIn general, both tasks improve the ability of language understanding and\ngeneration by selectively using the denoising data. Extensive experiments in\nlanguage generation benchmarks show that GanLM with the powerful language\nunderstanding capability outperforms various strong pre-trained language models\n(PLMs) and achieves state-of-the-art performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yuwei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liqun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-trained Language Models for Keyphrase Generation: A Thorough Empirical Study. (arXiv:2212.10233v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10233","description":"<p>Neural models that do not rely on pre-training have excelled in the keyphrase\ngeneration task with large annotated datasets. Meanwhile, new approaches have\nincorporated pre-trained language models (PLMs) for their data efficiency.\nHowever, there lacks a systematic study of how the two types of approaches\ncompare and how different design choices can affect the performance of\nPLM-based models. To fill in this knowledge gap and facilitate a more informed\nuse of PLMs for keyphrase extraction and keyphrase generation, we present an\nin-depth empirical study. Formulating keyphrase extraction as sequence labeling\nand keyphrase generation as sequence-to-sequence generation, we perform\nextensive experiments in three domains. After showing that PLMs have\ncompetitive high-resource performance and state-of-the-art low-resource\nperformance, we investigate important design choices including in-domain PLMs,\nPLMs with different pre-training objectives, using PLMs with a parameter\nbudget, and different formulations for present keyphrases. Further results show\nthat (1) in-domain BERT-like PLMs can be used to build strong and\ndata-efficient keyphrase generation models; (2) with a fixed parameter budget,\nprioritizing model depth over width and allocating more layers in the encoder\nleads to better encoder-decoder models; and (3) introducing four in-domain\nPLMs, we achieve a competitive performance in the news domain and the\nstate-of-the-art performance in the scientific domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diff-Glat: Diffusion Glancing Transformer for Parallel Sequence to Sequence Learning. (arXiv:2212.10240v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10240","description":"<p>For sequence generation, both autoregressive models and non-autoregressive\nmodels have been developed in recent years. Autoregressive models can achieve\nhigh generation quality, but the sequential decoding scheme causes slow\ndecoding speed. Non-autoregressive models accelerate the inference speed with\nparallel decoding, while their generation quality still needs to be improved\ndue to the difficulty of modeling multi-modalities in data. To address the\nmulti-modality issue, we propose Diff-Glat, a non-autoregressive model featured\nwith a modality diffusion process and residual glancing training. The modality\ndiffusion process decomposes the modalities and reduces the modalities to learn\nfor each transition. And the residual glancing sampling further smooths the\nmodality learning procedures. Experiments demonstrate that, without using\nknowledge distillation data, Diff-Glat can achieve superior performance in both\ndecoding efficiency and accuracy compared with the autoregressive Transformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1\">Lihua Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Original or Translated? On the Use of Parallel Data for Translation Quality Estimation. (arXiv:2212.10257v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10257","description":"<p>Machine Translation Quality Estimation (QE) is the task of evaluating\ntranslation output in the absence of human-written references. Due to the\nscarcity of human-labeled QE data, previous works attempted to utilize the\nabundant unlabeled parallel corpora to produce additional training data with\npseudo labels. In this paper, we demonstrate a significant gap between parallel\ndata and real QE data: for QE data, it is strictly guaranteed that the source\nside is original texts and the target side is translated (namely\ntranslationese). However, for parallel data, it is indiscriminate and the\ntranslationese may occur on either source or target side. We compare the impact\nof parallel data with different translation directions in QE data augmentation,\nand find that using the source-original part of parallel corpus consistently\noutperforms its target-original counterpart. Moreover, since the WMT corpus\nlacks direction information for each parallel sentence, we train a classifier\nto distinguish source- and target-original bitext, and carry out an analysis of\ntheir difference in both style and domain. Together, these findings suggest\nusing source-original parallel data for QE data augmentation, which brings a\nrelative improvement of up to 4.0% and 6.4% compared to undifferentiated data\non sentence- and word-level QE tasks respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_B/0/1/0/all/0/1\">Baopu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1\">Lin Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1\">Yibing Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In and Out-of-Domain Text Adversarial Robustness via Label Smoothing. (arXiv:2212.10258v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10258","description":"<p>Recently it has been shown that state-of-the-art NLP models are vulnerable to\nadversarial attacks, where the predictions of a model can be drastically\naltered by slight modifications to the input (such as synonym substitutions).\nWhile several defense techniques have been proposed, and adapted, to the\ndiscrete nature of text adversarial attacks, the benefits of general-purpose\nregularization methods such as label smoothing for language models, have not\nbeen studied. In this paper, we study the adversarial robustness provided by\nvarious label smoothing strategies in foundational models for diverse NLP tasks\nin both in-domain and out-of-domain settings. Our experiments show that label\nsmoothing significantly improves adversarial robustness in pre-trained models\nlike BERT, against various popular attacks. We also analyze the relationship\nbetween prediction confidence and robustness, showing that label smoothing\nreduces over-confident errors on adversarial examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yahan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dan_S/0/1/0/all/0/1\">Soham Dan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_I/0/1/0/all/0/1\">Insup Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReCode: Robustness Evaluation of Code Generation Models. (arXiv:2212.10264v1 [cs.LG])","link":"http://arxiv.org/abs/2212.10264","description":"<p>Code generation models have achieved impressive performance. However, they\ntend to be brittle as slight edits to a prompt could lead to very different\ngenerations; these robustness properties, critical for user experience when\ndeployed in real-life applications, are not well understood. Most existing\nworks on robustness in text or code tasks have focused on classification, while\nrobustness in generation tasks is an uncharted area and to date there is no\ncomprehensive benchmark for robustness in code generation. In this paper, we\npropose ReCode, a comprehensive robustness evaluation benchmark for code\ngeneration models. We customize over 30 transformations specifically for code\non docstrings, function and variable names, code syntax, and code format. They\nare carefully designed to be natural in real-life coding practice, preserve the\noriginal semantic meaning, and thus provide multifaceted assessments of a\nmodel's robustness performance. With human annotators, we verified that over\n90% of the perturbed prompts do not alter the semantic meaning of the original\nprompt. In addition, we define robustness metrics for code generation models\nconsidering the worst-case behavior under each type of perturbation, taking\nadvantage of the fact that executing the generated code can serve as objective\nevaluation. We demonstrate ReCode on SOTA models using HumanEval, MBPP, as well\nas function completion tasks derived from them. Interesting observations\ninclude: better robustness for CodeGen over InCoder and GPT-J; models are most\nsensitive to syntax perturbations; more challenging robustness evaluation on\nMBPP over HumanEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1\">Haifeng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chenghao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_M/0/1/0/all/0/1\">Mingyue Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Varun Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Samson Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1\">Baishakhi Ray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_P/0/1/0/all/0/1\">Parminder Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nallapati_R/0/1/0/all/0/1\">Ramesh Nallapati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanathan_M/0/1/0/all/0/1\">Murali Krishna Ramanathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extrinsic Evaluation of Machine Translation Metrics. (arXiv:2212.10297v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10297","description":"<p>Automatic machine translation (MT) metrics are widely used to distinguish the\ntranslation qualities of machine translation systems across relatively large\ntest sets (system-level evaluation). However, it is unclear if automatic\nmetrics are reliable at distinguishing good translations from bad translations\nat the sentence level (segment-level evaluation). In this paper, we investigate\nhow useful MT metrics are at detecting the success of a machine translation\ncomponent when placed in a larger platform with a downstream task. We evaluate\nthe segment-level performance of the most widely used MT metrics (chrF, COMET,\nBERTScore, etc.) on three downstream cross-lingual tasks (dialogue state\ntracking, question answering, and semantic parsing). For each task, we only\nhave access to a monolingual task-specific model. We calculate the correlation\nbetween the metric's ability to predict a good/bad translation with the\nsuccess/failure on the final task for the Translate-Test setup. Our experiments\ndemonstrate that all metrics exhibit negligible correlation with the extrinsic\nevaluation of the downstream outcomes. We also find that the scores provided by\nneural metrics are not interpretable mostly because of undefined ranges. Our\nanalysis suggests that future MT metrics be designed to produce error labels\nrather than scores to facilitate extrinsic evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moghe_N/0/1/0/all/0/1\">Nikita Moghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sherborne_T/0/1/0/all/0/1\">Tom Sherborne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steedman_M/0/1/0/all/0/1\">Mark Steedman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Triplet: Leveraging the Most Data for Multimodal Machine Translation. (arXiv:2212.10313v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10313","description":"<p>Multimodal machine translation (MMT) aims to improve translation quality by\nincorporating information from other modalities, such as vision. Previous MMT\nsystems mainly focus on better access and use of visual information and tend to\nvalidate their methods on image-related datasets. These studies face two\nchallenges. First, they can only utilize triple data (bilingual texts with\nimages), which is scarce; second, current benchmarks are relatively restricted\nand do not correspond to realistic scenarios. Therefore, this paper\ncorrespondingly establishes new methods and new datasets for MMT. First, we\npropose a framework 2/3-Triplet with two new approaches to enhance MMT by\nutilizing large-scale non-triple data: monolingual image-text data and parallel\ntext-only data. Second, we construct an English-Chinese {e}-commercial\n{m}ulti{m}odal {t}ranslation dataset (including training and testing), named\nEMMT, where its test set is carefully selected as some words are ambiguous and\nshall be translated mistakenly without the help of images. Experiments show\nthat our method is more suitable for real-world scenarios and can significantly\nimprove translation performance by using more non-triple data. In addition, our\nmodel also rivals various SOTA models in conventional multimodal translation\nbenchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaoming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zewei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HINT: Hypernetwork Instruction Tuning for Efficient Zero-Shot Generalisation. (arXiv:2212.10315v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10315","description":"<p>Recent NLP models have the great ability to generalise `zero-shot' to new\ntasks using only an instruction as guidance. However, these approaches usually\nrepeat their instructions with every input, requiring costly reprocessing of\nlengthy instructions for every inference example. To alleviate this, we\nintroduce Hypernetworks for INstruction Tuning (HINT), which convert task\ninstructions and examples using a pretrained text encoder into\nparameter-efficient modules inserted into an underlying model, eliminating the\nneed to include instructions in the model input. Compared to prior approaches\nthat concatenate instructions with every input instance, we find that HINT\nmodels are significantly more compute-efficient and consistently outperform\nthese approaches for a given inference budget.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ivison_H/0/1/0/all/0/1\">Hamish Ivison</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagia_A/0/1/0/all/0/1\">Akshita Bhagia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peters_M/0/1/0/all/0/1\">Matthew Peters</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers. (arXiv:2212.10325v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10325","description":"<p>Diffusion model, a new generative modelling paradigm, has achieved great\nsuccess in image, audio, and video generation. However, considering the\ndiscrete categorical nature of text, it is not trivial to extend continuous\ndiffusion models to natural language, and text diffusion models are less\nstudied. Sequence-to-sequence text generation is one of the essential natural\nlanguage processing topics. In this work, we apply diffusion models to approach\nsequence-to-sequence text generation, and explore whether the superiority\ngeneration performance of diffusion model can transfer to natural language\ndomain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence\ngeneration. SeqDiffuSeq uses an encoder-decoder Transformers architecture to\nmodel denoising function. In order to improve generation quality, SeqDiffuSeq\ncombines the self-conditioning technique and a newly proposed adaptive noise\nschedule technique. The adaptive noise schedule has the difficulty of denoising\nevenly distributed across time steps, and considers exclusive noise schedules\nfor tokens at different positional order. Experiment results illustrate the\ngood performance on sequence-to-sequence generation in terms of text quality\nand inference time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongyi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data Limitation With Contrastive Learning. (arXiv:2212.10341v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10341","description":"<p>Machine-Generated Text (MGT) detection, a task that discriminates MGT from\nHuman-Written Text (HWT), plays a crucial role in preventing misuse of text\ngenerative models, which excel in mimicking human writing style recently.\nLatest proposed detectors usually take coarse text sequence as input and output\nsome good results by fine-tune pretrained models with standard cross-entropy\nloss. However, these methods fail to consider the linguistic aspect of text\n(e.g., coherence) and sentence-level structures. Moreover, they lack the\nability to handle the low-resource problem which could often happen in practice\nconsidering the enormous amount of textual data online. In this paper, we\npresent a coherence-based contrastive learning model named CoCo to detect the\npossible MGT under low-resource scenario. Inspired by the distinctiveness and\npermanence properties of linguistic feature, we represent text as a coherence\ngraph to capture its entity consistency, which is further encoded by the\npretrained model and graph neural network. To tackle the challenges of data\nlimitations, we employ a contrastive learning framework and propose an improved\ncontrastive loss for making full use of hard negative samples in training\nstage. The experiment results on two public datasets prove our approach\noutperforms the state-of-art methods significantly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaohan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yu Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does It Affect You? Social and Learning Implications of Using Cognitive-Affective State Recognition for Proactive Human-Robot Tutoring. (arXiv:2212.10346v1 [cs.RO])","link":"http://arxiv.org/abs/2212.10346","description":"<p>Using robots in educational contexts has already shown to be beneficial for a\nstudent's learning and social behaviour. For levitating them to the next level\nof providing more effective and human-like tutoring, the ability to adapt to\nthe user and to express proactivity is fundamental. By acting proactively,\nintelligent robotic tutors anticipate possible situations where problems for\nthe student may arise and act in advance for preventing negative outcomes.\nStill, the decisions of when and how to behave proactively are open questions.\nTherefore, this paper deals with the investigation of how the student's\ncognitive-affective states can be used by a robotic tutor for triggering\nproactive tutoring dialogue. In doing so, it is aimed to improve the learning\nexperience. For this reason, a concept learning task scenario was observed\nwhere a robotic assistant proactively helped when negative user states were\ndetected. In a learning task, the user's states of frustration and confusion\nwere deemed to have negative effects on the outcome of the task and were used\nto trigger proactive behaviour. In an empirical user study with 40\nundergraduate and doctoral students, we studied whether the initiation of\nproactive behaviour after the detection of signs of confusion and frustration\nimproves the student's concentration and trust in the agent. Additionally, we\ninvestigated which level of proactive dialogue is useful for promoting the\nstudent's concentration and trust. The results show that high proactive\nbehaviour harms trust, especially when triggered during negative\ncognitive-affective states but contributes to keeping the student focused on\nthe task when triggered in these states. Based on our study results, we further\ndiscuss future steps for improving the proactive assistance of robotic tutoring\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kraus_M/0/1/0/all/0/1\">Matthias Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Betancourt_D/0/1/0/all/0/1\">Diana Betancourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minker_W/0/1/0/all/0/1\">Wolfgang Minker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Receptive Field Alignment Enables Transformer Length Extrapolation. (arXiv:2212.10356v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10356","description":"<p>Length extrapolation is a desirable property that permits training a\ntransformer language model on short sequences and retaining similar\nperplexities when the model is tested on substantially longer sequences. A\nrelative positional embedding mechanism applied on the transformer\nself-attention matrix, ALiBi, demonstrates the length extrapolation property\nwith the widest usage to date. In this paper, we show that ALiBi surprisingly\ndoes not utilize tokens further than the training sequence length, which can be\nexplained by its implicit windowed attention effect that aligns the receptive\nfield during training and testing stages. Inspired by ALiBi and the receptive\nfiled alignment hypothesis, we propose another transformer positional embedding\ndesign named~\\textbf{Sandwich} that uses longer than training sequence length\ninformation, and it is a greatly simplified formulation of the earliest\nproposed Sinusoidal positional embedding. Finally, we show that both ALiBi and\nSandwich enable efficient inference thanks to their implicit windowed attention\neffect.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1\">Ta-Chung Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Ting-Han Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander I. Rudnicky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-adaptive In-context Learning. (arXiv:2212.10375v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10375","description":"<p>Despite the surprising few-shot performance of in-context learning (ICL), it\nis still a common practice to randomly sample examples to serve as context.\nThis paper advocates a new principle for ICL: self-adaptive in-context\nlearning. The self-adaption mechanism is introduced to help each sample find an\nin-context example permutation (i.e., selection and ordering) that can derive\nthe correct prediction, thus maximizing performance. To validate the\neffectiveness of self-adaptive ICL, we propose a general select-then-rank\nframework and instantiate it with new selection and ranking algorithms. Upon\nextensive evaluation on eight different NLP datasets, our self-adaptive ICL\nmethod achieves a 40% relative improvement over the common practice setting.\nFurther analysis reveals the enormous potential of self-adaptive ICL that it\nmight be able to close the gap between ICL and finetuning given more advanced\nalgorithms. Our code is released to facilitate future research in this area:\nhttps://github.com/Shark-NLP/self-adaptive-ICL\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaoxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiacheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Careful Data Curation Stabilizes In-context Learning. (arXiv:2212.10378v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10378","description":"<p>In-context learning (ICL) enables large language models (LLMs) to perform new\ntasks by prompting them with a sequence of training examples. However, ICL is\nvery sensitive to the choice of training examples: randomly sampling examples\nfrom a training set leads to high variance in performance. In this paper, we\nshow that curating a carefully chosen subset of training data greatly\nstabilizes ICL performance. We propose two methods to choose training subsets,\nboth of which score training examples individually and then select the\nhighest-scoring ones. CondAcc scores a training example by its average ICL\naccuracy when combined with random training examples, while Datamodels learns a\nlinear proxy model that estimates how the presence of each training example\ninfluences LLM accuracy. On average, CondAcc and Datamodels outperform sampling\nfrom the entire training set by 7.7% and 6.3%, respectively, across 5 tasks and\ntwo LLMs. Our analysis shows that stable subset examples are no more diverse\nthan average, and are not outliers in terms of sequence length and perplexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1\">Ting-Yun Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Robin Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Are You Token About? Dense Retrieval as Distributions Over the Vocabulary. (arXiv:2212.10380v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10380","description":"<p>Dual encoders are now the dominant architecture for dense retrieval. Yet, we\nhave little understanding of how they represent text, and why this leads to\ngood performance. In this work, we shed light on this question via\ndistributions over the vocabulary. We propose to interpret the vector\nrepresentations produced by dual encoders by projecting them into the model's\nvocabulary space. We show that the resulting distributions over vocabulary\ntokens are intuitive and contain rich semantic information. We find that this\nview can explain some of the failure cases of dense retrievers. For example,\nthe inability of models to handle tail entities can be explained via a tendency\nof the token distributions to forget some of the tokens of those entities. We\nleverage this insight and propose a simple way to enrich query and passage\nrepresentations with lexical information at inference time, and show that this\nsignificantly improves performance compared to the original model in\nout-of-domain settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1\">Ori Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bezalel_L/0/1/0/all/0/1\">Liat Bezalel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zicher_A/0/1/0/all/0/1\">Adi Zicher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1\">Amir Globerson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"To Adapt or to Annotate: Challenges and Interventions for Domain Adaptation in Open-Domain Question Answering. (arXiv:2212.10381v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10381","description":"<p>Recent advances in open-domain question answering (ODQA) have demonstrated\nimpressive accuracy on standard Wikipedia style benchmarks. However, it is less\nclear how robust these models are and how well they perform when applied to\nreal-world applications in drastically different domains. While there has been\nsome work investigating how well ODQA models perform when tested for\nout-of-domain (OOD) generalization, these studies have been conducted only\nunder conservative shifts in data distribution and typically focus on a single\ncomponent (ie. retrieval) rather than an end-to-end system. In response, we\npropose a more realistic and challenging domain shift evaluation setting and,\nthrough extensive experiments, study end-to-end model performance. We find that\nnot only do models fail to generalize, but high retrieval scores often still\nyield poor answer prediction accuracy. We then categorize different types of\nshifts and propose techniques that, when presented with a new dataset, predict\nif intervention methods are likely to be successful. Finally, using insights\nfrom this analysis, we propose and evaluate several intervention methods which\nimprove end-to-end answer F1 score by up to 24 points.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dua_D/0/1/0/all/0/1\">Dheeru Dua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verga_P/0/1/0/all/0/1\">Pat Verga</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TeSS: Zero-Shot Classification via Textual Similarity Comparison with Prompting using Sentence Encoder. (arXiv:2212.10391v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10391","description":"<p>We introduce TeSS (Text Similarity Comparison using Sentence Encoder), a\nframework for zero-shot classification where the assigned label is determined\nby the embedding similarity between the input text and each candidate label\nprompt. We leverage representations from sentence encoders optimized to locate\nsemantically similar samples closer to each other in embedding space during\npre-training. The label prompt embeddings serve as prototypes of their\ncorresponding class clusters. Furthermore, to compensate for the potentially\npoorly descriptive labels in their original format, we retrieve semantically\nsimilar sentences from external corpora and additionally use them with the\noriginal label prompt (TeSS-R). TeSS outperforms strong baselines on various\nclosed-set and open-set classification datasets under zero-shot setting, with\nfurther gains when combined with label prompt diversification through\nretrieval. These results are robustly attained to verbalizer variations, an\nancillary benefit of using a bi-encoder. Altogether, our method serves as a\nreliable baseline for zero-shot classification and a simple interface to assess\nthe quality of sentence encoders.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Jimin Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungsoo Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Daeyoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Seongjae Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_B/0/1/0/all/0/1\">Bokyung Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewook Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Debiasing Stance Detection Models with Counterfactual Reasoning and Adversarial Bias Learning. (arXiv:2212.10392v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10392","description":"<p>Stance detection models may tend to rely on dataset bias in the text part as\na shortcut and thus fail to sufficiently learn the interaction between the\ntargets and texts. Recent debiasing methods usually treated features learned by\nsmall models or big models at earlier steps as bias features and proposed to\nexclude the branch learning those bias features during inference. However, most\nof these methods fail to disentangle the ``good'' stance features and ``bad''\nbias features in the text part. In this paper, we investigate how to mitigate\ndataset bias in stance detection. Motivated by causal effects, we leverage a\nnovel counterfactual inference framework, which enables us to capture the\ndataset bias in the text part as the direct causal effect of the text on\nstances and reduce the dataset bias in the text part by subtracting the direct\ntext effect from the total causal effect. We novelly model bias features as\nfeatures that correlate with the stance labels but fail on intermediate stance\nreasoning subtasks and propose an adversarial bias learning module to model the\nbias more accurately. To verify whether our model could better model the\ninteraction between texts and targets, we test our model on recently proposed\ntest sets to evaluate the understanding of the task from various aspects.\nExperiments demonstrate that our proposed method (1) could better model the\nbias features, and (2) outperforms existing debiasing baselines on both the\noriginal dataset and most of the newly constructed test sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianhua Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Needle in a Haystack: An Analysis of Finding Qualified Workers on MTurk for Summarization. (arXiv:2212.10397v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10397","description":"<p>The acquisition of high-quality human annotations through crowdsourcing\nplatforms like Amazon Mechanical Turk (MTurk) is more challenging than\nexpected. The annotation quality might be affected by various aspects like\nannotation instructions, Human Intelligence Task (HIT) design, and wages paid\nto annotators, etc. To avoid potentially low-quality annotations which could\nmislead the evaluation of automatic summarization system outputs, we\ninvestigate the recruitment of high-quality MTurk workers via a three-step\nqualification pipeline. We show that we can successfully filter out bad workers\nbefore they carry out the evaluations and obtain high-quality annotations while\noptimizing the use of resources. This paper can serve as basis for the\nrecruitment of qualified annotators in other challenging annotation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lining Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1\">Jo&#xe3;o Sedoc</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mille_S/0/1/0/all/0/1\">Simon Mille</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yufang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1\">Sebastian Gehrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deutsch_D/0/1/0/all/0/1\">Daniel Deutsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_E/0/1/0/all/0/1\">Elizabeth Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clinciu_M/0/1/0/all/0/1\">Miruna Clinciu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahamood_S/0/1/0/all/0/1\">Saad Mahamood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1\">Khyathi Chandu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Learning Reduces Hallucination in Conversations. (arXiv:2212.10400v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10400","description":"<p>Pre-trained language models (LMs) store knowledge in their parameters and can\ngenerate informative responses when used in conversational systems. However,\nLMs suffer from the problem of \"hallucination:\" they may generate\nplausible-looking statements that are irrelevant or factually incorrect. To\naddress this problem, we propose a contrastive learning scheme, named MixCL. A\nnovel mixed contrastive objective is proposed to explicitly optimize the\nimplicit knowledge elicitation process of LMs, and thus reduce their\nhallucination in conversations. We also examine negative sampling strategies of\nretrieved hard negatives and model-generated negatives. We conduct experiments\non Wizard-of-Wikipedia, a public, open-domain knowledge-grounded dialogue\nbenchmark, and assess the effectiveness of MixCL. MixCL effectively reduces the\nhallucination of LMs in conversations and achieves the highest performance\namong LM-based dialogue agents in terms of relevancy and factuality. We show\nthat MixCL achieves comparable performance to state-of-the-art KB-based\napproaches while enjoying notable advantages in terms of efficiency and\nscalability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengliang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Shen Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1\">Maarten de Rijke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Reasoning in Large Language Models: A Survey. (arXiv:2212.10403v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10403","description":"<p>Reasoning is a fundamental aspect of human intelligence that plays a crucial\nrole in activities such as problem solving, decision making, and critical\nthinking. In recent years, large language models (LLMs) have made significant\nprogress in natural language processing, and there is observation that these\nmodels may exhibit reasoning abilities when they are sufficiently large.\nHowever, it is not yet clear to what extent LLMs are capable of reasoning. This\npaper provides a comprehensive overview of the current state of knowledge on\nreasoning in LLMs, including techniques for improving and eliciting reasoning\nin these models, methods and benchmarks for evaluating reasoning abilities,\nfindings and implications of previous research in this field, and suggestions\non future directions. Our aim is to provide a detailed and up-to-date review of\nthis topic and stimulate meaningful discussion and future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AnnoBERT: Effectively Representing Multiple Annotators' Label Choices to Improve Hate Speech Detection. (arXiv:2212.10405v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10405","description":"<p>Supervised approaches generally rely on majority-based labels. However, it is\nhard to achieve high agreement among annotators in subjective tasks such as\nhate speech detection. Existing neural network models principally regard labels\nas categorical variables, while ignoring the semantic information in diverse\nlabel texts. In this paper, we propose AnnoBERT, a first-of-its-kind\narchitecture integrating annotator characteristics and label text with a\ntransformer-based model to detect hate speech, with unique representations\nbased on each annotator's characteristics via Collaborative Topic Regression\n(CTR) and integrate label text to enrich textual representations. During\ntraining, the model associates annotators with their label choices given a\npiece of text; during evaluation, when label information is not available, the\nmodel predicts the aggregated label given by the participating annotators by\nutilising the learnt association. The proposed approach displayed an advantage\nin detecting hate speech, especially in the minority class and edge cases with\nannotator disagreement. Improvement in the overall performance is the largest\nwhen the dataset is more label-imbalanced, suggesting its practical value in\nidentifying real-world hate speech, as the volume of hate speech in-the-wild is\nextremely small on social media, when compared with normal (non-hate) speech.\nThrough ablation studies, we show the relative contributions of annotator\nembeddings and label text to the model performance, and tested a range of\nalternative annotator embeddings and label text combinations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenjie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_V/0/1/0/all/0/1\">Vibhor Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_A/0/1/0/all/0/1\">Aiqi Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zubiaga_A/0/1/0/all/0/1\">Arkaitz Zubiaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sastry_N/0/1/0/all/0/1\">Nishanth Sastry</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Geographic and Geopolitical Biases of Language Models. (arXiv:2212.10408v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10408","description":"<p>Pretrained language models (PLMs) often fail to fairly represent target users\nfrom certain world regions because of the under-representation of those regions\nin training datasets. With recent PLMs trained on enormous data sources,\nquantifying their potential biases is difficult, due to their black-box nature\nand the sheer scale of the data sources. In this work, we devise an approach to\nstudy the geographic bias (and knowledge) present in PLMs, proposing a\nGeographic-Representation Probing Framework adopting a self-conditioning method\ncoupled with entity-country mappings. Our findings suggest PLMs'\nrepresentations map surprisingly well to the physical world in terms of\ncountry-to-country associations, but this knowledge is unequally shared across\nlanguages. Last, we explain how large PLMs despite exhibiting notions of\ngeographical proximity, over-amplify geopolitical favouritism at inference\ntime.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faisal_F/0/1/0/all/0/1\">Fahim Faisal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reinforced Clarification Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations. (arXiv:2212.10409v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10409","description":"<p>Context is vital for commonsense moral reasoning. \"Lying to a friend\" is\nwrong if it is meant to deceive them, but may be morally okay if it is intended\nto protect them. Such nuanced but salient contextual information can\npotentially flip the moral judgment of an action. Thus, we present\nClarifyDelphi, an interactive system that elicits missing contexts of a moral\nsituation by generating clarification questions such as \"Why did you lie to\nyour friend?\". Our approach is inspired by the observation that questions whose\npotential answers lead to diverging moral judgments are the most informative.\nWe learn to generate questions using Reinforcement Learning, by maximizing the\ndivergence between moral judgements of hypothetical answers to a question.\nHuman evaluation shows that our system generates more relevant, informative and\ndefeasible questions compared to other question generation baselines.\nClarifyDelphi assists informed moral reasoning processes by seeking additional\nmorally consequential context to disambiguate social and moral situations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1\">Jena D. Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Localising In-Domain Adaptation of Transformer-Based Biomedical Language Models. (arXiv:2212.10422v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10422","description":"<p>In the era of digital healthcare, the huge volumes of textual information\ngenerated every day in hospitals constitute an essential but underused asset\nthat could be exploited with task-specific, fine-tuned biomedical language\nrepresentation models, improving patient care and management. For such\nspecialized domains, previous research has shown that fine-tuning models\nstemming from broad-coverage checkpoints can largely benefit additional\ntraining rounds over large-scale in-domain resources. However, these resources\nare often unreachable for less-resourced languages like Italian, preventing\nlocal medical institutions to employ in-domain adaptation. In order to reduce\nthis gap, our work investigates two accessible approaches to derive biomedical\nlanguage models in languages other than English, taking Italian as a concrete\nuse-case: one based on neural machine translation of English resources,\nfavoring quantity over quality; the other based on a high-grade, narrow-scoped\ncorpus natively in Italian, thus preferring quality over quantity. Our study\nshows that data quantity is a harder constraint than data quality for\nbiomedical adaptation, but the concatenation of high-quality data can improve\nmodel performance even when dealing with relatively size-limited corpora. The\nmodels published from our investigations have the potential to unlock important\nresearch opportunities for Italian hospitals and academia. Finally, the set of\nlessons learned from the study constitutes valuable insights towards a solution\nto build biomedical language models that are generalizable to other\nless-resourced languages and different domain settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Buonocore_T/0/1/0/all/0/1\">Tommaso Mario Buonocore</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Crema_C/0/1/0/all/0/1\">Claudio Crema</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Parimbelli_E/0/1/0/all/0/1\">Enea Parimbelli</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Redolfi_A/0/1/0/all/0/1\">Alberto Redolfi</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Bellazzi_R/0/1/0/all/0/1\">Riccardo Bellazzi</a> (1) ((1) Dept. of Electrical, Computer and Biomedical Engineering, University of Pavia, (2) Laboratory of Neuroinformatics, IRCCS Istituto Centro San Giovanni di Dio Fatebenefratelli)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-Grained Distillation for Long Document Retrieval. (arXiv:2212.10423v1 [cs.IR])","link":"http://arxiv.org/abs/2212.10423","description":"<p>Long document retrieval aims to fetch query-relevant documents from a\nlarge-scale collection, where knowledge distillation has become de facto to\nimprove a retriever by mimicking a heterogeneous yet powerful cross-encoder.\nHowever, in contrast to passages or sentences, retrieval on long documents\nsuffers from the scope hypothesis that a long document may cover multiple\ntopics. This maximizes their structure heterogeneity and poses a\ngranular-mismatch issue, leading to an inferior distillation efficacy. In this\nwork, we propose a new learning framework, fine-grained distillation (FGD), for\nlong-document retrievers. While preserving the conventional dense retrieval\nparadigm, it first produces global-consistent representations crossing\ndifferent fine granularity and then applies multi-granular aligned distillation\nmerely during training. In experiments, we evaluate our framework on two\nlong-document retrieval benchmarks, which show state-of-the-art performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yucheng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiubo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chongyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1\">Guodong Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Can Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Perplexed by Quality: A Perplexity-based Method for Adult and Harmful Content Detection in Multilingual Heterogeneous Web Data. (arXiv:2212.10440v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10440","description":"<p>As demand for large corpora increases with the size of current\nstate-of-the-art language models, using web data as the main part of the\npre-training corpus for these models has become a ubiquitous practice. This, in\nturn, has introduced an important challenge for NLP practitioners, as they are\nnow confronted with the task of developing highly optimized models and\npipelines for pre-processing large quantities of textual data, which implies,\neffectively classifying and filtering multilingual, heterogeneous and noisy\ndata, at web scale. One of the main components of this pre-processing step for\nthe pre-training corpora of large language models, is the removal of adult and\nharmful content. In this paper we explore different methods for detecting adult\nand harmful of content in multilingual heterogeneous web data. We first show\nhow traditional methods in harmful content detection, that seemingly perform\nquite well in small and specialized datasets quickly break down when confronted\nwith heterogeneous noisy web data. We then resort to using a perplexity based\napproach but with a twist: Instead of using a so-called \"clean\" corpus to train\na small language model and then use perplexity so select the documents with low\nperplexity, i.e., the documents that resemble this so-called \"clean\" corpus the\nmost. We train solely with adult and harmful textual data, and then select the\ndocuments having a perplexity value above a given threshold. This approach will\nvirtually cluster our documents into two distinct groups, which will greatly\nfacilitate the choice of the threshold for the perplexity and will also allow\nus to obtain higher precision than with the traditional classification methods\nfor detecting adult and harmful content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jansen_T/0/1/0/all/0/1\">Tim Jansen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yangling Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zevallos_V/0/1/0/all/0/1\">Victoria Zevallos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suarez_P/0/1/0/all/0/1\">Pedro Ortiz Suarez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter-efficient Zero-shot Transfer for Cross-Language Dense Retrieval with Adapters. (arXiv:2212.10448v1 [cs.IR])","link":"http://arxiv.org/abs/2212.10448","description":"<p>A popular approach to creating a zero-shot cross-language retrieval model is\nto substitute a monolingual pretrained language model in the retrieval model\nwith a multilingual pretrained language model such as Multilingual BERT. This\nmultilingual model is fined-tuned to the retrieval task with monolingual data\nsuch as English MS MARCO using the same training recipe as the monolingual\nretrieval model used. However, such transferred models suffer from mismatches\nin the languages of the input text during training and inference. In this work,\nwe propose transferring monolingual retrieval models using adapters, a\nparameter-efficient component for a transformer network. By adding adapters\npretrained on language tasks for a specific language with task-specific\nadapters, prior work has shown that the adapter-enhanced models perform better\nthan fine-tuning the entire model when transferring across languages in various\nNLP tasks. By constructing dense retrieval models with adapters, we show that\nmodels trained with monolingual data are more effective than fine-tuning the\nentire model when transferring to a Cross Language Information Retrieval (CLIR)\nsetting. However, we found that the prior suggestion of replacing the language\nadapters to match the target language at inference time is suboptimal for dense\nretrieval models. We provide an in-depth analysis of this discrepancy between\nother cross-language NLP tasks and CLIR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1\">Eugene Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1\">Suraj Nair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrie_D/0/1/0/all/0/1\">Dawn Lawrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayfield_J/0/1/0/all/0/1\">James Mayfield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1\">Douglas W. Oard</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Socratic Pretraining: Question-Driven Pretraining for Controllable Summarization. (arXiv:2212.10449v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10449","description":"<p>In long document controllable summarization, where labeled data is scarce,\npretrained models struggle to adapt to the task and effectively respond to user\nqueries. In this paper, we introduce Socratic pretraining, a question-driven,\nunsupervised pretraining objective specifically designed to improve\ncontrollability in summarization tasks. By training a model to generate and\nanswer relevant questions in a given context, Socratic pretraining enables the\nmodel to more effectively adhere to user-provided queries and identify relevant\ncontent to be summarized. We demonstrate the effectiveness of this approach\nthrough extensive experimentation on two summarization domains, short stories\nand dialogue, and multiple control strategies: keywords, questions, and factoid\nQA pairs. Our pretraining method relies only on unlabeled documents and a\nquestion generation system and outperforms pre-finetuning approaches that use\nadditional supervised data. Furthermore, our results show that Socratic\npretraining cuts task-specific labeled data requirements in half, is more\nfaithful to user-provided queries, and achieves state-of-the-art performance on\nQMSum and SQuALITY.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pagnoni_A/0/1/0/all/0/1\">Artidoro Pagnoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander R. Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kryscinski_W/0/1/0/all/0/1\">Wojciech Kry&#x15b;ci&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chien-Sheng Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is GPT-3 a Good Data Annotator?. (arXiv:2212.10450v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10450","description":"<p>GPT-3 (Generative Pre-trained Transformer 3) is a large-scale autoregressive\nlanguage model developed by OpenAI, which has demonstrated impressive few-shot\nperformance on a wide range of natural language processing (NLP) tasks. Hence,\nan intuitive application is to use it for data annotation. In this paper, we\ninvestigate whether GPT-3 can be used as a good data annotator for NLP tasks.\nData annotation is the process of labeling data that could be used to train\nmachine learning models. It is a crucial step in the development of NLP\nsystems, as it allows the model to learn the relationship between the input\ndata and the desired output. Given the impressive language capabilities of\nGPT-3, it is natural to wonder whether it can be used to effectively annotate\ndata for NLP tasks. In this paper, we evaluate the performance of GPT-3 as a\ndata annotator by comparing it with traditional data annotation methods and\nanalyzing its output on a range of tasks. Through this analysis, we aim to\nprovide insight into the potential of GPT-3 as a general-purpose data annotator\nin NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bosheng Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain Dataset for Natural Language Understanding in Task-Oriented Dialogue. (arXiv:2212.10455v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10455","description":"<p>Task-oriented dialogue (TOD) systems have been applied in a range of domains\nto support human users to achieve specific goals. Systems are typically\nconstructed for a single domain or language and do not generalise well beyond\nthis. Their extension to other languages in particular is restricted by the\nlack of available training data for many of the world's languages. To support\nwork on Natural Language Understanding (NLU) in TOD across multiple languages\nand domains simultaneously, we constructed MULTI3NLU++, a multilingual,\nmulti-intent, multi-domain dataset. MULTI3NLU++ extends the English-only NLU++\ndataset to include manual translations into a range of high, medium and low\nresource languages (Spanish, Marathi, Turkish and Amharic), in two domains\n(banking and hotels). MULTI3NLU++ inherits the multi-intent property of NLU++,\nwhere an utterance may be labelled with multiple intents, providing a more\nrealistic representation of a user's goals and aligning with the more complex\ntasks that commercial systems aim to model. We use MULTI3NLU++ to benchmark\nstate-of-the-art multilingual language models as well as Machine Translation\nand Question Answering systems for the NLU task of intent detection for TOD\nsystems in the multilingual setting. The results demonstrate the challenging\nnature of the dataset, particularly in the low-resource language setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moghe_N/0/1/0/all/0/1\">Nikita Moghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razumovskaia_E/0/1/0/all/0/1\">Evgeniia Razumovskaia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guillou_L/0/1/0/all/0/1\">Liane Guillou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Go-tuning: Improving Zero-shot Learning Abilities of Smaller Language Models. (arXiv:2212.10461v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10461","description":"<p>With increasing scale, large language models demonstrate both quantitative\nimprovement and new qualitative capabilities, especially as zero-shot learners,\nlike GPT-3. However, these results rely heavily on delicate prompt design and\nlarge computation. In this work, we explore whether the strong zero-shot\nability could be achieved at a smaller model scale without any external\nsupervised data. To achieve this goal, we revisit masked language modeling and\npresent a geometry-guided self-supervised learning method (Go-tuningfor short)\nby taking a small number of task-aware self-supervised data to update language\nmodels further. Experiments show that Go-tuning can enable T5-small (80M)\ncompetitive zero-shot results compared with large language models, such as\nT5-XL (3B). We also apply Go-tuning on multi-task settings and develop a\nmulti-task model, mgo-T5 (250M). It can reach the average performance of OPT\n(175B) on 9 datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1\">Qingxiu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hongyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization. (arXiv:2212.10465v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10465","description":"<p>We present SODA: the first publicly available, million-scale high-quality\nsocial dialogue dataset. Using SODA, we train COSMO: a generalizable\nconversation agent outperforming previous best-performing agents on both in-\nand out-of-domain datasets.\n</p>\n<p>In contrast to most existing crowdsourced, small-scale dialogue corpora, we\ndistill 1.5M socially-grounded dialogues from a pre-trained language model\n(InstructGPT; Ouyang et al., 2022). Dialogues are distilled by contextualizing\nsocial commonsense knowledge from a knowledge graph (Atomic10x; West et al.,\n2022). Human evaluation shows that dialogues in SODA are more consistent,\nspecific, and (surprisingly) natural than prior human-authored datasets - e.g.,\nDailyDialog (Li et al., 2017), BlendedSkillTalk (Smith et al., 2020).\n</p>\n<p>In addition, extensive evaluations show that COSMO is significantly more\nnatural and consistent on unseen datasets than best-performing dialogue models\n- e.g., GODEL (Peng et al., 2022), BlenderBot (Roller et al., 2021), DialoGPT\n(Zhang et al., 2020). Furthermore, it is sometimes even preferred to the\noriginal human-written gold responses. We make our data, models, and code\npublic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunwoo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alikhani_M/0/1/0/all/0/1\">Malihe Alikhani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gunhee Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Text Generation with Language Constraints. (arXiv:2212.10466v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10466","description":"<p>We consider the task of text generation in language models with constraints\nspecified in natural language. To this end, we first create a challenging\nbenchmark Cognac that provides as input to the model a topic with example text,\nalong with a constraint on text to be avoided. Unlike prior work, our benchmark\ncontains knowledge-intensive constraints sourced from databases like Wordnet\nand Wikidata, which allows for straightforward evaluation while striking a\nbalance between broad attribute-level and narrow lexical-level controls. We\nfind that even state-of-the-art language models like GPT-3 fail often on this\ntask, and propose a solution to leverage a language model's own internal\nknowledge to guide generation. Our method, called CognacGen, first queries the\nlanguage model to generate guidance terms for a specified topic or constraint,\nand uses the guidance to modify the model's token generation probabilities. We\npropose three forms of guidance (binary verifier, top-k tokens, textual\nexample), and employ prefix-tuning approaches to distill the guidance to tackle\ndiverse natural language constraints. Through extensive empirical evaluations,\nwe demonstrate that CognacGen can successfully generalize to unseen\ninstructions and outperform competitive baselines in generating constraint\nconforming text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Howard Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huihan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generic Temporal Reasoning with Differential Analysis and Explanation. (arXiv:2212.10467v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10467","description":"<p>Temporal reasoning is the task of predicting temporal relations of event\npairs with corresponding contexts. While some temporal reasoning models perform\nreasonably well on in-domain benchmarks, we have little idea of the systems'\ngeneralizability due to existing datasets' limitations. In this work, we\nintroduce a novel task named TODAY that bridges this gap with temporal\ndifferential analysis, which as the name suggests, evaluates if systems can\ncorrectly understand the effect of incremental changes. Specifically, TODAY\nmakes slight context changes for given event pairs, and systems need to tell\nhow this subtle contextual change will affect temporal relation distributions.\nTo facilitate learning, TODAY also annotates human explanations. We show that\nexisting models, including GPT-3, drop to random guessing on TODAY, suggesting\nthat they heavily rely on spurious information rather than proper reasoning for\ntemporal predictions. On the other hand, we show that TODAY's supervision style\nand explanation annotations can be used in joint learning and encourage models\nto use more appropriate signals during training and outperform across several\nbenchmarks. TODAY can also be used to train models to solicit incidental\nsupervision from noisy sources such as GPT-3 and moves farther towards generic\ntemporal reasoning systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yu Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1\">Ben Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Helen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BMX: Boosting Machine Translation Metrics with Explainability. (arXiv:2212.10469v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10469","description":"<p>State-of-the-art machine translation evaluation metrics are based on\nblack-box language models. Hence, recent works consider their explainability\nwith the goals of better understandability for humans and better metric\nanalysis, including failure cases. In contrast, we explicitly leverage\nexplanations to boost the metrics' performance. In particular, we perceive\nexplanations as word-level scores, which we convert, via power means, into\nsentence-level scores. We combine this sentence-level score with the original\nmetric to obtain a better metric. Our extensive evaluation and analysis across\n5 datasets, 5 metrics and 4 explainability techniques shows that some\nconfigurations reliably improve the original metrics' correlation with human\njudgment. On two held datasets for testing, we obtain improvements in 15/18\nresp. 4/4 cases. The gains in Pearson correlation are up to 0.032 resp. 0.055.\nWe make our code available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Leiter_C/0/1/0/all/0/1\">Christoph Leiter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hoa Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning and Generation with Large Language Models. (arXiv:2212.10471v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10471","description":"<p>We consider the problem of automatically generating stories in multiple\nlanguages. Compared to prior work in monolingual story generation, crosslingual\nstory generation allows for more universal research on story planning. We\npropose to use Prompting Large Language Models with Plans to study which plan\nis optimal for story generation. We consider 4 types of plans and\nsystematically analyse how the outputs differ for different planning\nstrategies. The study demonstrates that formulating the plans as\nquestion-answer pairs leads to more coherent generated stories while the plan\ngives more control to the story creators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razumovskaia_E/0/1/0/all/0/1\">Evgeniia Razumovskaia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Annie Louis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1\">Shashi Narayan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ByGPT5: End-to-End Style-conditioned Poetry Generation with Token-free Language Models. (arXiv:2212.10474v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10474","description":"<p>State-of-the-art poetry generation systems are often complex. They either\nconsist of task-specific model pipelines, incorporate prior knowledge in the\nform of manually created constraints or both. In contrast, end-to-end models\nwould not suffer from the overhead of having to model prior knowledge and could\nlearn the nuances of poetry from data alone, reducing the degree of human\nsupervision required. In this work, we investigate end-to-end poetry generation\nconditioned on styles such as rhyme, meter, and alliteration. We identify and\naddress lack of training data and mismatching tokenization algorithms as\npossible limitations of past attempts. In particular, we successfully pre-train\nand release ByGPT5, a new token-free decoder-only language model, and fine-tune\nit on a large custom corpus of English and German quatrains annotated with our\nstyles. We show that ByGPT5 outperforms other models such as mT5, ByT5, GPT-2\nand ChatGPT, while also being more parameter efficient and performing favorably\ncompared to humans. In addition, we analyze its runtime performance and\nintrospect the model's understanding of style conditions. We make our code,\nmodels, and datasets publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belouadi_J/0/1/0/all/0/1\">Jonas Belouadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Execution-Based Evaluation for Open-Domain Code Generation. (arXiv:2212.10481v1 [cs.SE])","link":"http://arxiv.org/abs/2212.10481","description":"<p>To extend the scope of coding queries to more realistic settings, we propose\nODEX, the first open-domain execution-based natural language (NL) to code\ngeneration dataset. ODEX has 945 NL-Code pairs spanning 79 diverse libraries,\nalong with 1,707 human-written test cases for execution. Our NL-Code pairs are\nharvested from StackOverflow forums to encourage natural and practical coding\nqueries, which are then carefully rephrased to ensure intent clarity and\nprevent potential data memorization. Moreover, ODEX supports four natural\nlanguages as intents, in English, Spanish, Japanese, and Russian. ODEX unveils\nintriguing behavioral differences between top-performing Code LMs: Codex\nperforms better on open-domain queries, yet CodeGen captures a better balance\nbetween open- and closed-domain. ODEX corroborates the merits of\nexecution-based evaluation over metrics without execution but also unveils\ntheir complementary effects. Powerful models such as CodeGen-6B only achieve an\n11.96 pass rate at top-1 prediction, suggesting plenty of headroom for\nimprovement. We release ODEX to facilitate research into open-domain problems\nfor the code generation community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiruo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Precise Zero-Shot Dense Retrieval without Relevance Labels. (arXiv:2212.10496v1 [cs.IR])","link":"http://arxiv.org/abs/2212.10496","description":"<p>While dense retrieval has been shown effective and efficient across tasks and\nlanguages, it remains difficult to create effective fully zero-shot dense\nretrieval systems when no relevance label is available. In this paper, we\nrecognize the difficulty of zero-shot learning and encoding relevance. Instead,\nwe propose to pivot through Hypothetical Document Embeddings~(HyDE). Given a\nquery, HyDE first zero-shot instructs an instruction-following language model\n(e.g. InstructGPT) to generate a hypothetical document. The document captures\nrelevance patterns but is unreal and may contain false details. Then, an\nunsupervised contrastively learned encoder~(e.g. Contriever) encodes the\ndocument into an embedding vector. This vector identifies a neighborhood in the\ncorpus embedding space, where similar real documents are retrieved based on\nvector similarity. This second step ground the generated document to the actual\ncorpus, with the encoder's dense bottleneck filtering out the incorrect\ndetails. Our experiments show that HyDE significantly outperforms the\nstate-of-the-art unsupervised dense retriever Contriever and shows strong\nperformance comparable to fine-tuned retrievers, across various tasks (e.g. web\nsearch, QA, fact verification) and languages~(e.g. sw, ko, ja).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xueguang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jimmy Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SimpleStyle: An Adaptable Style Transfer Approach. (arXiv:2212.10498v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10498","description":"<p>Attribute Controlled Text Rewriting, also known as text style transfer, has\nreceived significant attention in the natural language generation community due\nto its crucial role in controllable natural language generation systems. In\nthis work we present SimpleStyle a minimalist yet effective approach for\nattribute controlled text rewriting based on a simple mechanism composed of two\ningredients. controlled denoising and output filtering. Despite the simplicity\nof our approach, which can be succinctly explained with just a few lines of\ncode, it is competitive with previous state-of-the-art methods both in\nautomatic and in human evaluations. Additionally, we demonstrate the practical\neffectiveness of our system, by applying it to real-world data from social\nnetworks. Additionally, we introduce a soft masking sampling technique that\nfurther improves the performance of the system. We also show that feeding the\noutput of our system into a text-to-text student model can produce high-quality\nresults without the need for additional filtering. Finally, we suggest that our\nmethod can solve the fundamental missing baseline absence that holding progress\nin the field by offering our protocol as a simple, adaptive and very strong\nbaseline for works wish to make incremental advancements in the field of\nattribute controlled text rewriting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bandel_E/0/1/0/all/0/1\">Elron Bandel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ein_Dor_L/0/1/0/all/0/1\">Liat Ein-Dor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Measure-Theoretic Characterization of Tight Language Models. (arXiv:2212.10502v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10502","description":"<p>Language modeling, a central task in natural language processing, involves\nestimating a probability distribution over strings. In most cases, the\nestimated distribution sums to 1 over all finite strings. However, in some\npathological cases, probability mass can ``leak'' onto the set of infinite\nsequences. In order to characterize the notion of leakage more precisely, this\npaper offers a measure-theoretic treatment of language modeling. We prove that\nmany popular language model families are in fact tight, meaning that they will\nnot leak in this sense. We also generalize characterizations of tightness\nproposed in previous works.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hennigen_L/0/1/0/all/0/1\">Lucas Torroba Hennigen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1\">Jason Eisner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mini-Model Adaptation: Efficiently Extending Pretrained Models to New Languages via Aligned Shallow Training. (arXiv:2212.10503v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10503","description":"<p>Prior work has shown that it is possible to expand pretrained Masked Language\nModels (MLMs) to new languages by learning a new set of embeddings, while\nkeeping the transformer body frozen. Despite learning a small subset of\nparameters, this approach is not compute-efficient, as training the new\nembeddings requires a full forward and backward pass over the entire model. In\nthis work, we propose mini-model adaptation, a compute-efficient alternative\nthat builds a shallow mini-model from a fraction of a large model's parameters.\nNew language-specific embeddings can then be efficiently trained over the\nmini-model, and plugged into the aligned large model for rapid cross-lingual\ntransfer. We explore two approaches to learn mini-models: MiniJoint, which\njointly pretrains the primary model and the mini-model using a single\ntransformer with a secondary MLM head at a middle layer; and MiniPost, where we\nstart from a regular pretrained model and build a mini-model by extracting and\nfreezing a few layers and learning a small number of parameters on top.\nExperiments on XNLI, MLQA and PAWS-X show that mini-model adaptation matches\nthe performance of the standard approach using up to 2.4x less compute.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marchisio_K/0/1/0/all/0/1\">Kelly Marchisio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_P/0/1/0/all/0/1\">Patrick Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Current Task-oriented Dialogue Models Automate Real-world Scenarios in the Wild?. (arXiv:2212.10504v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10504","description":"<p>Task-oriented dialogue (TOD) systems are mainly based on the\nslot-filling-based TOD (SF-TOD) framework, in which dialogues are broken down\ninto smaller, controllable units (i.e., slots) to fulfill a specific task. A\nseries of approaches based on this framework achieved remarkable success on\nvarious TOD benchmarks. However, we argue that the current TOD benchmarks are\nlimited to surrogate real-world scenarios and that the current TOD models are\nstill a long way from unraveling the scenarios. In this position paper, we\nfirst identify current status and limitations of SF-TOD systems. After that, we\nexplore the WebTOD framework, the alternative direction for building a scalable\nTOD system when a web/mobile interface is available. In WebTOD, the dialogue\nsystem learns how to understand the web/mobile interface that the human agent\ninteracts with, powered by a large-scale language model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Woo Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ko_D/0/1/0/all/0/1\">Donghyeon Ko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ham_D/0/1/0/all/0/1\">Donghoon Ham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Youngki Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Shin Ah Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_H/0/1/0/all/0/1\">Hyunhoon Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1\">Wangkyo Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwak_D/0/1/0/all/0/1\">Donghyun Kwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noh_H/0/1/0/all/0/1\">Hyungsuk Noh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_W/0/1/0/all/0/1\">Woomyoung Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DePlot: One-shot visual language reasoning by plot-to-table translation. (arXiv:2212.10505v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10505","description":"<p>Visual language such as charts and plots is ubiquitous in the human world.\nComprehending plots and charts requires strong reasoning skills. Prior\nstate-of-the-art (SOTA) models require at least tens of thousands of training\nexamples and their reasoning capabilities are still much limited, especially on\ncomplex human-written queries. This paper presents the first one-shot solution\nto visual language reasoning. We decompose the challenge of visual language\nreasoning into two steps: (1) plot-to-text translation, and (2) reasoning over\nthe translated text. The key in this method is a modality conversion module,\nnamed as DePlot, which translates the image of a plot or chart to a linearized\ntable. The output of DePlot can then be directly used to prompt a pretrained\nlarge language model (LLM), exploiting the few-shot reasoning capabilities of\nLLMs. To obtain DePlot, we standardize the plot-to-table task by establishing\nunified task formats and metrics, and train DePlot end-to-end on this task.\nDePlot can then be used off-the-shelf together with LLMs in a plug-and-play\nfashion. Compared with a SOTA model finetuned on more than &gt;28k data points,\nDePlot+LLM with just one-shot prompting achieves a 24.0% improvement over\nfinetuned SOTA on human-written queries from the task of chart QA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1\">Julian Martin Eisenschlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piccinno_F/0/1/0/all/0/1\">Francesco Piccinno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krichene_S/0/1/0/all/0/1\">Syrine Krichene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_C/0/1/0/all/0/1\">Chenxi Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kenton Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1\">Mandar Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altun_Y/0/1/0/all/0/1\">Yasemin Altun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interleaving Retrieval with Chain-of-Thought Reasoning for Knowledge-Intensive Multi-Step Questions. (arXiv:2212.10509v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10509","description":"<p>Recent work has shown that large language models are capable of generating\nnatural language reasoning steps or Chains-of-Thoughts (CoT) to answer a\nmulti-step question when prompted to do so. This is insufficient, however, when\nthe necessary knowledge is not available or up-to-date within a model's\nparameters. A straightforward approach to address this is to retrieve text from\nan external knowledge source using the question as a query and prepend it as\ncontext to the model's input. This, however, is also insufficient for\nmulti-step QA where \\textit{what to retrieve} depends on \\textit{what has\nalready been derived}. To address this issue we propose IRCoT, a new approach\nthat interleaves retrieval with CoT for multi-step QA, guiding the retrieval\nwith CoT and in turn using retrieved results to improve CoT. Our experiments\nwith GPT3 show substantial improvements in retrieval (up to 22 points) and\ndownstream QA (up to 16 points) over the baselines on four datasets: HotpotQA,\n2WikiMultihopQA, MuSiQue, and IIRC. Notably, our method also works well for\nmuch smaller models such as T5-Flan-large (0.7B) without any additional\ntraining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1\">Harsh Trivedi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Not to Trust Language Models: Investigating Effectiveness and Limitations of Parametric and Non-Parametric Memories. (arXiv:2212.10511v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10511","description":"<p>Despite their impressive performance on diverse tasks, large language models\n(LMs) still struggle with tasks requiring rich world knowledge, implying the\nlimitations of relying solely on their parameters to encode a wealth of world\nknowledge. This paper aims to understand LMs' strengths and limitations in\nmemorizing factual knowledge, by conducting large-scale knowledge probing\nexperiments of 10 models and 4 augmentation methods on PopQA, our new\nopen-domain QA dataset with 14k questions. We find that LMs struggle with less\npopular factual knowledge, and that scaling fails to appreciably improve\nmemorization of factual knowledge in the tail. We then show that\nretrieval-augmented LMs largely outperform orders of magnitude larger LMs,\nwhile unassisted LMs remain competitive in questions about high-popularity\nentities. Based on those findings, we devise a simple, yet effective, method\nfor powerful and efficient retrieval-augmented LMs, which retrieves\nnon-parametric memories only when necessary. Experimental results show that\nthis significantly improves models' performance while reducing the inference\ncosts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1\">Alex Mallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1\">Rajarshi Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CausalDialogue: Modeling Utterance-level Causality in Conversations. (arXiv:2212.10515v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10515","description":"<p>Despite their widespread adoption, neural conversation models have yet to\nexhibit natural chat capabilities with humans. In this research, we examine\nuser utterances as causes and generated responses as effects, recognizing that\nchanges in a cause should produce a different effect. To further explore this\nconcept, we have compiled and expanded upon a new dataset called CausalDialogue\nthrough crowd-sourcing. This dataset includes multiple cause-effect pairs\nwithin a directed acyclic graph (DAG) structure. Our analysis reveals that\ntraditional loss functions can struggle to effectively incorporate the DAG\nstructure, leading us to propose a causality-enhanced method called Exponential\nMaximum Average Treatment Effect (ExMATE) to enhance the impact of causality at\nthe utterance level in training neural conversation models. To evaluate the\neffectiveness of this approach, we have built a comprehensive benchmark using\nthe CausalDialogue dataset leveraging large-scale pre-trained language models,\nand have assessed the results through both human and automatic evaluation\nmetrics for coherence, diversity, and agility. Our findings show that current\ntechniques are still unable to effectively address conversational DAGs, and\nthat the ExMATE method can improve the diversity and agility of conventional\nloss functions while maintaining coherence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1\">Yi-Lin Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wenda Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxon_M/0/1/0/all/0/1\">Michael Saxon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryor_C/0/1/0/all/0/1\">Connor Pryor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Getoor_L/0/1/0/all/0/1\">Lise Getoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Privacy-Preserving Domain Adaptation of Semantic Parsers. (arXiv:2212.10520v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10520","description":"<p>Task-oriented dialogue systems often assist users with personal or\nconfidential matters. For this reason, the developers of such a system are\ngenerally prohibited from observing actual usage. So how can they know where\nthe system is failing and needs more training data or new functionality? In\nthis work, we study ways in which realistic user utterances can be generated\nsynthetically, to help increase the linguistic and functional coverage of the\nsystem, without compromising the privacy of actual users. To this end, we\npropose a two-stage Differentially Private (DP) generation method which first\ngenerates latent semantic parses, and then generates utterances based on the\nparses. Our proposed approach improves MAUVE by 3.8$\\times$ and parse tree\nnode-type overlap by 1.4$\\times$ relative to current approaches for private\nsynthetic data generation, improving both on fluency and semantic coverage. We\nfurther validate our approach on a realistic domain adaptation task of adding\nnew functionality from private user data to a semantic parser, and show gains\nof 1.3$\\times$ on its accuracy with the new feature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mireshghallah_F/0/1/0/all/0/1\">Fatemehsadat Mireshghallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_R/0/1/0/all/0/1\">Richard Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1\">Jason Eisner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformers Go for the LOLs: Generating (Humourous) Titles from Scientific Abstracts End-to-End. (arXiv:2212.10522v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10522","description":"<p>We consider the end-to-end abstract-to-title generation problem, exploring\nseven recent transformer based models (including ChatGPT) fine-tuned on more\nthan 30k abstract-title pairs from NLP and machine learning venues. As an\nextension, we also consider the harder problem of generating humorous paper\ntitles. For the latter, we compile the first large-scale humor annotated\ndataset for scientific papers in the NLP/ML domains, comprising almost 2.5k\ntitles. We evaluate all models using human and automatic metrics. Our human\nevaluation suggests that our best end-to-end system performs similarly to human\nauthors (but arguably slightly worse). Generating funny titles is more\ndifficult, however, and our automatic systems clearly underperform relative to\nhumans and often learn dataset artefacts of humor. Finally, ChatGPT, without\nany fine-tuning, performs on the level of our best fine-tuned system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding Tasks. (arXiv:2212.10525v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10525","description":"<p>Spoken language understanding (SLU) tasks have been studied for many decades\nin the speech research community, but have not received as much attention as\nlower-level tasks like speech and speaker recognition. In particular, there are\nnot nearly as many SLU task benchmarks, and many of the existing ones use data\nthat is not freely available to all researchers. Recent work has begun to\nintroduce such benchmark datasets for several tasks. In this work, we introduce\nseveral new annotated SLU benchmark tasks based on freely available speech\ndata, which complement existing benchmarks and address gaps in the SLU\nevaluation landscape. We contribute four tasks: question answering and\nsummarization involve inference over longer speech sequences; named entity\nlocalization addresses the speech-specific task of locating the targeted\ncontent in the signal; dialog act classification identifies the function of a\ngiven speech utterance. We follow the blueprint of the Spoken Language\nUnderstanding Evaluation (SLUE) benchmark suite. In order to facilitate the\ndevelopment of SLU models that leverage the success of pre-trained speech\nrepresentations, we will be publishing for each task (i) annotations for a\nrelatively small fine-tuning set, (ii) annotated development and test sets, and\n(iii) baseline models for easy reproducibility and comparisons. In this work,\nwe present the details of data collection and annotation and the performance of\nthe baseline models. We also perform sensitivity analysis of pipeline models'\nperformance (speech recognizer + text model) to the speech recognition\naccuracy, using more than 20 state-of-the-art speech recognition models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shon_S/0/1/0/all/0/1\">Suwon Shon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Siddhant Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chyi-Jiunn Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasad_A/0/1/0/all/0/1\">Ankita Pasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Felix Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Roshan Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Challenges of Open Domain Multi-Document Summarization. (arXiv:2212.10526v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10526","description":"<p>Multi-document summarization (MDS) has traditionally been studied assuming a\nset of ground-truth topic-related input documents is provided. In practice, the\ninput document set is unlikely to be available a priori and would need to be\nretrieved based on an information need, a setting we call open-domain MDS. We\nexperiment with current state-of-the-art retrieval and summarization models on\nseveral popular MDS datasets extended to the open-domain setting. We find that\nexisting summarizers suffer large reductions in performance when applied as-is\nto this more realistic task, though training summarizers with retrieved inputs\ncan reduce their sensitivity retrieval errors. To further probe these findings,\nwe conduct perturbation experiments on summarizer inputs to study the impact of\ndifferent types of document retrieval errors. Based on our results, we provide\npractical guidelines to help facilitate a shift to open-domain MDS. We release\nour code and experimental results alongside all data or model artifacts created\nduring our investigation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_J/0/1/0/all/0/1\">John Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1\">Luca Soldaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bader_G/0/1/0/all/0/1\">Gary Bader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">Kyle Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lucy Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HYRR: Hybrid Infused Reranking for Passage Retrieval. (arXiv:2212.10528v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10528","description":"<p>We present Hybrid Infused Reranking for Passages Retrieval (HYRR), a\nframework for training rerankers based on a hybrid of BM25 and neural retrieval\nmodels. Retrievers based on hybrid models have been shown to outperform both\nBM25 and neural models alone. Our approach exploits this improved performance\nwhen training a reranker, leading to a robust reranking model. The reranker, a\ncross-attention neural model, is shown to be robust to different first-stage\nretrieval systems, achieving better performance than rerankers simply trained\nupon the first-stage retrievers in the multi-stage systems. We present\nevaluations on a supervised passage retrieval task using MS MARCO and zero-shot\nretrieval tasks using BEIR. The empirical results show strong performance on\nboth evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hall_K/0/1/0/all/0/1\">Keith Hall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Ji Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is GPT-3 a Psychopath? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10529","description":"<p>Are large language models (LLMs) like GPT-3 psychologically safe? In this\nwork, we design unbiased prompts to evaluate LLMs systematically from a\npsychological perspective. Firstly, we test the personality traits of three\ndifferent LLMs with Short Dark Triad (SD-3) and Big Five Inventory (BFI). We\nfind all of them show higher scores on SD-3 than the human average, indicating\na relatively darker personality. Furthermore, LLMs like InstructGPT and\nFLAN-T5, which are fine-tuned with safety metrics, do not necessarily have more\npositive personalities. They score higher on Machiavellianism and Narcissism\nthan GPT-3. Secondly, we test the LLMs in GPT-3 series on well-being tests to\nstudy the impact of fine-tuning with more training data. Interestingly, we\nobserve a continuous increase in well-being scores from GPT-3 to InstructGPT.\nFollowing the observations, we show that instruction-finetune FLAN-T5 with\npositive answers in BFI can effectively improve the model from a psychological\nperspective. Finally, we call on the community to evaluate and improve LLMs'\nsafety systematically instead of at the sentence level only.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yutong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DISCO: Distilling Phrasal Counterfactuals with Large Language Models. (arXiv:2212.10534v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10534","description":"<p>Recent methods demonstrate that data augmentation using counterfactual\nknowledge can teach models the causal structure of a task, leading to robust\nand generalizable models. However, such counterfactual data often has a limited\nscale and diversity if crowdsourced and is computationally expensive to extend\nto new perturbation types if generated using supervised methods. To address\nthis, we introduce a new framework called DISCO for automatically generating\nhigh-quality counterfactual data at scale. DISCO engineers prompts to generate\nphrasal perturbations with a large general language model. Then, a\ntask-specific teacher model filters the generation to distill high-quality\ncounterfactual data. We show that learning with this counterfactual data yields\na comparatively small student model that is 6% (absolute) more robust and\ngeneralizes 5% better across distributions than baselines on various\nchallenging evaluations. This model is also 15% more sensitive in\ndifferentiating original and counterfactual examples, on three evaluation sets\nwritten by human workers and via human-AI collaboration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qiyue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Richardson_K/0/1/0/all/0/1\">Kyle Richardson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Deep Learning for Mathematical Reasoning. (arXiv:2212.10535v1 [cs.AI])","link":"http://arxiv.org/abs/2212.10535","description":"<p>Mathematical reasoning is a fundamental aspect of human intelligence and is\napplicable in various fields, including science, engineering, finance, and\neveryday life. The development of artificial intelligence (AI) systems capable\nof solving math problems and proving theorems has garnered significant interest\nin the fields of machine learning and natural language processing. For example,\nmathematics serves as a testbed for aspects of reasoning that are challenging\nfor powerful deep learning models, driving new algorithmic and modeling\nadvances. On the other hand, recent advances in large-scale neural language\nmodels have opened up new benchmarks and opportunities to use deep learning for\nmathematical reasoning. In this survey paper, we review the key tasks,\ndatasets, and methods at the intersection of mathematical reasoning and deep\nlearning over the past decade. We also evaluate existing benchmarks and\nmethods, and discuss future research directions in this domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Liang Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measure More, Question More: Experimental Studies on Transformer-based Language Models and Complement Coercion. (arXiv:2212.10536v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10536","description":"<p>Transformer-based language models have shown strong performance on an array\nof natural language understanding tasks. However, the question of how these\nmodels react to implicit meaning has been largely unexplored. We investigate\nthis using the complement coercion phenomenon, which involves sentences like\n\"The student finished the book about sailing\" where the action \"reading\" is\nimplicit. We compare LMs' surprisal estimates at various critical sentence\nregions in sentences with and without implicit meaning. Effects associated with\nrecovering implicit meaning were found at a critical region other than where\nsentences minimally differ. We then use follow-up experiments to factor out\npotential confounds, revealing different perspectives that offer a richer and\nmore accurate picture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuling Gu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does CLIP Bind Concepts? Probing Compositionality in Large Image Models. (arXiv:2212.10537v1 [cs.CV])","link":"http://arxiv.org/abs/2212.10537","description":"<p>Large-scale models combining text and images have made incredible progress in\nrecent years. However, they can still fail at tasks requiring compositional\nknowledge, such as correctly picking out a red cube from a picture of multiple\nshapes. We examine the ability of CLIP (Radford et al., 2021), to caption\nimages requiring compositional knowledge. We implement five compositional\nlanguage models to probe the kinds of structure that CLIP may be using, and\ndevelop a novel training algorithm, Compositional Skipgram for Images (CoSI),\nto train these models. We look at performance in attribute-based tasks,\nrequiring the identification of a particular combination of attribute and\nobject (such as \"red cube\"), and in relational settings, where the spatial\nrelation between two shapes (such as \"cube behind sphere\") must be identified.\nWe find that in some conditions, CLIP is able to learn attribute-object\nlabellings, and to generalize to unseen attribute-object combinations. However,\nwe also see evidence that CLIP is not able to bind features together reliably.\nMoreover, CLIP is not able to reliably learn relations between objects, whereas\nsome compositional models are able to learn these perfectly. Of the five models\nwe developed, none were able to generalize to unseen relations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Martha Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qinan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merullo_J/0/1/0/all/0/1\">Jack Merullo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlick_E/0/1/0/all/0/1\">Ellie Pavlick</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good movie, and a good prompt too?. (arXiv:2212.10539v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10539","description":"<p>Large language models can perform new tasks in a zero-shot fashion, given\nnatural language prompts that specify the desired behavior. Such prompts are\ntypically hand engineered, but can also be learned with gradient-based methods\nfrom labeled data. However, it is underexplored what factors make the prompts\neffective, especially when the prompts are natural language. In this paper, we\ninvestigate common attributes shared by effective prompts. We first propose a\nhuman readable prompt tuning method (F LUENT P ROMPT) based on Langevin\ndynamics that incorporates a fluency constraint to find a diverse distribution\nof effective and fluent prompts. Our analysis reveals that effective prompts\nare topically related to the task domain and calibrate the prior probability of\nlabel words. Based on these findings, we also propose a method for generating\nprompts using only unlabeled data, outperforming strong baselines by an average\nof 7.0% accuracy across three tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaochuang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonen_H/0/1/0/all/0/1\">Hila Gonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holtzman_A/0/1/0/all/0/1\">Ari Holtzman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts. (arXiv:2212.10543v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10543","description":"<p>Text detoxification has the potential to mitigate the harms of toxicity by\nrephrasing text to remove offensive meaning, but subtle toxicity remains\nchallenging to tackle. We introduce MaRCo, a detoxification algorithm that\ncombines controllable generation and text rewriting methods using a Product of\nExperts with autoencoder language models (LMs). MaRCo uses likelihoods under a\nnon-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to\nmask and potentially replace. We evaluate our method on several subtle toxicity\nand microaggressions datasets, and show that it not only outperforms baselines\non automatic metrics, but MaRCo's rewrites are preferred 2.1 $\\times$ more in\nhuman evaluation. Its applicability to instances of subtle toxicity is\nespecially promising, demonstrating a path forward for addressing increasingly\nelusive online hate.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hallinan_S/0/1/0/all/0/1\">Skyler Hallinan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alisa Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pretraining Without Attention. (arXiv:2212.10544v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10544","description":"<p>Transformers have been essential to pretraining success in NLP. Other\narchitectures have been used, but require attention layers to match benchmark\naccuracy. This work explores pretraining without attention. We test recently\ndeveloped routing layers based on state-space models (SSM) and model\narchitectures based on multiplicative gating. Used together these modeling\nchoices have a large impact on pretraining accuracy. Empirically the proposed\nBidirectional Gated SSM (BiGS) replicates BERT pretraining results without\nattention and can be extended to long-form pretraining of 4096 tokens without\napproximation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junxiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jing Nathan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1\">Albert Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1\">Alexander M. Rush</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DimonGen: Diversified Generative Commonsense Reasoning for Explaining Concept Relationships. (arXiv:2212.10545v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10545","description":"<p>In this paper, we propose DimonGen, which aims to generate diverse sentences\ndescribing concept relationships in various everyday scenarios. To support\nthis, we create a benchmark dataset for this task by adapting the existing\nCommonGen dataset and propose a two-stage model called MoREE (Mixture of\nRetrieval-Enhanced Experts) to generate the target sentences. MoREE consists of\na mixture of retriever models that retrieve diverse context sentences related\nto the given concepts, and a mixture of generator models that generate diverse\nsentences based on the retrieved contexts. We conduct experiments on the\nDimonGen task and show that MoREE outperforms strong baselines in terms of both\nthe quality and diversity of the generated sentences. Our results demonstrate\nthat MoREE is able to generate diverse sentences that reflect different\nrelationships between concepts, leading to a comprehensive understanding of\nconcept relationships.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chenzhengyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kerui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantically-informed Hierarchical Event Modeling. (arXiv:2212.10547v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10547","description":"<p>Prior work has shown that coupling sequential latent variable models with\nsemantic ontological knowledge can improve the representational capabilities of\nevent modeling approaches. In this work, we present a novel, doubly\nhierarchical, semi-supervised event modeling framework that provides structural\nhierarchy while also accounting for ontological hierarchy. Our approach\nconsists of multiple layers of structured latent variables, where each\nsuccessive layer compresses and abstracts the previous layers. We guide this\ncompression through the injection of structured ontological knowledge that is\ndefined at the type level of events: importantly, our model allows for partial\ninjection of semantic knowledge and it does not depend on observing instances\nat any particular level of the semantic ontology. Across two different datasets\nand four different evaluation metrics, we demonstrate that our approach is able\nto out-perform the previous state-of-the-art approaches, demonstrating the\nbenefits of structured and semantic hierarchical knowledge for event modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dipta_S/0/1/0/all/0/1\">Shubhashis Roy Dipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaee_M/0/1/0/all/0/1\">Mehdi Rezaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feraro_F/0/1/0/all/0/1\">Francis Feraro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"T-Projection: High Quality Annotation Projection for Sequence Labeling Tasks. (arXiv:2212.10548v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10548","description":"<p>In the absence of readily available labeled data for a given task and\nlanguage, annotation projection has been proposed as one of the possible\nstrategies to automatically generate annotated data which may then be used to\ntrain supervised systems. Annotation projection has often been formulated as\nthe task of projecting, on parallel corpora, some labels from a source into a\ntarget language. In this paper we present T-Projection, a new approach for\nannotation projection that leverages large pretrained text2text language models\nand state-of-the-art machine translation technology. T-Projection decomposes\nthe label projection task into two subtasks: (i) The candidate generation step,\nin which a set of projection candidates using a multilingual T5 model is\ngenerated and, (ii) the candidate selection step, in which the candidates are\nranked based on translation probabilities. We evaluate our method in three\ndownstream tasks and five different languages. Our results show that\nT-projection improves the average F1 score of previous methods by more than 8\npoints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Ferrero_I/0/1/0/all/0/1\">Iker Garc&#xed;a-Ferrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1\">German Rigau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-modal Attention Congruence Regularization for Vision-Language Relation Alignment. (arXiv:2212.10549v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10549","description":"<p>Despite recent progress towards scaling up multimodal vision-language models,\nthese models are still known to struggle on compositional generalization\nbenchmarks such as Winoground. We find that a critical component lacking from\ncurrent vision-language models is relation-level alignment: the ability to\nmatch directional semantic relations in text (e.g., \"mug in grass\") with\nspatial relationships in the image (e.g., the position of the mug relative to\nthe grass). To tackle this problem, we show that relation alignment can be\nenforced by encouraging the directed language attention from 'mug' to 'grass'\n(capturing the semantic relation 'in') to match the directed visual attention\nfrom the mug to the grass. Tokens and their corresponding objects are softly\nidentified using the cross-modal attention. We prove that this notion of soft\nrelation alignment is equivalent to enforcing congruence between vision and\nlanguage attention matrices under a 'change of basis' provided by the\ncross-modal attention matrix. Intuitively, our approach projects visual\nattention into the language attention space to calculate its divergence from\nthe actual language attention, and vice versa. We apply our Cross-modal\nAttention Congruence Regularization (CACR) loss to UNITER and improve on the\nstate-of-the-art approach to Winoground.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pandey_R/0/1/0/all/0/1\">Rohan Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Rulin Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Paul Pu Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1\">Louis-Philippe Morency</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation. (arXiv:2212.10551v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10551","description":"<p>Traditional multilingual neural machine translation (MNMT) uses a single\nmodel to translate all directions. However, with the increasing scale of\nlanguage pairs, simply using a single model for massive MNMT brings new\nchallenges: parameter tension and large computations. In this paper, we revisit\nmulti-way structures by assigning an individual branch for each language\n(group). Despite being a simple architecture, it is challenging to train\nde-centralized models due to the lack of constraints to align representations\nfrom all languages. We propose a localized training recipe to map different\nbranches into a unified space, resulting in an efficient detachable model,\nLego-MT. For a fair comparison, we collect data from OPUS and build the first\nlarge-scale open-source translation benchmark covering 7 language-centric data,\neach containing 445 language pairs. Experiments show that Lego-MT (1.2B) brings\ngains of more than 4 BLEU while outperforming M2M-100 (12B) (We will public all\ntraining data, models, and checkpoints)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1\">Fei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yinquan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">WenHao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Length-Extrapolatable Transformer. (arXiv:2212.10554v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10554","description":"<p>Position modeling plays a critical role in Transformers. In this paper, we\nfocus on length extrapolation, i.e., training on short texts while evaluating\nlonger sequences. We define attention resolution as an indicator of\nextrapolation. Then we propose two designs to improve the above metric of\nTransformers. Specifically, we introduce a relative position embedding to\nexplicitly maximize attention resolution. Moreover, we use blockwise causal\nattention during inference for better resolution. We evaluate different\nTransformer variants with language modeling. Experimental results show that our\nmodel achieves strong performance in both interpolation and extrapolation\nsettings. The code will be available at https://aka.ms/LeX-Transformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yutao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patra_B/0/1/0/all/0/1\">Barun Patra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benhaim_A/0/1/0/all/0/1\">Alon Benhaim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_V/0/1/0/all/0/1\">Vishrav Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xia Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PairReranker: Pairwise Reranking for Natural Language Generation. (arXiv:2212.10555v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10555","description":"<p>Pre-trained language models have been successful in natural language\ngeneration (NLG) tasks. While various decoding methods have been employed, they\noften produce suboptimal results. We first present an empirical analysis of\nthree NLG tasks: summarization, machine translation, and constrained text\ngeneration. We found that selecting the best output from the results of\nmultiple decoding methods can significantly improve performance. To further\nimprove reranking for NLG tasks, we proposed a novel method,\n\\textsc{PairReranker}, which uses a single encoder and a pairwise loss function\nto jointly encode a source input and a pair of candidates and compare them.\nExperiments on three NLG tasks demonstrated the effectiveness and flexibility\nof \\textsc{PairReranker}, showing strong results, compared with previous\nbaselines. In addition, our \\textsc{PairReranker} can generalize to\nsignificantly improve GPT-3 (text-davinci-003) results (e.g., 24.55\\% on\nCommonGen and 11.35\\% on WMT18 zh-en), even though our rerankers are not\ntrained with any GPT-3 candidates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Dongfu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines. (arXiv:2212.10557v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10557","description":"<p>Dialogue models are able to generate coherent and fluent responses, but they\ncan still be challenging to control and may produce non-engaging, unsafe\nresults. This unpredictability diminishes user trust and can hinder the use of\nthe models in the real world. To address this, we introduce DialGuide, a novel\nframework for controlling dialogue model behavior using natural language rules,\nor guidelines. These guidelines provide information about the context they are\napplicable to and what should be included in the response, allowing the models\nto generate responses that are more closely aligned with the developer's\nexpectations and intent. We evaluate DialGuide on three tasks in open-domain\ndialogue response generation: guideline selection, response generation, and\nresponse entailment verification. Our dataset contains 10,737 positive and\n15,467 negative dialogue context-response-guideline triplets across two domains\n- chit-chat and safety. We provide baseline models for the tasks and benchmark\ntheir performance. We also demonstrate that DialGuide is effective in the\ndialogue safety domain, producing safe and engaging responses that follow\ndeveloper guidelines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gella_S/0/1/0/all/0/1\">Spandana Gella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_P/0/1/0/all/0/1\">Patrick Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirschberg_J/0/1/0/all/0/1\">Julia Hirschberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On-the-fly Denoising for Data Augmentation in Natural Language Understanding. (arXiv:2212.10558v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10558","description":"<p>Data Augmentation (DA) is frequently used to automatically provide additional\ntraining data without extra human annotation. However, data augmentation may\nintroduce noisy data that impairs training. To guarantee the quality of\naugmented data, existing methods either assume no noise exists in the augmented\ndata and adopt consistency training or use simple heuristics such as training\nloss and diversity constraints to filter out ``noisy'' data. However, those\nfiltered examples may still contain useful information, and dropping them\ncompletely causes loss of supervision signals. In this paper, based on the\nassumption that the original dataset is cleaner than the augmented data, we\npropose an on-the-fly denoising technique for data augmentation that learns\nfrom soft augmented labels provided by an organic teacher model trained on the\ncleaner original data. A simple self-regularization module is applied to force\nthe model prediction to be consistent across two distinct dropouts to further\nprevent overfitting on noisy labels. Our method can be applied to augmentation\ntechniques in general and can consistently improve the performance on both text\nclassification and question-answering tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why Can GPT Learn In-Context? Language Models Secretly Perform Gradient Descent as Meta Optimizers. (arXiv:2212.10559v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10559","description":"<p>Large pretrained language models have shown surprising In-Context Learning\n(ICL) ability. With a few demonstration input-label pairs, they can predict the\nlabel for an unseen input without additional parameter updates. Despite the\ngreat success in performance, the working mechanism of ICL still remains an\nopen problem. In order to better understand how ICL works, this paper explains\nlanguage models as meta optimizers and understands ICL as a kind of implicit\nfinetuning. Theoretically, we figure out that the Transformer attention has a\ndual form of gradient descent based optimization. On top of it, we understand\nICL as follows: GPT first produces meta gradients according to the\ndemonstration examples, and then these meta gradients are applied to the\noriginal GPT to build an ICL model. Experimentally, we comprehensively compare\nthe behavior of ICL and explicit finetuning based on real tasks to provide\nempirical evidence that supports our understanding. The results prove that ICL\nbehaves similarly to explicit finetuning at the prediction level, the\nrepresentation level, and the attention behavior level. Further, inspired by\nour understanding of meta optimization, we design a momentum-based attention by\nanalogy with the momentum-based gradient descent algorithm. Its consistently\nbetter performance over vanilla attention supports our understanding again from\nanother aspect, and more importantly, it shows the potential to utilize our\nunderstanding for future model designing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yutao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1\">Li Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1\">Yaru Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Instruct: Aligning Language Model with Self Generated Instructions. (arXiv:2212.10560v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10560","description":"<p>Large \"instruction-tuned\" language models (finetuned to respond to\ninstructions) have demonstrated a remarkable ability to generalize zero-shot to\nnew tasks. Nevertheless, they depend heavily on human-written instruction data\nthat is limited in quantity, diversity, and creativity, therefore hindering the\ngenerality of the tuned model. We introduce Self-Instruct, a framework for\nimproving the instruction-following capabilities of pretrained language models\nby bootstrapping off its own generations. Our pipeline generates instruction,\ninput, and output samples from a language model, then prunes them before using\nthem to finetune the original model. Applying our method to vanilla GPT3, we\ndemonstrate a 33% absolute improvement over the original model on\nSuper-NaturalInstructions, on par with the performance of InstructGPT_001,\nwhich is trained with private user data and human annotations. For further\nevaluation, we curate a set of expert-written instructions for novel tasks, and\nshow through human evaluation that tuning GPT3 with Self-Instruct outperforms\nusing existing public instruction datasets by a large margin, leaving only a 5%\nabsolute gap behind InstructGPT_001. Self-Instruct provides an almost\nannotation-free method for aligning pre-trained language models with\ninstructions, and we release our large synthetic dataset to facilitate future\nstudies on instruction tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kordi_Y/0/1/0/all/0/1\">Yeganeh Kordi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Swaroop Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alisa Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parsel: A Unified Natural Language Framework for Algorithmic Reasoning. (arXiv:2212.10561v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10561","description":"<p>Despite recent success in large language model (LLM) reasoning, LLMs still\nstruggle with hierarchical multi-step reasoning like generating complex\nprograms. In these cases, humans often start with a high-level algorithmic\ndesign and implement each part gradually. We introduce Parsel, a framework\nenabling automatic implementation and validation of complex algorithms with\ncode LLMs, based on hierarchical function descriptions in natural language.\nParsel can be used across domains requiring hierarchical reasoning, e.g. code\nsynthesis, theorem proving, and robotic planning. We demonstrate Parsel's\ncapabilities by using it to generate complex programs that cannot currently be\nautomatically implemented from one description and backtranslating Python\nprograms in the APPS dataset. Beyond modeling capabilities, Parsel allows\nproblem-solving with high-level algorithmic designs, benefiting both students\nand professional programmers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zelikman_E/0/1/0/all/0/1\">Eric Zelikman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poesia_G/0/1/0/all/0/1\">Gabriel Poesia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haber_N/0/1/0/all/0/1\">Nick Haber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Character-Aware Models Improve Visual Text Rendering. (arXiv:2212.10562v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10562","description":"<p>Current image generation models struggle to reliably produce well-formed\nvisual text. In this paper, we investigate a key contributing factor: popular\ntext-to-image models lack character-level input features, making it much harder\nto predict a word's visual makeup as a series of glyphs. To quantify the extent\nof this effect, we conduct a series of controlled experiments comparing\ncharacter-aware vs. character-blind text encoders. In the text-only domain, we\nfind that character-aware models provide large gains on a novel spelling task\n(WikiSpell). Transferring these learnings onto the visual domain, we train a\nsuite of image generation models, and show that character-aware variants\noutperform their character-blind counterparts across a range of novel text\nrendering tasks (our DrawText benchmark). Our models set a much higher\nstate-of-the-art on visual spelling, with 30+ point accuracy gains over\ncompetitors on rare words, despite training on far fewer examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Rosanne Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrette_D/0/1/0/all/0/1\">Dan Garrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saharia_C/0/1/0/all/0/1\">Chitwan Saharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1\">William Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_A/0/1/0/all/0/1\">Adam Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1\">Sharan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blok_I/0/1/0/all/0/1\">Irina Blok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mical_R/0/1/0/all/0/1\">RJ Mical</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1\">Mohammad Norouzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1\">Noah Constant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Debiasing NLP Models Without Demographic Information. (arXiv:2212.10563v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10563","description":"<p>Models trained from real-world data tend to imitate and amplify social\nbiases. Although there are many methods suggested to mitigate biases, they\nrequire a preliminary information on the types of biases that should be\nmitigated (e.g., gender or racial bias) and the social groups associated with\neach data sample. In this work, we propose a debiasing method that operates\nwithout any prior knowledge of the demographics in the dataset, detecting\nbiased examples based on an auxiliary model that predicts the main model's\nsuccess and down-weights them during the training process. Results on racial\nand gender bias demonstrate that it is possible to mitigate social biases\nwithout having to use a costly demographic annotation process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Orgad_H/0/1/0/all/0/1\">Hadas Orgad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does unsupervised grammar induction need pixels?. (arXiv:2212.10564v1 [cs.CL])","link":"http://arxiv.org/abs/2212.10564","description":"<p>Are extralinguistic signals such as image pixels crucial for inducing\nconstituency grammars? While past work has shown substantial gains from\nmultimodal cues, we investigate whether such gains persist in the presence of\nrich information from large language models (LLMs). We find that our approach,\nLLM-based C-PCFG (LC-PCFG), outperforms previous multi-modal methods on the\ntask of unsupervised constituency parsing, achieving state-of-the-art\nperformance on a variety of datasets. Moreover, LC-PCFG results in an over 50%\nreduction in parameter count, and speedups in training time of 1.7x for\nimage-aided models and more than 5x for video-aided models, respectively. These\nresults challenge the notion that extralinguistic signals such as image pixels\nare needed for unsupervised grammar induction, and point to the need for better\ntext-only baselines in evaluating the need of multi-modality for the task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Boyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Corona_R/0/1/0/all/0/1\">Rodolfo Corona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mangalam_K/0/1/0/all/0/1\">Karttikeya Mangalam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Catherine Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flaherty_D/0/1/0/all/0/1\">Daniel Flaherty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1\">Serge Belongie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1\">Kilian Q. Weinberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interactive Model with Structural Loss for Language-based Abductive Reasoning. (arXiv:2112.00284v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.00284","description":"<p>The abductive natural language inference task ($\\alpha$NLI) is proposed to\ninfer the most plausible explanation between the cause and the event. In the\n$\\alpha$NLI task, two observations are given, and the most plausible hypothesis\nis asked to pick out from the candidates. Existing methods model the relation\nbetween each candidate hypothesis separately and penalize the inference network\nuniformly. In this paper, we argue that it is unnecessary to distinguish the\nreasoning abilities among correct hypotheses; and similarly, all wrong\nhypotheses contribute the same when explaining the reasons of the observations.\nTherefore, we propose to group instead of ranking the hypotheses and design a\nstructural loss called ``joint softmax focal loss'' in this paper. Based on the\nobservation that the hypotheses are generally semantically related, we have\ndesigned a novel interactive language model aiming at exploiting the rich\ninteraction among competing hypotheses. We name this new model for $\\alpha$NLI:\nInteractive Model with Structural Loss (IMSL). The experimental results show\nthat our IMSL has achieved the highest performance on the RoBERTa-large\npretrained model, with ACC and AUC results increased by about 1\\% and 5\\%\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Ming Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yongfeng Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1\">Ao Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deduplicating Training Data Mitigates Privacy Risks in Language Models. (arXiv:2202.06539v3 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2202.06539","description":"<p>Past work has shown that large language models are susceptible to privacy\nattacks, where adversaries generate sequences from a trained model and detect\nwhich sequences are memorized from the training set. In this work, we show that\nthe success of these attacks is largely due to duplication in commonly used\nweb-scraped training sets. We first show that the rate at which language models\nregenerate training sequences is superlinearly related to a sequence's count in\nthe training set. For instance, a sequence that is present 10 times in the\ntraining data is on average generated ~1000 times more often than a sequence\nthat is present only once. We next show that existing methods for detecting\nmemorized sequences have near-chance accuracy on non-duplicated training\nsequences. Finally, we find that after applying methods to deduplicate training\ndata, language models are considerably more secure against these types of\nprivacy attacks. Taken together, our results motivate an increased focus on\ndeduplication in privacy-sensitive applications and a reevaluation of the\npracticality of existing privacy attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kandpal_N/0/1/0/all/0/1\">Nikhil Kandpal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_E/0/1/0/all/0/1\">Eric Wallace</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"P4E: Few-Shot Event Detection as Prompt-Guided Identification and Localization. (arXiv:2202.07615v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.07615","description":"<p>We propose P4E, an identify-and-localize event detection framework that\nintegrates the best of few-shot prompting and structured prediction. Our\nframework decomposes event detection into an identification task and a\nlocalization task. For the identification task, which we formulate as\nmulti-label classification, we leverage cloze-based prompting to align our\nobjective with the pre-training task of language models, allowing our model to\nquickly adapt to new event types. We then employ an event type-agnostic\nsequence labeling model to localize the event trigger conditioned on the\nidentification output. This heterogeneous model design allows P4E to quickly\nlearn new event types without sacrificing the ability to make structured\npredictions. Our experiments demonstrate the effectiveness of our proposed\ndesign, and P4E shows superior performance for few-shot event detection on\nbenchmark datasets FewEvent and MAVEN and comparable performance to SOTA for\nfully-supervised event detection on ACE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Liyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yiqing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Delving into the Openness of CLIP. (arXiv:2206.01986v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2206.01986","description":"<p>Contrastive Language-Image Pre-training (CLIP) has demonstrated great\npotential in realizing open-vocabulary visual recognition in a matching style,\ndue to its holistic use of natural language supervision that covers\nunconstrained real-world visual concepts. However, it is, in turn, also\ndifficult to evaluate and analyze the openness of CLIP-like models, since they\nare in theory open to any vocabulary but the actual accuracy varies. To address\nthe insufficiency of conventional studies on openness, we resort to an\nincremental perspective and define the extensibility, which essentially\napproximates the model's ability to deal with new visual concepts, by\nevaluating openness through vocabulary expansions. Our evaluation based on\nextensibility shows that CLIP-like models are hardly truly open and their\nperformance degrades as the vocabulary expands to different degrees. Further\nanalysis reveals that the over-estimation of openness is not because CLIP-like\nmodels fail to capture the general similarity of image and text features of\nnovel visual concepts, but because of the confusion among competing text\nfeatures, that is, they are not stable with respect to the vocabulary. In light\nof this, we propose to improve the openness of CLIP in the feature space by\nenforcing the distinguishability of text features. Our method retrieves\nrelevant texts from the pre-training corpus to enhance prompts for inference,\nwhich boosts the extensibility and stability of CLIP even without fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BertNet: Harvesting Knowledge Graphs from Pretrained Language Models. (arXiv:2206.14268v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.14268","description":"<p>Symbolic knowledge graphs (KGs) have been constructed either by expensive\nhuman crowdsourcing or with complex text mining pipelines. The emerging large\npretrained language models (LMs), such as Bert, have shown to implicitly encode\nmassive knowledge which can be queried with properly designed prompts. However,\ncompared to the explicit KGs, the implict knowledge in the black-box LMs is\noften difficult to access or edit and lacks explainability. In this work, we\naim at harvesting symbolic KGs from the LMs, and propose a new framework for\nautomatic KG construction empowered by the neural LMs' flexibility and\nscalability. Compared to prior works that often rely on large human annotated\ndata or existing massive KGs, our approach requires only the minimal definition\nof relations as inputs, and hence is suitable for extracting knowledge of rich\nnew relations that are instantly assigned and not available before. The\nframework automatically generates diverse prompts, and performs efficient\nknowledge search within a given LM for consistent outputs. The knowledge\nharvested with our approach shows competitive quality, diversity, and novelty.\nAs a result, we derive from diverse LMs a family of new KGs (e.g., BertNet and\nRoBERTaNet) that contain a richer set of relations, including some complex ones\n(e.g., \"A is capable of but not good at B\") that cannot be extracted with\nprevious methods. Besides, the resulting KGs also serve as a vehicle to\ninterpret the respective source LMs, leading to new insights into the varying\nknowledge capability of different LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_S/0/1/0/all/0/1\">Shibo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_B/0/1/0/all/0/1\">Bowen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1\">Kaiwen Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1\">Bin Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MILAN: Masked Image Pretraining on Language Assisted Representation. (arXiv:2208.06049v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2208.06049","description":"<p>Self-attention based transformer models have been dominating many computer\nvision tasks in the past few years. Their superb model qualities heavily depend\non the excessively large labeled image datasets. In order to reduce the\nreliance on large labeled datasets, reconstruction based masked autoencoders\nare gaining popularity, which learn high quality transferable representations\nfrom unlabeled images. For the same purpose, recent weakly supervised image\npretraining methods explore language supervision from text captions\naccompanying the images. In this work, we propose masked image pretraining on\nlanguage assisted representation, dubbed as MILAN. Instead of predicting raw\npixels or low level features, our pretraining objective is to reconstruct the\nimage features with substantial semantic signals that are obtained using\ncaption supervision. Moreover, to accommodate our reconstruction target, we\npropose a more effective prompting decoder architecture and a semantic aware\nmask sampling mechanism, which further advance the transfer performance of the\npretrained model. Experimental results demonstrate that MILAN delivers higher\naccuracy than the previous works. When the masked autoencoder is pretrained and\nfinetuned on ImageNet-1K dataset with an input resolution of 224x224, MILAN\nachieves a top-1 accuracy of 85.4% on ViT-Base, surpassing previous\nstate-of-the-arts by 1%. In the downstream semantic segmentation task, MILAN\nachieves 52.7 mIoU using ViT-Base on ADE20K dataset, outperforming previous\nmasked pretraining results by 4 points.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zejiang Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Fei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Kuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kung_S/0/1/0/all/0/1\">Sun-Yuan Kung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing Transformers in Embedding Space. (arXiv:2209.02535v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.02535","description":"<p>Understanding Transformer-based models has attracted significant attention,\nas they lie at the heart of recent technological advances across machine\nlearning. While most interpretability methods rely on running models over\ninputs, recent work has shown that a zero-pass approach, where parameters are\ninterpreted directly without a forward/backward pass is feasible for some\nTransformer parameters, and for two-layer attention networks. In this work, we\npresent a theoretical analysis where all parameters of a trained Transformer\nare interpreted by projecting them into the embedding space, that is, the space\nof vocabulary items they operate on. We derive a simple theoretical framework\nto support our arguments and provide ample evidence for its validity. First, an\nempirical analysis showing that parameters of both pretrained and fine-tuned\nmodels can be interpreted in embedding space. Second, we present two\napplications of our framework: (a) aligning the parameters of different models\nthat share a vocabulary, and (b) constructing a classifier without training by\n``translating'' the parameters of a fine-tuned classifier to parameters of a\ndifferent model that was only pretrained. Overall, our findings open the door\nto interpretation methods that, at least in part, abstract away from model\nspecifics and operate in the embedding space only.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dar_G/0/1/0/all/0/1\">Guy Dar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1\">Mor Geva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Ankit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Optimal Granularity for Extractive Summarization of Unstructured Health Records: Analysis of the Largest Multi-Institutional Archive of Health Records in Japan. (arXiv:2209.10041v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.10041","description":"<p>Automated summarization of clinical texts can reduce the burden of medical\nprofessionals. \"Discharge summaries\" are one promising application of the\nsummarization, because they can be generated from daily inpatient records. Our\npreliminary experiment suggests that 20-31% of the descriptions in discharge\nsummaries overlap with the content of the inpatient records. However, it\nremains unclear how the summaries should be generated from the unstructured\nsource. To decompose the physician's summarization process, this study aimed to\nidentify the optimal granularity in summarization. We first defined three types\nof summarization units with different granularities to compare the performance\nof the discharge summary generation: whole sentences, clinical segments, and\nclauses. We defined clinical segments in this study, aiming to express the\nsmallest medically meaningful concepts. To obtain the clinical segments, it was\nnecessary to automatically split the texts in the first stage of the pipeline.\nAccordingly, we compared rule-based methods and a machine learning method, and\nthe latter outperformed the formers with an F1 score of 0.846 in the splitting\ntask. Next, we experimentally measured the accuracy of extractive summarization\nusing the three types of units, based on the ROUGE-1 metric, on a\nmulti-institutional national archive of health records in Japan. The measured\naccuracies of extractive summarization using whole sentences, clinical\nsegments, and clauses were 31.91, 36.15, and 25.18, respectively. We found that\nthe clinical segments yielded higher accuracy than sentences and clauses. This\nresult indicates that summarization of inpatient records demands finer\ngranularity than sentence-oriented processing. Although we used only Japanese\nhealth records, it can be interpreted as follows: physicians extract \"concepts\nof medical significance\" from patient records and recombine them ...\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ando_K/0/1/0/all/0/1\">Kenichiro Ando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okumura_T/0/1/0/all/0/1\">Takashi Okumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komachi_M/0/1/0/all/0/1\">Mamoru Komachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horiguchi_H/0/1/0/all/0/1\">Hiromasa Horiguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_Y/0/1/0/all/0/1\">Yuji Matsumoto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Interdisciplinary Perspective on Evaluation and Experimental Design for Visual Text Analytics: Position Paper. (arXiv:2209.11534v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2209.11534","description":"<p>Appropriate evaluation and experimental design are fundamental for empirical\nsciences, particularly in data-driven fields. Due to the successes in\ncomputational modeling of languages, for instance, research outcomes are having\nan increasingly immediate impact on end users. As the gap in adoption by end\nusers decreases, the need increases to ensure that tools and models developed\nby the research communities and practitioners are reliable, trustworthy, and\nsupportive of the users in their goals. In this position paper, we focus on the\nissues of evaluating visual text analytics approaches. We take an\ninterdisciplinary perspective from the visualization and natural language\nprocessing communities, as we argue that the design and validation of visual\ntext analytics include concerns beyond computational or visual/interactive\nmethods on their own. We identify four key groups of challenges for evaluating\nvisual text analytics approaches (data ambiguity, experimental design, user\ntrust, and \"big picture\" concerns) and provide suggestions for research\nopportunities from an interdisciplinary perspective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kucher_K/0/1/0/all/0/1\">Kostiantyn Kucher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sultanum_N/0/1/0/all/0/1\">Nicole Sultanum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daza_A/0/1/0/all/0/1\">Angel Daza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simaki_V/0/1/0/all/0/1\">Vasiliki Simaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skeppstedt_M/0/1/0/all/0/1\">Maria Skeppstedt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fekete_J/0/1/0/all/0/1\">Jean-Daniel Fekete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahyar_N/0/1/0/all/0/1\">Narges Mahyar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XNOR-FORMER: Learning Accurate Approximations in Long Speech Transformers. (arXiv:2210.16643v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.16643","description":"<p>Transformers are among the state of the art for many tasks in speech, vision,\nand natural language processing, among others. Self-attentions, which are\ncrucial contributors to this performance have quadratic computational\ncomplexity, which makes training on longer input sequences challenging. Prior\nwork has produced state-of-the-art transformer variants with linear attention,\nhowever, current models sacrifice performance to achieve efficient\nimplementations. In this work, we develop a novel linear transformer by\nexamining the properties of the key-query product within self-attentions. Our\nmodel outperforms state of the art approaches on speech recognition and speech\nsummarization, resulting in 1 % absolute WER improvement on the Librispeech-100\nspeech recognition benchmark and a new INTERVIEW speech recognition benchmark,\nand 5 points on ROUGE for summarization with How2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Roshan Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"lilGym: Natural Language Visual Reasoning with Reinforcement Learning. (arXiv:2211.01994v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2211.01994","description":"<p>We present lilGym, a new benchmark for language-conditioned reinforcement\nlearning in visual environments. lilGym is based on 2,661 highly-compositional\nhuman-written natural language statements grounded in an interactive visual\nenvironment. We introduce a new approach for exact reward computation in every\npossible world state by annotating all statements with executable Python\nprograms. Each statement is paired with multiple start states and reward\nfunctions to form thousands of distinct Markov Decision Processes of varying\ndifficulty. We experiment with lilGym with different models and learning\nregimes. Our results and analysis show that while existing methods are able to\nachieve non-trivial performance, lilGym forms a challenging open problem.\nlilGym is available at https://lil.nlp.cornell.edu/lilgym/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Anne Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1\">Kiant&#xe9; Brantley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kojima_N/0/1/0/all/0/1\">Noriyuki Kojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1\">Yoav Artzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Knowledge Is Needed? Towards Explainable Memory for kNN-MT Domain Adaptation. (arXiv:2211.04052v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.04052","description":"<p>kNN-MT presents a new paradigm for domain adaptation by building an external\ndatastore, which usually saves all target language token occurrences in the\nparallel corpus. As a result, the constructed datastore is usually large and\npossibly redundant. In this paper, we investigate the interpretability issue of\nthis approach: what knowledge does the NMT model need? We propose the notion of\nlocal correctness (LAC) as a new angle, which describes the potential\ntranslation correctness for a single entry and for a given neighborhood.\nEmpirical study shows that our investigation successfully finds the conditions\nwhere the NMT model could easily fail and need related knowledge. Experiments\non six diverse target domains and two language-pairs show that pruning\naccording to local correctness brings a light and more explainable memory for\nkNN-MT domain adaptation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wenhao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1\">Yunzhe Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective. (arXiv:2211.08073v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08073","description":"<p>Pre-trained language models (PLMs) are known to improve the generalization\nperformance of natural language understanding models by leveraging large\namounts of data during the pre-training phase. However, the out-of-distribution\n(OOD) generalization problem remains a challenge in many NLP tasks, limiting\nthe real-world deployment of these methods. This paper presents the first\nattempt at creating a unified benchmark named GLUE-X for evaluating OOD\nrobustness in NLP models, highlighting the importance of OOD robustness and\nproviding insights on how to measure the robustness of a model and how to\nimprove it. The benchmark includes 13 publicly available datasets for OOD\ntesting, and evaluations are conducted on 8 classic NLP tasks over 19 popularly\nused PLMs. Our findings confirm the need for improved OOD accuracy in NLP\ntasks, as significant performance degradation was observed in all settings\ncompared to in-distribution (ID) accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuibai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Libo Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yafu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanmeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-aware Retrieval with Instructions. (arXiv:2211.09260v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.09260","description":"<p>We study the problem of retrieval with instructions, where users of a\nretrieval system explicitly describe their intent along with their queries. We\naim to develop a general-purpose task-aware retrieval system using multi-task\ninstruction tuning, which can follow human-written instructions to find the\nbest documents for a given query. We introduce the first large-scale collection\nof approximately 40 retrieval datasets with instructions, BERRI, and present\nTART, a multi-task retrieval system trained on BERRI with instructions. TART\nshows strong capabilities to adapt to a new retrieval task via instructions and\nadvances the state of the art on two zero-shot retrieval benchmarks, BEIR and\nLOTTE, outperforming models up to three times larger. We further introduce a\nnew evaluation setup, X^2-Retrieval to better reflect real-world scenarios,\nwhere diverse domains and tasks are pooled and a system needs to find documents\naligning users' intents. In this setup, TART significantly outperforms\ncompetitive baselines, further demonstrating the effectiveness of guiding\nretrieval with instructions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schick_T/0/1/0/all/0/1\">Timo Schick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_P/0/1/0/all/0/1\">Patrick Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xilun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Izacard_G/0/1/0/all/0/1\">Gautier Izacard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1\">Sebastian Riedel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning. (arXiv:2211.16773v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.16773","description":"<p>In task-oriented dialogs, an informative and successful system response needs\nto include key information such as the phone number of a hotel. Therefore, we\nhypothesize that a model can achieve better overall performance by focusing on\ncorrectly generating key quantities. In this paper, we propose a new training\nalgorithm, Keywords Reinforcement Learning with Next-word Sampling (KRLS), that\nutilizes Reinforcement Learning but avoids the time-consuming auto-regressive\ngeneration, and a fine-grained per-token reward function to help the model\nlearn keywords generation more robustly. Empirical results show that the KRLS\nalgorithm can achieve state-of-the-art performance on the inform, success, and\ncombined score on the MultiWoZ benchmark dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What do you MEME? Generating Explanations for Visual Semantic Role Labelling in Memes. (arXiv:2212.00715v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2212.00715","description":"<p>Memes are powerful means for effective communication on social media. Their\neffortless amalgamation of viral visuals and compelling messages can have\nfar-reaching implications with proper marketing. Previous research on memes has\nprimarily focused on characterizing their affective spectrum and detecting\nwhether the meme's message insinuates any intended harm, such as hate, offense,\nracism, etc. However, memes often use abstraction, which can be elusive. Here,\nwe introduce a novel task - EXCLAIM, generating explanations for visual\nsemantic role labeling in memes. To this end, we curate ExHVV, a novel dataset\nthat offers natural language explanations of connotative roles for three types\nof entities - heroes, villains, and victims, encompassing 4,680 entities\npresent in 3K memes. We also benchmark ExHVV with several strong unimodal and\nmultimodal baselines. Moreover, we posit LUMEN, a novel multimodal, multi-task\nlearning framework that endeavors to address EXCLAIM optimally by jointly\nlearning to predict the correct semantic roles and correspondingly to generate\nsuitable natural language explanations. LUMEN distinctly outperforms the best\nbaseline across 18 standard natural language generation evaluation metrics. Our\nsystematic evaluation and analyses demonstrate that characteristic multimodal\ncues required for adjudicating semantic roles are also helpful for generating\nsuitable explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1\">Siddhant Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_T/0/1/0/all/0/1\">Tharun Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md. Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unifying Vision, Text, and Layout for Universal Document Processing. (arXiv:2212.02623v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2212.02623","description":"<p>We propose Universal Document Processing (UDOP), a foundation Document AI\nmodel which unifies text, image, and layout modalities together with varied\ntask formats, including document understanding and generation. UDOP leverages\nthe spatial correlation between textual content and document image to model\nimage, text, and layout modalities with one uniform representation. With a\nnovel Vision-Text-Layout Transformer, UDOP unifies pretraining and multi-domain\ndownstream tasks into a prompt-based sequence generation scheme. UDOP is\npretrained on both large-scale unlabeled document corpora using innovative\nself-supervised objectives and diverse labeled data. UDOP also learns to\ngenerate document images from text and layout modalities via masked image\nreconstruction. To the best of our knowledge, this is the first time in the\nfield of document AI that one model simultaneously achieves high-quality neural\ndocument editing and content customization. Our method sets the\nstate-of-the-art on 9 Document AI tasks, e.g., document understanding and QA,\nacross diverse data domains like finance reports, academic papers, and\nwebsites. UDOP ranks first on the leaderboard of the Document Understanding\nBenchmark (DUE).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zineng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuwei Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Cha Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Technical Report -- Competition Solution for Prompt Tuning using Pretrained Language Model. (arXiv:2212.06369v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.06369","description":"<p>Prompt tuning recently becomes a hot-spot in the applications of large\npretrained language models on specific downstream tasks. Regarding the Language\nModel as a Service (LMaaS), black-box tuning using derivative-free optimization\n(DFO) provides a novel approach to expand the practical scenarios of pretrained\nmodels and enrich the researches of few-shot learning. In this report, we\npresent our solution in this competition that is based on the LMaaS scenario.\nOur solution consists of several modifications to BBTv2, including multiple\nlabel words, selection of P0, rolling update strategy, multi-task loss from MLP\nclassifier, and finally using the ensemble method to further improve\ngeneralization ability. We also shared some strategies that we tried but didn't\nuse in the final submission for further discussion. In the end we raised a\nquestion about the SNLI dataset and the impact on the results, as well as our\nconcerns about the competition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jiang-Long Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1\">Wu-He Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Feng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1\">Xiao-Lei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Dong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diverse Demonstrations Improve In-context Compositional Generalization. (arXiv:2212.06800v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.06800","description":"<p>In-context learning has shown great success in i.i.d semantic parsing splits,\nwhere the training and test sets are drawn from the same distribution. In this\nsetup, models are typically prompted with demonstrations that are similar to\nthe input question. However, in the setup of compositional generalization,\nwhere models are tested on outputs with structures that are absent from the\ntraining set, selecting similar demonstrations is insufficient, as often no\nexample will be similar enough to the input. In this work, we propose a method\nto select diverse demonstrations that aims to collectively cover all of the\nstructures required in the output program, in order to encourage the model to\ngeneralize to new structures from these demonstrations. We empirically show\nthat combining diverse demonstrations with in-context learning substantially\nimproves performance across three compositional generalization semantic parsing\ndatasets in the pure in-context learning setup and when combined with\nfinetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Levy_I/0/1/0/all/0/1\">Itay Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogin_B/0/1/0/all/0/1\">Ben Bogin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Detecting and Mitigating Hallucinations in Machine Translation: Model Internal Workings Alone Do Well, Sentence Similarity Even Better. (arXiv:2212.08597v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08597","description":"<p>While the problem of hallucinations in neural machine translation has long\nbeen recognized, so far the progress on its alleviation is very little. Indeed,\nrecently it turned out that without artificially encouraging models to\nhallucinate, previously existing methods fall short and even the standard\nsequence log-probability is more informative. It means that characteristics\ninternal to the model can give much more information than we expect, and before\nusing external models and measures, we first need to ask: how far can we go if\nwe use nothing but the translation model itself ? We propose to use a method\nthat evaluates the percentage of the source contribution to a generated\ntranslation. Intuitively, hallucinations are translations \"detached\" from the\nsource, hence they can be identified by low source contribution. This method\nimproves detection accuracy for the most severe hallucinations by a factor of 2\nand is able to alleviate hallucinations at test time on par with the previous\nbest approach that relies on external models. Next, if we move away from\ninternal model characteristics and allow external tools, we show that using\nsentence similarity from cross-lingual embeddings further improves these\nresults.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dale_D/0/1/0/all/0/1\">David Dale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Voita_E/0/1/0/all/0/1\">Elena Voita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrault_L/0/1/0/all/0/1\">Lo&#xef;c Barrault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1\">Marta R. Costa-juss&#xe0;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems. (arXiv:2212.09252v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09252","description":"<p>Many dialogue systems (DSs) lack characteristics humans have, such as emotion\nperception, factuality, and informativeness. Enhancing DSs with knowledge\nalleviates this problem, but, as many ways of doing so exist, keeping track of\nall proposed methods is difficult. Here, we present the first survey of\nknowledge-enhanced DSs. We define three categories of systems - internal,\nexternal, and hybrid - based on the knowledge they use. We survey the\nmotivation for enhancing DSs with knowledge, used datasets, and methods for\nknowledge search, knowledge encoding, and knowledge incorporation. Finally, we\npropose how to improve existing systems based on theories from linguistics and\ncognitive science.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shaier_S/0/1/0/all/0/1\">Sagi Shaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hunter_L/0/1/0/all/0/1\">Lawrence Hunter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1\">Katharina Kann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NusaCrowd: Open Source Initiative for Indonesian NLP Resources. (arXiv:2212.09648v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09648","description":"<p>We present NusaCrowd, a collaborative initiative to collect and unite\nexisting resources for Indonesian languages, including opening access to\npreviously non-public resources. Through this initiative, we have has brought\ntogether 137 datasets and 117 standardized data loaders. The quality of the\ndatasets has been assessed manually and automatically, and their effectiveness\nhas been demonstrated in multiple experiments. NusaCrowd's data collection\nenables the creation of the first zero-shot benchmarks for natural language\nunderstanding and generation in Indonesian and its local languages.\nFurthermore, NusaCrowd brings the creation of the first multilingual automatic\nspeech recognition benchmark in Indonesian and its local languages. Our work is\nintended to help advance natural language processing research in\nunder-represented languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilie_B/0/1/0/all/0/1\">Bryan Wilie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahendra_R/0/1/0/all/0/1\">Rahmad Mahendra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wibisono_C/0/1/0/all/0/1\">Christian Wibisono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romadhony_A/0/1/0/all/0/1\">Ade Romadhony</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vincentio_K/0/1/0/all/0/1\">Karissa Vincentio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1\">Fajri Koto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santoso_J/0/1/0/all/0/1\">Jennifer Santoso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moeljadi_D/0/1/0/all/0/1\">David Moeljadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirawan_C/0/1/0/all/0/1\">Cahya Wirawan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hudi_F/0/1/0/all/0/1\">Frederikus Hudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmonangan_I/0/1/0/all/0/1\">Ivan Halim Parmonangan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfina_I/0/1/0/all/0/1\">Ika Alfina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicaksono_M/0/1/0/all/0/1\">Muhammad Satrio Wicaksono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putra_I/0/1/0/all/0/1\">Ilham Firdausi Putra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmadani_S/0/1/0/all/0/1\">Samsul Rahmadani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oenang_Y/0/1/0/all/0/1\">Yulianti Oenang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Septiandri_A/0/1/0/all/0/1\">Ali Akbar Septiandri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaya_J/0/1/0/all/0/1\">James Jaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1\">Kaustubh D. Dhole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suryani_A/0/1/0/all/0/1\">Arie Ardiyanti Suryani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Putri_R/0/1/0/all/0/1\">Rifki Afina Putri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_K/0/1/0/all/0/1\">Keith Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nityasya_M/0/1/0/all/0/1\">Made Nindyatama Nityasya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adilazuarda_M/0/1/0/all/0/1\">Muhammad Farid Adilazuarda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ignatius_R/0/1/0/all/0/1\">Ryan Ignatius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diandaru_R/0/1/0/all/0/1\">Ryandito Diandaru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghifari_V/0/1/0/all/0/1\">Vito Ghifari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenliang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damapuspita_D/0/1/0/all/0/1\">Dyah Damapuspita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tho_C/0/1/0/all/0/1\">Cuk Tho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karo_I/0/1/0/all/0/1\">Ichwanul Muslim Karo Karo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fatyanosa_T/0/1/0/all/0/1\">Tirana Noor Fatyanosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sujaini_H/0/1/0/all/0/1\">Herry Sujaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakti_S/0/1/0/all/0/1\">Sakriani Sakti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purwarianti_A/0/1/0/all/0/1\">Ayu Purwarianti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Embedder, Any Task: Instruction-Finetuned Text Embeddings. (arXiv:2212.09741v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09741","description":"<p>We introduce INSTRUCTOR, a new method for computing text embeddings given\ntask instructions: every text input is embedded together with instructions\nexplaining the use case (e.g., task and domain descriptions). Unlike encoders\nfrom prior work that are more specialized, INSTRUCTOR is a single embedder that\ncan generate text embeddings tailored to different downstream tasks and\ndomains, without any further training. We first annotate instructions for 330\ndiverse tasks and train INSTRUCTOR on this multitask mixture with a contrastive\nloss. We evaluate INSTRUCTOR on 70 embedding evaluation tasks (66 of which are\nunseen during training), ranging from classification and information retrieval\nto semantic textual similarity and text generation evaluation. INSTRUCTOR,\nwhile having an order of magnitude fewer parameters than the previous best\nmodel, achieves state-of-the-art performance, with an average improvement of\n3.4% compared to the previous best results on the 70 diverse datasets. Our\nanalysis suggests that INSTRUCTOR is robust to changes in instructions, and\nthat instruction finetuning mitigates the challenge of training a single model\non diverse datasets. Our model, code, and data are available at\nhttps://instructor-embedding.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hongjin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1\">Jungo Kasai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yizhong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yushi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1\">Mari Ostendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1\">Wen-tau Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tao Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Human-Language Model Interaction. (arXiv:2212.09746v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09746","description":"<p>Many real-world applications of language models (LMs), such as code\nautocomplete and writing assistance, involve human-LM interaction. However, the\nmain LM benchmarks are non-interactive in that a system produces output without\nhuman involvement. To evaluate human-LM interaction, we develop a new\nframework, Human-AI Language-based Interaction Evaluation (HALIE), that expands\nnon-interactive evaluation along three dimensions, capturing (i) the\ninteractive process, not only the final output; (ii) the first-person\nsubjective experience, not just a third-party assessment; and (iii) notions of\npreference beyond quality. We then design five tasks ranging from goal-oriented\nto open-ended to capture different forms of interaction. On four\nstate-of-the-art LMs (three variants of OpenAI's GPT-3 and AI21's J1-Jumbo), we\nfind that non-interactive performance does not always result in better human-LM\ninteraction and that first-person and third-party metrics can diverge,\nsuggesting the importance of examining the nuances of human-LM interaction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mina Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1\">Megha Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardy_A/0/1/0/all/0/1\">Amelia Hardy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1\">John Thickstun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1\">Esin Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paranjape_A/0/1/0/all/0/1\">Ashwin Paranjape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerard_Ursin_I/0/1/0/all/0/1\">Ines Gerard-Ursin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lisa Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladhak_F/0/1/0/all/0/1\">Faisal Ladhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_F/0/1/0/all/0/1\">Frieda Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rose E. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_M/0/1/0/all/0/1\">Minae Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Joon Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Hancheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Tony Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bommasani_R/0/1/0/all/0/1\">Rishi Bommasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernstein_M/0/1/0/all/0/1\">Michael Bernstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FRAME: Evaluating Rationale-Label Consistency Metrics for Free-Text Rationales. (arXiv:2207.00779v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2207.00779","description":"<p>Following how humans communicate, free-text rationales aim to use natural\nlanguage to explain neural language model (LM) behavior. However, free-text\nrationales' unconstrained nature makes them prone to hallucination, so it is\nimportant to have metrics for free-text rationale quality. Existing free-text\nrationale metrics measure how consistent the rationale is with the LM's\npredicted label, but there is no protocol for assessing such metrics'\nreliability. Thus, we propose FRAME, a framework for evaluating rationale-label\nconsistency (RLC) metrics for free-text rationales. FRAME is based on three\naxioms: (1) good metrics should yield highest scores for reference rationales,\nwhich maximize RLC by construction; (2) good metrics should be appropriately\nsensitive to semantic perturbation of rationales; and (3) good metrics should\nbe robust to variation in the LM's task performance. Across three text\nclassification datasets, we show that existing RLC metrics cannot satisfy all\nthree FRAME axioms, since they are implemented via model pretraining which\nmuddles the metric's signal. Then, we introduce a non-pretraining RLC metric\nthat greatly outperforms baselines on (1) and (3), while performing\ncompetitively on (2). Finally, we discuss the limitations of using RLC to\nevaluate free-text rationales.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Aaron Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1\">Shaoliang Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1\">Liang Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaochang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1\">Hamed Firooz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2022-12-20T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}