{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-11-29T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition. (arXiv:2311.16119v1 [cs.CR])","link":"http://arxiv.org/abs/2311.16119","description":"<p>Large Language Models (LLMs) are increasingly being deployed in interactive\ncontexts that involve direct user engagement, such as chatbots and writing\nassistants. These deployments are increasingly plagued by prompt injection and\njailbreaking (collectively, prompt hacking), in which models are manipulated to\nignore their original instructions and instead follow potentially malicious\nones. Although widely acknowledged as a significant security threat, there is a\ndearth of large-scale resources and quantitative studies on prompt hacking. To\naddress this lacuna, we launch a global prompt hacking competition, which\nallows for free-form human input attacks. We elicit 600K+ adversarial prompts\nagainst three state-of-the-art LLMs. We describe the dataset, which empirically\nverifies that current LLMs can indeed be manipulated via prompt hacking. We\nalso present a comprehensive taxonomical ontology of the types of adversarial\nprompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schulhoff_S/0/1/0/all/0/1\">Sander Schulhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1\">Jeremy Pinto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Anaum Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouchard_L/0/1/0/all/0/1\">Louis-Fran&#xe7;ois Bouchard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anati_S/0/1/0/all/0/1\">Svetlina Anati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tagliabue_V/0/1/0/all/0/1\">Valen Tagliabue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kost_A/0/1/0/all/0/1\">Anson Liu Kost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carnahan_C/0/1/0/all/0/1\">Christopher Carnahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Artificial Intelligence Technology for Mapping Research to Sustainable Development Goals: A Case Study. (arXiv:2311.16162v1 [cs.DL])","link":"http://arxiv.org/abs/2311.16162","description":"<p>The number of publications related to the Sustainable Development Goals\n(SDGs) continues to grow. These publications cover a diverse spectrum of\nresearch, from humanities and social sciences to engineering and health. Given\nthe imperative of funding bodies to monitor outcomes and impacts, linking\npublications to relevant SDGs is critical but remains time-consuming and\ndifficult given the breadth and complexity of the SDGs. A publication may\nrelate to several goals (interconnection feature of goals), and therefore\nrequire multidisciplinary knowledge to tag accurately. Machine learning\napproaches are promising and have proven particularly valuable for tasks such\nas manual data labeling and text classification. In this study, we employed\nover 82,000 publications from an Australian university as a case study. We\nutilized a similarity measure to map these publications onto Sustainable\nDevelopment Goals (SDGs). Additionally, we leveraged the OpenAI GPT model to\nconduct the same task, facilitating a comparative analysis between the two\napproaches. Experimental results show that about 82.89% of the results obtained\nby the similarity measure overlap (at least one tag) with the outputs of the\nGPT model. The adopted model (similarity measure) can complement GPT model for\nSDG classification. Furthermore, deep learning methods, which include the\nsimilarity measure used here, are more accessible and trusted for dealing with\nsensitive data without the use of commercial AI services or the deployment of\nexpensive computing resources to operate large language models. Our study\ndemonstrates how a crafted combination of the two methods can achieve reliable\nresults for mapping research to the SDGs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Hui Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aryani_A/0/1/0/all/0/1\">Amir Aryani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambert_G/0/1/0/all/0/1\">Gavin Lambert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1\">Marcus White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salvador_Carulla_L/0/1/0/all/0/1\">Luis Salvador-Carulla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadiq_S/0/1/0/all/0/1\">Shazia Sadiq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sojli_E/0/1/0/all/0/1\">Elvira Sojli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boddy_J/0/1/0/all/0/1\">Jennifer Boddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_G/0/1/0/all/0/1\">Greg Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tham_W/0/1/0/all/0/1\">Wing Wah Tham</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditions for Length Generalization in Learning Reasoning Skills. (arXiv:2311.16173v1 [cs.AI])","link":"http://arxiv.org/abs/2311.16173","description":"<p>Reasoning is a fundamental capability of AI agents. Recently, large language\nmodels (LLMs) have shown remarkable abilities to perform reasoning tasks.\nHowever, numerous evaluations of the reasoning capabilities of LLMs have also\nshowed some limitations. An outstanding limitation is length generalization,\nmeaning that when trained on reasoning problems of smaller lengths or sizes,\nthe resulting models struggle with problems of larger sizes or lengths. This\npotentially indicates some theoretical limitations of generalization in\nlearning reasoning skills. These evaluations and their observations motivated\nus to perform a theoretical study of the length generalization problem. This\nwork focused on reasoning tasks that can be formulated as Markov dynamic\nprocesses (MDPs) and/or directed acyclic graphs (DAGs). It identifies and\nproves conditions that decide whether the length generalization problem can be\nsolved or not for a reasoning task in a particular representation. Experiments\nare also conducted to verify the theoretical results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Changnan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Sentiment Analysis Results through Outlier Detection Optimization. (arXiv:2311.16185v1 [cs.LG])","link":"http://arxiv.org/abs/2311.16185","description":"<p>When dealing with text data containing subjective labels like speaker\nemotions, inaccuracies or discrepancies among labelers are not uncommon. Such\ndiscrepancies can significantly affect the performance of machine learning\nalgorithms. This study investigates the potential of identifying and addressing\noutliers in text data with subjective labels, aiming to enhance classification\noutcomes. We utilized the Deep SVDD algorithm, a one-class classification\nmethod, to detect outliers in nine text-based emotion and sentiment analysis\ndatasets. By employing both a small-sized language model (DistilBERT base model\nwith 66 million parameters) and non-deep learning machine learning algorithms\n(decision tree, KNN, Logistic Regression, and LDA) as the classifier, our\nfindings suggest that the removal of outliers can lead to enhanced results in\nmost cases. Additionally, as outliers in such datasets are not necessarily\nunlearnable, we experienced utilizing a large language model -- DeBERTa v3\nlarge with 131 million parameters, which can capture very complex patterns in\ndata. We continued to observe performance enhancements across multiple\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuetian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_M/0/1/0/all/0/1\">Mei Si</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image Generation. (arXiv:2311.16201v1 [cs.CV])","link":"http://arxiv.org/abs/2311.16201","description":"<p>Recent advances in image tokenizers, such as VQ-VAE, have enabled\ntext-to-image generation using auto-regressive methods, similar to language\nmodeling. However, these methods have yet to leverage pre-trained language\nmodels, despite their adaptability to various downstream tasks. In this work,\nwe explore this gap by adapting a pre-trained language model for\nauto-regressive text-to-image generation, and find that pre-trained language\nmodels offer limited help. We provide a two-fold explanation by analyzing\ntokens from each modality. First, we demonstrate that image tokens possess\nsignificantly different semantics compared to text tokens, rendering\npre-trained language models no more effective in modeling them than randomly\ninitialized ones. Second, the text tokens in the image-text datasets are too\nsimple compared to normal language model pre-training data, which causes the\ncatastrophic degradation of language models' capability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKinzie_B/0/1/0/all/0/1\">Brandon McKinzie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1\">Zhe Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1\">Vaishaal Shankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toshev_A/0/1/0/all/0/1\">Alexander Toshev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatTraffc: Text-to-Traffic Generation via Diffusion Model. (arXiv:2311.16203v1 [cs.LG])","link":"http://arxiv.org/abs/2311.16203","description":"<p>Traffic prediction is one of the most significant foundations in Intelligent\nTransportation Systems (ITS). Traditional traffic prediction methods rely only\non historical traffic data to predict traffic trends and face two main\nchallenges. 1) insensitivity to unusual events. 2) poor performance in\nlong-term prediction. In this work, we explore how generative models combined\nwith text describing the traffic system can be applied for traffic generation\nand name the task Text-to-Traffic Generation (TTG). The key challenge of the\nTTG task is how to associate text with the spatial structure of the road\nnetwork and traffic data for generating traffic situations. To this end, we\npropose ChatTraffic, the first diffusion model for text-to-traffic generation.\nTo guarantee the consistency between synthetic and real data, we augment a\ndiffusion model with the Graph Convolutional Network (GCN) to extract spatial\ncorrelations of traffic data. In addition, we construct a large dataset\ncontaining text-traffic pairs for the TTG task. We benchmarked our model\nqualitatively and quantitatively on the released dataset. The experimental\nresults indicate that ChatTraffic can generate realistic traffic situations\nfrom the text. Our code and dataset are available at\nhttps://github.com/ChyaZhang/ChatTraffic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chengyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Q/0/1/0/all/0/1\">Qitan Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1\">Yisheng Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piao_X/0/1/0/all/0/1\">Xinglin Piao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Baocai Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Removing NSFW Concepts from Vision-and-Language Models for Text-to-Image Retrieval and Generation. (arXiv:2311.16254v1 [cs.CV])","link":"http://arxiv.org/abs/2311.16254","description":"<p>Vision-and-Language models such as CLIP have demonstrated remarkable\neffectiveness across a wide range of tasks. However, these models are typically\ntrained on web-scale data, which can introduce inappropriate content and lead\nto the development of unsafe and biased behavior. This, in turn, hampers their\napplicability in sensitive and trustworthy contexts and could raise significant\nconcern in their adoption. To overcome these limitations, we introduce a\nmethodology to make Vision-and-Language models safer by removing their\nsensitivity to not-safe-for-work concepts. We show how this can be done by\ndistilling from a large language model which converts between safe and unsafe\nsentences and which is fine-tuned starting from just 100 manually-curated\npairs. We conduct extensive experiments on the resulting embedding space for\nboth retrieval and text-to-image generation, where we show that our model can\nalso be properly employed with pre-trained image generators. Our source code\nand trained models are available at: https://github.com/aimagelab/safe-clip.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Poppi_S/0/1/0/all/0/1\">Samuele Poppi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poppi_T/0/1/0/all/0/1\">Tobia Poppi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cocchi_F/0/1/0/all/0/1\">Federico Cocchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1\">Marcella Cornia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1\">Rita Cucchiara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Exploration of Left-Corner Transformations. (arXiv:2311.16258v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16258","description":"<p>The left-corner transformation (Rosenkrantz and Lewis, 1970) is used to\nremove left recursion from context-free grammars, which is an important step\ntowards making the grammar parsable top-down with simple techniques. This paper\ngeneralizes prior left-corner transformations to support semiring-weighted\nproduction rules and to provide finer-grained control over which left corners\nmay be moved. Our generalized left-corner transformation (GLCT) arose from\nunifying the left-corner transformation and speculation transformation (Eisner\nand Blatz, 2007), originally for logic programming. Our new transformation and\nspeculation define equivalent weighted languages. Yet, their derivation trees\nare structurally different in an important way: GLCT replaces left recursion\nwith right recursion, and speculation does not. We also provide several\ntechnical results regarding the formal relationships between the outputs of\nGLCT, speculation, and the original grammar. Lastly, we empirically investigate\nthe efficiency of GLCT for left-recursion elimination from grammars of nine\nlanguages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Opedal_A/0/1/0/all/0/1\">Andreas Opedal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsipidi_E/0/1/0/all/0/1\">Eleftheria Tsipidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Applications of Large Language Models in Data Processing: Innovative Approaches to Segmenting and Renewing Information. (arXiv:2311.16267v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16267","description":"<p>Our paper investigates effective methods for code generation in\n\"specific-domain\" applications, including the use of Large Language Models\n(LLMs) for data segmentation and renewal, as well as stimulating deeper\nthinking in LLMs through prompt adjustments. Using a real company product as an\nexample, we provide user manuals, API documentation, and other data. The ideas\ndiscussed in this paper help segment and then convert this data into semantic\nvectors to better reflect their true positioning. Subsequently, user\nrequirements are transformed into vectors to retrieve the most relevant\ncontent, achieving about 70% accuracy in simple to medium-complexity tasks\nthrough various prompt techniques. This paper is the first to enhance\nspecific-domain code generation effectiveness from this perspective.\nAdditionally, we experiment with generating more scripts from a limited number\nusing llama2-based fine-tuning to test its effectiveness in professional domain\ncode generation. This is a challenging and promising field, and once achieved,\nit will not only lead to breakthroughs in LLM development across multiple\nindustries but also enable LLMs to understand and learn any new knowledge\neffectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yu-Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Akhilesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wen-Liang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_N/0/1/0/all/0/1\">Norman Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zakir_M/0/1/0/all/0/1\">Muhammad Zakir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Apte_R/0/1/0/all/0/1\">Rucha Apte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jyh-Shing Roger Jang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Student Mastery or AI Deception? Analyzing ChatGPT's Assessment Proficiency and Evaluating Detection Strategies. (arXiv:2311.16292v1 [cs.CY])","link":"http://arxiv.org/abs/2311.16292","description":"<p>Generative AI systems such as ChatGPT have a disruptive effect on learning\nand assessment. Computer science requires practice to develop skills in problem\nsolving and programming that are traditionally developed using assignments.\nGenerative AI has the capability of completing these assignments for students\nwith high accuracy, which dramatically increases the potential for academic\nintegrity issues and students not achieving desired learning outcomes. This\nwork investigates the performance of ChatGPT by evaluating it across three\ncourses (CS1,CS2,databases). ChatGPT completes almost all introductory\nassessments perfectly. Existing detection methods, such as MOSS and JPlag\n(based on similarity metrics) and GPTzero (AI detection), have mixed success in\nidentifying AI solutions. Evaluating instructors and teaching assistants using\nheuristics to distinguish between student and AI code shows that their\ndetection is not sufficiently accurate. These observations emphasize the need\nfor adapting assessments and improved detection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kevin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akins_S/0/1/0/all/0/1\">Seth Akins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammed_A/0/1/0/all/0/1\">Abdallah Mohammed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrence_R/0/1/0/all/0/1\">Ramon Lawrence</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Influence Scores at Scale for Efficient Language Data Sampling. (arXiv:2311.16298v1 [cs.LG])","link":"http://arxiv.org/abs/2311.16298","description":"<p>Modern ML systems ingest data aggregated from diverse sources, such as\nsynthetic, human-annotated, and live customer traffic. Understanding\n\\textit{which} examples are important to the performance of a learning\nalgorithm is crucial for efficient model training. Recently, a growing body of\nliterature has given rise to various \"influence scores,\" which use training\nartifacts such as model confidence or checkpointed gradients to identify\nimportant subsets of data. However, these methods have primarily been developed\nin computer vision settings, and it remains unclear how well they generalize to\nlanguage-based tasks using pretrained models.\n</p>\n<p>In this paper, we explore the applicability of influence scores in language\nclassification tasks. We evaluate a diverse subset of these scores on the SNLI\ndataset by quantifying accuracy changes in response to pruning training data\nthrough random and influence-score-based sampling. We then stress-test one of\nthe scores -- \"variance of gradients\" (VoG) from Agarwal et al. (2022) -- in an\nNLU model stack that was exposed to dynamic user speech patterns in a voice\nassistant type of setting. Our experiments demonstrate that in many cases,\nencoder-based language models can be finetuned on roughly 50% of the original\ndata without degradation in performance metrics. Along the way, we summarize\nlessons learned from applying out-of-the-box implementations of influence\nscores, quantify the effects of noisy and class-imbalanced data, and offer\nrecommendations on score-based sampling for better accuracy and training\nefficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Anand_N/0/1/0/all/0/1\">Nikhil Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Joshua Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minakova_M/0/1/0/all/0/1\">Maria Minakova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comprehensive Benchmarking of Entropy and Margin Based Scoring Metrics for Data Selection. (arXiv:2311.16302v1 [cs.LG])","link":"http://arxiv.org/abs/2311.16302","description":"<p>While data selection methods have been studied extensively in active\nlearning, data pruning, and data augmentation settings, there is little\nevidence for the efficacy of these methods in industry scale settings,\nparticularly in low-resource languages. Our work presents ways of assessing\nprospective training examples in those settings for their \"usefulness\" or\n\"difficulty\". We also demonstrate how these measures can be used in selecting\nimportant examples for training supervised machine learning models. We\nprimarily experiment with entropy and Error L2-Norm (EL2N) scores. We use these\nmetrics to curate high quality datasets from a large pool of \\textit{Weak\nSignal Labeled} data, which assigns no-defect high confidence hypotheses during\ninference as ground truth labels. We then conduct training data augmentation\nexperiments using these de-identified datasets and demonstrate that score-based\nselection can result in a 2% decrease in semantic error rate and 4%-7% decrease\nin domain classification error rate when compared to the baseline technique of\nrandom selection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sabbineni_A/0/1/0/all/0/1\">Anusha Sabbineni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anand_N/0/1/0/all/0/1\">Nikhil Anand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minakova_M/0/1/0/all/0/1\">Maria Minakova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Releasing the CRaQAn (Coreference Resolution in Question-Answering): An open-source dataset and dataset creation methodology using instruction-following models. (arXiv:2311.16338v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16338","description":"<p>Instruction-following language models demand robust methodologies for\ninformation retrieval to augment instructions for question-answering\napplications. A primary challenge is the resolution of coreferences in the\ncontext of chunking strategies for long documents. The critical barrier to\nexperimentation of handling coreferences is a lack of open source datasets,\nspecifically in question-answering tasks that require coreference resolution.\nIn this work we present our Coreference Resolution in Question-Answering\n(CRaQAn) dataset, an open-source dataset that caters to the nuanced information\nretrieval requirements of coreference resolution in question-answering tasks by\nproviding over 250 question-answer pairs containing coreferences. To develop\nthis dataset, we developed a novel approach for creating high-quality datasets\nusing an instruction-following model (GPT-4) and a Recursive Criticism and\nImprovement Loop.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Grzywinski_R/0/1/0/all/0/1\">Rob Grzywinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DArcy_J/0/1/0/all/0/1\">Joshua D&#x27;Arcy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naidoff_R/0/1/0/all/0/1\">Rob Naidoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1\">Ashish Shukla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Browne_A/0/1/0/all/0/1\">Alex Browne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gibbons_R/0/1/0/all/0/1\">Ren Gibbons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bent_B/0/1/0/all/0/1\">Brinnae Bent</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reducing Gender Bias in Machine Translation through Counterfactual Data Generation. (arXiv:2311.16362v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16362","description":"<p>Recent advances in neural methods have led to substantial improvement in the\nquality of Neural Machine Translation (NMT) systems. However, these systems\nfrequently produce translations with inaccurate gender (Stanovsky et al.,\n2019), which can be traced to bias in training data. Saunders and Byrne (2020)\ntackle this problem with a handcrafted dataset containing balanced gendered\nprofession words. By using this data to fine-tune an existing NMT model, they\nshow that gender bias can be significantly mitigated, albeit at the expense of\ntranslation quality due to catastrophic forgetting. They recover some of the\nlost quality with modified training objectives or additional models at\ninference. We find, however, that simply supplementing the handcrafted dataset\nwith a random sample from the base model training corpus is enough to\nsignificantly reduce the catastrophic forgetting. We also propose a novel\ndomain-adaptation technique that leverages in-domain data created with the\ncounterfactual data generation techniques proposed by Zmigrod et al. (2019) to\nfurther improve accuracy on the WinoMT challenge test set without significant\nloss in translation quality. We show its effectiveness in NMT systems from\nEnglish into three morphologically rich languages French, Spanish, and Italian.\nThe relevant dataset and code will be available at Github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naik_R/0/1/0/all/0/1\">Ranjita Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rarrick_S/0/1/0/all/0/1\">Spencer Rarrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhary_V/0/1/0/all/0/1\">Vishal Chowdhary</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CDEval: A Benchmark for Measuring the Cultural Dimensions of Large Language Models. (arXiv:2311.16421v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16421","description":"<p>As the scaling of Large Language Models (LLMs) has dramatically enhanced\ntheir capabilities, there has been a growing focus on the alignment problem to\nensure their responsible and ethical use. While existing alignment efforts\npredominantly concentrate on universal values such as the HHH principle, the\naspect of culture, which is inherently pluralistic and diverse, has not\nreceived adequate attention. This work introduces a new benchmark, CDEval,\naimed at evaluating the cultural dimensions of LLMs. CDEval is constructed by\nincorporating both GPT-4's automated generation and human verification,\ncovering six cultural dimensions across seven domains. Our comprehensive\nexperiments provide intriguing insights into the culture of mainstream LLMs,\nhighlighting both consistencies and variations across different dimensions and\ndomains. The findings underscore the importance of integrating cultural\nconsiderations in LLM development, particularly for applications in diverse\ncultural settings. Through CDEval, we aim to broaden the horizon of LLM\nalignment research by including cultural dimensions, thus providing a more\nholistic framework for the future development and evaluation of LLMs. This\nbenchmark serves as a valuable resource for cultural studies in LLMs, paving\nthe way for more culturally aware and sensitive models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yanxu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_C/0/1/0/all/0/1\">Chao Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Shuyu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jitao Sang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities Using Web Instructional Videos. (arXiv:2311.16444v1 [cs.CV])","link":"http://arxiv.org/abs/2311.16444","description":"<p>We propose a novel benchmark for cross-view knowledge transfer of dense video\ncaptioning, adapting models from web instructional videos with exocentric views\nto an egocentric view. While dense video captioning (predicting time segments\nand their captions) is primarily studied with exocentric videos (e.g.,\nYouCook2), benchmarks with egocentric videos are restricted due to data\nscarcity. To overcome the limited video availability, transferring knowledge\nfrom abundant exocentric web videos is demanded as a practical approach.\nHowever, learning the correspondence between exocentric and egocentric views is\ndifficult due to their dynamic view changes. The web videos contain mixed views\nfocusing on either human body actions or close-up hand-object interactions,\nwhile the egocentric view is constantly shifting as the camera wearer moves.\nThis necessitates the in-depth study of cross-view transfer under complex view\nchanges. In this work, we first create a real-life egocentric dataset (EgoYC2)\nwhose captions are shared with YouCook2, enabling transfer learning between\nthese datasets assuming their ground-truth is accessible. To bridge the view\ngaps, we propose a view-invariant learning method using adversarial training in\nboth the pre-training and fine-tuning stages. While the pre-training is\ndesigned to learn invariant features against the mixed views in the web videos,\nthe view-invariant fine-tuning further mitigates the view gaps between both\ndatasets. We validate our proposed method by studying how effectively it\novercomes the view change problem and efficiently transfers the knowledge to\nthe egocentric domain. Our benchmark pushes the study of the cross-view\ntransfer into a new task domain of dense video captioning and will envision\nmethodologies to describe egocentric videos in natural language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ohkawa_T/0/1/0/all/0/1\">Takehiko Ohkawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yagi_T/0/1/0/all/0/1\">Takuma Yagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishimura_T/0/1/0/all/0/1\">Taichi Nishimura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furuta_R/0/1/0/all/0/1\">Ryosuke Furuta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_A/0/1/0/all/0/1\">Atsushi Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1\">Yoshitaka Ushiku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1\">Yoichi Sato</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case Study in Medicine. (arXiv:2311.16452v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16452","description":"<p>Generalist foundation models such as GPT-4 have displayed surprising\ncapabilities in a wide variety of domains and tasks. Yet, there is a prevalent\nassumption that they cannot match specialist capabilities of fine-tuned models.\nFor example, most explorations to date on medical competency benchmarks have\nleveraged domain-specific training, as exemplified by efforts on BioGPT and\nMed-PaLM. We build on a prior study of GPT-4's capabilities on medical\nchallenge benchmarks in the absence of special training. Rather than using\nsimple prompting to highlight the model's out-of-the-box capabilities, we\nperform a systematic exploration of prompt engineering. We find that prompting\ninnovation can unlock deeper specialist capabilities and show that GPT-4 easily\ntops prior leading results for medical benchmarks. The prompting methods we\nexplore are general purpose, and make no specific use of domain expertise,\nremoving the need for expert-curated content. Our experimental design carefully\ncontrols for overfitting during the prompt engineering process. We introduce\nMedprompt, based on a composition of several prompting strategies. With\nMedprompt, GPT-4 achieves state-of-the-art results on all nine of the benchmark\ndatasets in the MultiMedQA suite. The method outperforms leading specialist\nmodels such as Med-PaLM 2 by a significant margin with an order of magnitude\nfewer calls to the model. Steering GPT-4 with Medprompt achieves a 27%\nreduction in error rate on the MedQA dataset over the best methods to date\nachieved with specialist models and surpasses a score of 90% for the first\ntime. Beyond medical problems, we show the power of Medprompt to generalize to\nother domains and provide evidence for the broad applicability of the approach\nvia studies of the strategy on exams in electrical engineering, machine\nlearning, philosophy, accounting, law, nursing, and clinical psychology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nori_H/0/1/0/all/0/1\">Harsha Nori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carignan_D/0/1/0/all/0/1\">Dean Carignan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edgar_R/0/1/0/all/0/1\">Richard Edgar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fusi_N/0/1/0/all/0/1\">Nicolo Fusi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_N/0/1/0/all/0/1\">Nicholas King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Larson_J/0/1/0/all/0/1\">Jonathan Larson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weishung Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKinney_S/0/1/0/all/0/1\">Scott Mayer McKinney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ness_R/0/1/0/all/0/1\">Robert Osazuwa Ness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_C/0/1/0/all/0/1\">Chris White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1\">Eric Horvitz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Human Persuasion With Large Language Models. (arXiv:2311.16466v1 [cs.HC])","link":"http://arxiv.org/abs/2311.16466","description":"<p>Although large language models (LLMs) are reshaping various aspects of human\nlife, our current understanding of their impacts remains somewhat constrained.\nHere we investigate the impact of LLMs on human communication, in the context\nof consumer complaints in the financial industry. Employing an AI detection\ntool on more than 780K complaints gathered by the Consumer Financial Protection\nBureau (CFPB), we find evidence of LLM usage in the writing of complaints -\nshortly after the release of ChatGPT. Our analyses reveal that LLM usage is\npositively correlated with the likelihood of obtaining desirable outcomes\n(i.e., offer of relief from financial firms) and suggest that this positive\ncorrelation may be partly due to the linguistic features improved by LLMs. We\ntest this conjecture with a preregistered experiment, which reveals results\nconsistent with those from observational studies: Consumer complaints written\nwith ChatGPT for improved linguistic qualities were more likely to receive\nhypothetical relief offers than the original consumer complaints, demonstrating\nthe LLM's ability to enhance message persuasiveness in human communication.\nBeing some of the earliest empirical evidence on LLM usage for enhancing\npersuasion, our results highlight the transformative potential of LLMs in human\ncommunication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shin_M/0/1/0/all/0/1\">Minkyu Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jin Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MI-Gen: Multiple Instance Generation of Pathology Reports for Gigapixel Whole-Slide Images. (arXiv:2311.16480v1 [cs.CV])","link":"http://arxiv.org/abs/2311.16480","description":"<p>Whole slide images are the foundation of digital pathology for the diagnosis\nand treatment of carcinomas. Writing pathology reports is laborious and\nerror-prone for inexperienced pathologists. To reduce the workload and improve\nclinical automation, we investigate how to generate pathology reports given\nwhole slide images. On the data end, we curated the largest WSI-text dataset\n(TCGA-PathoText). In specific, we collected nearly 10000 high-quality WSI-text\npairs for visual-language models by recognizing and cleaning pathology reports\nwhich narrate diagnostic slides in TCGA. On the model end, we propose the\nmultiple instance generative model (MI-Gen) which can produce pathology reports\nfor gigapixel WSIs. We benchmark our model on the largest subset of\nTCGA-PathoText. Experimental results show our model can generate pathology\nreports which contain multiple clinical clues. Furthermore, WSI-text prediction\ncan be seen as an approach of visual-language pre-training, which enables our\nmodel to be transferred to downstream diagnostic tasks like carcinoma grading\nand phenotyping. We observe that simple semantic extraction from the pathology\nreports can achieve the best performance (0.838 of F1 score) on BRCA subtyping\nwithout adding extra parameters or tricky fine-tuning. Our collected dataset\nand related code will all be publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pingyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Honglin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenglu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sunyi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Lin Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChartLlama: A Multimodal LLM for Chart Understanding and Generation. (arXiv:2311.16483v1 [cs.CV])","link":"http://arxiv.org/abs/2311.16483","description":"<p>Multi-modal large language models have demonstrated impressive performances\non most vision-language tasks. However, the model generally lacks the\nunderstanding capabilities for specific domain data, particularly when it comes\nto interpreting chart figures. This is mainly due to the lack of relevant\nmulti-modal instruction tuning datasets. In this article, we create a\nhigh-quality instruction-tuning dataset leveraging GPT-4. We develop a\nmulti-step data generation process in which different steps are responsible for\ngenerating tabular data, creating chart figures, and designing instruction\ntuning data separately. Our method's flexibility enables us to generate\ndiverse, high-quality instruction-tuning data consistently and efficiently\nwhile maintaining a low resource expenditure. Additionally, it allows us to\nincorporate a wider variety of chart and task types not yet featured in\nexisting datasets. Next, we introduce ChartLlama, a multi-modal large language\nmodel that we've trained using our created dataset. ChartLlama outperforms all\nprior methods in ChartQA, Chart-to-text, and Chart-extraction evaluation\nbenchmarks. Additionally, ChartLlama significantly improves upon the baseline\nin our specially compiled chart dataset, which includes new chart and task\ntypes. The results of ChartLlama confirm the value and huge potential of our\nproposed data generation method in enhancing chart comprehension.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yucheng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhibin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1\">Gang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1\">Bin Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanwang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark for Expert AGI. (arXiv:2311.16502v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16502","description":"<p>We introduce MMMU: a new benchmark designed to evaluate multimodal models on\nmassive multi-discipline tasks demanding college-level subject knowledge and\ndeliberate reasoning. MMMU includes 11.5K meticulously collected multimodal\nquestions from college exams, quizzes, and textbooks, covering six core\ndisciplines: Art &amp; Design, Business, Science, Health &amp; Medicine, Humanities &amp;\nSocial Science, and Tech &amp; Engineering. These questions span 30 subjects and\n183 subfields, comprising 30 highly heterogeneous image types, such as charts,\ndiagrams, maps, tables, music sheets, and chemical structures. Unlike existing\nbenchmarks, MMMU focuses on advanced perception and reasoning with\ndomain-specific knowledge, challenging models to perform tasks akin to those\nfaced by experts. Our evaluation of 14 open-source LMMs and the proprietary\nGPT-4V(ision) highlights the substantial challenges posed by MMMU. Even the\nadvanced GPT-4V only achieves a 56% accuracy, indicating significant room for\nimprovement. We believe MMMU will stimulate the community to build\nnext-generation multimodal foundation models towards expert artificial general\nintelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiang Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1\">Yuansheng Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1\">Tianyu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruoqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1\">Samuel Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Dongfu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1\">Weiming Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yuxuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Cong Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Botao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Ruibin Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Renliang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1\">Ming Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Boyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenzhu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yibo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StyleCap: Automatic Speaking-Style Captioning from Speech Based on Speech and Language Self-supervised Learning Models. (arXiv:2311.16509v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16509","description":"<p>We propose StyleCap, a method to generate natural language descriptions of\nspeaking styles appearing in speech. Although most of conventional techniques\nfor para-/non-linguistic information recognition focus on the category\nclassification or the intensity estimation of pre-defined labels, they cannot\nprovide the reasoning of the recognition result in an interpretable manner. As\na first step towards an end-to-end method for generating speaking-style prompts\nfrom speech, i.e., automatic speaking-style captioning, StyleCap uses paired\ndata of speech and natural language descriptions to train neural networks that\npredict prefix vectors fed into a large language model (LLM)-based text decoder\nfrom a speech representation vector. We explore an appropriate text decoder and\nspeech feature representation suitable for this new task. The experimental\nresults demonstrate that our StyleCap leveraging richer LLMs for the text\ndecoder, speech self-supervised learning (SSL) features, and sentence\nrephrasing augmentation improves the accuracy and diversity of generated\nspeaking-style captions. Samples of speaking-style captions generated by our\nStyleCap are publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamauchi_K/0/1/0/all/0/1\">Kazuki Yamauchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ijima_Y/0/1/0/all/0/1\">Yusuke Ijima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1\">Yuki Saito</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of dynamic characteristics of power grid based on GNN and application on knowledge graph. (arXiv:2311.16522v1 [cs.LG])","link":"http://arxiv.org/abs/2311.16522","description":"<p>A novel method for detecting faults in power grids using a graph neural\nnetwork (GNN) has been developed, aimed at enhancing intelligent fault\ndiagnosis in network operation and maintenance. This GNN-based approach\nidentifies faulty nodes within the power grid through a specialized electrical\nfeature extraction model coupled with a knowledge graph. Incorporating temporal\ndata, the method leverages the status of nodes from preceding and subsequent\ntime periods to aid in current fault detection. To validate the effectiveness\nof this GNN in extracting node features, a correlation analysis of the output\nfeatures from each node within the neural network layer was conducted. The\nresults from experiments show that this method can accurately locate fault\nnodes in simulated scenarios with a remarkable 99.53% accuracy. Additionally,\nthe graph neural network's feature modeling allows for a qualitative\nexamination of how faults spread across nodes, providing valuable insights for\nanalyzing fault nodes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pei_H/0/1/0/all/0/1\">Hao Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Si Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chuanfu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Che Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haoming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sizhe Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recognizing Conditional Causal Relationships about Emotions and Their Corresponding Conditions. (arXiv:2311.16579v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16579","description":"<p>The study of causal relationships between emotions and causes in texts has\nrecently received much attention. Most works focus on extracting causally\nrelated clauses from documents. However, none of these works has considered\nthat the causal relationships among the extracted emotion and cause clauses can\nonly be valid under some specific context clauses. To highlight the context in\nsuch special causal relationships, we propose a new task to determine whether\nor not an input pair of emotion and cause has a valid causal relationship under\ndifferent contexts and extract the specific context clauses that participate in\nthe causal relationship. Since the task is new for which no existing dataset is\navailable, we conduct manual annotation on a benchmark dataset to obtain the\nlabels for our tasks and the annotations of each context clause's type that can\nalso be used in some other applications. We adopt negative sampling to\nconstruct the final dataset to balance the number of documents with and without\ncausal relationships. Based on the constructed dataset, we propose an\nend-to-end multi-task framework, where we design two novel and general modules\nto handle the two goals of our task. Specifically, we propose a context masking\nmodule to extract the context clauses participating in the causal\nrelationships. We propose a prediction aggregation module to fine-tune the\nprediction results according to whether the input emotion and causes depend on\nspecific context clauses. Results of extensive comparative experiments and\nablation studies demonstrate the effectiveness and generality of our proposed\nframework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinhong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zongxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1\">Haoran Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedGen: A Python Natural Language Processing Toolkit for Medical Text Processing. (arXiv:2311.16588v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16588","description":"<p>This study introduces MedGen, a comprehensive natural language processing\n(NLP) toolkit designed for medical text processing. MedGen is tailored for\nbiomedical researchers and healthcare professionals with an easy-to-use,\nall-in-one solution that requires minimal programming expertise. It includes\n(1) Generative Functions: For the first time, MedGen includes four advanced\ngenerative functions: question answering, text summarization, text\nsimplification, and machine translation; (2) Basic NLP Functions: MedGen\nintegrates 12 essential NLP functions such as word tokenization and sentence\nsegmentation; and (3) Query and Search Capabilities: MedGen provides\nuser-friendly query and search functions on text corpora. We fine-tuned 32\ndomain-specific language models, evaluated them thoroughly on 24 established\nbenchmarks and conducted manual reviews with clinicians. Additionally, we\nexpanded our toolkit by introducing query and search functions, while also\nstandardizing and integrating functions from third-party libraries. The\ntoolkit, its models, and associated data are publicly available via\nhttps://github.com/Yale-LILY/MedGen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Rui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingcheng Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1\">Keen You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yujie Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lucas Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Chia-Chun Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosand_B/0/1/0/all/0/1\">Benjamin Rosand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_J/0/1/0/all/0/1\">Jeremy Goldwasser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dave_A/0/1/0/all/0/1\">Amisha D Dave</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keenan_T/0/1/0/all/0/1\">Tiarnan D.L. Keenan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chew_E/0/1/0/all/0/1\">Emily Y Chew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Long Range Abilities of Transformers. (arXiv:2311.16620v1 [cs.LG])","link":"http://arxiv.org/abs/2311.16620","description":"<p>Despite their dominance in modern DL and, especially, NLP domains,\ntransformer architectures exhibit sub-optimal performance on long-range tasks\ncompared to recent layers that are specifically designed for this purpose. In\nthis work, drawing inspiration from key attributes of long-range layers, such\nas state-space layers, linear RNN layers, and global convolution layers, we\ndemonstrate that minimal modifications to the transformer architecture can\nsignificantly enhance performance on the Long Range Arena (LRA) benchmark, thus\nnarrowing the gap with these specialized layers. We identify that two key\nprinciples for long-range tasks are (i) incorporating an inductive bias towards\nsmoothness, and (ii) locality. As we show, integrating these ideas into the\nattention mechanism improves results with a negligible amount of additional\ncomputation and without any additional trainable parameters. Our theory and\nexperiments also shed light on the reasons for the inferior performance of\ntransformers on long-range tasks and identify critical properties that are\nessential for successfully capturing long-range dependencies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zimerman_I/0/1/0/all/0/1\">Itamar Zimerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lior Wolf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Political Texts with ChatGPT. (arXiv:2311.16639v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16639","description":"<p>We use GPT-4 to obtain position estimates of political texts in continuous\nspaces. We develop and validate a new approach by positioning British party\nmanifestos on the economic, social, and immigration policy dimensions and\ntweets by members of the US Congress on the left-right ideological spectrum.\nFor the party manifestos, the correlation between the positions produced by\nGPT-4 and experts is 93% or higher, a performance similar to or better than\nthat obtained with crowdsourced position estimates. For individual tweets, the\npositions obtained with GPT-4 achieve a correlation of 91% with crowdsourced\nposition estimates. For senators of the 117th US Congress, the positions\nobtained with GPT-4 achieve a correlation of 97% with estimates based on roll\ncall votes and of 96% with those based on campaign funding. Correlations are\nalso substantial within party, indicating that position estimates produced with\nGPT-4 capture within-party differences between senators. Overall, using GPT-4\nfor ideological scaling is fast, cost-efficient, and reliable. This approach\nprovides a viable alternative to scaling by both expert raters and\ncrowdsourcing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mens_G/0/1/0/all/0/1\">Ga&#xeb;l Le Mens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallego_A/0/1/0/all/0/1\">Aina Gallego</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for Imbalanced Medical Classification. (arXiv:2311.16650v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16650","description":"<p>Deep learning approaches exhibit promising performances on various text\ntasks. However, they are still struggling on medical text classification since\nsamples are often extremely imbalanced and scarce. Different from existing\nmainstream approaches that focus on supplementary semantics with external\nmedical information, this paper aims to rethink the data challenges in medical\ntexts and present a novel framework-agnostic algorithm called Text2Tree that\nonly utilizes internal label hierarchy in training deep learning models. We\nembed the ICD code tree structure of labels into cascade attention modules for\nlearning hierarchy-aware label representations. Two new learning schemes,\nSimilarity Surrogate Learning (SSL) and Dissimilarity Mixup Learning (DML), are\ndevised to boost text classification by reusing and distinguishing samples of\nother labels following the label representation hierarchy, respectively.\nExperiments on authoritative public datasets and real-world medical records\nshow that our approach stably achieves superior performances over classical and\nadvanced imbalanced classification methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jiahuan Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1\">Haojun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kai_Z/0/1/0/all/0/1\">Zhang Kai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weize Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Danny Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jintai Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Distribution-Based Threshold for Determining Sentence Similarity. (arXiv:2311.16675v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16675","description":"<p>We hereby present a solution to a semantic textual similarity (STS) problem\nin which it is necessary to match two sentences containing, as the only\ndistinguishing factor, highly specific information (such as names, addresses,\nidentification codes), and from which we need to derive a definition for when\nthey are similar and when they are not. The solution revolves around the use of\na neural network, based on the siamese architecture, to create the\ndistributions of the distances between similar and dissimilar pairs of\nsentences. The goal of these distributions is to find a discriminating factor,\nthat we call \"threshold\", which represents a well-defined quantity that can be\nused to distinguish vector distances of similar pairs from vector distances of\ndissimilar pairs in new predictions and later analyses. In addition, we\ndeveloped a way to score the predictions by combining attributes from both the\ndistributions' features and the way the distance function works. Finally, we\ngeneralize the results showing that they can be transferred to a wider range of\ndomains by applying the system discussed to a well-known and widely used\nbenchmark dataset for STS problems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cadamuro_G/0/1/0/all/0/1\">Gioele Cadamuro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gruppo_M/0/1/0/all/0/1\">Marco Gruppo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained Sentiment Analysis. (arXiv:2311.16678v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16678","description":"<p>Product reviews often contain a large number of implicit aspects and\nobject-attribute co-existence cases. Unfortunately, many existing studies in\nAspect-Based Sentiment Analysis (ABSA) have overlooked this issue, which can\nmake it difficult to extract opinions comprehensively and fairly. In this\npaper, we propose a new task called Entity-Aspect-Opinion-Sentiment Quadruple\nExtraction (EASQE), which aims to hierarchically decompose aspect terms into\nentities and aspects to avoid information loss, non-exclusive annotations, and\nopinion misunderstandings in ABSA tasks. To facilitate research in this new\ntask, we have constructed four datasets (Res14-EASQE, Res15-EASQE, Res16-EASQE,\nand Lap14-EASQE) based on the SemEval Restaurant and Laptop datasets. We have\nalso proposed a novel two-stage sequence-tagging based Trigger-Opinion\nframework as the baseline for the EASQE task. Empirical evaluations show that\nour Trigger-Opinion framework can generate satisfactory EASQE results and can\nalso be applied to other ABSA tasks, significantly outperforming\nstate-of-the-art methods. We have made the four datasets and source code of\nTrigger-Opinion publicly available to facilitate further research in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1\">Dan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zongyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xuezhi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Y/0/1/0/all/0/1\">Yunsen Xian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs for Science: Usage for Code Generation and Data Analysis. (arXiv:2311.16733v1 [cs.SE])","link":"http://arxiv.org/abs/2311.16733","description":"<p>Large language models (LLMs) have been touted to enable increased\nproductivity in many areas of today's work life. Scientific research as an area\nof work is no exception: the potential of LLM-based tools to assist in the\ndaily work of scientists has become a highly discussed topic across\ndisciplines. However, we are only at the very onset of this subject of study.\nIt is still unclear how the potential of LLMs will materialise in research\npractice. With this study, we give first empirical evidence on the use of LLMs\nin the research process. We have investigated a set of use cases for LLM-based\ntools in scientific research, and conducted a first study to assess to which\ndegree current tools are helpful. In this paper we report specifically on use\ncases related to software engineering, such as generating application code and\ndeveloping scripts for data analytics. While we studied seemingly simple use\ncases, results across tools differ significantly. Our results highlight the\npromise of LLM-based tools in general, yet we also observe various issues,\nparticularly regarding the integrity of the output these tools provide.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nejjar_M/0/1/0/all/0/1\">Mohamed Nejjar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zacharias_L/0/1/0/all/0/1\">Luca Zacharias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiehle_F/0/1/0/all/0/1\">Fabian Stiehle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_I/0/1/0/all/0/1\">Ingo Weber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Radiology-Aware Model-Based Evaluation Metric for Report Generation. (arXiv:2311.16764v1 [cs.CL])","link":"http://arxiv.org/abs/2311.16764","description":"<p>We propose a new automated evaluation metric for machine-generated radiology\nreports using the successful COMET architecture adapted for the radiology\ndomain. We train and publish four medically-oriented model checkpoints,\nincluding one trained on RadGraph, a radiology knowledge graph. Our results\nshow that our metric correlates moderately to high with established metrics\nsuch as BERTscore, BLEU, and CheXbert scores. Furthermore, we demonstrate that\none of our checkpoints exhibits a high correlation with human judgment, as\nassessed using the publicly available annotations of six board-certified\nradiologists, using a set of 200 reports. We also performed our own analysis\ngathering annotations with two radiologists on a collection of 100 reports. The\nresults indicate the potential effectiveness of our method as a\nradiology-specific evaluation metric. The code, data, and model checkpoints to\nreproduce our findings will be publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Calamida_A/0/1/0/all/0/1\">Amos Calamida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nooralahzadeh_F/0/1/0/all/0/1\">Farhad Nooralahzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rohanian_M/0/1/0/all/0/1\">Morteza Rohanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujimoto_K/0/1/0/all/0/1\">Koji Fujimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishio_M/0/1/0/all/0/1\">Mizuho Nishio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krauthammer_M/0/1/0/all/0/1\">Michael Krauthammer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Post-hoc Interpretability for Neural NLP: A Survey. (arXiv:2108.04840v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.04840","description":"<p>Neural networks for NLP are becoming increasingly complex and widespread, and\nthere is a growing concern if these models are responsible to use. Explaining\nmodels helps to address the safety and ethical concerns and is essential for\naccountability. Interpretability serves to provide these explanations in terms\nthat are understandable to humans. Additionally, post-hoc methods provide\nexplanations after a model is learned and are generally model-agnostic. This\nsurvey provides a categorization of how recent post-hoc interpretability\nmethods communicate explanations to humans, it discusses each method in-depth,\nand how they are validated, as the latter is often a common concern.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madsen_A/0/1/0/all/0/1\">Andreas Madsen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1\">Sarath Chandar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym Prediction. (arXiv:2112.03002v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.03002","description":"<p>In the expansion of biomedical dataset, the same category may be labeled with\ndifferent terms, thus being tedious and onerous to curate these terms.\nTherefore, automatically mapping synonymous terms onto the ontologies is\ndesirable, which we name as biomedical synonym prediction task. Unlike\nbiomedical concept normalization (BCN), no clues from context can be used to\nenhance synonym prediction, making it essential to extract graph features from\nontology. We introduce an expert-curated dataset OBO-syn encompassing 70\ndifferent types of concepts and 2 million curated concept-term pairs for\nevaluating synonym prediction methods. We find BCN methods perform weakly on\nthis task for not making full use of graph information. Therefore, we propose\nGraphPrompt, a prompt-based learning approach that creates prompt templates\naccording to the graphs. GraphPrompt obtained 37.2\\% and 28.5\\% improvement on\nzero-shot and few-shot settings respectively, indicating the effectiveness of\nthese graph-based prompt templates. We envision that our method GraphPrompt and\nOBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as\nthe basis for analyzing diverse and accumulating biomedical data. All the data\nand codes are avalible at: https://github.com/HanwenXuTHU/GraphPrompt\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hanwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiayou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhirui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shizhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhalerao_M/0/1/0/all/0/1\">Megh Manoj Bhalerao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yucong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dawei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Just ClozE! A Novel Framework for Evaluating the Factual Consistency Faster in Abstractive Summarization. (arXiv:2210.02804v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.02804","description":"<p>The issue of factual consistency in abstractive summarization has received\nextensive attention in recent years, and the evaluation of factual consistency\nbetween summary and document has become an important and urgent task. Most of\nthe current evaluation metrics are adopted from the question answering (QA) or\nnatural language inference (NLI) task. However, the application of QA-based\nmetrics is extremely time-consuming in practice while NLI-based metrics are\nlack of interpretability. In this paper, we propose a cloze-based evaluation\nframework called ClozE and show the great potential of the cloze-based metric.\nIt inherits strong interpretability from QA, while maintaining the speed of\nNLI- level reasoning. We demonstrate that ClozE can reduce the evaluation time\nby nearly 96% relative to QA-based metrics while retaining their\ninterpretability and performance through experiments on six human-annotated\ndatasets and a meta-evaluation benchmark GO FIGURE (Gabriel et al., 2021).\nFinally, we discuss three important facets of ClozE in practice, which further\nshows better overall performance of ClozE compared to other metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litvak_M/0/1/0/all/0/1\">Marina Litvak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanetik_N/0/1/0/all/0/1\">Natalia Vanetik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1\">Dingxin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuze Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanquan Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DSI++: Updating Transformer Memory with New Documents. (arXiv:2212.09744v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09744","description":"<p>Differentiable Search Indices (DSIs) encode a corpus of documents in model\nparameters and use the same model to answer user queries directly. Despite the\nstrong performance of DSI models, deploying them in situations where the corpus\nchanges over time is computationally expensive because reindexing the corpus\nrequires re-training the model. In this work, we introduce DSI++, a continual\nlearning challenge for DSI to incrementally index new documents while being\nable to answer queries related to both previously and newly indexed documents.\nAcross different model scales and document identifier representations, we show\nthat continual indexing of new documents leads to considerable forgetting of\npreviously indexed documents. We also hypothesize and verify that the model\nexperiences forgetting events during training, leading to unstable learning. To\nmitigate these issues, we investigate two approaches. The first focuses on\nmodifying the training dynamics. Flatter minima implicitly alleviate\nforgetting, so we optimize for flatter loss basins and show that the model\nstably memorizes more documents ($+12\\%$). Next, we introduce a generative\nmemory to sample pseudo-queries for documents and supplement them during\ncontinual indexing to prevent forgetting for the retrieval task. Extensive\nexperiments on novel continual indexing benchmarks based on Natural Questions\n(NQ) and MS MARCO demonstrate that our proposed solution mitigates forgetting\nsignificantly. Concretely, it improves the average Hits@10 by $+21.1\\%$ over\ncompetitive baselines for NQ and requires $6$ times fewer model updates\ncompared to re-training the DSI model for incrementally indexing five corpora\nin a sequence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1\">Sanket Vaibhav Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1\">Jai Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1\">Yi Tay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Mostafa Dehghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vinh Q. Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1\">Jinfeng Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1\">Marc Najork</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Metzler_D/0/1/0/all/0/1\">Donald Metzler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Multitask, Multilingual, Multimodal Evaluation of ChatGPT on Reasoning, Hallucination, and Interactivity. (arXiv:2302.04023v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.04023","description":"<p>This paper proposes a framework for quantitatively evaluating interactive\nLLMs such as ChatGPT using publicly available data sets. We carry out an\nextensive technical evaluation of ChatGPT using 23 data sets covering 8\ndifferent common NLP application tasks. We evaluate the multitask, multilingual\nand multi-modal aspects of ChatGPT based on these data sets and a newly\ndesigned multimodal dataset. We find that ChatGPT outperforms LLMs with\nzero-shot learning on most tasks and even outperforms fine-tuned models on some\ntasks. We find that it is better at understanding non-Latin script languages\nthan generating them. It is able to generate multimodal content from textual\nprompts, via an intermediate code generation step. Moreover, we find that\nChatGPT is 63.41% accurate on average in 10 different reasoning categories\nunder logical reasoning, non-textual reasoning, and commonsense reasoning,\nhence making it an unreliable reasoner. It is, for example, better at deductive\nthan inductive reasoning. ChatGPT suffers from hallucination problems like\nother LLMs and it generates more extrinsic hallucinations from its parametric\nmemory as it does not have access to an external knowledge base. Finally, the\ninteractive feature of ChatGPT enables human collaboration with the underlying\nLLM to improve its performance, i.e, 8% ROUGE-1 on summarization and 2% ChrF++\non machine translation, in a multi-turn \"prompt engineering\" fashion. We also\nrelease codebase for evaluation set extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenliang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilie_B/0/1/0/all/0/1\">Bryan Wilie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Do_Q/0/1/0/all/0/1\">Quyet V. Do</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training Language Models for Comparative Reasoning. (arXiv:2305.14457v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14457","description":"<p>Comparative reasoning is a process of comparing objects, concepts, or\nentities to draw conclusions, which constitutes a fundamental cognitive\nability. In this paper, we propose a novel framework to pre-train language\nmodels for enhancing their abilities of comparative reasoning over texts. While\nthere have been approaches for NLP tasks that require comparative reasoning,\nthey suffer from costly manual data labeling and limited generalizability to\ndifferent tasks. Our approach introduces a novel method of collecting scalable\ndata for text-based entity comparison, which leverages both structured and\nunstructured data. Moreover, we present a framework of pre-training language\nmodels via three novel objectives on comparative reasoning. Evaluation on\ndownstream tasks including comparative question answering, question generation,\nand summarization shows that our pre-training framework significantly improves\nthe comparative reasoning abilities of language models, especially under\nlow-resource conditions. This work also releases the first integrated benchmark\nfor comparative reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1\">Mengxia Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Demonstration Selection with Cross Entropy Difference. (arXiv:2305.14726v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14726","description":"<p>Large language models (LLMs) can use in-context demonstrations to improve\nperformance on zero-shot tasks. However, selecting the best in-context examples\nis challenging because model performance can vary widely depending on the\nselected examples. We present a cross-entropy difference (CED) method for\nselecting in-context demonstrations. Our method is based on the observation\nthat the effectiveness of in-context demonstrations negatively correlates with\nthe perplexity of the test example by a language model that was finetuned on\nthat demonstration. We utilize parameter efficient finetuning to train small\nmodels on training data that are used for computing the cross-entropy\ndifference between a test example and every candidate in-context demonstration.\nThis metric is used to rank and select in-context demonstrations independently\nfor each test input. We evaluate our method on a mix-domain dataset that\ncombines 8 benchmarks, representing 4 text generation tasks, showing that CED\nfor in-context demonstration selection can improve performance for a variety of\nLLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Patent Documents to Engineering Design Knowledge Graphs. (arXiv:2307.06985v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.06985","description":"<p>Aimed at supporting knowledge-intensive tasks in the design process,\npopulating design knowledge from text documents involves the extraction of\ntriples - head entity :: relationship :: tail entity or h :: r :: t that could\nbe combined into a knowledge graph representation. As relationships are largely\nchosen from ontological or common-sense alternatives, knowledge graphs built\nusing these depict an approximation or restricted view of design knowledge,\nrather than what is explicated in text document. In this article, we present a\ndata-driven approach to identify and explicate facts (h :: r :: t) from\nsentences in patent documents. We create a dataset of 44,227 sentences and\nfacts, encompassing all patent classifications while also capturing the\nvariations among patent document sections. Using this dataset, we train taggers\nthat classify tokens to: 1) identify all entities (h) and relationships (r) and\n2) specific relationships (r) for a pair of entities (h :: ___ :: t). While\nthese taggers are built upon transformer-based sequence classification models,\nwe evaluate our proposed method against edge classification approaches that use\nlinear classifiers and graph neural networks, incorporating transformer-based\ntoken embeddings and linguistic features. The simplicity and coverage of the\nproposed method enable its application to patent documents at any scale and\nvariety. Upon deploying an open-source python package, we apply our method to\npatent documents related to fan systems. From the knowledge graphs thus\nextracted, we explain how facts could be generalised to domain ontologies as\nwell as be specified to subsystem levels. We also highlight the importance of\nknowledge graph representations by retrieving and explicating the knowledge of\nkey issues in fan systems, while holding a comparative discussion against\nopinions from ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Siddharth_L/0/1/0/all/0/1\">L Siddharth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianxi Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Certifying LLM Safety against Adversarial Prompting. (arXiv:2309.02705v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02705","description":"<p>Large language models (LLMs) released for public use incorporate guardrails\nto ensure their output is safe, often referred to as \"model alignment.\" An\naligned language model should decline a user's request to produce harmful\ncontent. However, such safety measures are vulnerable to adversarial attacks,\nwhich add maliciously designed token sequences to a harmful prompt to bypass\nthe model's safety guards. In this work, we introduce erase-and-check, the\nfirst framework to defend against adversarial prompts with verifiable safety\nguarantees. We defend against three attack modes: i) adversarial suffix, which\nappends an adversarial sequence at the end of the prompt; ii) adversarial\ninsertion, where the adversarial sequence is inserted anywhere in the middle of\nthe prompt; and iii) adversarial infusion, where adversarial tokens are\ninserted at arbitrary positions in the prompt, not necessarily as a contiguous\nblock. Our experimental results demonstrate that this procedure can obtain\nstrong certified safety guarantees on harmful prompts while maintaining good\nempirical performance on safe prompts. For example, against adversarial\nsuffixes of length 20, it certifiably detects 92% of harmful prompts and labels\n94% of safe prompts correctly using the open-source language model Llama 2 as\nthe safety filter. We further improve the filter's performance, in terms of\naccuracy and speed, by replacing Llama 2 with a DistilBERT safety classifier\nfine-tuned on safe and harmful prompts. Additionally, we propose two efficient\nempirical defenses: i) RandEC, a randomized version of erase-and-check that\nevaluates the safety filter on a small subset of the erased subsequences, and\nii) GradEC, a gradient-based version that optimizes the erased tokens to remove\nthe adversarial sequence. The code for our experiments is available at\nhttps://github.com/aounon/certified-llm-safety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Aounon Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1\">Chirag Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivas_S/0/1/0/all/0/1\">Suraj Srinivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Aaron Jiaxun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1\">Soheil Feizi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FELM: Benchmarking Factuality Evaluation of Large Language Models. (arXiv:2310.00741v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00741","description":"<p>Assessing factuality of text generated by large language models (LLMs) is an\nemerging yet crucial research area, aimed at alerting users to potential errors\nand guiding the development of more reliable LLMs. Nonetheless, the evaluators\nassessing factuality necessitate suitable evaluation themselves to gauge\nprogress and foster advancements. This direction remains under-explored,\nresulting in substantial impediments to the progress of factuality evaluators.\nTo mitigate this issue, we introduce a benchmark for Factuality Evaluation of\nlarge Language Models, referred to as felm. In this benchmark, we collect\nresponses generated from LLMs and annotate factuality labels in a fine-grained\nmanner. Contrary to previous studies that primarily concentrate on the\nfactuality of world knowledge (e.g.~information from Wikipedia), felm focuses\non factuality across diverse domains, spanning from world knowledge to math and\nreasoning. Our annotation is based on text segments, which can help pinpoint\nspecific factual errors. The factuality annotations are further supplemented by\npredefined error types and reference links that either support or contradict\nthe statement. In our experiments, we investigate the performance of several\nLLM-based factuality evaluators on felm, including both vanilla LLMs and those\naugmented with retrieval mechanisms and chain-of-thought processes. Our\nfindings reveal that while retrieval aids factuality evaluation, current LLMs\nare far from satisfactory to faithfully detect factual errors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shiqi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yiran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinghan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chern_I/0/1/0/all/0/1\">I-Chun Chern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Siyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation. (arXiv:2310.01837v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.01837","description":"<p>Current AI-based methods do not provide comprehensible physical\ninterpretations of the utilized data, extracted features, and\npredictions/inference operations. As a result, deep learning models trained\nusing high-resolution satellite imagery lack transparency and explainability\nand can be merely seen as a black box, which limits their wide-level adoption.\nExperts need help understanding the complex behavior of AI models and the\nunderlying decision-making process. The explainable artificial intelligence\n(XAI) field is an emerging field providing means for robust, practical, and\ntrustworthy deployment of AI models. Several XAI techniques have been proposed\nfor image classification tasks, whereas the interpretation of image\nsegmentation remains largely unexplored. This paper offers to bridge this gap\nby adapting the recent XAI classification algorithms and making them usable for\nmuti-class image segmentation, where we mainly focus on buildings' segmentation\nfrom high-resolution satellite images. To benchmark and compare the performance\nof the proposed approaches, we introduce a new XAI evaluation methodology and\nmetric based on \"Entropy\" to measure the model uncertainty. Conventional XAI\nevaluation methods rely mainly on feeding area-of-interest regions from the\nimage back to the pre-trained (utility) model and then calculating the average\nchange in the probability of the target class. Those evaluation metrics lack\nthe needed robustness, and we show that using Entropy to monitor the model\nuncertainty in segmenting the pixels within the target class is more suitable.\nWe hope this work will pave the way for additional XAI research for image\nsegmentation and applications in the remote sensing discipline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gizzini_A/0/1/0/all/0/1\">Abdul Karim Gizzini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shukor_M/0/1/0/all/0/1\">Mustafa Shukor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandour_A/0/1/0/all/0/1\">Ali J. Ghandour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards End-to-End Embodied Decision Making via Multi-modal Large Language Model: Explorations with GPT4-Vision and Beyond. (arXiv:2310.02071v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.02071","description":"<p>In this study, we explore the potential of Multimodal Large Language Models\n(MLLMs) in improving embodied decision-making processes for agents. While Large\nLanguage Models (LLMs) have been widely used due to their advanced reasoning\nskills and vast world knowledge, MLLMs like GPT4-Vision offer enhanced visual\nunderstanding and reasoning capabilities. We investigate whether\nstate-of-the-art MLLMs can handle embodied decision-making in an end-to-end\nmanner and whether collaborations between LLMs and MLLMs can enhance\ndecision-making. To address these questions, we introduce a new benchmark\ncalled PCA-EVAL, which evaluates embodied decision-making from the perspectives\nof Perception, Cognition, and Action. Additionally, we propose HOLMES, a\nmulti-agent cooperation framework that allows LLMs to leverage MLLMs and APIs\nto gather multimodal information for informed decision-making. We compare\nend-to-end embodied decision-making and HOLMES on our benchmark and find that\nthe GPT4-Vision model demonstrates strong end-to-end embodied decision-making\nabilities, outperforming GPT4-HOLMES in terms of average decision accuracy\n(+3%). However, this performance is exclusive to the latest GPT4-Vision model,\nsurpassing the open-source state-of-the-art MLLM by 26%. Our results indicate\nthat powerful MLLMs like GPT4-Vision hold promise for decision-making in\nembodied agents, offering new avenues for MLLM research. Code and data are open\nat https://github.com/pkunlp-icler/PCA-EVAL/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zefan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuchi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peiyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Performance of Multimodal Language Models. (arXiv:2310.03211v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03211","description":"<p>Instruction-tuned large language models (LLMs) have demonstrated promising\nzero-shot generalization capabilities across various downstream tasks. Recent\nresearch has introduced multimodal capabilities to LLMs by integrating\nindependently pretrained vision encoders through model grafting. These\nmultimodal variants undergo instruction tuning, similar to LLMs, enabling\neffective zero-shot generalization for multimodal tasks. This study conducts a\ncomparative analysis of different multimodal instruction tuning approaches and\nevaluates their performance across a range of tasks, including complex\nreasoning, conversation, image captioning, multiple-choice questions (MCQs),\nand binary classification. Through rigorous benchmarking and ablation\nexperiments, we reveal key insights for guiding architectural choices when\nincorporating multimodal capabilities into LLMs. However, current approaches\nhave limitations; they do not sufficiently address the need for a diverse\nmultimodal instruction dataset, which is crucial for enhancing task\ngeneralization. Additionally, they overlook issues related to truthfulness and\nfactuality when generating responses. These findings illuminate current\nmethodological constraints in adapting language models for image comprehension\nand provide valuable guidance for researchers and practitioners seeking to\nharness multimodal versions of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garg_U/0/1/0/all/0/1\">Utsav Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bas_E/0/1/0/all/0/1\">Erhan Bas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Brief History of Prompt: Leveraging Language Models. (Through Advanced Prompting). (arXiv:2310.04438v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04438","description":"<p>This paper presents a comprehensive exploration of the evolution of prompt\nengineering and generation in the field of natural language processing (NLP).\nStarting from the early language models and information retrieval systems, we\ntrace the key developments that have shaped prompt engineering over the years.\nThe introduction of attention mechanisms in 2015 revolutionized language\nunderstanding, leading to advancements in controllability and\ncontext-awareness. Subsequent breakthroughs in reinforcement learning\ntechniques further enhanced prompt engineering, addressing issues like exposure\nbias and biases in generated text. We examine the significant contributions in\n2018 and 2019, focusing on fine-tuning strategies, control codes, and\ntemplate-based generation. The paper also discusses the growing importance of\nfairness, human-AI collaboration, and low-resource adaptation. In 2020 and\n2021, contextual prompting and transfer learning gained prominence, while 2022\nand 2023 witnessed the emergence of advanced techniques like unsupervised\npre-training and novel reward shaping. Throughout the paper, we reference\nspecific research studies that exemplify the impact of various developments on\nprompt engineering. The journey of prompt engineering continues, with ethical\nconsiderations being paramount for the responsible and inclusive future of AI\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muktadir_G/0/1/0/all/0/1\">Golam Md Muktadir</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of Multi-modal Language Models. (arXiv:2310.06627v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06627","description":"<p>Counterfactual reasoning, a fundamental aspect of human cognition, involves\ncontemplating alternatives to established facts or past events, significantly\nenhancing our abilities in planning and decision-making. In light of the\nadvancements in current multi-modal large language models, we explore their\neffectiveness in counterfactual reasoning. To facilitate this investigation, we\nintroduce a novel dataset, C-VQA, specifically designed to test the\ncounterfactual reasoning capabilities of modern multi-modal large language\nmodels. This dataset is constructed by infusing original questions with\ncounterfactual presuppositions, spanning various types such as numerical and\nboolean queries. It encompasses a mix of real and synthetic data, representing\na wide range of difficulty levels. Our thorough evaluations of contemporary\nvision-language models using this dataset have revealed substantial performance\ndrops, with some models showing up to a 40% decrease, highlighting a\nsignificant gap between current models and human-like vision reasoning\ncapabilities. We hope our dataset will serve as a vital benchmark for\nevaluating the counterfactual reasoning capabilities of models. Code and\ndataset are publicly available at https://bzhao.me/C-VQA/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Letian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaotong Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhongkai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zong_Y/0/1/0/all/0/1\">Yongshuo Zong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bingchen Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement. (arXiv:2310.08559v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08559","description":"<p>The ability to derive underlying principles from a handful of observations\nand then generalize to novel situations -- known as inductive reasoning -- is\ncentral to human intelligence. Prior work suggests that language models (LMs)\noften fall short on inductive reasoning, despite achieving impressive success\non research benchmarks. In this work, we conduct a systematic study of the\ninductive reasoning capabilities of LMs through iterative hypothesis\nrefinement, a technique that more closely mirrors the human inductive process\nthan standard input-output prompting. Iterative hypothesis refinement employs a\nthree-step process: proposing, selecting, and refining hypotheses in the form\nof textual rules. By examining the intermediate rules, we observe that LMs are\nphenomenal hypothesis proposers (i.e., generating candidate rules), and when\ncoupled with a (task-specific) symbolic interpreter that is able to\nsystematically filter the proposed set of rules, this hybrid approach achieves\nstrong results across inductive reasoning benchmarks that require inducing\ncausal relations, language-like instructions, and symbolic concepts. However,\nthey also behave as puzzling inductive reasoners, showing notable performance\ngaps between rule induction (i.e., identifying plausible rules) and rule\napplication (i.e., applying proposed rules to instances), suggesting that LMs\nare proposing hypotheses without being able to actually apply the rules.\nThrough empirical and human analyses, we further reveal several discrepancies\nbetween the inductive reasoning processes of LMs and humans, shedding light on\nboth the potentials and limitations of using LMs in inductive reasoning tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Linlu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Liwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sclar_M/0/1/0/all/0/1\">Melanie Sclar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1\">Chandra Bhagavatula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bailin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dziri_N/0/1/0/all/0/1\">Nouha Dziri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models. (arXiv:2310.08659v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08659","description":"<p>Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves generalization in\ndownstream tasks. We evaluate our method on natural language understanding,\nquestion answering, summarization, and natural language generation tasks.\nExperiments show that our method is highly effective and outperforms existing\nquantization methods, especially in the challenging 2-bit and 2/4-bit mixed\nprecision regimes. The code is available on https://github.com/yxli2123/LoftQ.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karampatziakis_N/0/1/0/all/0/1\">Nikos Karampatziakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules. (arXiv:2310.08992v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.08992","description":"<p>Large Language Models (LLMs) have already become quite proficient at solving\nsimpler programming tasks like those in HumanEval or MBPP benchmarks. However,\nsolving more complex and competitive programming tasks is still quite\nchallenging for these models - possibly due to their tendency to generate\nsolutions as monolithic code blocks instead of decomposing them into logical\nsub-tasks and sub-modules. On the other hand, experienced programmers\ninstinctively write modularized code with abstraction for solving complex\ntasks, often reusing previously developed modules. To address this gap, we\npropose CodeChain, a novel framework for inference that elicits modularized\ncode generation through a chain of self-revisions, each being guided by some\nrepresentative sub-modules generated in previous iterations. Concretely,\nCodeChain first instructs the LLM to generate modularized codes through\nchain-of-thought prompting. Then it applies a chain of self-revisions by\niterating the two steps: 1) extracting and clustering the generated sub-modules\nand selecting the cluster representatives as the more generic and re-usable\nimplementations, and 2) augmenting the original chain-of-thought prompt with\nthese selected module-implementations and instructing the LLM to re-generate\nnew modularized solutions. We find that by naturally encouraging the LLM to\nreuse the previously developed and verified sub-modules, CodeChain can\nsignificantly boost both modularity as well as correctness of the generated\nsolutions, achieving relative pass@1 improvements of 35% on APPS and 76% on\nCodeContests. It is shown to be effective on both OpenAI LLMs as well as\nopen-sourced LLMs like WizardCoder. We also conduct comprehensive ablation\nstudies with different methods of prompting, number of clusters, model sizes,\nprogram qualities, etc., to provide useful insights that underpin CodeChain's\nsuccess.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hailin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Amrita Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gokul_A/0/1/0/all/0/1\">Akash Gokul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahoo_D/0/1/0/all/0/1\">Doyen Sahoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Learning Dynamics with Random Binary Sequences. (arXiv:2310.17639v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.17639","description":"<p>Large language models (LLMs) trained on huge corpora of text datasets\ndemonstrate intriguing capabilities, achieving state-of-the-art performance on\ntasks they were not explicitly trained for. The precise nature of LLM\ncapabilities is often mysterious, and different prompts can elicit different\ncapabilities through in-context learning. We propose a framework that enables\nus to analyze in-context learning dynamics to understand latent concepts\nunderlying LLMs' behavioral patterns. This provides a more nuanced\nunderstanding than success-or-failure evaluation benchmarks, but does not\nrequire observing internal activations as a mechanistic interpretation of\ncircuits would. Inspired by the cognitive science of human randomness\nperception, we use random binary sequences as context and study dynamics of\nin-context learning by manipulating properties of context data, such as\nsequence length. In the latest GPT-3.5+ models, we find emergent abilities to\ngenerate seemingly random numbers and learn basic formal languages, with\nstriking in-context learning dynamics where model outputs transition sharply\nfrom seemingly random behaviors to deterministic repetition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bigelow_E/0/1/0/all/0/1\">Eric J. Bigelow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1\">Ekdeep Singh Lubana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1\">Robert P. Dick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1\">Hidenori Tanaka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1\">Tomer D. Ullman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations. (arXiv:2310.20246v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.20246","description":"<p>Existing research predominantly focuses on developing powerful language\nlearning models (LLMs) for mathematical reasoning within monolingual languages,\nwith few explorations in preserving efficacy in a multilingual context. To\nbridge this gap, this paper pioneers exploring and training powerful\nMultilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we\nconstruct the first multilingual math reasoning instruction dataset,\nMGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue\nof training data scarcity in xMR tasks. Based on the collected dataset, we\npropose different training strategies to build powerful xMR LLMs, named\nMathOctopus, notably outperform conventional open-source LLMs and exhibit\nsuperiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B\nreaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond\nremarkable results, we unearth several pivotal observations and insights from\nextensive experiments: (1) When extending the rejection sampling strategy to\nthe multilingual context, it proves effective for model performances, albeit\nlimited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT)\nacross multiple languages not only significantly enhances model performance\nmultilingually but also elevates their monolingual performance. This indicates\nthat crafting multilingual corpora can be regarded as a vital strategy for\nenhancing model performance in a specific language, especially in mathematical\nreasoning tasks. For instance, MathOctopus-7B improves its counterparts that\ntrained on English from 42.2% to 50.8% on GSM8K testset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zinan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Ning Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Ming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection. (arXiv:2311.01270v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.01270","description":"<p>NLP models are used in a variety of critical social computing tasks, such as\ndetecting sexist, racist, or otherwise hateful content. Therefore, it is\nimperative that these models are robust to spurious features. Past work has\nattempted to tackle such spurious features using training data augmentation,\nincluding Counterfactually Augmented Data (CADs). CADs introduce minimal\nchanges to existing training data points and flip their labels; training on\nthem may reduce model dependency on spurious features. However, manually\ngenerating CADs can be time-consuming and expensive. Hence in this work, we\nassess if this task can be automated using generative NLP models. We\nautomatically generate CADs using Polyjuice, ChatGPT, and Flan-T5, and evaluate\ntheir usefulness in improving model robustness compared to manually-generated\nCADs. By testing both model performance on multiple out-of-domain test sets and\nindividual data point efficacy, our results show that while manual CADs are\nstill the most effective, CADs generated by ChatGPT come a close second. One\nkey reason for the lower performance of automated methods is that the changes\nthey introduce are often insufficient to flip the original label.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sen_I/0/1/0/all/0/1\">Indira Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assenmacher_D/0/1/0/all/0/1\">Dennis Assenmacher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samory_M/0/1/0/all/0/1\">Mattia Samory</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aalst_W/0/1/0/all/0/1\">Wil van der Aalst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1\">Claudia Wagner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using large language models to study human memory for meaningful narratives. (arXiv:2311.04742v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.04742","description":"<p>One of the most impressive achievements of the AI revolution is the\ndevelopment of large language models that can generate meaningful text and\nrespond to instructions in plain English with no additional training necessary.\nHere we show that language models can be used as a scientific instrument for\nstudying human memory for meaningful material. We developed a pipeline for\ndesigning large scale memory experiments and analyzing the obtained results. We\nperformed online memory experiments with a large number of participants and\ncollected recognition and recall data for narratives of different lengths. We\nfound that both recall and recognition performance scale linearly with\nnarrative length. Furthermore, in order to investigate the role of narrative\ncomprehension in memory, we repeated these experiments using scrambled versions\nof the presented stories. We found that even though recall performance declined\nsignificantly, recognition remained largely unaffected. Interestingly, recalls\nin this condition seem to follow the original narrative order rather than the\nscrambled presentation, pointing to a contextual reconstruction of the story in\nmemory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Georgiou_A/0/1/0/all/0/1\">Antonios Georgiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Can_T/0/1/0/all/0/1\">Tankut Can</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katkov_M/0/1/0/all/0/1\">Mikhail Katkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsodyks_M/0/1/0/all/0/1\">Misha Tsodyks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Road with GPT-4V(ision): Early Explorations of Visual-Language Model on Autonomous Driving. (arXiv:2311.05332v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2311.05332","description":"<p>The pursuit of autonomous driving technology hinges on the sophisticated\nintegration of perception, decision-making, and control systems. Traditional\napproaches, both data-driven and rule-based, have been hindered by their\ninability to grasp the nuance of complex driving environments and the\nintentions of other road users. This has been a significant bottleneck,\nparticularly in the development of common sense reasoning and nuanced scene\nunderstanding necessary for safe and reliable autonomous driving. The advent of\nVisual Language Models (VLM) represents a novel frontier in realizing fully\nautonomous vehicle driving. This report provides an exhaustive evaluation of\nthe latest state-of-the-art VLM, GPT-4V(ision), and its application in\nautonomous driving scenarios. We explore the model's abilities to understand\nand reason about driving scenes, make decisions, and ultimately act in the\ncapacity of a driver. Our comprehensive tests span from basic scene recognition\nto complex causal reasoning and real-time decision-making under varying\nconditions. Our findings reveal that GPT-4V demonstrates superior performance\nin scene understanding and causal reasoning compared to existing autonomous\nsystems. It showcases the potential to handle out-of-distribution scenarios,\nrecognize intentions, and make informed decisions in real driving contexts.\nHowever, challenges remain, particularly in direction discernment, traffic\nlight recognition, vision grounding, and spatial reasoning tasks. These\nlimitations underscore the need for further research and development. Project\nis now available on GitHub for interested parties to access and utilize:\n\\url{https://github.com/PJLab-ADG/GPT4V-AD-Exploration}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Licheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xuemeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daocheng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1\">Pinlong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1\">Linran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_D/0/1/0/all/0/1\">Dengke Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zheng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shaoyan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yeqi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xinyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_M/0/1/0/all/0/1\">Min Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Shuanglu Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Botian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Graph Meets Large Language Model: Progress and Future Directions. (arXiv:2311.12399v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2311.12399","description":"<p>Graph plays a significant role in representing and analyzing complex\nrelationships in real-world applications such as citation networks, social\nnetworks, and biological data. Recently, Large Language Models (LLMs), which\nhave achieved tremendous success in various domains, have also been leveraged\nin graph-related tasks to surpass traditional Graph Neural Networks (GNNs)\nbased methods and yield state-of-the-art performance. In this survey, we first\npresent a comprehensive review and analysis of existing methods that integrate\nLLMs with graphs. First of all, we propose a new taxonomy, which organizes\nexisting methods into three categories based on the role (i.e., enhancer,\npredictor, and alignment component) played by LLMs in graph-related tasks. Then\nwe systematically survey the representative methods along the three categories\nof the taxonomy. Finally, we discuss the remaining limitations of existing\nstudies and highlight promising avenues for future research. The relevant\npapers are summarized and will be consistently updated at:\nhttps://github.com/yhLeeee/Awesome-LLMs-in-Graph-tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhixun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peisong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiangguo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jeffrey Xu Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The effect of source disclosure on evaluation of AI-generated messages: A two-part study. (arXiv:2311.15544v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.15544","description":"<p>Advancements in artificial intelligence (AI) over the last decade demonstrate\nthat machines can exhibit communicative behavior and influence how humans\nthink, feel, and behave. In fact, the recent development of ChatGPT has shown\nthat large language models (LLMs) can be leveraged to generate high-quality\ncommunication content at scale and across domains, suggesting that they will be\nincreasingly used in practice. However, many questions remain about how knowing\nthe source of the messages influences recipients' evaluation of and preference\nfor AI-generated messages compared to human-generated messages. This paper\ninvestigated this topic in the context of vaping prevention messaging. In Study\n1, which was pre-registered, we examined the influence of source disclosure on\npeople's evaluation of AI-generated health prevention messages compared to\nhuman-generated messages. We found that source disclosure (i.e., labeling the\nsource of a message as AI vs. human) significantly impacted the evaluation of\nthe messages but did not significantly alter message rankings. In a follow-up\nstudy (Study 2), we examined how the influence of source disclosure may vary by\nthe participants' negative attitudes towards AI. We found a significant\nmoderating effect of negative attitudes towards AI on message evaluation, but\nnot for message selection. However, for those with moderate levels of negative\nattitudes towards AI, source disclosure decreased the preference for\nAI-generated messages. Overall, the results of this series of studies showed a\nslight bias against AI-generated messages once the source was disclosed, adding\nto the emerging area of study that lies at the intersection of AI and\ncommunication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Sue Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmalzle_R/0/1/0/all/0/1\">Ralf Schm&#xe4;lzle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-11-28T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}