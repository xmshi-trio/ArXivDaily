{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2022-11-14T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Casual Conversations v2: Designing a large consent-driven dataset to measure algorithmic bias and robustness. (arXiv:2211.05809v1 [cs.CV])","link":"http://arxiv.org/abs/2211.05809","description":"<p>Developing robust and fair AI systems require datasets with comprehensive set\nof labels that can help ensure the validity and legitimacy of relevant\nmeasurements. Recent efforts, therefore, focus on collecting person-related\ndatasets that have carefully selected labels, including sensitive\ncharacteristics, and consent forms in place to use those attributes for model\ntesting and development. Responsible data collection involves several stages,\nincluding but not limited to determining use-case scenarios, selecting\ncategories (annotations) such that the data are fit for the purpose of\nmeasuring algorithmic bias for subgroups and most importantly ensure that the\nselected categories/subcategories are robust to regional diversities and\ninclusive of as many subgroups as possible.\n</p>\n<p>Meta, in a continuation of our efforts to measure AI algorithmic bias and\nrobustness\n(https://ai.facebook.com/blog/shedding-light-on-fairness-in-ai-with-a-new-data-set),\nis working on collecting a large consent-driven dataset with a comprehensive\nlist of categories. This paper describes our proposed design of such categories\nand subcategories for Casual Conversations v2.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hazirbas_C/0/1/0/all/0/1\">Caner Hazirbas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assar_P/0/1/0/all/0/1\">Parisa Assar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porgali_B/0/1/0/all/0/1\">Bilal Porgali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albiero_V/0/1/0/all/0/1\">V&#xed;tor Albiero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hermanek_S/0/1/0/all/0/1\">Stefan Hermanek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jacqueline Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McReynolds_E/0/1/0/all/0/1\">Emily McReynolds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bogen_M/0/1/0/all/0/1\">Miranda Bogen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The CRINGE Loss: Learning what language not to model. (arXiv:2211.05826v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05826","description":"<p>Standard language model training employs gold human documents or human-human\ninteraction data, and treats all training data as positive examples. Growing\nevidence shows that even with very large amounts of positive training data,\nissues remain that can be alleviated with relatively small amounts of negative\ndata -- examples of what the model should not do. In this work, we propose a\nnovel procedure to train with such data called the CRINGE loss (ContRastive\nIterative Negative GEneration). We show the effectiveness of this approach\nacross three different experiments on the tasks of safe generation,\ncontradiction avoidance, and open-domain dialogue. Our models outperform\nmultiple strong baselines and are conceptually simple, easy to train and\nimplement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adolphs_L/0/1/0/all/0/1\">Leonard Adolphs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1\">Tianyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuster_K/0/1/0/all/0/1\">Kurt Shuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1\">Sainbayar Sukhbaatar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1\">Jason Weston</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Climate Policy Tracker: Pipeline for automated analysis of public climate policies. (arXiv:2211.05852v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05852","description":"<p>The number of standardized policy documents regarding climate policy and\ntheir publication frequency is significantly increasing. The documents are long\nand tedious for manual analysis, especially for policy experts, lawmakers, and\ncitizens who lack access or domain expertise to utilize data analytics tools.\nPotential consequences of such a situation include reduced citizen governance\nand involvement in climate policies and an overall surge in analytics costs,\nrendering less accessibility for the public. In this work, we use a Latent\nDirichlet Allocation-based pipeline for the automatic summarization and\nanalysis of 10-years of national energy and climate plans (NECPs) for the\nperiod from 2021 to 2030, established by 27 Member States of the European\nUnion. We focus on analyzing policy framing, the language used to describe\nspecific issues, to detect essential nuances in the way governments frame their\nclimate policies and achieve climate goals. The methods leverage topic modeling\nand clustering for the comparative analysis of policy documents across\ndifferent countries. It allows for easier integration in potential\nuser-friendly applications for the development of theories and processes of\nclimate policy. This would further lead to better citizen governance and\nengagement over climate policies and public policy research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zolkowski_A/0/1/0/all/0/1\">Artur &#x17b;&#xf3;&#x142;kowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krzyzinski_M/0/1/0/all/0/1\">Mateusz Krzyzi&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilczynski_P/0/1/0/all/0/1\">Piotr Wilczy&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gizinski_S/0/1/0/all/0/1\">Stanis&#x142;aw Gizi&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wisnios_E/0/1/0/all/0/1\">Emilia Wi&#x15b;nios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pielinski_B/0/1/0/all/0/1\">Bartosz Pieli&#x144;ski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sienkiewicz_J/0/1/0/all/0/1\">Julian Sienkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Biecek_P/0/1/0/all/0/1\">Przemys&#x142;aw Biecek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Reliability of Large Language Models through Semantic Consistency. (arXiv:2211.05853v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05853","description":"<p>While large pretrained language models (PLMs) demonstrate incredible fluency\nand performance on many natural language tasks, recent work has shown that\nwell-performing PLMs are very sensitive to what prompts are feed into them.\nEven when prompts are semantically identical, language models may give very\ndifferent answers. When considering safe and trustworthy deployments of PLMs we\nwould like their outputs to be consistent under prompts that mean the same\nthing or convey the same intent. While some work has looked into how\nstate-of-the-art PLMs address this need, they have been limited to only\nevaluating lexical equality of single- or multi-word answers and do not address\nconsistency of generative text sequences. In order to understand consistency of\nPLMs under text generation settings, we develop a measure of semantic\nconsistency that allows the comparison of open-ended text outputs. We implement\nseveral versions of this consistency metric to evaluate the performance of a\nnumber of PLMs on paraphrased versions of questions in the TruthfulQA dataset,\nwe find that our proposed metrics are considerably more consistent than\ntraditional metrics embodying lexical consistency, and also correlate with\nhuman evaluation of output consistency to a higher degree.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raj_H/0/1/0/all/0/1\">Harsh Raj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosati_D/0/1/0/all/0/1\">Domenic Rosati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1\">Subhabrata Majumdar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on the Integration of Pre-trained SSL, ASR, LM and SLU Models for Spoken Language Understanding. (arXiv:2211.05869v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05869","description":"<p>Collecting sufficient labeled data for spoken language understanding (SLU) is\nexpensive and time-consuming. Recent studies achieved promising results by\nusing pre-trained models in low-resource scenarios. Inspired by this, we aim to\nask: which (if any) pre-training strategies can improve performance across SLU\nbenchmarks? To answer this question, we employ four types of pre-trained models\nand their combinations for SLU. We leverage self-supervised speech and language\nmodels (LM) pre-trained on large quantities of unpaired data to extract strong\nspeech and text representations. We also explore using supervised models\npre-trained on larger external automatic speech recognition (ASR) or SLU\ncorpora. We conduct extensive experiments on the SLU Evaluation (SLUE)\nbenchmark and observe self-supervised pre-trained models to be more powerful,\nwith pre-trained LM and speech models being most beneficial for the Sentiment\nAnalysis and Named Entity Recognition task, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Siddhant Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Higuchi_Y/0/1/0/all/0/1\">Yosuke Higuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ueda_Y/0/1/0/all/0/1\">Yushi Ueda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sujay Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1\">Karthik Ganesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1\">Siddharth Dalmia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xuankai Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CREATIVESUMM: Shared Task on Automatic Summarization for Creative Writing. (arXiv:2211.05886v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05886","description":"<p>This paper introduces the shared task of summarizing documents in several\ncreative domains, namely literary texts, movie scripts, and television scripts.\nSummarizing these creative documents requires making complex literary\ninterpretations, as well as understanding non-trivial temporal dependencies in\ntexts containing varied styles of plot development and narrative structure.\nThis poses unique challenges and is yet underexplored for text summarization\nsystems. In this shared task, we introduce four sub-tasks and their\ncorresponding datasets, focusing on summarizing books, movie scripts, primetime\ntelevision scripts, and daytime soap opera scripts. We detail the process of\ncurating these datasets for the task, as well as the metrics used for the\nevaluation of the submissions. As part of the CREATIVESUMM workshop at COLING\n2022, the shared task attracted 18 submissions in total. We discuss the\nsubmissions and the baselines for each sub-task in this paper, along with\ndirections for facilitating future work in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_D/0/1/0/all/0/1\">Divyansh Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander R. Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Simeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kryscinski_W/0/1/0/all/0/1\">Wojciech Kryscinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladhak_F/0/1/0/all/0/1\">Faisal Ladhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bryan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wiseman_S/0/1/0/all/0/1\">Sam Wiseman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding ME? Multimodal Evaluation for Fine-grained Visual Commonsense. (arXiv:2211.05895v1 [cs.CV])","link":"http://arxiv.org/abs/2211.05895","description":"<p>Visual commonsense understanding requires Vision Language (VL) models to not\nonly understand image and text but also cross-reference in-between to fully\nintegrate and achieve comprehension of the visual scene described. Recently,\nvarious approaches have been developed and have achieved high performance on\nvisual commonsense benchmarks. However, it is unclear whether the models really\nunderstand the visual scene and underlying commonsense knowledge due to limited\nevaluation data resources. To provide an in-depth analysis, we present a\nMultimodal Evaluation (ME) pipeline to automatically generate question-answer\npairs to test models' understanding of the visual scene, text, and related\nknowledge. We then take a step further to show that training with the ME data\nboosts the model's performance in standard VCR evaluation. Lastly, our in-depth\nanalysis and comparison reveal interesting findings: (1) semantically low-level\ninformation can assist the learning of high-level information but not the\nopposite; (2) visual information is generally under utilization compared with\ntext.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoxuan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yicheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-Fu Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breadth-First Pipeline Parallelism. (arXiv:2211.05953v1 [cs.DC])","link":"http://arxiv.org/abs/2211.05953","description":"<p>We introduce Breadth-First Pipeline Parallelism, a novel training schedule\nwhich optimizes the combination of pipeline and data parallelism. Breadth-First\nPipeline Parallelism lowers training time, cost and memory usage by combining a\nhigh GPU utilization with a small batch size per GPU, and by making use of\nfully sharded data parallelism. Experimentally, we observed increases of up to\n53% in training speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1\">Joel Lamy-Poirier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEE: A Novel Multilingual Event Extraction Dataset. (arXiv:2211.05955v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05955","description":"<p>Event Extraction (EE) is one of the fundamental tasks in Information\nExtraction (IE) that aims to recognize event mentions and their arguments\n(i.e., participants) from text. Due to its importance, extensive methods and\nresources have been developed for Event Extraction. However, one limitation of\ncurrent research for EE involves the under-exploration for non-English\nlanguages in which the lack of high-quality multilingual EE datasets for model\ntraining and evaluation has been the main hindrance. To address this\nlimitation, we propose a novel Multilingual Event Extraction dataset (MEE) that\nprovides annotation for more than 50K event mentions in 8 typologically\ndifferent languages. MEE comprehensively annotates data for entity mentions,\nevent triggers and event arguments. We conduct extensive experiments on the\nproposed dataset to reveal challenges and opportunities for multilingual EE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Veyseh_A/0/1/0/all/0/1\">Amir Pouran Ben Veyseh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ebrahimi_J/0/1/0/all/0/1\">Javid Ebrahimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thien Huu Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MINION: a Large-Scale and Diverse Dataset for Multilingual Event Detection. (arXiv:2211.05958v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05958","description":"<p>Event Detection (ED) is the task of identifying and classifying trigger words\nof event mentions in text. Despite considerable research efforts in recent\nyears for English text, the task of ED in other languages has been\nsignificantly less explored. Switching to non-English languages, important\nresearch questions for ED include how well existing ED models perform on\ndifferent languages, how challenging ED is in other languages, and how well ED\nknowledge and annotation can be transferred across languages. To answer those\nquestions, it is crucial to obtain multilingual ED datasets that provide\nconsistent event annotation for multiple languages. There exist some\nmultilingual ED datasets; however, they tend to cover a handful of languages\nand mainly focus on popular ones. Many languages are not covered in existing\nmultilingual ED datasets. In addition, the current datasets are often small and\nnot accessible to the public. To overcome those shortcomings, we introduce a\nnew large-scale multilingual dataset for ED (called MINION) that consistently\nannotates events for 8 different languages; 5 of them have not been supported\nby existing multilingual datasets. We also perform extensive experiments and\nanalysis to demonstrate the challenges and transferability of ED across\nlanguages in MINION that in all call for more research effort in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Veyseh_A/0/1/0/all/0/1\">Amir Pouran Ben Veyseh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thien Huu Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Align, Write, Re-order: Explainable End-to-End Speech Translation via Operation Sequence Generation. (arXiv:2211.05967v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05967","description":"<p>The black-box nature of end-to-end speech translation (E2E ST) systems makes\nit difficult to understand how source language inputs are being mapped to the\ntarget language. To solve this problem, we would like to simultaneously\ngenerate automatic speech recognition (ASR) and ST predictions such that each\nsource language word is explicitly mapped to a target language word. A major\nchallenge arises from the fact that translation is a non-monotonic sequence\ntransduction task due to word ordering differences between languages -- this\nclashes with the monotonic nature of ASR. Therefore, we propose to generate ST\ntokens out-of-order while remembering how to re-order them later. We achieve\nthis by predicting a sequence of tuples consisting of a source word, the\ncorresponding target words, and post-editing operations dictating the correct\ninsertion points for the target word. We examine two variants of such operation\nsequences which enable generation of monotonic transcriptions and non-monotonic\ntranslations from the same speech input simultaneously. We apply our approach\nto offline and real-time streaming models, demonstrating that we can provide\nexplainable translations without sacrificing quality or latency. In fact, the\ndelayed re-ordering ability of our approach improves performance during\nstreaming. As an added benefit, our method performs ASR and ST simultaneously,\nmaking it faster than using two separate systems to perform these tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Omachi_M/0/1/0/all/0/1\">Motoi Omachi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Brian Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1\">Siddharth Dalmia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujita_Y/0/1/0/all/0/1\">Yuya Fujita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hardness-guided domain adaptation to recognise biomedical named entities under low-resource scenarios. (arXiv:2211.05980v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05980","description":"<p>Domain adaptation is an effective solution to data scarcity in low-resource\nscenarios. However, when applied to token-level tasks such as bioNER, domain\nadaptation methods often suffer from the challenging linguistic characteristics\nthat clinical narratives possess, which leads to unsatisfactory performance. In\nthis paper, we present a simple yet effective hardness-guided domain adaptation\n(HGDA) framework for bioNER tasks that can effectively leverage the domain\nhardness information to improve the adaptability of the learnt model in\nlow-resource scenarios. Experimental results on biomedical datasets show that\nour model can achieve significant performance improvement over the recently\npublished state-of-the-art (SOTA) MetaNER model\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngoc Dang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1\">Wray Buntine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beare_R/0/1/0/all/0/1\">Richard Beare</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Getting the Most out of Simile Recognition. (arXiv:2211.05984v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05984","description":"<p>Simile recognition involves two subtasks: simile sentence classification that\ndiscriminates whether a sentence contains simile, and simile component\nextraction that locates the corresponding objects (i.e., tenors and vehicles).\nRecent work ignores features other than surface strings. In this paper, we\nexplore expressive features for this task to achieve more effective data\nutilization. Particularly, we study two types of features: 1) input-side\nfeatures that include POS tags, dependency trees and word definitions, and 2)\ndecoding features that capture the interdependence among various decoding\ndecisions. We further construct a model named HGSR, which merges the input-side\nfeatures as a heterogeneous graph and leverages decoding features via\ndistillation. Experiments show that HGSR significantly outperforms the current\nstate-of-the-art systems and carefully designed baselines, verifying the\neffectiveness of introduced features. Our code is available at\nhttps://github.com/DeepLearnXMU/HGSR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chulun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinsong Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Misinformation Detection using Persuasive Writing Strategies. (arXiv:2211.05985v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05985","description":"<p>The spread of misinformation is a prominent problem in today's society, and\nmany researchers in academia and industry are trying to combat it. Due to the\nvast amount of misinformation that is created every day, it is unrealistic to\nleave this task to human fact-checkers. Data scientists and researchers have\nbeen working on automated misinformation detection for years, and it is still a\nchallenging problem today. The goal of our research is to add a new level to\nautomated misinformation detection; classifying segments of text with\npersuasive writing techniques in order to produce interpretable reasoning for\nwhy an article can be marked as misinformation. To accomplish this, we present\na novel annotation scheme containing many common persuasive writing tactics,\nalong with a dataset with human annotations accordingly. For this task, we make\nuse of a RoBERTa model for text classification, due to its high performance in\nNLP. We develop several language model-based baselines and present the results\nof our persuasive strategy label predictions as well as the improvements these\nintermediate labels make in detecting misinformation and producing\ninterpretable results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Romain_J/0/1/0/all/0/1\">Joseph Romain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huiyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_J/0/1/0/all/0/1\">Jingbo Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kordjamshidi_P/0/1/0/all/0/1\">Parisa Kordjamshidi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CCPrompt: Counterfactual Contrastive Prompt-Tuning for Many-Class Classification. (arXiv:2211.05987v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05987","description":"<p>With the success of the prompt-tuning paradigm in Natural Language Processing\n(NLP), various prompt templates have been proposed to further stimulate\nspecific knowledge for serving downstream tasks, e.g., machine translation,\ntext generation, relation extraction, and so on. Existing prompt templates are\nmainly shared among all training samples with the information of task\ndescription. However, training samples are quite diverse. The sharing task\ndescription is unable to stimulate the unique task-related information in each\ntraining sample, especially for tasks with the finite-label space. To exploit\nthe unique task-related information, we imitate the human decision process\nwhich aims to find the contrastive attributes between the objective factual and\ntheir potential counterfactuals. Thus, we propose the \\textbf{C}ounterfactual\n\\textbf{C}ontrastive \\textbf{Prompt}-Tuning (CCPrompt) approach for many-class\nclassification, e.g., relation classification, topic classification, and entity\ntyping. Compared with simple classification tasks, these tasks have more\ncomplex finite-label spaces and are more rigorous for prompts. First of all, we\nprune the finite label space to construct fact-counterfactual pairs. Then, we\nexploit the contrastive attributes by projecting training instances onto every\nfact-counterfactual pair. We further set up global prototypes corresponding\nwith all contrastive attributes for selecting valid contrastive attributes as\nadditional tokens in the prompt template. Finally, a simple Siamese\nrepresentation learning is employed to enhance the robustness of the model. We\nconduct experiments on relation classification, topic classification, and\nentity typing tasks in both fully supervised setting and few-shot setting. The\nresults indicate that our model outperforms former baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Canran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jing Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1\">Guodong Long</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Knowledge-Enhanced Pre-trained Language Models. (arXiv:2211.05994v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05994","description":"<p>Pre-trained Language Models (PLMs) which are trained on large text corpus\nthrough the self-supervised learning method, have yielded promising performance\non various tasks in Natural Language Processing (NLP). However, though PLMs\nwith huge parameters can effectively possess rich knowledge learned from\nmassive training text and benefit downstream tasks at the fine-tuning stage,\nthey still have some limitations such as poor reasoning ability due to the lack\nof external knowledge. Incorporating knowledge into PLMs has been tried to\ntackle these issues. In this paper, we present a comprehensive review of\nKnowledge-Enhanced Pre-trained Language Models (KE-PLMs) to provide a clear\ninsight into this thriving field. We introduce appropriate taxonomies\nrespectively for Natural Language Understanding (NLU) and Natural Language\nGeneration (NLG) to highlight the focus of these two kinds of tasks. For NLU,\nwe take several types of knowledge into account and divide them into four\ncategories: linguistic knowledge, text knowledge, knowledge graph (KG), and\nrule knowledge. The KE-PLMs for NLG are categorized into KG-based and\nretrieval-based methods. Finally, we point out some promising future directions\nof KE-PLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1\">Linmei Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zeyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Ziwang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Liqiang Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-game Toxic Language Detection: Shared Task and Attention Residuals. (arXiv:2211.05995v1 [cs.CL])","link":"http://arxiv.org/abs/2211.05995","description":"<p>In-game toxic language becomes the hot potato in the gaming industry and\ncommunity. There have been several online game toxicity analysis frameworks and\nmodels proposed. However, it is still challenging to detect toxicity due to the\nnature of in-game chat, which has extremely short length. In this paper, we\ndescribe how the in-game toxic language shared task has been established using\nthe real-world in-game chat data. In addition, we propose and introduce the\nmodel/framework for toxic language token tagging (slot filling) from the\nin-game chat. The data and code will be released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuanzhe Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Weixuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_F/0/1/0/all/0/1\">Feiqi Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gradient Imitation Reinforcement Learning for General Low-Resource Information Extraction. (arXiv:2211.06014v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06014","description":"<p>Information Extraction (IE) aims to extract structured information from\nheterogeneous sources. IE from natural language texts include sub-tasks such as\nNamed Entity Recognition (NER), Relation Extraction (RE), and Event Extraction\n(EE). Most IE systems require comprehensive understandings of sentence\nstructure, implied semantics, and domain knowledge to perform well; thus, IE\ntasks always need adequate external resources and annotations. However, it\ntakes time and effort to obtain more human annotations. Low-Resource\nInformation Extraction (LRIE) strives to use unsupervised data, reducing the\nrequired resources and human annotation. In practice, existing systems either\nutilize self-training schemes to generate pseudo labels that will cause the\ngradual drift problem, or leverage consistency regularization methods which\ninevitably possess confirmation bias. To alleviate confirmation bias due to the\nlack of feedback loops in existing LRIE learning paradigms, we develop a\nGradient Imitation Reinforcement Learning (GIRL) method to encourage\npseudo-labeled data to imitate the gradient descent direction on labeled data,\nwhich can force pseudo-labeled data to achieve better optimization capabilities\nsimilar to labeled data. Based on how well the pseudo-labeled data imitates the\ninstructive gradient descent direction obtained from labeled data, we design a\nreward to quantify the imitation process and bootstrap the optimization\ncapability of pseudo-labeled data through trial and error. In addition to\nlearning paradigms, GIRL is not limited to specific sub-tasks, and we leverage\nGIRL to solve all IE sub-tasks (named entity recognition, relation extraction,\nand event extraction) in low-resource settings (semi-supervised IE and few-shot\nIE).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_S/0/1/0/all/0/1\">Shiao Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiangli Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoRAL: a Context-aware Croatian Abusive Language Dataset. (arXiv:2211.06053v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06053","description":"<p>In light of unprecedented increases in the popularity of the internet and\nsocial media, comment moderation has never been a more relevant task.\nSemi-automated comment moderation systems greatly aid human moderators by\neither automatically classifying the examples or allowing the moderators to\nprioritize which comments to consider first. However, the concept of\ninappropriate content is often subjective, and such content can be conveyed in\nmany subtle and indirect ways. In this work, we propose CoRAL -- a language and\nculturally aware Croatian Abusive dataset covering phenomena of implicitness\nand reliance on local and global context. We show experimentally that current\nmodels degrade when comments are not explicit and further degrade when language\nskill and context knowledge are required to interpret the comment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shekhar_R/0/1/0/all/0/1\">Ravi Shekhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karan_M/0/1/0/all/0/1\">Mladen Karan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SceneFake: An Initial Dataset and Benchmarks for Scene Fake Audio Detection. (arXiv:2211.06073v1 [cs.SD])","link":"http://arxiv.org/abs/2211.06073","description":"<p>Previous databases have been designed to further the development of fake\naudio detection. However, fake utterances are mostly generated by altering\ntimbre, prosody, linguistic content or channel noise of original audios. They\nignore a fake situation, in which the attacker manipulates an acoustic scene of\nthe original audio with another forgery one. It will pose a major threat to our\nsociety if some people misuse the manipulated audio with malicious purpose.\nTherefore, this motivates us to fill in the gap. This paper designs such a\ndataset for scene fake audio detection (SceneFake). A manipulated audio in the\nSceneFake dataset involves only tampering the acoustic scene of an utterance by\nusing speech enhancement technologies. We can not only detect fake utterances\non a seen test set but also evaluate the generalization of fake detection\nmodels to unseen manipulation attacks. Some benchmark results are described on\nthe SceneFake dataset. Besides, an analysis of fake attacks with different\nspeech enhancement technologies and signal-to-noise ratios are presented on the\ndataset. The results show that scene manipulated utterances can not be detected\nreliably by the existing baseline models of ASVspoof 2019. Furthermore, the\ndetection of unseen scene manipulation audio is still challenging.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1\">Jiangyan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenglong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhengkun Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Cunhang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Haoxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_R/0/1/0/all/0/1\">Ruibo Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Helping the Weak Makes You Strong: Simple Multi-Task Learning Improves Non-Autoregressive Translators. (arXiv:2211.06075v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06075","description":"<p>Recently, non-autoregressive (NAR) neural machine translation models have\nreceived increasing attention due to their efficient parallel decoding.\nHowever, the probabilistic framework of NAR models necessitates conditional\nindependence assumption on target sequences, falling short of characterizing\nhuman language data. This drawback results in less informative learning signals\nfor NAR models under conventional MLE training, thereby yielding unsatisfactory\naccuracy compared to their autoregressive (AR) counterparts. In this paper, we\npropose a simple and model-agnostic multi-task learning framework to provide\nmore informative learning signals. During training stage, we introduce a set of\nsufficiently weak AR decoders that solely rely on the information provided by\nNAR decoder to make prediction, forcing the NAR decoder to become stronger or\nelse it will be unable to support its weak AR partners. Experiments on WMT and\nIWSLT datasets show that our approach can consistently improve accuracy of\nmultiple NAR baselines without adding any additional decoding overhead.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zaixiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards automating Numerical Consistency Checks in Financial Reports. (arXiv:2211.06112v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06112","description":"<p>We introduce KPI-Check, a novel system that automatically identifies and\ncross-checks semantically equivalent key performance indicators (KPIs), e.g.\n\"revenue\" or \"total costs\", in real-world German financial reports. It combines\na financial named entity and relation extraction module with a BERT-based\nfiltering and text pair classification component to extract KPIs from\nunstructured sentences before linking them to synonymous occurrences in the\nbalance sheet and profit &amp; loss statement. The tool achieves a high matching\nperformance of $73.00$% micro F$_1$ on a hold out test set and is currently\nbeing deployed for a globally operating major auditing firm to assist the\nauditing procedure of financial statements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hillebrand_L/0/1/0/all/0/1\">Lars Hillebrand</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deusser_T/0/1/0/all/0/1\">Tobias Deu&#xdf;er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dilmaghani_T/0/1/0/all/0/1\">Tim Dilmaghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kliem_B/0/1/0/all/0/1\">Bernd Kliem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Loitz_R/0/1/0/all/0/1\">R&#xfc;diger Loitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauckhage_C/0/1/0/all/0/1\">Christian Bauckhage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifa_R/0/1/0/all/0/1\">Rafet Sifa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Much Hate with #china? A Preliminary Analysis on China-related Hateful Tweets Two Years After the Covid Pandemic Began. (arXiv:2211.06116v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06116","description":"<p>Following the outbreak of a global pandemic, online content is filled with\nhate speech. Donald Trump's ''Chinese Virus'' tweet shifted the blame for the\nspread of the Covid-19 virus to China and the Chinese people, which triggered a\nnew round of anti-China hate both online and offline. This research intends to\nexamine China-related hate speech on Twitter during the two years following the\nburst of the pandemic (2020 and 2021). Through Twitter's API, in total\n2,172,333 tweets hashtagged #china posted during the time were collected. By\nemploying multiple state-of-the-art pretrained language models for hate speech\ndetection, we identify a wide range of hate of various types, resulting in an\nautomatically labeled anti-China hate speech dataset. We identify a hateful\nrate in #china tweets of 2.5% in 2020 and 1.9% in 2021. This is well above the\naverage rate of online hate speech on Twitter at 0.6% identified in Gao et al.,\n2017. We further analyzed the longitudinal development of #china tweets and\nthose identified as hateful in 2020 and 2021 through visualizing the daily\nnumber and hate rate over the two years. Our keyword analysis of hate speech in\n#china tweets reveals the most frequently mentioned terms in the hateful #china\ntweets, which can be used for further social science studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinghua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weiss_Z/0/1/0/all/0/1\">Zarah Weiss</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"English Contrastive Learning Can Learn Universal Cross-lingual Sentence Embeddings. (arXiv:2211.06127v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06127","description":"<p>Universal cross-lingual sentence embeddings map semantically similar\ncross-lingual sentences into a shared embedding space. Aligning cross-lingual\nsentence embeddings usually requires supervised cross-lingual parallel\nsentences. In this work, we propose mSimCSE, which extends SimCSE to\nmultilingual settings and reveal that contrastive learning on English data can\nsurprisingly learn high-quality universal cross-lingual sentence embeddings\nwithout any parallel data. In unsupervised and weakly supervised settings,\nmSimCSE significantly improves previous sentence embedding methods on\ncross-lingual retrieval and multilingual STS tasks. The performance of\nunsupervised mSimCSE is comparable to fully supervised methods in retrieving\nlow-resource languages and multilingual STS. The performance can be further\nenhanced when cross-lingual NLI data is available. Our code is publicly\navailable at https://github.com/yaushian/mSimCSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yau-Shian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1\">Ashley Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unimodal and Multimodal Representation Training for Relation Extraction. (arXiv:2211.06168v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06168","description":"<p>Multimodal integration of text, layout and visual information has achieved\nSOTA results in visually rich document understanding (VrDU) tasks, including\nrelation extraction (RE). However, despite its importance, evaluation of the\nrelative predictive capacity of these modalities is less prevalent. Here, we\ndemonstrate the value of shared representations for RE tasks by conducting\nexperiments in which each data type is iteratively excluded during training. In\naddition, text and layout data are evaluated in isolation. While a bimodal text\nand layout approach performs best (F1=0.684), we show that text is the most\nimportant single predictor of entity relations. Additionally, layout geometry\nis highly predictive and may even be a feasible unimodal approach. Despite\nbeing less effective, we highlight circumstances where visual information can\nbolster performance. In total, our results demonstrate the efficacy of training\njoint representations for RE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cooney_C/0/1/0/all/0/1\">Ciaran Cooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heyburn_R/0/1/0/all/0/1\">Rachel Heyburn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddigan_L/0/1/0/all/0/1\">Liam Maddigan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OCuinn_M/0/1/0/all/0/1\">Mairead O&#x27;Cuinn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_C/0/1/0/all/0/1\">Chloe Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cavadas_J/0/1/0/all/0/1\">Joana Cavadas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DocuT5: Seq2seq SQL Generation with Table Documentation. (arXiv:2211.06193v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06193","description":"<p>Current SQL generators based on pre-trained language models struggle to\nanswer complex questions requiring domain context or understanding fine-grained\ntable structure. Humans would deal with these unknowns by reasoning over the\ndocumentation of the tables. Based on this hypothesis, we propose DocuT5, which\nuses off-the-shelf language model architecture and injects knowledge from\nexternal `documentation' to improve domain generalization. We perform\nexperiments on the Spider family of datasets that contain complex questions\nthat are cross-domain and multi-table. Specifically, we develop a new\ntext-to-SQL failure taxonomy and find that 19.6% of errors are due to foreign\nkey mistakes, and 49.2% are due to a lack of domain knowledge. We proposed\nDocuT5, a method that captures knowledge from (1) table structure context of\nforeign keys and (2) domain knowledge through contextualizing tables and\ncolumns. Both types of knowledge improve over state-of-the-art T5 with\nconstrained decoding on Spider, and domain knowledge produces state-of-the-art\ncomparable effectiveness on Spider-DK and Spider-SYN datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soare_E/0/1/0/all/0/1\">Elena Soare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackie_I/0/1/0/all/0/1\">Iain Mackie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalton_J/0/1/0/all/0/1\">Jeffrey Dalton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Factual Consistency in Summarization with Compression-Based Post-Editing. (arXiv:2211.06196v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06196","description":"<p>State-of-the-art summarization models still struggle to be factually\nconsistent with the input text. A model-agnostic way to address this problem is\npost-editing the generated summaries. However, existing approaches typically\nfail to remove entity errors if a suitable input entity replacement is not\navailable or may insert erroneous content. In our work, we focus on removing\nextrinsic entity errors, or entities not in the source, to improve consistency\nwhile retaining the summary's essential information and form. We propose to use\nsentence-compression data to train the post-editing model to take a summary\nwith extrinsic entity errors marked with special tokens and output a\ncompressed, well-formed summary with those errors removed. We show that this\nmodel improves factual consistency while maintaining ROUGE, improving entity\nprecision by up to 30% on XSum, and that this model can be applied on top of\nanother post-editor, improving entity precision by up to a total of 38%. We\nperform an extensive comparison of post-editing approaches that demonstrate\ntrade-offs between factual consistency, informativeness, and grammaticality,\nand we analyze settings where post-editors show the largest improvements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1\">Alexander R. Fabbri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choubey_P/0/1/0/all/0/1\">Prafulla Kumar Choubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vig_J/0/1/0/all/0/1\">Jesse Vig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chien-Sheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving word mover's distance by leveraging self-attention matrix. (arXiv:2211.06229v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06229","description":"<p>Measuring the semantic similarity between two sentences is still an important\ntask. The word mover's distance (WMD) computes the similarity via the optimal\nalignment between the sets of word embeddings. However, WMD does not utilize\nword order, making it difficult to distinguish sentences with large overlaps of\nsimilar words, even if they are semantically very different. Here, we attempt\nto improve WMD by incorporating the sentence structure represented by BERT's\nself-attention matrix (SAM). The proposed method is based on the Fused\nGromov-Wasserstein distance, which simultaneously considers the similarity of\nthe word embedding and the SAM for calculating the optimal transport between\ntwo sentences. Experiments on paraphrase identification and semantic textual\nsimilarity show that the proposed method improves WMD and its variants. Our\ncode is available at https://github.com/ymgw55/WSMD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamagiwa_H/0/1/0/all/0/1\">Hiroaki Yamagiwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yokoi_S/0/1/0/all/0/1\">Sho Yokoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimodaira_H/0/1/0/all/0/1\">Hidetoshi Shimodaira</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A hybrid entity-centric approach to Persian pronoun resolution. (arXiv:2211.06257v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06257","description":"<p>Pronoun resolution is a challenging subset of an essential field in natural\nlanguage processing called coreference resolution. Coreference resolution is\nabout finding all entities in the text that refers to the same real-world\nentity. This paper presents a hybrid model combining multiple rulebased sieves\nwith a machine-learning sieve for pronouns. For this purpose, seven\nhigh-precision rule-based sieves are designed for the Persian language. Then, a\nrandom forest classifier links pronouns to the previous partial clusters. The\npresented method demonstrates exemplary performance using pipeline design and\ncombining the advantages of machine learning and rulebased methods. This method\nhas solved some challenges in end-to-end models. In this paper, the authors\ndevelop a Persian coreference corpus called Mehr in the form of 400 documents.\nThis corpus fixes some weaknesses of the previous corpora in the Persian\nlanguage. Finally, the efficiency of the presented system compared to the\nearlier model in Persian is reported by evaluating the proposed method on the\nMehr and Uppsala test sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_H/0/1/0/all/0/1\">Hassan Haji Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talebpour_A/0/1/0/all/0/1\">Alireza Talebpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aznaveh_A/0/1/0/all/0/1\">Ahmad Mahmoudi Aznaveh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yazdani_S/0/1/0/all/0/1\">Samaneh Yazdani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Developer Discussions to Guide Fixing Bugs in Software. (arXiv:2211.06335v1 [cs.SE])","link":"http://arxiv.org/abs/2211.06335","description":"<p>Automatically fixing software bugs is a challenging task. While recent work\nshowed that natural language context is useful in guiding bug-fixing models,\nthe approach required prompting developers to provide this context, which was\nsimulated through commit messages written after the bug-fixing code changes\nwere made. We instead propose using bug report discussions, which are available\nbefore the task is performed and are also naturally occurring, avoiding the\nneed for any additional information from developers. For this, we augment\nstandard bug-fixing datasets with bug report discussions. Using these newly\ncompiled datasets, we demonstrate that various forms of natural language\ncontext derived from such discussions can aid bug-fixing, even leading to\nimproved performance over using commit messages corresponding to the oracle\nbug-fixing commits.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Panthaplackel_S/0/1/0/all/0/1\">Sheena Panthaplackel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gligoric_M/0/1/0/all/0/1\">Milos Gligoric</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Raymond J. Mooney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analysis of Male and Female Speakers' Word Choices in Public Speeches. (arXiv:2211.06366v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06366","description":"<p>The extent to which men and women use language differently has been\nquestioned previously. Finding clear and consistent gender differences in\nlanguage is not conclusive in general, and the research is heavily influenced\nby the context and method employed to identify the difference. In addition, the\nmajority of the research was conducted in written form, and the sample was\ncollected in writing. Therefore, we compared the word choices of male and\nfemale presenters in public addresses such as TED lectures. The frequency of\nnumerous types of words, such as parts of speech (POS), linguistic,\npsychological, and cognitive terms were analyzed statistically to determine how\nmale and female speakers use words differently. Based on our data, we\ndetermined that male speakers use specific types of linguistic, psychological,\ncognitive, and social words in considerably greater frequency than female\nspeakers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md Zobaer Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samin_A/0/1/0/all/0/1\">Ahnaf Mozib Samin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Fairness Disparities in Peer Review: A Language Model Enhanced Approach. (arXiv:2211.06398v1 [cs.CY])","link":"http://arxiv.org/abs/2211.06398","description":"<p>Double-blind peer review mechanism has become the skeleton of academic\nresearch across multiple disciplines including computer science, yet several\nstudies have questioned the quality of peer reviews and raised concerns on\npotential biases in the process. In this paper, we conduct a thorough and\nrigorous study on fairness disparities in peer review with the help of large\nlanguage models (LMs). We collect, assemble, and maintain a comprehensive\nrelational database for the International Conference on Learning\nRepresentations (ICLR) conference from 2017 to date by aggregating data from\nOpenReview, Google Scholar, arXiv, and CSRanking, and extracting high-level\nfeatures using language models. We postulate and study fairness disparities on\nmultiple protective attributes of interest, including author gender, geography,\nauthor, and institutional prestige. We observe that the level of disparity\ndiffers and textual features are essential in reducing biases in the predictive\nmodeling. We distill several insights from our analysis on study the peer\nreview process with the help of large LMs. Our database also provides avenues\nfor studying new natural language processing (NLP) methods that facilitate the\nunderstanding of the peer review mechanism. We study a concrete example towards\nautomatic machine review systems and provide baseline models for the review\ngeneration and scoring tasks such that the database can be used as a benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiayao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Federated Approach to Predicting Emojis in Hindi Tweets. (arXiv:2211.06401v1 [cs.LG])","link":"http://arxiv.org/abs/2211.06401","description":"<p>The use of emojis affords a visual modality to, often private, textual\ncommunication. The task of predicting emojis however provides a challenge for\nmachine learning as emoji use tends to cluster into the frequently used and the\nrarely used emojis. Much of the machine learning research on emoji use has\nfocused on high resource languages and has conceptualised the task of\npredicting emojis around traditional server-side machine learning approaches.\nHowever, traditional machine learning approaches for private communication can\nintroduce privacy concerns, as these approaches require all data to be\ntransmitted to a central storage. In this paper, we seek to address the dual\nconcerns of emphasising high resource languages for emoji prediction and\nrisking the privacy of people's data. We introduce a new dataset of $118$k\ntweets (augmented from $25$k unique tweets) for emoji prediction in Hindi, and\npropose a modification to the federated learning algorithm, CausalFedGSD, which\naims to strike a balance between model performance and user privacy. We show\nthat our approach obtains comparative scores with more complex centralised\nmodels while reducing the amount of data required to optimise the models and\nminimising risks to user privacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_D/0/1/0/all/0/1\">Deep Gandhi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehta_J/0/1/0/all/0/1\">Jash Mehta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parekh_N/0/1/0/all/0/1\">Nirali Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waghela_K/0/1/0/all/0/1\">Karan Waghela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DMello_L/0/1/0/all/0/1\">Lynette D&#x27;Mello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talat_Z/0/1/0/all/0/1\">Zeerak Talat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Architectural Bottleneck Principle. (arXiv:2211.06420v1 [cs.CL])","link":"http://arxiv.org/abs/2211.06420","description":"<p>In this paper, we seek to measure how much information a component in a\nneural network could extract from the representations fed into it. Our work\nstands in contrast to prior probing work, most of which investigates how much\ninformation a model's representations contain. This shift in perspective leads\nus to propose a new principle for probing, the architectural bottleneck\nprinciple: In order to estimate how much information a given component could\nextract, a probe should look exactly like the component. Relying on this\nprinciple, we estimate how much syntactic information is available to\ntransformers through our attentional probe, a probe that exactly resembles a\ntransformer's self-attention head. Experimentally, we find that, in three\nmodels (BERT, ALBERT, and RoBERTa), a sentence's syntax tree is mostly\nextractable by our probe, suggesting these models have access to syntactic\ninformation while composing their contextual representations. Whether this\ninformation is actually used by these models, however, remains an open\nquestion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valvoda_J/0/1/0/all/0/1\">Josef Valvoda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoehr_N/0/1/0/all/0/1\">Niklas Stoehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Word-Level Semantic Representation via Dependency Structure for Expressive Text-to-Speech Synthesis. (arXiv:2104.06835v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06835","description":"<p>Exploiting rich linguistic information in raw text is crucial for expressive\ntext-to-speech (TTS). As large scale pre-trained text representation develops,\nbidirectional encoder representations from Transformers (BERT) has been proven\nto embody semantic information and employed to TTS recently. However, original\nor simply fine-tuned BERT embeddings still cannot provide sufficient semantic\nknowledge that expressive TTS models should take into account. In this paper,\nwe propose a word-level semantic representation enhancing method based on\ndependency structure and pre-trained BERT embedding. The BERT embedding of each\nword is reprocessed considering its specific dependencies and related words in\nthe sentence, to generate more effective semantic representation for TTS. To\nbetter utilize the dependency structure, relational gated graph network (RGGN)\nis introduced to make semantic information flow and aggregate through the\ndependency structure. The experimental results show that the proposed method\ncan further improve the naturalness and expressiveness of synthesized speeches\non both Mandarin and English datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yixuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Changhe Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingbei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1\">Yanyao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Helen Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialoging Resonance: How Users Perceive, Reciprocate and React to Chatbot's Self-Disclosure in Conversational Recommendations. (arXiv:2106.01666v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.01666","description":"<p>Using chatbots to deliver recommendations is increasingly popular. The design\nof recommendation chatbots has primarily been taking an information-centric\napproach by focusing on the recommended content per se. Limited attention is on\nhow social connection and relational strategies, such as self-disclosure from a\nchatbot, may influence users' perception and acceptance of the recommendation.\nIn this work, we designed, implemented, and evaluated a social chatbot capable\nof performing three different levels of self-disclosure: factual information\n(low), cognitive opinions (medium), and emotions (high). In the evaluation, we\nrecruited 372 participants to converse with the chatbot on two topics: movies\nand COVID-19 experiences. In each topic, the chatbot performed small talks and\nmade recommendations relevant to the topic. Participants were randomly assigned\nto four experimental conditions where the chatbot used factual, cognitive,\nemotional, and adaptive strategies to perform self-disclosures. By training a\ntext classifier to identify users' level of self-disclosure in real-time, the\nadaptive chatbot can dynamically match its self-disclosure to the level of\ndisclosure exhibited by the users. Our results show that users reciprocate with\nhigher-level self-disclosure when a recommendation chatbot consistently\ndisplays emotions throughout the conversation. Chatbot's emotional disclosure\nalso led to increased interactional enjoyment and more positive interpersonal\nperception towards the bot, fostering a stronger human-chatbot relationship and\nthus leading to increased recommendation effectiveness, including a higher\ntendency to accept the recommendation. We discuss the understandings obtained\nand implications to future design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1\">Kai-Hui Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1\">Yoojung Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao-Chuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Regression Transformer: Concurrent sequence regression and generation for molecular language modeling. (arXiv:2202.01338v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2202.01338","description":"<p>Despite significant progress of generative models in the natural sciences,\ntheir controllability remains challenging. One fundamentally missing aspect of\nmolecular or protein generative models is an inductive bias that can reflect\ncontinuous properties of interest. To that end, we propose the Regression\nTransformer (RT), a novel method that abstracts regression as a conditional\nsequence modeling problem. This introduces a new paradigm of multitask language\nmodels which seamlessly bridge sequence regression and conditional sequence\ngeneration.\n</p>\n<p>We thoroughly demonstrate that, despite using a nominal-scale training\nobjective, the RT matches or surpasses the performance of conventional\nregression models in property prediction tasks of small molecules, proteins and\nchemical reactions. Critically, priming the same model with continuous\nproperties yields a highly competitive conditional generative model that\noutperforms specialized approaches in a substructure-constrained,\nproperty-driven molecule generation benchmark. Our dichotomous approach is\nfacilitated by a novel, alternating training scheme that enables the model to\ndecorate seed sequences by desired properties, e.g., to optimize reaction\nyield.\n</p>\n<p>In sum, the RT is the first report of a multitask model that concurrently\nexcels at predictive and generative tasks in biochemistry. This finds\nparticular application in property-driven, local exploration of the chemical or\nprotein space and could pave the road toward foundation models in material\ndesign.\n</p>\n<p>The code to reproduce all experiments of the paper is available at:\nhttps://github.com/IBM/regression-transformer\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Born_J/0/1/0/all/0/1\">Jannis Born</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manica_M/0/1/0/all/0/1\">Matteo Manica</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CAVES: A Dataset to facilitate Explainable Classification and Summarization of Concerns towards COVID Vaccines. (arXiv:2204.13746v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.13746","description":"<p>Convincing people to get vaccinated against COVID-19 is a key societal\nchallenge in the present times. As a first step towards this goal, many prior\nworks have relied on social media analysis to understand the specific concerns\nthat people have towards these vaccines, such as potential side-effects,\nineffectiveness, political factors, and so on. Though there are datasets that\nbroadly classify social media posts into Anti-vax and Pro-Vax labels, there is\nno dataset (to our knowledge) that labels social media posts according to the\nspecific anti-vaccine concerns mentioned in the posts. In this paper, we have\ncurated CAVES, the first large-scale dataset containing about 10k COVID-19\nanti-vaccine tweets labelled into various specific anti-vaccine concerns in a\nmulti-label setting. This is also the first multi-label classification dataset\nthat provides explanations for each of the labels. Additionally, the dataset\nalso provides class-wise summaries of all the tweets. We also perform\npreliminary experiments on the dataset and show that this is a very challenging\ndataset for multi-label explainable classification and tweet summarization, as\nis evident by the moderate scores achieved by some state-of-the-art models. Our\ndataset and codes are available at: https://github.com/sohampoddar26/caves-data\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Poddar_S/0/1/0/all/0/1\">Soham Poddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samad_A/0/1/0/all/0/1\">Azlaan Mustafa Samad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1\">Rajdeep Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Saptarshi Ghosh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Generalist Agent. (arXiv:2205.06175v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2205.06175","description":"<p>Inspired by progress in large-scale language modeling, we apply a similar\napproach towards building a single generalist agent beyond the realm of text\noutputs. The agent, which we refer to as Gato, works as a multi-modal,\nmulti-task, multi-embodiment generalist policy. The same network with the same\nweights can play Atari, caption images, chat, stack blocks with a real robot\narm and much more, deciding based on its context whether to output text, joint\ntorques, button presses, or other tokens. In this report we describe the model\nand the data, and document the current capabilities of Gato.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reed_S/0/1/0/all/0/1\">Scott Reed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zolna_K/0/1/0/all/0/1\">Konrad Zolna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parisotto_E/0/1/0/all/0/1\">Emilio Parisotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colmenarejo_S/0/1/0/all/0/1\">Sergio Gomez Colmenarejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Novikov_A/0/1/0/all/0/1\">Alexander Novikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barth_Maron_G/0/1/0/all/0/1\">Gabriel Barth-Maron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimenez_M/0/1/0/all/0/1\">Mai Gimenez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sulsky_Y/0/1/0/all/0/1\">Yury Sulsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kay_J/0/1/0/all/0/1\">Jackie Kay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1\">Jost Tobias Springenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eccles_T/0/1/0/all/0/1\">Tom Eccles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruce_J/0/1/0/all/0/1\">Jake Bruce</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Razavi_A/0/1/0/all/0/1\">Ali Razavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1\">Ashley Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1\">Nicolas Heess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yutian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1\">Raia Hadsell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1\">Oriol Vinyals</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordbar_M/0/1/0/all/0/1\">Mahyar Bordbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1\">Nando de Freitas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Classifiers are Better Experts for Controllable Text Generation. (arXiv:2205.07276v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.07276","description":"<p>This paper proposes a simple method for controllable text generation based on\nweighting logits with a free-form classifier, namely CAIF sampling. Using an\narbitrary text classifier, we adjust a small part of a language model's logits\nand guide text generation towards or away from classifier prediction. We\nexperimented with toxicity avoidance and sentiment control tasks and showed\nthat the proposed method significantly outperforms recent PPLM, GeDi, and\nDExperts on PPL and task accuracy metrics based on the external classifier of\ngenerated texts. In addition, compared to other approaches, it is easier to\nimplement and tune and has significantly fewer restrictions and requirements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sitdikov_A/0/1/0/all/0/1\">Askhat Sitdikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balagansky_N/0/1/0/all/0/1\">Nikita Balagansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavrilov_D/0/1/0/all/0/1\">Daniil Gavrilov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markov_A/0/1/0/all/0/1\">Alexander Markov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Perceiver-Actor: A Multi-Task Transformer for Robotic Manipulation. (arXiv:2209.05451v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2209.05451","description":"<p>Transformers have revolutionized vision and natural language processing with\ntheir ability to scale with large datasets. But in robotic manipulation, data\nis both limited and expensive. Can manipulation still benefit from Transformers\nwith the right problem formulation? We investigate this question with PerAct, a\nlanguage-conditioned behavior-cloning agent for multi-task 6-DoF manipulation.\nPerAct encodes language goals and RGB-D voxel observations with a Perceiver\nTransformer, and outputs discretized actions by ``detecting the next best voxel\naction''. Unlike frameworks that operate on 2D images, the voxelized 3D\nobservation and action space provides a strong structural prior for efficiently\nlearning 6-DoF actions. With this formulation, we train a single multi-task\nTransformer for 18 RLBench tasks (with 249 variations) and 7 real-world tasks\n(with 18 variations) from just a few demonstrations per task. Our results show\nthat PerAct significantly outperforms unstructured image-to-action agents and\n3D ConvNet baselines for a wide range of tabletop tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shridhar_M/0/1/0/all/0/1\">Mohit Shridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manuelli_L/0/1/0/all/0/1\">Lucas Manuelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1\">Dieter Fox</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing Multi-Task Learning for Abstractive Text Summarization. (arXiv:2210.14606v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.14606","description":"<p>Despite the recent success of multi-task learning and pre-finetuning for\nnatural language understanding, few works have studied the effects of task\nfamilies on abstractive text summarization. Task families are a form of task\ngrouping during the pre-finetuning stage to learn common skills, such as\nreading comprehension. To close this gap, we analyze the influence of\nmulti-task learning strategies using task families for the English abstractive\ntext summarization task. We group tasks into one of three strategies, i.e.,\nsequential, simultaneous, and continual multi-task learning, and evaluate\ntrained models through two downstream tasks. We find that certain combinations\nof task families (e.g., advanced reading comprehension and natural language\ninference) positively impact downstream performance. Further, we find that\nchoice and combinations of task families influence downstream performance more\nthan the training scheme, supporting the use of task families for abstractive\ntext summarization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirstein_F/0/1/0/all/0/1\">Frederic Kirstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wahle_J/0/1/0/all/0/1\">Jan Philip Wahle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruas_T/0/1/0/all/0/1\">Terry Ruas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Text Classification Data and Models Using Aggregated Input Salience. (arXiv:2211.05485v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05485","description":"<p>Realizing when a model is right for a wrong reason is not trivial and\nrequires a significant effort by model developers. In some cases, an input\nsalience method, which highlights the most important parts of the input, may\nreveal problematic reasoning. But scrutinizing highlights over many data\ninstances is tedious and often infeasible. Furthermore, analyzing examples in\nisolation does not reveal general patterns in the data or in the model's\nbehavior. In this paper we aim to address these issues and go from\nunderstanding single examples to understanding entire datasets and models. The\nmethodology we propose is based on aggregated salience maps. Using this\nmethodology we address multiple distinct but common model developer needs by\nshowing how problematic data and model behavior can be identified -- a\nnecessary first step for improving the model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ebert_S/0/1/0/all/0/1\">Sebastian Ebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jakobovits_A/0/1/0/all/0/1\">Alice Shoshana Jakobovits</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filippova_K/0/1/0/all/0/1\">Katja Filippova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MoNET: Tackle State Momentum via Noise-Enhanced Training for Dialogue State Tracking. (arXiv:2211.05503v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05503","description":"<p>Dialogue state tracking (DST) aims to convert the dialogue history into\ndialogue states which consist of slot-value pairs. As condensed structural\ninformation memorizing all history information, the dialogue state in the last\nturn is typically adopted as the input for predicting the current state by DST\nmodels. However, these models tend to keep the predicted slot values unchanged,\nwhich is defined as state momentum in this paper. Specifically, the models\nstruggle to update slot values that need to be changed and correct wrongly\npredicted slot values in the last turn. To this end, we propose MoNET to tackle\nstate momentum via noise-enhanced training. First, the previous state of each\nturn in the training data is noised via replacing some of its slot values.\nThen, the noised previous state is used as the input to learn to predict the\ncurrent state, improving the model's ability to update and correct slot values.\nFurthermore, a contrastive context matching framework is designed to narrow the\nrepresentation distance between a state and its corresponding noised variant,\nwhich reduces the impact of noised state and makes the model better understand\nthe dialogue history. Experimental results on MultiWOZ datasets show that MoNET\noutperforms previous DST methods. Ablations and analysis verify the\neffectiveness of MoNET in alleviating state momentum and improving anti-noise\nability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Haoning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1\">Junwei Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Haipeng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Youzheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shuguang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaodong He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2022-11-13T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}