{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-07-04T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Investigating Masking-based Data Generation in Language Models. (arXiv:2307.00008v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00008","description":"<p>The current era of natural language processing (NLP) has been defined by the\nprominence of pre-trained language models since the advent of BERT. A feature\nof BERT and models with similar architecture is the objective of masked\nlanguage modeling, in which part of the input is intentionally masked and the\nmodel is trained to predict this piece of masked information. Data augmentation\nis a data-driven technique widely used in machine learning, including research\nareas like computer vision and natural language processing, to improve model\nperformance by artificially augmenting the training data set by designated\ntechniques. Masked language models (MLM), an essential training feature of\nBERT, have introduced a novel approach to perform effective pre-training on\nTransformer based models in natural language processing tasks. Recent studies\nhave utilized masked language model to generate artificially augmented data for\nNLP downstream tasks. The experimental results show that Mask based data\naugmentation method provides a simple but efficient approach to improve the\nmodel performance. In this paper, we explore and discuss the broader\nutilization of these data augmentation methods based on MLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_E/0/1/0/all/0/1\">Ed S. Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Assignment and Classification of Software Issues. (arXiv:2307.00009v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00009","description":"<p>Software issues contain units of work to fix, improve or create new threads\nduring the development and facilitate communication among the team members.\nAssigning an issue to the most relevant team member and determining a category\nof an issue is a tedious and challenging task. Wrong classifications cause\ndelays and rework in the project and trouble among the team members. This\nthesis proposes a set of carefully curated linguistic features for shallow\nmachine learning methods and compares the performance of shallow and ensemble\nmethods with deep language models. Unlike the state-of-the-art, we assign\nissues to four roles (designer, developer, tester, and leader) rather than to\nspecific individuals or teams to contribute to the generality of our solution.\nWe also consider the level of experience of the developers to reflect the\nindustrial practices in our solution formulation. We employ a classification\napproach to categorize issues into distinct classes, namely bug, new feature,\nimprovement, and other. Additionally, we endeavor to further classify bugs\nbased on the specific type of modification required. We collect and annotate\nfive industrial data sets from one of the top three global television producers\nto evaluate our proposal and compare it with deep language models. Our data\nsets contain 5324 issues in total. We show that an ensemble classifier of\nshallow techniques achieves 0.92 for issue assignment and 0.90 for issue\nclassification in accuracy which is statistically comparable to the\nstate-of-the-art deep language models. The contributions include the public\nsharing of five annotated industrial issue data sets, the development of a\nclear and comprehensive feature set, the introduction of a novel label set and\nthe validation of the efficacy of an ensemble classifier of shallow machine\nlearning techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tabak_B/0/1/0/all/0/1\">B&#xfc;&#x15f;ra Tabak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SAHAAYAK 2023 -- the Multi Domain Bilingual Parallel Corpus of Sanskrit to Hindi for Machine Translation. (arXiv:2307.00021v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00021","description":"<p>The data article presents the large bilingual parallel corpus of\nlow-resourced language pair Sanskrit-Hindi, named SAHAAYAK 2023. The corpus\ncontains total of 1.5M sentence pairs between Sanskrit and Hindi. To make the\nuniversal usability of the corpus and to make it balanced, data from multiple\ndomain has been incorporated into the corpus that includes, News, Daily\nconversations, Politics, History, Sport, and Ancient Indian Literature. The\nmultifaceted approach has been adapted to make a sizable multi-domain corpus of\nlow-resourced languages like Sanskrit. Our development approach is spanned from\ncreating a small hand-crafted dataset to applying a wide range of mining,\ncleaning, and verification. We have used the three-fold process of mining:\nmining from machine-readable sources, mining from non-machine readable sources,\nand collation from existing corpora sources. Post mining, the dedicated\npipeline for normalization, alignment, and corpus cleaning is developed and\napplied to the corpus to make it ready to use on machine translation\nalgorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bakrola_V/0/1/0/all/0/1\">Vishvajitsinh Bakrola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nasariwala_J/0/1/0/all/0/1\">Jitendra Nasariwala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Seeing in Words: Learning to Classify through Language Bottlenecks. (arXiv:2307.00028v1 [cs.CV])","link":"http://arxiv.org/abs/2307.00028","description":"<p>Neural networks for computer vision extract uninterpretable features despite\nachieving high accuracy on benchmarks. In contrast, humans can explain their\npredictions using succinct and intuitive descriptions. To incorporate\nexplainability into neural networks, we train a vision model whose feature\nrepresentations are text. We show that such a model can effectively classify\nImageNet images, and we discuss the challenges we encountered when training it.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1\">Khalid Saifullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1\">Jonas Geiping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models. (arXiv:2307.00101v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00101","description":"<p>Large Language Models (LLMs) are trained primarily on minimally processed web\ntext, which exhibits the same wide range of social biases held by the humans\nwho created that content. Consequently, text generated by LLMs can\ninadvertently perpetuate stereotypes towards marginalized groups, like the\nLGBTQIA+ community. In this paper, we perform a comparative study of how LLMs\ngenerate text describing people with different sexual identities. Analyzing\nbias in the text generated by an LLM using regard score shows measurable bias\nagainst queer people. We then show that a post-hoc method based on\nchain-of-thought prompting using SHAP analysis can increase the regard of the\nsentence, representing a promising approach towards debiasing the output of\nLLMs in this setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dhingra_H/0/1/0/all/0/1\">Harnoor Dhingra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayashanker_P/0/1/0/all/0/1\">Preetiha Jayashanker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moghe_S/0/1/0/all/0/1\">Sayali Moghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ticket-BERT: Labeling Incident Management Tickets with Language Models. (arXiv:2307.00108v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00108","description":"<p>An essential aspect of prioritizing incident tickets for resolution is\nefficiently labeling tickets with fine-grained categories. However, ticket data\nis often complex and poses several unique challenges for modern machine\nlearning methods: (1) tickets are created and updated either by machines with\npre-defined algorithms or by engineers with domain expertise that share\ndifferent protocols, (2) tickets receive frequent revisions that update ticket\nstatus by modifying all or parts of ticket descriptions, and (3) ticket\nlabeling is time-sensitive and requires knowledge updates and new labels per\nthe rapid software and hardware improvement lifecycle. To handle these issues,\nwe introduce Ticket- BERT which trains a simple yet robust language model for\nlabeling tickets using our proposed ticket datasets. Experiments demonstrate\nthe superiority of Ticket-BERT over baselines and state-of-the-art text\nclassifiers on Azure Cognitive Services. We further encapsulate Ticket-BERT\nwith an active learning cycle and deploy it on the Microsoft IcM system, which\nenables the model to quickly finetune on newly-collected tickets with a few\nannotations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhexiong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Benge_C/0/1/0/all/0/1\">Cris Benge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Siduo Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta-training with Demonstration Retrieval for Efficient Few-shot Learning. (arXiv:2307.00119v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00119","description":"<p>Large language models show impressive results on few-shot NLP tasks. However,\nthese models are memory and computation-intensive. Meta-training allows one to\nleverage smaller models for few-shot generalization in a domain-general and\ntask-agnostic manner; however, these methods alone results in models that may\nnot have sufficient parameterization or knowledge to adapt quickly to a large\nvariety of tasks. To overcome this issue, we propose meta-training with\ndemonstration retrieval, where we use a dense passage retriever to retrieve\nsemantically similar labeled demonstrations to each example for more varied\nsupervision. By separating external knowledge from model parameters, we can use\nmeta-training to train parameter-efficient models that generalize well on a\nlarger variety of tasks. We construct a meta-training set from UnifiedQA and\nCrossFit, and propose a demonstration bank based on UnifiedQA tasks. To our\nknowledge, our work is the first to combine retrieval with meta-training, to\nuse DPR models to retrieve demonstrations, and to leverage demonstrations from\nmany tasks simultaneously, rather than randomly sampling demonstrations from\nthe training set of the target task. Our approach outperforms a variety of\ntargeted parameter-efficient and retrieval-augmented few-shot methods on QA,\nNLI, and text classification tasks (including SQuAD, QNLI, and TREC). Our\napproach can be meta-trained and fine-tuned quickly on a single GPU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mueller_A/0/1/0/all/0/1\">Aaron Mueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_K/0/1/0/all/0/1\">Kanika Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathias_L/0/1/0/all/0/1\">Lambert Mathias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1\">Hamed Firooz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Information Extraction in Domain and Generic Documents: Findings from Heuristic-based and Data-driven Approaches. (arXiv:2307.00130v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00130","description":"<p>Information extraction (IE) plays very important role in natural language\nprocessing (NLP) and is fundamental to many NLP applications that used to\nextract structured information from unstructured text data. Heuristic-based\nsearching and data-driven learning are two main stream implementation\napproaches. However, no much attention has been paid to document genre and\nlength influence on IE tasks. To fill the gap, in this study, we investigated\nthe accuracy and generalization abilities of heuristic-based searching and\ndata-driven to perform two IE tasks: named entity recognition (NER) and\nsemantic role labeling (SRL) on domain-specific and generic documents with\ndifferent length. We posited two hypotheses: first, short documents may yield\nbetter accuracy results compared to long documents; second, generic documents\nmay exhibit superior extraction outcomes relative to domain-dependent documents\ndue to training document genre limitations. Our findings reveals that no single\nmethod demonstrated overwhelming performance in both tasks. For named entity\nextraction, data-driven approaches outperformed symbolic methods in terms of\naccuracy, particularly in short texts. In the case of semantic roles\nextraction, we observed that heuristic-based searching method and data-driven\nbased model with syntax representation surpassed the performance of pure\ndata-driven approach which only consider semantic information. Additionally, we\ndiscovered that different semantic roles exhibited varying accuracy levels with\nthe same method. This study offers valuable insights for downstream text mining\ntasks, such as NER and SRL, when addressing various document features and\ngenres.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Shiyu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipizzi_C/0/1/0/all/0/1\">Carlo Lipizzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"iMETRE: Incorporating Markers of Entity Types for Relation Extraction. (arXiv:2307.00132v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00132","description":"<p>Sentence-level relation extraction (RE) aims to identify the relationship\nbetween 2 entities given a contextual sentence. While there have been many\nattempts to solve this problem, the current solutions have a lot of room to\nimprove. In this paper, we approach the task of relationship extraction in the\nfinancial dataset REFinD. Our approach incorporates typed entity markers\nrepresentations and various models finetuned on the dataset, which has allowed\nus to achieve an F1 score of 69.65% on the validation set. Through this paper,\nwe discuss various approaches and possible limitations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vardhan_N/0/1/0/all/0/1\">N Harsha Vardhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_M/0/1/0/all/0/1\">Manav Chaudhary</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SMILE: Evaluation and Domain Adaptation for Social Media Language Understanding. (arXiv:2307.00135v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00135","description":"<p>We study the ability of transformer-based language models (LMs) to understand\nsocial media language. Social media (SM) language is distinct from standard\nwritten language, yet existing benchmarks fall short of capturing LM\nperformance in this socially, economically, and politically important domain.\nWe quantify the degree to which social media language differs from conventional\nlanguage and conclude that the difference is significant both in terms of token\ndistribution and rate of linguistic shift. Next, we introduce a new benchmark\nfor Social MedIa Language Evaluation (SMILE) that covers four SM platforms and\neleven tasks. Finally, we show that learning a tokenizer and pretraining on a\nmix of social media and conventional language yields an LM that outperforms the\nbest similar-sized alternative by 4.2 points on the overall SMILE score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bashlovkina_V/0/1/0/all/0/1\">Vasilisa Bashlovkina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthews_R/0/1/0/all/0/1\">Riley Matthews</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Z/0/1/0/all/0/1\">Zhaobin Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baumgartner_S/0/1/0/all/0/1\">Simon Baumgartner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What do self-supervised speech models know about words?. (arXiv:2307.00162v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00162","description":"<p>Many self-supervised speech models (S3Ms) have been introduced over the last\nfew years, producing performance and data efficiency improvements for a variety\nof speech tasks. Evidence is emerging that different S3Ms encode linguistic\ninformation in different layers, and also that some S3Ms appear to learn\nphone-like sub-word units. However, the extent to which these models capture\nlarger linguistic units, such as words, and where word-related information is\nencoded, remains unclear. In this study, we conduct several analyses of word\nsegment representations extracted from different layers of three S3Ms:\nwav2vec2, HuBERT, and WavLM. We employ canonical correlation analysis (CCA), a\nlightweight analysis tool, to measure the similarity between these\nrepresentations and word-level linguistic properties. We find that the maximal\nword-level linguistic content tends to be found in intermediate model layers,\nwhile some lower-level information like pronunciation is also retained in\nhigher layers of HuBERT and WavLM. Syntactic and semantic word attributes have\nsimilar layer-wise behavior. We also find that, for all of the models tested,\nword identity information is concentrated near the center of each word segment.\nWe then test the layer-wise performance of the same models, when used directly\nwith no additional learned parameters, on several tasks: acoustic word\ndiscrimination, word segmentation, and semantic sentence similarity. We find\nsimilar layer-wise trends in performance, and furthermore, find that when using\nthe best-performing layer of HuBERT or WavLM, it is possible to achieve\nperformance on word segmentation and sentence similarity that rivals more\ncomplex existing approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pasad_A/0/1/0/all/0/1\">Ankita Pasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chien_C/0/1/0/all/0/1\">Chung-Ming Chien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Settle_S/0/1/0/all/0/1\">Shane Settle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Integer Linear Programming Inference Cookbook. (arXiv:2307.00171v1 [cs.AI])","link":"http://arxiv.org/abs/2307.00171","description":"<p>Over the years, integer linear programs have been employed to model inference\nin many natural language processing problems. This survey is meant to guide the\nreader through the process of framing a new inference problem as an instance of\nan integer linear program and is structured as a collection of recipes. At the\nend, we will see two worked examples to illustrate the use of these recipes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Still No Lie Detector for Language Models: Probing Empirical and Conceptual Roadblocks. (arXiv:2307.00175v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00175","description":"<p>We consider the questions of whether or not large language models (LLMs) have\nbeliefs, and, if they do, how we might measure them. First, we evaluate two\nexisting approaches, one due to Azaria and Mitchell (2023) and the other to\nBurns et al. (2022). We provide empirical results that show that these methods\nfail to generalize in very basic ways. We then argue that, even if LLMs have\nbeliefs, these methods are unlikely to be successful for conceptual reasons.\nThus, there is still no lie-detector for LLMs. After describing our empirical\nresults we take a step back and consider whether or not we should expect LLMs\nto have something like beliefs in the first place. We consider some recent\narguments aiming to show that LLMs cannot have beliefs. We show that these\narguments are misguided. We provide a more productive framing of questions\nsurrounding the status of beliefs in LLMs, and highlight the empirical nature\nof the problem. We conclude by suggesting some concrete paths for future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Levinstein_B/0/1/0/all/0/1\">B.A. Levinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrmann_D/0/1/0/all/0/1\">Daniel A. Herrmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personality Traits in Large Language Models. (arXiv:2307.00184v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00184","description":"<p>The advent of large language models (LLMs) has revolutionized natural\nlanguage processing, enabling the generation of coherent and contextually\nrelevant text. As LLMs increasingly power conversational agents, the\nsynthesized personality embedded in these models by virtue of their training on\nlarge amounts of human-generated data draws attention. Since personality is an\nimportant factor determining the effectiveness of communication, we present a\ncomprehensive method for administering validated psychometric tests and\nquantifying, analyzing, and shaping personality traits exhibited in text\ngenerated from widely-used LLMs. We find that: 1) personality simulated in the\noutputs of some LLMs (under specific prompting configurations) is reliable and\nvalid; 2) evidence of reliability and validity of LLM-simulated personality is\nstronger for larger and instruction fine-tuned models; and 3) personality in\nLLM outputs can be shaped along desired dimensions to mimic specific\npersonality profiles. We also discuss potential applications and ethical\nimplications of our measurement and shaping framework, especially regarding\nresponsible use of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Safdari_M/0/1/0/all/0/1\">Mustafa Safdari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Serapio_Garcia_G/0/1/0/all/0/1\">Greg Serapio-Garc&#xed;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crepy_C/0/1/0/all/0/1\">Cl&#xe9;ment Crepy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fitz_S/0/1/0/all/0/1\">Stephen Fitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_P/0/1/0/all/0/1\">Peter Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Luning Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1\">Marwa Abdulhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1\">Aleksandra Faust</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mataric_M/0/1/0/all/0/1\">Maja Matari&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How far is Language Model from 100% Few-shot Named Entity Recognition in Medical Domain. (arXiv:2307.00186v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00186","description":"<p>Recent advancements in language models (LMs) have led to the emergence of\npowerful models such as Small LMs (e.g., T5) and Large LMs (e.g., GPT-4). These\nmodels have demonstrated exceptional capabilities across a wide range of tasks,\nsuch as name entity recognition (NER) in the general domain. (We define SLMs as\npre-trained models with fewer parameters compared to models like GPT-3/3.5/4,\nsuch as T5, BERT, and others.) Nevertheless, their efficacy in the medical\nsection remains uncertain and the performance of medical NER always needs high\naccuracy because of the particularity of the field. This paper aims to provide\na thorough investigation to compare the performance of LMs in medical few-shot\nNER and answer How far is LMs from 100\\% Few-shot NER in Medical Domain, and\nmoreover to explore an effective entity recognizer to help improve the NER\nperformance. Based on our extensive experiments conducted on 16 NER models\nspanning from 2018 to 2023, our findings clearly indicate that LLMs outperform\nSLMs in few-shot medical NER tasks, given the presence of suitable examples and\nappropriate logical frameworks. Despite the overall superiority of LLMs in\nfew-shot medical NER tasks, it is important to note that they still encounter\nsome challenges, such as misidentification, wrong template prediction, etc.\nBuilding on previous findings, we introduce a simple and effective method\ncalled \\textsc{RT} (Retrieving and Thinking), which serves as retrievers,\nfinding relevant examples, and as thinkers, employing a step-by-step reasoning\nprocess. Experimental results show that our proposed \\textsc{RT} framework\nsignificantly outperforms the strong open baselines on the two open medical\nbenchmark datasets\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])","link":"http://arxiv.org/abs/2307.00209","description":"<p>Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection\nof hyperbole is an important part of understanding human expression. There have\nbeen several studies on hyperbole detection, but most of which focus on text\nmodality only. However, with the development of social media, people can create\nhyperbolic expressions with various modalities, including text, images, videos,\netc. In this paper, we focus on multimodal hyperbole detection. We create a\nmultimodal detection dataset\\footnote{The dataset will be released to the\ncommunity.} from Weibo (a Chinese social media) and carry out some studies on\nit. We treat the text and image from a piece of weibo as two modalities and\nexplore the role of text and image for hyperbole detection. Different\npre-trained multimodal encoders are also evaluated on this downstream task to\nshow their performance. Besides, since this dataset is constructed from five\ndifferent topics, we also evaluate the cross-domain performance of different\nmodels. These studies can serve as a benchmark and point out the direction of\nfurther study on multimodal hyperbole detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InstructEval: Systematic Evaluation of Instruction Selection Methods. (arXiv:2307.00259v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00259","description":"<p>In-context learning (ICL) performs tasks by prompting a large language model\n(LLM) using an instruction and a small set of annotated examples called\ndemonstrations. Recent work has shown that the precise details of the inputs\nused in the prompt significantly impacts ICL, which has incentivized\ninstruction selection algorithms. The effect of instruction-choice however is\nseverely underexplored, with existing analyses being restricted to shallow\nsubsets of models and tasks, which limits the generalizability of their\ninsights. We develop an ICL evaluation suite to conduct a thorough assessment\nof these techniques. The suite includes 13 open-sourced LLMs of varying scales\nfrom 4 distinct model families and covers 9 different tasks, representing a\nrange of task types across 3 categories. In this work, we evaluate the relative\nperformance of 7 popular instruction selection methods using our benchmark over\nfive desiderata relevant to ICL. We discover that using curated\nmanually-written instructions and simple instructions without any task-specific\ndescriptions often elicits superior ICL performance than that of automatic\ninstruction-induction methods, pointing to a lack of generalizability among the\nlatter. We release our evaluation suite for benchmarking instruction selection\napproaches, and call for more rigorous and generalizable methods in this space.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1\">Anirudh Ajith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1\">Chris Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_M/0/1/0/all/0/1\">Mengzhou Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ameet Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Pretraining for Biomedical Term Embeddings. (arXiv:2307.00266v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00266","description":"<p>Electronic health records (EHR) contain narrative notes that provide\nextensive details on the medical condition and management of patients. Natural\nlanguage processing (NLP) of clinical notes can use observed frequencies of\nclinical terms as predictive features for downstream applications such as\nclinical decision making and patient trajectory prediction. However, due to the\nvast number of highly similar and related clinical concepts, a more effective\nmodeling strategy is to represent clinical terms as semantic embeddings via\nrepresentation learning and use the low dimensional embeddings as feature\nvectors for predictive modeling. To achieve efficient representation,\nfine-tuning pretrained language models with biomedical knowledge graphs may\ngenerate better embeddings for biomedical terms than those from standard\nlanguage models alone. These embeddings can effectively discriminate synonymous\npairs of from those that are unrelated. However, they often fail to capture\ndifferent degrees of similarity or relatedness for concepts that are\nhierarchical in nature. To overcome this limitation, we propose HiPrBERT, a\nnovel biomedical term representation model trained on additionally complied\ndata that contains hierarchical structures for various biomedical terms. We\nmodify an existing contrastive loss function to extract information from these\nhierarchies. Our numerical experiments demonstrate that HiPrBERT effectively\nlearns the pair-wise distance from hierarchical information, resulting in a\nsubstantially more informative embeddings for further biomedical applications\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_B/0/1/0/all/0/1\">Bryan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Sihang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yucong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Doudou Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_L/0/1/0/all/0/1\">Lu Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let Me Teach You: Pedagogical Foundations of Feedback for Language Models. (arXiv:2307.00279v1 [cs.CL])","link":"http://arxiv.org/abs/2307.00279","description":"<p>Natural Language Feedback (NLF) is an increasingly popular avenue to align\nLarge Language Models (LLMs) to human preferences. Despite the richness and\ndiversity of the information it can convey, NLF is often hand-designed and\narbitrary. In a different world, research in pedagogy has long established\nseveral effective feedback models. In this opinion piece, we compile ideas from\npedagogy to introduce FELT, a feedback framework for LLMs that outlines the\nvarious characteristics of the feedback space, and a feedback content taxonomy\nbased on these variables. Our taxonomy offers both a general mapping of the\nfeedback space, as well as pedagogy-established discrete categories, allowing\nus to empirically demonstrate the impact of different feedback types on revised\ngenerations. In addition to streamlining existing NLF designs, FELT also brings\nout new, unexplored directions for research in NLF. We make our taxonomy\navailable to the community, providing guides and examples for mapping our\ncategorizations to future resources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Borges_B/0/1/0/all/0/1\">Beatriz Borges</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tandon_N/0/1/0/all/0/1\">Niket Tandon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaser_T/0/1/0/all/0/1\">Tanja K&#xe4;ser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A model of interaction semantics. (arXiv:2007.06258v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2007.06258","description":"<p>Purpose: The purpose of this article is to propose, based on a model of an\ninteraction semantics, a certain understanding of the ''meaning'' of the\nexchanged characters within an interaction.\n</p>\n<p>Methodology: Based on a model of system interaction, I structure the model of\ninteraction semantics similar to the semantics of a formal language: first, I\nidentify adequate variables in my interaction model to assign values to, and\nsecond, I identify the interpretation function to provide meaning. Thereby I\narrive at a model of interaction semantics which, in the sense of the late\nLudwig Wittgenstein, can do without a 'mental' mapping from characters to\nconcepts.\n</p>\n<p>Findings: The key findings are a better understanding of the tight relation\nbetween the informatical approach to model interactions and game theory; of the\ncentral 'chicken and egg' problem, any natural language has to solve, namely\nthat to interact sensibly, we have to understand each other and to acquire a\ncommon understanding, we have to interact with each other, which I call the\n'simultaneous interaction and understanding (SIAU)' problem; why ontologies are\nless 'semantic' then their proponents suggest; and how 'semantic'\ninteroperability is to be achieved.\n</p>\n<p>Value: The main value of the proposed model of interaction semantics is that\nit could be applied in many different disciplines and therefore could serve as\na basis for scientists of natural sciences and humanities as well as engineers\nto understand each other more easily talking about semantics, especially with\nthe advent of cyber-physical systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reich_J/0/1/0/all/0/1\">Johannes Reich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CPTAM: Constituency Parse Tree Aggregation Method. (arXiv:2201.07905v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.07905","description":"<p>Diverse Natural Language Processing tasks employ constituency parsing to\nunderstand the syntactic structure of a sentence according to a phrase\nstructure grammar. Many state-of-the-art constituency parsers are proposed, but\nthey may provide different results for the same sentences, especially for\ncorpora outside their training domains. This paper adopts the truth discovery\nidea to aggregate constituency parse trees from different parsers by estimating\ntheir reliability in the absence of ground truth. Our goal is to consistently\nobtain high-quality aggregated constituency parse trees. We formulate the\nconstituency parse tree aggregation problem in two steps, structure aggregation\nand constituent label aggregation. Specifically, we propose the first truth\ndiscovery solution for tree structures by minimizing the weighted sum of\nRobinson-Foulds (RF) distances, a classic symmetric distance metric between two\ntrees. Extensive experiments are conducted on benchmark datasets in different\nlanguages and domains. The experimental results show that our method, CPTAM,\noutperforms the state-of-the-art aggregation baselines. We also demonstrate\nthat the weights estimated by CPTAM can adequately evaluate constituency\nparsers in the absence of ground truth.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Adithya Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabetpour_N/0/1/0/all/0/1\">Nasim Sabetpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markin_A/0/1/0/all/0/1\">Alexey Markin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eulenstein_O/0/1/0/all/0/1\">Oliver Eulenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ELQA: A Corpus of Metalinguistic Questions and Answers about English. (arXiv:2205.00395v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.00395","description":"<p>We present ELQA, a corpus of questions and answers in and about the English\nlanguage. Collected from two online forums, the &gt;70k questions (from English\nlearners and others) cover wide-ranging topics including grammar, meaning,\nfluency, and etymology. The answers include descriptions of general properties\nof English vocabulary and grammar as well as explanations about specific\n(correct and incorrect) usage examples. Unlike most NLP datasets, this corpus\nis metalinguistic -- it consists of language about language. As such, it can\nfacilitate investigations of the metalinguistic capabilities of NLU models, as\nwell as educational applications in the language learning domain. To study\nthis, we define a free-form question answering task on our dataset and conduct\nevaluations on multiple LLMs (Large Language Models) to analyze their capacity\nto generate metalinguistic answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Behzad_S/0/1/0/all/0/1\">Shabnam Behzad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakaguchi_K/0/1/0/all/0/1\">Keisuke Sakaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeldes_A/0/1/0/all/0/1\">Amir Zeldes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-shot Reranking for Multi-hop QA via Language Model Prompting. (arXiv:2205.12650v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12650","description":"<p>We study few-shot reranking for multi-hop QA with open-domain questions. To\nalleviate the need for a large number of labeled question-document pairs for\nretriever training, we propose PromptRank, which relies on large language\nmodels prompting for multi-hop path reranking. PromptRank first constructs an\ninstruction-based prompt that includes a candidate document path and then\ncomputes the relevance score between a given question and the path based on the\nconditional likelihood of the question given the path prompt according to a\nlanguage model. PromptRank yields strong retrieval performance on HotpotQA with\nonly 128 training examples compared to state-of-the-art methods trained on\nthousands of examples -- 73.6 recall@10 by PromptRank vs. 77.8 by PathRetriever\nand 77.5 by multi-hop dense retrieval. Code available at\nhttps://github.com/mukhal/PromptRank\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_M/0/1/0/all/0/1\">Muhammad Khalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Logeswaran_L/0/1/0/all/0/1\">Lajanugen Logeswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Moontae Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Honglak Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PASTA: A Dataset for Modeling Participant States in Narratives. (arXiv:2208.00329v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.00329","description":"<p>The events in a narrative are understood as a coherent whole via the\nunderlying states of their participants. Often, these participant states are\nnot explicitly mentioned, instead left to be inferred by the reader. A model\nthat understands narratives should likewise infer these implicit states, and\neven reason about the impact of changes to these states on the narrative. To\nfacilitate this goal, we introduce a new crowdsourced English-language,\nParticipant States dataset, PASTA. This dataset contains inferable participant\nstates; a counterfactual perturbation to each state; and the changes to the\nstory that would be necessary if the counterfactual were true. We introduce\nthree state-based reasoning tasks that test for the ability to infer when a\nstate is entailed by a story, to revise a story conditioned on a counterfactual\nstate, and to explain the most likely state change given a revised story.\nExperiments show that today's LLMs can reason about states to some degree, but\nthere is large room for improvement, especially in problems requiring access\nand ability to reason with diverse types of knowledge (e.g. physical,\nnumerical, factual).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sayontan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koupaee_M/0/1/0/all/0/1\">Mahnaz Koupaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_I/0/1/0/all/0/1\">Isabella Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferraro_F/0/1/0/all/0/1\">Francis Ferraro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chambers_N/0/1/0/all/0/1\">Nathanael Chambers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1\">Niranjan Balasubramanian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language-agnostic Code-Switching in Sequence-To-Sequence Speech Recognition. (arXiv:2210.08992v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.08992","description":"<p>Code-Switching (CS) is referred to the phenomenon of alternately using words\nand phrases from different languages. While today's neural end-to-end (E2E)\nmodels deliver state-of-the-art performances on the task of automatic speech\nrecognition (ASR) it is commonly known that these systems are very\ndata-intensive. However, there is only a few transcribed and aligned CS speech\navailable. To overcome this problem and train multilingual systems which can\ntranscribe CS speech, we propose a simple yet effective data augmentation in\nwhich audio and corresponding labels of different source languages are\nconcatenated. By using this training data, our E2E model improves on\ntranscribing CS speech. It also surpasses monolingual models on monolingual\ntests. The results show that this augmentation technique can even improve the\nmodel's performance on inter-sentential language switches not seen during\ntraining by 5,03% WER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ugan_E/0/1/0/all/0/1\">Enes Yavuz Ugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1\">Christian Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_J/0/1/0/all/0/1\">Juan Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alexander Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cracking Double-Blind Review: Authorship Attribution with Deep Learning. (arXiv:2211.07467v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.07467","description":"<p>Double-blind peer review is considered a pillar of academic research because\nit is perceived to ensure a fair, unbiased, and fact-centered scientific\ndiscussion. Yet, experienced researchers can often correctly guess from which\nresearch group an anonymous submission originates, biasing the peer-review\nprocess. In this work, we present a transformer-based, neural-network\narchitecture that only uses the text content and the author names in the\nbibliography to attribute an anonymous manuscript to an author. To train and\nevaluate our method, we created the largest authorship identification dataset\nto date. It leverages all research papers publicly available on arXiv amounting\nto over 2 million manuscripts. In arXiv-subsets with up to 2,000 different\nauthors, our method achieves an unprecedented authorship attribution accuracy,\nwhere up to 73% of papers are attributed correctly. We present a scaling\nanalysis to highlight the applicability of the proposed method to even larger\ndatasets when sufficient compute capabilities are more widely available to the\nacademic community. Furthermore, we analyze the attribution accuracy in\nsettings where the goal is to identify all authors of an anonymous manuscript.\nThanks to our method, we are not only able to predict the author of an\nanonymous work, but we also provide empirical evidence of the key aspects that\nmake a paper attributable. We have open-sourced the necessary tools to\nreproduce our experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bauersfeld_L/0/1/0/all/0/1\">Leonard Bauersfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romero_A/0/1/0/all/0/1\">Angel Romero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muglikar_M/0/1/0/all/0/1\">Manasi Muglikar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scaramuzza_D/0/1/0/all/0/1\">Davide Scaramuzza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptBoosting: Black-Box Text Classification with Ten Forward Passes. (arXiv:2212.09257v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09257","description":"<p>We describe PromptBoosting, a query-efficient procedure for building a text\nclassifier from a neural language model (LM) without access to the LM's\nparameters, gradients, or hidden representations. This form of \"black-box\"\nclassifier training has become increasingly important as the cost of training\nand inference in large-scale LMs grows. But existing black-box LM classifier\nlearning approaches are themselves computationally inefficient, typically\nspecializing LMs to the target task by searching in a large space of (discrete\nor continuous) prompts using zeroth-order optimization methods. Instead of\ndirectly optimizing in prompt space, PromptBoosting obtains a small pool of\nprompts via a gradient-free approach and then constructs a large pool of weak\nlearners by pairing these prompts with different elements of the LM's output\ndistribution. These weak learners are then ensembled using the AdaBoost\nalgorithm. The entire learning process requires only a small number of forward\npasses and no backward pass. Experiments show that PromptBoosting achieves\nstate-of-the-art performance in multiple black-box few-shot classification\ntasks, and matches or outperforms full fine-tuning in both few-shot and\nstandard learning paradigms, while training 10x faster than existing black-box\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1\">Bairu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OConnor_J/0/1/0/all/0/1\">Joe O&#x27;Connor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shiyu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-in-the-loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments. (arXiv:2212.09683v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09683","description":"<p>We present a human-in-the-loop evaluation framework for fact-checking novel\nmisinformation claims and identifying social media messages that support them.\nOur approach extracts check-worthy claims, which are aggregated and ranked for\nreview. Stance classifiers are then used to identify tweets supporting novel\nmisinformation claims, which are further reviewed to determine whether they\nviolate relevant policies. To demonstrate the feasibility of our approach, we\ndevelop a baseline system based on modern NLP methods for human-in-the-loop\nfact-checking in the domain of COVID-19 treatments. We make our data and\ndetailed annotation guidelines available to support the evaluation of\nhuman-in-the-loop systems that identify novel misinformation directly from raw\nuser-generated content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mendes_E/0/1/0/all/0/1\">Ethan Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ritter_A/0/1/0/all/0/1\">Alan Ritter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for Indian Languages. (arXiv:2212.10180v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10180","description":"<p>The rapid growth of machine translation (MT) systems has necessitated\ncomprehensive studies to meta-evaluate evaluation metrics being used, which\nenables a better selection of metrics that best reflect MT quality.\nUnfortunately, most of the research focuses on high-resource languages, mainly\nEnglish, the observations for which may not always apply to other languages.\nIndian languages, having over a billion speakers, are linguistically different\nfrom English, and to date, there has not been a systematic study of evaluating\nMT systems from English into Indian languages. In this paper, we fill this gap\nby creating an MQM dataset consisting of 7000 fine-grained annotations,\nspanning 5 Indian languages and 7 MT systems, and use it to establish\ncorrelations between annotator scores and scores obtained using existing\nautomatic metrics. Our results show that pre-trained metrics, such as COMET,\nhave the highest correlations with annotator scores. Additionally, we find that\nthe metrics do not adequately capture fluency-based errors in Indian languages,\nand there is a need to develop metrics focused on Indian languages. We hope\nthat our dataset and analysis will help promote further research in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sai_A/0/1/0/all/0/1\">Ananya B. Sai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagarajan_V/0/1/0/all/0/1\">Vignesh Nagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixit_T/0/1/0/all/0/1\">Tanay Dixit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabre_R/0/1/0/all/0/1\">Raj Dabre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Pratyush Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1\">Mitesh M. Khapra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Not to Trust Language Models: Investigating Effectiveness of Parametric and Non-Parametric Memories. (arXiv:2212.10511v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10511","description":"<p>Despite their impressive performance on diverse tasks, large language models\n(LMs) still struggle with tasks requiring rich world knowledge, implying the\nlimitations of relying solely on their parameters to encode a wealth of world\nknowledge. This paper aims to understand LMs' strengths and limitations in\nmemorizing factual knowledge, by conducting large-scale knowledge probing\nexperiments of 10 models and 4 augmentation methods on PopQA, our new\nopen-domain QA dataset with 14k questions. We find that LMs struggle with less\npopular factual knowledge, and that scaling fails to appreciably improve\nmemorization of factual knowledge in the long tail. We then show that\nretrieval-augmented LMs largely outperform orders of magnitude larger LMs,\nwhile unassisted LMs remain competitive in questions about high-popularity\nentities. Based on those findings, we devise a simple, yet effective, method\nfor powerful and efficient retrieval-augmented LMs, which retrieves\nnon-parametric memories only when necessary. Experimental results show that\nthis significantly improves models' performance while reducing the inference\ncosts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mallen_A/0/1/0/all/0/1\">Alex Mallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1\">Akari Asai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1\">Victor Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1\">Rajarshi Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets. (arXiv:2301.12139v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12139","description":"<p>We investigate five English NLP benchmark datasets (on the superGLUE\nleaderboard) and two Swedish datasets for bias, along multiple axes. The\ndatasets are the following: Boolean Question (Boolq), CommitmentBank (CB),\nWinograd Schema Challenge (WSC), Wino-gender diagnostic (AXg), Recognising\nTextual Entailment (RTE), Swedish CB, and SWEDN. Bias can be harmful and it is\nknown to be common in data, which ML models learn from. In order to mitigate\nbias in data, it is crucial to be able to estimate it objectively. We use\nbipol, a novel multi-axes bias metric with explainability, to estimate and\nexplain how much bias exists in these datasets. Multilingual, multi-axes bias\nevaluation is not very common. Hence, we also contribute a new, large Swedish\nbias-labelled dataset (of 2 million samples), translated from the English\nversion and train the SotA mT5 model on it. In addition, we contribute new\nmulti-axes lexica for bias detection in Swedish. We make the codes, model, and\nnew dataset publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adewumi_T/0/1/0/all/0/1\">Tosin Adewumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sodergren_I/0/1/0/all/0/1\">Isabella S&#xf6;dergren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhaled_L/0/1/0/all/0/1\">Lama Alkhaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabry_S/0/1/0/all/0/1\">Sana Sabah Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_F/0/1/0/all/0/1\">Foteini Liwicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-Specific Skill Localization in Fine-tuned Language Models. (arXiv:2302.06600v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06600","description":"<p>Pre-trained language models can be fine-tuned to solve diverse NLP tasks,\nincluding in few-shot settings. Thus fine-tuning allows the model to quickly\npick up task-specific ``skills,'' but there has been limited study of where\nthese newly-learnt skills reside inside the massive model. This paper\nintroduces the term skill localization for this problem and proposes a\nsolution. Given the downstream task and a model fine-tuned on that task, a\nsimple optimization is used to identify a very small subset of parameters\n($\\sim0.01$% of model parameters) responsible for ($&gt;95$%) of the model's\nperformance, in the sense that grafting the fine-tuned values for just this\ntiny subset onto the pre-trained model gives performance almost as well as the\nfine-tuned model. While reminiscent of recent works on parameter-efficient\nfine-tuning, the novel aspects here are that: (i) No further re-training is\nneeded on the subset (unlike, say, with lottery tickets). (ii) Notable\nimprovements are seen over vanilla fine-tuning with respect to calibration of\npredictions in-distribution ($40$-$90$% error reduction) as well as the quality\nof predictions out-of-distribution (OOD). In models trained on multiple tasks,\na stronger notion of skill localization is observed, where the sparse regions\ncorresponding to different tasks are almost disjoint, and their overlap (when\nit happens) is a proxy for task similarity. Experiments suggest that\nlocalization via grafting can assist certain forms of continual learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Panigrahi_A/0/1/0/all/0/1\">Abhishek Panigrahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saunshi_N/0/1/0/all/0/1\">Nikunj Saunshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haoyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sanjeev Arora</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Cross-Lingual Summarization via Large Language Models. (arXiv:2302.14229v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.14229","description":"<p>Given a document in a source language, cross-lingual summarization (CLS) aims\nto generate a summary in a different target language. Recently, the emergence\nof Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has\nattracted wide attention from the computational linguistics community. However,\nit is not yet known the performance of LLMs on CLS. In this report, we\nempirically use various prompts to guide LLMs to perform zero-shot CLS from\ndifferent paradigms (i.e., end-to-end and pipeline), and provide a preliminary\nevaluation on the generated summaries. We find that ChatGPT and GPT-4\noriginally prefer to produce lengthy summaries with detailed information. These\ntwo LLMs can further balance informativeness and conciseness with the help of\nan interactive prompt, significantly improving their CLS performance.\nExperimental results on three widely-used CLS datasets show that GPT-4 achieves\nstate-of-the-art zero-shot CLS performance, and performs competitively compared\nwith the fine-tuned mBART-50. Moreover, we also find some multi-lingual and\nbilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limited\nzero-shot CLS ability. Due to the composite nature of CLS, which requires\nmodels to perform summarization and translation simultaneously, accomplishing\nthis task in a zero-shot manner is even a challenge for LLMs. Therefore, we\nsincerely hope and recommend future LLM research could use CLS as a testbed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yunlong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_B/0/1/0/all/0/1\">Beiqi Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhixu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_J/0/1/0/all/0/1\">Jianfeng Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Overview on Language Models: Recent Developments and Outlook. (arXiv:2303.05759v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.05759","description":"<p>Language modeling studies the probability distributions over strings of\ntexts. It is one of the most fundamental tasks in natural language processing\n(NLP). It has been widely used in text generation, speech recognition, machine\ntranslation, etc. Conventional language models (CLMs) aim to predict the\nprobability of linguistic sequences in a causal manner, while pre-trained\nlanguage models (PLMs) cover broader concepts and can be used in both causal\nsequential modeling and fine-tuning for downstream applications. PLMs have\ntheir own training paradigms (usually self-supervised) and serve as foundation\nmodels in modern NLP systems. This overview paper provides an introduction to\nboth CLMs and PLMs from five aspects, i.e., linguistic units, architectures,\ntraining methods, evaluation methods, and applications. Furthermore, we discuss\nthe relationship between CLMs and PLMs and shed light on the future directions\nof language modeling in the pre-trained era.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chengwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun-Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1\">C.-C. Jay Kuo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understand Legal Documents with Contextualized Large Language Models. (arXiv:2303.12135v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12135","description":"<p>The growth of pending legal cases in populous countries, such as India, has\nbecome a major issue. Developing effective techniques to process and understand\nlegal documents is extremely useful in resolving this problem. In this paper,\nwe present our systems for SemEval-2023 Task 6: understanding legal texts (Modi\net al., 2023). Specifically, we first develop the Legal-BERT-HSLN model that\nconsiders the comprehensive context information in both intra- and\ninter-sentence levels to predict rhetorical roles (subtask A) and then train a\nLegal-LUKE model, which is legal-contextualized and entity-aware, to recognize\nlegal entities (subtask B). Our evaluations demonstrate that our designed\nmodels are more accurate than baselines, e.g., with an up to 15.0% better F1\nscore in subtask B. We achieved notable performance in the task leaderboard,\ne.g., 0.834 micro F1 score, and ranked No.5 out of 27 teams in subtask A.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1\">Xin Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuchen Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v3 [q-fin.ST] UPDATED)","link":"http://arxiv.org/abs/2304.07619","description":"<p>We examine the potential of ChatGPT, and other large language models, in\npredicting stock market returns using sentiment analysis of news headlines. We\nuse ChatGPT to indicate whether a given headline is good, bad, or irrelevant\nnews for firms' stock prices. We then compute a numerical score and document a\npositive correlation between these ``ChatGPT scores'' and subsequent daily\nstock market returns. Further, ChatGPT outperforms traditional sentiment\nanalysis methods. We find that more basic models such as GPT-1, GPT-2, and BERT\ncannot accurately forecast returns, indicating return predictability is an\nemerging capacity of complex models. ChatGPT-4's implied Sharpe ratios are\nlarger than ChatGPT-3's; however, the latter model has larger total returns.\nOur results suggest that incorporating advanced language models into the\ninvestment decision-making process can yield more accurate predictions and\nenhance the performance of quantitative trading strategies. Predictability is\nconcentrated on smaller stocks and more prominent on firms with bad news,\nconsistent with limits-to-arbitrage arguments rather than market\ninefficiencies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-fin/1/au:+Lopez_Lira_A/0/1/0/all/0/1\">Alejandro Lopez-Lira</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Tang_Y/0/1/0/all/0/1\">Yuehua Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analysis of Climate Campaigns on Social Media using Bayesian Model Averaging. (arXiv:2305.06174v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06174","description":"<p>Climate change is the defining issue of our time, and we are at a defining\nmoment. Various interest groups, social movement organizations, and individuals\nengage in collective action on this issue on social media. In addition, issue\nadvocacy campaigns on social media often arise in response to ongoing societal\nconcerns, especially those faced by energy industries. Our goal in this paper\nis to analyze how those industries, their advocacy group, and climate advocacy\ngroup use social media to influence the narrative on climate change. In this\nwork, we propose a minimally supervised model soup [57] approach combined with\nmessaging themes to identify the stances of climate ads on Facebook. Finally,\nwe release our stance dataset, model, and set of themes related to climate\ncampaigns for future work on opinion mining and the automatic detection of\nclimate change stances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1\">Tunazzina Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1\">Dan Goldwasser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to Index Item IDs for Recommendation Foundation Models. (arXiv:2305.06569v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.06569","description":"<p>Recommendation foundation model utilizes large language models (LLM) for\nrecommendation by converting recommendation tasks into natural language tasks.\nIt enables generative recommendation which directly generates the item(s) to\nrecommend rather than calculating a ranking score for each and every candidate\nitem in traditional recommendation models, simplifying the recommendation\npipeline from multi-stage filtering to single-stage filtering. To avoid\ngenerating excessively long text when deciding which item(s) to recommend,\ncreating LLM-compatible item IDs is essential for recommendation foundation\nmodels. In this study, we systematically examine the item indexing problem for\nrecommendation foundation models, using P5 as the representative backbone model\nand replicating its results with various indexing methods. To emphasize the\nimportance of item indexing, we first discuss the issues of several trivial\nitem indexing methods, such as independent indexing, title indexing, and random\nindexing. We then propose four simple yet effective solutions, including\nsequential indexing, collaborative indexing, semantic (content-based) indexing,\nand hybrid indexing. Our reproducibility study of P5 highlights the significant\ninfluence of item indexing methods on the model performance, and our results on\nreal-world datasets validate the effectiveness of our proposed solutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large Language Model Recommendation. (arXiv:2305.07609v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.07609","description":"<p>The remarkable achievements of Large Language Models (LLMs) have led to the\nemergence of a novel recommendation paradigm -- Recommendation via LLM\n(RecLLM). Nevertheless, it is important to note that LLMs may contain social\nprejudices, and therefore, the fairness of recommendations made by RecLLM\nrequires further investigation. To avoid the potential risks of RecLLM, it is\nimperative to evaluate the fairness of RecLLM with respect to various sensitive\nattributes on the user side. Due to the differences between the RecLLM paradigm\nand the traditional recommendation paradigm, it is problematic to directly use\nthe fairness benchmark of traditional recommendation. To address the dilemma,\nwe propose a novel benchmark called Fairness of Recommendation via LLM\n(FaiRLLM). This benchmark comprises carefully crafted metrics and a dataset\nthat accounts for eight sensitive attributes1 in two recommendation scenarios:\nmusic and movies. By utilizing our FaiRLLM benchmark, we conducted an\nevaluation of ChatGPT and discovered that it still exhibits unfairness to some\nsensitive attributes when generating recommendations. Our code and dataset can\nbe found at https://github.com/jizhi-zhang/FaiRLLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jizhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_K/0/1/0/all/0/1\">Keqin Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts. (arXiv:2305.15689v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15689","description":"<p>Recent studies have demonstrated that natural-language prompts can help to\nleverage the knowledge learned by pre-trained language models for the binary\nsentence-level sentiment classification task. Specifically, these methods\nutilize few-shot learning settings to fine-tune the sentiment classification\nmodel using manual or automatically generated prompts. However, the performance\nof these methods is sensitive to the perturbations of the utilized prompts.\nFurthermore, these methods depend on a few labeled instances for automatic\nprompt generation and prompt ranking. This study aims to find high-quality\nprompts for the given task in a zero-shot setting. Given a base prompt, our\nproposed approach automatically generates multiple prompts similar to the base\nprompt employing positional, reasoning, and paraphrasing techniques and then\nranks the prompts using a novel metric. We empirically demonstrate that the\ntop-ranked prompts are high-quality and significantly outperform the base\nprompt and the prompts generated using few-shot learning for the binary\nsentence-level sentiment classification task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Mohna Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Adithya Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MERGE: Fast Private Text Generation. (arXiv:2305.15769v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15769","description":"<p>Recent years have seen increasing concerns about the private inference of NLP\nservices and Transformer models. However, existing two-party privacy-preserving\nmethods solely consider NLU scenarios, while the private inference of text\ngeneration such as translation, dialogue, and code completion remains unsolved.\nBesides, while migrated to NLG models, existing privacy-preserving methods\nperform poorly in terms of inference speed, and suffer from the convergence\nproblem during the training stage. To address these issues, we propose MERGE, a\nfast private text generation framework for Transformer-based language models.\nSpecifically, MERGE reuse the output hidden state as the word embedding to\nbypass the embedding computation, and reorganize the linear operations in the\nTransformer module to accelerate the forward procedure. Based on these two\noptimizations, extensive experiments show that MERGE can achieve a 26.5x\nspeedup under the sequence length 512, and reduce 80\\% communication bytes,\nwith an up to 10x speedup to existing state-of-art models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zi Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pinghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruofei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_L/0/1/0/all/0/1\">Lifeng Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scan and Snap: Understanding Training Dynamics and Token Composition in 1-layer Transformer. (arXiv:2305.16380v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16380","description":"<p>Transformer architecture has shown impressive performance in multiple\nresearch domains and has become the backbone of many neural network models.\nHowever, there is limited understanding on how it works. In particular, with a\nsimple predictive loss, how the representation emerges from the gradient\n\\emph{training dynamics} remains a mystery. In this paper, for 1-layer\ntransformer with one self-attention layer plus one decoder layer, we analyze\nits SGD training dynamics for the task of next token prediction in a\nmathematically rigorous manner. We open the black box of the dynamic process of\nhow the self-attention layer combines input tokens, and reveal the nature of\nunderlying inductive bias. More specifically, with the assumption (a) no\npositional encoding, (b) long input sequence, and (c) the decoder layer learns\nfaster than the self-attention layer, we prove that self-attention acts as a\n\\emph{discriminative scanning algorithm}: starting from uniform attention, it\ngradually attends more to distinct key tokens for a specific next token to be\npredicted, and pays less attention to common key tokens that occur across\ndifferent next tokens. Among distinct tokens, it progressively drops attention\nweights, following the order of low to high co-occurrence between the key and\nthe query token in the training set. Interestingly, this procedure does not\nlead to winner-takes-all, but decelerates due to a \\emph{phase transition} that\nis controllable by the learning rates of the two layers, leaving (almost) fixed\ntoken combination. We verify this \\textbf{\\emph{scan and snap}} dynamics on\nsynthetic and real-world data (WikiText).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Beidi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1\">Simon Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Practical PCG Through Large Language Models. (arXiv:2305.18243v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18243","description":"<p>Large Language Models (LLMs) have proven to be useful tools in various\ndomains outside of the field of their inception, which was natural language\nprocessing. In this study, we provide practical directions on how to use LLMs\nto generate 2D-game rooms for an under-development game, named Metavoidal. Our\ntechnique can harness the power of GPT-3 by Human-in-the-loop fine-tuning which\nallows our method to create 37% Playable-Novel levels from as scarce data as\nonly 60 hand-designed rooms under a scenario of the non-trivial game, with\nrespect to (Procedural Content Generation) PCG, that has a good amount of local\nand global constraints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nasir_M/0/1/0/all/0/1\">Muhammad U Nasir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"W-procer: Weighted Prototypical Contrastive Learning for Medical Few-Shot Named Entity Recognition. (arXiv:2305.18624v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18624","description":"<p>Contrastive learning has become a popular solution for few-shot Name Entity\nRecognization (NER). The conventional configuration strives to reduce the\ndistance between tokens with the same labels and increase the distance between\ntokens with different labels. The effect of this setup may, however, in the\nmedical domain, there are a lot of entities annotated as OUTSIDE (O), and they\nare undesirably pushed apart to other entities that are not labeled as OUTSIDE\n(O) by the current contrastive learning method end up with a noisy prototype\nfor the semantic representation of the label, though there are many OUTSIDE (O)\nlabeled entities are relevant to the labeled entities. To address this\nchallenge, we propose a novel method named Weighted Prototypical Contrastive\nLearning for Medical Few Shot Named Entity Recognization (W-PROCER). Our\napproach primarily revolves around constructing the prototype-based contractive\nloss and weighting network. These components play a crucial role in assisting\nthe model in differentiating the negative samples from OUTSIDE (O) tokens and\nenhancing the discrimination ability of contrastive learning. Experimental\nresults show that our proposed W-PROCER framework significantly outperforms the\nstrong baselines on the three medical benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingchen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1\">Yang Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_J/0/1/0/all/0/1\">Jeremy Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Huixue Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1\">Huaiyuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring the Robustness of Natural Language Processing Models to Domain Shifts. (arXiv:2306.00168v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00168","description":"<p>Existing research on Domain Robustness (DR) suffers from disparate setups,\nlack of evaluation task variety, and reliance on challenge sets. In this paper,\nwe pose a fundamental question: What is the state of affairs of the DR\nchallenge in the era of Large Language Models (LLMs)? To this end, we construct\na DR benchmark comprising diverse NLP tasks, including sentence and token-level\nclassification, QA, and generation, each task consists of several domains. We\nexplore the DR challenge of fine-tuned and few-shot learning models in natural\ndomain shift settings and devise two diagnostic metrics of Out-of-Distribution\n(OOD) performance degradation: The commonly used Source Drop (SD) and the\noverlooked Target Drop (TD). Our findings reveal important insights: First,\ndespite their capabilities, zero-to-few shot LLMs and fine-tuning approaches\nstill fail to meet satisfactory performance in the OOD context; Second, TD\napproximates better than SD the average OOD degradation; Third, in a\nsignificant proportion of domain shifts, either SD or TD is positive, but not\nboth, and therefore disregarding one can lead to incorrect DR conclusions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Calderon_N/0/1/0/all/0/1\">Nitay Calderon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Porat_N/0/1/0/all/0/1\">Naveh Porat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1\">Eyal Ben-David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gekhman_Z/0/1/0/all/0/1\">Zorik Gekhman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oved_N/0/1/0/all/0/1\">Nadav Oved</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion. (arXiv:2306.02561v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02561","description":"<p>We present LLM-Blender, an ensembling framework designed to attain\nconsistently superior performance by leveraging the diverse strengths of\nmultiple open-source large language models (LLMs). Our framework consists of\ntwo modules: PairRanker and GenFuser, addressing the observation that optimal\nLLMs for different examples can significantly vary. PairRanker employs a\nspecialized pairwise comparison method to distinguish subtle differences\nbetween candidate outputs. It jointly encodes the input text and a pair of\ncandidates, using cross-attention encoders to determine the superior one. Our\nresults demonstrate that PairRanker exhibits the highest correlation with\nChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates,\ngenerating an improved output by capitalizing on their strengths and mitigating\ntheir weaknesses. To facilitate large-scale evaluation, we introduce a\nbenchmark dataset, MixInstruct, which is a mixture of multiple instruction\ndatasets featuring oracle pairwise comparisons. Our LLM-Blender significantly\noutperform individual LLMs and baseline methods across various metrics,\nestablishing a substantial performance gap.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Dongfu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Bill Yuchen Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Reliability of Watermarks for Large Language Models. (arXiv:2306.04634v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.04634","description":"<p>As LLMs become commonplace, machine-generated text has the potential to flood\nthe internet with spam, social media bots, and valueless content. Watermarking\nis a simple and effective strategy for mitigating such harms by enabling the\ndetection and documentation of LLM-generated text. Yet a crucial question\nremains: How reliable is watermarking in realistic settings in the wild? There,\nwatermarked text may be modified to suit a user's needs, or entirely rewritten\nto avoid detection.\n</p>\n<p>We study the robustness of watermarked text after it is re-written by humans,\nparaphrased by a non-watermarked LLM, or mixed into a longer hand-written\ndocument. We find that watermarks remain detectable even after human and\nmachine paraphrasing. While these attacks dilute the strength of the watermark,\nparaphrases are statistically likely to leak n-grams or even longer fragments\nof the original text, resulting in high-confidence detections when enough\ntokens are observed. For example, after strong human paraphrasing the watermark\nis detectable after observing 800 tokens on average, when setting a 1e-5 false\npositive rate. We also consider a range of new detection schemes that are\nsensitive to short spans of watermarked text embedded inside a large document,\nand we compare the robustness of watermarking to other kinds of detectors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirchenbauer_J/0/1/0/all/0/1\">John Kirchenbauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1\">Jonas Geiping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_M/0/1/0/all/0/1\">Manli Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saifullah_K/0/1/0/all/0/1\">Khalid Saifullah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_K/0/1/0/all/0/1\">Kezhi Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_K/0/1/0/all/0/1\">Kasun Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aniruddha Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for Situated Neural Dialogue Generation. (arXiv:2306.15253v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.15253","description":"<p>Humans talk in free-form while negotiating the expressed meanings or common\nground. Despite the impressive conversational abilities of the large generative\nlanguage models, they do not consider the individual differences in contextual\nunderstanding in a shared situated environment. In this work, we propose\nMindDial, a novel conversational framework that can generate situated free-form\nresponses to negotiate common ground. We design an explicit mind module that\ncan track three-level beliefs -- the speaker's belief, the speaker's prediction\nof the listener's belief, and the common belief based on the gap between the\nfirst two. Then the speaking act classification head will decide to continue to\ntalk, end this turn, or take task-related action. We augment a common ground\nalignment dataset MutualFriend with belief dynamics annotation, of which the\ngoal is to find a single mutual friend based on the free chat between two\nagents. Experiments show that our model with mental state modeling can resemble\nhuman responses when aligning common ground meanwhile mimic the natural human\nconversation flow. The ablation study further validates the third-level common\nbelief can aggregate information of the first and second-order beliefs and\nalign common ground more efficiently.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shuwen Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Song-Chun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zilong Zheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate via Compiler Co-design. (arXiv:2306.15656v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.15656","description":"<p>This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be publicly\navailable upon paper acceptance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1\">Fu-Ming Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probabilistic Linguistic Knowledge and Token-level Text Augmentation. (arXiv:2306.16644v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.16644","description":"<p>This paper investigates the effectiveness of token-level text augmentation\nand the role of probabilistic linguistic knowledge within a\nlinguistically-motivated evaluation context. Two text augmentation programs,\nREDA and REDA$_{NG}$, were developed, both implementing five token-level text\nediting operations: Synonym Replacement (SR), Random Swap (RS), Random\nInsertion (RI), Random Deletion (RD), and Random Mix (RM). REDA$_{NG}$\nleverages pretrained $n$-gram language models to select the most likely\naugmented texts from REDA's output. Comprehensive and fine-grained experiments\nwere conducted on a binary question matching classification task in both\nChinese and English. The results strongly refute the general effectiveness of\nthe five token-level text augmentation techniques under investigation, whether\napplied together or separately, and irrespective of various common\nclassification model types used, including transformers. Furthermore, the role\nof probabilistic linguistic knowledge is found to be minimal.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengxiang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"weighted CapsuleNet networks for Persian multi-domain sentiment analysis. (arXiv:2306.17068v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17068","description":"<p>Sentiment classification is a fundamental task in natural language\nprocessing, assigning one of the three classes, positive, negative, or neutral,\nto free texts. However, sentiment classification models are highly domain\ndependent; the classifier may perform classification with reasonable accuracy\nin one domain but not in another due to the Semantic multiplicity of words\ngetting poor accuracy. This article presents a new Persian/Arabic multi-domain\nsentiment analysis method using the cumulative weighted capsule networks\napproach. Weighted capsule ensemble consists of training separate capsule\nnetworks for each domain and a weighting measure called domain belonging degree\n(DBD). This criterion consists of TF and IDF, which calculates the dependency\nof each document for each domain separately; this value is multiplied by the\npossible output that each capsule creates. In the end, the sum of these\nmultiplications is the title of the final output, and is used to determine the\npolarity. And the most dependent domain is considered the final output for each\ndomain. The proposed method was evaluated using the Digikala dataset and\nobtained acceptable accuracy compared to the existing approaches. It achieved\nan accuracy of 0.89 on detecting the domain of belonging and 0.99 on detecting\nthe polarity. Also, for the problem of dealing with unbalanced classes, a\ncost-sensitive function was used. This function was able to achieve 0.0162\nimprovements in accuracy for sentiment classification. This approach on Amazon\nArabic data can achieve 0.9695 accuracies in domain classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kobari_M/0/1/0/all/0/1\">Mahboobeh Sadat Kobari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karimi_N/0/1/0/all/0/1\">Nima Karimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pourhosseini_B/0/1/0/all/0/1\">Benyamin Pourhosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousa_R/0/1/0/all/0/1\">Ramin Mousa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LMBot: Distilling Graph Knowledge into Language Model for Graph-less Deployment in Twitter Bot Detection. (arXiv:2306.17408v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2306.17408","description":"<p>As malicious actors employ increasingly advanced and widespread bots to\ndisseminate misinformation and manipulate public opinion, the detection of\nTwitter bots has become a crucial task. Though graph-based Twitter bot\ndetection methods achieve state-of-the-art performance, we find that their\ninference depends on the neighbor users multi-hop away from the targets, and\nfetching neighbors is time-consuming and may introduce bias. At the same time,\nwe find that after finetuning on Twitter bot detection, pretrained language\nmodels achieve competitive performance and do not require a graph structure\nduring deployment. Inspired by this finding, we propose a novel bot detection\nframework LMBot that distills the knowledge of graph neural networks (GNNs)\ninto language models (LMs) for graph-less deployment in Twitter bot detection\nto combat the challenge of data dependency. Moreover, LMBot is compatible with\ngraph-based and graph-less datasets. Specifically, we first represent each user\nas a textual sequence and feed them into the LM for domain adaptation. For\ngraph-based datasets, the output of LMs provides input features for the GNN,\nenabling it to optimize for bot detection and distill knowledge back to the LM\nin an iterative, mutually enhancing process. Armed with the LM, we can perform\ngraph-less inference, which resolves the graph data dependency and sampling\nbias issues. For datasets without graph structure, we simply replace the GNN\nwith an MLP, which has also shown strong performance. Our experiments\ndemonstrate that LMBot achieves state-of-the-art performance on four Twitter\nbot detection benchmarks. Extensive studies also show that LMBot is more\nrobust, versatile, and efficient compared to graph-based Twitter bot detection\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zijian Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zhaoxuan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1\">Zhenyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Zifeng Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongrui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qinghua Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Minnan Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressive Multi-task Learning Framework for Chinese Text Error Correction. (arXiv:2306.17447v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17447","description":"<p>Chinese Text Error Correction (CTEC) aims to detect and correct errors in the\ninput text, which benefits human's daily life and various downstream tasks.\nRecent approaches mainly employ Pre-trained Language Models (PLMs) to resolve\nCTEC task and achieve tremendous success. However, previous approaches suffer\nfrom issues of over-correction and under-correction, and the former is\nespecially conspicuous in the precision-critical CTEC task. To mitigate the\nissue of overcorrection, we propose a novel model-agnostic progressive\nmultitask learning framework for CTEC, named ProTEC, which guides a CTEC model\nto learn the task from easy to difficult. We divide CTEC task into three\nsub-tasks from easy to difficult: Error Detection, Error Type Identification,\nand Correction Result Generation. During the training process, ProTEC guides\nthe model to learn text error correction progressively by incorporating these\nsub-tasks into a multi-task training objective. During the inference process,\nthe model completes these sub-tasks in turn to generate the correction results.\nExtensive experiments and detailed analyses fully demonstrate the effectiveness\nand efficiency of our proposed framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shirong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haojing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shulin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Ying Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Statler: State-Maintaining Language Models for Embodied Reasoning. (arXiv:2306.17840v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2306.17840","description":"<p>Large language models (LLMs) provide a promising tool that enable robots to\nperform complex robot reasoning tasks. However, the limited context window of\ncontemporary LLMs makes reasoning over long time horizons difficult. Embodied\ntasks such as those that one might expect a household robot to perform\ntypically require that the planner consider information acquired a long time\nago (e.g., properties of the many objects that the robot previously encountered\nin the environment). Attempts to capture the world state using an LLM's\nimplicit internal representation is complicated by the paucity of task- and\nenvironment-relevant information available in a robot's action history, while\nmethods that rely on the ability to convey information via the prompt to the\nLLM are subject to its limited context window. In this paper, we propose\nStatler, a framework that endows LLMs with an explicit representation of the\nworld state as a form of ``memory'' that is maintained over time. Integral to\nStatler is its use of two instances of general LLMs -- a world-model reader and\na world-model writer -- that interface with and maintain the world state. By\nproviding access to this world state ``memory'', Statler improves the ability\nof existing LLMs to reason over longer time horizons without the constraint of\ncontext length. We evaluate the effectiveness of our approach on three\nsimulated table-top manipulation domains and a real robot domain, and show that\nit improves the state-of-the-art in LLM-based robot reasoning. Project website:\nhttps://statler-lm.github.io/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoneda_T/0/1/0/all/0/1\">Takuma Yoneda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_J/0/1/0/all/0/1\">Jiading Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Huanyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1\">Tianchong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shengjie Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Picker_B/0/1/0/all/0/1\">Ben Picker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yunis_D/0/1/0/all/0/1\">David Yunis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1\">Hongyuan Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walter_M/0/1/0/all/0/1\">Matthew R. Walter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs. (arXiv:2306.17842v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2306.17842","description":"<p>In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling\nfrozen LLMs to perform both understanding and generation tasks involving\nnon-linguistic modalities such as images or videos. SPAE converts between raw\npixels and interpretable lexical tokens (or words) extracted from the LLM's\nvocabulary. The resulting tokens capture both the semantic meaning and the\nfine-grained details needed for visual reconstruction, effectively translating\nthe visual content into a language comprehensible to the LLM, and empowering it\nto perform a wide array of multimodal tasks. Our approach is validated through\nin-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set\nof image understanding and generation tasks. Our method marks the first\nsuccessful attempt to enable a frozen LLM to generate image content while\nsurpassing state-of-the-art performance in image understanding tasks, under the\nsame setting, by over 25%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lijun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiruo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vivek Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Macherey_W/0/1/0/all/0/1\">Wolfgang Macherey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yanping Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1\">David A. Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Essa_I/0/1/0/all/0/1\">Irfan Essa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Ming-Hsuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1\">Kevin Murphy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hauptmann_A/0/1/0/all/0/1\">Alexander G. Hauptmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1\">Lu Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-07-03T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}