{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-09T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Rule-Guided Joint Embedding Learning of Knowledge Graphs. (arXiv:2401.02968v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02968","description":"<p>In recent studies, the focus has been on enhancing knowledge graph embedding\nlearning, which encodes entities and relations in knowledge graphs into\nlow-dimensional vector spaces. While current models mainly consider the\nstructural aspects of these graphs, there's a wealth of contextual and literal\ninformation in knowledge graphs that can be utilized for more effective\nembeddings. This paper introduces a novel model that incorporates both\ncontextual and literal information into entity and relation embeddings,\nutilizing graph convolutional networks. Specifically, for contextual\ninformation, we assess its significance through confidence and relatedness\nmetrics. A unique rule-based method is developed to calculate the confidence\nmetric, and the relatedness metric is derived from the literal information's\nrepresentations. We validated our model's performance with thorough experiments\non two established benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qisong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Ji Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1\">Sijia Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Neng Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Anomaly Detection in Text. (arXiv:2401.02971v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02971","description":"<p>Deep anomaly detection methods have become increasingly popular in recent\nyears, with methods like Stacked Autoencoders, Variational Autoencoders, and\nGenerative Adversarial Networks greatly improving the state-of-the-art. Other\nmethods rely on augmenting classical models (such as the One-Class Support\nVector Machine), by learning an appropriate kernel function using Neural\nNetworks. Recent developments in representation learning by self-supervision\nare proving to be very beneficial in the context of anomaly detection. Inspired\nby the advancements in anomaly detection using self-supervised learning in the\nfield of computer vision, this thesis aims to develop a method for detecting\nanomalies by exploiting pretext tasks tailored for text corpora. This approach\ngreatly improves the state-of-the-art on two datasets, 20Newsgroups, and AG\nNews, for both semi-supervised and unsupervised anomaly detection, thus proving\nthe potential for self-supervised anomaly detectors in the field of natural\nlanguage processing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manolache_A/0/1/0/all/0/1\">Andrei Manolache</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"REE-HDSC: Recognizing Extracted Entities for the Historical Database Suriname Curacao. (arXiv:2401.02972v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02972","description":"<p>We describe the project REE-HDSC and outline our efforts to improve the\nquality of named entities extracted automatically from texts generated by\nhand-written text recognition (HTR) software. We describe a six-step processing\npipeline and test it by processing 19th and 20th century death certificates\nfrom the civil registry of Curacao. We find that the pipeline extracts dates\nwith high precision but that the precision of person name extraction is low.\nNext we show how name precision extraction can be improved by retraining HTR\nmodels with names, post-processing and by identifying and removing incorrect\nnames.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sang_E/0/1/0/all/0/1\">Erik Tjong Kim Sang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficacy of Utilizing Large Language Models to Detect Public Threat Posted Online. (arXiv:2401.02974v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02974","description":"<p>This paper examines the efficacy of utilizing large language models (LLMs) to\ndetect public threats posted online. Amid rising concerns over the spread of\nthreatening rhetoric and advance notices of violence, automated content\nanalysis techniques may aid in early identification and moderation. Custom data\ncollection tools were developed to amass post titles from a popular Korean\nonline community, comprising 500 non-threat examples and 20 threats. Various\nLLMs (GPT-3.5, GPT-4, PaLM) were prompted to classify individual posts as\neither \"threat\" or \"safe.\" Statistical analysis found all models demonstrated\nstrong accuracy, passing chi-square goodness of fit tests for both threat and\nnon-threat identification. GPT-4 performed best overall with 97.9% non-threat\nand 100% threat accuracy. Affordability analysis also showed PaLM API pricing\nas highly cost-efficient. The findings indicate LLMs can effectively augment\nhuman content moderation at scale to help mitigate emerging online risks.\nHowever, biases, transparency, and ethical oversight remain vital\nconsiderations before real-world implementation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taeksoo Kwon</a> (Algorix Convergence Research Office), <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Connor Kim</a> (Centennial High School)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncovering Regulatory Affairs Complexity in Medical Products: A Qualitative Assessment Utilizing Open Coding and Natural Language Processing (NLP). (arXiv:2401.02975v1 [cs.CY])","link":"http://arxiv.org/abs/2401.02975","description":"<p>This study investigates the complexity of regulatory affairs in the medical\ndevice industry, a critical factor influencing market access and patient care.\nThrough qualitative research, we sought expert insights to understand the\nfactors contributing to this complexity. The study involved semi-structured\ninterviews with 28 professionals from medical device companies, specializing in\nvarious aspects of regulatory affairs. These interviews were analyzed using\nopen coding and Natural Language Processing (NLP) techniques. The findings\nreveal key sources of complexity within the regulatory landscape, divided into\nfive domains: (A) Regulatory language complexity, (B) Intricacies within the\nregulatory process, (C) Global-level complexities, (D) Database-related\nconsiderations, and (E) Product-level issues. The participants highlighted the\nneed for strategies to streamline regulatory compliance, enhance interactions\nbetween regulatory bodies and industry players, and develop adaptable\nframeworks for rapid technological advancements. Emphasizing interdisciplinary\ncollaboration and increased transparency, the study concludes that these\nelements are vital for establishing coherent and effective regulatory\nprocedures in the medical device sector.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceross_A/0/1/0/all/0/1\">Aaron Ceross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergmann_J/0/1/0/all/0/1\">Jeroen H.M. Bergmann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trace and Edit Relation Associations in GPT. (arXiv:2401.02976v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02976","description":"<p>This study introduces a novel approach for analyzing and modifying entity\nrelationships in GPT models, diverging from ROME's entity-focused methods. We\ndevelop a relation tracing technique to understand the influence of language\nmodel computations on relationship judgments. Using the FewRel dataset, we\nidentify key roles of MLP modules and attention mechanisms in processing\nrelationship information. Our method, tested against ROME on a new dataset,\nshows improved balance in specificity and generalization, underscoring the\npotential of manipulating early-layer modules for enhanced model understanding\nand accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiahang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Taoyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuanli Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning from a Generative AI Predecessor -- The Many Motivations for Interacting with Conversational Agents. (arXiv:2401.02978v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02978","description":"<p>For generative AI to succeed, how engaging a conversationalist must it be?\nFor almost sixty years, some conversational agents have responded to any\nquestion or comment to keep a conversation going. In recent years, several\nutilized machine learning or sophisticated language processing, such as Tay,\nXiaoice, Zo, Hugging Face, Kuki, and Replika. Unlike generative AI, they\nfocused on engagement, not expertise. Millions of people were motivated to\nengage with them. What were the attractions? Will generative AI do better if it\nis equally engaging, or should it be less engaging? Prior to the emergence of\ngenerative AI, we conducted a large-scale quantitative and qualitative analysis\nto learn what motivated millions of people to engage with one such 'virtual\ncompanion,' Microsoft's Zo. We examined the complete chat logs of 2000\nanonymized people. We identified over a dozen motivations that people had for\ninteracting with this software. Designers learned different ways to increase\nengagement. Generative conversational AI does not yet have a clear revenue\nmodel to address its high cost. It might benefit from being more engaging, even\nas it supports productivity and creativity. Our study and analysis point to\nopportunities and challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brinkman_D/0/1/0/all/0/1\">Donald Brinkman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grudin_J/0/1/0/all/0/1\">Jonathan Grudin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are we describing the same sound? An analysis of word embedding spaces of expressive piano performance. (arXiv:2401.02979v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02979","description":"<p>Semantic embeddings play a crucial role in natural language-based information\nretrieval. Embedding models represent words and contexts as vectors whose\nspatial configuration is derived from the distribution of words in large text\ncorpora. While such representations are generally very powerful, they might\nfail to account for fine-grained domain-specific nuances. In this article, we\ninvestigate this uncertainty for the domain of characterizations of expressive\npiano performance. Using a music research dataset of free text performance\ncharacterizations and a follow-up study sorting the annotations into clusters,\nwe derive a ground truth for a domain-specific semantic similarity structure.\nWe test five embedding models and their similarity structure for correspondence\nwith the ground truth. We further assess the effects of contextualizing\nprompts, hubness reduction, cross-modal similarity, and k-means clustering. The\nquality of embedding models shows great variability with respect to this task;\nmore general models perform better than domain-adapted ones and the best model\nconfigurations reach human-level agreement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peter_S/0/1/0/all/0/1\">Silvan David Peter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Shreyan Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cancino_Chacon_C/0/1/0/all/0/1\">Carlos Eduardo Cancino-Chac&#xf3;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1\">Gerhard Widmer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-tuning and Utilization Methods of Domain-specific LLMs. (arXiv:2401.02981v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02981","description":"<p>Recent releases of pre-trained Large Language Models (LLMs) have gained\nconsiderable traction, yet research on fine-tuning and employing\ndomain-specific LLMs remains scarce. This study investigates approaches for\nfine-tuning and leveraging domain-specific LLMs, highlighting trends in LLMs,\nfoundational models, and methods for domain-specific pre-training. Focusing on\nthe financial sector, it details dataset selection, preprocessing, model\nchoice, and considerations crucial for LLM fine-tuning in finance. Addressing\nthe unique characteristics of financial data, the study explores the\nconstruction of domain-specific vocabularies and considerations for security\nand regulatory compliance. In the practical application of LLM fine-tuning, the\nstudy outlines the procedure and implementation for generating domain-specific\nLLMs in finance. Various financial cases, including stock price prediction,\nsentiment analysis of financial news, automated document processing, research,\ninformation extraction, and customer service enhancement, are exemplified. The\nstudy explores the potential of LLMs in the financial domain, identifies\nlimitations, and proposes directions for improvement, contributing valuable\ninsights for future research. Ultimately, it advances natural language\nprocessing technology in business, suggesting proactive LLM utilization in\nfinancial services across industries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1\">Cheonsu Jeong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BIBench: Benchmarking Data Analysis Knowledge of Large Language Models. (arXiv:2401.02982v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02982","description":"<p>Large Language Models (LLMs) have demonstrated impressive capabilities across\na wide range of tasks. However, their proficiency and reliability in the\nspecialized domain of Data Analysis, particularly with a focus on data-driven\nthinking, remain uncertain. To bridge this gap, we introduce BIBench, a\ncomprehensive benchmark designed to evaluate the data analysis capabilities of\nLLMs within the context of Business Intelligence (BI). BIBench assesses LLMs\nacross three dimensions: 1) BI foundational knowledge, evaluating the models'\nnumerical reasoning and familiarity with financial concepts; 2) BI knowledge\napplication, determining the models' ability to quickly comprehend textual\ninformation and generate analysis questions from multiple views; and 3) BI\ntechnical skills, examining the models' use of technical knowledge to address\nreal-world data analysis challenges. BIBench comprises 11 sub-tasks, spanning\nthree categories of task types: classification, extraction, and generation.\nAdditionally, we've developed BIChat, a domain-specific dataset with over a\nmillion data points, to fine-tune LLMs. We will release BIBenchmark, BIChat,\nand the evaluation scripts at \\url{https://github.com/cubenlp/BIBench}. This\nbenchmark aims to provide a measure for in-depth analysis of LLM abilities and\nfoster the advancement of LLMs in the field of data analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shangqing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_C/0/1/0/all/0/1\">Chenghao Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_X/0/1/0/all/0/1\">Xinlin Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_Z/0/1/0/all/0/1\">Zhaoguang Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_M/0/1/0/all/0/1\">Man Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models in Mental Health Care: a Scoping Review. (arXiv:2401.02984v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02984","description":"<p>Objective: The growing use of large language models (LLMs) stimulates a need\nfor a comprehensive review of their applications and outcomes in mental health\ncare contexts. This scoping review aims to critically analyze the existing\ndevelopment and applications of LLMs in mental health care, highlighting their\nsuccesses and identifying their challenges and limitations in these specialized\nfields. Materials and Methods: A broad literature search was conducted in\nNovember 2023 using six databases (PubMed, Web of Science, Google Scholar,\narXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred\nReporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A\ntotal of 313 publications were initially identified, and after applying the\nstudy inclusion criteria, 34 publications were selected for the final review.\nResults: We identified diverse applications of LLMs in mental health care,\nincluding diagnosis, therapy, patient engagement enhancement, etc. Key\nchallenges include data availability and reliability, nuanced handling of\nmental states, and effective evaluation methods. Despite successes in accuracy\nand accessibility improvement, gaps in clinical applicability and ethical\nconsiderations were evident, pointing to the need for robust data, standardized\nevaluations, and interdisciplinary collaboration. Conclusion: LLMs show\npromising potential in advancing mental health care, with applications in\ndiagnostics, and patient support. Continued advancements depend on\ncollaborative, multidisciplinary efforts focused on framework enhancement,\nrigorous dataset development, technological refinement, and ethical integration\nto ensure the effective and safe application of LLMs in mental health care.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yining Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kailai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zehan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheu_Y/0/1/0/all/0/1\">Yi-han Sheu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peilin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_L/0/1/0/all/0/1\">Lauren V. Moran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1\">Sophia Ananiadou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1\">Andrew Beam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Large Language Models on the GMAT: Implications for the Future of Business Education. (arXiv:2401.02985v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02985","description":"<p>The rapid evolution of artificial intelligence (AI), especially in the domain\nof Large Language Models (LLMs) and generative AI, has opened new avenues for\napplication across various fields, yet its role in business education remains\nunderexplored. This study introduces the first benchmark to assess the\nperformance of seven major LLMs, OpenAI's models (GPT-3.5 Turbo, GPT-4, and\nGPT-4 Turbo), Google's models (PaLM 2, Gemini 1.0 Pro), and Anthropic's models\n(Claude 2 and Claude 2.1), on the GMAT, which is a key exam in the admission\nprocess for graduate business programs. Our analysis shows that most LLMs\noutperform human candidates, with GPT-4 Turbo not only outperforming the other\nmodels but also surpassing the average scores of graduate students at top\nbusiness schools. Through a case study, this research examines GPT-4 Turbo's\nability to explain answers, evaluate responses, identify errors, tailor\ninstructions, and generate alternative scenarios. The latest LLM versions,\nGPT-4 Turbo, Claude 2.1, and Gemini 1.0 Pro, show marked improvements in\nreasoning tasks compared to their predecessors, underscoring their potential\nfor complex problem-solving. While AI's promise in education, assessment, and\ntutoring is clear, challenges remain. Our study not only sheds light on LLMs'\nacademic potential but also emphasizes the need for careful development and\napplication of AI in education. As AI technology advances, it is imperative to\nestablish frameworks and protocols for AI interaction, verify the accuracy of\nAI-generated content, ensure worldwide access for diverse learners, and create\nan educational environment where AI supports human expertise. This research\nsets the stage for further exploration into the responsible use of AI to enrich\neducational experiences and improve exam preparation and assessment methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ashrafimoghari_V/0/1/0/all/0/1\">Vahid Ashrafimoghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurkan_N/0/1/0/all/0/1\">Necdet G&#xfc;rkan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suchow_J/0/1/0/all/0/1\">Jordan W. Suchow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identification of Regulatory Requirements Relevant to Business Processes: A Comparative Study on Generative AI, Embedding-based Ranking, Crowd and Expert-driven Methods. (arXiv:2401.02986v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02986","description":"<p>Organizations face the challenge of ensuring compliance with an increasing\namount of requirements from various regulatory documents. Which requirements\nare relevant depends on aspects such as the geographic location of the\norganization, its domain, size, and business processes. Considering these\ncontextual factors, as a first step, relevant documents (e.g., laws,\nregulations, directives, policies) are identified, followed by a more detailed\nanalysis of which parts of the identified documents are relevant for which step\nof a given business process. Nowadays the identification of regulatory\nrequirements relevant to business processes is mostly done manually by domain\nand legal experts, posing a tremendous effort on them, especially for a large\nnumber of regulatory documents which might frequently change. Hence, this work\nexamines how legal and domain experts can be assisted in the assessment of\nrelevant requirements. For this, we compare an embedding-based NLP ranking\nmethod, a generative AI method using GPT-4, and a crowdsourced method with the\npurely manual method of creating relevancy labels by experts. The proposed\nmethods are evaluated based on two case studies: an Australian insurance case\ncreated with domain experts and a global banking use case, adapted from SAP\nSignavio's workflow example of an international guideline. A gold standard is\ncreated for both BPMN2.0 processes and matched to real-world textual\nrequirements from multiple regulatory documents. The evaluation and discussion\nprovide insights into strengths and weaknesses of each method regarding\napplicability, automation, transparency, and reproducibility and provide\nguidelines on which method combinations will maximize benefits for given\ncharacteristics such as process usage, impact, and dynamics of an application\nscenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sai_C/0/1/0/all/0/1\">Catherine Sai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadiq_S/0/1/0/all/0/1\">Shazia Sadiq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demartini_G/0/1/0/all/0/1\">Gianluca Demartini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rinderle_Ma_S/0/1/0/all/0/1\">Stefanie Rinderle-Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02987","description":"<p>The emergence of pretrained models has significantly impacted from Natural\nLanguage Processing (NLP) and Computer Vision to relational datasets.\nTraditionally, these models are assessed through fine-tuned downstream tasks.\nHowever, this raises the question of how to evaluate these models more\nefficiently and more effectively. In this study, we explore a novel approach\nwhere we leverage the meta features associated with each entity as a source of\nworldly knowledge and employ entity representations from the models. We propose\nusing the consistency between these representations and the meta features as a\nmetric for evaluating pretrained models. Our method's effectiveness is\ndemonstrated across various domains, including models with relational datasets,\nlarge language models and images models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aboagye_P/0/1/0/all/0/1\">Prince Aboagye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junpeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saini_U/0/1/0/all/0/1\">Uday Singh Saini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xin Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_M/0/1/0/all/0/1\">Michael Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yujie Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1\">Zhongfang Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shubham Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Latent Dirichlet Allocation (LDA) Semantic Text Analytics Approach to Explore Topical Features in Charity Crowdfunding Campaigns. (arXiv:2401.02988v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02988","description":"<p>Crowdfunding in the realm of the Social Web has received substantial\nattention, with prior research examining various aspects of campaigns,\nincluding project objectives, durations, and influential project categories for\nsuccessful fundraising. These factors are crucial for entrepreneurs seeking\ndonor support. However, the terrain of charity crowdfunding within the Social\nWeb remains relatively unexplored, lacking comprehension of the motivations\ndriving donations that often lack concrete reciprocation. Distinct from\nconventional crowdfunding that offers tangible returns, charity crowdfunding\nrelies on intangible rewards like tax advantages, recognition posts, or\nadvisory roles. Such details are often embedded within campaign narratives,\nyet, the analysis of textual content in charity crowdfunding is limited. This\nstudy introduces an inventive text analytics framework, utilizing Latent\nDirichlet Allocation (LDA) to extract latent themes from textual descriptions\nof charity campaigns. The study has explored four different themes, two each in\ncampaign and incentive descriptions. Campaign description themes are focused on\nchild and elderly health mainly the ones who are diagnosed with terminal\ndiseases. Incentive description themes are based on tax benefits, certificates,\nand appreciation posts. These themes, combined with numerical parameters,\npredict campaign success. The study was successful in using Random Forest\nClassifier to predict success of the campaign using both thematic and numerical\nparameters. The study distinguishes thematic categories, particularly medical\nneed-based charity and general causes, based on project and incentive\ndescriptions. In conclusion, this research bridges the gap by showcasing topic\nmodelling utility in uncharted charity crowdfunding domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muzumdar_P/0/1/0/all/0/1\">Prathamesh Muzumdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurian_G/0/1/0/all/0/1\">George Kurian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basyal_G/0/1/0/all/0/1\">Ganga Prasad Basyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GLIDE-RL: Grounded Language Instruction through DEmonstration in RL. (arXiv:2401.02991v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02991","description":"<p>One of the final frontiers in the development of complex human - AI\ncollaborative systems is the ability of AI agents to comprehend the natural\nlanguage and perform tasks accordingly. However, training efficient\nReinforcement Learning (RL) agents grounded in natural language has been a\nlong-standing challenge due to the complexity and ambiguity of the language and\nsparsity of the rewards, among other factors. Several advances in reinforcement\nlearning, curriculum learning, continual learning, language models have\nindependently contributed to effective training of grounded agents in various\nenvironments. Leveraging these developments, we present a novel algorithm,\nGrounded Language Instruction through DEmonstration in RL (GLIDE-RL) that\nintroduces a teacher-instructor-student curriculum learning framework for\ntraining an RL agent capable of following natural language instructions that\ncan generalize to previously unseen language instructions. In this multi-agent\nframework, the teacher and the student agents learn simultaneously based on the\nstudent's current skill level. We further demonstrate the necessity for\ntraining the student agent with not just one, but multiple teacher agents.\nExperiments on a complex sparse reward environment validates the effectiveness\nof our proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kharyal_C/0/1/0/all/0/1\">Chaitanya Kharyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gottipati_S/0/1/0/all/0/1\">Sai Krishna Gottipati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_T/0/1/0/all/0/1\">Tanmay Kumar Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Srijita Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1\">Matthew E. Taylor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advanced Unstructured Data Processing for ESG Reports: A Methodology for Structured Transformation and Enhanced Analysis. (arXiv:2401.02992v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02992","description":"<p>In the evolving field of corporate sustainability, analyzing unstructured\nEnvironmental, Social, and Governance (ESG) reports is a complex challenge due\nto their varied formats and intricate content. This study introduces an\ninnovative methodology utilizing the \"Unstructured Core Library\", specifically\ntailored to address these challenges by transforming ESG reports into\nstructured, analyzable formats. Our approach significantly advances the\nexisting research by offering high-precision text cleaning, adept\nidentification and extraction of text from images, and standardization of\ntables within these reports. Emphasizing its capability to handle diverse data\ntypes, including text, images, and tables, the method adeptly manages the\nnuances of differing page layouts and report styles across industries. This\nresearch marks a substantial contribution to the fields of industrial ecology\nand corporate sustainability assessment, paving the way for the application of\nadvanced NLP technologies and large language models in the analysis of\ncorporate governance and sustainability. Our code is available at\nhttps://github.com/linancn/TianGong-AI-Unstructure.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jiahui Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jing Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1\">Xin Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jianchuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruiqiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1\">Nan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Ming Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Natural Language Understanding with Computation-Efficient Retrieval Representation Fusion. (arXiv:2401.02993v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02993","description":"<p>Retrieval-based augmentations that aim to incorporate knowledge from an\nexternal database into language models have achieved great success in various\nknowledge-intensive (KI) tasks, such as question-answering and text generation.\nHowever, integrating retrievals in non-knowledge-intensive (NKI) tasks, such as\ntext classification, is still challenging. Existing works focus on\nconcatenating retrievals to inputs as context to form the prompt-based inputs.\nUnfortunately, such methods require language models to have the capability to\nhandle long texts. Besides, inferring such concatenated data would also consume\na significant amount of computational resources.\n</p>\n<p>To solve these challenges, we propose \\textbf{ReFusion} in this paper, a\ncomputation-efficient \\textbf{Re}trieval representation \\textbf{Fusion} with\nneural architecture search. The main idea is to directly fuse the retrieval\nrepresentations into the language models. Specifically, we first propose an\nonline retrieval module that retrieves representations of similar sentences.\nThen, we present a retrieval fusion module including two effective ranking\nschemes, i.e., reranker-based scheme and ordered-mask-based scheme, to fuse the\nretrieval representations with hidden states. Furthermore, we use Neural\nArchitecture Search (NAS) to seek the optimal fusion structure across different\nlayers. Finally, we conduct comprehensive experiments, and the results\ndemonstrate our ReFusion can achieve superior and robust performance on various\nNKI tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shangyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Ying Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1\">Yufei Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_B/0/1/0/all/0/1\">Buzhou Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_T/0/1/0/all/0/1\">Tei-Wei Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1\">Chun Jason Xue</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM. (arXiv:2401.02994v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02994","description":"<p>In conversational AI research, there's a noticeable trend towards developing\nmodels with a larger number of parameters, exemplified by models like ChatGPT.\nWhile these expansive models tend to generate increasingly better chat\nresponses, they demand significant computational resources and memory. This\nstudy explores a pertinent question: Can a combination of smaller models\ncollaboratively achieve comparable or enhanced performance relative to a\nsingular large model? We introduce an approach termed \"blending\", a\nstraightforward yet effective method of integrating multiple chat AIs. Our\nempirical evidence suggests that when specific smaller models are\nsynergistically blended, they can potentially outperform or match the\ncapabilities of much larger counterparts. For instance, integrating just three\nmodels of moderate size (6B/13B paramaeters) can rival or even surpass the\nperformance metrics of a substantially larger model like ChatGPT (175B+\nparamaters). This hypothesis is rigorously tested using A/B testing\nmethodologies with a large user base on the Chai research platform over a span\nof thirty days. The findings underscore the potential of the \"blending\"\nstrategy as a viable approach for enhancing chat AI efficacy without a\ncorresponding surge in computational demands.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xiaoding Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vyas Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beauchamp_W/0/1/0/all/0/1\">William Beauchamp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CANAMRF: An Attention-Based Model for Multimodal Depression Detection. (arXiv:2401.02995v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02995","description":"<p>Multimodal depression detection is an important research topic that aims to\npredict human mental states using multimodal data. Previous methods treat\ndifferent modalities equally and fuse each modality by na\\\"ive mathematical\noperations without measuring the relative importance between them, which cannot\nobtain well-performed multimodal representations for downstream depression\ntasks. In order to tackle the aforementioned concern, we present a Cross-modal\nAttention Network with Adaptive Multi-modal Recurrent Fusion (CANAMRF) for\nmultimodal depression detection. CANAMRF is constructed by a multimodal feature\nextractor, an Adaptive Multimodal Recurrent Fusion module, and a Hybrid\nAttention Module. Through experimentation on two benchmark datasets, CANAMRF\ndemonstrates state-of-the-art performance, underscoring the effectiveness of\nour proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yuntao Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuzhe Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blar-SQL: Faster, Stronger, Smaller NL2SQL. (arXiv:2401.02997v1 [cs.CL])","link":"http://arxiv.org/abs/2401.02997","description":"<p>Large Language Models (LLMs) have gained considerable notoriety in the field\nof natural language to SQL tasks (NL2SQL). In this study, we show how task\ndecomposition can greatly benefit LLMs in database understanding and query\ngeneration in order to answer human questions with an SQL query.\n</p>\n<p>We fined-tuned open source models, specifically Llama-2 and Code Llama, by\ncombining 2 different models each designated to focus on one of two tasks in\norder to leverage each model's core competency to further increase the accuracy\nof the final SQL query.\n</p>\n<p>We propose a new framework to divide the schema into chunks in order to fit\nmore information into a limited context. Our results are comparable with those\nobtained by GPT-4 at the same time being 135 times smaller, 90 times faster and\nmore than 100 times cheaper than GPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dominguez_J/0/1/0/all/0/1\">Jos&#xe9; Manuel Dom&#xed;nguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Errazuriz_B/0/1/0/all/0/1\">Benjam&#xed;n Err&#xe1;zuriz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daher_P/0/1/0/all/0/1\">Patricio Daher</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AST-T5: Structure-Aware Pretraining for Code Generation and Understanding. (arXiv:2401.03003v1 [cs.SE])","link":"http://arxiv.org/abs/2401.03003","description":"<p>Large language models (LLMs) have made significant advancements in\ncode-related tasks, yet many LLMs treat code as simple sequences, neglecting\nits structured nature. We introduce AST-T5, a novel pretraining paradigm that\nleverages the Abstract Syntax Tree (AST) for enhanced code generation,\ntranspilation, and understanding. Using dynamic programming, our AST-Aware\nSegmentation retains code structure, while our AST-Aware Span Corruption\nobjective equips the model to reconstruct various code structures. Unlike other\nmodels, AST-T5 avoids intricate program analyses or architectural changes, so\nit integrates seamlessly with any encoder-decoder Transformer. Evaluations show\nthat AST-T5 consistently outperforms similar-sized LMs across various\ncode-related tasks. Structure-awareness makes AST-T5 particularly powerful in\ncode-to-code tasks, surpassing CodeT5 by 2 points in exact match score for the\nBugs2Fix task and by 3 points in exact match score for Java-C# Transpilation in\nCodeXGLUE. Our code and model are publicly available at\nhttps://github.com/gonglinyuan/ast_t5.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gong_L/0/1/0/all/0/1\">Linyuan Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1\">Mostafa Elhoushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_A/0/1/0/all/0/1\">Alvin Cheung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Gender Biases in Language Patterns of Human-Conversational Agent Conversations. (arXiv:2401.03030v1 [cs.HC])","link":"http://arxiv.org/abs/2401.03030","description":"<p>With the rise of human-machine communication, machines are increasingly\ndesigned with humanlike characteristics, such as gender, which can\ninadvertently trigger cognitive biases. Many conversational agents (CAs), such\nas voice assistants and chatbots, default to female personas, leading to\nconcerns about perpetuating gender stereotypes and inequality. Critiques have\nemerged regarding the potential objectification of females and reinforcement of\ngender stereotypes by these technologies. This research, situated in\nconversational AI design, aims to delve deeper into the impacts of gender\nbiases in human-CA interactions. From a behavioral and communication research\nstandpoint, this program focuses not only on perceptions but also the\nlinguistic styles of users when interacting with CAs, as previous research has\nrarely explored. It aims to understand how pre-existing gender biases might be\ntriggered by CAs' gender designs. It further investigates how CAs' gender\ndesigns may reinforce gender biases and extend them to human-human\ncommunication. The findings aim to inform ethical design of conversational\nagents, addressing whether gender assignment in CAs is appropriate and how to\npromote gender equality in design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weizi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Examining Forgetting in Continual Pre-training of Aligned Large Language Models. (arXiv:2401.03129v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03129","description":"<p>Recent advances in Large Language Models (LLMs) have exhibited remarkable\nproficiency across various tasks. Given the potent applications of LLMs in\nnumerous fields, there has been a surge in LLM development. In developing LLMs,\na common practice involves continual pre-training on previously fine-tuned\nmodels. However, this can lead to catastrophic forgetting. In our work, we\ninvestigate the phenomenon of forgetting that occurs during continual\npre-training on an existing fine-tuned LLM. We evaluate the impact of\ncontinuous pre-training on the fine-tuned LLM across various dimensions,\nincluding output format, knowledge, and reliability. Experiment results\nhighlight the non-trivial challenge of addressing catastrophic forgetting\nduring continual pre-training, especially the repetition issue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen-An Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing Short Text Classification. (arXiv:2401.03158v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03158","description":"<p>Short Text Classification (STC) is crucial for processing and comprehending\nthe brief but substantial content prevalent on contemporary digital platforms.\nThe STC encounters difficulties in grasping semantic and syntactic intricacies,\nan issue that is apparent in traditional pre-trained language models. Although\nGraph Convolutional Networks enhance performance by integrating external\nknowledge bases, these methods are limited by the quality and extent of the\nknowledge applied. Recently, the emergence of Large Language Models (LLMs) and\nChain-of-Thought (CoT) has significantly improved the performance of complex\nreasoning tasks. However, some studies have highlighted the limitations of\ntheir application in fundamental NLP tasks. Consequently, this study sought to\nemploy CoT to investigate the capabilities of LLMs in STC tasks. This study\nintroduces Quartet Logic: A Four-Step Reasoning (QLFR) framework. This\nframework primarily incorporates Syntactic and Semantic Enrichment CoT,\neffectively decomposing the STC task into four distinct steps: (i) essential\nconcept identification, (ii) common-sense knowledge retrieval, (iii) text\nrewriting, and (iv) classification. This elicits the inherent knowledge and\nabilities of LLMs to address the challenges in STC. Surprisingly, we found that\nQLFR can also improve the performance of smaller models. Therefore, we\ndeveloped a CoT-Driven Multi-task learning (QLFR-CML) method to facilitate the\nknowledge transfer from LLMs to smaller models. Extensive experimentation\nacross six short-text benchmarks validated the efficacy of the proposed\nmethods. Notably, QLFR achieved state-of-the-art performance on all datasets,\nwith significant improvements, particularly on the Ohsumed and TagMyNews\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hui Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanben Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhonghe Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yingyan Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Q/0/1/0/all/0/1\">Qihang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yunping Ge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Part-of-Speech Tagger for Bodo Language using Deep Learning approach. (arXiv:2401.03175v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03175","description":"<p>Language Processing systems such as Part-of-speech tagging, Named entity\nrecognition, Machine translation, Speech recognition, and Language modeling\n(LM) are well-studied in high-resource languages. Nevertheless, research on\nthese systems for several low-resource languages, including Bodo, Mizo,\nNagamese, and others, is either yet to commence or is in its nascent stages.\nLanguage model plays a vital role in the downstream tasks of modern NLP.\nExtensive studies are carried out on LMs for high-resource languages.\nNevertheless, languages such as Bodo, Rabha, and Mising continue to lack\ncoverage. In this study, we first present BodoBERT, a language model for the\nBodo language. To the best of our knowledge, this work is the first such effort\nto develop a language model for Bodo. Secondly, we present an ensemble DL-based\nPOS tagging model for Bodo. The POS tagging model is based on combinations of\nBiLSTM with CRF and stacked embedding of BodoBERT with BytePairEmbeddings. We\ncover several language models in the experiment to see how well they work in\nPOS tagging tasks. The best-performing model achieves an F1 score of 0.8041. A\ncomparative experiment was also conducted on Assamese POS taggers, considering\nthat the language is spoken in the same region as Bodo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1\">Dhrubajyoti Pathak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narzary_S/0/1/0/all/0/1\">Sanjib Narzary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nandi_S/0/1/0/all/0/1\">Sukumar Nandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Som_B/0/1/0/all/0/1\">Bidisha Som</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text-Video Retrieval via Variational Multi-Modal Hypergraph Networks. (arXiv:2401.03177v1 [cs.CV])","link":"http://arxiv.org/abs/2401.03177","description":"<p>Text-video retrieval is a challenging task that aims to identify relevant\nvideos given textual queries. Compared to conventional textual retrieval, the\nmain obstacle for text-video retrieval is the semantic gap between the textual\nnature of queries and the visual richness of video content. Previous works\nprimarily focus on aligning the query and the video by finely aggregating\nword-frame matching signals. Inspired by the human cognitive process of\nmodularly judging the relevance between text and video, the judgment needs\nhigh-order matching signal due to the consecutive and complex nature of video\ncontents. In this paper, we propose chunk-level text-video matching, where the\nquery chunks are extracted to describe a specific retrieval unit, and the video\nchunks are segmented into distinct clips from videos. We formulate the\nchunk-level matching as n-ary correlations modeling between words of the query\nand frames of the video and introduce a multi-modal hypergraph for n-ary\ncorrelation modeling. By representing textual units and video frames as nodes\nand using hyperedges to depict their relationships, a multi-modal hypergraph is\nconstructed. In this way, the query and the video can be aligned in a\nhigh-order semantic space. In addition, to enhance the model's generalization\nability, the extracted features are fed into a variational inference component\nfor computation, obtaining the variational representation under the Gaussian\ndistribution. The incorporation of hypergraphs and variational inference allows\nour model to capture complex, n-ary interactions among textual and visual\ncontents. Experimental results demonstrate that our proposed method achieves\nstate-of-the-art performance on the text-video retrieval task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Lixin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jiashu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1\">Long Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hengyi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Suqi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Hengzhu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Dawei Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Joint-Reasoning based Disease Q&A System. (arXiv:2401.03181v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03181","description":"<p>Medical question answer (QA) assistants respond to lay users' health-related\nqueries by synthesizing information from multiple sources using natural\nlanguage processing and related techniques. They can serve as vital tools to\nalleviate issues of misinformation, information overload, and complexity of\nmedical language, thus addressing lay users' information needs while reducing\nthe burden on healthcare professionals. QA systems, the engines of such\nassistants, have typically used either language models (LMs) or knowledge\ngraphs (KG), though the approaches could be complementary. LM-based QA systems\nexcel at understanding complex questions and providing well-formed answers, but\nare prone to factual mistakes. KG-based QA systems, which represent facts well,\nare mostly limited to answering short-answer questions with pre-created\ntemplates. While a few studies have jointly used LM and KG approaches for\ntext-based QA, this was done to answer multiple-choice questions. Extant QA\nsystems also have limitations in terms of automation and performance. We\naddress these challenges by designing a novel, automated disease QA system\nwhich effectively utilizes both LM and KG techniques through a joint-reasoning\napproach to answer disease-related questions appropriate for lay users. Our\nevaluation of the system using a range of quality metrics demonstrates its\nefficacy over benchmark systems, including the popular ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sukhwal_P/0/1/0/all/0/1\">Prakash Chandra Sukhwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_V/0/1/0/all/0/1\">Vaibhav Rajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankanhalli_A/0/1/0/all/0/1\">Atreyi Kankanhalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"{\\delta}-CAUSAL: Exploring Defeasibility in Causal Reasoning. (arXiv:2401.03183v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03183","description":"<p>Defeasibility in causal reasoning implies that the causal relationship\nbetween cause and effect can be strengthened or weakened. Namely, the causal\nstrength between cause and effect should increase or decrease with the\nincorporation of strengthening arguments (supporters) or weakening arguments\n(defeaters), respectively. However, existing works ignore defeasibility in\ncausal reasoning and fail to evaluate existing causal strength metrics in\ndefeasible settings. In this work, we present {\\delta}-CAUSAL, the first\nbenchmark dataset for studying defeasibility in causal reasoning.\n{\\delta}-CAUSAL includes around 11K events spanning ten domains, featuring\ndefeasible causality pairs, i.e., cause-effect pairs accompanied by supporters\nand defeaters. We further show current causal strength metrics fail to reflect\nthe change of causal strength with the incorporation of supporters or defeaters\nin {\\delta}-CAUSAL. To this end, we propose CESAR (Causal Embedding aSsociation\nwith Attention Rating), a metric that measures causal strength based on\ntoken-level causal relationships. CESAR achieves a significant 69.7% relative\nimprovement over existing metrics, increasing from 47.2% to 80.1% in capturing\nthe causal strength change brought by supporters and defeaters. We further\ndemonstrate even Large Language Models (LLMs) like GPT-3.5 still lag 4.5 and\n10.7 points behind humans in generating supporters and defeaters, emphasizing\nthe challenge posed by {\\delta}-CAUSAL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shaobo Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milikic_L/0/1/0/all/0/1\">Lazar Milikic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yiyang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ismayilzada_M/0/1/0/all/0/1\">Mete Ismayilzada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjit Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1\">Boi Faltings</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model Editing. (arXiv:2401.03190v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03190","description":"<p>Large language models are known for encoding a vast amount of factual\nknowledge, but they often becomes outdated due to the ever-changing nature of\nexternal information. A promising solution to this challenge is the utilization\nof model editing methods to update the knowledge in an efficient manner.\nHowever, the majority of existing model editing techniques are limited to\nmonolingual frameworks, thus failing to address the crucial issue of\ncross-lingual knowledge synchronization for multilingual models. To tackle this\nproblem, we propose a simple yet effective method that trains multilingual\npatch neuron to store cross-lingual knowledge. It can be easily adapted to\nexisting approaches to enhance their cross-lingual editing capabilities. To\nevaluate our method, we conduct experiments using both the XNLI dataset and a\nself-constructed XFEVER dataset. Experimental results demonstrate that our\nproposed method achieves improved performance in cross-lingual editing tasks\nwithout requiring excessive modifications to the original methodology, thereby\nshowcasing its user-friendly characteristics. Codes will be released soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_N/0/1/0/all/0/1\">Nianwen Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weiqiang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models. (arXiv:2401.03205v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03205","description":"<p>In the era of large language models (LLMs), hallucination (i.e., the tendency\nto generate factually incorrect content) poses great challenge to trustworthy\nand reliable deployment of LLMs in real-world applications. To tackle the LLM\nhallucination, three key questions should be well studied: how to detect\nhallucinations (detection), why do LLMs hallucinate (source), and what can be\ndone to mitigate them (mitigation). To address these challenges, this work\npresents a systematic empirical study on LLM hallucination, focused on the the\nthree aspects of hallucination detection, source and mitigation. Specially, we\nconstruct a new hallucination benchmark HaluEval 2.0, and designs a simple yet\neffective detection method for LLM hallucination. Furthermore, we zoom into the\ndifferent training or utilization stages of LLMs and extensively analyze the\npotential factors that lead to the LLM hallucination. Finally, we implement and\nexamine a series of widely used techniques to mitigate the hallucinations in\nLLMs. Our work has led to several important findings to understand the\nhallucination origin and mitigate the hallucinations in LLMs. Our code and data\ncan be accessed at https://github.com/RUCAIBox/HaluEval-2.0.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xiaoxue Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reflections on Inductive Thematic Saturation as a potential metric for measuring the validity of an inductive Thematic Analysis with LLMs. (arXiv:2401.03239v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03239","description":"<p>This paper presents a set of reflections on saturation and the use of Large\nLanguage Models (LLMs) for performing Thematic Analysis (TA). The paper\nsuggests that initial thematic saturation (ITS) could be used as a metric to\nassess part of the transactional validity of TA with LLM, focusing on the\ninitial coding. The paper presents the initial coding of two datasets of\ndifferent sizes, and it reflects on how the LLM reaches some form of analytical\nsaturation during the coding. The procedure proposed in this work leads to the\ncreation of two codebooks, one comprising the total cumulative initial codes\nand the other the total unique codes. The paper proposes a metric to\nsynthetically measure ITS using a simple mathematical calculation employing the\nratio between slopes of cumulative codes and unique codes. The paper\ncontributes to the initial body of work exploring how to perform qualitative\nanalysis with LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paoli_S/0/1/0/all/0/1\">Stefano De Paoli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathis_W/0/1/0/all/0/1\">Walter Stan Mathis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Visual Cross-Domain Learners. (arXiv:2401.03253v1 [cs.CV])","link":"http://arxiv.org/abs/2401.03253","description":"<p>Recent advances achieved by deep learning models rely on the independent and\nidentically distributed assumption, hindering their applications in real-world\nscenarios with domain shifts. To address the above issues, cross-domain\nlearning aims at extracting domain-invariant knowledge to reduce the domain\nshift between training and testing data. However, in visual cross-domain\nlearning, traditional methods concentrate solely on the image modality,\nneglecting the use of the text modality to alleviate the domain shift. In this\nwork, we propose Large Language models as Visual cross-dOmain learners (LLaVO).\nLLaVO uses vision-language models to convert images into detailed textual\ndescriptions. A large language model is then finetuned on textual descriptions\nof the source/target domain generated by a designed instruction template.\nExtensive experimental results on various cross-domain tasks under the domain\ngeneralization and unsupervised domain adaptation settings have demonstrated\nthe effectiveness of the proposed method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yulong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weisen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jiangang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Context Through Contrast. (arXiv:2401.03314v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03314","description":"<p>Neural machine translation benefits from semantically rich representations.\nConsiderable progress in learning such representations has been achieved by\nlanguage modelling and mutual information maximization objectives using\ncontrastive learning. The language-dependent nature of language modelling\nintroduces a trade-off between the universality of the learned representations\nand the model's performance on the language modelling tasks. Although\ncontrastive learning improves performance, its success cannot be attributed to\nmutual information alone. We propose a novel Context Enhancement step to\nimprove performance on neural machine translation by maximizing mutual\ninformation using the Barlow Twins loss. Unlike other approaches, we do not\nexplicitly augment the data but view languages as implicit augmentations,\neradicating the risk of disrupting semantic information. Further, our method\ndoes not learn embeddings from scratch and can be generalised to any set of\npre-trained embeddings. Finally, we evaluate the language-agnosticism of our\nembeddings through language classification and use them for neural machine\ntranslation to compare with state-of-the-art approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ambilduke_K/0/1/0/all/0/1\">Kshitij Ambilduke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shetye_A/0/1/0/all/0/1\">Aneesh Shetye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagade_D/0/1/0/all/0/1\">Diksha Bagade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhagwatkar_R/0/1/0/all/0/1\">Rishika Bhagwatkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fitter_K/0/1/0/all/0/1\">Khurshed Fitter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vagdargi_P/0/1/0/all/0/1\">Prasad Vagdargi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiddarwar_S/0/1/0/all/0/1\">Shital Chiddarwar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PIXAR: Auto-Regressive Language Modeling in Pixel Space. (arXiv:2401.03321v1 [cs.CL])","link":"http://arxiv.org/abs/2401.03321","description":"<p>Recent works showed the possibility of building open-vocabulary large\nlanguage models (LLMs) that directly operate on pixel representations and are\nimplemented as encoder-decoder models that reconstruct masked image patches of\nrendered text. However, these pixel-based LLMs are limited to autoencoding\ntasks and cannot generate new text as images. As such, they cannot be used for\nopen-answer or generative language tasks. In this work, we overcome this\nlimitation and introduce PIXAR, the first pixel-based autoregressive LLM that\ndoes not rely on a pre-defined vocabulary for both input and output text.\nConsisting of only a decoder, PIXAR can answer free-form generative tasks while\nkeeping the text representation learning performance on par with previous\nencoder-decoder models. Furthermore, we highlight the challenges to\nautoregressively generate non-blurred text as images and link this to the usual\nmaximum likelihood objective. We propose a simple adversarial pretraining that\nsignificantly improves the readability and performance of PIXAR making it\ncomparable to GPT2 on short text generation tasks. This paves the way to\nbuilding open-vocabulary LLMs that are usable for free-form generative tasks\nand questions the necessity of the usual symbolic input representation -- text\nas tokens -- for these challenging tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1\">Yintao Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xiyang Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suglia_A/0/1/0/all/0/1\">Alessandro Suglia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1\">Antonio Vergari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Investigation of Large Language Models for Real-World Hate Speech Detection. (arXiv:2401.03346v1 [cs.CY])","link":"http://arxiv.org/abs/2401.03346","description":"<p>Hate speech has emerged as a major problem plaguing our social spaces today.\nWhile there have been significant efforts to address this problem, existing\nmethods are still significantly limited in effectively detecting hate speech\nonline. A major limitation of existing methods is that hate speech detection is\na highly contextual problem, and these methods cannot fully capture the context\nof hate speech to make accurate predictions. Recently, large language models\n(LLMs) have demonstrated state-of-the-art performance in several natural\nlanguage tasks. LLMs have undergone extensive training using vast amounts of\nnatural language data, enabling them to grasp intricate contextual details.\nHence, they could be used as knowledge bases for context-aware hate speech\ndetection. However, a fundamental problem with using LLMs to detect hate speech\nis that there are no studies on effectively prompting LLMs for context-aware\nhate speech detection. In this study, we conduct a large-scale study of hate\nspeech detection, employing five established hate speech datasets. We discover\nthat LLMs not only match but often surpass the performance of current benchmark\nmachine learning models in identifying hate speech. By proposing four diverse\nprompting strategies that optimize the use of LLMs in detecting hate speech.\nOur study reveals that a meticulously crafted reasoning prompt can effectively\ncapture the context of hate speech by fully utilizing the knowledge base in\nLLMs, significantly outperforming existing techniques. Furthermore, although\nLLMs can provide a rich knowledge base for the contextual detection of hate\nspeech, suitable prompting strategies play a crucial role in effectively\nleveraging this knowledge base for efficient detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Keyan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1\">Alexander Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1\">Jaden Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Ziheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Ziming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vishwamitra_N/0/1/0/all/0/1\">Nishant Vishwamitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hongxin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Token-Modification Adversarial Attacks for Natural Language Processing: A Survey. (arXiv:2103.00676v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.00676","description":"<p>Many adversarial attacks target natural language processing systems, most of\nwhich succeed through modifying the individual tokens of a document. Despite\nthe apparent uniqueness of each of these attacks, fundamentally they are simply\na distinct configuration of four components: a goal function, allowable\ntransformations, a search method, and constraints. In this survey, we\nsystematically present the different components used throughout the literature,\nusing an attack-independent framework which allows for easy comparison and\ncategorisation of components. Our work aims to serve as a comprehensive guide\nfor newcomers to the field and to spark targeted research into refining the\nindividual attack components.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roth_T/0/1/0/all/0/1\">Tom Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yansong Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abuadbba_A/0/1/0/all/0/1\">Alsharif Abuadbba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nepal_S/0/1/0/all/0/1\">Surya Nepal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Visual Grounding by Encouraging Consistent Gradient-based Explanations. (arXiv:2206.15462v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2206.15462","description":"<p>We propose a margin-based loss for tuning joint vision-language models so\nthat their gradient-based explanations are consistent with region-level\nannotations provided by humans for relatively smaller grounding datasets. We\nrefer to this objective as Attention Mask Consistency (AMC) and demonstrate\nthat it produces superior visual grounding results than previous methods that\nrely on using vision-language models to score the outputs of object detectors.\nParticularly, a model trained with AMC on top of standard vision-language\nmodeling objectives obtains a state-of-the-art accuracy of 86.49% in the\nFlickr30k visual grounding benchmark, an absolute improvement of 5.38% when\ncompared to the best previous model trained under the same level of\nsupervision. Our approach also performs exceedingly well on established\nbenchmarks for referring expression comprehension where it obtains 80.34%\naccuracy in the easy test of RefCOCO+, and 64.55% in the difficult split. AMC\nis effective, easy to implement, and is general as it can be adopted by any\nvision-language model, and can use any type of region annotations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Ziyan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kafle_K/0/1/0/all/0/1\">Kushal Kafle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ordonez_V/0/1/0/all/0/1\">Vicente Ordonez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Human-Language Model Interaction. (arXiv:2212.09746v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09746","description":"<p>Many real-world applications of language models (LMs), such as writing\nassistance and code autocomplete, involve human-LM interaction. However, most\nbenchmarks are non-interactive in that a model produces output without human\ninvolvement. To evaluate human-LM interaction, we develop a new framework,\nHuman-AI Language-based Interaction Evaluation (HALIE), that defines the\ncomponents of interactive systems and dimensions to consider when designing\nevaluation metrics. Compared to standard, non-interactive evaluation, HALIE\ncaptures (i) the interactive process, not only the final output; (ii) the\nfirst-person subjective experience, not just a third-party assessment; and\n(iii) notions of preference beyond quality (e.g., enjoyment and ownership). We\nthen design five tasks to cover different forms of interaction: social\ndialogue, question answering, crossword puzzles, summarization, and metaphor\ngeneration. With four state-of-the-art LMs (three variants of OpenAI's GPT-3\nand AI21 Labs' Jurassic-1), we find that better non-interactive performance\ndoes not always translate to better human-LM interaction. In particular, we\nhighlight three cases where the results from non-interactive and interactive\nmetrics diverge and underscore the importance of human-LM interaction for LM\nevaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Mina Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1\">Megha Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hardy_A/0/1/0/all/0/1\">Amelia Hardy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1\">John Thickstun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1\">Esin Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paranjape_A/0/1/0/all/0/1\">Ashwin Paranjape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerard_Ursin_I/0/1/0/all/0/1\">Ines Gerard-Ursin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Lisa Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladhak_F/0/1/0/all/0/1\">Faisal Ladhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rong_F/0/1/0/all/0/1\">Frieda Rong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rose E. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_M/0/1/0/all/0/1\">Minae Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Joon Sung Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_H/0/1/0/all/0/1\">Hancheng Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Tony Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bommasani_R/0/1/0/all/0/1\">Rishi Bommasani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernstein_M/0/1/0/all/0/1\">Michael Bernstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain. (arXiv:2301.13126v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.13126","description":"<p>Lately, propelled by the phenomenal advances around the transformer\narchitecture, the legal NLP field has enjoyed spectacular growth. To measure\nprogress, well curated and challenging benchmarks are crucial. However, most\nbenchmarks are English only and in legal NLP specifically there is no\nmultilingual benchmark available yet. Additionally, many benchmarks are\nsaturated, with the best models clearly outperforming the best humans and\nachieving near perfect scores. We survey the legal NLP literature and select 11\ndatasets covering 24 languages, creating LEXTREME. To provide a fair\ncomparison, we propose two aggregate scores, one based on the datasets and one\non the languages. The best baseline (XLM-R large) achieves both a dataset\naggregate score a language aggregate score of 61.3. This indicates that\nLEXTREME is still very challenging and leaves ample room for improvement. To\nmake it easy for researchers and practitioners to use, we release LEXTREME on\nhuggingface together with all the code required to evaluate models and a public\nWeights and Biases project with all the runs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niklaus_J/0/1/0/all/0/1\">Joel Niklaus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matoshi_V/0/1/0/all/0/1\">Veton Matoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_P/0/1/0/all/0/1\">Pooja Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galassi_A/0/1/0/all/0/1\">Andrea Galassi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sturmer_M/0/1/0/all/0/1\">Matthias St&#xfc;rmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalkidis_I/0/1/0/all/0/1\">Ilias Chalkidis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey on Instruction Following. (arXiv:2303.10475v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.10475","description":"<p>Task semantics can be expressed by a set of input-output examples or a piece\nof textual instruction. Conventional machine learning approaches for natural\nlanguage processing (NLP) mainly rely on the availability of large-scale sets\nof task-specific examples. Two issues arise: first, collecting task-specific\nlabeled examples does not apply to scenarios where tasks may be too complicated\nor costly to annotate, or the system is required to handle a new task\nimmediately; second, this is not user-friendly since end-users are probably\nmore willing to provide task description rather than a set of examples before\nusing the system. Therefore, the community is paying increasing interest in a\nnew supervision-seeking paradigm for NLP: learning to follow task instructions,\ni.e., instruction following. Despite its impressive progress, there are some\ncommon issues that the community struggles with. This survey paper tries to\nsummarize and provide insights to the current research on instruction\nfollowing, particularly, by answering the following questions: (i) What is task\ninstruction, and what instruction types exist? (ii) How to model instructions?\n(iii) What are popular instruction following datasets and evaluation metrics?\n(iv) What factors influence and explain the instructions' performance? (v) What\nchallenges remain in instruction following? To our knowledge, this is the first\ncomprehensive survey about instruction following.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lou_R/0/1/0/all/0/1\">Renze Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Deep Latent Position Topic Model for Clustering and Representation of Networks with Textual Edges. (arXiv:2304.08242v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2304.08242","description":"<p>Numerical interactions leading to users sharing textual content published by\nothers are naturally represented by a network where the individuals are\nassociated with the nodes and the exchanged texts with the edges. To understand\nthose heterogeneous and complex data structures, clustering nodes into\nhomogeneous groups as well as rendering a comprehensible visualisation of the\ndata is mandatory. To address both issues, we introduce Deep-LPTM, a\nmodel-based clustering strategy relying on a variational graph auto-encoder\napproach as well as a probabilistic model to characterise the topics of\ndiscussion. Deep-LPTM allows to build a joint representation of the nodes and\nof the edges in two embeddings spaces. The parameters are inferred using a\nvariational inference algorithm. We also introduce IC2L, a model selection\ncriterion specifically designed to choose models with relevant clustering and\nvisualisation properties. An extensive benchmark study on synthetic data is\nprovided. In particular, we find that Deep-LPTM better recovers the partitions\nof the nodes than the state-of-the art ETSBM and STBM. Eventually, the emails\nof the Enron company are analysed and visualisations of the results are\npresented, with meaningful highlights of the graph structure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Boutin_R/0/1/0/all/0/1\">R&#xe9;mi Boutin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latouche_P/0/1/0/all/0/1\">Pierre Latouche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bouveyron_C/0/1/0/all/0/1\">Charles Bouveyron</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Building a Non-native Speech Corpus Featuring Chinese-English Bilingual Children: Compilation and Rationale. (arXiv:2305.00446v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.00446","description":"<p>This paper introduces a non-native speech corpus consisting of narratives\nfrom fifty 5- to 6-year-old Chinese-English children. Transcripts totaling 6.5\nhours of children taking a narrative comprehension test in English (L2) are\npresented, along with human-rated scores and annotations of grammatical and\npronunciation errors. The children also completed the parallel MAIN tests in\nChinese (L1) for reference purposes. For all tests we recorded audio and video\nwith our innovative self-developed remote collection methods. The video\nrecordings serve to mitigate the challenge of low intelligibility in L2\nnarratives produced by young children during the transcription process. This\ncorpus offers valuable resources for second language teaching and has the\npotential to enhance the overall performance of automatic speech recognition\n(ASR).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hung_H/0/1/0/all/0/1\">Hiuchung Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maier_A/0/1/0/all/0/1\">Andreas Maier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piske_T/0/1/0/all/0/1\">Thorsten Piske</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explainable Recommender with Geometric Information Bottleneck. (arXiv:2305.05331v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.05331","description":"<p>Explainable recommender systems can explain their recommendation decisions,\nenhancing user trust in the systems. Most explainable recommender systems\neither rely on human-annotated rationales to train models for explanation\ngeneration or leverage the attention mechanism to extract important text spans\nfrom reviews as explanations. The extracted rationales are often confined to an\nindividual review and may fail to identify the implicit features beyond the\nreview text. To avoid the expensive human annotation process and to generate\nexplanations beyond individual reviews, we propose to incorporate a geometric\nprior learnt from user-item interactions into a variational network which\ninfers latent factors from user-item reviews. The latent factors from an\nindividual user-item pair can be used for both recommendation and explanation\ngeneration, which naturally inherit the global characteristics encoded in the\nprior knowledge. Experimental results on three e-commerce datasets show that\nour model significantly improves the interpretability of a variational\nrecommender using the Wasserstein distance while achieving performance\ncomparable to existing content-based recommender systems in terms of\nrecommendation behaviours.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hanqi Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Menghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yulan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HPE:Answering Complex Questions over Text by Hybrid Question Parsing and Execution. (arXiv:2305.07789v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07789","description":"<p>The dominant paradigm of textual question answering systems is based on\nend-to-end neural networks, which excels at answering natural language\nquestions but falls short on complex ones. This stands in contrast to the broad\nadaptation of semantic parsing approaches over structured data sources (e.g.,\nrelational database, knowledge graphs), that convert natural language questions\nto logical forms and execute them with query engines. Towards combining the\nstrengths of neural and symbolic methods, we propose a framework of question\nparsing and execution on textual QA. It comprises two central pillars: (1) We\nparse the question of varying complexity into an intermediate representation,\nnamed H-expression, which is composed of simple questions as the primitives and\nsymbolic operations representing the relationships among them; (2) To execute\nthe resulting H-expressions, we design a hybrid executor, which integrates the\ndeterministic rules to translate the symbolic operations with a drop-in neural\nreader network to answer each decomposed simple question. Hence, the proposed\nframework can be viewed as a top-down question parsing followed by a bottom-up\nanswer backtracking. The resulting H-expressions closely guide the execution\nprocess, offering higher precision besides better interpretability while still\npreserving the advantages of the neural readers for resolving its primitive\nelements. Our extensive experiments on MuSiQue, 2WikiQA, HotpotQA, and NQ show\nthat the proposed parsing and hybrid execution framework outperforms existing\napproaches in supervised, few-shot, and zero-shot settings, while also\neffectively exposing its underlying reasoning process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Language Decomposition and Interpretation of Complex Utterances. (arXiv:2305.08677v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08677","description":"<p>Designing natural language interfaces has historically required collecting\nsupervised data to translate user requests into carefully designed intent\nrepresentations. This requires enumerating and labeling a long tail of user\nrequests, which is challenging. At the same time, large language models (LLMs)\nencode knowledge about goals and plans that can help conversational assistants\ninterpret user requests requiring numerous steps to complete. We introduce an\napproach to handle complex-intent-bearing utterances from a user via a process\nof hierarchical natural language decomposition and interpretation. Our approach\nuses a pre-trained language model to decompose a complex utterance into a\nsequence of simpler natural language steps and interprets each step using the\nlanguage-to-program model designed for the interface. To test our approach, we\ncollect and release DeCU -- a new NL-to-program benchmark to evaluate\nDecomposition of Complex Utterances. Experiments show that the proposed\napproach enables the interpretation of complex utterances with almost no\ncomplex training data, while outperforming standard few-shot prompting\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1\">Harsh Jhamtani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hao Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_P/0/1/0/all/0/1\">Patrick Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_E/0/1/0/all/0/1\">Eran Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Ben Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Language Models Solve Graph Problems in Natural Language?. (arXiv:2305.10037v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10037","description":"<p>Large language models (LLMs) are increasingly adopted for a variety of tasks\nwith implicit graphical structures, such as planning in robotics, multi-hop\nquestion answering or knowledge probing, structured commonsense reasoning, and\nmore. While LLMs have advanced the state-of-the-art on these tasks with\nstructure implications, whether LLMs could explicitly process textual\ndescriptions of graphs and structures, map them to grounded conceptual spaces,\nand perform structured operations remains underexplored. To this end, we\npropose NLGraph (Natural Language Graph), a comprehensive benchmark of\ngraph-based problem solving designed in natural language. NLGraph contains\n29,370 problems, covering eight graph reasoning tasks with varying complexity\nfrom simple tasks such as connectivity and shortest path up to complex problems\nsuch as maximum flow and simulating graph neural networks. We evaluate LLMs\n(GPT-3/4) with various prompting approaches on the NLGraph benchmark and find\nthat 1) language models do demonstrate preliminary graph reasoning abilities,\n2) the benefit of advanced prompting and in-context learning diminishes on more\ncomplex graph problems, while 3) LLMs are also (un)surprisingly brittle in the\nface of spurious correlations in graph and problem settings. We then propose\nBuild-a-Graph Prompting and Algorithmic Prompting, two instruction-based\napproaches to enhance LLMs in solving natural language graph problems.\nBuild-a-Graph and Algorithmic prompting improve the performance of LLMs on\nNLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to\nsolve the most complicated graph reasoning tasks in our setup with language\nmodels remains an open research question. The NLGraph benchmark and evaluation\ncode are available at https://github.com/Arthur-Heng/NLGraph.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Heng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shangbin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zhaoxuan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaochuang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback. (arXiv:2305.14387v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.14387","description":"<p>Large language models (LLMs) such as ChatGPT have seen widespread adoption\ndue to their strong instruction-following abilities. Developing these LLMs\ninvolves a complex yet poorly understood workflow requiring training with human\nfeedback. Replicating and understanding this instruction-following requires\ntackling three major challenges: the high cost of data collection, the lack of\ntrustworthy evaluation, and the absence of reference method implementations. We\naddress these challenges with AlpacaFarm, a simulator that enables research and\ndevelopment for learning from feedback at a low cost. First, we design LLM\nprompts to simulate human feedback that are 50x cheaper than crowdworkers and\ndisplay high agreement with humans. Second, we propose an automatic evaluation\nand validate it against human instructions obtained on real-world interactions.\nThird, we contribute reference implementations for several methods (PPO, DPO,\nbest-of-n, expert iteration, and more) that learn from pairwise feedback.\nFinally, as an end-to-end validation of AlpacaFarm, we train and evaluate\neleven models on 10k pairs of real human feedback and show that rankings of\nmodels trained in AlpacaFarm match rankings of models trained on human data. As\na demonstration of the research possible in AlpacaFarm, we find that methods\nthat use a reward model can substantially improve over supervised fine-tuning\nand that our reference PPO implementation leads to a +10% improvement in\nwin-rate against Davinci003. We release all components of AlpacaFarm at\nhttps://github.com/tatsu-lab/alpaca_farm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1\">Yann Dubois</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuechen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taori_R/0/1/0/all/0/1\">Rohan Taori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gulrajani_I/0/1/0/all/0/1\">Ishaan Gulrajani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1\">Jimmy Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1\">Carlos Guestrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1\">Tatsunori B. Hashimoto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Lingual Transfer Learning for Low-Resource Speech Translation. (arXiv:2306.00789v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00789","description":"<p>The paper presents a novel three-step transfer learning framework for\nenhancing cross-lingual transfer from high- to low-resource languages in the\ndownstream application of Automatic Speech Translation. The approach integrates\na semantic knowledge-distillation step into the existing two-step cross-lingual\ntransfer learning framework XLS-R. This extra step aims to encode semantic\nknowledge in the multilingual speech encoder pre-trained via Self-Supervised\nLearning using unlabeled speech. Our proposed three-step cross-lingual transfer\nlearning framework addresses the large cross-lingual transfer gap (TRFGap)\nobserved in the XLS-R framework between high-resource and low-resource\nlanguages. We validate our proposal through extensive experiments and\ncomparisons on the CoVoST-2 benchmark, showing significant improvements in\ntranslation performance, especially for low-resource languages, and a notable\nreduction in the TRFGap.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khurana_S/0/1/0/all/0/1\">Sameer Khurana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawalatabad_N/0/1/0/all/0/1\">Nauman Dawalatabad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laurent_A/0/1/0/all/0/1\">Antoine Laurent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vicente_L/0/1/0/all/0/1\">Luis Vicente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimeno_P/0/1/0/all/0/1\">Pablo Gimeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mingote_V/0/1/0/all/0/1\">Victoria Mingote</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1\">James Glass</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media. (arXiv:2307.09312v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.09312","description":"<p>We present the Multi-Modal Discussion Transformer (mDT), a novel methodfor\ndetecting hate speech in online social networks such as Reddit discussions. In\ncontrast to traditional comment-only methods, our approach to labelling a\ncomment as hate speech involves a holistic analysis of text and images grounded\nin the discussion context. This is done by leveraging graph transformers to\ncapture the contextual relationships in the discussion surrounding a comment\nand grounding the interwoven fusion layers that combine text and image\nembeddings instead of processing modalities separately. To evaluate our work,\nwe present a new dataset, HatefulDiscussions, comprising complete multi-modal\ndiscussions from multiple online communities on Reddit. We compare the\nperformance of our model to baselines that only process individual comments and\nconduct extensive ablation studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1\">Liam Hebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yuxuan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivas_N/0/1/0/all/0/1\">Nanda Kishore Sreenivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1\">Lukasz Golab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Robin Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Format Consistency for Instruction Tuning. (arXiv:2307.15504v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.15504","description":"<p>Instruction tuning has emerged as a promising approach to enhancing large\nlanguage models in following human instructions. It is shown that increasing\nthe diversity and number of instructions in the training data can consistently\nenhance generalization performance, which facilitates a recent endeavor to\ncollect various instructions and integrate existing instruction tuning datasets\ninto larger collections. However, different users have their unique ways of\nexpressing instructions, and there often exist variations across different\ndatasets in the instruction styles and formats, i.e., format inconsistency. In\nthis work, we propose a framework named Unified Instruction Tuning (UIT), which\ncalls OpenAI APIs for automatic format transfer among different instruction\ntuning datasets such as PromptSource, FLAN and CrossFit. With the framework, we\n(1) demonstrate the necessity of maintaining format consistency in instruction\ntuning; (2) improve the generalization performance on unseen instructions on\nT5-LM-xl; (3) provide a novel perplexity-based denoising method to reduce the\nnoise of automatic format transfer to make the UIT framework more practical and\na smaller offline model based on GPT-J that achieves comparable format transfer\ncapability to OpenAI APIs to reduce costs in practice. Further analysis\nregarding variations of targeted formats and other effects is intended.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shihao Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_R/0/1/0/all/0/1\">Runchu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kunlun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huadong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaojiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Learning-Based Knowledge Injection for Metaphor Detection: A Comprehensive Review. (arXiv:2308.04306v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04306","description":"<p>Metaphor as an advanced cognitive modality works by extracting familiar\nconcepts in the target domain in order to understand vague and abstract\nconcepts in the source domain. This helps humans to quickly understand and\nmaster new domains and thus adapt to changing environments. With the continuous\ndevelopment of metaphor research in the natural language community, many\nstudies using knowledge-assisted models to detect textual metaphors have\nemerged in recent years. Compared to not using knowledge, systems that\nintroduce various kinds of knowledge achieve greater performance gains and\nreach SOTA in a recent study. Based on this, the goal of this paper is to\nprovide a comprehensive review of research advances in the application of deep\nlearning for knowledge injection in metaphor detection tasks. We will first\nsystematically summarize and generalize the mainstream knowledge and knowledge\ninjection principles. Then, the datasets, evaluation metrics, and benchmark\nmodels used in metaphor detection tasks are examined. Finally, we explore the\ncurrent issues facing knowledge injection methods and provide an outlook on\nfuture research directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingbao Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Convoifilter: A case study of doing cocktail party speech recognition. (arXiv:2308.11380v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2308.11380","description":"<p>This paper presents an end-to-end model designed to improve automatic speech\nrecognition (ASR) for a particular speaker in a crowded, noisy environment. The\nmodel utilizes a single-channel speech enhancement module that isolates the\nspeaker's voice from background noise (ConVoiFilter) and an ASR module. The\nmodel can decrease ASR's word error rate (WER) from 80% to 26.4% through this\napproach. Typically, these two components are adjusted independently due to\nvariations in data requirements. However, speech enhancement can create\nanomalies that decrease ASR efficiency. By implementing a joint fine-tuning\nstrategy, the model can reduce the WER from 26.4% in separate tuning to 14.5%\nin joint tuning. We openly share our pre-trained model to foster further\nresearch hf.co/nguyenvulebinh/voice-filter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thai-Binh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alexander Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WavMark: Watermarking for Audio Generation. (arXiv:2308.12770v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2308.12770","description":"<p>Recent breakthroughs in zero-shot voice synthesis have enabled imitating a\nspeaker's voice using just a few seconds of recording while maintaining a high\nlevel of realism. Alongside its potential benefits, this powerful technology\nintroduces notable risks, including voice fraud and speaker impersonation.\nUnlike the conventional approach of solely relying on passive methods for\ndetecting synthetic data, watermarking presents a proactive and robust defence\nmechanism against these looming risks. This paper introduces an innovative\naudio watermarking framework that encodes up to 32 bits of watermark within a\nmere 1-second audio snippet. The watermark is imperceptible to human senses and\nexhibits strong resilience against various attacks. It can serve as an\neffective identifier for synthesized voices and holds potential for broader\napplications in audio copyright protection. Moreover, this framework boasts\nhigh flexibility, allowing for the combination of multiple watermark segments\nto achieve heightened robustness and expanded capacity. Utilizing 10 to\n20-second audio as the host, our approach demonstrates an average Bit Error\nRate (BER) of 0.48\\% across ten common attacks, a remarkable reduction of over\n2800\\% in BER compared to the state-of-the-art watermarking tool. See\nhttps://aka.ms/wavmark for demos of our work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xiaoyong Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Long-Term Ad Memorability: Understanding and Generating Memorable Ads. (arXiv:2309.00378v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00378","description":"<p>Marketers spend billions of dollars on advertisements but to what end? At the\ntime of purchase, if customers cannot recognize the brand for which they saw an\nad, the money spent on the ad is essentially wasted. Despite its importance in\nmarketing, until now, there has been no study on the memorability of ads in the\nML literature. Most studies have been conducted on short-term recall (&lt;5 mins)\non specific content types like object and action videos. On the other hand, the\nadvertising industry only cares about long-term memorability, and ads are\nalmost always highly multimodal, depicting a story through its different\nmodalities. With this motivation, we release the first large-scale memorability\ndataset, LAMDBA, consisting of 1749 participants and 2205 ads covering 276\nbrands. Running statistical tests over different participant subpopulations and\nad types, we find many interesting insights into what makes an ad memorable.\nFor e.g., we find that brands that use commercials with fast-moving scenes are\nmore memorable than those with slower scenes (p=8e-10) and that people who use\nad-blockers remember fewer ads than those who don't (p=5e-3). Next, to simulate\nthe memorability of marketing materials for a particular audience, we present a\nnovel model, Henry, trained to leverage real-world knowledge of LLMs and visual\nknowledge to predict the memorability. We test Henry on all the prominent\nmemorability datasets in literature (both images and videos) and achieve\nstate-of-the-art performance across all of them. Henry shows strong\ngeneralization showing better results in 0-shot on unseen datasets. Next, we\npropose the task of memorable ad generation and release a large-scale ad\ndataset, UltraLAMBDA, consisting of 4 million ads with their Henry-assigned\nmemorability scores. We show that aligning Henry to generate memorable content\nimproves memorability scores by more than 25%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+I_H/0/1/0/all/0/1\">Harini S I</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Somesh Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman K Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1\">Aanisha Bhattacharyya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baths_V/0/1/0/all/0/1\">Veeky Baths</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhance Multi-domain Sentiment Analysis of Review Texts through Prompting Strategies. (arXiv:2309.02045v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02045","description":"<p>Large Language Models (LLMs) have made significant strides in both scientific\nresearch and practical applications. Existing studies have demonstrated the\nstate-of-the-art (SOTA) performance of LLMs in various natural language\nprocessing tasks. However, the question of how to further enhance LLMs'\nperformance in specific task using prompting strategies remains a pivotal\nconcern. This paper explores the enhancement of LLMs' performance in sentiment\nanalysis through the application of prompting strategies. We formulate the\nprocess of prompting for sentiment analysis tasks and introduce two novel\nstrategies tailored for sentiment analysis: RolePlaying (RP) prompting and\nChain-of-thought (CoT) prompting. Specifically, we also propose the RP-CoT\nprompting strategy which is a combination of RP prompting and CoT prompting. We\nconduct comparative experiments on three distinct domain datasets to evaluate\nthe effectiveness of the proposed sentiment analysis strategies. The results\ndemonstrate that the adoption of the proposed prompting strategies leads to a\nincreasing enhancement in sentiment analysis accuracy. Further, the CoT\nprompting strategy exhibits a notable impact on implicit sentiment analysis,\nwith the RP-CoT prompting strategy delivering the most superior performance\namong all strategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yajing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zongwei Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TextBind: Multi-turn Interleaved Multimodal Instruction-following in the Wild. (arXiv:2309.08637v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08637","description":"<p>Large language models with instruction-following abilities have\nrevolutionized the field of artificial intelligence. These models show\nexceptional generalizability to tackle various real-world tasks through their\nnatural language interfaces. However, their performance heavily relies on\nhigh-quality exemplar data, which is often difficult to obtain. This challenge\nis further exacerbated when it comes to multimodal instruction following. We\nintroduce TextBind, an almost annotation-free framework for empowering larger\nlanguage models with the multi-turn interleaved multimodal\ninstruction-following capabilities. Our approach requires only image-caption\npairs and generates multi-turn multimodal instruction-response conversations\nfrom a language model. To accommodate interleaved image-text inputs and\noutputs, we devise MIM, a language model-centric architecture that seamlessly\nintegrates image encoder and decoder models. We release our dataset, model, and\ndemo to foster future research in the area of multimodal instruction following.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1\">Taro Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Understand Real-World Complex Instructions?. (arXiv:2309.09150v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.09150","description":"<p>Large language models (LLMs) can understand human instructions, showing their\npotential for pragmatic applications beyond traditional NLP tasks. However,\nthey still struggle with complex instructions, which can be either complex task\ndescriptions that require multiple tasks and constraints, or complex input that\ncontains long context, noise, heterogeneous information and multi-turn format.\nDue to these features, LLMs often ignore semantic constraints from task\ndescriptions, generate incorrect formats, violate length or sample count\nconstraints, and be unfaithful to the input text. Existing benchmarks are\ninsufficient to assess LLMs' ability to understand complex instructions, as\nthey are close-ended and simple. To bridge this gap, we propose CELLO, a\nbenchmark for evaluating LLMs' ability to follow complex instructions\nsystematically. We design eight features for complex instructions and construct\na comprehensive evaluation dataset from real-world scenarios. We also establish\nfour criteria and develop corresponding metrics, as current ones are\ninadequate, biased or too strict and coarse-grained. We compare the performance\nof representative Chinese-oriented and English-oriented models in following\ncomplex instructions through extensive experiments. Resources of CELLO are\npublicly available at https://github.com/Abbey4799/CELLO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jie Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lina Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qianxi He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xunzhe Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lida Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xintao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuncheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haoning Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zihan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shisong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yikai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhouhong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Data Generation in Low-Resource Settings via Fine-Tuning of Large Language Models. (arXiv:2310.01119v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01119","description":"<p>The in-context learning ability of large language models (LLMs) enables them\nto generalize to novel downstream tasks with relatively few labeled examples.\nHowever, they require enormous computational resources to be deployed.\nAlternatively, smaller models can solve specific tasks if fine-tuned with\nenough labeled examples. These examples, however, are expensive to obtain. In\npursuit of the best of both worlds, we study synthetic data generation of\nfine-tuning training data via fine-tuned teacher LLMs to improve the downstream\nperformance of much smaller models. In four text classification and two text\ngeneration tasks, we find that both data generation and annotation dramatically\nimprove the respective downstream model's performance, occasionally\nnecessitating only a minor fraction of the original training dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1\">Jean Kaddour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Evaluation of Classroom Instructional Support with LLMs and BoWs: Connecting Global Predictions to Specific Feedback. (arXiv:2310.01132v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01132","description":"<p>With the aim to provide teachers with more specific, frequent, and actionable\nfeedback about their teaching, we explore how Large Language Models (LLMs) can\nbe used to estimate ``Instructional Support'' domain scores of the CLassroom\nAssessment Scoring System (CLASS), a widely used observation protocol. We\ndesign a machine learning architecture that uses either zero-shot prompting of\nMeta's Llama2, and/or a classic Bag of Words (BoW) model, to classify\nindividual utterances of teachers' speech (transcribed automatically using\nOpenAI's Whisper) for the presence of Instructional Support. Then, these\nutterance-level judgments are aggregated over an entire 15-min observation\nsession to estimate a global CLASS score. Experiments on two CLASS-coded\ndatasets of toddler and pre-kindergarten classrooms indicate that (1) automatic\nCLASS Instructional Support estimation accuracy using the proposed method\n(Pearson $R$ up to $0.47$) approaches human inter-rater reliability (up to\n$R=0.55$); (2) LLMs yield slightly greater accuracy than BoW for this task,\nthough the best models often combined features extracted from both LLM and BoW;\nand (3) for classifying individual utterances, there is still room for\nimprovement of automated methods compared to human-level judgments. Finally,\n(4) we illustrate how the model's outputs can be visualized at the utterance\nlevel to provide teachers with explainable feedback on which utterances were\nmost positively or negatively correlated with specific CLASS dimensions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Whitehill_J/0/1/0/all/0/1\">Jacob Whitehill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+LoCasale_Crouch_J/0/1/0/all/0/1\">Jennifer LoCasale-Crouch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ResidualTransformer: Residual Low-Rank Learning with Weight-Sharing for Transformer Layers. (arXiv:2310.02489v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02489","description":"<p>Memory constraint of always-on devices is one of the major concerns when\ndeploying speech processing models on these devices. While larger models\ntrained with sufficiently large amount of data generally perform better, making\nthem fit in the device memory is a demanding challenge. In this paper, we aim\nto reduce model size by reparameterizing model weights across Transformer\nencoder layers and assuming a special weight composition and structure. More\nspecifically, inspired by ResNet and the more recent LoRA work, we propose an\napproach named ResidualTransformer, where each weight matrix in a Transformer\nlayer comprises 1) a shared full-rank component with its adjacent layers, and\n2) a unique low-rank component to itself. The low-rank matrices only account\nfor a small amount of model size increase. In addition, we add diagonal weight\nmatrices to improve modeling capacity of the low-rank matrices. Experiments of\nour 10k-hour speech recognition and speech translation tasks show that the\nTransformer encoder size can be reduced by ~3X with very slight performance\ndegradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pragmatic Evaluation of Clarifying Questions with Fact-Level Masking. (arXiv:2310.11571v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11571","description":"<p>The ability to derive useful information by asking clarifying questions (ACQ)\nis an important element of real life collaboration on reasoning tasks, such as\nquestion answering (QA). Existing natural language ACQ challenges, however,\nevaluate generations based on word overlap rather than the value of the\ninformation itself. Word overlap is often an inappropriate metric for question\ngeneration since many different questions could be useful in a given situation,\nand a single question can be phrased many different ways. Instead, we propose\nevaluating questions pragmatically based on the value of the information they\nretrieve. Here we present a definition and framework for natural language\npragmatic asking of clarifying questions (PACQ), the problem of generating\nquestions that result in answers useful for a reasoning task. We also present\nfact-level masking (FLM), a procedure for converting natural language datasets\ninto self-supervised PACQ datasets by omitting particular critical facts.\nFinally, we generate a PACQ dataset from the HotpotQA dataset using FLM and\nevaluate several zero-shot language models on it. Our experiments show that\ncurrent zero-shot models struggle to ask questions that retrieve useful\ninformation, as compared to human annotators. These results demonstrate an\nopportunity to use FLM datasets and the PACQ framework to objectively evaluate\nand improve question generation and other language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toles_M/0/1/0/all/0/1\">Matthew Toles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yukun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gravano_L/0/1/0/all/0/1\">Luis Gravano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons. (arXiv:2310.16582v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16582","description":"<p>Personality plays a pivotal role in shaping human expression patterns, thus\nregulating the personality of large language models (LLMs) holds significant\npotential in enhancing the user experience of LLMs. Previous methods either\nrelied on fine-tuning LLMs on specific corpora or necessitated manually crafted\nprompts to elicit specific personalities from LLMs. However, the former\napproach is inefficient and costly, while the latter cannot precisely\nmanipulate personality traits at a fine-grained level. To address the above\nchallenges, we have employed a novel Unsupervisedly-Built Personalized Lexicons\n(UBPL) in a pluggable manner during the decoding phase of LLMs to manipulate\ntheir personality traits. UBPL is a lexicon built through an unsupervised\napproach from a situational judgment test dataset (SJTs4LLM). Users can utilize\nUBPL to adjust the probability vectors of predicted words in the decoding phase\nof LLMs, thus influencing the personality expression of LLMs. Extensive\nexperimentation demonstrates the remarkable effectiveness and pluggability of\nour method for fine-grained manipulation of LLM's personality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_C/0/1/0/all/0/1\">Changze Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wenhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jianhan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1\">Muling Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zixuan Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Kiki or Bouba? Sound Symbolism in Vision-and-Language Models. (arXiv:2310.16781v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.16781","description":"<p>Although the mapping between sound and meaning in human language is assumed\nto be largely arbitrary, research in cognitive science has shown that there are\nnon-trivial correlations between particular sounds and meanings across\nlanguages and demographic groups, a phenomenon known as sound symbolism. Among\nthe many dimensions of meaning, sound symbolism is particularly salient and\nwell-demonstrated with regards to cross-modal associations between language and\nthe visual domain. In this work, we address the question of whether sound\nsymbolism is reflected in vision-and-language models such as CLIP and Stable\nDiffusion. Using zero-shot knowledge probing to investigate the inherent\nknowledge of these models, we find strong evidence that they do show this\npattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our\nwork provides a novel method for demonstrating sound symbolism and\nunderstanding its nature using computational tools. Our code will be made\npublicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alper_M/0/1/0/all/0/1\">Morris Alper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1\">Hadar Averbuch-Elor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explore Spurious Correlations at the Concept Level in Language Models for Text Classification. (arXiv:2311.08648v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.08648","description":"<p>Language models (LMs) have achieved notable success in numerous NLP tasks,\nemploying both fine-tuning and in-context learning (ICL) methods. While\nlanguage models demonstrate exceptional performance, they face robustness\nchallenges due to spurious correlations arising from imbalanced label\ndistributions in training data or ICL exemplars. Previous research has\nprimarily concentrated on word, phrase, and syntax features, neglecting the\nconcept level, often due to the absence of concept labels and difficulty in\nidentifying conceptual content in input texts. This paper introduces two main\ncontributions. First, we employ ChatGPT to assign concept labels to texts,\nassessing concept bias in models during fine-tuning or ICL on test data. We\nfind that LMs, when encountering spurious correlations between a concept and a\nlabel in training or prompts, resort to shortcuts for predictions. Second, we\nintroduce a data rebalancing technique that incorporates ChatGPT-generated\ncounterfactual data, thereby balancing label distribution and mitigating\nspurious correlations. Our method's efficacy, surpassing traditional token\nremoval approaches, is validated through extensive testing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Paiheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1\">Bang An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_W/0/1/0/all/0/1\">Wei Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Furong Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Experimentation of Accuracy Metrics in Automated Medical Reporting: The Case of Otitis Consultations. (arXiv:2311.13273v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.13273","description":"<p>Generative Artificial Intelligence (AI) can be used to automatically generate\nmedical reports based on transcripts of medical consultations. The aim is to\nreduce the administrative burden that healthcare professionals face. The\naccuracy of the generated reports needs to be established to ensure their\ncorrectness and usefulness. There are several metrics for measuring the\naccuracy of AI generated reports, but little work has been done towards the\napplication of these metrics in medical reporting. A comparative\nexperimentation of 10 accuracy metrics has been performed on AI generated\nmedical reports against their corresponding General Practitioner's (GP) medical\nreports concerning Otitis consultations. The number of missing, incorrect, and\nadditional statements of the generated reports have been correlated with the\nmetric scores. In addition, we introduce and define a Composite Accuracy Score\nwhich produces a single score for comparing the metrics within the field of\nautomated medical reporting. Findings show that based on the correlation study\nand the Composite Accuracy Score, the ROUGE-L and Word Mover's Distance metrics\nare the preferred metrics, which is not in line with previous work. These\nfindings help determine the accuracy of an AI generated medical report, which\naids the development of systems that generate medical reports for GPs to reduce\nthe administrative burden.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Faber_W/0/1/0/all/0/1\">Wouter Faber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bootsma_R/0/1/0/all/0/1\">Renske Eline Bootsma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huibers_T/0/1/0/all/0/1\">Tom Huibers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dulmen_S/0/1/0/all/0/1\">Sandra van Dulmen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brinkkemper_S/0/1/0/all/0/1\">Sjaak Brinkkemper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Beginner to Expert: Modeling Medical Knowledge into General LLMs. (arXiv:2312.01040v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.01040","description":"<p>Recently, large language model (LLM) based artificial intelligence (AI)\nsystems have demonstrated remarkable capabilities in natural language\nunderstanding and generation. However, these models face a significant\nchallenge when it comes to sensitive applications, such as reasoning over\nmedical knowledge and answering medical questions in a physician-like manner.\nPrior studies attempted to overcome this challenge by increasing the model size\n(&gt;100B) to learn more general medical knowledge, while there is still room for\nimprovement in LLMs with smaller-scale model sizes (&lt;100B). In this work, we\nstart from a pre-trained general LLM model (AntGLM-10B) and fine-tune it from a\nmedical beginner towards a medical expert (called AntGLM-Med-10B), which\nleverages a 3-stage optimization procedure, i.e., general medical knowledge\ninjection, medical domain instruction tuning, and specific medical task\nadaptation. Our contributions are threefold: (1) We specifically investigate\nhow to adapt a pre-trained general LLM in medical domain, especially for a\nspecific medical task. (2) We collect and construct large-scale medical\ndatasets for each stage of the optimization process. These datasets encompass\nvarious data types and tasks, such as question-answering, medical reasoning,\nmulti-choice questions, and medical conversations. (3) Specifically for\nmulti-choice questions in the medical domain, we propose a novel\nVerification-of-Choice approach for prompting engineering, which significantly\nenhances the reasoning ability of LLMs. Remarkably, by combining the above\napproaches, our AntGLM-Med-10B model can outperform the most of LLMs on\nPubMedQA, including both general and medical LLMs, even when these LLMs have\nlarger model size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoyan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_M/0/1/0/all/0/1\">Mingyuan Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Sen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yicheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1\">Cong Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wangshu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Teng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Group_Guannan_Zhang_Ant/0/1/0/all/0/1\">Guannan Zhang Ant Group</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing the Impact of Fake News on the Anticipated Outcome of the 2024 Election Ahead of Time. (arXiv:2312.03750v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03750","description":"<p>Despite increasing awareness and research around fake news, there is still a\nsignificant need for datasets that specifically target racial slurs and biases\nwithin North American political speeches. This is particulary important in the\ncontext of upcoming North American elections. This study introduces a\ncomprehensive dataset that illuminates these critical aspects of\nmisinformation. To develop this fake news dataset, we scraped and built a\ncorpus of 40,000 news articles about political discourses in North America. A\nportion of this dataset (4000) was then carefully annotated, using a blend of\nadvanced language models and human verification methods. We have made both\nthese datasets openly available to the research community and have conducted\nbenchmarking on the annotated data to demonstrate its utility. We release the\nbest-performing language model along with data. We encourage researchers and\ndevelopers to make use of this dataset and contribute to this ongoing\ninitiative.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mizanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghuge_S/0/1/0/all/0/1\">Shardul Ghuge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RJUA-QA: A Comprehensive QA Dataset for Urology. (arXiv:2312.09785v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.09785","description":"<p>We introduce RJUA-QA, a novel medical dataset for question answering (QA) and\nreasoning with clinical evidence, contributing to bridge the gap between\ngeneral large language models (LLMs) and medical-specific LLM applications.\nRJUA-QA is derived from realistic clinical scenarios and aims to facilitate\nLLMs in generating reliable diagnostic and advice. The dataset contains 2,132\ncurated Question-Context-Answer pairs, corresponding about 25,000 diagnostic\nrecords and clinical cases. The dataset covers 67 common urological disease\ncategories, where the disease coverage exceeds 97.6\\% of the population seeking\nmedical services in urology. Each data instance in RJUA-QA comprises: (1) a\nquestion mirroring real patient to inquiry about clinical symptoms and medical\nconditions, (2) a context including comprehensive expert knowledge, serving as\na reference for medical examination and diagnosis, (3) a doctor response\noffering the diagnostic conclusion and suggested examination guidance, (4) a\ndiagnosed clinical disease as the recommended diagnostic outcome, and (5)\nclinical advice providing recommendations for medical examination. RJUA-QA is\nthe first medical QA dataset for clinical reasoning over the patient inquiries,\nwhere expert-level knowledge and experience are required for yielding\ndiagnostic conclusions and medical examination advice. A comprehensive\nevaluation is conducted to evaluate the performance of both medical-specific\nand general LLMs on the RJUA-QA dataset. Our data is are publicly available at\n\\url{https://github.com/alipay/RJU_Ant_QA}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1\">Shiwei Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_C/0/1/0/all/0/1\">Chenfei Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hongbo Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Lei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaoyan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Deng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_X/0/1/0/all/0/1\">Xianguo Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fangzhou Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xiaowei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yue Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jinjie Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wei Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yiran Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Paraphrasing The Original Text\" Makes High Accuracy Long-Context QA. (arXiv:2312.11193v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.11193","description":"<p>Most open-source generative language models currently have a context window\nof no more than 4k, limiting their ability when facing long text. Even models\nwith longer context windows cannot guarantee satisfactory accuracy on\nlong-context problems. To tackle this issue, we explore from the perspective of\ntraining data and theoretically demonstrate that improving the capability to\nhandle long contexts requires \"effective\" rather than simply \"long\" data. Based\non this insight, we propose using the \"original text paraphrasing\" task and\nsuccessfully extend the context window of existing models to 32k through a\nlow-cost and effective method. Our fine-tuned model achieves state-of-the-art\naccuracy in multi-document-QA among models of comparable scale. The model and\ntraining data have been made available on\nHuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) and\nWiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yijiong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward A Reinforcement-Learning-Based System for Adjusting Medication to Minimize Speech Disfluency. (arXiv:2312.11509v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.11509","description":"<p>We propose a Reinforcement-Learning-based system that would automatically\nprescribe a hypothetical patient medication that may help the patient with\ntheir mental-health-related speech disfluency, and adjust the medication and\nthe dosages in response to zero-cost frequent measurement of the fluency of the\npatient. We demonstrate the components of the system: a module that detects and\nevaluates speech disfluency on a large dataset we built, and a Reinforcement\nLearning algorithm that automatically finds good combinations of medications.\nTo support the two modules, we collect data on the effect of psychiatric\nmedications for speech disfluency from the literature, and build a plausible\npatient simulation system. We demonstrate that the Reinforcement Learning\nsystem is, under some circumstances, able to converge to a good medication\nregime. We collect and label a dataset of people with possible speech\ndisfluency and demonstrate our methods using that dataset. Our work is a proof\nof concept: we show that there is promise in the idea of using automatic data\ncollection to address disfluency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Constas_P/0/1/0/all/0/1\">Pavlos Constas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawal_V/0/1/0/all/0/1\">Vikram Rawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_M/0/1/0/all/0/1\">Matthew Honorio Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constas_A/0/1/0/all/0/1\">Andreas Constas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Aditya Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheung_K/0/1/0/all/0/1\">Kaison Cheung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sultani_N/0/1/0/all/0/1\">Najma Sultani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Carrie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altomare_M/0/1/0/all/0/1\">Micol Altomare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akzam_M/0/1/0/all/0/1\">Michael Akzam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiacheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_V/0/1/0/all/0/1\">Vhea He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altomare_L/0/1/0/all/0/1\">Lauren Altomare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murqi_H/0/1/0/all/0/1\">Heraa Murqi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhanshali_N/0/1/0/all/0/1\">Nimit Amikumar Bhanshali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rachad_Y/0/1/0/all/0/1\">Youssef Rachad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerzhoy_M/0/1/0/all/0/1\">Michael Guerzhoy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Granularity Information Interaction Framework for Incomplete Utterance Rewriting. (arXiv:2312.11945v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.11945","description":"<p>Recent approaches in Incomplete Utterance Rewriting (IUR) fail to capture the\nsource of important words, which is crucial to edit the incomplete utterance,\nand introduce words from irrelevant utterances. We propose a novel and\neffective multi-task information interaction framework including context\nselection, edit matrix construction, and relevance merging to capture the\nmulti-granularity of semantic information. Benefiting from fetching the\nrelevant utterance and figuring out the important words, our approach\noutperforms existing state-of-the-art models on two benchmark datasets\nRestoration-200K and CANAND in this field. Code will be provided on\n\\url{https://github.com/yanmenxue/QR}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_H/0/1/0/all/0/1\">Haowei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dinghao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"YAYI-UIE: A Chat-Enhanced Instruction Tuning Framework for Universal Information Extraction. (arXiv:2312.15548v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.15548","description":"<p>The difficulty of the information extraction task lies in dealing with the\ntask-specific label schemas and heterogeneous data structures. Recent work has\nproposed methods based on large language models to uniformly model different\ninformation extraction tasks. However, these existing methods are deficient in\ntheir information extraction capabilities for Chinese languages other than\nEnglish. In this paper, we propose an end-to-end chat-enhanced instruction\ntuning framework for universal information extraction (YAYI-UIE), which\nsupports both Chinese and English. Specifically, we utilize dialogue data and\ninformation extraction data to enhance the information extraction performance\njointly. Experimental results show that our proposed framework achieves\nstate-of-the-art performance on Chinese datasets while also achieving\ncomparable performance on English datasets under both supervised settings and\nzero-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_X/0/1/0/all/0/1\">Xinglin Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hanxuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Minzheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yin Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_W/0/1/0/all/0/1\">Wenji Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Daniel Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Action-Item-Driven Summarization of Long Meeting Transcripts. (arXiv:2312.17581v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17581","description":"<p>The increased prevalence of online meetings has significantly enhanced the\npracticality of a model that can automatically generate the summary of a given\nmeeting. This paper introduces a novel and effective approach to automate the\ngeneration of meeting summaries. Current approaches to this problem generate\ngeneral and basic summaries, considering the meeting simply as a long dialogue.\nHowever, our novel algorithms can generate abstractive meeting summaries that\nare driven by the action items contained in the meeting transcript. This is\ndone by recursively generating summaries and employing our action-item\nextraction algorithm for each section of the meeting in parallel. All of these\nsectional summaries are then combined and summarized together to create a\ncoherent and action-item-driven summary. In addition, this paper introduces\nthree novel methods for dividing up long transcripts into topic-based sections\nto improve the time efficiency of our algorithm, as well as to resolve the\nissue of large language models (LLMs) forgetting long-term dependencies. Our\npipeline achieved a BERTScore of 64.98 across the AMI corpus, which is an\napproximately 4.98% increase from the current state-of-the-art result produced\nby a fine-tuned BART (Bidirectional and Auto-Regressive Transformers) model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Golia_L/0/1/0/all/0/1\">Logan Golia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SecFormer: Towards Fast and Accurate Privacy-Preserving Inference for Large Language Models. (arXiv:2401.00793v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2401.00793","description":"<p>With the growing use of large language models hosted on cloud platforms to\noffer inference services, privacy concerns are escalating, especially\nconcerning sensitive data like investment plans and bank account details.\nSecure Multi-Party Computing (SMPC) emerges as a promising solution to protect\nthe privacy of inference data and model parameters. However, the application of\nSMPC in Privacy-Preserving Inference (PPI) for large language models,\nparticularly those based on the Transformer architecture, often leads to\nconsiderable slowdowns or declines in performance. This is largely due to the\nmultitude of nonlinear operations in the Transformer architecture, which are\nnot well-suited to SMPC and difficult to circumvent or optimize effectively. To\naddress this concern, we introduce an advanced optimization framework called\nSecFormer, to achieve fast and accurate PPI for Transformer models. By\nimplementing model design optimization, we successfully eliminate the high-cost\nexponential and maximum operations in PPI without sacrificing model\nperformance. Additionally, we have developed a suite of efficient SMPC\nprotocols that utilize segmented polynomials, Fourier series and Goldschmidt's\nmethod to handle other complex nonlinear functions within PPI, such as GeLU,\nLayerNorm, and Softmax. Our extensive experiments reveal that SecFormer\noutperforms MPCFormer in performance, showing improvements of $5.6\\%$ and\n$24.2\\%$ for BERT$_{\\text{BASE}}$ and BERT$_{\\text{LARGE}}$, respectively. In\nterms of efficiency, SecFormer is 3.56 and 3.58 times faster than Puma for\nBERT$_{\\text{BASE}}$ and BERT$_{\\text{LARGE}}$, demonstrating its effectiveness\nand speed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jinglong Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yehong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaqi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_X/0/1/0/all/0/1\">Xin Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents. (arXiv:2401.00812v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.00812","description":"<p>The prominent large language models (LLMs) of today differ from past language\nmodels not only in size, but also in the fact that they are trained on a\ncombination of natural language and formal language (code). As a medium between\nhumans and computers, code translates high-level goals into executable steps,\nfeaturing standard syntax, logical consistency, abstraction, and modularity. In\nthis survey, we present an overview of the various benefits of integrating code\ninto LLMs' training data. Specifically, beyond enhancing LLMs in code\ngeneration, we observe that these unique properties of code help (i) unlock the\nreasoning ability of LLMs, enabling their applications to a range of more\ncomplex natural language tasks; (ii) steer LLMs to produce structured and\nprecise intermediate steps, which can then be connected to external execution\nends through function calls; and (iii) take advantage of code compilation and\nexecution environment, which also provides diverse feedback for model\nimprovement. In addition, we trace how these profound capabilities of LLMs,\nbrought by code, have led to their emergence as intelligent agents (IAs) in\nsituations where the ability to understand instructions, decompose goals, plan\nand execute actions, and refine from feedback are crucial to their success on\ndownstream tasks. Finally, we present several key challenges and future\ndirections of empowering LLMs with code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Ke Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiateng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">John Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chaoqi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_Y/0/1/0/all/0/1\">Yi R. Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zixuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xingyao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiquan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">Chengxiang Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cheetah: Natural Language Generation for 517 African Languages. (arXiv:2401.01053v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01053","description":"<p>Low-resource African languages pose unique challenges for natural language\nprocessing (NLP) tasks, including natural language generation (NLG). In this\npaper, we develop Cheetah, a massively multilingual NLG language model for\nAfrican languages. Cheetah supports 517 African languages and language\nvarieties, allowing us to address the scarcity of NLG resources and provide a\nsolution to foster linguistic diversity. We demonstrate the effectiveness of\nCheetah through comprehensive evaluations across seven generation downstream\ntasks. In five of the seven tasks, Cheetah significantly outperforms other\nmodels, showcasing its remarkable performance for generating coherent and\ncontextually appropriate text in a wide range of African languages. We\nadditionally conduct a detailed human evaluation to delve deeper into the\nlinguistic capabilities of Cheetah. The introduction of Cheetah has\nfar-reaching benefits for linguistic diversity. By leveraging pretrained models\nand adapting them to specific languages, our approach facilitates the\ndevelopment of practical NLG applications for African communities. The findings\nof this study contribute to advancing NLP research in low-resource settings,\nenabling greater accessibility and inclusion for African languages in a rapidly\nexpanding digital landscape. We publicly release our models for research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adebara_I/0/1/0/all/0/1\">Ife Adebara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quality and Quantity of Machine Translation References for Automated Metrics. (arXiv:2401.01283v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01283","description":"<p>Automatic machine translation metrics often use human translations to\ndetermine the quality of system translations. Common wisdom in the field\ndictates that the human references should be of very high quality. However,\nthere are no cost-benefit analyses that could be used to guide practitioners\nwho plan to collect references for machine translation evaluation. We find that\nhigher-quality references lead to better metric correlations with humans at the\nsegment-level. Having up to 7 references per segment and taking their average\nhelps all metrics. Interestingly, the references from vendors of different\nqualities can be mixed together and improve metric success. Higher quality\nreferences, however, cost more to create and we frame this as an optimization\nproblem: given a specific budget, what references should be collected to\nmaximize metric success. These findings can be used by evaluators of shared\ntasks when references need to be created under a certain budget.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bojar_O/0/1/0/all/0/1\">Ond&#x159;ej Bojar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01286","description":"<p>Large Language Models (LLMs) have shown extraordinary capabilities in\nunderstanding and generating text that closely mirrors human communication.\nHowever, a primary limitation lies in the significant computational demands\nduring training, arising from their extensive parameterization. This challenge\nis further intensified by the dynamic nature of the world, necessitating\nfrequent updates to LLMs to correct outdated information or integrate new\nknowledge, thereby ensuring their continued relevance. Note that many\napplications demand continual model adjustments post-training to address\ndeficiencies or undesirable behaviors. There is an increasing interest in\nefficient, lightweight methods for on-the-fly model modifications. To this end,\nrecent years have seen a burgeoning in the techniques of knowledge editing for\nLLMs, which aim to efficiently modify LLMs' behaviors within specific domains\nwhile preserving overall performance across various inputs. In this paper, we\nfirst define the knowledge editing problem and then provide a comprehensive\nreview of cutting-edge approaches. Drawing inspiration from educational and\ncognitive research theories, we propose a unified categorization criterion that\nclassifies knowledge editing methods into three groups: resorting to external\nknowledge, merging knowledge into the model, and editing intrinsic knowledge.\nFurthermore, we introduce a new benchmark, KnowEdit, for a comprehensive\nempirical evaluation of representative knowledge editing approaches.\nAdditionally, we provide an in-depth analysis of knowledge location, which can\nprovide a deeper understanding of the knowledge structures inherent within\nLLMs. Finally, we discuss several potential applications of knowledge editing,\noutlining its broad and impactful implications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_B/0/1/0/all/0/1\">Bozhong Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mengru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zekun Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shengyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jintian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Y/0/1/0/all/0/1\">Yuansheng Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Siyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Ziwen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1\">Pengjun Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Lei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhiqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaowei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey of Hallucination Mitigation Techniques in Large Language Models. (arXiv:2401.01313v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01313","description":"<p>As Large Language Models (LLMs) continue to advance in their ability to write\nhuman-like text, a key challenge remains around their tendency to hallucinate\ngenerating content that appears factual but is ungrounded. This issue of\nhallucination is arguably the biggest hindrance to safely deploying these\npowerful LLMs into real-world production systems that impact people's lives.\nThe journey toward widespread adoption of LLMs in practical settings heavily\nrelies on addressing and mitigating hallucinations. Unlike traditional AI\nsystems focused on limited tasks, LLMs have been exposed to vast amounts of\nonline text data during training. While this allows them to display impressive\nlanguage fluency, it also means they are capable of extrapolating information\nfrom the biases in training data, misinterpreting ambiguous prompts, or\nmodifying the information to align superficially with the input. This becomes\nhugely alarming when we rely on language generation capabilities for sensitive\napplications, such as summarizing medical records, financial analysis reports,\netc. This paper presents a comprehensive survey of over 32 techniques developed\nto mitigate hallucination in LLMs. Notable among these are Retrieval Augmented\nGeneration (Lewis et al, 2021), Knowledge Retrieval (Varshney et al,2023),\nCoNLI (Lei et al, 2023), and CoVe (Dhuliawala et al, 2023). Furthermore, we\nintroduce a detailed taxonomy categorizing these methods based on various\nparameters, such as dataset utilization, common tasks, feedback mechanisms, and\nretriever types. This classification helps distinguish the diverse approaches\nspecifically designed to tackle hallucination issues in LLMs. Additionally, we\nanalyze the challenges and limitations inherent in these techniques, providing\na solid foundation for future research in addressing hallucinations and related\nphenomena within the realm of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tonmoy_S/0/1/0/all/0/1\">S.M Towhidul Islam Tonmoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaman_S/0/1/0/all/0/1\">S M Mehedi Zaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawte_V/0/1/0/all/0/1\">Vipula Rawte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse. (arXiv:2401.01523v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01523","description":"<p>The exponential growth of social media has profoundly transformed how\ninformation is created, disseminated, and absorbed, exceeding any precedent in\nthe digital age. Regrettably, this explosion has also spawned a significant\nincrease in the online abuse of memes. Evaluating the negative impact of memes\nis notably challenging, owing to their often subtle and implicit meanings,\nwhich are not directly conveyed through the overt text and imagery. In light of\nthis, large multimodal models (LMMs) have emerged as a focal point of interest\ndue to their remarkable capabilities in handling diverse multimodal tasks. In\nresponse to this development, our paper aims to thoroughly examine the capacity\nof various LMMs (e.g. GPT-4V) to discern and respond to the nuanced aspects of\nsocial abuse manifested in memes. We introduce the comprehensive meme\nbenchmark, GOAT-Bench, comprising over 6K varied memes encapsulating themes\nsuch as implicit hate speech, sexism, and cyberbullying, etc. Utilizing\nGOAT-Bench, we delve into the ability of LMMs to accurately assess hatefulness,\nmisogyny, offensiveness, sarcasm, and harmful content. Our extensive\nexperiments across a range of LMMs reveal that current models still exhibit a\ndeficiency in safety awareness, showing insensitivity to various forms of\nimplicit abuse. We posit that this shortfall represents a critical impediment\nto the realization of safe artificial intelligence. The GOAT-Bench and\naccompanying resources are publicly accessible at https://goatlmm.github.io/,\ncontributing to ongoing research in this vital field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Ziyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Ruichao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Semi-Supervised Learning Algorithms in Text Datasets. (arXiv:2401.01843v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01843","description":"<p>Using large training datasets enhances the generalization capabilities of\nneural networks. Semi-supervised learning (SSL) is useful when there are few\nlabeled data and a lot of unlabeled data. SSL methods that use data\naugmentation are most successful for image datasets. In contrast, texts do not\nhave consistent augmentation methods as images. Consequently, methods that use\naugmentation are not as effective in text data as they are in image data. In\nthis study, we compared SSL algorithms that do not require augmentation; these\nare self-training, co-training, tri-training, and tri-training with\ndisagreement. In the experiments, we used 4 different text datasets for\ndifferent tasks. We examined the algorithms from a variety of perspectives by\nasking experiment questions and suggested several improvements. Among the\nalgorithms, tri-training with disagreement showed the closest performance to\nthe Oracle; however, performance gap shows that new semi-supervised algorithms\nor improvements in existing methods are needed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kesgin_H/0/1/0/all/0/1\">Himmet Toprak Kesgin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amasyali_M/0/1/0/all/0/1\">Mehmet Fatih Amasyali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generalist embedding models are better at short-context clinical semantic search than specialized embedding models. (arXiv:2401.01943v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.01943","description":"<p>The increasing use of tools and solutions based on Large Language Models\n(LLMs) for various tasks in the medical domain has become a prominent trend.\nTheir use in this highly critical and sensitive domain has thus raised\nimportant questions about their robustness, especially in response to\nvariations in input, and the reliability of the generated outputs. This study\naddresses these questions by constructing a textual dataset based on the\nICD-10-CM code descriptions, widely used in US hospitals and containing many\nclinical terms, and their easily reproducible rephrasing. We then benchmarked\nexisting embedding models, either generalist or specialized in the clinical\ndomain, in a semantic search task where the goal was to correctly match the\nrephrased text to the original description. Our results showed that generalist\nmodels performed better than clinical models, suggesting that existing clinical\nspecialized models are more sensitive to small changes in input that confuse\nthem. The highlighted problem of specialized models may be due to the fact that\nthey have not been trained on sufficient data, and in particular on datasets\nthat are not diverse enough to have a reliable global language understanding,\nwhich is still necessary for accurate handling of medical documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Excoffier_J/0/1/0/all/0/1\">Jean-Baptiste Excoffier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roehr_T/0/1/0/all/0/1\">Tom Roehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Figueroa_A/0/1/0/all/0/1\">Alexei Figueroa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papaioannou_J/0/1/0/all/0/1\">Jens-Michalis Papaioannou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bressem_K/0/1/0/all/0/1\">Keno Bressem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortala_M/0/1/0/all/0/1\">Matthieu Ortala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding LLMs: A Comprehensive Overview from Training to Inference. (arXiv:2401.02038v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.02038","description":"<p>The introduction of ChatGPT has led to a significant increase in the\nutilization of Large Language Models (LLMs) for addressing downstream tasks.\nThere's an increasing focus on cost-efficient training and deployment within\nthis context. Low-cost training and deployment of LLMs represent the future\ndevelopment trend. This paper reviews the evolution of large language model\ntraining techniques and inference deployment technologies aligned with this\nemerging trend. The discussion on training includes various aspects, including\ndata preprocessing, training architecture, pre-training tasks, parallel\ntraining, and relevant content related to model fine-tuning. On the inference\nside, the paper covers topics such as model compression, parallel computation,\nmemory scheduling, and structural optimization. It also explores LLMs'\nutilization and provides insights into their future development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Hao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Tianle Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_J/0/1/0/all/0/1\">Jiaming Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yutong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaohui Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_T/0/1/0/all/0/1\">Tianyang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shaochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xintao Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_N/0/1/0/all/0/1\">Ning Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_B/0/1/0/all/0/1\">Bao Ge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-08T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}