{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-06T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Misinformation Concierge: A Proof-of-Concept with Curated Twitter Dataset on COVID-19 Vaccination. (arXiv:2309.00639v1 [cs.CL])","link":"http://arxiv.org/abs/2309.00639","description":"<p>We demonstrate the Misinformation Concierge, a proof-of-concept that provides\nactionable intelligence on misinformation prevalent in social media.\nSpecifically, it uses language processing and machine learning tools to\nidentify subtopics of discourse and discern non/misleading posts; presents\nstatistical reports for policy-makers to understand the big picture of\nprevalent misinformation in a timely manner; and recommends rebuttal messages\nfor specific pieces of misinformation, identified from within the corpus of\ndata - providing means to intervene and counter misinformation promptly. The\nMisinformation Concierge proof-of-concept using a curated dataset is accessible\nat: https://demo-frontend-uy34.onrender.com/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shakshi Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1\">Anwitaman Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shankaran_V/0/1/0/all/0/1\">Vigneshwaran Shankaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Rajesh Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extracting Mathematical Concepts with Large Language Models. (arXiv:2309.00642v1 [cs.CL])","link":"http://arxiv.org/abs/2309.00642","description":"<p>We extract mathematical concepts from mathematical text using generative\nlarge language models (LLMs) like ChatGPT, contributing to the field of\nautomatic term extraction (ATE) and mathematical text processing, and also to\nthe study of LLMs themselves. Our work builds on that of others in that we aim\nfor automatic extraction of terms (keywords) in one mathematical field,\ncategory theory, using as a corpus the 755 abstracts from a snapshot of the\nonline journal \"Theory and Applications of Categories\", circa 2020. Where our\nstudy diverges from previous work is in (1) providing a more thorough analysis\nof what makes mathematical term extraction a difficult problem to begin with;\n(2) paying close attention to inter-annotator disagreements; (3) providing a\nset of guidelines which both human and machine annotators could use to\nstandardize the extraction process; (4) introducing a new annotation tool to\nhelp humans with ATE, applicable to any mathematical field and even beyond\nmathematics; (5) using prompts to ChatGPT as part of the extraction process,\nand proposing best practices for such prompts; and (6) raising the question of\nwhether ChatGPT could be used as an annotator on the same level as human\nexperts. Our overall findings are that the matter of mathematical ATE is an\ninteresting field which can benefit from participation by LLMs, but LLMs\nthemselves cannot at this time surpass human performance on it.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paiva_V/0/1/0/all/0/1\">Valeria de Paiva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qiyue Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kovalev_P/0/1/0/all/0/1\">Pavel Kovalev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moss_L/0/1/0/all/0/1\">Lawrence S. Moss</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT has become financially literate: Insights from financial literacy tests of GPT and a preliminary test of how people use it as a source of advice. (arXiv:2309.00649v1 [cs.CL])","link":"http://arxiv.org/abs/2309.00649","description":"<p>We assess the ability of GPT -- a large language model -- to serve as a\nfinancial robo-advisor for the masses, by using a financial literacy test.\nDavinci and ChatGPT based on GPT-3.5 score 66% and 65% on the financial\nliteracy test, respectively, compared to a baseline of 33%. However, ChatGPT\nbased on GPT-4 achieves a near-perfect 99% score, pointing to financial\nliteracy becoming an emergent ability of state-of-the-art models. We use the\nJudge-Advisor System and a savings dilemma to illustrate how researchers might\nassess advice-utilization from large language models. We also present a number\nof directions for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niszczota_P/0/1/0/all/0/1\">Pawe&#x142; Niszczota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbas_S/0/1/0/all/0/1\">Sami Abbas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Taken out of context: On measuring situational awareness in LLMs. (arXiv:2309.00667v1 [cs.CL])","link":"http://arxiv.org/abs/2309.00667","description":"<p>We aim to better understand the emergence of `situational awareness' in large\nlanguage models (LLMs). A model is situationally aware if it's aware that it's\na model and can recognize whether it's currently in testing or deployment.\nToday's LLMs are tested for safety and alignment before they are deployed. An\nLLM could exploit situational awareness to achieve a high score on safety\ntests, while taking harmful actions after deployment. Situational awareness may\nemerge unexpectedly as a byproduct of model scaling. One way to better foresee\nthis emergence is to run scaling experiments on abilities necessary for\nsituational awareness. As such an ability, we propose `out-of-context\nreasoning' (in contrast to in-context learning). We study out-of-context\nreasoning experimentally. First, we finetune an LLM on a description of a test\nwhile providing no examples or demonstrations. At test time, we assess whether\nthe model can pass the test. To our surprise, we find that LLMs succeed on this\nout-of-context reasoning task. Their success is sensitive to the training setup\nand only works when we apply data augmentation. For both GPT-3 and LLaMA-1,\nperformance improves with model size. These findings offer a foundation for\nfurther empirical study, towards predicting and potentially controlling the\nemergence of situational awareness in LLMs. Code is available at:\nhttps://github.com/AsaCooperStickland/situational-awareness-evals.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berglund_L/0/1/0/all/0/1\">Lukas Berglund</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stickland_A/0/1/0/all/0/1\">Asa Cooper Stickland</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balesni_M/0/1/0/all/0/1\">Mikita Balesni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaufmann_M/0/1/0/all/0/1\">Max Kaufmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1\">Meg Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kokotajlo_D/0/1/0/all/0/1\">Daniel Kokotajlo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_O/0/1/0/all/0/1\">Owain Evans</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextual Biasing of Named-Entities with Large Language Models. (arXiv:2309.00723v1 [cs.CL])","link":"http://arxiv.org/abs/2309.00723","description":"<p>This paper studies contextual biasing with Large Language Models (LLMs),\nwhere during second-pass rescoring additional contextual information is\nprovided to a LLM to boost Automatic Speech Recognition (ASR) performance. We\npropose to leverage prompts for a LLM without fine tuning during rescoring\nwhich incorporate a biasing list and few-shot examples to serve as additional\ninformation when calculating the score for the hypothesis. In addition to\nfew-shot prompt learning, we propose multi-task training of the LLM to predict\nboth the entity class and the next token. To improve the efficiency for\ncontextual biasing and to avoid exceeding LLMs' maximum sequence lengths, we\npropose dynamic prompting, where we select the most likely class using the\nclass tag prediction, and only use entities in this class as contexts for next\ntoken prediction. Word Error Rate (WER) evaluation is performed on i) an\ninternal calling, messaging, and dictation dataset, and ii) the SLUE-Voxpopuli\ndataset. Results indicate that biasing lists and few-shot examples can achieve\n17.8% and 9.6% relative improvement compared to first pass ASR, and that\nmulti-task training and dynamic prompting can achieve 20.0% and 11.3% relative\nWER improvement, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chuanneng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1\">Zeeshan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingyi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1\">Yutong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How trial-to-trial learning shapes mappings in the mental lexicon: Modelling Lexical Decision with Linear Discriminative Learning. (arXiv:2207.00430v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.00430","description":"<p>Trial-to-trial effects have been found in a number of studies, indicating\nthat processing a stimulus influences responses in subsequent trials. A special\ncase are priming effects which have been modelled successfully with\nerror-driven learning (Marsolek, 2008), implying that participants are\ncontinuously learning during experiments. This study investigates whether\ntrial-to-trial learning can be detected in an unprimed lexical decision\nexperiment. We used the Discriminative Lexicon Model (DLM; Baayen et al.,\n2019), a model of the mental lexicon with meaning representations from\ndistributional semantics, which models error-driven incremental learning with\nthe Widrow-Hoff rule. We used data from the British Lexicon Project (BLP;\nKeuleers et al., 2012) and simulated the lexical decision experiment with the\nDLM on a trial-by-trial basis for each subject individually. Then, reaction\ntimes were predicted with Generalised Additive Models (GAMs), using measures\nderived from the DLM simulations as predictors. We extracted measures from two\nsimulations per subject (one with learning updates between trials and one\nwithout), and used them as input to two GAMs. Learning-based models showed\nbetter model fit than the non-learning ones for the majority of subjects. Our\nmeasures also provide insights into lexical processing and individual\ndifferences. This demonstrates the potential of the DLM to model behavioural\ndata and leads to the conclusion that trial-to-trial learning can indeed be\ndetected in unprimed lexical decision. Our results support the possibility that\nour lexical knowledge is subject to continuous changes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Heitmeier_M/0/1/0/all/0/1\">Maria Heitmeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yu-Ying Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_R/0/1/0/all/0/1\">R. Harald Baayen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Combing for Credentials: Active Pattern Extraction from Smart Reply. (arXiv:2207.10802v3 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2207.10802","description":"<p>Pre-trained large language models, such as GPT\\nobreakdash-2 and BERT, are\noften fine-tuned to achieve state-of-the-art performance on a downstream task.\nOne natural example is the ``Smart Reply'' application where a pre-trained\nmodel is tuned to provide suggested responses for a given query message. Since\nthe tuning data is often sensitive data such as emails or chat transcripts, it\nis important to understand and mitigate the risk that the model leaks its\ntuning data. We investigate potential information leakage vulnerabilities in a\ntypical Smart Reply pipeline. We consider a realistic setting where the\nadversary can only interact with the underlying model through a front-end\ninterface that constrains what types of queries can be sent to the model.\nPrevious attacks do not work in these settings, but require the ability to send\nunconstrained queries directly to the model. Even when there are no constraints\non the queries, previous attacks typically require thousands, or even millions,\nof queries to extract useful information, while our attacks can extract\nsensitive data in just a handful of queries. We introduce a new type of active\nextraction attack that exploits canonical patterns in text containing sensitive\ndata. We show experimentally that it is possible for an adversary to extract\nsensitive user information present in the training data, even in realistic\nsettings where all interactions with the model must go through a front-end that\nlimits the types of queries. We explore potential mitigation strategies and\ndemonstrate empirically how differential privacy appears to be a reasonably\neffective defense mechanism to such pattern extraction attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jayaraman_B/0/1/0/all/0/1\">Bargav Jayaraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_E/0/1/0/all/0/1\">Esha Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chase_M/0/1/0/all/0/1\">Melissa Chase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Sambuddha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1\">David Evans</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Representations of Mathematical Expressions in a Continuous Vector Space. (arXiv:2211.08142v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08142","description":"<p>Mathematical notation makes up a large portion of STEM literature, yet\nfinding semantic representations for formulae remains a challenging problem.\nBecause mathematical notation is precise, and its meaning changes significantly\nwith small character shifts, the methods that work for natural text do not\nnecessarily work well for mathematical expressions. This work describes an\napproach for representing mathematical expressions in a continuous vector\nspace. We use the encoder of a sequence-to-sequence architecture, trained on\nvisually different but mathematically equivalent expressions, to generate\nvector representations (or embeddings). We compare this approach with a\nstructural approach that considers visual layout to embed an expression and\nshow that our proposed approach is better at capturing mathematical semantics.\nFinally, to expedite future research, we publish a corpus of equivalent\ntranscendental and algebraic expression pairs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gangwar_N/0/1/0/all/0/1\">Neeraj Gangwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kani_N/0/1/0/all/0/1\">Nickvash Kani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Social media mining for toxicovigilance of prescription medications: End-to-end pipeline, challenges and future work. (arXiv:2211.10443v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.10443","description":"<p>Substance use, substance use disorder, and overdoses related to substance use\nare major public health problems globally and in the United States. A key\naspect of addressing these problems from a public health standpoint is improved\nsurveillance. Traditional surveillance systems are laggy, and social media are\npotentially useful sources of timely data. However, mining knowledge from\nsocial media is challenging, and requires the development of advanced\nartificial intelligence, specifically natural language processing (NLP) and\nmachine learning methods. We developed a sophisticated end-to-end pipeline for\nmining information about nonmedical prescription medication use from social\nmedia, namely Twitter and Reddit. Our pipeline employs supervised machine\nlearning and NLP for filtering out noise and characterizing the chatter. In\nthis paper, we describe our end-to-end pipeline developed over four years. In\naddition to describing our data mining infrastructure, we discuss existing\nchallenges in social media mining for toxicovigilance, and possible future\nresearch directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarker_A/0/1/0/all/0/1\">Abeed Sarker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Triplet: Leveraging the Most Data for Multimodal Machine Translation. (arXiv:2212.10313v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10313","description":"<p>Multimodal machine translation (MMT) aims to improve translation quality by\nincorporating information from other modalities, such as vision. Previous MMT\nsystems mainly focus on better access and use of visual information and tend to\nvalidate their methods on image-related datasets. These studies face two\nchallenges. First, they can only utilize triple data (bilingual texts with\nimages), which is scarce; second, current benchmarks are relatively restricted\nand do not correspond to realistic scenarios. Therefore, this paper\ncorrespondingly establishes new methods and new datasets for MMT. First, we\npropose a framework 2/3-Triplet with two new approaches to enhance MMT by\nutilizing large-scale non-triple data: monolingual image-text data and parallel\ntext-only data. Second, we construct an English-Chinese {e}-commercial\n{m}ulti{m}odal {t}ranslation dataset (including training and testing), named\nEMMT, where its test set is carefully selected as some words are ambiguous and\nshall be translated mistakenly without the help of images. Experiments show\nthat our method is more suitable for real-world scenarios and can significantly\nimprove translation performance by using more non-triple data. In addition, our\nmodel also rivals various SOTA models in conventional multimodal translation\nbenchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yaoming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zewei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shanbo Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Luyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Liwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingxuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reveal the Unknown: Out-of-Knowledge-Base Mention Discovery with Entity Linking. (arXiv:2302.07189v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07189","description":"<p>Discovering entity mentions that are out of a Knowledge Base (KB) from texts\nplays a critical role in KB maintenance, but has not yet been fully explored.\nThe current methods are mostly limited to the simple threshold-based approach\nand feature-based classification, and the datasets for evaluation are\nrelatively rare. We propose BLINKout, a new BERT-based Entity Linking (EL)\nmethod which can identify mentions that do not have corresponding KB entities\nby matching them to a special NIL entity. To better utilize BERT, we propose\nnew techniques including NIL entity representation and classification, with\nsynonym enhancement. We also apply KB Pruning and Versioning strategies to\nautomatically construct out-of-KB datasets from common in-KB EL datasets.\nResults on five datasets of clinical notes, biomedical publications, and\nWikipedia articles in various domains show the advantages of BLINKout over\nexisting methods to identify out-of-KB mentions for the medical ontologies,\nUMLS, SNOMED CT, and the general KB, WikiData.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yinan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1\">Ian Horrocks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models. (arXiv:2302.07371v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07371","description":"<p>Pretrained Language Models (PLMs) harbor inherent social biases that can\nresult in harmful real-world implications. Such social biases are measured\nthrough the probability values that PLMs output for different social groups and\nattributes appearing in a set of test sentences. However, bias testing is\ncurrently cumbersome since the test sentences are generated either from a\nlimited set of manual templates or need expensive crowd-sourcing. We instead\npropose using ChatGPT for controllable generation of test sentences, given any\narbitrary user-specified combination of social groups and attributes appearing\nin the test sentences. When compared to template-based methods, our approach\nusing ChatGPT for test sentence generation is superior in detecting social\nbias, especially in challenging settings such as intersectional biases. We\npresent an open-source comprehensive bias testing framework (BiasTestGPT),\nhosted on HuggingFace, that can be plugged into any open-source PLM for bias\ntesting. We provide a large diverse dataset of test sentences generated by\nChatGPT that satisfies the specified social group and attribute requirements\nand matches the quality of human-generated sentences. We thus enable seamless\nopen-ended social bias testing of PLMs through an automatic large-scale\ngeneration of diverse test sentences for any combination of social categories\nand attributes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kocielnik_R/0/1/0/all/0/1\">Rafal Kocielnik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhumoye_S/0/1/0/all/0/1\">Shrimai Prabhumoye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_V/0/1/0/all/0/1\">Vivian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1\">Roy Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alvarez_R/0/1/0/all/0/1\">R. Michael Alvarez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Integrating Image Features with Convolutional Sequence-to-sequence Network for Multilingual Visual Question Answering. (arXiv:2303.12671v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2303.12671","description":"<p>Visual Question Answering (VQA) is a task that requires computers to give\ncorrect answers for the input questions based on the images. This task can be\nsolved by humans with ease but is a challenge for computers. The\nVLSP2022-EVJVQA shared task carries the Visual Question Answering task in the\nmultilingual domain on a newly released dataset: UIT-EVJVQA, in which the\nquestions and answers are written in three different languages: English,\nVietnamese and Japanese. We approached the challenge as a sequence-to-sequence\nlearning task, in which we integrated hints from pre-trained state-of-the-art\nVQA models and image features with Convolutional Sequence-to-Sequence network\nto generate the desired answers. Our results obtained up to 0.3442 by F1 score\non the public test set, 0.4210 on the private test set, and placed 3rd in the\ncompetition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thai_T/0/1/0/all/0/1\">Triet Minh Thai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1\">Son T. Luu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InterviewBot: Real-Time End-to-End Dialogue System to Interview Students for College Admission. (arXiv:2303.15049v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.15049","description":"<p>We present the InterviewBot that dynamically integrates conversation history\nand customized topics into a coherent embedding space to conduct 10 mins\nhybrid-domain (open and closed) conversations with foreign students applying to\nU.S. colleges for assessing their academic and cultural readiness. To build a\nneural-based end-to-end dialogue model, 7,361 audio recordings of\nhuman-to-human interviews are automatically transcribed, where 440 are manually\ncorrected for finetuning and evaluation. To overcome the input/output size\nlimit of a transformer-based encoder-decoder model, two new methods are\nproposed, context attention and topic storing, allowing the model to make\nrelevant and consistent interactions. Our final model is tested both\nstatistically by comparing its responses to the interview data and dynamically\nby inviting professional interviewers and various students to interact with it\nin real-time, finding it highly satisfactory in fluency and context awareness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keyes_N/0/1/0/all/0/1\">Nathan Keyes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crawford_T/0/1/0/all/0/1\">Terry Crawford</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Research without Re-search: Maximal Update Parametrization Yields Accurate Loss Prediction across Scales. (arXiv:2304.06875v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.06875","description":"<p>As language models scale up, it becomes increasingly expensive to verify\nresearch ideas because conclusions on small models do not trivially transfer to\nlarge ones. A possible solution is to establish a generic system that directly\npredicts some metrics for large models solely based on the results and\nhyperparameters from small models. Existing methods based on scaling laws\nrequire hyperparameter search on the largest models, which is impractical with\nlimited resources. We address this issue by presenting our discoveries\nindicating that Maximal Update parametrization (Mup) enables accurate fitting\nof scaling laws for hyperparameters close to common loss basins, without any\nsearch. Thus, different models can be directly compared on large scales with\nloss prediction even before the training starts. We propose a new paradigm as a\nfirst step towards reliable academic research for any model scale without heavy\ncomputation. Code is publicly available at\nhttps://github.com/cofe-ai/Mu-scaling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yiqun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yequan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AMR4NLI: Interpretable and robust NLI measures from semantic graphs. (arXiv:2306.00936v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00936","description":"<p>The task of natural language inference (NLI) asks whether a given premise\n(expressed in NL) entails a given NL hypothesis. NLI benchmarks contain human\nratings of entailment, but the meaning relationships driving these ratings are\nnot formalized. Can the underlying sentence pair relationships be made more\nexplicit in an interpretable yet robust fashion? We compare semantic structures\nto represent premise and hypothesis, including sets of contextualized\nembeddings and semantic graphs (Abstract Meaning Representations), and measure\nwhether the hypothesis is a semantic substructure of the premise, utilizing\ninterpretable metrics. Our evaluation on three English benchmarks finds value\nin both contextualized embeddings and semantic graphs; moreover, they provide\ncomplementary signals, and can be leveraged together in a hybrid model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Opitz_J/0/1/0/all/0/1\">Juri Opitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wein_S/0/1/0/all/0/1\">Shira Wein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steen_J/0/1/0/all/0/1\">Julius Steen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1\">Anette Frank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCALE: Scaling up the Complexity for Advanced Language Model Evaluation. (arXiv:2306.09237v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09237","description":"<p>Recent strides in Large Language Models (LLMs) have saturated many NLP\nbenchmarks (even professional domain-specific ones), emphasizing the need for\nnovel, more challenging novel ones to properly assess LLM capabilities. In this\npaper, we introduce a novel NLP benchmark that poses challenges to current LLMs\nacross four key dimensions: processing long documents (up to 50K tokens),\nutilizing domain specific knowledge (embodied in legal texts), multilingual\nunderstanding (covering five languages), and multitasking (comprising legal\ndocument to document Information Retrieval, Court View Generation, Leading\nDecision Summarization, Citation Extraction, and eight challenging Text\nClassification tasks). Our benchmark comprises diverse legal NLP datasets from\nthe Swiss legal system, allowing for a comprehensive study of the underlying\nNon-English, inherently multilingual, federal legal system. Despite recent\nadvances, efficiently processing long documents for intense review/analysis\ntasks remains an open challenge for language models. Also, comprehensive,\ndomain-specific benchmarks requiring high expertise to develop are rare, as are\nmultilingual benchmarks. This scarcity underscores our contribution's value,\nconsidering most public models are trained predominantly on English corpora,\nwhile other languages remain understudied, particularly for practical\ndomain-specific NLP tasks. Our benchmark allows for testing and advancing the\nstate-of-the-art LLMs. As part of our study, we evaluate several pre-trained\nmultilingual language models on our benchmark to establish strong baselines as\na point of reference. Despite the large size of our datasets (tens to hundreds\nof thousands of examples), existing publicly available models struggle with\nmost tasks, even after in-domain pretraining. We publish all resources\n(benchmark suite, pre-trained models, code) under a fully permissive open CC\nBY-SA license.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rasiah_V/0/1/0/all/0/1\">Vishvaksenan Rasiah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stern_R/0/1/0/all/0/1\">Ronja Stern</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matoshi_V/0/1/0/all/0/1\">Veton Matoshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sturmer_M/0/1/0/all/0/1\">Matthias St&#xfc;rmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalkidis_I/0/1/0/all/0/1\">Ilias Chalkidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1\">Daniel E. Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niklaus_J/0/1/0/all/0/1\">Joel Niklaus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification Task. (arXiv:2307.06954v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.06954","description":"<p>Conspiracy Theory Identication task is a new shared task proposed for the\nfirst time at the Evalita 2023. The ACTI challenge, based exclusively on\ncomments published on conspiratorial channels of telegram, is divided into two\nsubtasks: (i) Conspiratorial Content Classification: identifying conspiratorial\ncontent and (ii) Conspiratorial Category Classification about specific\nconspiracy theory classification. A total of fifteen teams participated in the\ntask for a total of 81 submissions. We illustrate the best performing\napproaches were based on the utilization of large language models. We finally\ndraw conclusions about the utilization of these models for counteracting the\nspreading of misinformation in online platforms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Russo_G/0/1/0/all/0/1\">Giuseppe Russo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoehr_N/0/1/0/all/0/1\">Niklas Stoehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1\">Manoel Horta Ribeiro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A scoping review on multimodal deep learning in biomedical images and texts. (arXiv:2307.07362v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.07362","description":"<p>Computer-assisted diagnostic and prognostic systems of the future should be\ncapable of simultaneously processing multimodal data. Multimodal deep learning\n(MDL), which involves the integration of multiple sources of data, such as\nimages and text, has the potential to revolutionize the analysis and\ninterpretation of biomedical data. However, it only caught researchers'\nattention recently. To this end, there is a critical need to conduct a\nsystematic review on this topic, identify the limitations of current work, and\nexplore future directions. In this scoping review, we aim to provide a\ncomprehensive overview of the current state of the field and identify key\nconcepts, types of studies, and research gaps with a focus on biomedical images\nand texts joint learning, mainly because these two were the most commonly\navailable data types in MDL research. This study reviewed the current uses of\nmultimodal deep learning on five tasks: (1) Report generation, (2) Visual\nquestion answering, (3) Cross-modal retrieval, (4) Computer-aided diagnosis,\nand (5) Semantic segmentation. Our results highlight the diverse applications\nand potential of MDL and suggest directions for future research in the field.\nWe hope our review will facilitate the collaboration of natural language\nprocessing (NLP) and medical imaging communities and support the next\ngeneration of decision-making and computer-assisted diagnostic system\ndevelopment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhaoyi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingquan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing Dataset Annotation Quality Management in the Wild. (arXiv:2307.08153v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.08153","description":"<p>Data quality is crucial for training accurate, unbiased, and trustworthy\nmachine learning models and their correct evaluation. Recent works, however,\nhave shown that even popular datasets used to train and evaluate\nstate-of-the-art models contain a non-negligible amount of erroneous\nannotations, bias or annotation artifacts. There exist best practices and\nguidelines regarding annotation projects. But to the best of our knowledge, no\nlarge-scale analysis has been performed as of yet on how quality management is\nactually conducted when creating natural language datasets and whether these\nrecommendations are followed. Therefore, we first survey and summarize\nrecommended quality management practices for dataset creation as described in\nthe literature and provide suggestions on how to apply them. Then, we compile a\ncorpus of 591 scientific publications introducing text datasets and annotate it\nfor quality-related aspects, such as annotator management, agreement,\nadjudication or data validation. Using these annotations, we then analyze how\nquality management is conducted in practice. We find that a majority of the\nannotated publications apply good or very good quality management. However, we\ndeem the effort of 30% of the works as only subpar. Our analysis also shows\ncommon errors, especially with using inter-annotator agreement and computing\nannotation error rates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Klie_J/0/1/0/all/0/1\">Jan-Christoph Klie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castilho_R/0/1/0/all/0/1\">Richard Eckart de Castilho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OUTFOX: LLM-generated Essay Detection through In-context Learning with Adversarially Generated Examples. (arXiv:2307.11729v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11729","description":"<p>Large Language Models (LLMs) have achieved human-level fluency in text\ngeneration, making it difficult to distinguish between human-written and\nLLM-generated texts. This poses a growing risk of misuse of LLMs and demands\nthe development of detectors to identify LLM-generated texts. However, existing\ndetectors lack robustness against attacks: they degrade detection accuracy by\nsimply paraphrasing LLM-generated texts. Furthermore, a malicious user might\nattempt to deliberately evade the detectors based on detection results, but\nthis has not been assumed in previous studies. In this paper, we propose\nOUTFOX, a framework that improves the robustness of LLM-generated-text\ndetectors by allowing both the detector and the attacker to consider each\nother's output. In this framework, the attacker uses the detector's prediction\nlabels as examples for in-context learning and adversarially generates essays\nthat are harder to detect, while the detector uses the adversarially generated\nessays as examples for in-context learning to learn to detect essays from a\nstrong attacker. Experiments in the domain of student essays show that the\nproposed detector improves the detection performance on the attacker-generated\ntexts by up to +41.3 points in F1-score. Furthermore, the proposed detector\nshows a state-of-the-art detection performance: up to 96.9 points in F1-score,\nbeating existing detectors on non-attacked texts. Finally, the proposed\nattacker drastically degrades the performance of detectors by up to -57.0\npoints F1-score, massively outperforming the baseline paraphrasing method for\nevading detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koike_R/0/1/0/all/0/1\">Ryuto Koike</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaneko_M/0/1/0/all/0/1\">Masahiro Kaneko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okazaki_N/0/1/0/all/0/1\">Naoaki Okazaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment enabled by Large Language Models. (arXiv:2307.11772v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2307.11772","description":"<p>The task of entity alignment between knowledge graphs (KGs) aims to identify\nevery pair of entities from two different KGs that represent the same entity.\nMany machine learning-based methods have been proposed for this task. However,\nto our best knowledge, existing methods all require manually crafted seed\nalignments, which are expensive to obtain. In this paper, we propose the first\nfully automatic alignment method named AutoAlign, which does not require any\nmanually crafted seed alignments. Specifically, for predicate embeddings,\nAutoAlign constructs a predicate-proximity-graph with the help of large\nlanguage models to automatically capture the similarity between predicates\nacross two KGs. For entity embeddings, AutoAlign first computes the entity\nembeddings of each KG independently using TransE, and then shifts the two KGs'\nentity embeddings into the same vector space by computing the similarity\nbetween entities based on their attributes. Thus, both predicate alignment and\nentity alignment can be done without manually crafted seed alignments.\nAutoAlign is not only fully automatic, but also highly effective. Experiments\nusing real-world KGs show that AutoAlign improves the performance of entity\nalignment significantly compared to state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yixin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trisedya_B/0/1/0/all/0/1\">Bayu Distiawan Trisedya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaoyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hong Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jianzhong Qi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation. (arXiv:2308.00085v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.00085","description":"<p>Recent approaches to empathetic response generation try to incorporate\ncommonsense knowledge or reasoning about the causes of emotions to better\nunderstand the user's experiences and feelings. However, these approaches\nmainly focus on understanding the causalities of context from the user's\nperspective, ignoring the system's perspective. In this paper, we propose a\ncommonsense-based causality explanation approach for diverse empathetic\nresponse generation that considers both the user's perspective (user's desires\nand reactions) and the system's perspective (system's intentions and\nreactions). We enhance ChatGPT's ability to reason for the system's perspective\nby integrating in-context learning with commonsense knowledge. Then, we\nintegrate the commonsense-based causality explanation with both ChatGPT and a\nT5-based model. Experimental evaluations demonstrate that our method\noutperforms other comparable methods on both automatic and human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yahui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1\">Koji Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1\">Tatsuya Kawahara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Generalist Foundation Model for Radiology. (arXiv:2308.02463v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.02463","description":"<p>In this study, we aim to initiate the development of Radiology Foundation\nModel, termed as RadFM.We consider the construction of foundational models from\nthe perspectives of dataset construction, model design, and thorough\nevaluation. Our contribution can be concluded as follows: (i), we construct a\nlarge-scale Medical Multi-modal Dataset, MedMD, which consists of 16M 2D and 3D\nmedical scans with high-quality text descriptions or reports across various\ndata formats, modalities, and tasks, covering over 5000 distinct diseases. To\nthe best of our knowledge, this is the first large-scale, high-quality, medical\nvisual-language dataset, with both 2D and 3D scans; (ii ), we propose an\narchitecture that enables visually conditioned generative pre-training, i.e.,\nallowing for integration of text input with 2D or 3D medical scans, and\ngenerate responses for diverse radiologic tasks. The model was initially\npre-trained on MedMD and subsequently fine-tuned on the domain-specific\ndataset, which is a radiologic cleaned version of MedMD, containing 3M\nradiologic visual-language pairs, termed as RadMD; (iii), we propose a new\nevaluation benchmark, RadBench, that comprises five tasks, including modality\nrecognition, disease diagnosis, visual question answering, report generation\nand rationale diagnosis, aiming to comprehensively assess the capability of\nfoundation models in handling practical clinical problems. We conduct both\nautomatic and human evaluation on RadBench, in both cases, RadFM significantly\noutperforms existing multi-modal foundation models. The codes, data, and model\ncheckpoint will all be made publicly available to promote further research and\ndevelopment in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chaoyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoman Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weidi Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing. (arXiv:2308.06035v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.06035","description":"<p>The advanced language processing abilities of large language models (LLMs)\nhave stimulated debate over their capacity to replicate human-like cognitive\nprocesses. One differentiating factor between language processing in LLMs and\nhumans is that language input is often grounded in several perceptual\nmodalities, whereas most LLMs process solely text-based information. Multimodal\ngrounding allows humans to integrate - e.g. visual context with linguistic\ninformation and thereby place constraints on the space of upcoming words,\nreducing cognitive load and improving comprehension. Recent multimodal LLMs\n(mLLMs) combine a visual-linguistic embedding space with a transformer type\nattention mechanism for next-word prediction. Here we ask whether predictive\nlanguage processing based on multimodal input in mLLMs aligns with humans.\nTwo-hundred participants watched short audio-visual clips and estimated\npredictability of an upcoming verb or noun. The same clips were processed by\nthe mLLM CLIP, with predictability scores based on comparing image and text\nfeature vectors. Eye-tracking was used to estimate what visual features\nparticipants attended to, and CLIP's visual attention weights were recorded. We\nfind that alignment of predictability scores was driven by multimodality of\nCLIP (no alignment for a unimodal state-of-the-art LLM) and by the attention\nmechanism (no alignment when attention weights were perturbated or when the\nsame input was fed to a multimodal model without attention). We further find a\nsignificant spatial overlap between CLIP's visual attention weights and human\neye-tracking data. Results suggest that comparable processes of integrating\nmultimodal information, guided by attention to relevant visual features,\nsupports predictive language processing in mLLMs and humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kewenig_V/0/1/0/all/0/1\">Viktor Kewenig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edwards_C/0/1/0/all/0/1\">Christopher Edwards</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DEstalenx_Q/0/1/0/all/0/1\">Quitterie Lacome DEstalenx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rechardt_A/0/1/0/all/0/1\">Akilles Rechardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skipper_J/0/1/0/all/0/1\">Jeremy I Skipper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vigliocco_G/0/1/0/all/0/1\">Gabriella Vigliocco</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CausalLM is not optimal for in-context learning. (arXiv:2308.06912v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.06912","description":"<p>Recent empirical evidence indicates that transformer based in-context\nlearning performs better when using a prefix language model (prefixLM), in\nwhich in-context samples can all attend to each other, compared to causal\nlanguage models (causalLM), which use auto-regressive attention that prohibits\nin-context samples to attend to future samples. While this result is intuitive,\nit is not understood from a theoretical perspective. In this paper we take a\ntheoretical approach and analyze the convergence behavior of prefixLM and\ncausalLM under a certain parameter construction. Our analysis shows that both\nLM types converge to their stationary points at a linear rate, but that while\nprefixLM converges to the optimal solution of linear regression, causalLM\nconvergence dynamics follows that of an online gradient descent algorithm,\nwhich is not guaranteed to be optimal even as the number of samples grows\ninfinitely. We supplement our theoretical claims with empirical experiments\nover synthetic and real tasks and using various types of transformers. Our\nexperiments verify that causalLM consistently underperforms prefixLM in all\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levinboim_T/0/1/0/all/0/1\">Tomer Levinboim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_S/0/1/0/all/0/1\">Sebastian Goodman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLaMA-Reviewer: Advancing Code Review Automation with Large Language Models through Parameter-Efficient Fine-Tuning. (arXiv:2308.11148v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2308.11148","description":"<p>The automation of code review activities, a long-standing pursuit in software\nengineering, has been primarily addressed by numerous domain-specific\npre-trained models. Despite their success, these models frequently demand\nextensive resources for pre-training from scratch. In contrast, Large Language\nModels (LLMs) provide an intriguing alternative, given their remarkable\ncapabilities when supplemented with domain-specific knowledge. However, their\npotential for automating code review tasks remains largely unexplored.\n</p>\n<p>In response to this research gap, we present LLaMA-Reviewer, an innovative\nframework that leverages the capabilities of LLaMA, a popular LLM, in the realm\nof code review. Mindful of resource constraints, this framework employs\nparameter-efficient fine-tuning (PEFT) methods, delivering high performance\nwhile using less than 1% of trainable parameters.\n</p>\n<p>An extensive evaluation of LLaMA-Reviewer is conducted on two diverse,\npublicly available datasets. Notably, even with the smallest LLaMA base model\nconsisting of 6.7B parameters and a limited number of tuning epochs,\nLLaMA-Reviewer equals the performance of existing code-review-focused models.\n</p>\n<p>The ablation experiments provide insights into the influence of various\nfine-tuning process components, including input representation, instruction\ntuning, and different PEFT methods. To foster continuous progress in this\nfield, the code and all PEFT-weight plugins have been made open-source.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junyi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaojia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Li Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_C/0/1/0/all/0/1\">Chun Zuo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding. (arXiv:2308.11592v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.11592","description":"<p>In the era of Large Language Models (LLMs), tremendous strides have been made\nin the field of multimodal understanding. However, existing advanced algorithms\nare limited to effectively utilizing the immense representation capabilities\nand rich world knowledge inherent to these large pre-trained models, and the\nbeneficial connections among tasks within the context of text-rich scenarios\nhave not been sufficiently explored. In this work, we introduce UniDoc, a novel\nmultimodal model equipped with text detection and recognition capabilities,\nwhich are deficient in existing approaches. Moreover, UniDoc capitalizes on the\nbeneficial interactions among tasks to enhance the performance of each\nindividual task. To implement UniDoc, we perform unified multimodal instruct\ntuning on the contributed large-scale instruction following datasets.\nQuantitative and qualitative experimental results show that UniDoc sets\nstate-of-the-art scores across multiple challenging benchmarks. To the best of\nour knowledge, this is the first large multimodal model capable of simultaneous\ntext detection, recognition, spotting, and understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Hao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jingqun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Jinghui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wengang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Houqiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Can Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying depression-related topics in smartphone-collected free-response speech recordings using an automatic speech recognition system and a deep learning topic model. (arXiv:2308.11773v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11773","description":"<p>Language use has been shown to correlate with depression, but large-scale\nvalidation is needed. Traditional methods like clinic studies are expensive.\nSo, natural language processing has been employed on social media to predict\ndepression, but limitations remain-lack of validated labels, biased user\nsamples, and no context. Our study identified 29 topics in 3919\nsmartphone-collected speech recordings from 265 participants using the Whisper\ntool and BERTopic model. Six topics with a median PHQ-8 greater than or equal\nto 10 were regarded as risk topics for depression: No Expectations, Sleep,\nMental Therapy, Haircut, Studying, and Coursework. To elucidate the topic\nemergence and associations with depression, we compared behavioral (from\nwearables) and linguistic characteristics across identified topics. The\ncorrelation between topic shifts and changes in depression severity over time\nwas also investigated, indicating the importance of longitudinally monitoring\nlanguage use. We also tested the BERTopic model on a similar smaller dataset\n(356 speech recordings from 57 participants), obtaining some consistent\nresults. In summary, our findings demonstrate specific speech topics may\nindicate depression severity. The presented data-driven workflow provides a\npractical approach to collecting and analyzing large-scale speech data from\nreal-world settings for digital health research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuezhou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Folarin_A/0/1/0/all/0/1\">Amos A Folarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dineley_J/0/1/0/all/0/1\">Judith Dineley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_P/0/1/0/all/0/1\">Pauline Conde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Angel_V/0/1/0/all/0/1\">Valeria de Angel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shaoxiong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjan_Y/0/1/0/all/0/1\">Yatharth Ranjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_Z/0/1/0/all/0/1\">Zulqarnain Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stewart_C/0/1/0/all/0/1\">Callum Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laiou_P/0/1/0/all/0/1\">Petroula Laiou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankesara_H/0/1/0/all/0/1\">Heet Sankesara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1\">Linglong Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matcham_F/0/1/0/all/0/1\">Faith Matcham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_K/0/1/0/all/0/1\">Katie M White</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oetzmann_C/0/1/0/all/0/1\">Carolin Oetzmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamers_F/0/1/0/all/0/1\">Femke Lamers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddi_S/0/1/0/all/0/1\">Sara Siddi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simblett_S/0/1/0/all/0/1\">Sara Simblett</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1\">Bj&#xf6;rn W. Schuller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vairavan_S/0/1/0/all/0/1\">Srinivasan Vairavan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wykes_T/0/1/0/all/0/1\">Til Wykes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haro_J/0/1/0/all/0/1\">Josep Maria Haro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penninx_B/0/1/0/all/0/1\">Brenda WJH Penninx</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_V/0/1/0/all/0/1\">Vaibhav A Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hotopf_M/0/1/0/all/0/1\">Matthew Hotopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1\">Richard JB Dobson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cummins_N/0/1/0/all/0/1\">Nicholas Cummins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+consortium_R/0/1/0/all/0/1\">RADAR-CNS consortium</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Instructions to Intrinsic Human Values -- A Survey of Alignment Goals for Big Models. (arXiv:2308.12014v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.12014","description":"<p>Big models, exemplified by Large Language Models (LLMs), are models typically\npre-trained on massive data and comprised of enormous parameters, which not\nonly obtain significantly improved performance across diverse tasks but also\npresent emergent capabilities absent in smaller models. However, the growing\nintertwining of big models with everyday human lives poses potential risks and\nmight cause serious social harm. Therefore, many efforts have been made to\nalign LLMs with humans to make them better follow user instructions and satisfy\nhuman preferences. Nevertheless, `what to align with' has not been fully\ndiscussed, and inappropriate alignment goals might even backfire. In this\npaper, we conduct a comprehensive survey of different alignment goals in\nexisting work and trace their evolution paths to help identify the most\nessential goal. Particularly, we investigate related works from two\nperspectives: the definition of alignment goals and alignment evaluation. Our\nanalysis encompasses three distinct levels of alignment goals and reveals a\ngoal transformation from fundamental abilities to value orientation, indicating\nthe potential of intrinsic human values as the alignment goal for enhanced\nLLMs. Based on such results, we further discuss the challenges of achieving\nsuch intrinsic value alignment and provide a collection of available resources\nfor future research on the alignment of big models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jing Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiting Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Construction Grammar and Language Models. (arXiv:2308.13315v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.13315","description":"<p>Recent progress in deep learning and natural language processing has given\nrise to powerful models that are primarily trained on a cloze-like task and\nshow some evidence of having access to substantial linguistic information,\nincluding some constructional knowledge. This groundbreaking discovery presents\nan exciting opportunity for a synergistic relationship between computational\nmethods and Construction Grammar research. In this chapter, we explore three\ndistinct approaches to the interplay between computational methods and\nConstruction Grammar: (i) computational methods for text analysis, (ii)\ncomputational Construction Grammar, and (iii) deep learning models, with a\nparticular focus on language models. We touch upon the first two approaches as\na contextual foundation for the use of computational methods before providing\nan accessible, yet comprehensive overview of deep learning models, which also\naddresses reservations construction grammarians may have. Additionally, we\ndelve into experiments that explore the emergence of constructionally relevant\ninformation within these models while also examining the aspects of\nConstruction Grammar that may pose challenges for these models. This chapter\naims to foster collaboration between researchers in the fields of natural\nlanguage processing and Construction Grammar. By doing so, we hope to pave the\nway for new insights and advancements in both these fields.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Madabushi_H/0/1/0/all/0/1\">Harish Tayyar Madabushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romain_L/0/1/0/all/0/1\">Laurence Romain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milin_P/0/1/0/all/0/1\">Petar Milin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Divjak_D/0/1/0/all/0/1\">Dagmar Divjak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do-Not-Answer: A Dataset for Evaluating Safeguards in LLMs. (arXiv:2308.13387v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.13387","description":"<p>With the rapid evolution of large language models (LLMs), new and\nhard-to-predict harmful capabilities are emerging. This requires developers to\nbe able to identify risks through the evaluation of \"dangerous capabilities\" in\norder to responsibly deploy LLMs. In this work, we collect the first\nopen-source dataset to evaluate safeguards in LLMs, and deploy safer\nopen-source LLMs at a low cost. Our dataset is curated and filtered to consist\nonly of instructions that responsible language models should not follow. We\nannotate and assess the responses of six popular LLMs to these instructions.\nBased on our annotation, we proceed to train several BERT-like classifiers, and\nfind that these small classifiers can achieve results that are comparable with\nGPT-4 on automatic safety evaluation. Warning: this paper contains example data\nthat may be offensive, harmful, or biased.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuxia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xudong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ParaGuide: Guided Diffusion Paraphrasers for Plug-and-Play Textual Style Transfer. (arXiv:2308.15459v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.15459","description":"<p>Textual style transfer is the task of transforming stylistic properties of\ntext while preserving meaning. Target \"styles\" can be defined in numerous ways,\nranging from single attributes (e.g, formality) to authorship (e.g,\nShakespeare). Previous unsupervised style-transfer approaches generally rely on\nsignificant amounts of labeled data for only a fixed set of styles or require\nlarge language models. In contrast, we introduce a novel diffusion-based\nframework for general-purpose style transfer that can be flexibly adapted to\narbitrary target styles at inference time. Our parameter-efficient approach,\nParaGuide, leverages paraphrase-conditioned diffusion models alongside\ngradient-based guidance from both off-the-shelf classifiers and strong existing\nstyle embedders to transform the style of text while preserving semantic\ninformation. We validate the method on the Enron Email Corpus, with both human\nand automatic evaluations, and find that it outperforms strong baselines on\nformality, sentiment, and even authorship style transfer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Horvitz_Z/0/1/0/all/0/1\">Zachary Horvitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1\">Ajay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1\">Kathleen McKeown</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is the U.S. Legal System Ready for AI's Challenges to Human Values?. (arXiv:2308.15906v3 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2308.15906","description":"<p>Our interdisciplinary study investigates how effectively U.S. laws confront\nthe challenges posed by Generative AI to human values. Through an analysis of\ndiverse hypothetical scenarios crafted during an expert workshop, we have\nidentified notable gaps and uncertainties within the existing legal framework\nregarding the protection of fundamental values, such as privacy, autonomy,\ndignity, diversity, equity, and physical/mental well-being. Constitutional and\ncivil rights, it appears, may not provide sufficient protection against\nAI-generated discriminatory outputs. Furthermore, even if we exclude the\nliability shield provided by Section 230, proving causation for defamation and\nproduct liability claims is a challenging endeavor due to the intricate and\nopaque nature of AI systems. To address the unique and unforeseeable threats\nposed by Generative AI, we advocate for legal frameworks that evolve to\nrecognize new threats and provide proactive, auditable guidelines to industry\nstakeholders. Addressing these issues requires deep interdisciplinary\ncollaborations to identify harms, values, and mitigation strategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheong_I/0/1/0/all/0/1\">Inyoung Cheong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caliskan_A/0/1/0/all/0/1\">Aylin Caliskan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohno_T/0/1/0/all/0/1\">Tadayoshi Kohno</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16137","description":"<p>In recent years, there have been remarkable advancements in the performance\nof Transformer-based Large Language Models (LLMs) across various domains. As\nthese LLMs are deployed for increasingly complex tasks, they often face the\nneed to conduct longer reasoning processes or understand larger contexts. In\nthese situations, the length generalization failure of LLMs on long sequences\nbecomes more prominent. Most pre-training schemes truncate training sequences\nto a fixed length. LLMs often struggle to generate fluent and coherent texts,\nlet alone carry out downstream tasks, after longer contexts, even with relative\npositional encoding designed to cope with this problem. Common solutions such\nas finetuning on longer corpora often involve daunting hardware and time costs\nand require careful training process design. To more efficiently leverage the\ngeneration capacity of existing LLMs, we theoretically and empirically\ninvestigate the main out-of-distribution (OOD) factors contributing to this\nproblem. Inspired by this diagnosis, we propose a simple yet effective solution\nfor on-the-fly length generalization, LM-Infinite. It involves only a\n$\\Lambda$-shaped attention mask (to avoid excessive attended tokens) and a\ndistance limit (to avoid unseen distances) while requiring no parameter updates\nor learning. We find it applicable to a variety of LLMs using relative-position\nencoding methods. LM-Infinite is computationally efficient with $O(n)$ time and\nspace, and demonstrates consistent text generation fluency and quality to as\nlong as 32k tokens on ArXiv and OpenWebText2 datasets, with 2.72x decoding\nspeedup. On downstream tasks such as passkey retrieval, it continues to work on\ninputs much longer than training lengths where vanilla models fail immediately.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge. (arXiv:2308.16458v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.16458","description":"<p>Pre-trained language models like ChatGPT have significantly improved code\ngeneration. As these models scale up, there is an increasing need for the\noutput to handle more intricate tasks. Moreover, in bioinformatics, generating\nfunctional programs poses additional notable challenges due to the amount of\ndomain knowledge, the need for complicated data operations, and intricate\nfunctional dependencies between the operations. Here, we present BioCoder, a\nbenchmark developed to evaluate existing pre-trained models in generating\nbioinformatics code. In relation to function-code generation, BioCoder covers\npotential package dependencies, class declarations, and global variables. It\nincorporates 1026 functions and 1243 methods in Python and Java from GitHub and\n253 examples from the Rosalind Project. BioCoder incorporates a fuzz-testing\nframework for evaluation, and we have applied it to evaluate many models\nincluding InCoder, CodeGen, CodeGen2, SantaCoder, StarCoder, StarCoder+,\nInstructCodeT5+, and ChatGPT. Our detailed analysis of these models emphasizes\nthe importance of domain knowledge, pragmatic code generation, and contextual\nunderstanding. Our dataset, benchmark, Docker images, and scripts required for\ntesting are all available at https://github.com/gersteinlab/biocoder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xiangru Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_B/0/1/0/all/0/1\">Bill Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1\">Rick Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiakang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerstein_M/0/1/0/all/0/1\">Mark Gerstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Link Prediction for Wikipedia Articles as a Natural Language Inference Task. (arXiv:2308.16469v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16469","description":"<p>Link prediction task is vital to automatically understanding the structure of\nlarge knowledge bases. In this paper, we present our system to solve this task\nat the Data Science and Advanced Analytics 2023 Competition \"Efficient and\nEffective Link Prediction\" (DSAA-2023 Competition) with a corpus containing\n948,233 training and 238,265 for public testing. This paper introduces an\napproach to link prediction in Wikipedia articles by formulating it as a\nnatural language inference (NLI) task. Drawing inspiration from recent\nadvancements in natural language processing and understanding, we cast link\nprediction as an NLI task, wherein the presence of a link between two articles\nis treated as a premise, and the task is to determine whether this premise\nholds based on the information presented in the articles. We implemented our\nsystem based on the Sentence Pair Classification for Link Prediction for the\nWikipedia Articles task. Our system achieved 0.99996 Macro F1-score and 1.00000\nMacro F1-score for the public and private test sets, respectively. Our team\nUIT-NLP ranked 3rd in performance on the private test set, equal to the scores\nof the first and second places. Our code is publicly for research purposes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Phan_C/0/1/0/all/0/1\">Chau-Thang Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc-Nam Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Programming Languages Boost Each Other via Instruction Tuning?. (arXiv:2308.16824v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16824","description":"<p>When human programmers have mastered a programming language, it would be\neasier when they learn a new programming language. In this report, we focus on\nexploring whether programming languages can boost each other during the\ninstruction fine-tuning phase of code large language models. We conduct\nextensive experiments of 8 popular programming languages (Python, JavaScript,\nTypeScript, C, C++, Java, Go, HTML) on StarCoder. Results demonstrate that\nprogramming languages can significantly improve each other. For example,\nCodeM-Python 15B trained on Python is able to increase Java by an absolute\n17.95% pass@1 on HumanEval-X. More surprisingly, we found that CodeM-HTML 7B\ntrained on the HTML corpus can improve Java by an absolute 15.24% pass@1. Our\ntraining data is released at https://github.com/NL2Code/CodeM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zan_D/0/1/0/all/0/1\">Daoguang Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1\">Ailun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1\">Bo Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1\">Taihong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_B/0/1/0/all/0/1\">Bing Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jichuan Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yafen Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianxiang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TouchStone: Evaluating Vision-Language Models by Language Models. (arXiv:2308.16890v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.16890","description":"<p>Large vision-language models (LVLMs) have recently witnessed rapid\nadvancements, exhibiting a remarkable capacity for perceiving, understanding,\nand processing visual information by connecting visual receptor with large\nlanguage models (LLMs). However, current assessments mainly focus on\nrecognizing and reasoning abilities, lacking direct evaluation of\nconversational skills and neglecting visual storytelling abilities. In this\npaper, we propose an evaluation method that uses strong LLMs as judges to\ncomprehensively evaluate the various abilities of LVLMs. Firstly, we construct\na comprehensive visual dialogue dataset TouchStone, consisting of open-world\nimages and questions, covering five major categories of abilities and 27\nsubtasks. This dataset not only covers fundamental recognition and\ncomprehension but also extends to literary creation. Secondly, by integrating\ndetailed image annotations we effectively transform the multimodal input\ncontent into a form understandable by LLMs. This enables us to employ advanced\nLLMs for directly evaluating the quality of the multimodal dialogue without\nrequiring human intervention. Through validation, we demonstrate that powerful\nLVLMs, such as GPT-4, can effectively score dialogue quality by leveraging\ntheir textual capabilities alone, aligning with human preferences. We hope our\nwork can serve as a touchstone for LVLMs' evaluation and pave the way for\nbuilding stronger LVLMs. The evaluation code is available at\nhttps://github.com/OFA-Sys/TouchStone.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1\">Shuai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shusheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jinze Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinggang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Baseline Defenses for Adversarial Attacks Against Aligned Language Models. (arXiv:2309.00614v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.00614","description":"<p>As Large Language Models quickly become ubiquitous, it becomes critical to\nunderstand their security vulnerabilities. Recent work shows that text\noptimizers can produce jailbreaking prompts that bypass moderation and\nalignment. Drawing from the rich body of work on adversarial machine learning,\nwe approach these attacks with three questions: What threat models are\npractically useful in this domain? How do baseline defense techniques perform\nin this new domain? How does LLM security differ from computer vision?\n</p>\n<p>We evaluate several baseline defense strategies against leading adversarial\nattacks on LLMs, discussing the various settings in which each is feasible and\neffective. Particularly, we look at three types of defenses: detection\n(perplexity based), input preprocessing (paraphrase and retokenization), and\nadversarial training. We discuss white-box and gray-box settings and discuss\nthe robustness-performance trade-off for each of the defenses considered. We\nfind that the weakness of existing discrete optimizers for text, combined with\nthe relatively high costs of optimization, makes standard adaptive attacks more\nchallenging for LLMs. Future research will be needed to uncover whether more\npowerful optimizers can be developed, or whether the strength of filtering and\npreprocessing defenses is greater in the LLMs domain than it has been in\ncomputer vision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Neel Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1\">Avi Schwarzschild</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yuxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Somepalli_G/0/1/0/all/0/1\">Gowthami Somepalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirchenbauer_J/0/1/0/all/0/1\">John Kirchenbauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chiang_P/0/1/0/all/0/1\">Ping-yeh Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1\">Micah Goldblum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1\">Aniruddha Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geiping_J/0/1/0/all/0/1\">Jonas Geiping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1\">Tom Goldstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-05T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}