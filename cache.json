{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-05-23T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Judgments of research co-created by generative AI: experimental evidence. (arXiv:2305.11873v1 [cs.HC])","link":"http://arxiv.org/abs/2305.11873","description":"<p>The introduction of ChatGPT has fuelled a public debate on the use of\ngenerative AI (large language models; LLMs), including its use by researchers.\nIn the current work, we test whether delegating parts of the research process\nto LLMs leads people to distrust and devalue researchers and scientific output.\nParticipants (N=402) considered a researcher who delegates elements of the\nresearch process to a PhD student or LLM, and rated (1) moral acceptability,\n(2) trust in the scientist to oversee future projects, and (3) the accuracy and\nquality of the output. People judged delegating to an LLM as less acceptable\nthan delegating to a human (d = -0.78). Delegation to an LLM also decreased\ntrust to oversee future research projects (d = -0.80), and people thought the\nresults would be less accurate and of lower quality (d = -0.85). We discuss how\nthis devaluation might transfer into the underreporting of generative AI use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Niszczota_P/0/1/0/all/0/1\">Pawe&#x142; Niszczota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conway_P/0/1/0/all/0/1\">Paul Conway</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"F-PABEE: Flexible-patience-based Early Exiting for Single-label and Multi-label text Classification Tasks. (arXiv:2305.11916v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11916","description":"<p>Computational complexity and overthinking problems have become the\nbottlenecks for pre-training language models (PLMs) with millions or even\ntrillions of parameters. A Flexible-Patience-Based Early Exiting method\n(F-PABEE) has been proposed to alleviate the problems mentioned above for\nsingle-label classification (SLC) and multi-label classification (MLC) tasks.\nF-PABEE makes predictions at the classifier and will exit early if predicted\ndistributions of cross-layer are consecutively similar. It is more flexible\nthan the previous state-of-the-art (SOTA) early exiting method PABEE because it\ncan simultaneously adjust the similarity score thresholds and the patience\nparameters. Extensive experiments show that: (1) F-PABEE makes a better\nspeedup-accuracy balance than existing early exiting strategies on both SLC and\nMLC tasks. (2) F-PABEE achieves faster inference and better performances on\ndifferent PLMs such as BERT and ALBERT. (3) F-PABEE-JSKD performs best for\nF-PABEE with different similarity measures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiangxiang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jiasheng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Congrui Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MParrotTTS: Multilingual Multi-speaker Text to Speech Synthesis in Low Resource Setting. (arXiv:2305.11926v1 [cs.SD])","link":"http://arxiv.org/abs/2305.11926","description":"<p>We present MParrotTTS, a unified multilingual, multi-speaker text-to-speech\n(TTS) synthesis model that can produce high-quality speech. Benefiting from a\nmodularized training paradigm exploiting self-supervised speech\nrepresentations, MParrotTTS adapts to a new language with minimal supervised\ndata and generalizes to languages not seen while training the self-supervised\nbackbone. Moreover, without training on any bilingual or parallel examples,\nMParrotTTS can transfer voices across languages while preserving the\nspeaker-specific characteristics, e.g., synthesizing fluent Hindi speech using\na French speaker's voice and accent. We present extensive results on six\nlanguages in terms of speech naturalness and speaker similarity in parallel and\ncross-lingual synthesis. The proposed model outperforms the state-of-the-art\nmultilingual TTS models and baselines, using only a small fraction of\nsupervised training data. Speech samples from our model can be found at\nhttps://paper2438.github.io/tts/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1\">Neil Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tambrahalli_V/0/1/0/all/0/1\">Vishal Tambrahalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosgi_S/0/1/0/all/0/1\">Saiteja Kosgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pedanekar_N/0/1/0/all/0/1\">Niranjan Pedanekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gandhi_V/0/1/0/all/0/1\">Vineet Gandhi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XTREME-UP: A User-Centric Scarce-Data Benchmark for Under-Represented Languages. (arXiv:2305.11938v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11938","description":"<p>Data scarcity is a crucial issue for the development of highly multilingual\nNLP systems. Yet for many under-represented languages (ULs) -- languages for\nwhich NLP re-search is particularly far behind in meeting user needs -- it is\nfeasible to annotate small amounts of data. Motivated by this, we propose\nXTREME-UP, a benchmark defined by: its focus on the scarce-data scenario rather\nthan zero-shot; its focus on user-centric tasks -- tasks with broad adoption by\nspeakers of high-resource languages; and its focus on under-represented\nlanguages where this scarce-data scenario tends to be most realistic. XTREME-UP\nevaluates the capabilities of language models across 88 under-represented\nlanguages over 9 key user-centric technologies including ASR, OCR, MT, and\ninformation access tasks that are of general utility. We create new datasets\nfor OCR, autocomplete, semantic parsing, and transliteration, and build on and\nrefine existing datasets for other tasks. XTREME-UP provides methodology for\nevaluating many modeling scenarios including text-only, multi-modal (vision,\naudio, and text),supervised parameter tuning, and in-context learning. We\nevaluate commonly used models on the benchmark. We release all code and scripts\nto train and evaluate models\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1\">Jonathan H. Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutkin_A/0/1/0/all/0/1\">Alexander Gutkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1\">Mihir Kale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Min Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicosia_M/0/1/0/all/0/1\">Massimo Nicosia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rijhwani_S/0/1/0/all/0/1\">Shruti Rijhwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riley_P/0/1/0/all/0/1\">Parker Riley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarr_J/0/1/0/all/0/1\">Jean-Michel A. Sarr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wieting_J/0/1/0/all/0/1\">John Wieting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Nitish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katanova_A/0/1/0/all/0/1\">Anna Katanova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirov_C/0/1/0/all/0/1\">Christo Kirov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dickinson_D/0/1/0/all/0/1\">Dana L. Dickinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roark_B/0/1/0/all/0/1\">Brian Roark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samanta_B/0/1/0/all/0/1\">Bidisha Samanta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Connie Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David I. Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Axelrod_V/0/1/0/all/0/1\">Vera Axelrod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caswell_I/0/1/0/all/0/1\">Isaac Caswell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherry_C/0/1/0/all/0/1\">Colin Cherry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garrette_D/0/1/0/all/0/1\">Dan Garrette</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ingle_R/0/1/0/all/0/1\">Reeve Ingle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Melvin Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Panteleev_D/0/1/0/all/0/1\">Dmitry Panteleev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Viability of Synthetic Query Generation for Relevance Prediction. (arXiv:2305.11944v1 [cs.IR])","link":"http://arxiv.org/abs/2305.11944","description":"<p>Query-document relevance prediction is a critical problem in Information\nRetrieval systems. This problem has increasingly been tackled using\n(pretrained) transformer-based models which are finetuned using large\ncollections of labeled data. However, in specialized domains such as e-commerce\nand healthcare, the viability of this approach is limited by the dearth of\nlarge in-domain data. To address this paucity, recent methods leverage these\npowerful models to generate high-quality task and domain-specific synthetic\ndata. Prior work has largely explored synthetic data generation or query\ngeneration (QGen) for Question-Answering (QA) and binary (yes/no) relevance\nprediction, where for instance, the QGen models are given a document, and\ntrained to generate a query relevant to that document. However in many\nproblems, we have a more fine-grained notion of relevance than a simple yes/no\nlabel. Thus, in this work, we conduct a detailed study into how QGen approaches\ncan be leveraged for nuanced relevance prediction. We demonstrate that --\ncontrary to claims from prior works -- current QGen approaches fall short of\nthe more conventional cross-domain transfer-learning approaches. Via empirical\nstudies spanning 3 public e-commerce benchmarks, we identify new shortcomings\nof existing QGen approaches -- including their inability to distinguish between\ndifferent grades of relevance. To address this, we introduce label-conditioned\nQGen models which incorporates knowledge about the different relevance. While\nour experiments demonstrate that these modifications help improve performance\nof QGen techniques, we also find that QGen approaches struggle to capture the\nfull nuance of the relevance label space and as a result the generated queries\nare not faithful to the desired relevance label.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Aditi Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raman_K/0/1/0/all/0/1\">Karthik Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_K/0/1/0/all/0/1\">Krishna Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hashimoto_K/0/1/0/all/0/1\">Kazuma Hashimoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Mike Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Najork_M/0/1/0/all/0/1\">Marc Najork</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Eye-SpatialNet: Spatial Information Extraction from Ophthalmology Notes. (arXiv:2305.11948v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11948","description":"<p>We introduce an annotated corpus of 600 ophthalmology notes labeled with\ndetailed spatial and contextual information of ophthalmic entities. We extend\nour previously proposed frame semantics-based spatial representation schema,\nRad-SpatialNet, to represent spatial language in ophthalmology text, resulting\nin the Eye-SpatialNet schema. The spatially-grounded entities are findings,\nprocedures, and drugs. To accurately capture all spatial details, we add some\ndomain-specific elements in Eye-SpatialNet. The annotated corpus contains 1715\nspatial triggers, 7308 findings, 2424 anatomies, and 9914 descriptors. To\nautomatically extract the spatial information, we employ a two-turn question\nanswering approach based on the transformer language model BERT. The results\nare promising, with F1 scores of 89.31, 74.86, and 88.47 for spatial triggers,\nFigure, and Ground frame elements, respectively. This is the first work to\nrepresent and extract a wide variety of clinical information in ophthalmology.\nExtracting detailed information can benefit ophthalmology applications and\nresearch targeted toward disease progression and screening.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1\">Surabhi Datta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaochar_T/0/1/0/all/0/1\">Tasneem Kaochar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_H/0/1/0/all/0/1\">Hio Cheng Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nwosu_N/0/1/0/all/0/1\">Nelly Nwosu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giancardo_L/0/1/0/all/0/1\">Luca Giancardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_A/0/1/0/all/0/1\">Alice Z. Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_R/0/1/0/all/0/1\">Robert M. Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1\">Kirk Roberts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-QA: Unsupervised Knowledge Guided Language Model Alignment. (arXiv:2305.11952v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11952","description":"<p>Large-scale language models like ChatGPT and GPT-4 have gained attention for\ntheir impressive conversational and generative capabilities. However, the\ncreation of supervised paired question-answering data for instruction tuning\npresents formidable challenges. This endeavor necessitates substantial human\neffort for data annotation and wrestles with issues concerning data quality,\ndiversity, accuracy, and other related factors. To overcome these obstacles, we\nintroduce an innovative framework named Self-QA, which replaces the traditional\npractice of human-written instruction seeds with a vast amount of unsupervised\nknowledge, enabling the model to generate a larger quantity of correct and\ndomain-specific instruction data. The effectiveness of our proposed method is\ndemonstrated through experiments conducted on unsupervised corpora from various\ndomains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuanyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qing Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Weak Supervision Approach for Few-Shot Aspect Based Sentiment. (arXiv:2305.11979v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11979","description":"<p>We explore how weak supervision on abundant unlabeled data can be leveraged\nto improve few-shot performance in aspect-based sentiment analysis (ABSA)\ntasks. We propose a pipeline approach to construct a noisy ABSA dataset, and we\nuse it to adapt a pre-trained sequence-to-sequence model to the ABSA tasks. We\ntest the resulting model on three widely used ABSA datasets, before and after\nfine-tuning. Our proposed method preserves the full fine-tuning performance\nwhile showing significant improvements (15.84% absolute F1) in the few-shot\nlearning scenario for the harder tasks. In zero-shot (i.e., without\nfine-tuning), our method outperforms the previous state of the art on the\naspect extraction sentiment classification (AESC) task and is, additionally,\ncapable of performing the harder aspect sentiment triplet extraction (ASTE)\ntask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vacareanu_R/0/1/0/all/0/1\">Robert Vacareanu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varia_S/0/1/0/all/0/1\">Siddharth Varia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Halder_K/0/1/0/all/0/1\">Kishaloy Halder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paolini_G/0/1/0/all/0/1\">Giovanni Paolini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+John_N/0/1/0/all/0/1\">Neha Anna John</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ballesteros_M/0/1/0/all/0/1\">Miguel Ballesteros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of medium-large Language Models at zero-shot closed book generative question answering. (arXiv:2305.11991v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11991","description":"<p>Large language models (LLMs) have garnered significant attention, but the\ndefinition of \"large\" lacks clarity. This paper focuses on medium-sized\nlan-guage models (MLMs), defined as having at least six billion parameters but\nless than 100 billion. The study evaluates MLMs regarding zero-shot genera-tive\nquestion answering, which requires models to provide elaborate answers without\nexternal document retrieval. The paper introduces an own test da-taset and\npresents results from human evaluation. Results show that combin-ing the best\nanswers from different MLMs yielded an overall correct answer rate of 82.7%\nwhich is better than the 60.9% of ChatGPT. The best MLM achieved 46.4% and has\n7B parameters, which highlights the importance of using appropriate training\ndata for fine-tuning rather than solely relying on the number of parameters.\nMore fine-grained feedback should be used to further improve the quality of\nanswers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peinl_R/0/1/0/all/0/1\">Ren&#xe9; Peinl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wirth_J/0/1/0/all/0/1\">Johannes Wirth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretable Word Sense Representations via Definition Generation: The Case of Semantic Change Analysis. (arXiv:2305.11993v1 [cs.CL])","link":"http://arxiv.org/abs/2305.11993","description":"<p>We propose using automatically generated natural language definitions of\ncontextualised word usages as interpretable word and word sense\nrepresentations. Given a collection of usage examples for a target word, and\nthe corresponding data-driven usage clusters (i.e., word senses), a definition\nis generated for each usage with a specialised Flan-T5 language model, and the\nmost prototypical definition in a usage cluster is chosen as the sense label.\n</p>\n<p>We demonstrate how the resulting sense labels can make existing approaches to\nsemantic change analysis more interpretable, and how they can allow users --\nhistorical linguists, lexicographers, or social scientists -- to explore and\nintuitively explain diachronic trajectories of word meaning. Semantic change\nanalysis is only one of many possible applications of the `definitions as\nrepresentations' paradigm. Beyond being human-readable, contextualised\ndefinitions also outperform token or usage sentence embeddings in\nword-in-context semantic similarity judgements, making them a new promising\ntype of lexical representation for NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1\">Mario Giulianelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luden_I/0/1/0/all/0/1\">Iris Luden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1\">Raquel Fernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutuzov_A/0/1/0/all/0/1\">Andrey Kutuzov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Learning Approaches to Lexical Simplification: A Survey. (arXiv:2305.12000v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12000","description":"<p>Lexical Simplification (LS) is the task of replacing complex for simpler\nwords in a sentence whilst preserving the sentence's original meaning. LS is\nthe lexical component of Text Simplification (TS) with the aim of making texts\nmore accessible to various target populations. A past survey (Paetzold and\nSpecia, 2017) has provided a detailed overview of LS. Since this survey,\nhowever, the AI/NLP community has been taken by storm by recent advances in\ndeep learning, particularly with the introduction of large language models\n(LLM) and prompt learning. The high performance of these models sparked renewed\ninterest in LS. To reflect these recent advances, we present a comprehensive\nsurvey of papers published between 2017 and 2023 on LS and its sub-tasks with a\nspecial focus on deep learning. We also present benchmark datasets for the\nfuture development of LS systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+North_K/0/1/0/all/0/1\">Kai North</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shardlow_M/0/1/0/all/0/1\">Matthew Shardlow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zampieri_M/0/1/0/all/0/1\">Marcos Zampieri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models. (arXiv:2305.12001v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12001","description":"<p>In this paper, we conduct a thorough investigation into the reasoning\ncapabilities of Large Language Models (LLMs), focusing specifically on the Open\nPretrained Transformers (OPT) models as a representative of such models. Our\nstudy entails finetuning three different sizes of OPT on a carefully curated\nreasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned\nwithout explanations, and OPT-RE, finetuned with explanations. We then evaluate\nall models on 57 out-of-domain tasks drawn from the SUPER-NATURALINSTRUCTIONS\nbenchmark, covering 26 distinct reasoning skills, utilizing three prompting\ntechniques. Through a comprehensive grid of 27 configurations and 6,156 test\nevaluations, we investigate the dimensions of finetuning, prompting, and scale\nto understand the role of explanations on different reasoning skills. Our\nfindings reveal that having explanations in the fewshot exemplar has no\nsignificant impact on the model's performance when the model is finetuned,\nwhile positively affecting the non-finetuned counterpart. Moreover, we observe\na slight yet consistent increase in classification accuracy as we incorporate\nexplanations during prompting and finetuning, respectively. Finally, we offer\ninsights on which skills benefit the most from incorporating explanations\nduring finetuning and prompting, such as Numerical (+20.4%) and Analogical\n(+13.9%) reasoning, as well as skills that exhibit negligible or negative\neffects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1\">Siddharth Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Ping Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters. (arXiv:2305.12002v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12002","description":"<p>In recent years, pre-trained language models have undergone rapid development\nwith the emergence of large-scale models. However, there is a lack of\nopen-sourced chat models specifically designed for the Chinese language,\nespecially in the field of Chinese finance, at the scale of hundreds of\nbillions. To address this gap, we introduce XuanYuan 2.0, the largest Chinese\nchat model to date, built upon the BLOOM-176B architecture. Additionally, we\npropose a novel training method called hybrid-tuning to mitigate catastrophic\nforgetting. By combining general-domain with domain-specific knowledge and\nintegrating the stages of pre-training and fine-tuning, XuanYuan 2.0 is capable\nof providing accurate and contextually appropriate responses in the Chinese\nfinancial domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuanyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongliang Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BOLT: Fast Energy-based Controlled Text Generation with Tunable Biases. (arXiv:2305.12018v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12018","description":"<p>Energy-based models (EBMs) have gained popularity for controlled text\ngeneration due to their high applicability to a wide range of constraints.\nHowever, sampling from EBMs is non-trivial, as it often requires a large number\nof iterations to converge to plausible text, which slows down the decoding\nprocess and makes it less practical for real-world applications. In this work,\nwe propose BOLT, which relies on tunable biases to directly adjust the language\nmodel's output logits. Unlike prior work, BOLT maintains the generator's\nautoregressive nature to assert a strong control on token-wise conditional\ndependencies and overall fluency, and thus converges faster. When compared with\nstate-of-the-arts on controlled generation tasks using both soft constraints\n(e.g., sentiment control) and hard constraints (e.g., keyword-guided topic\ncontrol), BOLT demonstrates significantly improved efficiency and fluency. On\nsentiment control, BOLT is 7x faster than competitive baselines, and more\nfluent in 74.4% of the evaluation samples according to human judges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalifa_M/0/1/0/all/0/1\">Muhammad Khalifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings. (arXiv:2305.12027v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12027","description":"<p>Entity linking methods based on dense retrieval are an efficient and widely\nused solution in large-scale applications, but they fall short of the\nperformance of generative models, as they are sensitive to the structure of the\nembedding space. In order to address this issue, this paper introduces DUCK, an\napproach to infusing structural information in the space of entity\nrepresentations, using prior knowledge of entity types. Inspired by duck typing\nin programming languages, we propose to define the type of an entity based on\nthe relations that it has with other entities in a knowledge graph. Then,\nporting the concept of box embeddings to spherical polar coordinates, we\npropose to represent relations as boxes on the hypersphere. We optimize the\nmodel to cluster entities of similar type by placing them inside the boxes\ncorresponding to their relations. Our experiments show that our method sets new\nstate-of-the-art results on standard entity-disambiguation benchmarks, it\nimproves the performance of the model by up to 7.9 F1 points, outperforms other\ntype-aware approaches, and matches the results of generative models with 18\ntimes more parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Atzeni_M/0/1/0/all/0/1\">Mattia Atzeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plekhanov_M/0/1/0/all/0/1\">Mikhail Plekhanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreyer_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric A. Dreyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kassner_N/0/1/0/all/0/1\">Nora Kassner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merello_S/0/1/0/all/0/1\">Simone Merello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Louis Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cancedda_N/0/1/0/all/0/1\">Nicola Cancedda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MultiTurnCleanup: A Benchmark for Multi-Turn Spoken Conversational Transcript Cleanup. (arXiv:2305.12029v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12029","description":"<p>Current disfluency detection models focus on individual utterances each from\na single speaker. However, numerous discontinuity phenomena in spoken\nconversational transcripts occur across multiple turns, hampering human\nreadability and the performance of downstream NLP tasks. This study addresses\nthese phenomena by proposing an innovative Multi-Turn Cleanup task for spoken\nconversational transcripts and collecting a new dataset, MultiTurnCleanup1. We\ndesign a data labeling schema to collect the high-quality dataset and provide\nextensive data analysis. Furthermore, we leverage two modeling approaches for\nexperimental evaluation as benchmarks for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Hua Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zayats_V/0/1/0/all/0/1\">Vicky Zayats</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocholl_J/0/1/0/all/0/1\">Johann C. Rocholl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_D/0/1/0/all/0/1\">Daniel D. Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padfield_D/0/1/0/all/0/1\">Dirk Padfield</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Camel: An Open-Source Expert-Level Medical Language Model with Dialogue-Based Knowledge Encoding. (arXiv:2305.12031v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12031","description":"<p>Large Language Models (LLMs) present immense potential in the medical field,\nyet concerns over data privacy, regulatory compliance, and model stability\nrestrict their widespread adoption. Although the distillation of\nhigh-performing closed-source LLMs has proven effective for general tasks,\ntheir application in healthcare is limited due to reduced domain knowledge and\nremnants of alignment behavior hindering clinical tasks. To address these\nchallenges, we propose Dialogue-Based Knowledge Encoding (DBKE). DBKE enhances\nmodels' implicit knowledge base and primes them for conversational recall,\naugmenting their conversational capabilities and enabling a soft alignment for\nsubsequent use cases. By transforming dense academic source text into synthetic\ndialogue, DBKE broadens the model's knowledge base and enables a soft alignment\nthat guides downstream behaviours. We present Clinical Camel, an open-source,\nhealthcare-focused conversational model, to showcase the effectiveness of DBKE.\nClinical Camel outperforms GPT-3.5 on the United States Medical Licensing\nExamination (USMLE) Step 1 and Step 3 with scores of 53.2 % and 58.2 %,\nrespectively, compared to GPT-3.5's scores of 36.1 % and 55.7 %. Clinical Camel\nadeptly handles multi-stage clinical case problems, provides adaptive\ncounseling, and generates clinical notes. However, it is prone to\nhallucinations, which pose a significant obstacle in safety-critical settings.\nThe performance of Clinical Camel underscores the importance of continued\nresearch and development of open-source models for the safe and effective\nintegration of LLMs in healthcare settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toma_A/0/1/0/all/0/1\">Augustin Toma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawler_P/0/1/0/all/0/1\">Patrick R. Lawler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1\">Jimmy Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_R/0/1/0/all/0/1\">Rahul G. Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubin_B/0/1/0/all/0/1\">Barry B. Rubin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Accurate Knowledge Distillation with n-best Reranking. (arXiv:2305.12057v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12057","description":"<p>We propose extending the Sequence-level Knowledge Distillation (Kim and Rush,\n2016) with n-best reranking to consider not only the top-1 hypotheses but also\nthe top n-best hypotheses of teacher models. Our approach leverages a diverse\nset of models, including publicly-available large pretrained models, to provide\nmore accurate pseudo-labels for training student models. We validate our\nproposal on the WMT21 German-English translation task and demonstrate that our\nstudent model achieves comparable accuracy to a large translation model with\n4.7 billion parameters from (Tran et al., 2021) while having two orders of\nmagnitude fewer parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Setiawan_H/0/1/0/all/0/1\">Hendra Setiawan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining. (arXiv:2305.12074v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12074","description":"<p>Many text mining models are constructed by fine-tuning a large deep\npre-trained language model (PLM) in downstream tasks. However, a significant\nchallenge is maintaining performance when we use a lightweight model with\nlimited labeled samples. We present DisCo, a semi-supervised learning (SSL)\nframework for fine-tuning a cohort of small student models generated from a\nlarge PLM using knowledge distillation. Our key insight is to share\ncomplementary knowledge among distilled student cohorts to promote their SSL\neffectiveness. DisCo employs a novel co-training technique to optimize multiple\nsmall student models by promoting knowledge sharing among students under\ndiversified views: model views produced by different distillation strategies\nand data views produced by various input augmentations. We evaluate DisCo on\nboth semi-supervised text classification and extractive summarization tasks.\nExperimental results show that DisCo can produce student models that are 7.6\ntimes smaller and 4.8 times faster in inference than the baseline PLMs while\nmaintaining comparable performance. We also show that DisCo-generated student\nmodels outperform the similar-sized models elaborately tuned in distinct tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weifeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qianren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_T/0/1/0/all/0/1\">Ting Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer. (arXiv:2305.12077v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12077","description":"<p>In real-world scenarios, labeled samples for dialogue summarization are\nusually limited (i.e., few-shot) due to high annotation costs for high-quality\ndialogue summaries. To efficiently learn from few-shot samples, previous works\nhave utilized massive annotated data from other downstream tasks and then\nperformed prompt transfer in prompt tuning so as to enable cross-task knowledge\ntransfer. However, existing general-purpose prompt transfer techniques lack\nconsideration for dialogue-specific information. In this paper, we focus on\nimproving the prompt transfer from dialogue state tracking to dialogue\nsummarization and propose Skeleton-Assisted Prompt Transfer (SAPT), which\nleverages skeleton generation as extra supervision that functions as a medium\nconnecting the distinct source and target task and resulting in the model's\nbetter consumption of dialogue state information. To automatically extract\ndialogue skeletons as supervised training data for skeleton generation, we\ndesign a novel approach with perturbation-based probes requiring neither\nannotation effort nor domain knowledge. Training the model on such skeletons\ncan also help preserve model capability during prompt transfer. Our method\nsignificantly outperforms existing baselines. In-depth analyses demonstrate the\neffectiveness of our method in facilitating cross-task knowledge transfer in\nfew-shot dialogue summarization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_K/0/1/0/all/0/1\">Kaige Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoliang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junda Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Handong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahadik_K/0/1/0/all/0/1\">Kanak Mahadik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenkova_A/0/1/0/all/0/1\">Ani Nenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1\">Mark Riedl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Entropy Rate Constancy in Text. (arXiv:2305.12084v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12084","description":"<p>The uniform information density (UID) hypothesis states that humans tend to\ndistribute information roughly evenly across an utterance or discourse. Early\nevidence in support of the UID hypothesis came from Genzel &amp; Charniak (2002),\nwhich proposed an entropy rate constancy principle based on the probability of\nEnglish text under n-gram language models. We re-evaluate the claims of Genzel\n&amp; Charniak (2002) with neural language models, failing to find clear evidence\nin support of entropy rate constancy. We conduct a range of experiments across\ndatasets, model sizes, and languages and discuss implications for the uniform\ninformation density hypothesis and linguistic theories of efficient\ncommunication more broadly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1\">Vivek Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomlin_N/0/1/0/all/0/1\">Nicholas Tomlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prefix Propagation: Parameter-Efficient Tuning for Long Sequences. (arXiv:2305.12086v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12086","description":"<p>Parameter-efficient tuning aims to mitigate the large memory requirements of\nadapting pretrained language models for downstream tasks. For example, one\npopular method, prefix-tuning, prepends trainable tokens to sequences while\nfreezing the rest of the model's parameters. Although such models attain\ncomparable performance with fine-tuning when applied to sequences with short to\nmoderate lengths, we show their inferior performance when modelling long\nsequences. To bridge this gap, we propose prefix-propagation, a simple but\neffective approach that conditions prefixes on previous hidden states. We\nempirically demonstrate that prefix-propagation outperforms prefix-tuning\nacross long-document tasks, while using 50% fewer parameters. To further\ninvestigate the proposed architecture, we also show its advantage in\ncalibration, and perform additional study on its relationship with kernel\nattention. To the best of our knowledge, this work is the first to focus on\nparameter-efficient learning for long-sequence language tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jonathan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aitken_W/0/1/0/all/0/1\">Will Aitken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhambhoria_R/0/1/0/all/0/1\">Rohan Bhambhoria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaodan Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UP5: Unbiased Foundation Model for Fairness-aware Recommendation. (arXiv:2305.12090v1 [cs.IR])","link":"http://arxiv.org/abs/2305.12090","description":"<p>Recent advancements in foundation models such as large language models (LLM)\nhave propelled them to the forefront of recommender systems (RS). Moreover,\nfairness in RS is critical since many users apply it for decision-making and\ndemand fulfillment. However, at present, there is a lack of understanding\nregarding the level of fairness exhibited by recommendation foundation models\nand the appropriate methods for equitably treating different groups of users in\nfoundation models. In this paper, we focus on user-side unfairness problem and\nshow through a thorough examination that there is unfairness involved in LLMs\nthat lead to unfair recommendation results. To eliminate bias from LLM for\nfairness-aware recommendation, we introduce a novel Unbiased P5 (UP5)\nfoundation model based on Counterfactually-Fair-Prompting (CFP) techniques. CFP\nincludes two sub-modules: a personalized prefix prompt that enhances fairness\nwith respect to individual sensitive attributes, and a Prompt Mixture that\nintegrates multiple counterfactually-fair prompts for a set of sensitive\nattributes. Experiments are conducted on two real-world datasets, MovieLens-1M\nand Insurance, and results are compared with both matching-based and\nsequential-based fairness-aware recommendation models. The results show that\nUP5 achieves better recommendation performance and meanwhile exhibits a high\nlevel of fairness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1\">Jianchao Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"What do others think?\": Task-Oriented Conversational Modeling with Subjective Knowledge. (arXiv:2305.12091v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12091","description":"<p>Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that\nassist users in accomplishing specific goals, such as booking a hotel or a\nrestaurant. Traditional TODs rely on domain-specific APIs/DBs or external\nfactual knowledge to generate responses, which cannot accommodate subjective\nuser requests (e.g., \"Is the WIFI reliable?\" or \"Does the restaurant have a\ngood atmosphere?\"). To address this issue, we propose a novel task of\nsubjective-knowledge-based TOD (SK-TOD). We also propose the first\ncorresponding dataset, which contains subjective knowledge-seeking dialogue\ncontexts and manually annotated responses grounded in subjective knowledge\nsources. When evaluated with existing TOD approaches, we find that this task\nposes new challenges such as aggregating diverse opinions from multiple\nknowledge snippets. We hope this task and dataset can promote further research\non TOD and subjective content understanding. The code and the dataset are\navailable at https://github.com/alexa/dstc11-track5.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gella_S/0/1/0/all/0/1\">Spandana Gella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seokhwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papangelis_A/0/1/0/all/0/1\">Alexandros Papangelis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namazifar_M/0/1/0/all/0/1\">Mahdi Namazifar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESCOXLM-R: Multilingual Taxonomy-driven Pre-training for the Job Market Domain. (arXiv:2305.12092v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12092","description":"<p>The increasing number of benchmarks for Natural Language Processing (NLP)\ntasks in the computational job market domain highlights the demand for methods\nthat can handle job-related tasks such as skill extraction, skill\nclassification, job title classification, and de-identification. While some\napproaches have been developed that are specific to the job market domain,\nthere is a lack of generalized, multilingual models and benchmarks for these\ntasks. In this study, we introduce a language model called ESCOXLM-R, based on\nXLM-R, which uses domain-adaptive pre-training on the European Skills,\nCompetences, Qualifications and Occupations (ESCO) taxonomy, covering 27\nlanguages. The pre-training objectives for ESCOXLM-R include dynamic masked\nlanguage modeling and a novel additional objective for inducing multilingual\ntaxonomical ESCO relations. We comprehensively evaluate the performance of\nESCOXLM-R on 6 sequence labeling and 3 classification tasks in 4 languages and\nfind that it achieves state-of-the-art results on 6 out of 9 datasets. Our\nanalysis reveals that ESCOXLM-R performs better on short spans and outperforms\nXLM-R on entity-level and surface-level span-F1, likely due to ESCO containing\nshort skill and occupation titles, and encoding information on the\nentity-level.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mike Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goot_R/0/1/0/all/0/1\">Rob van der Goot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can NLP Models Correctly Reason Over Contexts that Break the Common Assumptions?. (arXiv:2305.12096v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12096","description":"<p>Pre-training on large corpora of text enables the language models to acquire\na vast amount of factual and commonsense knowledge which allows them to achieve\nremarkable performance on a variety of language understanding tasks. They\ntypically acquire this knowledge by learning from the pre-training text and\ncapturing certain patterns from it. However, real-world settings often present\nscenarios that do not abide by these patterns i.e. scenarios that break the\ncommon assumptions. Can state-of-the-art NLP models correctly reason over the\ncontexts of such scenarios?\n</p>\n<p>Addressing the above question, in this paper, we investigate the ability of\nmodels to correctly reason over contexts that break the common assumptions. To\nthis end, we first systematically create evaluation data in which each data\ninstance consists of (a) a common assumption, (b) a context that follows the\nassumption, (c) a context that breaks the assumption, and (d) questions based\non the contexts. Then, through evaluations on multiple models including GPT-3\nand Flan T5, we show that while doing fairly well on contexts that follow the\ncommon assumptions, the models struggle to correctly reason over contexts that\nbreak those assumptions. Specifically, the performance gap is as high as 20%\nabsolute points. Furthermore, we thoroughly analyze these results revealing\nseveral interesting findings. We believe our work and findings will encourage\nand facilitate further research in developing more robust models that can also\nreliably reason over contexts that break the common assumptions. Data is\navailable at \\url{https://github.com/nrjvarshney/break_the_common_assumptions}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Varshney_N/0/1/0/all/0/1\">Neeraj Varshney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parmar_M/0/1/0/all/0/1\">Mihir Parmar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1\">Nisarg Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Handa_D/0/1/0/all/0/1\">Divij Handa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Sayantan Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1\">Man Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baral_C/0/1/0/all/0/1\">Chitta Baral</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EE-TTS: Emphatic Expressive TTS with Linguistic Information. (arXiv:2305.12107v1 [cs.SD])","link":"http://arxiv.org/abs/2305.12107","description":"<p>While Current TTS systems perform well in synthesizing high-quality speech,\nproducing highly expressive speech remains a challenge. Emphasis, as a critical\nfactor in determining the expressiveness of speech, has attracted more\nattention nowadays. Previous works usually enhance the emphasis by adding\nintermediate features, but they can not guarantee the overall expressiveness of\nthe speech. To resolve this matter, we propose Emphatic Expressive TTS\n(EE-TTS), which leverages multi-level linguistic information from syntax and\nsemantics. EE-TTS contains an emphasis predictor that can identify appropriate\nemphasis positions from text and a conditioned acoustic model to synthesize\nexpressive speech with emphasis and linguistic information. Experimental\nresults indicate that EE-TTS outperforms baseline with MOS improvements of 0.49\nand 0.67 in expressiveness and naturalness. EE-TTS also shows strong\ngeneralization across different datasets according to AB test results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xule Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chenxi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weishan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Haifeng Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhongqian Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling the Q-Diversity in a Min-max Play Game for Robust Optimization. (arXiv:2305.12123v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12123","description":"<p>Models trained with empirical risk minimization (ERM) are revealed to easily\nrely on spurious correlations, resulting in poor generalization. Group\ndistributionally robust optimization (group DRO) can alleviate this problem by\nminimizing the worst-case loss over pre-defined groups. While promising, in\npractice factors like expensive annotations and privacy preclude the\navailability of group labels. More crucially, when taking a closer look at the\nfailure modes of out-of-distribution generalization, the typical procedure of\nreweighting in group DRO loses efficiency. Hinged on the limitations, in this\nwork, we reformulate the group DRO framework by proposing Q-Diversity.\nCharacterized by an interactive training mode, Q-Diversity relaxes the group\nidentification from annotation into direct parameterization. Furthermore, a\nnovel mixing strategy across groups is presented to diversify the\nunder-represented groups. In a series of experiments on both synthetic and\nreal-world text classification tasks, results demonstrate that Q-Diversity can\nconsistently improve worst-case accuracy under different distributional shifts,\noutperforming state-of-the-art alternatives.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Ting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lifting the Curse of Capacity Gap in Distilling Language Models. (arXiv:2305.12129v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12129","description":"<p>Pretrained language models (LMs) have shown compelling performance on various\ndownstream tasks, but unfortunately they require a tremendous amount of\ninference compute. Knowledge distillation finds a path to compress LMs to small\nones with a teacher-student paradigm. However, when the capacity gap between\nthe teacher and the student is large, a curse of capacity gap appears, invoking\na deficiency in distilling LMs. While a few studies have been carried out to\nfill the gap, the curse is not yet well tackled. In this paper, we aim at\nlifting the curse of capacity gap via enlarging the capacity of the student\nwithout notably increasing the inference compute. Largely motivated by sparse\nactivation regime of mixture of experts (MoE), we propose a mixture of minimal\nexperts (MiniMoE), which imposes extra parameters to the student but introduces\nalmost no additional inference compute. Experimental results on GLUE and CoNLL\ndemonstrate the curse of capacity gap is lifted by the magic of MiniMoE to a\nlarge extent. MiniMoE also achieves the state-of-the-art performance at small\nFLOPs compared with a range of competitive baselines. With a compression rate\nas much as $\\sim$50$\\times$, MiniMoE preserves $\\sim$95\\% GLUE score of the\nteacher.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiahao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Y/0/1/0/all/0/1\">Yunsen Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Benyou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawei Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hedges in Bidirectional Translations of Publicity-Oriented Documents. (arXiv:2305.12146v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12146","description":"<p>Hedges are widely studied across registers and disciplines, yet research on\nthe translation of hedges in political texts is extremely limited. This\ncontrastive study is dedicated to investigating whether there is a diachronic\nchange in the frequencies of hedging devices in the target texts, to what\nextent the changing frequencies of translated hedges through years are\nattributed to the source texts, and what translation strategies are adopted to\ndeal with them. For the purposes of this research, two types of official\npolitical texts and their translations from China and the United Nations were\ncollected to form three sub-corpora. Results show that hedges tend to appear\nmore frequently in English political texts, be it original English or\ntranslated English. In addition, directionality seems to play an important role\nin influencing both the frequencies and translation strategies regarding the\nuse of hedges. A noticeable diachronic increase of hedging devices is also\nobserved in our corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhaokun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LogiCoT: Logical Chain-of-Thought Instruction-Tuning Data Collection with GPT-4. (arXiv:2305.12147v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12147","description":"<p>Generative Pre-trained Transformer 4 (GPT-4) demonstrates impressive\nchain-of-thought reasoning ability. Recent work on self-instruction tuning,\nsuch as Alpaca, has focused on enhancing the general proficiency of models.\nThese instructions enable the model to achieve performance comparable to\nGPT-3.5 on general tasks like open-domain text generation and paraphrasing.\nHowever, they fall short of helping the model handle complex reasoning tasks.\nTo bridge the gap, this paper presents LogiCoT, a new instruction-tuning\ndataset for Logical Chain-of-Thought reasoning with GPT-4. We elaborate on the\nprocess of harvesting instructions for prompting GPT-4 to generate\nchain-of-thought rationales. LogiCoT serves as an instruction set for teaching\nmodels of logical reasoning and elicits general reasoning skills.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanmeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teng_Z/0/1/0/all/0/1\">Zhiyang Teng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1\">Leyang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chaoli Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qiji Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Re-visiting Automated Topic Model Evaluation with Large Language Models. (arXiv:2305.12152v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12152","description":"<p>Topic models are used to make sense of large text collections. However,\nautomatically evaluating topic model output and determining the optimal number\nof topics both have been longstanding challenges, with no effective automated\nsolutions to date. This paper proposes using large language models to evaluate\nsuch output. We find that large language models appropriately assess the\nresulting topics, correlating more strongly with human judgments than existing\nautomated metrics. We then investigate whether we can use large language models\nto automatically determine the optimal number of topics. We automatically\nassign labels to documents and choosing configurations with the most pure\nlabels returns reasonable values for the optimal number of topics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stammbach_D/0/1/0/all/0/1\">Dominik Stammbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyle_A/0/1/0/all/0/1\">Alexander Hoyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ash_E/0/1/0/all/0/1\">Elliott Ash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learn to Compose Syntactic and Semantic Representations Appropriately for Compositional Generalization. (arXiv:2305.12169v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12169","description":"<p>Recent studies have shown that sequence-to-sequence (Seq2Seq) models are\nlimited in solving the compositional generalization (CG) tasks, failing to\nsystematically generalize to unseen compositions of seen components. There is\nmounting evidence that one of the reasons hindering CG is the representation of\nthe encoder uppermost layer is entangled. In other words, the syntactic and\nsemantic representations of sequences are twisted inappropriately. However,\nmost previous studies mainly concentrate on enhancing semantic information at\ntoken-level, rather than composing the syntactic and semantic representations\nof sequences appropriately as humans do. In addition, we consider the\nrepresentation entanglement problem they found is not comprehensive, and\nfurther hypothesize that source keys and values representations passing into\ndifferent decoder layers are also entangled. Staring from this intuition and\ninspired by humans' strategies for CG, we propose COMPSITION (Compose Syntactic\nand Semantic Representations), an extension to Seq2Seq models to learn to\ncompose representations of different encoder layers appropriately for\ngenerating different keys and values passing into different decoder layers\nthrough introducing a composed layer between the encoder and decoder.\nCOMPSITION achieves competitive and even state-of-the-art results on two\nrealistic benchmarks, which empirically demonstrates the effectiveness of our\nproposal.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuangtao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_B/0/1/0/all/0/1\">Biao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yafang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yidong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaodong Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Glot500: Scaling Multilingual Corpora and Language Models to 500 Languages. (arXiv:2305.12182v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12182","description":"<p>The NLP community has mainly focused on scaling Large Language Models (LLMs)\nvertically, i.e., making them better for about 100 languages. We instead scale\nLLMs horizontally: we create, through continued pretraining, Glot500-m, an LLM\nthat covers 511 languages, almost all of them low-resource. An important part\nof this effort is to collect and clean Glot500-c, a corpus that covers these\n511 languages and allows us to train Glot500-m. We evaluate Glot500-m on five\ndiverse tasks across these languages. We observe large improvements for both\nhigh-resource and lowresource languages compared to an XLM-R baseline. Our\nanalysis shows that no single factor explains the quality of multilingual LLM\nrepresentations. Rather, a combination of factors determines quality including\ncorpus size, script, \"help\" from related languages and the total capacity of\nthe model. Our work addresses an important goal of NLP research: we should not\nlimit NLP to a small fraction of the world's languages and instead strive to\nsupport as many languages as possible to bring the benefits of NLP technology\nto all languages and cultures. Code, data and models are available at\nhttps://github.com/cisnlp/Glot500.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ImaniGooghari_A/0/1/0/all/0/1\">Ayyoob ImaniGooghari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1\">Peiqin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kargaran_A/0/1/0/all/0/1\">Amir Hossein Kargaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Severini_S/0/1/0/all/0/1\">Silvia Severini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabet_M/0/1/0/all/0/1\">Masoud Jalili Sabet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kassner_N/0/1/0/all/0/1\">Nora Kassner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chunlan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_H/0/1/0/all/0/1\">Helmut Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1\">Fran&#xe7;ois Yvon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Paragraph-level Citation Recommendation based on Topic Sentences as Queries. (arXiv:2305.12190v1 [cs.IR])","link":"http://arxiv.org/abs/2305.12190","description":"<p>Citation recommendation (CR) models may help authors find relevant articles\nat various stages of the paper writing process. Most research has dealt with\neither global CR, which produces general recommendations suitable for the\ninitial writing stage, or local CR, which produces specific recommendations\nmore fitting for the final writing stages. We propose the task of\nparagraph-level CR as a middle ground between the two approaches, where the\nparagraph's topic sentence is taken as input and recommendations for citing\nwithin the paragraph are produced at the output. We propose a model for this\ntask, fine-tune it using the quadruplet loss on the dataset of ACL papers, and\nshow improvements over the baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Medic_Z/0/1/0/all/0/1\">Zoran Medi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs. (arXiv:2305.12191v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12191","description":"<p>A major concern in using deep learning based generative models for\ndocument-grounded dialogs is the potential generation of responses that are not\n\\textit{faithful} to the underlying document. Existing automated metrics used\nfor evaluating the faithfulness of response with respect to the grounding\ndocument measure the degree of similarity between the generated response and\nthe document's content. However, these automated metrics are far from being\nwell aligned with human judgments. Therefore, to improve the measurement of\nfaithfulness, we propose a new metric that utilizes (Conditional) Point-wise\nMutual Information (PMI) between the generated response and the source\ndocument, conditioned on the dialogue. PMI quantifies the extent to which the\ndocument influences the generated response -- with a higher PMI indicating a\nmore faithful response. We build upon this idea to create a new decoding\ntechnique that incorporates PMI into the response generation process to predict\nmore faithful responses. Our experiments on the BEGIN benchmark demonstrate an\nimproved correlation of our metric with human evaluation. We also show that our\ndecoding technique is effective in generating more faithful responses when\ncompared to standard decoding techniques on a set of publicly available\ndocument-grounded dialog datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nandwani_Y/0/1/0/all/0/1\">Yatin Nandwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1\">Vineet Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghu_D/0/1/0/all/0/1\">Dinesh Raghu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1\">Sachindra Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lastras_L/0/1/0/all/0/1\">Luis A. Lastras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experimental results from applying GPT-4 to an unpublished formal language. (arXiv:2305.12196v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12196","description":"<p>Can large language models be used to complete mathematical tasks that are\ntraditionally performed either manually or with the aid of theorem provers? To\nanswer this question, a state-of-the-art system, GPT-4, was provided with a\nconcise natural language specification for a previously unpublished formal\nsystem and asked to complete a number of tasks, from stating function and type\ndefinitions to proving simple theorems and verifying user-supplied proofs. The\nsystem completed all tasks successfully, showed extensive domain knowledge,\ninvented helpful new syntax and semantics, and exhibited generalization and\ninference abilities. So the answer seems to be: yes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scheidt_G/0/1/0/all/0/1\">Gregor vom Scheidt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VNHSGE: VietNamese High School Graduation Examination Dataset for Large Language Models. (arXiv:2305.12199v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12199","description":"<p>The VNHSGE (VietNamese High School Graduation Examination) dataset, developed\nexclusively for evaluating large language models (LLMs), is introduced in this\narticle. The dataset, which covers nine subjects, was generated from the\nVietnamese National High School Graduation Examination and comparable tests.\n300 literary essays have been included, and there are over 19,000\nmultiple-choice questions on a range of topics. The dataset assesses LLMs in\nmultitasking situations such as question answering, text generation, reading\ncomprehension, visual question answering, and more by including both textual\ndata and accompanying images. Using ChatGPT and BingChat, we evaluated LLMs on\nthe VNHSGE dataset and contrasted their performance with that of Vietnamese\nstudents to see how well they performed. The results show that ChatGPT and\nBingChat both perform at a human level in a number of areas, including\nliterature, English, history, geography, and civics education. They still have\nspace to grow, though, especially in the areas of mathematics, physics,\nchemistry, and biology. The VNHSGE dataset seeks to provide an adequate\nbenchmark for assessing the abilities of LLMs with its wide-ranging coverage\nand variety of activities. We intend to promote future developments in the\ncreation of LLMs by making this dataset available to the scientific community,\nespecially in resolving LLMs' limits in disciplines involving mathematics and\nthe natural sciences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xuan_Quy_D/0/1/0/all/0/1\">Dao Xuan-Quy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngoc_Bich_L/0/1/0/all/0/1\">Le Ngoc-Bich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+The_Duy_V/0/1/0/all/0/1\">Vo The-Duy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xuan_Dung_P/0/1/0/all/0/1\">Phan Xuan-Dung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bac_Bien_N/0/1/0/all/0/1\">Ngo Bac-Bien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Van_Tien_N/0/1/0/all/0/1\">Nguyen Van-Tien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thi_My_Thanh_N/0/1/0/all/0/1\">Nguyen Thi-My-Thanh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Phuoc_N/0/1/0/all/0/1\">Nguyen Hong-Phuoc</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Distillation with Meta Learning for Knowledge Graph Completion. (arXiv:2305.12209v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12209","description":"<p>In this paper, we propose a selfdistillation framework with meta\nlearning(MetaSD) for knowledge graph completion with dynamic pruning, which\naims to learn compressed graph embeddings and tackle the longtail samples.\nSpecifically, we first propose a dynamic pruning technique to obtain a small\npruned model from a large source model, where the pruning mask of the pruned\nmodel could be updated adaptively per epoch after the model weights are\nupdated. The pruned model is supposed to be more sensitive to difficult to\nmemorize samples(e.g., longtail samples) than the source model. Then, we\npropose a onestep meta selfdistillation method for distilling comprehensive\nknowledge from the source model to the pruned model, where the two models\ncoevolve in a dynamic manner during training. In particular, we exploit the\nperformance of the pruned model, which is trained alongside the source model in\none iteration, to improve the source models knowledge transfer ability for the\nnext iteration via meta learning. Extensive experiments show that MetaSD\nachieves competitive performance compared to strong baselines, while being 10x\nsmaller than baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunshui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junhao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1\">Min Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt ChatGPT In MNER: Improved multimodal named entity recognition method based on auxiliary refining knowledge from ChatGPT. (arXiv:2305.12212v1 [cs.CL])","link":"http://arxiv.org/abs/2305.12212","description":"<p>Multimodal Named Entity Recognition (MNER) on social media aims to enhance\ntextual entity prediction by incorporating image-based clues. Existing research\nin this domain has primarily focused on maximizing the utilization of\npotentially relevant information in images or incorporating external knowledge\nfrom explicit knowledge bases (KBs). However, these methods either neglect the\nnecessity of providing the model with relevant external knowledge, or the\nretrieved external knowledge suffers from high redundancy. To address these\nproblems, we propose a conceptually simple two-stage framework called Prompt\nChatGPT In MNER (PGIM) in this paper. We leverage ChatGPT as an implicit\nknowledge engine to acquire auxiliary refined knowledge, thereby bolstering the\nmodel's performance in MNER tasks. Specifically, we first utilize a Multimodal\nSimilar Example Awareness module to select suitable examples from a small\nnumber of manually annotated samples. These examples are then integrated into a\nformatted prompt template tailored to the MNER task, guiding ChatGPT to\ngenerate auxiliary refined knowledge. Finally, the acquired knowledge is\nintegrated with the raw text and inputted into the downstream model for further\nprocessing. Extensive experiments show that our PGIM significantly outperforms\nall existing state-of-the-art methods on two classic MNER datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Han Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1\">Zhuo Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1\">Gang Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Language Specification of Reinforcement Learning Policies through Differentiable Decision Trees. (arXiv:2101.07140v4 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2101.07140","description":"<p>Human-AI policy specification is a novel procedure we define in which humans\ncan collaboratively warm-start a robot's reinforcement learning policy. This\nprocedure is comprised of two steps; (1) Policy Specification, i.e. humans\nspecifying the behavior they would like their companion robot to accomplish,\nand (2) Policy Optimization, i.e. the robot applying reinforcement learning to\nimprove the initial policy. Existing approaches to enabling collaborative\npolicy specification are often unintelligible black-box methods, and are not\ncatered towards making the autonomous system accessible to a novice end-user.\nIn this paper, we develop a novel collaborative framework to allow humans to\ninitialize and interpret an autonomous agent's behavior. Through our framework,\nwe enable humans to specify an initial behavior model via unstructured, natural\nlanguage (NL), which we convert to lexical decision trees. Next, we leverage\nthese translated specifications, to warm-start reinforcement learning and allow\nthe agent to further optimize these potentially suboptimal policies. Our\napproach warm-starts an RL agent by utilizing non-expert natural language\nspecifications without incurring the additional domain exploration costs. We\nvalidate our approach by showing that our model is able to produce &gt;80%\ntranslation accuracy, and that policies initialized by a human can match the\nperformance of relevant RL baselines in two domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tambwekar_P/0/1/0/all/0/1\">Pradyumna Tambwekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1\">Andrew Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalan_N/0/1/0/all/0/1\">Nakul Gopalan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gombolay_M/0/1/0/all/0/1\">Matthew Gombolay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PoNet: Pooling Network for Efficient Token Mixing in Long Sequences. (arXiv:2110.02442v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.02442","description":"<p>Transformer-based models have achieved great success in various NLP, vision,\nand speech tasks. However, the core of Transformer, the self-attention\nmechanism, has a quadratic time and memory complexity with respect to the\nsequence length, which hinders applications of Transformer-based models to long\nsequences. Many approaches have been proposed to mitigate this problem, such as\nsparse attention mechanisms, low-rank matrix approximations and scalable\nkernels, and token mixing alternatives to self-attention. We propose a novel\nPooling Network (PoNet) for token mixing in long sequences with linear\ncomplexity. We design multi-granularity pooling and pooling fusion to capture\ndifferent levels of contextual information and combine their interactions with\ntokens. On the Long Range Arena benchmark, PoNet significantly outperforms\nTransformer and achieves competitive accuracy, while being only slightly slower\nthan the fastest model, FNet, across all sequence lengths measured on GPUs. We\nalso conduct systematic studies on the transfer learning capability of PoNet\nand observe that PoNet achieves 95.7% of the accuracy of BERT on the GLUE\nbenchmark, outperforming FNet by 4.5% relative. Comprehensive ablation analysis\ndemonstrates effectiveness of the designed multi-granularity pooling and\npooling fusion for token mixing in long sequences and efficacy of the designed\npre-training tasks for PoNet to learn transferable contextualized language\nrepresentations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chao-Hong Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Siqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ASR data augmentation in low-resource settings using cross-lingual multi-speaker TTS and cross-lingual voice conversion. (arXiv:2204.00618v5 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2204.00618","description":"<p>We explore cross-lingual multi-speaker speech synthesis and cross-lingual\nvoice conversion applied to data augmentation for automatic speech recognition\n(ASR) systems in low/medium-resource scenarios. Through extensive experiments,\nwe show that our approach permits the application of speech synthesis and voice\nconversion to improve ASR systems using only one target-language speaker during\nmodel training. We also managed to close the gap between ASR models trained\nwith synthesized versus human speech compared to other works that use many\nspeakers. Finally, we show that it is possible to obtain promising ASR training\nresults with our data augmentation method using only a single real speaker in a\ntarget language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Casanova_E/0/1/0/all/0/1\">Edresson Casanova</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shulby_C/0/1/0/all/0/1\">Christopher Shulby</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korolev_A/0/1/0/all/0/1\">Alexander Korolev</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Junior_A/0/1/0/all/0/1\">Arnaldo Candido Junior</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Soares_A/0/1/0/all/0/1\">Anderson da Silva Soares</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Aluisio_S/0/1/0/all/0/1\">Sandra Alu&#xed;sio</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ponti_M/0/1/0/all/0/1\">Moacir Antonelli Ponti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models. (arXiv:2205.10558v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.10558","description":"<p>In the field of Natural Language Processing, there are many tasks that can be\ntackled effectively using the cross-entropy (CE) loss function. However, the\ntask of dialog generation poses unique challenges for CE loss. This is because\nCE loss assumes that, for any given input, the only possible output is the one\navailable as the ground truth in the training dataset. But, in dialog\ngeneration, there can be multiple valid responses (for a given context) that\nnot only have different surface forms but can also be semantically different.\nFurthermore, CE loss computation for the dialog generation task does not take\nthe input context into consideration and, hence, it grades the response\nirrespective of the context. To grade the generated response for qualities like\nrelevance, engagingness, etc., the loss function should depend on both the\ncontext and the generated response. To address these limitations, this paper\nproposes CORAL, a novel loss function based on a reinforcement learning (RL)\nview of the dialog generation task with a reward function that estimates human\npreference for generated responses while considering both the context and the\nresponse. Furthermore, to overcome challenges such as high sample complexity of\nRL training and a large action space, we propose a mix-policy training\nalgorithm. Notably, using CORAL we can train dialog generation models without\nassuming the ground-truth as the only correct response. Extensive comparisons\non benchmark datasets demonstrate that CORAL based models outperform strong\nstate-of-the-art baseline models of different sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Santra_B/0/1/0/all/0/1\">Bishal Santra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghadia_R/0/1/0/all/0/1\">Ravi Ghadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CombLM: Adapting Black-Box Language Models through Small Fine-Tuned Models. (arXiv:2205.12213v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12213","description":"<p>Methods for adapting language models (LMs) to new tasks and domains have\ntraditionally assumed white-box access to the model, and work by modifying its\nparameters. However, this is incompatible with a recent trend in the field,\nwhere the highest quality models are only available as black-boxes through\ninference APIs. Even when the model weights are available, the computational\ncost of fine-tuning large LMs can be prohibitive for most practitioners. In\nthis work, we present a lightweight method for adapting large LMs to new\ndomains and tasks, assuming no access to their weights or intermediate\nactivations. Our approach fine-tunes a small white-box LM and combines it with\nthe large black-box LM at the probability level through a small network,\nlearned on a small validation set. We validate our approach by adapting a large\nLM (OPT-30B) to several domains and a downstream task (machine translation),\nobserving improved performance in all cases, of up to 9\\%, while using a domain\nexpert 23x smaller.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ormazabal_A/0/1/0/all/0/1\">Aitor Ormazabal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1\">Mikel Artetxe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection. (arXiv:2205.12495v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12495","description":"<p>Hate speech detection is complex; it relies on commonsense reasoning,\nknowledge of stereotypes, and an understanding of social nuance that differs\nfrom one culture to the next. It is also difficult to collect a large-scale\nhate speech annotated dataset. In this work, we frame this problem as a\nfew-shot learning task, and show significant gains with decomposing the task\ninto its \"constituent\" parts. In addition, we see that infusing knowledge from\nreasoning datasets (e.g. Atomic2020) improves the performance even further.\nMoreover, we observe that the trained models generalize to out-of-distribution\ndatasets, showing the superiority of task decomposition and knowledge infusion\ncompared to previously used methods. Concretely, our method outperforms the\nbaseline by 17.83% absolute gain in the 16-shot case.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ladhak_F/0/1/0/all/0/1\">Faisal Ladhak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_S/0/1/0/all/0/1\">Srini Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Ves Stoyanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozareva_Z/0/1/0/all/0/1\">Zornitsa Kozareva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathias_L/0/1/0/all/0/1\">Lambert Mathias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1\">Mona Diab</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Multimodal Transformer with Dual-Level Feature Restoration for Robust Multimodal Sentiment Analysis. (arXiv:2208.07589v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2208.07589","description":"<p>With the proliferation of user-generated online videos, Multimodal Sentiment\nAnalysis (MSA) has attracted increasing attention recently. Despite significant\nprogress, there are still two major challenges on the way towards robust MSA:\n1) inefficiency when modeling cross-modal interactions in unaligned multimodal\ndata; and 2) vulnerability to random modality feature missing which typically\noccurs in realistic settings. In this paper, we propose a generic and unified\nframework to address them, named Efficient Multimodal Transformer with\nDual-Level Feature Restoration (EMT-DLFR). Concretely, EMT employs\nutterance-level representations from each modality as the global multimodal\ncontext to interact with local unimodal features and mutually promote each\nother. It not only avoids the quadratic scaling cost of previous local-local\ncross-modal interaction methods but also leads to better performance. To\nimprove model robustness in the incomplete modality setting, on the one hand,\nDLFR performs low-level feature reconstruction to implicitly encourage the\nmodel to learn semantic information from incomplete data. On the other hand, it\ninnovatively regards complete and incomplete data as two different views of one\nsample and utilizes siamese representation learning to explicitly attract their\nhigh-level representations. Comprehensive experiments on three popular datasets\ndemonstrate that our method achieves superior performance in both complete and\nincomplete modality settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Licai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_Z/0/1/0/all/0/1\">Zheng Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1\">Jianhua Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Psychologically-informed chain-of-thought prompts for metaphor understanding in large language models. (arXiv:2209.08141v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.08141","description":"<p>Probabilistic models of language understanding are valuable tools for\ninvestigating human language use. However, they need to be hand-designed for a\nparticular domain. In contrast, large language models (LLMs) are trained on\ntext that spans a wide array of domains, but they lack the structure and\ninterpretability of probabilistic models. In this paper, we use\nchain-of-thought prompts to introduce structures from probabilistic models into\nLLMs. We explore this approach in the case of metaphor understanding. Our\nchain-of-thought prompts lead language models to infer latent variables and\nreason about their relationships in order to choose appropriate paraphrases for\nmetaphors. The latent variables and relationships chosen are informed by\ntheories of metaphor understanding from cognitive psychology. We apply these\nprompts to the two largest versions of GPT-3 and show that they can improve\nperformance in a paraphrase selection task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prystawski_B/0/1/0/all/0/1\">Ben Prystawski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thibodeau_P/0/1/0/all/0/1\">Paul Thibodeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Few-shot Approach to Resume Information Extraction via Prompts. (arXiv:2209.09450v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.09450","description":"<p>Prompt learning's fine-tune performance on text classification tasks has\nattracted the NLP community. This paper applies it to resume information\nextraction, improving existing methods for this task. We created manual\ntemplates and verbalizers tailored to resume texts and compared the performance\nof Masked Language Model (MLM) and Seq2Seq PLMs. Also, we enhanced the\nverbalizer design for Knowledgeable Prompt-tuning, contributing to prompt\ntemplate design across NLP tasks. We present the Manual Knowledgeable\nVerbalizer (MKV), a rule for constructing verbalizers for specific\napplications. Our tests show that MKV rules yield more effective, robust\ntemplates and verbalizers than existing methods. Our MKV approach resolved\nsample imbalance, surpassing current automatic prompt methods. This study\nunderscores the value of tailored prompt learning for resume extraction,\nstressing the importance of custom-designed templates and verbalizers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1\">Chengguang Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1\">Tatsunori Mori</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-CLS BERT: An Efficient Alternative to Traditional Ensembling. (arXiv:2210.05043v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.05043","description":"<p>Ensembling BERT models often significantly improves accuracy, but at the cost\nof significantly more computation and memory footprint. In this work, we\npropose Multi-CLS BERT, a novel ensembling method for CLS-based prediction\ntasks that is almost as efficient as a single BERT model. Multi-CLS BERT uses\nmultiple CLS tokens with a parameterization and objective that encourages their\ndiversity. Thus instead of fine-tuning each BERT model in an ensemble (and\nrunning them all at test time), we need only fine-tune our single Multi-CLS\nBERT model (and run the one model at test time, ensembling just the multiple\nfinal CLS embeddings). To test its effectiveness, we build Multi-CLS BERT on\ntop of a state-of-the-art pretraining method for BERT (Aroca-Ouellette and\nRudzicz, 2020). In experiments on GLUE and SuperGLUE we show that our Multi-CLS\nBERT reliably improves both overall accuracy and confidence estimation. When\nonly 100 training samples are available in GLUE, the Multi-CLS BERT_Base model\ncan even outperform the corresponding BERT_Large model. We analyze the behavior\nof our Multi-CLS BERT, showing that it has many of the same characteristics and\nbehavior as a typical BERT 5-way ensemble, but with nearly 4-times less\ncomputation and memory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Haw-Shiuan Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruei-Yao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ricci_K/0/1/0/all/0/1\">Kathryn Ricci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DICTDIS: Dictionary Constrained Disambiguation for Improved NMT. (arXiv:2210.06996v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06996","description":"<p>Domain-specific neural machine translation (NMT) systems (\\eg, in educational\napplications) are socially significant with the potential to help make\ninformation accessible to a diverse set of users in multilingual societies. It\nis desirable that such NMT systems be lexically constrained and draw from\ndomain-specific dictionaries. Dictionaries could present multiple candidate\ntranslations for a source word/phrase due to the polysemous nature of words.\nThe onus is then on the NMT model to choose the contextually most appropriate\ncandidate. Prior work has largely ignored this problem and focused on the\nsingle candidate constraint setting wherein the target word or phrase is\nreplaced by a single constraint. In this work we present \\dictdis, a lexically\nconstrained NMT system that disambiguates between multiple candidate\ntranslations derived from dictionaries. We achieve this by augmenting training\ndata with multiple dictionary candidates to actively encourage disambiguation\nduring training by implicitly aligning multiple candidate constraints. We\ndemonstrate the utility of \\dictdis\\ via extensive experiments on English-Hindi\nand English-German sentences in a variety of domains including regulatory,\nfinance, engineering. We also present comparisons on standard benchmark test\ndatasets. In comparison with existing approaches for lexically constrained and\nunconstrained NMT, we demonstrate superior performance with respect to\nconstraint copy and disambiguation related measures on all domains while also\nobtaining improved fluency of up to 2-3 BLEU points on some domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maheshwari_A/0/1/0/all/0/1\">Ayush Maheshwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1\">Piyush Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1\">Preethi Jyothi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Entity Detection with Proposer and Regressor. (arXiv:2210.10260v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10260","description":"<p>Named entity recognition is a traditional task in natural language\nprocessing. In particular, nested entity recognition receives extensive\nattention for the widespread existence of the nesting scenario. The latest\nresearch migrates the well-established paradigm of set prediction in object\ndetection to cope with entity nesting. However, the manual creation of query\nvectors, which fail to adapt to the rich semantic information in the context,\nlimits these approaches. An end-to-end entity detection approach with proposer\nand regressor is presented in this paper to tackle the issues. First, the\nproposer utilizes the feature pyramid network to generate high-quality entity\nproposals. Then, the regressor refines the proposals for generating the final\nprediction. The model adopts encoder-only architecture and thus obtains the\nadvantages of the richness of query semantics, high precision of entity\nlocalization, and easiness of model training. Moreover, we introduce the novel\nspatially modulated attention and progressive refinement for further\nimprovement. Extensive experiments demonstrate that our model achieves advanced\nperformance in flat and nested NER, achieving a new state-of-the-art F1 score\nof 80.74 on the GENIA dataset and 72.38 on the WeiboNER dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xueru Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Changjiang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haotian Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1\">Luguang Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1\">Hong Qi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Speech Translation and Named Entity Recognition. (arXiv:2210.11987v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.11987","description":"<p>Modern automatic translation systems aim at place the human at the center by\nproviding contextual support and knowledge. In this context, a critical task is\nenriching the output with information regarding the mentioned entities, which\nis currently achieved processing the generated translation with named entity\nrecognition (NER) and entity linking systems. In light of the recent promising\nresults shown by direct speech translation (ST) models and the known weaknesses\nof cascades (error propagation and additional latency), in this paper we\npropose multitask models that jointly perform ST and NER, and compare them with\na cascade baseline. The experimental results show that our models significantly\noutperform the cascade on the NER task (by 0.4-1.0 F1), without degradation in\nterms of translation quality, and with the same computational efficiency of a\nplain direct ST model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gaido_M/0/1/0/all/0/1\">Marco Gaido</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papi_S/0/1/0/all/0/1\">Sara Papi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1\">Matteo Negri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1\">Marco Turchi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Training and Inference Strategy Using Noisy and Enhanced Speech as Target for Speech Enhancement without Clean Speech. (arXiv:2210.15368v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2210.15368","description":"<p>The lack of clean speech is a practical challenge to the development of\nspeech enhancement systems, which means that there is an inevitable mismatch\nbetween their training criterion and evaluation metric. In response to this\nunfavorable situation, we propose a training and inference strategy that\nadditionally uses enhanced speech as a target by improving the previously\nproposed noisy-target training (NyTT). Because homogeneity between in-domain\nnoise and extraneous noise is the key to the effectiveness of NyTT, we train\nvarious student models by remixing 1) the teacher model's estimated speech and\nnoise for enhanced-target training or 2) raw noisy speech and the teacher\nmodel's estimated noise for noisy-target training. Experimental results show\nthat our proposed method outperforms several baselines, especially with the\nteacher/student inference, where predicted clean speech is derived successively\nthrough the teacher and final student models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li-Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1\">Yao-Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Shin Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1\">Yu Tsao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hsin-Min Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiaASQ : A Benchmark of Conversational Aspect-based Sentiment Quadruple Analysis. (arXiv:2211.05705v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.05705","description":"<p>The rapid development of aspect-based sentiment analysis (ABSA) within recent\ndecades shows great potential for real-world society. The current ABSA works,\nhowever, are mostly limited to the scenario of a single text piece, leaving the\nstudy in dialogue contexts unexplored. To bridge the gap between fine-grained\nsentiment analysis and conversational opinion mining, in this work, we\nintroduce a novel task of conversational aspect-based sentiment quadruple\nanalysis, namely DiaASQ, aiming to detect the quadruple of\ntarget-aspect-opinion-sentiment in a dialogue. We manually construct a\nlarge-scale high-quality DiaASQ dataset in both Chinese and English languages.\nWe deliberately develop a neural model to benchmark the task, which advances in\neffectively performing end-to-end quadruple prediction, and manages to\nincorporate rich dialogue-specific and discourse feature representations for\nbetter cross-utterance quadruple extraction. We hope the new benchmark will\nspur more advancements in the sentiment analysis community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jinsong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingye Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yijiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1\">Lizi Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Donghong Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting Language Models for Linguistic Structure. (arXiv:2211.07830v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.07830","description":"<p>Although pretrained language models (PLMs) can be prompted to perform a wide\nrange of language tasks, it remains an open question how much this ability\ncomes from generalizable linguistic understanding versus surface-level lexical\npatterns. To test this, we present a structured prompting approach for\nlinguistic structured prediction tasks, allowing us to perform zero- and\nfew-shot sequence tagging with autoregressive PLMs. We evaluate this approach\non part-of-speech tagging, named entity recognition, and sentence chunking,\ndemonstrating strong few-shot performance in all cases. We also find that while\nPLMs contain significant prior knowledge of task labels due to task leakage\ninto the pretraining corpus, structured prompting can also retrieve linguistic\nstructure with arbitrary labels. These findings indicate that the in-context\nlearning ability and linguistic knowledge of PLMs generalizes beyond\nmemorization of their training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Blevins_T/0/1/0/all/0/1\">Terra Blevins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonen_H/0/1/0/all/0/1\">Hila Gonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GLUE-X: Evaluating Natural Language Understanding Models from an Out-of-distribution Generalization Perspective. (arXiv:2211.08073v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08073","description":"<p>Pre-trained language models (PLMs) are known to improve the generalization\nperformance of natural language understanding models by leveraging large\namounts of data during the pre-training phase. However, the out-of-distribution\n(OOD) generalization problem remains a challenge in many NLP tasks, limiting\nthe real-world deployment of these methods. This paper presents the first\nattempt at creating a unified benchmark named GLUE-X for evaluating OOD\nrobustness in NLP models, highlighting the importance of OOD robustness and\nproviding insights on how to measure the robustness of a model and how to\nimprove it. The benchmark includes 13 publicly available datasets for OOD\ntesting, and evaluations are conducted on 8 classic NLP tasks over 21 popularly\nused PLMs, including GPT-3 and GPT-3.5. Our findings confirm the need for\nimproved OOD accuracy in NLP tasks, as significant performance degradation was\nobserved in all settings compared to in-distribution (ID) accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuibai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Libo Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yafu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanmeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEAL: Stable and Active Learning for Few-Shot Prompting. (arXiv:2211.08358v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08358","description":"<p>Few-shot classification has made great strides due to foundation models that,\nthrough priming and prompting, are highly effective few-shot learners. However,\nthis approach has high variance both across different sets of few shots (data\nselection) and across different finetuning runs (run variability). This is\nproblematic not only because it impedes the fair comparison of different\napproaches, but especially because it makes few-shot learning too unreliable\nfor many real-world applications. To alleviate these issues, we make two\ncontributions for more stable and effective few-shot learning: First, we\npropose novel ensembling methods and show that they substantially reduce run\nvariability. Second, we introduce a new active learning (AL) criterion for data\nselection and present the first AL-based approach specifically tailored towards\nprompt-based learning. In our experiments, we show that our combined method,\nMEAL (Multiprompt finetuning and prediction Ensembling with Active Learning),\nimproves overall performance of prompt-based finetuning by 2.3 points on five\ndiverse tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koksal_A/0/1/0/all/0/1\">Abdullatif K&#xf6;ksal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schick_T/0/1/0/all/0/1\">Timo Schick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pragmatics in Language Grounding: Phenomena, Tasks, and Modeling Approaches. (arXiv:2211.08371v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08371","description":"<p>People rely heavily on context to enrich meaning beyond what is literally\nsaid, enabling concise but effective communication. To interact successfully\nand naturally with people, user-facing artificial intelligence systems will\nrequire similar skills in pragmatics: relying on various types of context --\nfrom shared linguistic goals and conventions, to the visual and embodied world\n-- to use language effectively. We survey existing grounded settings and\npragmatic modeling approaches and analyze how the task goals, environmental\ncontexts, and communicative affordances in each work enrich linguistic meaning.\nWe present recommendations for future grounded task design to naturally elicit\npragmatic phenomena, and suggest directions that focus on a broader range of\ncommunicative contexts and affordances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1\">Daniel Fried</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomlin_N/0/1/0/all/0/1\">Nicholas Tomlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jennifer Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_R/0/1/0/all/0/1\">Roma Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1\">Aida Nematzadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"[RE]VER: Learning Natural Language Representations for Verbalizing Entities and Relations. (arXiv:2211.11093v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11093","description":"<p>Entities and relationships between entities are vital in the real world.\nEssentially, we understand the world by understanding entities and relations.\nFor instance, to understand a field, e.g., computer science, we need to\nunderstand the relevant concepts, e.g., machine learning, and the relationships\nbetween concepts, e.g., machine learning and artificial intelligence. To\nunderstand a person, we should first know who he/she is and how he/she is\nrelated to others. To understand entities and relations, humans may refer to\nnatural language descriptions. For instance, when learning a new scientific\nterm, people usually start by reading its definition in dictionaries or\nencyclopedias. To know the relationship between two entities, humans tend to\ncreate a sentence to connect them. In this paper, we propose [RE]VER: A Unified\nModel for Verbalizing Entities and Relations. Specifically, we attempt to build\na system that takes any entity or entity set as input and generates a sentence\nto represent entities and relations, named \"natural language representation\".\nExtensive experiments demonstrate that our model can generate high-quality\nsentences describing entities and entity relationships and facilitate various\ntasks on entities and relations, including definition modeling, relation\nmodeling, and generative commonsense reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntactic Substitutability as Unsupervised Dependency Syntax. (arXiv:2211.16031v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.16031","description":"<p>Syntax is a latent hierarchical structure which underpins the robust and\ncompositional nature of human language. In this work, we further explore the\nhypothesis that syntactic dependencies can be represented in the attention\ndistributions of language models trained on text and propose a new method to\ninduce these structures theory-agnostically. Instead of modeling syntactic\nrelations as defined by annotation schemata, we model a more general property\nimplicit in the definition of dependency relations, syntactic substitutability.\nThis property captures the fact that the words at either end of a syntactic\ndependency can be substituted with words from the same syntactic category,\ndefining a set of syntactically-invariant sentences whose representations are\nthen used as the basis for parsing. We demonstrate that our method results in\nboth qualitative and quantitative gains, for example achieving 78.3% recall on\na long-distance subject-verb agreement task vs. 8.5% with a previous\nunsupervised parsing method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jian_J/0/1/0/all/0/1\">Jasper Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EURO: ESPnet Unsupervised ASR Open-source Toolkit. (arXiv:2211.17196v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.17196","description":"<p>This paper describes the ESPnet Unsupervised ASR Open-source Toolkit (EURO),\nan end-to-end open-source toolkit for unsupervised automatic speech recognition\n(UASR). EURO adopts the state-of-the-art UASR learning method introduced by the\nWav2vec-U, originally implemented at FAIRSEQ, which leverages self-supervised\nspeech representations and adversarial training. In addition to wav2vec2, EURO\nextends the functionality and promotes reproducibility for UASR tasks by\nintegrating S3PRL and k2, resulting in flexible frontends from 27\nself-supervised models and various graph-based decoding strategies. EURO is\nimplemented in ESPnet and follows its unified pipeline to provide UASR recipes\nwith a complete setup. This improves the pipeline's efficiency and allows EURO\nto be easily applied to existing datasets in ESPnet. Extensive experiments on\nthree mainstream self-supervised models demonstrate the toolkit's effectiveness\nand achieve state-of-the-art UASR performance on TIMIT and LibriSpeech\ndatasets. EURO will be publicly available at https://github.com/espnet/espnet,\naiming to promote this exciting and emerging research area based on UASR\nthrough open-source activity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dongji Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_S/0/1/0/all/0/1\">Shun-Po Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_L/0/1/0/all/0/1\">Leibny Paola Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khudanpur_S/0/1/0/all/0/1\">Sanjeev Khudanpur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Identification of Eviction Status from Electronic Health Record Notes. (arXiv:2212.02762v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.02762","description":"<p>Objective: Evictions are important social and behavioral determinants of\nhealth. Evictions are associated with a cascade of negative events that can\nlead to unemployment, housing insecurity/homelessness, long-term poverty, and\nmental health problems. In this study, we developed a natural language\nprocessing system to automatically detect eviction status from electronic\nhealth record (EHR) notes.\n</p>\n<p>Materials and Methods: We first defined eviction status (eviction presence\nand eviction period) and then annotated eviction status in 5000 EHR notes from\nthe Veterans Health Administration (VHA). We developed a novel model, KIRESH,\nthat has shown to substantially outperform other state-of-the-art models such\nas fine-tuning pre-trained language models like BioBERT and BioClinicalBERT.\nMoreover, we designed a novel prompt to further improve the model performance\nby using the intrinsic connection between the two sub-tasks of eviction\npresence and period prediction. Finally, we used the Temperature Scaling-based\nCalibration on our KIRESH-Prompt method to avoid over-confidence issues arising\nfrom the imbalance dataset.\n</p>\n<p>Results: KIRESH-Prompt substantially outperformed strong baseline models\nincluding fine-tuning the BioClinicalBERT model to achieve 0.74672 MCC, 0.71153\nMacro-F1, and 0.83396 Micro-F1 in predicting eviction period and 0.66827 MCC,\n0.62734 Macro-F1, and 0.7863 Micro-F1 in predicting eviction presence. We also\nconducted additional experiments on a benchmark social determinants of health\n(SBDH) dataset to demonstrate the generalizability of our methods.\n</p>\n<p>Conclusion and Future Work: KIRESH-Prompt has substantially improved eviction\nstatus classification. We plan to deploy KIRESH-Prompt to the VHA EHRs as an\neviction surveillance system to help address the US Veterans' housing\ninsecurity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zonghai Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsai_J/0/1/0/all/0/1\">Jack Tsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weisong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_D/0/1/0/all/0/1\">David A. Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Druhl_E/0/1/0/all/0/1\">Emily Druhl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reisman_J/0/1/0/all/0/1\">Joel I Reisman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Glyph Phonetic Information for Chinese Spell Checking: What Works and What's Next. (arXiv:2212.04068v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.04068","description":"<p>While pre-trained Chinese language models have demonstrated impressive\nperformance on a wide range of NLP tasks, the Chinese Spell Checking (CSC) task\nremains a challenge. Previous research has explored using information such as\nglyphs and phonetics to improve the ability to distinguish misspelled\ncharacters, with good results. However, the generalization ability of these\nmodels is not well understood: it is unclear whether they incorporate\nglyph-phonetic information and, if so, whether this information is fully\nutilized. In this paper, we aim to better understand the role of glyph-phonetic\ninformation in the CSC task and suggest directions for improvement.\nAdditionally, we propose a new, more challenging, and practical setting for\ntesting the generalizability of CSC models. All code is made publicly\navailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yanjun Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Text-based Personality Computing: Challenges and Future Directions. (arXiv:2212.06711v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.06711","description":"<p>Text-based personality computing (TPC) has gained many research interests in\nNLP. In this paper, we describe 15 challenges that we consider deserving the\nattention of the research community. These challenges are organized by the\nfollowing topics: personality taxonomies, measurement quality, datasets,\nperformance evaluation, modelling choices, as well as ethics and fairness. When\naddressing each challenge, not only do we combine perspectives from both NLP\nand social sciences, but also offer concrete suggestions. We hope to inspire\nmore valid and reliable TPC research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_Q/0/1/0/all/0/1\">Qixiang Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giachanou_A/0/1/0/all/0/1\">Anastasia Giachanou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagheri_A/0/1/0/all/0/1\">Ayoub Bagheri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boeschoten_L/0/1/0/all/0/1\">Laura Boeschoten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kesteren_E/0/1/0/all/0/1\">Erik-Jan van Kesteren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamalabad_M/0/1/0/all/0/1\">Mahdi Shafiee Kamalabad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oberski_D/0/1/0/all/0/1\">Daniel L Oberski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RISE: Leveraging Retrieval Techniques for Summarization Evaluation. (arXiv:2212.08775v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.08775","description":"<p>Evaluating automatically-generated text summaries is a challenging task.\nWhile there have been many interesting approaches, they still fall short of\nhuman evaluations. We present RISE, a new approach for evaluating summaries by\nleveraging techniques from information retrieval. RISE is first trained as a\nretrieval task using a dual-encoder retrieval setup, and can then be\nsubsequently utilized for evaluating a generated summary given an input\ndocument, without gold reference summaries. RISE is especially well suited when\nworking on new datasets where one may not have reference summaries available\nfor evaluation. We conduct comprehensive experiments on the SummEval benchmark\n(Fabbri et al., 2021) and the results show that RISE has higher correlation\nwith human evaluations compared to many past approaches to summarization\nevaluation. Furthermore, RISE also demonstrates data-efficiency and\ngeneralizability across languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uthus_D/0/1/0/all/0/1\">David Uthus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Norm of Word Embedding Encodes Information Gain. (arXiv:2212.09663v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09663","description":"<p>Distributed representations of words encode lexical semantic information, but\nwhat type of information is encoded, and how? Focusing on the skip-gram with\nnegative-sampling method, we found that the squared norm of static word\nembedding encodes the information gain conveyed by the word; the information\ngain is defined by the Kullback-Leibler divergence of the co-occurrence\ndistribution of the word to the unigram distribution of the corpus. Our\nfindings are explained by the theoretical framework of the exponential family\nof probability distributions and confirmed through precise experiments that\nremove spurious correlations arising from word frequency. We demonstrate that\nboth the KL divergence and the squared norm of embedding provide a useful\nmetric of a word's informativeness in tasks such as keyword extraction,\npart-of-speech discrimination, and hypernym classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oyama_M/0/1/0/all/0/1\">Momose Oyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yokoi_S/0/1/0/all/0/1\">Sho Yokoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shimodaira_H/0/1/0/all/0/1\">Hidetoshi Shimodaira</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SegAugment: Maximizing the Utility of Speech Translation Data with Segmentation-based Augmentations. (arXiv:2212.09699v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09699","description":"<p>End-to-end Speech Translation is hindered by a lack of available data\nresources. While most of them are based on documents, a sentence-level version\nis available, which is however single and static, potentially impeding the\nusefulness of the data. We propose a new data augmentation strategy,\nSegAugment, to address this issue by generating multiple alternative\nsentence-level versions of a dataset. Our method utilizes an Audio Segmentation\nsystem, which re-segments the speech of each document with different length\nconstraints, after which we obtain the target text via alignment methods.\nExperiments demonstrate consistent gains across eight language pairs in MuST-C,\nwith an average increase of 2.5 BLEU points, and up to 5 BLEU for low-resource\nscenarios in mTEDx. Furthermore, when combined with a strong system, SegAugment\nestablishes new state-of-the-art results in MuST-C. Finally, we show that the\nproposed method can also successfully augment sentence-level datasets, and that\nit enables Speech Translation models to close the gap between the manual and\nautomatic segmentation at inference time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tsiamas_I/0/1/0/all/0/1\">Ioannis Tsiamas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonollosa_J/0/1/0/all/0/1\">Jos&#xe9; A. R. Fonollosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1\">Marta R. Costa-juss&#xe0;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KNIFE: Distilling Reasoning Knowledge From Free-Text Rationales. (arXiv:2212.09721v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09721","description":"<p>Language models (LMs) have yielded impressive results on many language\nreasoning tasks, but their unexpected errors raise doubts about their reasoning\nabilities. In light of this, there is growing interest in finetuning/prompting\nLMs with both task instances and their associated free-text rationales (FTRs),\nwhich explain the correct reasoning process for predicting the correct task\noutput (i.e., how to be \"right for the right reasons\"). However, existing\nfinetuning methods fail to improve LM performance, while prompting needs\nprohibitively large (i.e., &gt;50B) LMs to work well. We propose KNIFE, which\nshows that reasoning knowledge can be effectively distilled from FTRs into a\nsmall (i.e., &lt;1B) LM and improve the LM's performance. First, KNIFE finetunes a\nteacher LM (given task input and FTR) to predict the task output, transferring\nreasoning knowledge from the FTRs to the teacher's hidden states. Second, KNIFE\nfinetunes a student LM (given task input only) such that its hidden states are\naligned with the teacher's. Thus, the student is endowed with reasoning\nknowledge but can be used for inference without direct FTR input. On two\nquestion-answering datasets, KNIFE outperforms various finetuning and prompting\nbaselines in fully-supervised and low-resource settings. Also, we observe that\nFTR quality is crucial to KNIFE's performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1\">Aaron Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhiyuan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lake_W/0/1/0/all/0/1\">Wyatt Lake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_B/0/1/0/all/0/1\">Brihi Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SeqDiffuSeq: Text Diffusion with Encoder-Decoder Transformers. (arXiv:2212.10325v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10325","description":"<p>Diffusion model, a new generative modelling paradigm, has achieved great\nsuccess in image, audio, and video generation. However, considering the\ndiscrete categorical nature of text, it is not trivial to extend continuous\ndiffusion models to natural language, and text diffusion models are less\nstudied. Sequence-to-sequence text generation is one of the essential natural\nlanguage processing topics. In this work, we apply diffusion models to approach\nsequence-to-sequence text generation, and explore whether the superiority\ngeneration performance of diffusion model can transfer to natural language\ndomain. We propose SeqDiffuSeq, a text diffusion model for sequence-to-sequence\ngeneration. SeqDiffuSeq uses an encoder-decoder Transformers architecture to\nmodel denoising function. In order to improve generation quality, SeqDiffuSeq\ncombines the self-conditioning technique and a newly proposed adaptive noise\nschedule technique. The adaptive noise schedule has the difficulty of denoising\nevenly distributed across time steps, and considers exclusive noise schedules\nfor tokens at different positional order. Experiment results illustrate the\ngood performance on sequence-to-sequence generation in terms of text quality\nand inference time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongyi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Little Red Riding Hood Goes Around the Globe:Crosslingual Story Planning and Generation with Large Language Models. (arXiv:2212.10471v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10471","description":"<p>Previous work has demonstrated the effectiveness of planning for story\ngeneration exclusively in a monolingual setting focusing primarily on English.\nWe consider whether planning brings advantages to automatic story generation\nacross languages. We propose a new task of cross-lingual story generation with\nplanning and present a new dataset for this task. We conduct a comprehensive\nstudy of different plans and generate stories in several languages, by\nleveraging the creative and reasoning capabilities of large pre-trained\nlanguage models. Our results demonstrate that plans which structure stories\ninto three acts lead to more coherent and interesting narratives, while\nallowing to explicitly control their content and structure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razumovskaia_E/0/1/0/all/0/1\">Evgeniia Razumovskaia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maynez_J/0/1/0/all/0/1\">Joshua Maynez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Annie Louis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_S/0/1/0/all/0/1\">Shashi Narayan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines. (arXiv:2212.10557v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10557","description":"<p>Dialogue models are able to generate coherent and fluent responses, but they\ncan still be challenging to control and may produce non-engaging, unsafe\nresults. This unpredictability diminishes user trust and can hinder the use of\nthe models in the real world. To address this, we introduce DialGuide, a novel\nframework for controlling dialogue model behavior using natural language rules,\nor guidelines. These guidelines provide information about the context they are\napplicable to and what should be included in the response, allowing the models\nto generate responses that are more closely aligned with the developer's\nexpectations and intent. We evaluate DialGuide on three tasks in open-domain\ndialogue response generation: guideline selection, response generation, and\nresponse entailment verification. Our dataset contains 10,737 positive and\n15,467 negative dialogue context-response-guideline triplets across two domains\n- chit-chat and safety. We provide baseline models for the tasks and benchmark\ntheir performance. We also demonstrate that DialGuide is effective in the\ndialogue safety domain, producing safe and engaging responses that follow\ndeveloper guidelines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hedayatnia_B/0/1/0/all/0/1\">Behnam Hedayatnia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gella_S/0/1/0/all/0/1\">Spandana Gella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Sijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lange_P/0/1/0/all/0/1\">Patrick Lange</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirschberg_J/0/1/0/all/0/1\">Julia Hirschberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-Tur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Black-box language model explanation by context length probing. (arXiv:2212.14815v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.14815","description":"<p>The increasingly widespread adoption of large language models has highlighted\nthe need for improving their explainability. We present context length probing,\na novel explanation technique for causal language models, based on tracking the\npredictions of a model as a function of the length of available context, and\nallowing to assign differential importance scores to different contexts. The\ntechnique is model-agnostic and does not rely on access to model internals\nbeyond computing token-level probabilities. We apply context length probing to\nlarge pre-trained language models and offer some initial analyses and insights,\nincluding the potential for studying long-range dependencies. The source code\nand an interactive demo of the method are available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cifka_O/0/1/0/all/0/1\">Ond&#x159;ej C&#xed;fka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liutkus_A/0/1/0/all/0/1\">Antoine Liutkus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Two Stage Contextual Word Filtering for Context bias in Unified Streaming and Non-streaming Transducer. (arXiv:2301.06735v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2301.06735","description":"<p>It is difficult for an E2E ASR system to recognize words such as entities\nappearing infrequently in the training data. A widely used method to mitigate\nthis issue is feeding contextual information into the acoustic model. Previous\nworks have proven that a compact and accurate contextual list can boost the\nperformance significantly. In this paper, we propose an efficient approach to\nobtain a high quality contextual list for a unified streaming/non-streaming\nbased E2E model. Specifically, we make use of the phone-level streaming output\nto first filter the predefined contextual word list then fuse it into\nnon-casual encoder and decoder to generate the final recognition results. Our\napproach improve the accuracy of the contextual ASR system and speed up the\ninference process. Experiments on two datasets demonstrates over 20% CERR\ncomparing to the baseline system. Meanwile, the RTF of our system can be\nstabilized within 0.15 when the size of the contextual word list grows over\n6000.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhanheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Sining Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yike Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Long Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lei Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Peanuts Fall in Love with Distributional Semantics?. (arXiv:2301.08731v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08731","description":"<p>Context changes expectations about upcoming words - following a story\ninvolving an anthropomorphic peanut, comprehenders expect the sentence the\npeanut was in love more than the peanut was salted, as indexed by N400\namplitude (Nieuwland &amp; van Berkum, 2006). This updating of expectations has\nbeen explained using Situation Models - mental representations of a described\nevent. However, recent work showing that N400 amplitude is predictable from\ndistributional information alone raises the question whether situation models\nare necessary for these contextual effects. We model the results of Nieuwland\nand van Berkum (2006) using six computational language models and three sets of\nword vectors, none of which have explicit situation models or semantic\ngrounding. We find that a subset of these can fully model the effect found by\nNieuwland and van Berkum (2006). Thus, at least some processing effects\nnormally explained through situation models may not in fact require explicit\nsituation models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Michaelov_J/0/1/0/all/0/1\">James A. Michaelov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coulson_S/0/1/0/all/0/1\">Seana Coulson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergen_B/0/1/0/all/0/1\">Benjamin K. Bergen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniAdapter: Unified Parameter-Efficient Transfer Learning for Cross-modal Modeling. (arXiv:2302.06605v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2302.06605","description":"<p>Large-scale vision-language pre-trained models have shown promising\ntransferability to various downstream tasks. As the size of these foundation\nmodels and the number of downstream tasks grow, the standard full fine-tuning\nparadigm becomes unsustainable due to heavy computational and storage costs.\nThis paper proposes UniAdapter, which unifies unimodal and multimodal adapters\nfor parameter-efficient cross-modal adaptation on pre-trained vision-language\nmodels. Specifically, adapters are distributed to different modalities and\ntheir interactions, with the total number of tunable parameters reduced by\npartial weight sharing. The unified and knowledge-sharing design enables\npowerful cross-modal representations that can benefit various downstream tasks,\nrequiring only 1.0%-2.0% tunable parameters of the pre-trained model. Extensive\nexperiments on 6 cross-modal downstream benchmarks (including video-text\nretrieval, image-text retrieval, VideoQA, and VQA) show that in most cases,\nUniAdapter not only outperforms the state-of-the-arts, but even beats the full\nfine-tuning strategy. Particularly, on the MSRVTT retrieval task, UniAdapter\nachieves 49.7% recall@1 with 2.2% model parameters, outperforming the latest\ncompetitors by 2.0%. The code and models are available at\nhttps://github.com/RERV/UniAdapter.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Haoyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yuqi Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guoxing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiwu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wei Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1\">Masayoshi Tomizuka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1\">Mingyu Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Initialize: Can Meta Learning Improve Cross-task Generalization in Prompt Tuning?. (arXiv:2302.08143v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08143","description":"<p>Prompt tuning (PT) which only tunes the embeddings of an additional sequence\nof tokens per task, keeping the pre-trained language model (PLM) frozen, has\nshown remarkable performance in few-shot learning. Despite this, PT has been\nshown to rely heavily on good initialization of the prompt embeddings. In this\nwork, we study meta prompt tuning (MPT) to systematically explore how\nmeta-learning can help improve (if it can) cross-task generalization in PT\nthrough learning to initialize the prompt embeddings from other relevant tasks.\nWe empirically analyze a representative set of meta learning algorithms in a\nwide range of adaptation settings with different source/target task\nconfigurations on a large set of few-shot tasks. With extensive experiments and\nanalysis, we demonstrate the effectiveness of MPT. We find the improvement to\nbe significant particularly on classification tasks. For other kinds of tasks\nsuch as question answering, we observe that while MPT can outperform PT in most\ncases, it does not always outperform multi-task learning. We further provide an\nin-depth analysis from the perspective of task similarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1\">Ruochen Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Handling the Alignment for Wake Word Detection: A Comparison Between Alignment-Based, Alignment-Free and Hybrid Approaches. (arXiv:2302.08950v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08950","description":"<p>Wake word detection exists in most intelligent homes and portable devices. It\noffers these devices the ability to \"wake up\" when summoned at a low cost of\npower and computing. This paper focuses on understanding alignment's role in\ndeveloping a wake-word system that answers a generic phrase. We discuss three\napproaches. The first is alignment-based, where the model is trained with\nframe-wise cross-entropy. The second is alignment-free, where the model is\ntrained with CTC. The third, proposed by us, is a hybrid solution in which the\nmodel is trained with a small set of aligned data and then tuned with a\nsizeable unaligned dataset. We compare the three approaches and evaluate the\nimpact of the different aligned-to-unaligned ratios for hybrid training. Our\nresults show that the alignment-free system performs better than the\nalignment-based for the target operating point, and with a small fraction of\nthe data (20%), we can train a model that complies with our initial\nconstraints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_V/0/1/0/all/0/1\">Vinicius Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yiteng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shangguan_Y/0/1/0/all/0/1\">Yuan Shangguan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhaojun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_L/0/1/0/all/0/1\">Li Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Ming Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers. (arXiv:2303.00807v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2303.00807","description":"<p>Many information retrieval tasks require large labeled datasets for\nfine-tuning. However, such datasets are often unavailable, and their utility\nfor real-world applications can diminish quickly due to domain shifts. To\naddress this challenge, we develop and motivate a method for using large\nlanguage models (LLMs) to generate large numbers of synthetic queries cheaply.\nThe method begins by generating a small number of synthetic queries using an\nexpensive LLM. After that, a much less expensive one is used to create large\nnumbers of synthetic queries, which are used to fine-tune a family of reranker\nmodels. These rerankers are then distilled into a single efficient retriever\nfor use in the target domain. We show that this technique boosts zero-shot\naccuracy in long-tail domains, even where only 2K synthetic queries are used\nfor fine-tuning, and that it achieves substantially lower latency than standard\nreranking methods. We make our end-to-end approach, including our synthetic\ndatasets and replication code, publicly available on Github:\nhttps://github.com/primeqa/primeqa.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saad_Falcon_J/0/1/0/all/0/1\">Jon Saad-Falcon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khattab_O/0/1/0/all/0/1\">Omar Khattab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santhanam_K/0/1/0/all/0/1\">Keshav Santhanam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florian_R/0/1/0/all/0/1\">Radu Florian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Franz_M/0/1/0/all/0/1\">Martin Franz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1\">Salim Roukos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sil_A/0/1/0/all/0/1\">Avirup Sil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1\">Md Arafat Sultan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reflexion: Language Agents with Verbal Reinforcement Learning. (arXiv:2303.11366v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2303.11366","description":"<p>Large language models (LLMs) have been increasingly used to interact with\nexternal environments (e.g., games, compilers, APIs) as goal-driven agents.\nHowever, it remains challenging for these language agents to quickly and\nefficiently learn from trial-and-error as traditional reinforcement learning\nmethods require extensive training samples and expensive model fine-tuning. We\npropose Reflexion, a novel framework to reinforce language agents not by\nupdating weights, but instead through linguistic feedback. Concretely,\nReflexion agents verbally reflect on task feedback signals, then maintain their\nown reflective text in an episodic memory buffer to induce better\ndecision-making in subsequent trials. Reflexion is flexible enough to\nincorporate various types (scalar values or free-form language) and sources\n(external or internally simulated) of feedback signals, and obtains significant\nimprovements over a baseline agent across diverse tasks (sequential\ndecision-making, coding, language reasoning). For example, Reflexion achieves a\n91% pass@1 accuracy on the HumanEval coding benchmark, surpassing the previous\nstate-of-the-art GPT-4 that achieves 80%. We also conduct ablation and analysis\nstudies using different feedback signals, feedback incorporation methods, and\nagent types, and provide insights into how they affect performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shinn_N/0/1/0/all/0/1\">Noah Shinn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassano_F/0/1/0/all/0/1\">Federico Cassano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labash_B/0/1/0/all/0/1\">Beck Labash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopinath_A/0/1/0/all/0/1\">Ashwin Gopinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shunyu Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization. (arXiv:2303.12314v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12314","description":"<p>Prompt tuning is a parameter-efficient method, which learns soft prompts and\nconditions frozen language models to perform specific downstream tasks. Though\neffective, prompt tuning under few-shot settings on the one hand heavily relies\non a good initialization of soft prompts. On the other hand, it can easily\noverfit to few-shot training samples, thereby undermining generalizability.\nExisting works leverage pre-training or supervised meta-learning to initialize\nsoft prompts but they fail to data-efficiently generalize to unseen downstream\ntasks. To address the above problems, this paper proposes a novel\nSelf-supervised meta-prompt learning framework with meta-gradient\nregularization for few-shot generalization (SUPMER). SUPMER leverages\nself-supervised meta-learning with a diverse set of well-designed meta-tasks to\nlearn a universal prompt initialization for efficient adaptation using only\nunlabeled data. Additionally, it jointly meta-learns a gradient regularization\nfunction to transform raw gradients into a domain-generalizable direction, thus\nalleviating the problem of overfitting. Extensive experiments show that SUPMER\nachieves better performance for different few-shot downstream tasks, and also\nexhibits a stronger domain generalization ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_K/0/1/0/all/0/1\">Kaihang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juncheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hongye Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEGA: Multilingual Evaluation of Generative AI. (arXiv:2303.12528v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12528","description":"<p>Generative AI models have impressive performance on many Natural Language\nProcessing tasks such as language understanding, reasoning and language\ngeneration. One of the most important questions that is being asked by the AI\ncommunity today is about the capabilities and limits of these models, and it is\nclear that evaluating generative AI is very challenging. Most studies on\ngenerative Large Language Models (LLMs) are restricted to English and it is\nunclear how capable these models are at understanding and generating other\nlanguages. We present the first comprehensive benchmarking of generative LLMs -\nMEGA, which evaluates models on standard NLP benchmarks, covering 8 diverse\ntasks and 33 typologically diverse languages. We also compare the performance\nof generative LLMs to State of the Art (SOTA) non-autoregressive models on\nthese tasks to determine how well generative models perform compared to the\nprevious generation of LLMs. We present a thorough analysis of the performance\nof models across languages and discuss some of the reasons why generative LLMs\nare currently not optimal for all languages. We create a framework for\nevaluating generative LLMs in the multilingual setting and provide directions\nfor future progress in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kabir Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diddee_H/0/1/0/all/0/1\">Harshita Diddee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1\">Rishav Hada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochieng_M/0/1/0/all/0/1\">Millicent Ochieng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_K/0/1/0/all/0/1\">Krithika Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prachi Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1\">Akshay Nambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1\">Tanuja Ganu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segal_S/0/1/0/all/0/1\">Sameer Segal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Axmed_M/0/1/0/all/0/1\">Maxamed Axmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_K/0/1/0/all/0/1\">Kalika Bali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitaram_S/0/1/0/all/0/1\">Sunayana Sitaram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inspecting and Editing Knowledge Representations in Language Models. (arXiv:2304.00740v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.00740","description":"<p>Neural language models (LMs) represent facts about the world described by\ntext. Sometimes these facts derive from training data (in most LMs, a\nrepresentation of the word \"banana\" encodes the fact that bananas are fruits).\nSometimes facts derive from input text itself (a representation of the sentence\n\"I poured out the bottle\" encodes the fact that the bottle became empty). We\ndescribe REMEDI, a method for learning to map statements in natural language to\nfact encodings in an LM's internal representation system. REMEDI encodings can\nbe used as knowledge editors: when added to LM hidden representations, they\nmodify downstream generation to be consistent with new facts. REMEDI encodings\nmay also be used as probes: when compared to LM representations, they reveal\nwhich properties LMs already attribute to mentioned entities, in some cases\nmaking it possible to predict when LMs will generate outputs that conflict with\nbackground knowledge or input text. REMEDI thus links work on probing,\nprompting, and LM editing, and offers steps toward general tools for\nfine-grained inspection and control of knowledge in LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_E/0/1/0/all/0/1\">Evan Hernandez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Belinda Z. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why think step by step? Reasoning emerges from the locality of experience. (arXiv:2304.03843v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.03843","description":"<p>Humans have a powerful and mysterious capacity to reason. By working through\na series of purely mental steps, we can make inferences we would not be capable\nof making directly -- despite the fact that we get no additional data from the\nworld. Similarly, when large language models generate a series of intermediate\nsteps (a chain of thought) before answering a question, they often produce\nbetter answers than they otherwise would. We investigate why and how\nchain-of-thought reasoning is useful in language models, testing the hypothesis\nthat reasoning is effective when training data consists of local clusters of\nvariables that influence each other strongly. These training conditions enable\nthe chaining of accurate local inferences in order to estimate relationships\nbetween variables that were not seen together in training. We prove that there\nwill exist a \"reasoning gap\", where reasoning through intermediate variables\nimproves inference, for the simple case of an autoregressive density estimator\ntrained on local samples from a chain-structured probabilistic model. We then\ntest our hypothesis empirically in more complex models, training an\nautoregressive language model on samples from Bayes nets but only including a\nsubset of variables in each sample. We test language models' ability to match\nconditional probabilities with and without intermediate reasoning steps,\nfinding that intermediate steps are only helpful when the training data is\nlocally structured with respect to dependencies between variables and that the\ncombination of locally-structured observations and reasoning is much more\ndata-efficient than training on all variables. Our results illustrate how the\neffectiveness of reasoning step by step is rooted in the local statistical\nstructure of the training data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Prystawski_B/0/1/0/all/0/1\">Ben Prystawski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Y. Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1\">Noah D. Goodman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RRHF: Rank Responses to Align Language Models with Human Feedback without tears. (arXiv:2304.05302v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.05302","description":"<p>Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment\nof large language models with human preferences, significantly enhancing the\nquality of interactions between humans and these models. InstructGPT implements\nRLHF through several stages, including Supervised Fine-Tuning (SFT), reward\nmodel training, and Proximal Policy Optimization (PPO). PPO, however, is\nsensitive to hyperparameters and requires a minimum of four models in its\nstandard implementation, which makes it hard to train. In contrast, we propose\na novel learning paradigm called RRHF, which scores responses generated by\ndifferent sampling policies and learns to align them with human preferences\nthrough ranking loss. RRHF can efficiently align language model output\nprobabilities with human preferences as robust as fine-tuning and it only needs\n1 to 2 models during tuning. In addition, RRHF can be considered an extension\nof SFT and reward models while being simpler than PPO in terms of coding, model\ncounts, and hyperparameters. The entire alignment process can be accomplished\nwithin a single RRHF training session. We evaluate RRHF using LLaMA and Alpaca\non Helpful and Harmless data, demonstrating performance comparable to PPO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongyi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LaMP: When Large Language Models Meet Personalization. (arXiv:2304.11406v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11406","description":"<p>This paper highlights the importance of personalization in the current state\nof natural language understanding and generation and introduces the LaMP\nbenchmark -- a novel benchmark for training and evaluating language models for\nproducing personalized outputs. LaMP offers a comprehensive evaluation\nframework with diverse language tasks and multiple entries for each user\nprofile. It consists of seven personalized tasks, spanning three classification\nand four text generation tasks. We also propose a retrieval augmentation\napproach that retrieves personalized items from user profiles to construct\npersonalized prompts for large language models. Our baseline zero-shot and\nfine-tuned model results indicate that LMs utilizing profile augmentation\noutperform their counterparts that do not factor in profile information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salemi_A/0/1/0/all/0/1\">Alireza Salemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1\">Sheshera Mysore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PMC-LLaMA: Further Finetuning LLaMA on Medical Papers. (arXiv:2304.14454v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.14454","description":"<p>Large Language Models (LLMs) have showcased remarkable capabilities in\nnatural language understanding in various domains. These models can usually\nbehave well on daily dialog, or question answering scenarios, however, in areas\nthat value precision, for example, in medical applications, they often exhibit\nunsatisfactory performance due to a lack of domain-specific knowledge. In this\nreport, we introduce PMC-LLaMA, an open-source language model that is acquired\nby fine-tuning an open-source language model on a total of 4.8 million\nbiomedical academic papers for further injecting medical knowledge, enhancing\nits capability in medical domain. Our preliminary evaluations are conducted on\nthree biomedical QA datasets, including PubMedQA, MedMCQA, and USMLE, showing\nthat the our model after finetuning, i.e., PMC-LLaMA, demonstrates better\nunderstanding of biomedical domain-specific concepts, thus achieving high\nperformance on QA benchmarks. The model and codes, along with an online demo,\nare publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chaoyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoman Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weidi Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Search-in-the-Chain: Towards Accurate, Credible and Traceable Large Language Models for Knowledge-intensive Tasks. (arXiv:2304.14732v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.14732","description":"<p>Making the contents generated by Large Language Model (LLM) such as ChatGPT,\naccurate, credible and traceable is crucial, especially in complex\nknowledge-intensive tasks that require multi-step reasoning and each of which\nneeds knowledge to solve. Introducing Information Retrieval (IR) to provide LLM\nwith external knowledge is good potential to solve this problem. However, where\nand how to introduce IR into LLM is a big challenge. Previous work has the\ndisadvantage that the wrong knowledge retrieved by IR misleads the LLM or\nbreaks the reasoning chain of LLM. In this paper, we propose a novel framework\ncalled Search-in-the-Chain (SearChain) for the interaction between LLM and IR\nto solve the challenges. First, LLM generates the global reasoning chain called\nChain-of-Query (CoQ) where each node consists of an IR-oriented query and the\nanswer to the query. Second, IR verifies the answer of each node of CoQ, it\ncorrects the answer that is not consistent with the retrieved information when\nIR gives high confidence, which improves the credibility. Third, LLM can mark\nits missing knowledge in CoQ and IR can provide this knowledge to LLM. These\nthree operations improve the accuracy of LLM for complex knowledge-intensive\ntasks in terms of reasoning ability and knowledge. Finally, SearChain generates\nthe reasoning process and marks references to supporting documents for each\nreasoning step, which improves traceability. SearChain transforms the topology\nof reasoning from chain to tree, which can modify the reasoning direction.\nExperiment shows that SearChain outperforms baselines on complex\nknowledge-intensive tasks including multi-hop question-answering, slot filling,\nfact checking, and long-form question-answering.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shicheng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCOTT: Self-Consistent Chain-of-Thought Distillation. (arXiv:2305.01879v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01879","description":"<p>Large language models (LMs) beyond a certain scale, demonstrate the emergent\ncapability of generating free-text rationales for their predictions via\nchain-of-thought (CoT) prompting. While CoT can yield dramatically improved\nperformance, such gains are only observed for sufficiently large LMs. Even more\nconcerning, there is little guarantee that the generated rationales are\nconsistent with LM's predictions or faithfully justify the decisions. In this\nwork, we propose a faithful knowledge distillation method to learn a small,\nself-consistent CoT model from a teacher model that is orders of magnitude\nlarger. To form better supervision, we elicit rationales supporting the gold\nanswers from a large LM (teacher) by contrastive decoding, which encourages the\nteacher to generate tokens that become more plausible only when the answer is\nconsidered. To ensure faithful distillation, we use the teacher-generated\nrationales to learn a student LM with a counterfactual reasoning objective,\nwhich prevents the student from ignoring the rationales to make inconsistent\npredictions. Experiments show that, while yielding comparable end-task\nperformance, our method can generate CoT rationales that are more faithful than\nbaselines do. Further analysis suggests that such a model respects the\nrationales more when making decisions; thus, we can improve its performance\nmore by refining its rationales.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yifan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_B/0/1/0/all/0/1\">Bing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Contrastive Learning of Sentence Embeddings from AI Feedback. (arXiv:2305.01918v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01918","description":"<p>Contrastive learning has become a popular approach in natural language\nprocessing, particularly for the learning of sentence embeddings. However, the\ndiscrete nature of natural language makes it difficult to ensure the quality of\npositive and negative sample pairs generated through data augmentation methods.\nAlthough supervised contrastive learning can produce more accurate sample pairs\nwith human feedback labels, it still lacks fine-grained training signals. In\nthis paper, we propose to improve \\textbf{C}ontrastive \\textbf{L}earning of\nsentence embeddings from \\textbf{AI} \\textbf{F}eedback \\textbf{(CLAIF)}. Our\nmethod utilizes AI feedback from large pre-trained language models (LLMs) to\nconstruct sample pairs with fine-grained sample similarity scores to improve\ncontrastive learning. Besides, we combine human feedback and AI feedback to\nprovide better supervision signals for supervised contrastive learning of\nsentence embeddings. Experimental results show that our method achieves\nstate-of-the-art performance on several semantic textual similarity (STS) and\ntransfer learning tasks compared to other unsupervised and supervised\ncontrastive learning methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qinyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaogui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System. (arXiv:2305.02468v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02468","description":"<p>Task-Oriented Dialogue (TOD) systems are designed to carry out specific tasks\nby tracking dialogue states and generating appropriate responses to help users\nachieve defined goals. Recently, end-to-end dialogue models pre-trained based\non large datasets have shown promising performance in the conversational\nsystem. However, they share the same parameters to train tasks of the dialogue\nsystem (NLU, DST, NLG), so debugging each task is challenging. Also, they\nrequire a lot of effort to fine-tune large parameters to create a task-oriented\nchatbot, making it difficult for non-experts to handle. Therefore, we intend to\ntrain relatively lightweight and fast models compared to PLM. In this paper, we\npropose an End-to-end TOD system with Task-Optimized Adapters which learn\nindependently per task, adding only small number of parameters after fixed\nlayers of pre-trained network. We also enhance the performance of the DST and\nNLG modules through reinforcement learning, overcoming the learning curve that\nhas lacked at the adapter learning and enabling the natural and consistent\nresponse generation that is appropriate for the goal. Our method is a\nmodel-agnostic approach and does not require prompt-tuning as only input data\nwithout a prompt. As results of the experiment, our method shows competitive\nperformance on the MultiWOZ benchmark compared to the existing end-to-end\nmodels. In particular, we attain state-of-the-art performance on the DST task\nof 2.2 dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bang_N/0/1/0/all/0/1\">Namo Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jeehyun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koo_M/0/1/0/all/0/1\">Myoung-Wan Koo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations. (arXiv:2305.03117v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03117","description":"<p>Human-annotated labels and explanations are critical for training explainable\nNLP models. However, unlike human-annotated labels whose quality is easier to\ncalibrate (e.g., with a majority vote), human-crafted free-form explanations\ncan be quite subjective. Before blindly using them as ground truth to train ML\nmodels, a vital question needs to be asked: How do we evaluate a\nhuman-annotated explanation's quality? In this paper, we build on the view that\nthe quality of a human-annotated explanation can be measured based on its\nhelpfulness (or impairment) to the ML models' performance for the desired NLP\ntasks for which the annotations were collected. In comparison to the commonly\nused Simulatability score, we define a new metric that can take into\nconsideration the helpfulness of an explanation for model performance at both\nfine-tuning and inference. With the help of a unified dataset format, we\nevaluated the proposed metric on five datasets (e.g., e-SNLI) against two model\narchitectures (T5 and BART), and the results show that our proposed metric can\nobjectively evaluate the quality of human-annotated explanations, while\nSimulatability falls short.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1\">Bingsheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sen_P/0/1/0/all/0/1\">Prithviraj Sen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1\">Lucian Popa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendler_J/0/1/0/all/0/1\">James Hendler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dakuo Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sensitive Data Detection with High-Throughput Machine Learning Models in Electrical Health Records. (arXiv:2305.03169v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2305.03169","description":"<p>In the era of big data, there is an increasing need for healthcare providers,\ncommunities, and researchers to share data and collaborate to improve health\noutcomes, generate valuable insights, and advance research. The Health\nInsurance Portability and Accountability Act of 1996 (HIPAA) is a federal law\ndesigned to protect sensitive health information by defining regulations for\nprotected health information (PHI). However, it does not provide efficient\ntools for detecting or removing PHI before data sharing. One of the challenges\nin this area of research is the heterogeneous nature of PHI fields in data\nacross different parties. This variability makes rule-based sensitive variable\nidentification systems that work on one database fail on another. To address\nthis issue, our paper explores the use of machine learning algorithms to\nidentify sensitive variables in structured data, thus facilitating the\nde-identification process. We made a key observation that the distributions of\nmetadata of PHI fields and non-PHI fields are very different. Based on this\nnovel finding, we engineered over 30 features from the metadata of the original\nfeatures and used machine learning to build classification models to\nautomatically identify PHI fields in structured Electronic Health Record (EHR)\ndata. We trained the model on a variety of large EHR databases from different\ndata sources and found that our algorithm achieves 99% accuracy when detecting\nPHI-related fields for unseen datasets. The implications of our study are\nsignificant and can benefit industries that handle sensitive data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaoqian Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04091","description":"<p>Large language models (LLMs) have recently been shown to deliver impressive\nperformance in various NLP tasks. To tackle multi-step reasoning tasks,\nfew-shot chain-of-thought (CoT) prompting includes a few manually crafted\nstep-by-step reasoning demonstrations which enable LLMs to explicitly generate\nreasoning steps and improve their reasoning task accuracy. To eliminate the\nmanual effort, Zero-shot-CoT concatenates the target problem statement with\n\"Let's think step by step\" as an input prompt to LLMs. Despite the success of\nZero-shot-CoT, it still suffers from three pitfalls: calculation errors,\nmissing-step errors, and semantic misunderstanding errors. To address the\nmissing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of\ntwo components: first, devising a plan to divide the entire task into smaller\nsubtasks, and then carrying out the subtasks according to the plan. To address\nthe calculation errors and improve the quality of generated reasoning steps, we\nextend PS prompting with more detailed instructions and derive PS+ prompting.\nWe evaluate our proposed prompting strategy on ten datasets across three\nreasoning problems. The experimental results over GPT-3 show that our proposed\nzero-shot prompting consistently outperforms Zero-shot-CoT across all datasets\nby a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought\nPrompting, and has comparable performance with 8-shot CoT prompting on the math\nreasoning problem. The code can be found at\nhttps://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wanyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yihuai Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiqiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yunshi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Roy Ka-Wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Ee-Peng Lim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04160","description":"<p>Large language models (LLMs) have demonstrated remarkable language abilities.\nGPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities\nbeyond previous visual language models. We attribute this to the use of more\nadvanced LLMs compared with previous multimodal models. Unfortunately, the\nmodel architecture and training strategies of GPT-4 are unknown. To endow LLMs\nwith multimodal capabilities, we propose X-LLM, which converts Multi-modalities\n(images, speech, videos) into foreign languages using X2L interfaces and inputs\nthem into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple\nfrozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X''\ndenotes multi-modalities such as image, speech, and videos, and ``L'' denotes\nlanguages. X-LLM's training consists of three stages: (1) Converting Multimodal\nInformation: The first stage trains each X2L interface to align with its\nrespective single-modal encoder separately to convert multimodal information\ninto languages. (2) Aligning X2L representations with the LLM: single-modal\nencoders are aligned with the LLM through X2L interfaces independently. (3)\nIntegrating multiple modalities: all single-modal encoders are aligned with the\nLLM through X2L interfaces to integrate multimodal capabilities into the LLM.\nOur experiments show that X-LLM demonstrates impressive multimodel chat\nabilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen\nimages/instructions, and yields a 84.5\\% relative score compared with GPT-4 on\na synthetic multimodal instruction-following dataset. And we also conduct\nquantitative tests on using LLM for ASR and multimodal ASR, hoping to promote\nthe era of LLM-based speech recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feilong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1\">Minglun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bo Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MGR: Multi-generator based Rationalization. (arXiv:2305.04492v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.04492","description":"<p>Rationalization is to employ a generator and a predictor to construct a\nself-explaining NLP model in which the generator selects a subset of\nhuman-intelligible pieces of the input text to the following predictor.\nHowever, rationalization suffers from two key challenges, i.e., spurious\ncorrelation and degeneration, where the predictor overfits the spurious or\nmeaningless pieces solely selected by the not-yet well-trained generator and in\nturn deteriorates the generator. Although many studies have been proposed to\naddress the two challenges, they are usually designed separately and do not\ntake both of them into account. In this paper, we propose a simple yet\neffective method named MGR to simultaneously solve the two problems. The key\nidea of MGR is to employ multiple generators such that the occurrence stability\nof real pieces is improved and more meaningful pieces are delivered to the\npredictor. Empirically, we show that MGR improves the F1 score by up to 20.9%\nas compared to state-of-the-art methods. Codes are available at\nhttps://github.com/jugechengzi/Rationalization-MGR .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xinyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuankai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yang Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distilling Script Knowledge from Large Language Models for Constrained Language Planning. (arXiv:2305.05252v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.05252","description":"<p>In everyday life, humans often plan their actions by following step-by-step\ninstructions in the form of goal-oriented scripts. Previous work has exploited\nlanguage models (LMs) to plan for abstract goals of stereotypical activities\n(e.g., \"make a cake\"), but leaves more specific goals with multi-facet\nconstraints understudied (e.g., \"make a cake for diabetics\"). In this paper, we\ndefine the task of constrained language planning for the first time. We propose\nan overgenerate-then-filter approach to improve large language models (LLMs) on\nthis task, and use it to distill a novel constrained language planning dataset,\nCoScript, which consists of 55,000 scripts. Empirical results demonstrate that\nour method significantly improves the constrained language planning ability of\nLLMs, especially on constraint faithfulness. Furthermore, CoScript is\ndemonstrated to be quite effective in endowing smaller LMs with constrained\nlanguage planning ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Siyu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiangjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Ziquan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_X/0/1/0/all/0/1\">Xuyang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Soham Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jankowski_C/0/1/0/all/0/1\">Charles Robert Jankowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Deqing Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Framework for Designing Foundation Model based Systems. (arXiv:2305.05352v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.05352","description":"<p>The recent release of large language model (LLM) based chatbots, such as\nChatGPT, has attracted significant attention on foundation models. It is widely\nbelieved that foundation models will serve as the fundamental building blocks\nfor future AI systems. As foundation models are in their early stages, the\ndesign of foundation model based systems has not yet been systematically\nexplored. There is little understanding about the impact of introducing\nfoundation models in software architecture. Therefore, in this paper, we\npropose a taxonomy of foundation model based systems, which classifies and\ncompares the characteristics of foundation models and design options of\nfoundation model based systems. Our taxonomy comprises three categories:\nfoundation model pretraining and fine-tuning, architecture design of foundation\nmodel based systems, and responsible-AI-by-design. This taxonomy provides\nconcrete guidance for making major design decisions when designing foundation\nmodel based systems and highlights trade-offs arising from design decisions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qinghua Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Liming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whittle_J/0/1/0/all/0/1\">Jon Whittle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Refinement via Interaction Between Search Engines and Large Language Models. (arXiv:2305.07402v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07402","description":"<p>Information retrieval (IR) plays a crucial role in locating relevant\nresources from vast amounts of data, and its applications have evolved from\ntraditional knowledge bases to modern search engines (SEs). The emergence of\nlarge language models (LLMs) has further revolutionized the IR field by\nenabling users to interact with search systems in natural language. In this\npaper, we explore the advantages and disadvantages of LLMs and SEs,\nhighlighting their respective strengths in understanding user-issued queries\nand retrieving up-to-date information. To leverage the benefits of both\nparadigms while circumventing their limitations, we propose InteR, a novel\nframework that facilitates knowledge refinement through interaction between SEs\nand LLMs. InteR allows SEs to expand knowledge in queries using LLM-generated\nknowledge collections and enables LLMs to enhance prompt formulation using\nSE-retrieved documents. This iterative refinement process augments the inputs\nof SEs and LLMs, leading to more accurate retrieval. Experiments on large-scale\nretrieval benchmarks involving web search and low-resource retrieval tasks\ndemonstrate that InteR achieves overall superior zero-shot retrieval\nperformance compared to state-of-the-art methods, even those using relevance\njudgment. Source code is available at https://github.com/Cyril-JZ/InteR\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1\">Jiazhan Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Chongyang Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1\">Xiubo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_T/0/1/0/all/0/1\">Tao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Can Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1\">Guodong Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CodeT5+: Open Code Large Language Models for Code Understanding and Generation. (arXiv:2305.07922v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07922","description":"<p>Large language models (LLMs) pretrained on vast source code have achieved\nprominent progress in code intelligence. However, existing code LLMs have two\nmain limitations in terms of architecture and pretraining tasks. First, they\noften adopt a specific architecture (encoder-only or decoder-only) or rely on a\nunified encoder-decoder network for different downstream tasks. The former\nparadigm is limited by inflexibility in applications while in the latter, the\nmodel is treated as a single system for all tasks, leading to suboptimal\nperformance on a subset of tasks. Secondly, they often employ a limited set of\npretraining objectives which might not be relevant to some downstream tasks and\nhence result in substantial performance degrade. To address these limitations,\nwe propose ``CodeT5+'', a family of encoder-decoder LLMs for code in which\ncomponent modules can be flexibly combined to suit a wide range of downstream\ncode tasks. Such flexibility is enabled by our proposed mixture of pretraining\nobjectives to mitigate the pretrain-finetune discrepancy. These objectives\ncover span denoising, contrastive learning, text-code matching, and causal LM\npretraining tasks, on both unimodal and bimodal multilingual code corpora.\nFurthermore, we propose to initialize CodeT5+ with frozen off-the-shelf LLMs\nwithout training from scratch to efficiently scale up our models, and explore\ninstruction-tuning to align with natural language instructions. We extensively\nevaluate CodeT5+ on over 20 code-related benchmarks in different settings,\nincluding zero-shot, finetuning, and instruction-tuning. We observe\nstate-of-the-art (SoTA) model performance on various code-related tasks, such\nas code generation and completion, math programming, and text-to-code retrieval\ntasks. Particularly, our instruction-tuned CodeT5+ 16B achieves new SoTA\nresults on HumanEval code generation task against other open code LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1\">Hung Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gotmare_A/0/1/0/all/0/1\">Akhilesh Deepak Gotmare</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_N/0/1/0/all/0/1\">Nghi D.Q. Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junnan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoi_S/0/1/0/all/0/1\">Steven C.H. Hoi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distinguish Before Answer: Generating Contrastive Explanation as Knowledge for Commonsense Question Answering. (arXiv:2305.08135v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08135","description":"<p>Existing knowledge-enhanced methods have achieved remarkable results in\ncertain QA tasks via obtaining diverse knowledge from different knowledge\nbases. However, limited by the properties of retrieved knowledge, they still\nhave trouble benefiting from both the knowledge relevance and distinguishment\nsimultaneously. To address the challenge, we propose CPACE, a Concept-centric\nPrompt-bAsed Contrastive Explanation Generation model, which aims to convert\nobtained symbolic knowledge into a contrastive explanation for better\ndistinguishing the differences among given candidates. Firstly, following\nprevious works, we retrieve different types of symbolic knowledge with a\nconcept-centric knowledge extraction module. After that, we generate\ncorresponding contrastive explanations using acquired symbolic knowledge and\nexplanation prompts as guidance for better modeling the knowledge\ndistinguishment and interpretability. Finally, we regard the generated\ncontrastive explanation as external knowledge for downstream task enhancement.\nWe conduct a series of experiments on three widely-used question-answering\ndatasets: CSQA, QASC, and OBQA. Experimental results demonstrate that with the\nhelp of generated contrastive explanation, our CPACE model achieves new SOTA on\nCSQA (89.8% on the testing set, 0.9% higher than human performance), and gains\nimpressive improvement on QASC and OBQA (4.2% and 3.5%, respectively).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qianglong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guohai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Ji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coreference-aware Double-channel Attention Network for Multi-party Dialogue Reading Comprehension. (arXiv:2305.08348v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08348","description":"<p>We tackle Multi-party Dialogue Reading Comprehension (abbr., MDRC). MDRC\nstands for an extractive reading comprehension task grounded on a batch of\ndialogues among multiple interlocutors. It is challenging due to the\nrequirement of understanding cross-utterance contexts and relationships in a\nmulti-turn multi-party conversation. Previous studies have made great efforts\non the utterance profiling of a single interlocutor and graph-based interaction\nmodeling. The corresponding solutions contribute to the answer-oriented\nreasoning on a series of well-organized and thread-aware conversational\ncontexts. However, the current MDRC models still suffer from two bottlenecks.\nOn the one hand, a pronoun like \"it\" most probably produces multi-skip\nreasoning throughout the utterances of different interlocutors. On the other\nhand, an MDRC encoder is potentially puzzled by fuzzy features, i.e., the\nmixture of inner linguistic features in utterances and external interactive\nfeatures among utterances. To overcome the bottlenecks, we propose a\ncoreference-aware attention modeling method to strengthen the reasoning\nability. In addition, we construct a two-channel encoding network. It\nseparately encodes utterance profiles and interactive relationships, so as to\nrelieve the confusion among heterogeneous features. We experiment on the\nbenchmark corpora Molweni and FriendsQA. Experimental results demonstrate that\nour approach yields substantial improvements on both corpora, compared to the\nfine-tuned BERT and ELECTRA baselines. The maximum performance gain is about\n2.5\\% F1-score. Besides, our MDRC models outperform the state-of-the-art in\nmost cases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanling Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_B/0/1/0/all/0/1\">Bowei Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yifan Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1\">Mengxing Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yu Hong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Classification via Large Language Models. (arXiv:2305.08377v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08377","description":"<p>Despite the remarkable success of large-scale Language Models (LLMs) such as\nGPT-3, their performances still significantly underperform fine-tuned models in\nthe task of text classification. This is due to (1) the lack of reasoning\nability in addressing complex linguistic phenomena (e.g., intensification,\ncontrast, irony etc); (2) limited number of tokens allowed in in-context\nlearning.\n</p>\n<p>In this paper, we introduce Clue And Reasoning Prompting (CARP). CARP adopts\na progressive reasoning strategy tailored to addressing the complex linguistic\nphenomena involved in text classification: CARP first prompts LLMs to find\nsuperficial clues (e.g., keywords, tones, semantic relations, references, etc),\nbased on which a diagnostic reasoning process is induced for final decisions.\nTo further address the limited-token issue, CARP uses a fine-tuned model on the\nsupervised dataset for $k$NN demonstration search in the in-context learning,\nallowing the model to take the advantage of both LLM's generalization ability\nand the task-specific evidence provided by the full labeled dataset.\nRemarkably, CARP yields new SOTA performances on 4 out of 5 widely-used\ntext-classification benchmarks, 97.39 (+1.24) on SST-2, 96.40 (+0.72) on\nAGNews, 98.78 (+0.25) on R8 and 96.95 (+0.6) on R52, and a performance\ncomparable to SOTA on MR (92.39 v.s. 93.3). More importantly, we find that CARP\ndelivers impressive abilities on low-resource and domain-adaptation setups.\nSpecifically, using 16 examples per class, CARP achieves comparable\nperformances to supervised models with 1,024 examples per class.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xiaofei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shangwei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Speech Dialogue Translation Mediating Speakers of Different Languages. (arXiv:2305.09210v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09210","description":"<p>We present a new task, speech dialogue translation mediating speakers of\ndifferent languages. We construct the SpeechBSD dataset for the task and\nconduct baseline experiments. Furthermore, we consider context to be an\nimportant aspect that needs to be addressed in this task and propose two ways\nof utilizing context, namely monolingual context and bilingual context. We\nconduct cascaded speech translation experiments using Whisper and mBART, and\nshow that bilingual context performs better in our settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1\">Shuichiro Shimizu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1\">Chenhui Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MemoryBank: Enhancing Large Language Models with Long-Term Memory. (arXiv:2305.10250v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10250","description":"<p>Revolutionary advancements in Large Language Models have drastically reshaped\nour interactions with artificial intelligence systems. Despite this, a notable\nhindrance remains-the deficiency of a long-term memory mechanism within these\nmodels. This shortfall becomes increasingly evident in situations demanding\nsustained interaction, such as personal companion systems and psychological\ncounseling. Therefore, we propose MemoryBank, a novel memory mechanism tailored\nfor LLMs. MemoryBank enables the models to summon relevant memories,\ncontinually evolve through continuous memory updates, comprehend, and adapt to\na user personality by synthesizing information from past interactions. To mimic\nanthropomorphic behaviors and selectively preserve memory, MemoryBank\nincorporates a memory updating mechanism, inspired by the Ebbinghaus Forgetting\nCurve theory, which permits the AI to forget and reinforce memory based on time\nelapsed and the relative significance of the memory, thereby offering a\nhuman-like memory mechanism. MemoryBank is versatile in accommodating both\nclosed-source models like ChatGPT and open-source models like ChatGLM. We\nexemplify application of MemoryBank through the creation of an LLM-based\nchatbot named SiliconFriend in a long-term AI Companion scenario. Further tuned\nwith psychological dialogs, SiliconFriend displays heightened empathy in its\ninteractions. Experiment involves both qualitative analysis with real-world\nuser dialogs and quantitative analysis with simulated dialogs. In the latter,\nChatGPT acts as users with diverse characteristics and generates long-term\ndialog contexts covering a wide array of topics. The results of our analysis\nreveal that SiliconFriend, equipped with MemoryBank, exhibits a strong\ncapability for long-term companionship as it can provide emphatic response,\nrecall relevant memories and understand user personality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Lianghong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1\">Qiqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">He Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"M3KE: A Massive Multi-Level Multi-Subject Knowledge Evaluation Benchmark for Chinese Large Language Models. (arXiv:2305.10263v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10263","description":"<p>Large language models have recently made tremendous progress in a variety of\naspects, e.g., cross-task generalization, instruction following.\nComprehensively evaluating the capability of large language models in multiple\ntasks is of great importance. In this paper, we propose M3KE, a Massive\nMulti-Level Multi-Subject Knowledge Evaluation benchmark, which is developed to\nmeasure knowledge acquired by Chinese large language models by testing their\nmultitask accuracy in zero- and few-shot settings. We have collected 20,477\nquestions from 71 tasks. Our selection covers all major levels of Chinese\neducation system, ranging from the primary school to college, as well as a wide\nvariety of subjects, including humanities, history, politics, law, education,\npsychology, science, technology, art and religion. All questions are\nmultiple-choice questions with four options, hence guaranteeing a standardized\nand unified assessment process. We've assessed a number of state-of-the-art\nopen-source Chinese large language models on the proposed benchmark. The size\nof these models varies from 335M to 130B parameters. Experiment results\ndemonstrate that they perform significantly worse than GPT-3.5 that reaches an\naccuracy of ~ 48% on M3KE. The dataset is available at\nhttps://github.com/tjunlp-lab/M3KE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1\">Renren Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yuqi Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Linhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1\">Tianyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiaohan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuting Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1\">Jianxiang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peiyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1\">Qingqing Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_X/0/1/0/all/0/1\">Xiaowen Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_D/0/1/0/all/0/1\">Deyi Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective. (arXiv:2305.10306v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10306","description":"<p>We propose a new paradigm for universal information extraction (IE) that is\ncompatible with any schema format and applicable to a list of IE tasks, such as\nnamed entity recognition, relation extraction, event extraction and sentiment\nanalysis. Our approach converts the text-based IE tasks as the token-pair\nproblem, which uniformly disassembles all extraction targets into joint span\ndetection, classification and association problems with a unified extractive\nframework, namely UniEX. UniEX can synchronously encode schema-based prompt and\ntextual information, and collaboratively learn the generalized knowledge from\npre-defined information using the auto-encoder language models. We develop a\ntraffine attention mechanism to integrate heterogeneous factors including\ntasks, labels and inside tokens, and obtain the extraction target via a scoring\nmatrix. Experiment results show that UniEX can outperform generative universal\nIE models in terms of performance and inference-speed on $14$ benchmarks IE\ndatasets with the supervised setting. The state-of-the-art performance in\nlow-resource scenarios also verifies the transferability and effectiveness of\nUniEX.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1\">Ping Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Junyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_R/0/1/0/all/0/1\">Ruyi Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiaxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pingjian Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What You See is What You Read? Improving Text-Image Alignment Evaluation. (arXiv:2305.10400v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10400","description":"<p>Automatically determining whether a text and a corresponding image are\nsemantically aligned is a significant challenge for vision-language models,\nwith applications in generative text-to-image and image-to-text tasks. In this\nwork, we study methods for automatic text-image alignment evaluation. We first\nintroduce SeeTRUE: a comprehensive evaluation set, spanning multiple datasets\nfrom both text-to-image and image-to-text generation tasks, with human\njudgements for whether a given text-image pair is semantically aligned. We then\ndescribe two automatic methods to determine alignment: the first involving a\npipeline based on question generation and visual question answering models, and\nthe second employing an end-to-end classification approach by finetuning\nmultimodal pretrained models. Both methods surpass prior approaches in various\ntext-image alignment tasks, with significant improvements in challenging cases\nthat involve complex composition or unnatural images. Finally, we demonstrate\nhow our approaches can localize specific misalignments between an image and a\ngiven text, and how they can be used to automatically re-rank candidates in\ntext-to-image generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yarom_M/0/1/0/all/0/1\">Michal Yarom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Changpinyo_S/0/1/0/all/0/1\">Soravit Changpinyo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lang_O/0/1/0/all/0/1\">Oran Lang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ofek_E/0/1/0/all/0/1\">Eran Ofek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Pre-trained Transformer: A Comprehensive Review on Enabling Technologies, Potential Applications, Emerging Challenges, and Future Directions. (arXiv:2305.10435v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10435","description":"<p>The Generative Pre-trained Transformer (GPT) represents a notable\nbreakthrough in the domain of natural language processing, which is propelling\nus toward the development of machines that can understand and communicate using\nlanguage in a manner that closely resembles that of humans. GPT is based on the\ntransformer architecture, a deep neural network designed for natural language\nprocessing tasks. Due to their impressive performance on natural language\nprocessing tasks and ability to effectively converse, GPT have gained\nsignificant popularity among researchers and industrial communities, making\nthem one of the most widely used and effective models in natural language\nprocessing and related fields, which motivated to conduct this review. This\nreview provides a detailed overview of the GPT, including its architecture,\nworking process, training procedures, enabling technologies, and its impact on\nvarious applications. In this review, we also explored the potential challenges\nand limitations of a GPT. Furthermore, we discuss potential solutions and\nfuture directions. Overall, this paper aims to provide a comprehensive\nunderstanding of GPT, enabling technologies, their impact on various\napplications, emerging challenges, and potential solutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yenduri_G/0/1/0/all/0/1\">Gokul Yenduri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+M_R/0/1/0/all/0/1\">Ramalingam M</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_C/0/1/0/all/0/1\">Chemmalar Selvi G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Y_S/0/1/0/all/0/1\">Supriya Y</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_G/0/1/0/all/0/1\">Gautam Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddikunta_P/0/1/0/all/0/1\">Praveen Kumar Reddy Maddikunta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+G_D/0/1/0/all/0/1\">Deepti Raj G</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jhaveri_R/0/1/0/all/0/1\">Rutvij H Jhaveri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+B_P/0/1/0/all/0/1\">Prabadevi B</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weizheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasilakos_A/0/1/0/all/0/1\">Athanasios V. Vasilakos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadekallu_T/0/1/0/all/0/1\">Thippa Reddy Gadekallu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Paxion: Patching Action Knowledge in Video-Language Foundation Models. (arXiv:2305.10683v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.10683","description":"<p>Action knowledge involves the understanding of textual, visual, and temporal\naspects of actions. We introduce the Action Dynamics Benchmark (ActionBench)\ncontaining two carefully designed probing tasks: Action Antonym and Video\nReversal, which targets multimodal alignment capabilities and temporal\nunderstanding skills of the model, respectively. Despite recent video-language\nmodels' (VidLM) impressive performance on various benchmark tasks, our\ndiagnostic tasks reveal their surprising deficiency (near-random performance)\nin action knowledge, suggesting that current models rely on object recognition\nabilities as a shortcut for action understanding. To remedy this, we propose a\nnovel framework, Paxion, along with a new Discriminative Video Dynamics\nModeling (DVDM) objective. The Paxion framework utilizes a Knowledge Patcher\nnetwork to encode new action knowledge and a Knowledge Fuser component to\nintegrate the Patcher into frozen VidLMs without compromising their existing\ncapabilities. Due to limitations of the widely-used Video-Text Contrastive\n(VTC) loss for learning action knowledge, we introduce the DVDM objective to\ntrain the Knowledge Patcher. DVDM forces the model to encode the correlation\nbetween the action text and the correct ordering of video frames. Our extensive\nanalyses show that Paxion and DVDM together effectively fill the gap in action\nknowledge understanding (~50% to 80%), while maintaining or improving\nperformance on a wide spectrum of both object- and action-centric downstream\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenhailong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blume_A/0/1/0/all/0/1\">Ansel Blume</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Genglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Jaemin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zineng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Learning Methods for Extracting Metaphorical Names of Flowers and Plants. (arXiv:2305.10833v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10833","description":"<p>The domain of Botany is rich with metaphorical terms. Those terms play an\nimportant role in the description and identification of flowers and plants.\nHowever, the identification of such terms in discourse is an arduous task. This\nleads in some cases to committing errors during translation processes and\nlexicographic tasks. The process is even more challenging when it comes to\nmachine translation, both in the cases of single-word terms and multi-word\nterms. One of the recent concerns of Natural Language Processing (NLP)\napplications and Machine Translation (MT) technologies is the automatic\nidentification of metaphor-based words in discourse through Deep Learning (DL).\nIn this study, we seek to fill this gap through the use of thirteen popular\ntransformer based models, as well as ChatGPT, and we show that discriminative\nmodels perform better than GPT-3.5 model with our best performer reporting\n92.2349% F1 score in metaphoric flower and plant names identification task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Haddad_A/0/1/0/all/0/1\">Amal Haddad Haddad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Premasiri_D/0/1/0/all/0/1\">Damith Premasiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranasinghe_T/0/1/0/all/0/1\">Tharindu Ranasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitkov_R/0/1/0/all/0/1\">Ruslan Mitkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-modality Data Augmentation for End-to-End Sign Language Translation. (arXiv:2305.11096v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11096","description":"<p>End-to-end sign language translation (SLT) aims to convert sign language\nvideos into spoken language texts directly without intermediate\nrepresentations. It has been a challenging task due to the modality gap between\nsign videos and texts and the data scarcity of labeled data. To tackle these\nchallenges, we propose a novel Cross-modality Data Augmentation (XmDA)\nframework to transfer the powerful gloss-to-text translation capabilities to\nend-to-end sign language translation (i.e. video-to-text) by exploiting pseudo\ngloss-text pairs from the sign gloss translation model. Specifically, XmDA\nconsists of two key components, namely, cross-modality mix-up and\ncross-modality knowledge distillation. The former explicitly encourages the\nalignment between sign video features and gloss embeddings to bridge the\nmodality gap. The latter utilizes the generation knowledge from gloss-to-text\nteacher models to guide the spoken language text generation. Experimental\nresults on two widely used SLT datasets, i.e., PHOENIX-2014T and CSL-Daily,\ndemonstrate that the proposed XmDA framework significantly and consistently\noutperforms the baseline models. Extensive analyses confirm our claim that XmDA\nenhances spoken language text generation by reducing the representation\ndistance between videos and texts, as well as improving the processing of\nlow-frequency words and long sentences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jinhui Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1\">Hui Xiong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Examining the Inter-Consistency of Large Language Models: An In-depth Analysis via Debate. (arXiv:2305.11595v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11595","description":"<p>Large Language Models (LLMs) have demonstrated human-like intelligence and\nare widely used in various applications. However, LLMs still exhibit various\nkinds of inconsistency problems. Existing works mainly focus on the\ninconsistency issues within a single LLM, while we investigate the\ninter-consistency among multiple LLMs, which is critical for collaborating to\nsolve a complex task. To examine whether LLMs can collaborate to ultimately\nachieve a consensus for the shared goal and whether LLMs easily change their\nviewpoints, we introduce a Formal Debate framework (FORD) With FORD, we conduct\na three-stage debate aligned with real-world scenarios: fair debate, mismatched\ndebate, and roundtable debate. Through extensive experiments on the commonsense\nreasoning task, LLMs not only become more inter-consistent but also achieve\nhigher performance. Moreover, we observe that stronger LLMs tend to dominate\nthe debates by adhering to their perspectives, while weaker ones are more\nlikely to change viewpoints. Additionally, we highlight the importance of a\ncompetent judge, such as GPT-4, to draw more proper conclusions. Our work\ncontributes to understanding the inter-consistency among LLMs and lays the\nfoundation for the development of future collaboration methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_K/0/1/0/all/0/1\">Kai Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_X/0/1/0/all/0/1\">Xiao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models. (arXiv:2305.11747v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11747","description":"<p>Large language models (LLMs), such as ChatGPT, are prone to generate\nhallucinations, \\ie content that conflicts with the source or cannot be\nverified by the factual knowledge. To understand what types of content and to\nwhich extent LLMs are apt to hallucinate, we introduce the Hallucination\nEvaluation for Large Language Models (HaluEval) benchmark, a large collection\nof generated and human-annotated hallucinated samples for evaluating the\nperformance of LLMs in recognizing hallucination. To generate these samples, we\npropose a ChatGPT-based two-step framework, \\ie sampling-then-filtering.\nBesides, we also hire some human labelers to annotate the hallucinations in\nChatGPT responses. The empirical results suggest that ChatGPT is likely to\ngenerate hallucinated content in specific topics by fabricating unverifiable\ninformation (\\ie about $11.4\\%$ user queries). Moreover, existing LLMs face\ngreat challenges in recognizing the hallucinations in texts. While, our\nexperiments also prove that the hallucination recognition can be improved by\nproviding external knowledge or adding reasoning steps. Our benchmark can be\naccessed at https://github.com/RUCAIBox/HaluEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xiaoxue Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11790","description":"<p>Prompting with natural language instructions has recently emerged as a\npopular method of harnessing the capabilities of large language models. Given\nthe inherent ambiguity present in natural language, it is intuitive to consider\nthe possible advantages of prompting with less ambiguous prompt styles, such as\nthe use of pseudo-code.\n</p>\n<p>In this paper we explore if prompting via pseudo-code instructions helps\nimprove the performance of pre-trained language models. We manually create a\ndataset of pseudo-code prompts for 132 different tasks spanning classification,\nQA and generative language tasks, sourced from the Super-NaturalInstructions\ndataset. Using these prompts along with their counterparts in natural language,\nwe study their performance on two LLM families - BLOOM and CodeGen. Our\nexperiments show that using pseudo-code instructions leads to better results,\nwith an average increase (absolute) of 7-16 points in F1 scores for\nclassification tasks and an improvement (relative) of 12-38% in aggregate\nROUGE-L scores across all tasks. We include detailed ablation studies which\nindicate that code comments, docstrings, and the structural clues encoded in\npseudo-code all contribute towards the improvement in performance.\n</p>\n<p>To the best of our knowledge our work is the first to demonstrate how\npseudo-code prompts can be helpful in improving the performance of pre-trained\nLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_M/0/1/0/all/0/1\">Mayank Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Prince Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1\">Riyaz Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contractor_D/0/1/0/all/0/1\">Danish Contractor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamilselvam_S/0/1/0/all/0/1\">Srikanth Tamilselvam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Appraising the Potential Uses and Harms of LLMs for Medical Systematic Reviews. (arXiv:2305.11828v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11828","description":"<p>Medical systematic reviews are crucial for informing clinical decision making\nand healthcare policy. But producing such reviews is onerous and\ntime-consuming. Thus, high-quality evidence synopses are not available for many\nquestions and may be outdated even when they are available. Large language\nmodels (LLMs) are now capable of generating long-form texts, suggesting the\ntantalizing possibility of automatically generating literature reviews on\ndemand. However, LLMs sometimes generate inaccurate (and potentially\nmisleading) texts by hallucinating or omitting important information. In the\nhealthcare context, this may render LLMs unusable at best and dangerous at\nworst. Most discussion surrounding the benefits and risks of LLMs have been\ndivorced from specific applications. In this work, we seek to qualitatively\ncharacterize the potential utility and risks of LLMs for assisting in\nproduction of medical evidence reviews. We conducted 16 semi-structured\ninterviews with international experts in systematic reviews, grounding\ndiscussion in the context of generating evidence reviews. Domain experts\nindicated that LLMs could aid writing reviews, as a tool for drafting or\ncreating plain language summaries, generating templates or suggestions,\ndistilling information, crosschecking, and synthesizing or interpreting text\ninputs. But they also identified issues with model outputs and expressed\nconcerns about potential downstream harms of confidently composed but\ninaccurate LLM outputs which might mislead. Other anticipated potential\ndownstream harms included lessened accountability and proliferation of\nautomatically generated reviews that might be of low quality. Informed by this\nqualitative analysis, we identify criteria for rigorous evaluation of\nbiomedical LLMs aligned with domain expert views.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yun_H/0/1/0/all/0/1\">Hye Sun Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marshall_I/0/1/0/all/0/1\">Iain J. Marshall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trikalinos_T/0/1/0/all/0/1\">Thomas Trikalinos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling laws for language encoding models in fMRI. (arXiv:2305.11863v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11863","description":"<p>Representations from transformer-based unidirectional language models are\nknown to be effective at predicting brain responses to natural language.\nHowever, most studies comparing language models to brains have used GPT-2 or\nsimilarly sized language models. Here we tested whether larger open-source\nmodels such as those from the OPT and LLaMA families are better at predicting\nbrain responses recorded using fMRI. Mirroring scaling results from other\ncontexts, we found that brain prediction performance scales log-linearly with\nmodel size from 125M to 30B parameter models, with ~15% increased encoding\nperformance as measured by correlation with a held-out test set across 3\nsubjects. Similar log-linear behavior was observed when scaling the size of the\nfMRI training set. We also characterized scaling for acoustic encoding models\nthat use HuBERT, WavLM, and Whisper, and we found comparable improvements with\nmodel size. A noise ceiling analysis of these large, high-performance encoding\nmodels showed that performance is nearing the theoretical maximum for brain\nareas such as the precuneus and higher auditory cortex. These results suggest\nthat increasing scale in both models and data will yield incredibly effective\nmodels of language processing in the brain, enabling better scientific\nunderstanding as well as applications such as decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Antonello_R/0/1/0/all/0/1\">Richard Antonello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaidya_A/0/1/0/all/0/1\">Aditya Vaidya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander G. Huth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-05-22T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}