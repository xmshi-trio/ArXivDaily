{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-04-25T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"ChatGPT, Large Language Technologies, and the Bumpy Road of Benefiting Humanity. (arXiv:2304.11163v1 [cs.CY])","link":"http://arxiv.org/abs/2304.11163","description":"<p>The allure of emerging AI technologies is undoubtedly thrilling. However, the\npromise that AI technologies will benefit all of humanity is empty so long as\nwe lack a nuanced understanding of what humanity is supposed to be in the face\nof widening global inequality and pressing existential threats. Going forward,\nit is crucial to invest in rigorous and collaborative AI safety and ethics\nresearch. We also need to develop standards in a sustainable and equitable way\nthat differentiate between merely speculative and well-researched questions.\nOnly the latter enable us to co-construct and deploy the values that are\nnecessary for creating beneficial AI. Failure to do so could result in a future\nin which our AI technological advancements outstrip our ability to navigate\ntheir ethical and social implications. This path we do not want to go down.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kasirzadeh_A/0/1/0/all/0/1\">Atoosa Kasirzadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialectical language model evaluation: An initial appraisal of the commonsense spatial reasoning abilities of LLMs. (arXiv:2304.11164v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11164","description":"<p>Language models have become very popular recently and many claims have been\nmade about their abilities, including for commonsense reasoning. Given the\nincreasingly better results of current language models on previous static\nbenchmarks for commonsense reasoning, we explore an alternative dialectical\nevaluation. The goal of this kind of evaluation is not to obtain an aggregate\nperformance value but to find failures and map the boundaries of the system.\nDialoguing with the system gives the opportunity to check for consistency and\nget more reassurance of these boundaries beyond anecdotal evidence. In this\npaper we conduct some qualitative investigations of this kind of evaluation for\nthe particular case of spatial reasoning (which is a fundamental aspect of\ncommonsense reasoning). We conclude with some suggestions for future work both\nto improve the capabilities of language models and to systematise this kind of\ndialectical evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1\">Anthony G Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Orallo_J/0/1/0/all/0/1\">Jose Hernandez-Orallo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learn What NOT to Learn: Towards Generative Safety in Chatbots. (arXiv:2304.11220v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11220","description":"<p>Conversational models that are generative and open-domain are particularly\nsusceptible to generating unsafe content since they are trained on web-based\nsocial data. Prior approaches to mitigating this issue have drawbacks, such as\ndisrupting the flow of conversation, limited generalization to unseen toxic\ninput contexts, and sacrificing the quality of the dialogue for the sake of\nsafety. In this paper, we present a novel framework, named \"LOT\" (Learn NOT\nto), that employs a contrastive loss to enhance generalization by learning from\nboth positive and negative training signals. Our approach differs from the\nstandard contrastive learning framework in that it automatically obtains\npositive and negative signals from the safe and unsafe language distributions\nthat have been learned beforehand. The LOT framework utilizes divergence to\nsteer the generations away from the unsafe subspace and towards the safe\nsubspace while sustaining the flow of conversation. Our approach is memory and\ntime-efficient during decoding and effectively reduces toxicity while\npreserving engagingness and fluency. Empirical results indicate that LOT\nreduces toxicity by up to four-fold while achieving four to six-fold higher\nrates of engagingness and fluency compared to baseline models. Our findings are\nfurther corroborated by human evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khalatbari_L/0/1/0/all/0/1\">Leila Khalatbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghadimi_S/0/1/0/all/0/1\">Saeed Ghadimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sameti_H/0/1/0/all/0/1\">Hossein Sameti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Group-Specific Approach to NLP for Hate Speech Detection. (arXiv:2304.11223v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11223","description":"<p>Automatic hate speech detection is an important yet complex task, requiring\nknowledge of common sense, stereotypes of protected groups, and histories of\ndiscrimination, each of which may constantly evolve. In this paper, we propose\na group-specific approach to NLP for online hate speech detection. The approach\nconsists of creating and infusing historical and linguistic knowledge about a\nparticular protected group into hate speech detection models, analyzing\nhistorical data about discrimination against a protected group to better\npredict spikes in hate speech against that group, and critically evaluating\nhate speech detection models through lenses of intersectionality and ethics. We\ndemonstrate this approach through a case study on NLP for detection of\nantisemitic hate speech. The case study synthesizes the current\nEnglish-language literature on NLP for antisemitism detection, introduces a\nnovel knowledge graph of antisemitic history and language from the 20th century\nto the present, infuses information from the knowledge graph into a set of\ntweets over Logistic Regression and uncased DistilBERT baselines, and suggests\nthat incorporating context from the knowledge graph can help models pick up\nsubtle stereotypes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Halevy_K/0/1/0/all/0/1\">Karina Halevy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UBC-DLNLP at SemEval-2023 Task 12: Impact of Transfer Learning on African Sentiment Analysis. (arXiv:2304.11256v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11256","description":"<p>We describe our contribution to the SemEVAl 2023 AfriSenti-SemEval shared\ntask, where we tackle the task of sentiment analysis in 14 different African\nlanguages. We develop both monolingual and multilingual models under a full\nsupervised setting (subtasks A and B). We also develop models for the zero-shot\nsetting (subtask C). Our approach involves experimenting with transfer learning\nusing six language models, including further pertaining of some of these models\nas well as a final finetuning stage. Our best performing models achieve an\nF1-score of 70.36 on development data and an F1-score of 66.13 on test data.\nUnsurprisingly, our results demonstrate the effectiveness of transfer learning\nand fine-tuning techniques for sentiment analysis across multiple languages.\nOur approach can be applied to other sentiment analysis tasks in different\nlanguages and domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_G/0/1/0/all/0/1\">Gagan Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adebara_I/0/1/0/all/0/1\">Ife Adebara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1\">AbdelRahim Elmadany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Who's the Best Detective? LLMs vs. MLs in Detecting Incoherent Fourth Grade Math Answers. (arXiv:2304.11257v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11257","description":"<p>Written answers to open-ended questions can have a higher long-term effect on\nlearning than multiple-choice questions. However, it is critical that teachers\nimmediately review the answers, and ask to redo those that are incoherent. This\ncan be a difficult task and can be time-consuming for teachers. A possible\nsolution is to automate the detection of incoherent answers. One option is to\nautomate the review with Large Language Models (LLM). In this paper, we analyze\nthe responses of fourth graders in mathematics using three LLMs: GPT-3, BLOOM,\nand YOU. We used them with zero, one, two, three and four shots. We compared\ntheir performance with the results of various classifiers trained with Machine\nLearning (ML). We found that LLMs perform worse than MLs in detecting\nincoherent answers. The difficulty seems to reside in recursive questions that\ncontain both questions and answers, and in responses from students with typical\nfourth-grader misspellings. Upon closer examination, we have found that the\nChatGPT model faces the same challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Urrutia_F/0/1/0/all/0/1\">Felipe Urrutia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Araya_R/0/1/0/all/0/1\">Roberto Araya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Role of AI in Human-AI Creative Writing for Hong Kong Secondary Students. (arXiv:2304.11276v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11276","description":"<p>The recent advancement in Natural Language Processing (NLP) capability has\nled to the development of language models (e.g., ChatGPT) that is capable of\ngenerating human-like language. In this study, we explore how language models\ncan be utilized to help the ideation aspect of creative writing. Our empirical\nfindings show that language models play different roles in helping student\nwriters to be more creative, such as the role of a collaborator, a provocateur,\netc\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Susanto_H/0/1/0/all/0/1\">Hengky Susanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_D/0/1/0/all/0/1\">David James Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kai Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Identification of the Energy related Issues from the App Reviews. (arXiv:2304.11292v1 [cs.AI])","link":"http://arxiv.org/abs/2304.11292","description":"<p>The energy inefficiency of the apps can be a major issue for the app users\nwhich is discussed on App Stores extensively. Previous research has shown the\nimportance of investigating the energy related app reviews to identify the\nmajor causes or categories of energy related user feedback. However, there is\nno study that efficiently extracts the energy related app reviews\nautomatically. In this paper, we empirically study different techniques for\nautomatic extraction of the energy related user feedback. We compare the\naccuracy, F1-score and run time of numerous machine-learning models with\nrelevant feature combinations and relatively modern Neural Network-based\nmodels. In total, 60 machine learning models are compared to 30 models that we\nbuild using six neural network architectures and three word embedding models.\nWe develop a visualization tool for this study through which a developer can\ntraverse through this large-scale result set. The results show that neural\nnetworks outperform the other machine learning techniques and can achieve the\nhighest F1-score of 0.935. To replicate the research results, we have open\nsourced the interactive visualization tool. After identifying the best results\nand extracting the energy related reviews, we further compare various\ntechniques to help the developers automatically investigate the emerging issues\nthat might be responsible for energy inefficiency of the apps. We experiment\nthe previously used string matching with results obtained from applying two of\nthe state-of-the-art topic modeling algorithms, OBTM and AOLDA. Finally, we run\na qualitative study performed in collaboration with developers and students\nfrom different institutions to determine their preferences for identifying\nnecessary topics from previously categorized reviews, which shows OBTM produces\nthe most helpful results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nawal_N/0/1/0/all/0/1\">Noshin Nawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Specialization for Knowledge-based Word Sense Disambiguation. (arXiv:2304.11340v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11340","description":"<p>A promising approach for knowledge-based Word Sense Disambiguation (WSD) is\nto select the sense whose contextualized embeddings computed for its definition\nsentence are closest to those computed for a target word in a given sentence.\nThis approach relies on the similarity of the \\textit{sense} and\n\\textit{context} embeddings computed by a pre-trained language model. We\npropose a semantic specialization for WSD where contextualized embeddings are\nadapted to the WSD task using solely lexical knowledge. The key idea is, for a\ngiven sense, to bring semantically related senses and contexts closer and send\ndifferent/unrelated senses farther away. We realize this idea as the joint\noptimization of the Attract-Repel objective for sense pairs and the\nself-training objective for context-sense pairs while controlling deviations\nfrom the original embeddings. The proposed method outperformed previous studies\nthat adapt contextualized embeddings. It achieved state-of-the-art performance\non knowledge-based WSD when combined with the reranking heuristic that uses the\nsense inventory. We found that the similarity characteristics of specialized\nembeddings conform to the key idea. We also found that the (dis)similarity of\nembeddings between the related/different/unrelated senses correlates well with\nthe performance of WSD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mizuki_S/0/1/0/all/0/1\">Sakae Mizuki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okazaki_N/0/1/0/all/0/1\">Naoaki Okazaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Romanian Multiword Expression Detection Using Multilingual Adversarial Training and Lateral Inhibition. (arXiv:2304.11350v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11350","description":"<p>Multiword expressions are a key ingredient for developing large-scale and\nlinguistically sound natural language processing technology. This paper\ndescribes our improvements in automatically identifying Romanian multiword\nexpressions on the corpus released for the PARSEME v1.2 shared task. Our\napproach assumes a multilingual perspective based on the recently introduced\nlateral inhibition layer and adversarial training to boost the performance of\nthe employed multilingual language models. With the help of these two methods,\nwe improve the F1-score of XLM-RoBERTa by approximately 2.7% on unseen\nmultiword expressions, the main task of the PARSEME 1.2 edition. In addition,\nour results can be considered SOTA performance, as they outperform the previous\nresults on Romanian obtained by the participants in this competition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Avram_A/0/1/0/all/0/1\">Andrei-Marius Avram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mititelu_V/0/1/0/all/0/1\">Verginica Barbu Mititelu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1\">Dumitru-Clementin Cercel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SAILER: Structure-aware Pre-trained Language Model for Legal Case Retrieval. (arXiv:2304.11370v1 [cs.IR])","link":"http://arxiv.org/abs/2304.11370","description":"<p>Legal case retrieval, which aims to find relevant cases for a query case,\nplays a core role in the intelligent legal system. Despite the success that\npre-training has achieved in ad-hoc retrieval tasks, effective pre-training\nstrategies for legal case retrieval remain to be explored. Compared with\ngeneral documents, legal case documents are typically long text sequences with\nintrinsic logical structures. However, most existing language models have\ndifficulty understanding the long-distance dependencies between different\nstructures. Moreover, in contrast to the general retrieval, the relevance in\nthe legal domain is sensitive to key legal elements. Even subtle differences in\nkey legal elements can significantly affect the judgement of relevance.\nHowever, existing pre-trained language models designed for general purposes\nhave not been equipped to handle legal elements.\n</p>\n<p>To address these issues, in this paper, we propose SAILER, a new\nStructure-Aware pre-traIned language model for LEgal case Retrieval. It is\nhighlighted in the following three aspects: (1) SAILER fully utilizes the\nstructural information contained in legal case documents and pays more\nattention to key legal elements, similar to how legal experts browse legal case\ndocuments. (2) SAILER employs an asymmetric encoder-decoder architecture to\nintegrate several different pre-training objectives. In this way, rich semantic\ninformation across tasks is encoded into dense vectors. (3) SAILER has powerful\ndiscriminative ability, even without any legal annotation data. It can\ndistinguish legal cases with different charges accurately. Extensive\nexperiments over publicly available legal benchmarks demonstrate that our\napproach can significantly outperform previous state-of-the-art methods in\nlegal case retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haitao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1\">Qingyao Ai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jia Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1\">Qian Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yueyue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiqun Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-Based LM Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens. (arXiv:2304.11389v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11389","description":"<p>Recent psycholinguistic studies have drawn conflicting conclusions about the\nrelationship between the quality of a language model and the ability of its\nsurprisal estimates to predict human reading times, which has been speculated\nto be due to the large gap in both the amount of training data and model\ncapacity across studies. The current work aims to consolidate these findings by\nevaluating surprisal estimates from Transformer-based language model variants\nthat vary systematically in the amount of training data and model capacity on\ntheir ability to predict human reading times. The results show that surprisal\nestimates from most variants with contemporary model capacities provide the\nbest fit after seeing about two billion training tokens, after which they begin\nto diverge from humanlike expectations. Additionally, newly-trained smaller\nmodel variants reveal a 'tipping point' at convergence, after which the\ndecrease in language model perplexity begins to result in poorer fits to human\nreading times. These results suggest that the massive amount of training data\nis mainly responsible for the poorer fit achieved by surprisal from larger\npre-trained language models, and that a certain degree of model capacity is\nnecessary for Transformer-based language models to capture humanlike\nexpectations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oh_B/0/1/0/all/0/1\">Byung-Doh Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuler_W/0/1/0/all/0/1\">William Schuler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LaMP: When Large Language Models Meet Personalization. (arXiv:2304.11406v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11406","description":"<p>This paper highlights the importance of personalization in the current state\nof natural language understanding and generation and introduces the LaMP\nbenchmark -- a novel benchmark for training and evaluating language models for\nproducing personalized outputs. LaMP offers a comprehensive evaluation\nframework with diverse language tasks and multiple entries for each user\nprofile. It consists of seven personalized tasks, spanning three classification\nand four text generation tasks. We also propose a retrieval augmentation\napproach that retrieves personalized items from user profiles to construct\npersonalized prompts for large language models. Our baseline zero-shot and\nfine-tuned model results indicate that LMs utilizing profile augmentation\noutperform their counterparts that do not factor in profile information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salemi_A/0/1/0/all/0/1\">Alireza Salemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mysore_S/0/1/0/all/0/1\">Sheshera Mysore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bendersky_M/0/1/0/all/0/1\">Michael Bendersky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A bounded rationality account of dependency length minimization in Hindi. (arXiv:2304.11410v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11410","description":"<p>The principle of DEPENDENCY LENGTH MINIMIZATION, which seeks to keep\nsyntactically related words close in a sentence, is thought to universally\nshape the structure of human languages for effective communication. However,\nthe extent to which dependency length minimization is applied in human language\nsystems is not yet fully understood. Preverbally, the placement of\nlong-before-short constituents and postverbally, short-before-long constituents\nare known to minimize overall dependency length of a sentence. In this study,\nwe test the hypothesis that placing only the shortest preverbal constituent\nnext to the main-verb explains word order preferences in Hindi (a SOV language)\nas opposed to the global minimization of dependency length. We characterize\nthis approach as a least-effort strategy because it is a cost-effective way to\nshorten all dependencies between the verb and its preverbal dependencies. As\nsuch, this approach is consistent with the bounded-rationality perspective\naccording to which decision making is governed by \"fast but frugal\" heuristics\nrather than by a search for optimal solutions. Consistent with this idea, our\nresults indicate that actual corpus sentences in the Hindi-Urdu Treebank corpus\nare better explained by the least effort strategy than by global minimization\nof dependency lengths. Additionally, for the task of distinguishing corpus\nsentences from counterfactual variants, we find that the dependency length and\nconstituent length of the constituent closest to the main verb are much better\npredictors of whether a sentence appeared in the corpus than total dependency\nlength. Overall, our findings suggest that cognitive resource constraints play\na crucial role in shaping natural languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ranjan_S/0/1/0/all/0/1\">Sidharth Ranjan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malsburg_T/0/1/0/all/0/1\">Titus von der Malsburg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L3Cube-IndicSBERT: A simple approach for learning cross-lingual sentence representations using multilingual BERT. (arXiv:2304.11434v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11434","description":"<p>The multilingual Sentence-BERT (SBERT) models map different languages to\ncommon representation space and are useful for cross-language similarity and\nmining tasks. We propose a simple yet effective approach to convert vanilla\nmultilingual BERT models into multilingual sentence BERT models using synthetic\ncorpus. We simply aggregate translated NLI or STS datasets of the low-resource\ntarget languages together and perform SBERT-like fine-tuning of the vanilla\nmultilingual BERT model. We show that multilingual BERT models are inherent\ncross-lingual learners and this simple baseline fine-tuning approach without\nexplicit cross-lingual training yields exceptional cross-lingual properties. We\nshow the efficacy of our approach on 10 major Indic languages and also show the\napplicability of our approach to non-Indic languages German and French. Using\nthis approach, we further present L3Cube-IndicSBERT, the first multilingual\nsentence representation model specifically for Indian languages Hindi, Marathi,\nKannada, Telugu, Malayalam, Tamil, Gujarati, Odia, Bengali, and Punjabi. The\nIndicSBERT exhibits strong cross-lingual capabilities and performs\nsignificantly better than alternatives like LaBSE, LASER, and\nparaphrase-multilingual-mpnet-base-v2 on Indic cross-lingual and monolingual\nsentence similarity tasks. We also release monolingual SBERT models for each of\nthe languages and show that IndicSBERT performs competitively with its\nmonolingual counterparts. These models have been evaluated using embedding\nsimilarity scores and classification accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deode_S/0/1/0/all/0/1\">Samruddhi Deode</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gadre_J/0/1/0/all/0/1\">Janhavi Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kajale_A/0/1/0/all/0/1\">Aditi Kajale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Ananya Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Raviraj Joshi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recurrent Neural Networks and Long Short-Term Memory Networks: Tutorial and Survey. (arXiv:2304.11461v1 [cs.LG])","link":"http://arxiv.org/abs/2304.11461","description":"<p>This is a tutorial paper on Recurrent Neural Network (RNN), Long Short-Term\nMemory Network (LSTM), and their variants. We start with a dynamical system and\nbackpropagation through time for RNN. Then, we discuss the problems of gradient\nvanishing and explosion in long-term dependencies. We explain close-to-identity\nweight matrix, long delays, leaky units, and echo state networks for solving\nthis problem. Then, we introduce LSTM gates and cells, history and variants of\nLSTM, and Gated Recurrent Units (GRU). Finally, we introduce bidirectional RNN,\nbidirectional LSTM, and the Embeddings from Language Model (ELMo) network, for\nprocessing a sequence in both directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghojogh_B/0/1/0/all/0/1\">Benyamin Ghojogh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"(Vector) Space is Not the Final Frontier: Product Search as Program Synthesis. (arXiv:2304.11473v1 [cs.IR])","link":"http://arxiv.org/abs/2304.11473","description":"<p>As ecommerce continues growing, huge investments in ML and NLP for\nInformation Retrieval are following. While the vector space model dominated\nretrieval modelling in product search - even as vectorization itself greatly\nchanged with the advent of deep learning -, our position paper argues in a\ncontrarian fashion that program synthesis provides significant advantages for\nmany queries and a significant number of players in the market. We detail the\nindustry significance of the proposed approach, sketch implementation details,\nand address common objections drawing from our experience building a similar\nsystem at Tooso.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1\">Jacopo Tagliabue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greco_C/0/1/0/all/0/1\">Ciro Greco</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding Lexical Biases when Identifying Gang-related Social Media Communications. (arXiv:2304.11485v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11485","description":"<p>Individuals involved in gang-related activity use mainstream social media\nincluding Facebook and Twitter to express taunts and threats as well as grief\nand memorializing. However, identifying the impact of gang-related activity in\norder to serve community member needs through social media sources has a unique\nset of challenges. This includes the difficulty of ethically identifying\ntraining data of individuals impacted by gang activity and the need to account\nfor a non-standard language style commonly used in the tweets from these\nindividuals. Our study provides evidence of methods where natural language\nprocessing tools can be helpful in efficiently identifying individuals who may\nbe in need of community care resources such as counselors, conflict mediators,\nor academic/professional training programs. We demonstrate that our binary\nlogistic classifier outperforms baseline standards in identifying individuals\nimpacted by gang-related violence using a sample of gang-related tweets\nassociated with Chicago. We ultimately found that the language of a tweet is\nhighly relevant and that uses of ``big data'' methods or machine learning\nmodels need to better understand how language impacts the model's performance\nand how it discriminates among populations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Murthy_D/0/1/0/all/0/1\">Dhiraj Murthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caramanis_C/0/1/0/all/0/1\">Constantine Caramanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudra_K/0/1/0/all/0/1\">Koustav Rudra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Theory-of-Mind Performance in Large Language Models via Prompting. (arXiv:2304.11490v1 [cs.AI])","link":"http://arxiv.org/abs/2304.11490","description":"<p>Large language models (LLMs) excel in many tasks in 2023, but they still face\nchallenges in complex reasoning. Theory-of-mind (ToM) tasks, which require\nunderstanding agents' beliefs, goals, and mental states, are essential for\ncommon-sense reasoning involving humans, making it crucial to enhance LLM\nperformance in this area. This study measures the ToM performance of GPT-4 and\nthree GPT-3.5 variants (Davinci-2, Davinci-3, GPT-3.5-Turbo), and investigates\nthe effectiveness of in-context learning in improving their ToM comprehension.\nWe evaluated prompts featuring two-shot chain of thought reasoning and\nstep-by-step thinking instructions. We found that LLMs trained with\nReinforcement Learning from Human Feedback (RLHF) (all models excluding\nDavinci-2) improved their ToM accuracy via in-context learning. GPT-4 performed\nbest in zero-shot settings, reaching nearly 80% ToM accuracy, but still fell\nshort of the 87% human accuracy on the test set. However, when supplied with\nprompts for in-context learning, all RLHF-trained LLMs exceeded 80% ToM\naccuracy, with GPT-4 reaching 100%. These results demonstrate that appropriate\nprompting enhances LLM ToM reasoning, and they underscore the context-dependent\nnature of LLM cognitive capacities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moghaddam_S/0/1/0/all/0/1\">Shima Rahimi Moghaddam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Honey_C/0/1/0/all/0/1\">Christopher J. Honey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Translationese Reduction using Abstract Meaning Representation. (arXiv:2304.11501v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11501","description":"<p>Translated texts or utterances bear several hallmarks distinct from texts\noriginating in the language. This phenomenon, known as translationese, is\nwell-documented, and when found in training or test sets can affect model\nperformance. Still, work to mitigate the effect of translationese in human\ntranslated text is understudied. We hypothesize that Abstract Meaning\nRepresentation (AMR), a semantic representation which abstracts away from the\nsurface form, can be used as an interlingua to reduce the amount of\ntranslationese in translated texts. By parsing English translations into an AMR\ngraph and then generating text from that AMR, we obtain texts that more closely\nresemble non-translationese by macro-level measures. We show that across four\nmetrics, and qualitatively, using AMR as an interlingua enables the reduction\nof translationese and we compare our results to two additional approaches: one\nbased on round-trip machine translation and one based on syntactically\ncontrolled generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wein_S/0/1/0/all/0/1\">Shira Wein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nathan Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Challenges of Deploying BERT-based NLP Models in Resource-Constrained Embedded Devices. (arXiv:2304.11520v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11520","description":"<p>BERT-based neural architectures have established themselves as popular\nstate-of-the-art baselines for many downstream NLP tasks. However, these\narchitectures are data-hungry and consume a lot of memory and energy, often\nhindering their deployment in many real-time, resource-constrained\napplications. Existing lighter versions of BERT (eg. DistilBERT and TinyBERT)\noften cannot perform well on complex NLP tasks. More importantly, from a\ndesigner's perspective, it is unclear what is the \"right\" BERT-based\narchitecture to use for a given NLP task that can strike the optimal trade-off\nbetween the resources available and the minimum accuracy desired by the end\nuser. System engineers have to spend a lot of time conducting trial-and-error\nexperiments to find a suitable answer to this question. This paper presents an\nexploratory study of BERT-based models under different resource constraints and\naccuracy budgets to derive empirical observations about this resource/accuracy\ntrade-offs. Our findings can help designers to make informed choices among\nalternative BERT-based architectures for embedded systems, thus saving\nsignificant development time and effort.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Souvika Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babar_M/0/1/0/all/0/1\">Mohammad Fakhruddin Babar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1\">Md Mahadi Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Monowar Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker Santu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Graph Neural Networks for Text Classification: A Survey. (arXiv:2304.11534v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11534","description":"<p>Text Classification is the most essential and fundamental problem in Natural\nLanguage Processing. While numerous recent text classification models applied\nthe sequential deep learning technique, graph neural network-based models can\ndirectly deal with complex structured text data and exploit global information.\nMany real text classification applications can be naturally cast into a graph,\nwhich captures words, documents, and corpus global features. In this survey, we\nbring the coverage of methods up to 2023, including corpus-level and\ndocument-level graph neural networks. We discuss each of these methods in\ndetail, dealing with the graph construction mechanisms and the graph-based\nlearning process. As well as the technological survey, we look at issues behind\nand future directions addressed in text classification using graph neural\nnetworks. We also cover datasets, evaluation metrics, and experiment design and\npresent a summary of published performance on the publicly available\nbenchmarks. Note that we present a comprehensive comparison between different\ntechniques and identify the pros and cons of various evaluation metrics in this\nsurvey.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kunze Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yihao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Divide and Prompt: Chain of Thought Prompting for Text-to-SQL. (arXiv:2304.11556v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11556","description":"<p>Chain-of-thought (CoT) prompting combined with large language models (LLMs)\nhave achieved encouraging results on complex reasoning tasks. Text-to-SQL is a\ncritical semantic parsing task that converts natural language questions into\nSQL statements, involving a complex reasoning process. However, there is little\nwork about using CoT prompting to activate LLM's reasoning capabilities on\nText-to-SQL tasks. In this work, we propose a new paradigm for prompting\nText-to-SQL tasks, called Divide-and-Prompt, which first divides the task into\nsubtasks, and then approach each subtask through CoT. We present 3\nprompting-based methods to enhance the Text-to-SQL ability of LLMs. Experiments\nshow that these prompts guide LLMs to generate Text-to-SQL with higher\nexecution accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1\">Zhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiate ChatGPT-generated and Human-written Medical Texts. (arXiv:2304.11567v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11567","description":"<p>Background: Large language models such as ChatGPT are capable of generating\ngrammatically perfect and human-like text content, and a large number of\nChatGPT-generated texts have appeared on the Internet. However, medical texts\nsuch as clinical notes and diagnoses require rigorous validation, and erroneous\nmedical content generated by ChatGPT could potentially lead to disinformation\nthat poses significant harm to healthcare and the general public.\n</p>\n<p>Objective: This research is among the first studies on responsible and\nethical AIGC (Artificial Intelligence Generated Content) in medicine. We focus\non analyzing the differences between medical texts written by human experts and\ngenerated by ChatGPT, and designing machine learning workflows to effectively\ndetect and differentiate medical texts generated by ChatGPT.\n</p>\n<p>Methods: We first construct a suite of datasets containing medical texts\nwritten by human experts and generated by ChatGPT. In the next step, we analyze\nthe linguistic features of these two types of content and uncover differences\nin vocabulary, part-of-speech, dependency, sentiment, perplexity, etc. Finally,\nwe design and implement machine learning methods to detect medical text\ngenerated by ChatGPT.\n</p>\n<p>Results: Medical texts written by humans are more concrete, more diverse, and\ntypically contain more useful information, while medical texts generated by\nChatGPT pay more attention to fluency and logic, and usually express general\nterminologies rather than effective information specific to the context of the\nproblem. A BERT-based model can effectively detect medical texts generated by\nChatGPT, and the F1 exceeds 95%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenxiong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Haixing Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shaochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zihao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yiyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xiaoke Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dajiang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hongmin Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modality-Aware Negative Sampling for Multi-modal Knowledge Graph Embedding. (arXiv:2304.11618v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11618","description":"<p>Negative sampling (NS) is widely used in knowledge graph embedding (KGE),\nwhich aims to generate negative triples to make a positive-negative contrast\nduring training. However, existing NS methods are unsuitable when multi-modal\ninformation is considered in KGE models. They are also inefficient due to their\ncomplex design. In this paper, we propose Modality-Aware Negative Sampling\n(MANS) for multi-modal knowledge graph embedding (MMKGE) to address the\nmentioned problems. MANS could align structural and visual embeddings for\nentities in KGs and learn meaningful embeddings to perform better in\nmulti-modal KGE while keeping lightweight and efficient. Empirical results on\ntwo benchmarks demonstrate that MANS outperforms existing NS methods.\nMeanwhile, we make further explorations about MANS to confirm its\neffectiveness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mingyang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wen Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating ChatGPT's Information Extraction Capabilities: An Assessment of Performance, Explainability, Calibration, and Faithfulness. (arXiv:2304.11633v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11633","description":"<p>The capability of Large Language Models (LLMs) like ChatGPT to comprehend\nuser intent and provide reasonable responses has made them extremely popular\nlately. In this paper, we focus on assessing the overall ability of ChatGPT\nusing 7 fine-grained information extraction (IE) tasks. Specially, we present\nthe systematically analysis by measuring ChatGPT's performance, explainability,\ncalibration, and faithfulness, and resulting in 15 keys from either the ChatGPT\nor domain experts. Our findings reveal that ChatGPT's performance in\nStandard-IE setting is poor, but it surprisingly exhibits excellent performance\nin the OpenIE setting, as evidenced by human evaluation. In addition, our\nresearch indicates that ChatGPT provides high-quality and trustworthy\nexplanations for its decisions. However, there is an issue of ChatGPT being\noverconfident in its predictions, which resulting in low calibration.\nFurthermore, ChatGPT demonstrates a high level of faithfulness to the original\ntext in the majority of cases. We manually annotate and release the test sets\nof 7 fine-grained IE tasks contains 14 datasets to further promote the\nresearch. The datasets and code are available at\nhttps://github.com/pkuserc/ChatGPT_for_IE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1\">Gexiang Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Quansen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shikun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models. (arXiv:2304.11657v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11657","description":"<p>Large language models (LLMs) can achieve highly effective performance on\nvarious reasoning tasks by incorporating step-by-step chain-of-thought (CoT)\nprompting as demonstrations. However, the reasoning chains of demonstrations\ngenerated by LLMs are prone to errors, which can subsequently lead to incorrect\nreasoning during inference. Furthermore, inappropriate exemplars (overly\nsimplistic or complex), can affect overall performance among varying levels of\ndifficulty. We introduce Iter-CoT (Iterative bootstrapping in Chain-of-Thoughts\nPrompting), an iterative bootstrapping approach for selecting exemplars and\ngenerating reasoning chains. By utilizing iterative bootstrapping, our approach\nenables LLMs to autonomously rectify errors, resulting in more precise and\ncomprehensive reasoning chains. Simultaneously, our approach selects\nchallenging yet answerable questions accompanied by reasoning chains as\nexemplars with a moderate level of difficulty, which enhances the LLMs'\ngeneralizability across varying levels of difficulty. Experimental results\nindicate that Iter-CoT exhibits superiority, achieving competitive performance\nacross three distinct reasoning tasks on eleven datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiashuo Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yi Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chen Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jian Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering in Islamic Text Resources. (arXiv:2304.11664v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11664","description":"<p>Nowadays, one of the main challenges for Question Answering Systems is to\nanswer complex questions using various sources of information. Multi-hop\nquestions are a type of complex questions that require multi-step reasoning to\nanswer. In this article, the IslamicPCQA dataset is introduced. This is the\nfirst Persian dataset for answering complex questions based on non-structured\ninformation sources and consists of 12,282 question-answer pairs extracted from\n9 Islamic encyclopedias. This dataset has been created inspired by the HotpotQA\nEnglish dataset approach, which was customized to suit the complexities of the\nPersian language. Answering questions in this dataset requires more than one\nparagraph and reasoning. The questions are not limited to any prior knowledge\nbase or ontology, and to provide robust reasoning ability, the dataset also\nincludes supporting facts and key sentences. The prepared dataset covers a wide\nrange of Islamic topics and aims to facilitate answering complex Persian\nquestions within this subject matter\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghafouri_A/0/1/0/all/0/1\">Arash Ghafouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naderi_H/0/1/0/all/0/1\">Hasan Naderi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+asl_M/0/1/0/all/0/1\">Mohammad Aghajani asl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firouzmandi_M/0/1/0/all/0/1\">Mahdi Firouzmandi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hold the Suspect! : An Analysis on Media Framing of Itaewon Halloween Crowd Crush. (arXiv:2304.11666v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11666","description":"<p>Based on the 10.9K articles from top 40 news providers of South Korea, this\npaper analyzed the media framing of Itaewon Halloween Crowd Crush during the\nfirst 72 hours after the incident. By adopting word-vector embedding and\nclustering, we figured out that conservative media focused on political\nparties' responses and the suspect's identity while the liberal media covered\nthe responsibility of the government and possible unequal spillover effect on\nthe low-income industry workers. Although the social tragedy was not directly\nconnected to institutional politics, the media clearly exhibited political bias\nin the coverage process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_T/0/1/0/all/0/1\">TaeYoung Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Domain Mastery Benchmark: An Ever-Updating Benchmark for Evaluating Holistic Domain Knowledge of Large Language Model--A Preliminary Release. (arXiv:2304.11679v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11679","description":"<p>Domain knowledge refers to the in-depth understanding, expertise, and\nfamiliarity with a specific subject, industry, field, or area of special\ninterest. The existing benchmarks are all lack of an overall design for domain\nknowledge evaluation. Holding the belief that the real ability of domain\nlanguage understanding can only be fairly evaluated by an comprehensive and\nin-depth benchmark, we introduces the Domma, a Domain Mastery Benchmark. DomMa\ntargets at testing Large Language Models (LLMs) on their domain knowledge\nunderstanding, it features extensive domain coverage, large data volume, and a\ncontinually updated data set based on Chinese 112 first-level subject\nclassifications. DomMa consist of 100,000 questions in both Chinese and English\nsourced from graduate entrance examinations and undergraduate exams in Chinese\ncollege. We have also propose designs to make benchmark and evaluation process\nmore suitable to LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zhouhong Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoxuan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haoning Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1\">Zhuozhi Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zihan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1\">Qianyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Sihang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Hongwei Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Studying the Impact of Semi-Cooperative Drivers on Overall Highway Flow. (arXiv:2304.11693v1 [cs.CL])","link":"http://arxiv.org/abs/2304.11693","description":"<p>Semi-cooperative behaviors are intrinsic properties of human drivers and\nshould be considered for autonomous driving. In addition, new autonomous\nplanners can consider the social value orientation (SVO) of human drivers to\ngenerate socially-compliant trajectories. Yet the overall impact on traffic\nflow for this new class of planners remain to be understood. In this work, we\npresent study of implicit semi-cooperative driving where agents deploy a\ngame-theoretic version of iterative best response assuming knowledge of the\nSVOs of other agents. We simulate nominal traffic flow and investigate whether\nthe proportion of prosocial agents on the road impact individual or system-wide\ndriving performance. Experiments show that the proportion of prosocial agents\nhas a minor impact on overall traffic flow and that benefits of\nsemi-cooperation disproportionally affect egoistic and high-speed drivers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Buckman_N/0/1/0/all/0/1\">Noam Buckman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karaman_S/0/1/0/all/0/1\">Sertac Karaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1\">Daniela Rus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human Attention during Goal-directed Reading Comprehension Relies on Task Optimization. (arXiv:2107.05799v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2107.05799","description":"<p>The computational principles underlying attention allocation in complex\ngoal-directed tasks remain elusive. Goal-directed reading, i.e., reading a\npassage to answer a question in mind, is a common real-world task that strongly\nengages attention. Here, we investigate what computational models can explain\nattention distribution in this complex task. We show that the reading time on\neach word is predicted by the attention weights in transformer-based deep\nneural networks (DNNs) optimized to perform the same reading task. Eye-tracking\nfurther reveals that readers separately attend to basic text features and\nquestion-relevant information during first-pass reading and rereading,\nrespectively. Similarly, text features and question relevance separately\nmodulate attention weights in shallow and deep DNN layers. Furthermore, when\nreaders scan a passage without a question in mind, their reading time is\npredicted by DNNs optimized for a word prediction task. Therefore, attention\nduring real-world reading can be interpreted as the consequence of task\noptimization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">Jiajie Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuran Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jialu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1\">Xing Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nai Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aspect-based Sentiment Analysis in Document -- FOMC Meeting Minutes on Economic Projection. (arXiv:2108.04080v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2108.04080","description":"<p>The Federal Open Market Committee within the Federal Reserve System is\nresponsible for managing inflation, maximizing employment, and stabilizing\ninterest rates. Meeting minutes play an important role for market movements\nbecause they provide the birds eye view of how this economic complexity is\nconstantly re-weighed. Therefore, There has been growing interest in analyzing\nand extracting sentiments on various aspects from large financial texts for\neconomic projection. However, Aspect-based Sentiment Analysis is not widely\nused on financial data due to the lack of large labeled dataset. In this paper,\nI propose a model to train ABSA on financial documents under weak supervision\nand analyze its predictive power on various macroeconomic indicators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarah-Yifei-Wang/0/1/0/all/0/1\">Sarah-Yifei-Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PAIR: Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval. (arXiv:2108.06027v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2108.06027","description":"<p>Recently, dense passage retrieval has become a mainstream approach to finding\nrelevant information in various natural language processing tasks. A number of\nstudies have been devoted to improving the widely adopted dual-encoder\narchitecture. However, most of the previous studies only consider query-centric\nsimilarity relation when learning the dual-encoder retriever. In order to\ncapture more comprehensive similarity relations, we propose a novel approach\nthat leverages both query-centric and PAssage-centric sImilarity Relations\n(called PAIR) for dense passage retrieval. To implement our approach, we make\nthree major technical contributions by introducing formal formulations of the\ntwo kinds of similarity relations, generating high-quality pseudo labeled data\nvia knowledge distillation, and designing an effective two-stage training\nprocedure that incorporates passage-centric similarity relation constraint.\nExtensive experiments show that our approach significantly outperforms previous\nstate-of-the-art models on both MSMARCO and Natural Questions datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_S/0/1/0/all/0/1\">Shangwen Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yingqi Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1\">QiaoQiao She</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RocketQAv2: A Joint Training Method for Dense Passage Retrieval and Passage Re-ranking. (arXiv:2110.07367v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.07367","description":"<p>In various natural language processing tasks, passage retrieval and passage\nre-ranking are two key procedures in finding and ranking relevant information.\nSince both the two procedures contribute to the final performance, it is\nimportant to jointly optimize them in order to achieve mutual improvement. In\nthis paper, we propose a novel joint training approach for dense passage\nretrieval and passage re-ranking. A major contribution is that we introduce the\ndynamic listwise distillation, where we design a unified listwise training\napproach for both the retriever and the re-ranker. During the dynamic\ndistillation, the retriever and the re-ranker can be adaptively improved\naccording to each other's relevance information. We also propose a hybrid data\naugmentation strategy to construct diverse training instances for listwise\ntraining approach. Extensive experiments show the effectiveness of our approach\non both MSMARCO and Natural Questions datasets. Our code is available at\nhttps://github.com/PaddlePaddle/RocketQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yingqi Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1\">Qiaoqiao She</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Review of Deep Learning for Automated Medical Coding. (arXiv:2201.02797v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.02797","description":"<p>Automated medical coding, an essential task for healthcare operation and\ndelivery, makes unstructured data manageable by predicting medical codes from\nclinical documents. Recent advances in deep learning and natural language\nprocessing have been widely applied to this task. However, deep learning-based\nmedical coding lacks a unified view of the design of neural network\narchitectures. This review proposes a unified framework to provide a general\nunderstanding of the building blocks of medical coding models and summarizes\nrecent advanced models under the proposed framework. Our unified framework\ndecomposes medical coding into four main components, i.e., encoder modules for\ntext feature extraction, mechanisms for building deep encoder architectures,\ndecoder modules for transforming hidden representations into medical codes, and\nthe usage of auxiliary information. Finally, we introduce the benchmarks and\nreal-world usage and discuss key research challenges and future directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1\">Shaoxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Wei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaobo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taalas_A/0/1/0/all/0/1\">Ara Taalas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Honghan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pitkanen_E/0/1/0/all/0/1\">Esa Pitk&#xe4;nen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marttinen_P/0/1/0/all/0/1\">Pekka Marttinen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Question-Answer Sentence Graph for Joint Modeling Answer Selection. (arXiv:2203.03549v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.03549","description":"<p>This research studies graph-based approaches for Answer Sentence Selection\n(AS2), an essential component for retrieval-based Question Answering (QA)\nsystems. During offline learning, our model constructs a small-scale relevant\ntraining graph per question in an unsupervised manner, and integrates with\nGraph Neural Networks. Graph nodes are question sentence to answer sentence\npairs. We train and integrate state-of-the-art (SOTA) models for computing\nscores between question-question, question-answer, and answer-answer pairs, and\nuse thresholding on relevance scores for creating graph edges. Online inference\nis then performed to solve the AS2 task on unseen queries. Experiments on two\nwell-known academic benchmarks and a real-world dataset show that our approach\nconsistently outperforms SOTA QA baseline models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Roshni G. Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Thuy Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moschitti_A/0/1/0/all/0/1\">Alessandro Moschitti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yizhou Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Compose Soft Prompts for Compositional Zero-Shot Learning. (arXiv:2204.03574v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2204.03574","description":"<p>We introduce compositional soft prompting (CSP), a parameter-efficient\nlearning technique to improve the zero-shot compositionality of large-scale\npretrained vision-language models (VLMs) like CLIP. We develop CSP for\ncompositional zero-shot learning, the task of predicting unseen\nattribute-object compositions (e.g., old cat and young tiger). VLMs have a\nflexible text encoder that can represent arbitrary classes as natural language\nprompts but they often underperform task-specific architectures on the\ncompositional zero-shot benchmark datasets. CSP treats the attributes and\nobjects that define classes as learnable tokens of vocabulary. During training,\nthe vocabulary is tuned to recognize classes that compose tokens in multiple\nways (e.g., old cat and white cat). At test time, we recompose the learned\nattribute-object vocabulary in new combinations to recognize novel classes. We\nshow that CSP outperforms the CLIP on benchmark datasets by an average of 10.9\npercentage points on AUC. CSP also outperforms CoOp, a soft prompting method\nthat fine-tunes the prefix context tokens, by an average of 5.8 percentage\npoints on AUC. We perform additional experiments to show that CSP improves\ngeneralization to higher-order attribute-attribute-object compositions (e.g.,\nold white cat) and combinations of pretrained attributes and fine-tuned\nobjects. The code is available at https://github.com/BatsResearch/csp.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nayak_N/0/1/0/all/0/1\">Nihal V. Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Peilin Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bach_S/0/1/0/all/0/1\">Stephen H. Bach</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval Enhanced Data Augmentation for Question Answering on Privacy Policies. (arXiv:2204.08952v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.08952","description":"<p>Prior studies in privacy policies frame the question answering (QA) task as\nidentifying the most relevant text segment or a list of sentences from a policy\ndocument given a user query. Existing labeled datasets are heavily imbalanced\n(only a few relevant segments), limiting the QA performance in this domain. In\nthis paper, we develop a data augmentation framework based on ensembling\nretriever models that captures the relevant text segments from unlabeled policy\ndocuments and expand the positive examples in the training set. In addition, to\nimprove the diversity and quality of the augmented data, we leverage multiple\npre-trained language models (LMs) and cascade them with noise reduction filter\nmodels. Using our augmented data on the PrivacyQA benchmark, we elevate the\nexisting baseline by a large margin (10\\% F1) and achieve a new\nstate-of-the-art F1 score of 50\\%. Our ablation studies provide further\ninsights into the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parvez_M/0/1/0/all/0/1\">Md Rizwan Parvez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1\">Jianfeng Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Thorough Examination on Zero-shot Dense Retrieval. (arXiv:2204.12755v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.12755","description":"<p>Recent years have witnessed the significant advance in dense retrieval (DR)\nbased on powerful pre-trained language models (PLM). DR models have achieved\nexcellent performance in several benchmark datasets, while they are shown to be\nnot as competitive as traditional sparse retrieval models (e.g., BM25) in a\nzero-shot retrieval setting. However, in the related literature, there still\nlacks a detailed and comprehensive study on zero-shot retrieval. In this paper,\nwe present the first thorough examination of the zero-shot capability of DR\nmodels. We aim to identify the key factors and analyze how they affect\nzero-shot retrieval performance. In particular, we discuss the effect of\nseveral key factors related to source training set, analyze the potential bias\nfrom the target dataset, and review and compare existing zero-shot DR models.\nOur findings provide important evidence to better understand and develop\nzero-shot DR models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1\">Yingqi Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qifei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yuchen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Hua Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding EFL Student Idea Generation Strategies for Creative Writing with NLG Tools. (arXiv:2207.01484v3 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2207.01484","description":"<p>Natural language generation (NLG) is a process within artificial intelligence\nwhere computer systems produce human-comprehensible language texts from\ninformation. English as a foreign language (EFL) students' use of NLG tools\nmight facilitate their idea generation, which is fundamental to creative\nwriting. However, little is known about how EFL students interact with NLG\ntools to generate ideas. This study explores strategies adopted by EFL students\nwhen searching for ideas using NLG tools, evaluating ideas generated by NLG\ntools and selecting NLG tools for ideas generation. Four Hong Kong secondary\nschool students attended workshops where they learned to write stories\ncomprising their own words and words generated by NLG tools. After the\nworkshops, they answered questions to reflect on their writing experience with\nNLG tools. In a thematic analysis of the written reflections, we found students\nmay have existing ideas when searching for ideas and evaluating ideas with NLG\ntools. Students showed some aversion to ideas generated by NLG tools and\nselected NLG tools that generated a greater quantity of ideas. The findings\ninform our understanding of EFL students' concerns when using NLG tools for\nidea generation and can inform educators' instruction to implement NLG tools\nfor classroom creative writing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Woo_D/0/1/0/all/0/1\">David James Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susanto_H/0/1/0/all/0/1\">Hengky Susanto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_K/0/1/0/all/0/1\">Kai Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Code Translation with Compiler Representations. (arXiv:2207.03578v5 [cs.PL] UPDATED)","link":"http://arxiv.org/abs/2207.03578","description":"<p>In this paper, we leverage low-level compiler intermediate representations\n(IR) to improve code translation. Traditional transpilers rely on syntactic\ninformation and handcrafted rules, which limits their applicability and\nproduces unnatural-looking code. Applying neural machine translation (NMT)\napproaches to code has successfully broadened the set of programs on which one\ncan get a natural-looking translation. However, they treat the code as\nsequences of text tokens, and still do not differentiate well enough between\nsimilar pieces of code which have different semantics in different languages.\nThe consequence is low quality translation, reducing the practicality of NMT,\nand stressing the need for an approach significantly increasing its accuracy.\nHere we propose to augment code translation with IRs, specifically LLVM IR,\nwith results on the C++, Java, Rust, and Go languages. Our method improves upon\nthe state of the art for unsupervised code translation, increasing the number\nof correct translations by 11% on average, and up to 79% for the Java -&gt; Rust\npair with greedy decoding. We extend previous test sets for code translation,\nby adding hundreds of Go and Rust functions. Additionally, we train models with\nhigh performance on the problem of IR decompilation, generating programming\nsource code from IR, and study using IRs as intermediary pivot for translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Szafraniec_M/0/1/0/all/0/1\">Marc Szafraniec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roziere_B/0/1/0/all/0/1\">Baptiste Roziere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leather_H/0/1/0/all/0/1\">Hugh Leather</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Charton_F/0/1/0/all/0/1\">Francois Charton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Labatut_P/0/1/0/all/0/1\">Patrick Labatut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphCFC: A Directed Graph Based Cross-Modal Feature Complementation Approach for Multimodal Conversational Emotion Recognition. (arXiv:2207.12261v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.12261","description":"<p>Emotion Recognition in Conversation (ERC) plays a significant part in\nHuman-Computer Interaction (HCI) systems since it can provide empathetic\nservices. Multimodal ERC can mitigate the drawbacks of uni-modal approaches.\nRecently, Graph Neural Networks (GNNs) have been widely used in a variety of\nfields due to their superior performance in relation modeling. In multimodal\nERC, GNNs are capable of extracting both long-distance contextual information\nand inter-modal interactive information. Unfortunately, since existing methods\nsuch as MMGCN directly fuse multiple modalities, redundant information may be\ngenerated and diverse information may be lost. In this work, we present a\ndirected Graph based Cross-modal Feature Complementation (GraphCFC) module that\ncan efficiently model contextual and interactive information. GraphCFC\nalleviates the problem of heterogeneity gap in multimodal fusion by utilizing\nmultiple subspace extractors and Pair-wise Cross-modal Complementary (PairCC)\nstrategy. We extract various types of edges from the constructed graph for\nencoding, thus enabling GNNs to extract crucial contextual and interactive\ninformation more accurately when performing message passing. Furthermore, we\ndesign a GNN structure called GAT-MLP, which can provide a new unified network\nframework for multimodal learning. The experimental results on two benchmark\ndatasets show that our GraphCFC outperforms the state-of-the-art (SOTA)\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guoqing Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhigang Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Incorporating Task-specific Concept Knowledge into Script Learning. (arXiv:2209.00068v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.00068","description":"<p>In this paper, we present Tetris, a new task of Goal-Oriented Script\nCompletion. Unlike previous work, it considers a more realistic and general\nsetting, where the input includes not only the goal but also additional user\ncontext, including preferences and history. To address this problem, we propose\na novel approach, which uses two techniques to improve performance: (1) concept\nprompting, and (2) script-oriented contrastive learning that addresses step\nrepetition and hallucination problems. On our WikiHow-based dataset, we find\nthat both methods improve performance. The dataset, repository, and models will\nbe publicly available to facilitate further research on this new task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chenkai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Collocate Visual-Linguistic Neural Modules for Image Captioning. (arXiv:2210.01338v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2210.01338","description":"<p>Humans tend to decompose a sentence into different parts like \\textsc{sth do\nsth at someplace} and then fill each part with certain content. Inspired by\nthis, we follow the \\textit{principle of modular design} to propose a novel\nimage captioner: learning to Collocate Visual-Linguistic Neural Modules\n(CVLNM). Unlike the \\re{widely used} neural module networks in VQA, where the\nlanguage (\\ie, question) is fully observable, \\re{the task of collocating\nvisual-linguistic modules is more challenging.} This is because the language is\nonly partially observable, for which we need to dynamically collocate the\nmodules during the process of image captioning. To sum up, we make the\nfollowing technical contributions to design and train our CVLNM: 1)\n\\textit{distinguishable module design} -- \\re{four modules in the encoder}\nincluding one linguistic module for function words and three visual modules for\ndifferent content words (\\ie, noun, adjective, and verb) and another linguistic\none in the decoder for commonsense reasoning, 2) a self-attention based\n\\textit{module controller} for robustifying the visual reasoning, 3) a\npart-of-speech based \\textit{syntax loss} imposed on the module controller for\nfurther regularizing the training of our CVLNM. Extensive experiments on the\nMS-COCO dataset show that our CVLNM is more effective, \\eg, achieving a new\nstate-of-the-art 129.5 CIDEr-D, and more robust, \\eg, being less likely to\noverfit to dataset bias and suffering less when fewer training samples are\navailable. Codes are available at \\url{https://github.com/GCYZSL/CVLMN}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanwang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1\">Jianfei Cai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Unified Encoder-Decoder Framework with Entity Memory. (arXiv:2210.03273v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.03273","description":"<p>Entities, as important carriers of real-world knowledge, play a key role in\nmany NLP tasks. We focus on incorporating entity knowledge into an\nencoder-decoder framework for informative text generation. Existing approaches\ntried to index, retrieve, and read external documents as evidence, but they\nsuffered from a large computational overhead. In this work, we propose an\nencoder-decoder framework with an entity memory, namely EDMem. The entity\nknowledge is stored in the memory as latent representations, and the memory is\npre-trained on Wikipedia along with encoder-decoder parameters. To precisely\ngenerate entity names, we design three decoding methods to constrain entity\ngeneration by linking entities in the memory. EDMem is a unified framework that\ncan be used on various entity-intensive question answering and generation\ntasks. Extensive experimental results show that EDMem outperforms both\nmemory-based auto-encoder models and non-memory encoder-decoder models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MN-DS: A Multilabeled News Dataset for News Articles Hierarchical Classification. (arXiv:2212.12061v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.12061","description":"<p>This article presents a dataset of 10,917 news articles with hierarchical\nnews categories collected between 1 January 2019 and 31 December 2019. We\nmanually labeled the articles based on a hierarchical taxonomy with 17\nfirst-level and 109 second-level categories. This dataset can be used to train\nmachine learning models for automatically classifying news articles by topic.\nThis dataset can be helpful for researchers working on news structuring,\nclassification, and predicting future events based on released news.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petukhova_A/0/1/0/all/0/1\">Alina Petukhova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fachada_N/0/1/0/all/0/1\">Nuno Fachada</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Multimodal Data Augmentation in Feature Space. (arXiv:2212.14453v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.14453","description":"<p>The ability to jointly learn from multiple modalities, such as text, audio,\nand visual data, is a defining feature of intelligent systems. While there have\nbeen promising advances in designing neural networks to harness multimodal\ndata, the enormous success of data augmentation currently remains limited to\nsingle-modality tasks like image classification. Indeed, it is particularly\ndifficult to augment each modality while preserving the overall semantic\nstructure of the data; for example, a caption may no longer be a good\ndescription of an image after standard augmentations have been applied, such as\ntranslation. Moreover, it is challenging to specify reasonable transformations\nthat are not tailored to a particular modality. In this paper, we introduce\nLeMDA, Learning Multimodal Data Augmentation, an easy-to-use method that\nautomatically learns to jointly augment multimodal data in feature space, with\nno constraints on the identities of the modalities or the relationship between\nmodalities. We show that LeMDA can (1) profoundly improve the performance of\nmultimodal deep learning architectures, (2) apply to combinations of modalities\nthat have not been previously considered, and (3) achieve state-of-the-art\nresults on a wide range of applications comprised of image, text, and tabular\ndata.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zichang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zhiqiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingjian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1\">Anshumali Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages. (arXiv:2302.08956v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08956","description":"<p>Africa is home to over 2000 languages from over six language families and has\nthe highest linguistic diversity among all continents. This includes 75\nlanguages with at least one million speakers each. Yet, there is little NLP\nresearch conducted on African languages. Crucial in enabling such research is\nthe availability of high-quality annotated datasets. In this paper, we\nintroduce AfriSenti, which consists of 14 sentiment datasets of 110,000+ tweets\nin 14 African languages (Amharic, Algerian Arabic, Hausa, Igbo, Kinyarwanda,\nMoroccan Arabic, Mozambican Portuguese, Nigerian Pidgin, Oromo, Swahili,\nTigrinya, Twi, Xitsonga, and Yor\\`ub\\'a) from four language families annotated\nby native speakers. The data is used in SemEval 2023 Task 12, the first\nAfro-centric SemEval shared task. We describe the data collection methodology,\nannotation process, and related challenges when curating each of the datasets.\nWe conduct experiments with different sentiment classification baselines and\ndiscuss their usefulness. We hope AfriSenti enables new work on\nunder-represented languages. The dataset is available at\nhttps://github.com/afrisenti-semeval/afrisent-semeval-2023 and can also be\nloaded as a huggingface datasets\n(https://huggingface.co/datasets/shmuhammad/AfriSenti).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muhammad_S/0/1/0/all/0/1\">Shamsuddeen Hassan Muhammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdulmumin_I/0/1/0/all/0/1\">Idris Abdulmumin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ayele_A/0/1/0/all/0/1\">Abinew Ali Ayele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ousidhoum_N/0/1/0/all/0/1\">Nedjma Ousidhoum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yimam_S/0/1/0/all/0/1\">Seid Muhie Yimam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_I/0/1/0/all/0/1\">Ibrahim Sa&#x27;id Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beloucif_M/0/1/0/all/0/1\">Meriem Beloucif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1\">Sebastian Ruder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hourrane_O/0/1/0/all/0/1\">Oumaima Hourrane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brazdil_P/0/1/0/all/0/1\">Pavel Brazdil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_F/0/1/0/all/0/1\">Felermino D&#xe1;rio M&#xe1;rio Ant&#xf3;nio Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+David_D/0/1/0/all/0/1\">Davis David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osei_S/0/1/0/all/0/1\">Salomey Osei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bello_B/0/1/0/all/0/1\">Bello Shehu Bello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibrahim_F/0/1/0/all/0/1\">Falalu Ibrahim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gwadabe_T/0/1/0/all/0/1\">Tajuddeen Gwadabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rutunda_S/0/1/0/all/0/1\">Samuel Rutunda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belay_T/0/1/0/all/0/1\">Tadesse Belay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messelle_W/0/1/0/all/0/1\">Wendimu Baye Messelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balcha_H/0/1/0/all/0/1\">Hailu Beshada Balcha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chala_S/0/1/0/all/0/1\">Sisay Adugna Chala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gebremichael_H/0/1/0/all/0/1\">Hagos Tesfahun Gebremichael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Opoku_B/0/1/0/all/0/1\">Bernard Opoku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arthur_S/0/1/0/all/0/1\">Steven Arthur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UZH_CLyp at SemEval-2023 Task 9: Head-First Fine-Tuning and ChatGPT Data Generation for Cross-Lingual Learning in Tweet Intimacy Prediction. (arXiv:2303.01194v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.01194","description":"<p>This paper describes the submission of UZH_CLyp for the SemEval 2023 Task 9\n\"Multilingual Tweet Intimacy Analysis\". We achieved second-best results in all\n10 languages according to the official Pearson's correlation regression\nevaluation measure. Our cross-lingual transfer learning approach explores the\nbenefits of using a Head-First Fine-Tuning method (HeFiT) that first updates\nonly the regression head parameters and then also updates the pre-trained\ntransformer encoder parameters at a reduced learning rate. Additionally, we\nstudy the impact of using a small set of automatically generated examples (in\nour case, from ChatGPT) for low-resource settings where no human-labeled data\nis available. Our study shows that HeFiT stabilizes training and consistently\nimproves results for pre-trained models that lack domain adaptation to tweets.\nOur study also shows a noticeable performance increase in cross-lingual\nlearning when synthetic data is used, confirming the usefulness of current text\ngeneration systems to improve zero-shot baseline results. Finally, we examine\nhow possible inconsistencies in the annotated data contribute to cross-lingual\ninterference issues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Michail_A/0/1/0/all/0/1\">Andrianos Michail</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konstantinou_S/0/1/0/all/0/1\">Stefanos Konstantinou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clematide_S/0/1/0/all/0/1\">Simon Clematide</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lon-ea at SemEval-2023 Task 11: A Comparison of Activation Functions for Soft and Hard Label Prediction. (arXiv:2303.02468v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.02468","description":"<p>We study the influence of different activation functions in the output layer\nof deep neural network models for soft and hard label prediction in the\nlearning with disagreement task. In this task, the goal is to quantify the\namount of disagreement via predicting soft labels. To predict the soft labels,\nwe use BERT-based preprocessors and encoders and vary the activation function\nused in the output layer, while keeping other parameters constant. The soft\nlabels are then used for the hard label prediction. The activation functions\nconsidered are sigmoid as well as a step-function that is added to the model\npost-training and a sinusoidal activation function, which is introduced for the\nfirst time in this paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_P/0/1/0/all/0/1\">Peyman Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mehran Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Azzawi_S/0/1/0/all/0/1\">Sana Sabah Al-Azzawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castro_I/0/1/0/all/0/1\">Ignacio Castro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1\">Matthew Purver</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeltaScore: Story Evaluation with Perturbations. (arXiv:2303.08991v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.08991","description":"<p>Various evaluation metrics exist for natural language generation tasks, but\nthey have limited utility for story generation since they generally do not\ncorrelate well with human judgments and are not designed to evaluate\nfine-grained story aspects, such as fluency and relatedness. In this paper, we\npropose deltascore, an approach that utilizes perturbation to evaluate\nfine-grained story aspects. Our core idea is based on the hypothesis that the\nbetter the story performs in a specific aspect (e.g., fluency), the more it\nwill be affected by a particular perturbation (e.g., introducing typos). To\nmeasure the impact, we calculate the likelihood difference between the pre- and\npost-perturbation stories using large pre-trained language models. We evaluate\ndeltascore against state-of-the-art model-based and traditional\nsimilarity-based metrics across two story domains, and investigate its\ncorrelation with human judgments on five fine-grained story aspects: fluency,\ncoherence, relatedness, logicality, and interestingness. The findings of our\nstudy indicate that the deltascore approach exhibits exceptional performance in\nevaluating intricate story aspects. An unexpected discovery was made in our\nexperiment, where a single perturbation method was found to effectively capture\na majority of these aspects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1\">Zhuohan Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Miao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1\">Trevor Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_J/0/1/0/all/0/1\">Jey Han Lau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection. (arXiv:2303.09314v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09314","description":"<p>Multimodal hate detection, which aims to identify harmful content online such\nas memes, is crucial for building a wholesome internet environment. Previous\nwork has made enlightening exploration in detecting explicit hate remarks.\nHowever, most of their approaches neglect the analysis of implicit harm, which\nis particularly challenging as explicit text markers and demographic visual\ncues are often twisted or missing. The leveraged cross-modal attention\nmechanisms also suffer from the distributional modality gap and lack logical\ninterpretability. To address these semantic gaps issues, we propose TOT: a\ntopology-aware optimal transport framework to decipher the implicit harm in\nmemes scenario, which formulates the cross-modal aligning problem as solutions\nfor optimal transportation plans. Specifically, we leverage an optimal\ntransport kernel method to capture complementary information from multiple\nmodalities. The kernel embedding provides a non-linear transformation ability\nto reproduce a kernel Hilbert space (RKHS), which reflects significance for\neliminating the distributional modality gap. Moreover, we perceive the topology\ninformation based on aligned representations to conduct bipartite graph path\nreasoning. The newly achieved state-of-the-art performance on two publicly\navailable benchmark datasets, together with further visual analysis,\ndemonstrate the superiority of TOT in capturing implicit cross-modal alignment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Linhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Li Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1\">Guangluan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zequn Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nayu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shiyao Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-View Zero-Shot Open Intent Induction from Dialogues: Multi Domain Batch and Proxy Gradient Transfer. (arXiv:2303.13099v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13099","description":"<p>In Task Oriented Dialogue (TOD) system, detecting and inducing new intents\nare two main challenges to apply the system in the real world. In this paper,\nwe suggest the semantic multi-view model to resolve these two challenges: (1)\nSBERT for General Embedding (GE), (2) Multi Domain Batch (MDB) for dialogue\ndomain knowledge, and (3) Proxy Gradient Transfer (PGT) for cluster-specialized\nsemantic. MDB feeds diverse dialogue datasets to the model at once to tackle\nthe multi-domain problem by learning the multiple domain knowledge. We\nintroduce a novel method PGT, which employs the Siamese network to fine-tune\nthe model with a clustering method directly.Our model can learn how to cluster\ndialogue utterances by using PGT. Experimental results demonstrate that our\nmulti-view model with MDB and PGT significantly improves the Open Intent\nInduction performance compared to baseline systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koh_H/0/1/0/all/0/1\">Hyukhun Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyun_H/0/1/0/all/0/1\">Haesung Pyun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1\">Nakyeong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyomin Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Semantic Reader Project: Augmenting Scholarly Documents through AI-Powered Interactive Reading Interfaces. (arXiv:2303.14334v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2303.14334","description":"<p>Scholarly publications are key to the transfer of knowledge from scholars to\nothers. However, research papers are information-dense, and as the volume of\nthe scientific literature grows, the need for new technology to support the\nreading process grows. In contrast to the process of finding papers, which has\nbeen transformed by Internet technology, the experience of reading research\npapers has changed little in decades. The PDF format for sharing research\npapers is widely used due to its portability, but it has significant downsides\nincluding: static content, poor accessibility for low-vision readers, and\ndifficulty reading on mobile devices. This paper explores the question \"Can\nrecent advances in AI and HCI power intelligent, interactive, and accessible\nreading interfaces -- even for legacy PDFs?\" We describe the Semantic Reader\nProject, a collaborative effort across multiple institutions to explore\nautomatic creation of dynamic reading interfaces for research papers. Through\nthis project, we've developed ten research prototype interfaces and conducted\nusability studies with more than 300 participants and real-world users showing\nimproved reading experiences for scholars. We've also released a production\nreading interface for research papers that will incorporate the best features\nas they mature. We structure this paper around challenges scholars and the\npublic face when reading research papers -- Discovery, Efficiency,\nComprehension, Synthesis, and Accessibility -- and present an overview of our\nprogress and remaining open challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">Kyle Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Joseph Chee Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Head_A/0/1/0/all/0/1\">Andrew Head</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bragg_J/0/1/0/all/0/1\">Jonathan Bragg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy X. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trier_C/0/1/0/all/0/1\">Cassidy Trier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasiades_C/0/1/0/all/0/1\">Chloe Anastasiades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+August_T/0/1/0/all/0/1\">Tal August</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Authur_R/0/1/0/all/0/1\">Russell Authur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bragg_D/0/1/0/all/0/1\">Danielle Bragg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bransom_E/0/1/0/all/0/1\">Erin Bransom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cachola_I/0/1/0/all/0/1\">Isabel Cachola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Candra_S/0/1/0/all/0/1\">Stefan Candra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandrasekhar_Y/0/1/0/all/0/1\">Yoganand Chandrasekhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Sung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_E/0/1/0/all/0/1\">Evie Yu-Yen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1\">Yvonne Chou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_R/0/1/0/all/0/1\">Rob Evans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fok_R/0/1/0/all/0/1\">Raymond Fok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_F/0/1/0/all/0/1\">Fangzhou Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huff_R/0/1/0/all/0/1\">Regan Huff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Tae Soo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kinney_R/0/1/0/all/0/1\">Rodney Kinney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kittur_A/0/1/0/all/0/1\">Aniket Kittur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1\">Hyeonsu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klevak_E/0/1/0/all/0/1\">Egor Klevak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuehl_B/0/1/0/all/0/1\">Bailey Kuehl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langan_M/0/1/0/all/0/1\">Michael Langan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latzke_M/0/1/0/all/0/1\">Matt Latzke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lochner_J/0/1/0/all/0/1\">Jaron Lochner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacMillan_K/0/1/0/all/0/1\">Kelsey MacMillan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marsh_E/0/1/0/all/0/1\">Eric Marsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_T/0/1/0/all/0/1\">Tyler Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_A/0/1/0/all/0/1\">Aakanksha Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngoc-Uyen Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palani_S/0/1/0/all/0/1\">Srishti Palani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Soya Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulic_C/0/1/0/all/0/1\">Caroline Paulic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rachatasumrit_N/0/1/0/all/0/1\">Napol Rachatasumrit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1\">Smita Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sayre_P/0/1/0/all/0/1\">Paul Sayre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zejiang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siangliulue_P/0/1/0/all/0/1\">Pao Siangliulue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1\">Luca Soldaini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Huy Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuylen_M/0/1/0/all/0/1\">Madeleine van Zuylen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lucy Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilhelm_C/0/1/0/all/0/1\">Christopher Wilhelm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Caroline Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jiangjiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamarron_A/0/1/0/all/0/1\">Angele Zamarron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hearst_M/0/1/0/all/0/1\">Marti A. Hearst</a>, et al. (1 additional author not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"$\\varepsilon$ K\\'U <MASK>: Integrating Yor\\`ub\\'a cultural greetings into machine translation. (arXiv:2303.17972v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.17972","description":"<p>This paper investigates the performance of massively multilingual neural\nmachine translation (NMT) systems in translating Yor\\`ub\\'a greetings\n($\\varepsilon$ k\\'u [MASK]), which are a big part of Yor\\`ub\\'a language and\nculture, into English. To evaluate these models, we present IkiniYor\\`ub\\'a, a\nYor\\`ub\\'a-English translation dataset containing some Yor\\`ub\\'a greetings,\nand sample use cases. We analysed the performance of different multilingual NMT\nsystems including Google and NLLB and show that these models struggle to\naccurately translate Yor\\`ub\\'a greetings into English. In addition, we trained\na Yor\\`ub\\'a-English model by finetuning an existing NMT model on the training\nsplit of IkiniYor\\`ub\\'a and this achieved better performance when compared to\nthe pre-trained multilingual NMT models, although they were trained on a large\nvolume of data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akinade_I/0/1/0/all/0/1\">Idris Akinade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alabi_J/0/1/0/all/0/1\">Jesujoba Alabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Adelani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Odoje_C/0/1/0/all/0/1\">Clement Odoje</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Large Language Models. (arXiv:2303.18223v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.18223","description":"<p>Language is essentially a complex, intricate system of human expressions\ngoverned by grammatical rules. It poses a significant challenge to develop\ncapable AI algorithms for comprehending and grasping a language. As a major\napproach, language modeling has been widely studied for language understanding\nand generation in the past two decades, evolving from statistical language\nmodels to neural language models. Recently, pre-trained language models (PLMs)\nhave been proposed by pre-training Transformer models over large-scale corpora,\nshowing strong capabilities in solving various NLP tasks. Since researchers\nhave found that model scaling can lead to performance improvement, they further\nstudy the scaling effect by increasing the model size to an even larger size.\nInterestingly, when the parameter scale exceeds a certain level, these enlarged\nlanguage models not only achieve a significant performance improvement but also\nshow some special abilities that are not present in small-scale language\nmodels. To discriminate the difference in parameter scale, the research\ncommunity has coined the term large language models (LLM) for the PLMs of\nsignificant size. Recently, the research on LLMs has been largely advanced by\nboth academia and industry, and a remarkable progress is the launch of ChatGPT,\nwhich has attracted widespread attention from society. The technical evolution\nof LLMs has been making an important impact on the entire AI community, which\nwould revolutionize the way how we develop and use AI algorithms. In this\nsurvey, we review the recent advances of LLMs by introducing the background,\nkey findings, and mainstream techniques. In particular, we focus on four major\naspects of LLMs, namely pre-training, adaptation tuning, utilization, and\ncapacity evaluation. Besides, we also summarize the available resources for\ndeveloping LLMs and discuss the remaining issues for future directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yupeng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1\">Yingqian Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Beichen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zican Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yifan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yushuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jinhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xinyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zikang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers. (arXiv:2304.03518v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03518","description":"<p>This paper describes our submission to Task 10 at SemEval 2023-Explainable\nDetection of Online Sexism (EDOS), divided into three subtasks. The recent rise\nin social media platforms has seen an increase in disproportionate levels of\nsexism experienced by women on social media platforms. This has made detecting\nand explaining online sexist content more important than ever to make social\nmedia safer and more accessible for women. Our approach consists of\nexperimenting and finetuning BERT-based models and using a Majority Voting\nensemble model that outperforms individual baseline model scores. Our system\nachieves a macro F1 score of 0.8392 for Task A, 0.6092 for Task B, and 0.4319\nfor Task C.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rallabandi_S/0/1/0/all/0/1\">Sriya Rallabandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singhal_S/0/1/0/all/0/1\">Sanchit Singhal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seth_P/0/1/0/all/0/1\">Pratinav Seth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Story Discovery from Continuous News Streams via Scalable Thematic Embedding. (arXiv:2304.04099v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2304.04099","description":"<p>Unsupervised discovery of stories with correlated news articles in real-time\nhelps people digest massive news streams without expensive human annotations. A\ncommon approach of the existing studies for unsupervised online story discovery\nis to represent news articles with symbolic- or graph-based embedding and\nincrementally cluster them into stories. Recent large language models are\nexpected to improve the embedding further, but a straightforward adoption of\nthe models by indiscriminately encoding all information in articles is\nineffective to deal with text-rich and evolving news streams. In this work, we\npropose a novel thematic embedding with an off-the-shelf pretrained sentence\nencoder to dynamically represent articles and stories by considering their\nshared temporal themes. To realize the idea for unsupervised online story\ndiscovery, a scalable framework USTORY is introduced with two main techniques,\ntheme- and time-aware dynamic embedding and novelty-aware adaptive clustering,\nfueled by lightweight story summaries. A thorough evaluation with real news\ndata sets demonstrates that USTORY achieves higher story discovery performances\nthan baselines while being robust and scalable to various streaming settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Susik Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongha Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PDFVQA: A New Dataset for Real-World VQA on PDF Documents. (arXiv:2304.06447v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.06447","description":"<p>Document-based Visual Question Answering examines the document understanding\nof document images in conditions of natural language questions. We proposed a\nnew document-based VQA dataset, PDF-VQA, to comprehensively examine the\ndocument understanding from various aspects, including document element\nrecognition, document layout structural understanding as well as contextual\nunderstanding and key information extraction. Our PDF-VQA dataset extends the\ncurrent scale of document understanding that limits on the single document page\nto the new scale that asks questions over the full document of multiple pages.\nWe also propose a new graph-based VQA model that explicitly integrates the\nspatial and hierarchically structural relationships between different document\nelements to boost the document structural understanding. The performances are\ncompared with several baselines over different question types and\ntasks\\footnote{The full dataset will be released after paper acceptance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yihao Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1\">Siwen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Hyunsuk Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Soyeon Caren Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Forecast Stock Price Movements? Return Predictability and Large Language Models. (arXiv:2304.07619v2 [q-fin.ST] UPDATED)","link":"http://arxiv.org/abs/2304.07619","description":"<p>We examine the potential of ChatGPT, and other large language models, in\npredicting stock market returns using sentiment analysis of news headlines. We\nuse ChatGPT to indicate whether a given headline is good, bad, or irrelevant\nnews for firms' stock prices. We then compute a numerical score and document a\npositive correlation between these ChatGPT scores and subsequent daily stock\nmarket returns. Further, ChatGPT outperforms traditional sentiment analysis\nmethods. We find that more basic models such as GPT-1, GPT-2, and BERT cannot\naccurately forecast returns, indicating return predictability is an emerging\ncapacity of complex models. Our results suggest that incorporating advanced\nlanguage models into the investment decision-making process can yield more\naccurate predictions and enhance the performance of quantitative trading\nstrategies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-fin/1/au:+Lopez_Lira_A/0/1/0/all/0/1\">Alejandro Lopez-Lira</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Tang_Y/0/1/0/all/0/1\">Yuehua Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts. (arXiv:2304.09548v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09548","description":"<p>In populous countries, pending legal cases have been growing exponentially.\nThere is a need for developing NLP-based techniques for processing and\nautomatically understanding legal documents. To promote research in the area of\nLegal NLP we organized the shared task LegalEval - Understanding Legal Texts at\nSemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles\nLabeling) is about automatically structuring legal documents into semantically\ncoherent units, Task-B (Legal Named Entity Recognition) deals with identifying\nrelevant entities in a legal document and Task-C (Court Judgement Prediction\nwith Explanation) explores the possibility of automatically predicting the\noutcome of a legal case along with providing an explanation for the prediction.\nIn total 26 teams (approx. 100 participants spread across the world) submitted\nsystems paper. In each of the sub-tasks, the proposed systems outperformed the\nbaselines; however, there is a lot of scope for improvement. This paper\ndescribes the tasks, and analyzes techniques proposed by various teams.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalamkar_P/0/1/0/all/0/1\">Prathamesh Kalamkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karn_S/0/1/0/all/0/1\">Saurabh Karn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1\">Aman Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Abhinav Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanikella_S/0/1/0/all/0/1\">Sai Kiran Tanikella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_S/0/1/0/all/0/1\">Shouvik Kumar Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malhan_S/0/1/0/all/0/1\">Sachin Malhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_V/0/1/0/all/0/1\">Vivek Raghavan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GeneGPT: Augmenting Large Language Models with Domain Tools for Improved Access to Biomedical Information. (arXiv:2304.09667v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09667","description":"<p>While large language models (LLMs) have been successfully applied to various\ntasks, they still face challenges with hallucinations and generating erroneous\ncontent. Augmenting LLMs with domain-specific tools such as database utilities\nhas the potential to facilitate more precise and straightforward access to\nspecialized knowledge. In this paper, we present GeneGPT, a novel method for\nteaching LLMs to use the Web Application Programming Interfaces (APIs) of the\nNational Center for Biotechnology Information (NCBI) and answer genomics\nquestions. Specifically, we prompt Codex (code-davinci-002) to solve the\nGeneTuring tests with few-shot URL requests of NCBI API calls as demonstrations\nfor in-context learning. During inference, we stop the decoding once a call\nrequest is detected and make the API call with the generated URL. We then\nappend the raw execution results returned by NCBI APIs to the generated texts\nand continue the generation until the answer is found or another API call is\ndetected. Our preliminary results show that GeneGPT achieves state-of-the-art\nresults on three out of four one-shot tasks and four out of five zero-shot\ntasks in the GeneTuring dataset. Overall, GeneGPT achieves a macro-average\nscore of 0.76, which is much higher than retrieval-augmented LLMs such as the\nNew Bing (0.44), biomedical LLMs such as BioMedLM (0.08) and BioGPT (0.04), as\nwell as other LLMs such as GPT-3 (0.16) and ChatGPT (0.12).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Latent Space Theory for Emergent Abilities in Large Language Models. (arXiv:2304.09960v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09960","description":"<p>Languages are not created randomly but rather to communicate information.\nThere is a strong association between languages and their underlying meanings,\nresulting in a sparse joint distribution that is heavily peaked according to\ntheir correlations. Moreover, these peak values happen to match with the\nmarginal distribution of languages due to the sparsity. With the advent of LLMs\ntrained on big data and large models, we can now precisely assess the marginal\ndistribution of languages, providing a convenient means of exploring the sparse\nstructures in the joint distribution for effective inferences. In this paper,\nwe categorize languages as either unambiguous or {\\epsilon}-ambiguous and\npresent quantitative results to demonstrate that the emergent abilities of\nLLMs, such as language understanding, in-context learning, chain-of-thought\nprompting, and effective instruction fine-tuning, can all be attributed to\nBayesian inference on the sparse joint distribution of languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hui Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Reproduce Human-Generated Labels? A Study of Social Computing Tasks. (arXiv:2304.10145v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.10145","description":"<p>The release of ChatGPT has uncovered a range of possibilities whereby large\nlanguage models (LLMs) can substitute human intelligence. In this paper, we\nseek to understand whether ChatGPT has the potential to reproduce\nhuman-generated label annotations in social computing tasks. Such an\nachievement could significantly reduce the cost and complexity of social\ncomputing research. As such, we use ChatGPT to relabel five seminal datasets\ncovering stance detection (2x), sentiment analysis, hate speech, and bot\ndetection. Our results highlight that ChatGPT does have the potential to handle\nthese data annotation tasks, although a number of challenges remain. ChatGPT\nobtains an average accuracy 0.609. Performance is highest for the sentiment\nanalysis dataset, with ChatGPT correctly annotating 64.9% of tweets. Yet, we\nshow that performance varies substantially across individual labels. We believe\nthis work can open up new lines of analysis and act as a basis for future\nresearch into the exploitation of ChatGPT for human annotation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yiming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peixian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haq_E/0/1/0/all/0/1\">Ehsan-Ul Haq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_P/0/1/0/all/0/1\">Pan Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tyson_G/0/1/0/all/0/1\">Gareth Tyson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Program with Natural Language. (arXiv:2304.10464v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.10464","description":"<p>Large Language Models (LLMs) have shown remarkable performance in various\nbasic natural language tasks, which raises hopes for achieving Artificial\nGeneral Intelligence. To better complete complex tasks, we need LLMs to program\nfor the task and then follow the program to generate a specific solution for\nthe test sample. We propose using natural language as a new programming\nlanguage to describe task procedures, making them easily understandable to both\nhumans and LLMs. LLMs are capable of directly generating natural language\nprograms, but these programs may still contain factual errors or incomplete\nsteps. Therefore, we further propose the Learning to Program (LP) method to ask\nLLMs themselves to learn natural language programs from the training dataset of\ncomplex tasks and then use the learned program to guide inference. Our\nexperiments on the AMPS (high school math) and Math (competition mathematics\nproblems) datasets demonstrate the effectiveness of our approach. When testing\nChatGPT on 10 tasks from the AMPS dataset, our LP method's average performance\noutperformed the direct zero-shot test performance by 18.3$\\%$. We release our\ncode at \\url{https://github.com/microsoft/NaturalLanguageProgram}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiduo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaobo Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenfei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenshan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named Entity Recognition using Knowledge Bases. (arXiv:2304.10637v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.10637","description":"<p>Named Entity Recognition (NER) is a core natural language processing task in\nwhich pre-trained language models have shown remarkable performance. However,\nstandard benchmarks like CoNLL 2003 do not address many of the challenges that\ndeployed NER systems face, such as having to classify emerging or complex\nentities in a fine-grained way. In this paper we present a novel NER cascade\napproach comprising three steps: first, identifying candidate entities in the\ninput sentence; second, linking the each candidate to an existing knowledge\nbase; third, predicting the fine-grained category for each entity candidate. We\nempirically demonstrate the significance of external knowledge bases in\naccurately classifying fine-grained and emerging entities. Our system exhibits\nrobust performance in the MultiCoNER2 shared task, even in the low-resource\nlanguage setting where we leverage knowledge bases of high-resource languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Ferrero_I/0/1/0/all/0/1\">Iker Garc&#xed;a-Ferrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campos_J/0/1/0/all/0/1\">Jon Ander Campos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainz_O/0/1/0/all/0/1\">Oscar Sainz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salaberria_A/0/1/0/all/0/1\">Ander Salaberria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text2Time: Transformer-based Article Time Period Prediction. (arXiv:2304.10859v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.10859","description":"<p>The task of predicting the publication period of text documents, such as news\narticles, is an important but less studied problem in the field of natural\nlanguage processing. Predicting the year of a news article can be useful in\nvarious contexts, such as historical research, sentiment analysis, and media\nmonitoring. In this work, we investigate the problem of predicting the\npublication period of a text document, specifically a news article, based on\nits textual content. In order to do so, we created our own extensive labeled\ndataset of over 350,000 news articles published by The New York Times over six\ndecades. In our approach, we use a pretrained BERT model fine-tuned for the\ntask of text classification, specifically for time period prediction.This model\nexceeds our expectations and provides some very impressive results in terms of\naccurately classifying news articles into their respective publication decades.\nThe results beat the performance of the baseline model for this relatively\nunexplored task of time prediction from text.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gunasekaran_K/0/1/0/all/0/1\">Karthick Prasad Gunasekaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babrich_B/0/1/0/all/0/1\">B Chase Babrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shirodkar_S/0/1/0/all/0/1\">Saurabh Shirodkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1\">Hee Hwang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-04-24T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}