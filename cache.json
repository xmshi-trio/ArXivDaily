{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-18T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults. (arXiv:2309.07927v1 [eess.AS])","link":"http://arxiv.org/abs/2309.07927","description":"<p>Recent advancements in Automatic Speech Recognition (ASR) systems,\nexemplified by Whisper, have demonstrated the potential of these systems to\napproach human-level performance given sufficient data. However, this progress\ndoesn't readily extend to ASR for children due to the limited availability of\nsuitable child-specific databases and the distinct characteristics of\nchildren's speech. A recent study investigated leveraging the My Science Tutor\n(MyST) children's speech corpus to enhance Whisper's performance in recognizing\nchildren's speech. This paper builds on these findings by enhancing the utility\nof the MyST dataset through more efficient data preprocessing. We also\nhighlight important challenges towards improving children's ASR performance.\nThe results showcase the viable and efficient integration of Whisper for\neffective children's speech recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Attia_A/0/1/0/all/0/1\">Ahmed Adel Attia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ai_W/0/1/0/all/0/1\">Wei Ai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Demszky_D/0/1/0/all/0/1\">Dorottya Demszky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Espy_Wilson_C/0/1/0/all/0/1\">Carol Espy-Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Contextual Information for Effective Entity Salience Detection. (arXiv:2309.07990v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07990","description":"<p>In text documents such as news articles, the content and key events usually\nrevolve around a subset of all the entities mentioned in a document. These\nentities, often deemed as salient entities, provide useful cues of the\naboutness of a document to a reader. Identifying the salience of entities was\nfound helpful in several downstream applications such as search, ranking, and\nentity-centric summarization, among others. Prior work on salient entity\ndetection mainly focused on machine learning models that require heavy feature\nengineering. We show that fine-tuning medium-sized language models with a\ncross-encoder style architecture yields substantial performance gains over\nfeature engineering approaches. To this end, we conduct a comprehensive\nbenchmarking of four publicly available datasets using models representative of\nthe medium-sized pre-trained language model family. Additionally, we show that\nzero-shot prompting of instruction-tuned language models yields inferior\nresults, indicating the task's uniqueness and complexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhowmik_R/0/1/0/all/0/1\">Rajarshi Bhowmik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponza_M/0/1/0/all/0/1\">Marco Ponza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tendle_A/0/1/0/all/0/1\">Atharva Tendle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Anant Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1\">Rebecca Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xingyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qian Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preotiuc-Pietro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Impact of Human Evaluator Group on Chat-Oriented Dialogue Evaluation. (arXiv:2309.07998v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07998","description":"<p>Human evaluation has been widely accepted as the standard for evaluating\nchat-oriented dialogue systems. However, there is a significant variation in\nprevious work regarding who gets recruited as evaluators. Evaluator groups such\nas domain experts, university students, and professional annotators have been\nused to assess and compare dialogue systems, although it is unclear to what\nextent the choice of an evaluator group can affect results. This paper analyzes\nthe evaluator group impact on dialogue system evaluation by testing 4\nstate-of-the-art dialogue systems using 4 distinct evaluator groups. Our\nanalysis reveals a robustness towards evaluator groups for Likert evaluations\nthat is not seen for Pairwise, with only minor differences observed when\nchanging evaluator groups. Furthermore, two notable limitations to this\nrobustness are observed, which reveal discrepancies between evaluators with\ndifferent levels of chatbot expertise and indicate that evaluator objectivity\nis beneficial for certain dialogue metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Finch_S/0/1/0/all/0/1\">Sarah E. Finch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finch_J/0/1/0/all/0/1\">James D. Finch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiariST: Streaming Speech Translation with Speaker Diarization. (arXiv:2309.08007v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08007","description":"<p>End-to-end speech translation (ST) for conversation recordings involves\nseveral under-explored challenges such as speaker diarization (SD) without\naccurate word time stamps and handling of overlapping speech in a streaming\nfashion. In this work, we propose DiariST, the first streaming ST and SD\nsolution. It is built upon a neural transducer-based streaming ST system and\nintegrates token-level serialized output training and t-vector, which were\noriginally developed for multi-talker speech recognition. Due to the absence of\nevaluation benchmarks in this area, we develop a new evaluation dataset,\nDiariST-AliMeeting, by translating the reference Chinese transcriptions of the\nAliMeeting corpus into English. We also propose new metrics, called\nspeaker-agnostic BLEU and speaker-attributed BLEU, to measure the ST quality\nwhile taking SD accuracy into account. Our system achieves a strong ST and SD\ncapability compared to offline systems based on Whisper, while performing\nstreaming inference for overlapping speech. To facilitate the research in this\nnew direction, we release the evaluation data, the offline baseline systems,\nand the evaluation code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_M/0/1/0/all/0/1\">Mu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1\">Naoyuki Kanda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofei Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xue_J/0/1/0/all/0/1\">Jian Xue</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yoshioka_T/0/1/0/all/0/1\">Takuya Yoshioka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing. (arXiv:2309.08008v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08008","description":"<p>Large language models (LLMs) have shown remarkable capabilities in Natural\nLanguage Processing (NLP), especially in domains where labeled data is scarce\nor expensive, such as clinical domain. However, to unlock the clinical\nknowledge hidden in these LLMs, we need to design effective prompts that can\nguide them to perform specific clinical NLP tasks without any task-specific\ntraining data. This is known as in-context learning, which is an art and\nscience that requires understanding the strengths and weaknesses of different\nLLMs and prompt engineering approaches. In this paper, we present a\ncomprehensive and systematic experimental study on prompt engineering for five\nclinical NLP tasks: Clinical Sense Disambiguation, Biomedical Evidence\nExtraction, Coreference Resolution, Medication Status Extraction, and\nMedication Attribute Extraction. We assessed the prompts proposed in recent\nliterature, including simple prefix, simple cloze, chain of thought, and\nanticipatory prompts, and introduced two new types of prompts, namely heuristic\nprompting and ensemble prompting. We evaluated the performance of these prompts\non three state-of-the-art LLMs: GPT-3.5, BARD, and LLAMA2. We also contrasted\nzero-shot prompting with few-shot prompting, and provide novel insights and\nguidelines for prompt engineering for LLMs in clinical NLP. To the best of our\nknowledge, this is one of the first works on the empirical evaluation of\ndifferent prompt engineering approaches for clinical NLP in this era of\ngenerative AI, and we hope that it will inspire and inform future research in\nthis area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sivarajkumar_S/0/1/0/all/0/1\">Sonish Sivarajkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kelley_M/0/1/0/all/0/1\">Mark Kelley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samolyk_Mazzanti_A/0/1/0/all/0/1\">Alyssa Samolyk-Mazzanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Visweswaran_S/0/1/0/all/0/1\">Shyam Visweswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanshan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement. (arXiv:2309.08030v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08030","description":"<p>Speech enhancement systems are typically trained using pairs of clean and\nnoisy speech. In audio-visual speech enhancement (AVSE), there is not as much\nground-truth clean data available; most audio-visual datasets are collected in\nreal-world environments with background noise and reverberation, hampering the\ndevelopment of AVSE. In this work, we introduce AV2Wav, a resynthesis-based\naudio-visual speech enhancement approach that can generate clean speech despite\nthe challenges of real-world training data. We obtain a subset of nearly clean\nspeech from an audio-visual corpus using a neural quality estimator, and then\ntrain a diffusion model on this subset to generate waveforms conditioned on\ncontinuous speech representations from AV-HuBERT with noise-robust training. We\nuse continuous rather than discrete representations to retain prosody and\nspeaker information. With this vocoding task alone, the model can perform\nspeech enhancement better than a masking-based baseline. We further fine-tune\nthe diffusion model on clean/noisy utterance pairs to improve the performance.\nOur approach outperforms a masking-based baseline in terms of both automatic\nmetrics and a human listening test and is close in quality to the target speech\nin the listening test. Audio samples can be found at\nhttps://home.ttic.edu/~jcchou/demo/avse/avse_demo.html.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Chou_J/0/1/0/all/0/1\">Ju-Chieh Chou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chien_C/0/1/0/all/0/1\">Chung-Ming Chien</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Livescu_K/0/1/0/all/0/1\">Karen Livescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Gender Bias in News Summarization. (arXiv:2309.08047v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08047","description":"<p>Summarization is an important application of large language models (LLMs).\nMost previous evaluation of summarization models has focused on their\nperformance in content selection, grammaticality and coherence. However, it is\nwell known that LLMs reproduce and reinforce harmful social biases. This raises\nthe question: Do these biases affect model outputs in a relatively constrained\nsetting like summarization?\n</p>\n<p>To help answer this question, we first motivate and introduce a number of\ndefinitions for biased behaviours in summarization models, along with practical\nmeasures to quantify them. Since we find biases inherent to the input document\ncan confound our analysis, we additionally propose a method to generate input\ndocuments with carefully controlled demographic attributes. This allows us to\nsidestep this issue, while still working with somewhat realistic input\ndocuments.\n</p>\n<p>Finally, we apply our measures to summaries generated by both purpose-built\nsummarization models and general purpose chat models. We find that content\nselection in single document summarization seems to be largely unaffected by\nbias, while hallucinations exhibit evidence of biases propagating to generated\nsummaries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Steen_J/0/1/0/all/0/1\">Julius Steen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Markert_K/0/1/0/all/0/1\">Katja Markert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Connecting the Dots in News Analysis: A Cross-Disciplinary Survey of Media Bias and Framing. (arXiv:2309.08069v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08069","description":"<p>The manifestation and effect of bias in news reporting have been central\ntopics in the social sciences for decades, and have received increasing\nattention in the NLP community recently. While NLP can help to scale up\nanalyses or contribute automatic procedures to investigate the impact of biased\nnews in society, we argue that methodologies that are currently dominant fall\nshort of addressing the complex questions and effects addressed in theoretical\nmedia studies. In this survey paper, we review social science approaches and\ndraw a comparison with typical task formulations, methods, and evaluation\nmetrics used in the analysis of media bias in NLP. We discuss open questions\nand suggest possible directions to close identified gaps between theory and\npredictive models, and their evaluation. These include model transparency,\nconsidering document-external information, and cross-document reasoning rather\nthan single-label assignment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_G/0/1/0/all/0/1\">Gisela Vallejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frermann_L/0/1/0/all/0/1\">Lea Frermann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Characterizing the temporal dynamics of universal speech representations for generalizable deepfake detection. (arXiv:2309.08099v1 [cs.SD])","link":"http://arxiv.org/abs/2309.08099","description":"<p>Existing deepfake speech detection systems lack generalizability to unseen\nattacks (i.e., samples generated by generative algorithms not seen during\ntraining). Recent studies have explored the use of universal speech\nrepresentations to tackle this issue and have obtained inspiring results. These\nworks, however, have focused on innovating downstream classifiers while leaving\nthe representation itself untouched. In this study, we argue that\ncharacterizing the long-term temporal dynamics of these representations is\ncrucial for generalizability and propose a new method to assess representation\ndynamics. Indeed, we show that different generative models generate similar\nrepresentation dynamics patterns with our proposed method. Experiments on the\nASVspoof 2019 and 2021 datasets validate the benefits of the proposed method to\ndetect deepfakes from methods unseen during training, significantly improving\non several benchmark methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Powar_S/0/1/0/all/0/1\">Saurabh Powar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Falk_T/0/1/0/all/0/1\">Tiago H. Falk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information. (arXiv:2309.08100v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08100","description":"<p>To address the issue of poor embedding performance in the knowledge graph of\na programming design course, a joint represen-tation learning model that\ncombines entity neighborhood infor-mation and description information is\nproposed. Firstly, a graph at-tention network is employed to obtain the\nfeatures of entity neigh-boring nodes, incorporating relationship features to\nenrich the structural information. Next, the BERT-WWM model is utilized in\nconjunction with attention mechanisms to obtain the representation of entity\ndescription information. Finally, the final entity vector representation is\nobtained by combining the vector representations of entity neighborhood\ninformation and description information. Experimental results demonstrate that\nthe proposed model achieves favorable performance on the knowledge graph\ndataset of the pro-gramming design course, outperforming other baseline models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Le Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_X/0/1/0/all/0/1\">Xin Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhua Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_M/0/1/0/all/0/1\">Miaolei Deng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech Using Natural Language Descriptions. (arXiv:2309.08140v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08140","description":"<p>We propose PromptTTS++, a prompt-based text-to-speech (TTS) synthesis system\nthat allows control over speaker identity using natural language descriptions.\nTo control speaker identity within the prompt-based TTS framework, we introduce\nthe concept of speaker prompt, which describes voice characteristics (e.g.,\ngender-neutral, young, old, and muffled) designed to be approximately\nindependent of speaking style. Since there is no large-scale dataset containing\nspeaker prompts, we first construct a dataset based on the LibriTTS-R corpus\nwith manually annotated speaker prompts. We then employ a diffusion-based\nacoustic model with mixture density networks to model diverse speaker factors\nin the training data. Unlike previous studies that rely on style prompts\ndescribing only a limited aspect of speaker individuality, such as pitch,\nspeaking speed, and energy, our method utilizes an additional speaker prompt to\neffectively learn the mapping from natural language descriptions to the\nacoustic features of diverse speakers. Our subjective evaluation results show\nthat the proposed method can better control speaker characteristics than the\nmethods without the speaker prompt. Audio samples are available at\nhttps://reppy4620.github.io/demo.promptttspp/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Shimizu_R/0/1/0/all/0/1\">Reo Shimizu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yamamoto_R/0/1/0/all/0/1\">Ryuichi Yamamoto</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kawamura_M/0/1/0/all/0/1\">Masaya Kawamura</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shirahata_Y/0/1/0/all/0/1\">Yuma Shirahata</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Doi_H/0/1/0/all/0/1\">Hironori Doi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Komatsu_T/0/1/0/all/0/1\">Tatsuya Komatsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tachibana_K/0/1/0/all/0/1\">Kentaro Tachibana</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audio Difference Learning for Audio Captioning. (arXiv:2309.08141v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08141","description":"<p>This study introduces a novel training paradigm, audio difference learning,\nfor improving audio captioning. The fundamental concept of the proposed\nlearning method is to create a feature representation space that preserves the\nrelationship between audio, enabling the generation of captions that detail\nintricate audio information. This method employs a reference audio along with\nthe input audio, both of which are transformed into feature representations via\na shared encoder. Captions are then generated from these differential features\nto describe their differences. Furthermore, a unique technique is proposed that\ninvolves mixing the input audio with additional audio, and using the additional\naudio as a reference. This results in the difference between the mixed audio\nand the reference audio reverting back to the original input audio. This allows\nthe original input's caption to be used as the caption for their difference,\neliminating the need for additional annotations for the differences. In the\nexperiments using the Clotho and ESC50 datasets, the proposed method\ndemonstrated an improvement in the SPIDEr score by 7% compared to conventional\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Komatsu_T/0/1/0/all/0/1\">Tatsuya Komatsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fujita_Y/0/1/0/all/0/1\">Yusuke Fujita</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Takeda_K/0/1/0/all/0/1\">Kazuya Takeda</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Toda_T/0/1/0/all/0/1\">Tomoki Toda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unimodal Aggregation for CTC-based Speech Recognition. (arXiv:2309.08150v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08150","description":"<p>This paper works on non-autoregressive automatic speech recognition. A\nunimodal aggregation (UMA) is proposed to segment and integrate the feature\nframes that belong to the same text token, and thus to learn better feature\nrepresentations for text tokens. The frame-wise features and weights are both\nderived from an encoder. Then, the feature frames with unimodal weights are\nintegrated and further processed by a decoder. Connectionist temporal\nclassification (CTC) loss is applied for training. Compared to the regular CTC,\nthe proposed method learns better feature representations and shortens the\nsequence length, resulting in lower recognition error and computational\ncomplexity. Experiments on three Mandarin datasets show that UMA demonstrates\nsuperior or comparable performance to other advanced non-autoregressive\nmethods, such as self-conditioned CTC. Moreover, by integrating\nself-conditioned CTC into the proposed framework, the performance can be\nfurther noticeably improved.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Ying Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaofei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue. (arXiv:2309.08156v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08156","description":"<p>Evaluating open-domain dialogue systems is challenging for reasons such as\nthe one-to-many problem, i.e., many appropriate responses other than just the\ngolden response. As of now, automatic evaluation methods need better\nconsistency with humans, while reliable human evaluation can be time- and\ncost-intensive. To this end, we propose the Reference-Assisted Dialogue\nEvaluation (RADE) approach under the multi-task learning framework, which\nleverages the pre-created utterance as reference other than the gold response\nto relief the one-to-many problem. Specifically, RADE explicitly compares\nreference and the candidate response to predict their overall scores. Moreover,\nan auxiliary response generation task enhances prediction via a shared encoder.\nTo support RADE, we extend three datasets with additional rated responses other\nthan just a golden response by human annotation. Experiments on our three\ndatasets and two existing benchmarks demonstrate the effectiveness of our\nmethod, where Pearson, Spearman, and Kendall correlations with human evaluation\noutperform state-of-the-art baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengliang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Applicability of Self-Assessment Tests for Personality Measurement of Large Language Models. (arXiv:2309.08163v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08163","description":"<p>As large language models (LLM) evolve in their capabilities, various recent\nstudies have tried to quantify their behavior using psychological tools created\nto study human behavior. One such example is the measurement of \"personality\"\nof LLMs using personality self-assessment tests. In this paper, we take three\nsuch studies on personality measurement of LLMs that use personality\nself-assessment tests created to study human behavior. We use the prompts used\nin these three different papers to measure the personality of the same LLM. We\nfind that all three prompts lead very different personality scores. This simple\ntest reveals that personality self-assessment scores in LLMs depend on the\nsubjective choice of the prompter. Since we don't know the ground truth value\nof personality scores for LLMs as there is no correct answer to such questions,\nthere's no way of claiming if one prompt is more or less correct than the\nother. We then introduce the property of option order symmetry for personality\nmeasurement of LLMs. Since most of the self-assessment tests exist in the form\nof multiple choice question (MCQ) questions, we argue that the scores should\nalso be robust to not just the prompt template but also the order in which the\noptions are presented. This test unsurprisingly reveals that the answers to the\nself-assessment tests are not robust to the order of the options. These simple\ntests, done on ChatGPT and Llama2 models show that self-assessment personality\ntests created for humans are not appropriate for measuring personality in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Akshat Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaoyang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Draft & Verify: Lossless Large Language Model Acceleration via Self-Speculative Decoding. (arXiv:2309.08168v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08168","description":"<p>We present a novel inference scheme, self-speculative decoding, for\naccelerating Large Language Models (LLMs) without the need for an auxiliary\nmodel. This approach is characterized by a two-stage process: drafting and\nverification. The drafting stage generates draft tokens at a slightly lower\nquality but more quickly, which is achieved by selectively skipping certain\nintermediate layers during drafting Subsequently, the verification stage\nemploys the original LLM to validate those draft output tokens in one forward\npass. This process ensures the final output remains identical to that produced\nby the unaltered LLM, thereby maintaining output quality. The proposed method\nrequires no additional neural network training and no extra memory footprint,\nmaking it a plug-and-play and cost-effective solution for inference\nacceleration. Benchmarks with LLaMA-2 and its fine-tuned models demonstrated a\nspeedup up to 1.73$\\times$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1\">Lidan Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Ke Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehrotra_S/0/1/0/all/0/1\">Sharad Mehrotra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LASER: LLM Agent with State-Space Exploration for Web Navigation. (arXiv:2309.08172v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08172","description":"<p>Large language models (LLMs) have been successfully adapted for interactive\ndecision-making tasks like web navigation. While achieving decent performance,\nprevious methods implicitly assume a forward-only execution mode for the model,\nwhere they only provide oracle trajectories as in-context examples to teach the\nmodel how to reason in the interactive environment. Consequently, the model\ncould not handle more challenging scenarios not covered in the in-context\nexamples, e.g., mistakes, leading to sub-optimal performance. To address this\nissue, we propose to model the interactive task as state space exploration,\nwhere the LLM agent transitions among a pre-defined set of states by performing\nactions to complete the task. This formulation enables flexible back-tracking,\nallowing the model to easily recover from errors. We evaluate our proposed LLM\nAgent with State-Space ExploRation (LASER) on the WebShop task. Experimental\nresults show that our LASER agent significantly outperforms previous methods\nand closes the gap with human performance on the web navigation task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1\">Kaixin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiaoman Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FedJudge: Federated Legal Large Language Model. (arXiv:2309.08173v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08173","description":"<p>Large Language Models (LLMs) have gained prominence in the field of Legal\nIntelligence, offering potential applications in assisting legal professionals\nand laymen. However, the centralized training of these Legal LLMs raises data\nprivacy concerns, as legal data is distributed among various institutions\ncontaining sensitive individual information. This paper addresses this\nchallenge by exploring the integration of Legal LLMs with Federated Learning\n(FL) methodologies. By employing FL, Legal LLMs can be fine-tuned locally on\ndevices or clients, and their parameters are aggregated and distributed on a\ncentral server, ensuring data privacy without directly sharing raw data.\nHowever, computation and communication overheads hinder the full fine-tuning of\nLLMs under the FL setting. Moreover, the distribution shift of legal data\nreduces the effectiveness of FL methods. To this end, in this paper, we propose\nthe first Federated Legal Large Language Model (FedJudge) framework, which\nfine-tunes Legal LLMs efficiently and effectively. Specifically, FedJudge\nutilizes parameter-efficient fine-tuning methods to update only a few\nadditional parameters during the FL training. Besides, we explore the continual\nlearning methods to preserve the global model's important parameters when\ntraining local clients to mitigate the problem of data shifts. Extensive\nexperimental results on three real-world datasets clearly validate the\neffectiveness of FedJudge. Code is released at\nhttps://github.com/yuelinan/FedJudge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_L/0/1/0/all/0/1\">Linan Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yichao Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Weibo Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_F/0/1/0/all/0/1\">Fangzhou Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Failure Mode Classification: An Investigation. (arXiv:2309.08181v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08181","description":"<p>In this paper we present the first investigation into the effectiveness of\nLarge Language Models (LLMs) for Failure Mode Classification (FMC). FMC, the\ntask of automatically labelling an observation with a corresponding failure\nmode code, is a critical task in the maintenance domain as it reduces the need\nfor reliability engineers to spend their time manually analysing work orders.\nWe detail our approach to prompt engineering to enable an LLM to predict the\nfailure mode of a given observation using a restricted code list. We\ndemonstrate that the performance of a GPT-3.5 model (F1=0.80) fine-tuned on\nannotated data is a significant improvement over a currently available text\nclassification model (F1=0.60) trained on the same annotated data set. The\nfine-tuned model also outperforms the out-of-the box GPT-3.5 (F1=0.46). This\ninvestigation reinforces the need for high quality fine-tuning data sets for\ndomain-specific tasks using LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stewart_M/0/1/0/all/0/1\">Michael Stewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hodkiewicz_M/0/1/0/all/0/1\">Melinda Hodkiewicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sirui Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Large Language Model to Solve and Explain Physics Word Problems Approaching Human Level. (arXiv:2309.08182v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08182","description":"<p>Our work demonstrates that large language model (LLM) pre-trained on texts\ncan not only solve pure math word problems, but also physics word\nproblems-problems to be solved by calculation and inference based on some prior\nphysical knowledge. We collect and annotate the first physics word problem\ndataset-PhysQA, which contains over 1000 junior high school physics word\nproblems (on Kinematics, Mass&amp;Density, Mechanics, Heat, Electricity). Then we\nuse OpenAI' s GPT3.5 to generate the answer of these problems and found that\nGPT3.5 could automatically solve 49.3% of the problems on zero-shot learning\nand 73.2% on few-shot learning. This result show that by using similar problem\nand its answer as prompt, LLM could solve elementary physics word problems\napproaching human level. Besides automatically solving problems, GPT3.5 could\nalso summarize the knowledge or topic examined by the problem, generate the\nrelevant explanation, and synthesis new physics word problems according tothe\ninput problems.Our work is the first research on automatically solving,\nexplaining and generating physics word problems of multiple types and scenes,\nand we gain an acceptable and state-of-art accuracy, which demonstrates the\npotential of LLM's further application in the field of secondary education.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jingzhe Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cen_Y/0/1/0/all/0/1\">Yan Cen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xinyuan Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Sentence-Level Semantic Search using Meta-Distillation Learning. (arXiv:2309.08185v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08185","description":"<p>Multilingual semantic search is the task of retrieving relevant contents to a\nquery expressed in different language combinations. This requires a better\nsemantic understanding of the user's intent and its contextual meaning.\nMultilingual semantic search is less explored and more challenging than its\nmonolingual or bilingual counterparts, due to the lack of multilingual parallel\nresources for this task and the need to circumvent \"language bias\". In this\nwork, we propose an alignment approach: MAML-Align, specifically for\nlow-resource scenarios. Our approach leverages meta-distillation learning based\non MAML, an optimization-based Model-Agnostic Meta-Learner. MAML-Align distills\nknowledge from a Teacher meta-transfer model T-MAML, specialized in\ntransferring from monolingual to bilingual semantic search, to a Student model\nS-MAML, which meta-transfers from bilingual to multilingual semantic search. To\nthe best of our knowledge, we are the first to extend meta-distillation to a\nmultilingual search application. Our empirical results show that on top of a\nstrong baseline based on sentence transformers, our meta-distillation approach\nboosts the gains provided by MAML and significantly outperforms naive\nfine-tuning methods. Furthermore, multilingual meta-distillation learning\nimproves generalization even to unseen languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mhamdi_M/0/1/0/all/0/1\">Meryem M&#x27;hamdi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1\">Jonathan May</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1\">Trung Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seunghyun Yoon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Encoded Summarization: Summarizing Documents into Continuous Vector Space for Legal Case Retrieval. (arXiv:2309.08187v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08187","description":"<p>We present our method for tackling a legal case retrieval task by introducing\nour method of encoding documents by summarizing them into continuous vector\nspace via our phrase scoring framework utilizing deep neural networks. On the\nother hand, we explore the benefits from combining lexical features and latent\nfeatures generated with neural networks. Our experiments show that lexical\nfeatures and latent features generated with neural networks complement each\nother to improve the retrieval system performance. Furthermore, our\nexperimental results suggest the importance of case summarization in different\naspects: using provided summaries and performing encoded summarization. Our\napproach achieved F1 of 65.6% and 57.6% on the experimental datasets of legal\ncase retrieval tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1\">Vu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh Le Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tojo_S/0/1/0/all/0/1\">Satoshi Tojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satoh_K/0/1/0/all/0/1\">Ken Satoh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Answerability of LLMs for Long-Form Question Answering. (arXiv:2309.08210v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08210","description":"<p>As we embark on a new era of LLMs, it becomes increasingly crucial to\nunderstand their capabilities, limitations, and differences. Toward making\nfurther progress in this direction, we strive to build a deeper understanding\nof the gaps between massive LLMs (e.g., ChatGPT) and smaller yet effective\nopen-source LLMs and their distilled counterparts. To this end, we specifically\nfocus on long-form question answering (LFQA) because it has several practical\nand impactful applications (e.g., troubleshooting, customer service, etc.) yet\nis still understudied and challenging for LLMs. We propose a\nquestion-generation method from abstractive summaries and show that generating\nfollow-up questions from summaries of long documents can create a challenging\nsetting for LLMs to reason and infer from long contexts. Our experimental\nresults confirm that: (1) our proposed method of generating questions from\nabstractive summaries pose a challenging setup for LLMs and shows performance\ngaps between LLMs like ChatGPT and open-source LLMs (Alpaca, Llama) (2)\nopen-source LLMs exhibit decreased reliance on context for generated questions\nfrom the original document, but their generation capabilities drop\nsignificantly on generated questions from summaries -- especially for longer\ncontexts (&gt;1024 tokens)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhat_M/0/1/0/all/0/1\">Meghana Moorthy Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Ye Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yavuz_S/0/1/0/all/0/1\">Semih Yavuz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for Robust Polyglot Text-To-Speech. (arXiv:2309.08255v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08255","description":"<p>In this work, we introduce a framework for cross-lingual speech synthesis,\nwhich involves an upstream Voice Conversion (VC) model and a downstream\nText-To-Speech (TTS) model. The proposed framework consists of 4 stages. In the\nfirst two stages, we use a VC model to convert utterances in the target locale\nto the voice of the target speaker. In the third stage, the converted data is\ncombined with the linguistic features and durations from recordings in the\ntarget language, which are then used to train a single-speaker acoustic model.\nFinally, the last stage entails the training of a locale-independent vocoder.\nOur evaluations show that the proposed paradigm outperforms state-of-the-art\napproaches which are based on training a large multilingual TTS model. In\naddition, our experiments demonstrate the robustness of our approach with\ndifferent model architectures, languages, speakers and amounts of data.\nMoreover, our solution is especially beneficial in low-resource settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Piotrowski_D/0/1/0/all/0/1\">Dariusz Piotrowski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Korzeniowski_R/0/1/0/all/0/1\">Renard Korzeniowski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Falai_A/0/1/0/all/0/1\">Alessio Falai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cygert_S/0/1/0/all/0/1\">Sebastian Cygert</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Pokora_K/0/1/0/all/0/1\">Kamil Pokora</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tinchev_G/0/1/0/all/0/1\">Georgi Tinchev</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyao Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yanagisawa_K/0/1/0/all/0/1\">Kayoko Yanagisawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structural Self-Supervised Objectives for Transformers. (arXiv:2309.08272v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08272","description":"<p>This thesis focuses on improving the pre-training of natural language models\nusing unsupervised raw data to make them more efficient and aligned with\ndownstream applications.\n</p>\n<p>In the first part, we introduce three alternative pre-training objectives to\nBERT's Masked Language Modeling (MLM), namely Random Token Substitution (RTS),\nCluster-based Random Token Substitution (C-RTS), and Swapped Language Modeling\n(SLM). These objectives involve token swapping instead of masking, with RTS and\nC-RTS aiming to predict token originality and SLM predicting the original token\nvalues. Results show that RTS and C-RTS require less pre-training time while\nmaintaining performance comparable to MLM. Surprisingly, SLM outperforms MLM on\ncertain tasks despite using the same computational budget.\n</p>\n<p>In the second part, we proposes self-supervised pre-training tasks that align\nstructurally with downstream applications, reducing the need for labeled data.\nWe use large corpora like Wikipedia and CC-News to train models to recognize if\ntext spans originate from the same paragraph or document in several ways. By\ndoing continuous pre-training, starting from existing models like RoBERTa,\nELECTRA, DeBERTa, BART, and T5, we demonstrate significant performance\nimprovements in tasks like Fact Verification, Answer Sentence Selection, and\nSummarization. These improvements are especially pronounced when limited\nannotation data is available. The proposed objectives also achieve\nstate-of-the-art results on various benchmark datasets, including FEVER (dev\nset), ASNQ, WikiQA, and TREC-QA, as well as enhancing the quality of summaries.\nImportantly, these techniques can be easily integrated with other methods\nwithout altering the internal structure of Transformer models, making them\nversatile for various NLP applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liello_L/0/1/0/all/0/1\">Luca Di Liello</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Consistent Narrative Prompts on Abductive Natural Language Inference. (arXiv:2309.08303v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08303","description":"<p>Abduction has long been seen as crucial for narrative comprehension and\nreasoning about everyday situations. The abductive natural language inference\n($\\alpha$NLI) task has been proposed, and this narrative text-based task aims\nto infer the most plausible hypothesis from the candidates given two\nobservations. However, the inter-sentential coherence and the model consistency\nhave not been well exploited in the previous works on this task. In this work,\nwe propose a prompt tuning model $\\alpha$-PACE, which takes self-consistency\nand inter-sentential coherence into consideration. Besides, we propose a\ngeneral self-consistent framework that considers various narrative sequences\n(e.g., linear narrative and reverse chronology) for guiding the pre-trained\nlanguage model in understanding the narrative context of input. We conduct\nextensive experiments and thorough ablation studies to illustrate the necessity\nand effectiveness of $\\alpha$-PACE. The performance of our method shows\nsignificant improvement against extensive competitive baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chunkit Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1\">Tsz Ho Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jiayang Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_G/0/1/0/all/0/1\">Ginny Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_S/0/1/0/all/0/1\">Simon See</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Topic, Domain, and Language Shifts: An Evaluation of Comprehensive Out-of-Distribution Scenarios. (arXiv:2309.08316v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08316","description":"<p>Language models (LMs) excel in in-distribution (ID) scenarios where train and\ntest data are independent and identically distributed. However, their\nperformance often degrades in real-world applications like argument mining.\nSuch degradation happens when new topics emerge, or other text domains and\nlanguages become relevant. To assess LMs' generalization abilities in such\nout-of-distribution (OOD) scenarios, we simulate such distribution shifts by\ndeliberately withholding specific instances for testing, as from the social\nmedia domain or the topic Solar Energy.\n</p>\n<p>Unlike prior studies focusing on specific shifts and metrics in isolation, we\ncomprehensively analyze OOD generalization. We define three metrics to pinpoint\ngeneralization flaws and propose eleven classification tasks covering topic,\ndomain, and language shifts. Overall, we find superior performance of\nprompt-based fine-tuning, notably when train and test splits primarily differ\nsemantically. Simultaneously, in-context learning is more effective than\nprompt-based or vanilla fine-tuning for tasks when training data embodies heavy\ndiscrepancies in label distribution compared to testing data. This reveals a\ncrucial drawback of gradient-based learning: it biases LMs regarding such\nstructural obstacles.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Waldis_A/0/1/0/all/0/1\">Andreas Waldis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distributional Inclusion Hypothesis and Quantifications: Probing Hypernymy in Functional Distributional Semantics. (arXiv:2309.08325v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08325","description":"<p>Functional Distributional Semantics (FDS) models the meaning of words by\ntruth-conditional functions. This provides a natural representation for\nhypernymy, but no guarantee that it is learnt when FDS models are trained on a\ncorpus. We demonstrate that FDS models learn hypernymy when a corpus strictly\nfollows the Distributional Inclusion Hypothesis. We further introduce a\ntraining objective that allows FDS to handle simple universal quantifications,\nthus enabling hypernymy learning under the reverse of DIH. Experimental results\non both synthetic and real data sets confirm our hypotheses and the\neffectiveness of our proposed objective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lo_C/0/1/0/all/0/1\">Chun Hei Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emerson_G/0/1/0/all/0/1\">Guy Emerson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Distribution Bottlenecks in Grounding Language Models to Knowledge Bases. (arXiv:2309.08345v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08345","description":"<p>Language models (LMs) have already demonstrated remarkable abilities in\nunderstanding and generating both natural and formal language. Despite these\nadvances, their integration with real-world environments such as large-scale\nknowledge bases (KBs) remains an underdeveloped area, affecting applications\nsuch as semantic parsing and indulging in \"hallucinated\" information. This\npaper is an experimental investigation aimed at uncovering the robustness\nchallenges that LMs encounter when tasked with knowledge base question\nanswering (KBQA). The investigation covers scenarios with inconsistent data\ndistribution between training and inference, such as generalization to unseen\ndomains, adaptation to various language variations, and transferability across\ndifferent datasets. Our comprehensive experiments reveal that even when\nemployed with our proposed data augmentation techniques, advanced small and\nlarge language models exhibit poor performance in various dimensions. While the\nLM is a promising technology, the robustness of the current form in dealing\nwith complex environments is fragile and of limited practicality because of the\ndata distribution issue. This calls for future research on data collection and\nLM learning paradims.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yiheng Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiwei Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reward Engineering for Generating Semi-structured Explanation. (arXiv:2309.08347v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08347","description":"<p>Semi-structured explanation depicts the implicit process of a reasoner with\nan explicit representation. This explanation highlights how available\ninformation in a specific query is supplemented with information a reasoner\nproduces from its internal weights towards generating an answer. Despite the\nrecent improvements in generative capabilities of language models, producing\nstructured explanations to verify model's true reasoning capabilities remains a\nchallenge. This issue is particularly pronounced for not-so-large LMs, as the\nreasoner is expected to couple a sequential answer with a structured\nexplanation which embodies both the correct presentation and the correct\nreasoning process. In this work, we first underscore the limitations of\nsupervised fine-tuning (SFT) in tackling this challenge, and then introduce a\ncarefully crafted reward engineering method in reinforcement learning (RL) to\nbetter address this problem. We investigate multiple reward aggregation methods\nand provide a detailed discussion which sheds light on the promising potential\nof RL for future research. Our proposed reward on two semi-structured\nexplanation generation benchmarks (ExplaGraph and COPA-SSE) achieves new\nstate-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiuzhou Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1\">Wray Buntine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Headless Language Models: Learning without Predicting with Contrastive Weight Tying. (arXiv:2309.08351v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08351","description":"<p>Self-supervised pre-training of language models usually consists in\npredicting probability distributions over extensive token vocabularies. In this\nstudy, we propose an innovative method that shifts away from probability\nprediction and instead focuses on reconstructing input embeddings in a\ncontrastive fashion via Constrastive Weight Tying (CWT). We apply this approach\nto pretrain Headless Language Models in both monolingual and multilingual\ncontexts. Our method offers practical advantages, substantially reducing\ntraining computational requirements by up to 20 times, while simultaneously\nenhancing downstream performance and data efficiency. We observe a significant\n+1.6 GLUE score increase and a notable +2.7 LAMBADA accuracy improvement\ncompared to classical LMs within similar compute budgets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Godey_N/0/1/0/all/0/1\">Nathan Godey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clergerie_E/0/1/0/all/0/1\">&#xc9;ric de la Clergerie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagot_B/0/1/0/all/0/1\">Beno&#xee;t Sagot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiaCorrect: Error Correction Back-end For Speaker Diarization. (arXiv:2309.08377v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08377","description":"<p>In this work, we propose an error correction framework, named DiaCorrect, to\nrefine the output of a diarization system in a simple yet effective way. This\nmethod is inspired by error correction techniques in automatic speech\nrecognition. Our model consists of two parallel convolutional encoders and a\ntransform-based decoder. By exploiting the interactions between the input\nrecording and the initial system's outputs, DiaCorrect can automatically\ncorrect the initial speaker activities to minimize the diarization errors.\nExperiments on 2-speaker telephony data show that the proposed DiaCorrect can\neffectively improve the initial model's results. Our source code is publicly\navailable at https://github.com/BUTSpeechFIT/diacorrect.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Han_J/0/1/0/all/0/1\">Jiangyu Han</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Landini_F/0/1/0/all/0/1\">Federico Landini</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rohdin_J/0/1/0/all/0/1\">Johan Rohdin</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Diez_M/0/1/0/all/0/1\">Mireia Diez</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Burget_L/0/1/0/all/0/1\">Lukas Burget</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cao_Y/0/1/0/all/0/1\">Yuhang Cao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lu_H/0/1/0/all/0/1\">Heng Lu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cernocky_J/0/1/0/all/0/1\">Jan Cernocky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PatFig: Generating Short and Long Captions for Patent Figures. (arXiv:2309.08379v1 [cs.CV])","link":"http://arxiv.org/abs/2309.08379","description":"<p>This paper introduces Qatent PatFig, a novel large-scale patent figure\ndataset comprising 30,000+ patent figures from over 11,000 European patent\napplications. For each figure, this dataset provides short and long captions,\nreference numerals, their corresponding terms, and the minimal claim set that\ndescribes the interactions between the components of the image. To assess the\nusability of the dataset, we finetune an LVLM model on Qatent PatFig to\ngenerate short and long descriptions, and we investigate the effects of\nincorporating various text-based cues at the prediction stage of the patent\nfigure captioning process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aubakirova_D/0/1/0/all/0/1\">Dana Aubakirova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gerdes_K/0/1/0/all/0/1\">Kim Gerdes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lufei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unleashing Potential of Evidence in Knowledge-Intensive Dialogue Generation. (arXiv:2309.08380v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08380","description":"<p>Incorporating external knowledge into dialogue generation (KIDG) is crucial\nfor improving the correctness of response, where evidence fragments serve as\nknowledgeable snippets supporting the factual dialogue replies. However,\nintroducing irrelevant content often adversely impacts reply quality and easily\nleads to hallucinated responses. Prior work on evidence retrieval and\nintegration in dialogue systems falls short of fully leveraging existing\nevidence since the model fails to locate useful fragments accurately and\noverlooks hidden evidence labels within the KIDG dataset. To fully Unleash the\npotential of evidence, we propose a framework to effectively incorporate\nEvidence in knowledge-Intensive Dialogue Generation (u-EIDG). Specifically, we\nintroduce an automatic evidence generation framework that harnesses the power\nof Large Language Models (LLMs) to mine reliable evidence veracity labels from\nunlabeled data. By utilizing these evidence labels, we train a reliable\nevidence indicator to effectively identify relevant evidence from retrieved\npassages. Furthermore, we propose an evidence-augmented generator with an\nevidence-focused attention mechanism, which allows the model to concentrate on\nevidenced segments. Experimental results on MultiDoc2Dial demonstrate the\nefficacy of evidential label augmentation and refined attention mechanisms in\nimproving model performance. Further analysis confirms that the proposed method\noutperforms other baselines (+3~+5 points) regarding coherence and factual\nconsistency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xianjie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tongliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Di Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yiyang Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancing the Evaluation of Traditional Chinese Language Models: Towards a Comprehensive Benchmark Suite. (arXiv:2309.08448v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08448","description":"<p>The evaluation of large language models is an essential task in the field of\nlanguage understanding and generation. As language models continue to advance,\nthe need for effective benchmarks to assess their performance has become\nimperative. In the context of Traditional Chinese, there is a scarcity of\ncomprehensive and diverse benchmarks to evaluate the capabilities of language\nmodels, despite the existence of certain benchmarks such as DRCD, TTQA, CMDQA,\nand FGC dataset. To address this gap, we propose a novel set of benchmarks that\nleverage existing English datasets and are tailored to evaluate language models\nin Traditional Chinese. These benchmarks encompass a wide range of tasks,\nincluding contextual question-answering, summarization, classification, and\ntable understanding. The proposed benchmarks offer a comprehensive evaluation\nframework, enabling the assessment of language models' capabilities across\ndifferent tasks. In this paper, we evaluate the performance of GPT-3.5,\nTaiwan-LLaMa-v1.0, and Model 7-C, our proprietary model, on these benchmarks.\nThe evaluation results highlight that our model, Model 7-C, achieves\nperformance comparable to GPT-3.5 with respect to a part of the evaluated\ncapabilities. In an effort to advance the evaluation of language models in\nTraditional Chinese and stimulate further research in this field, we have\nopen-sourced our benchmark and opened the model for trial.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang-Le Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_F/0/1/0/all/0/1\">Feng-Ting Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_P/0/1/0/all/0/1\">Po-Chun Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Chang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mixture Encoder Supporting Continuous Speech Separation for Meeting Recognition. (arXiv:2309.08454v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08454","description":"<p>Many real-life applications of automatic speech recognition (ASR) require\nprocessing of overlapped speech. A commonmethod involves first separating the\nspeech into overlap-free streams and then performing ASR on the resulting\nsignals. Recently, the inclusion of a mixture encoder in the ASR model has been\nproposed. This mixture encoder leverages the original overlapped speech to\nmitigate the effect of artifacts introduced by the speech separation.\nPreviously, however, the method only addressed two-speaker scenarios. In this\nwork, we extend this approach to more natural meeting contexts featuring an\narbitrary number of speakers and dynamic overlaps. We evaluate the performance\nusing different speech separators, including the powerful TF-GridNet model. Our\nexperiments show state-of-the-art performance on the LibriCSS dataset and\nhighlight the advantages of the mixture encoder. Furthermore, they demonstrate\nthe strong separation of TF-GridNet which largely closes the gap between\nprevious methods and oracle separation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Vieting_P/0/1/0/all/0/1\">Peter Vieting</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Berger_S/0/1/0/all/0/1\">Simon Berger</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Neumann_T/0/1/0/all/0/1\">Thilo von Neumann</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Boeddeker_C/0/1/0/all/0/1\">Christoph Boeddeker</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Schluter_R/0/1/0/all/0/1\">Ralf Schl&#xfc;ter</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Haeb_Umbach_R/0/1/0/all/0/1\">Reinhold Haeb-Umbach</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SilverRetriever: Advancing Neural Passage Retrieval for Polish Question Answering. (arXiv:2309.08469v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08469","description":"<p>Modern open-domain question answering systems often rely on accurate and\nefficient retrieval components to find passages containing the facts necessary\nto answer the question. Recently, neural retrievers have gained popularity over\nlexical alternatives due to their superior performance. However, most of the\nwork concerns popular languages such as English or Chinese. For others, such as\nPolish, few models are available. In this work, we present SilverRetriever, a\nneural retriever for Polish trained on a diverse collection of manually or\nweakly labeled datasets. SilverRetriever achieves much better results than\nother Polish models and is competitive with larger multilingual models.\nTogether with the model, we open-source five new passage retrieval datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rybak_P/0/1/0/all/0/1\">Piotr Rybak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ogrodniczuk_M/0/1/0/all/0/1\">Maciej Ogrodniczuk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Large Language Models for Knowledge Engineering (LLMKE): A Case Study on Wikidata. (arXiv:2309.08491v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08491","description":"<p>In this work, we explore the use of Large Language Models (LLMs) for\nknowledge engineering tasks in the context of the ISWC 2023 LM-KBC Challenge.\nFor this task, given subject and relation pairs sourced from Wikidata, we\nutilize pre-trained LLMs to produce the relevant objects in string format and\nlink them to their respective Wikidata QIDs. We developed a pipeline using LLMs\nfor Knowledge Engineering (LLMKE), combining knowledge probing and Wikidata\nentity mapping. The method achieved a macro-averaged F1-score of 0.701 across\nthe properties, with the scores varying from 1.00 to 0.328. These results\ndemonstrate that the knowledge of LLMs varies significantly depending on the\ndomain and that further experimentation is required to determine the\ncircumstances under which LLMs can be used for automatic Knowledge Base (e.g.,\nWikidata) completion and correction. The investigation of the results also\nsuggests the promising contribution of LLMs in collaborative knowledge\nengineering. LLMKE won Track 2 of the challenge. The implementation is\navailable at https://github.com/bohuizhang/LLMKE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Bohui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reklos_I/0/1/0/all/0/1\">Ioannis Reklos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_N/0/1/0/all/0/1\">Nitisha Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Penuela_A/0/1/0/all/0/1\">Albert Mero&#xf1;o Pe&#xf1;uela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simperl_E/0/1/0/all/0/1\">Elena Simperl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking. (arXiv:2309.08503v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08503","description":"<p>Seeking health-related advice on the internet has become a common practice in\nthe digital era. Determining the trustworthiness of medical claims found online\nand finding appropriate evidence for this information is increasingly\nchallenging. Fact-checking has emerged as an approach to assess the veracity of\nfactual claims using evidence from credible knowledge sources. To help advance\nthe automation of this task, in this paper, we introduce a novel dataset of 750\nhealth-related claims, labeled for veracity by medical experts and backed with\nevidence from appropriate clinical studies. We provide an analysis of the\ndataset, highlighting its characteristics and challenges. The dataset can be\nused for Machine Learning tasks related to automated fact-checking such as\nevidence retrieval, veracity prediction, and explanation generation. For this\npurpose, we provide baseline models based on different approaches, examine\ntheir performance, and discuss the findings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vladika_J/0/1/0/all/0/1\">Juraj Vladika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_P/0/1/0/all/0/1\">Phillip Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matthes_F/0/1/0/all/0/1\">Florian Matthes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens. (arXiv:2309.08531v1 [cs.CV])","link":"http://arxiv.org/abs/2309.08531","description":"<p>In this paper, we propose methods to build a powerful and efficient\nImage-to-Speech captioning (Im2Sp) model. To this end, we start with importing\nthe rich knowledge related to image comprehension and language modeling from a\nlarge-scale pre-trained vision-language model into Im2Sp. We set the output of\nthe proposed Im2Sp as discretized speech units, i.e., the quantized speech\nfeatures of a self-supervised speech model. The speech units mainly contain\nlinguistic information while suppressing other characteristics of speech. This\nallows us to incorporate the language modeling capability of the pre-trained\nvision-language model into the spoken language modeling of Im2Sp. With the\nvision-language pre-training strategy, we set new state-of-the-art Im2Sp\nperformances on two widely used benchmark databases, COCO and Flickr8k. Then,\nwe further improve the efficiency of the Im2Sp model. Similar to the speech\nunit case, we convert the original image into image units, which are derived\nthrough vector quantization of the raw image. With these image units, we can\ndrastically reduce the required data storage for saving image data to just 0.8%\nwhen compared to the original image data in terms of bits. Demo page:\nhttps://ms-dot-k.github.io/Image-to-Speech-Captioning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jeongsoo Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maiti_S/0/1/0/all/0/1\">Soumi Maiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_J/0/1/0/all/0/1\">Jeong Hun Yeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ro_Y/0/1/0/all/0/1\">Yong Man Ro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers. (arXiv:2309.08532v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08532","description":"<p>Large Language Models (LLMs) excel in various tasks, but they rely on\ncarefully crafted prompts that often demand substantial human effort. To\nautomate this process, in this paper, we propose a novel framework for discrete\nprompt optimization, called EvoPrompt, which borrows the idea of evolutionary\nalgorithms (EAs) as they exhibit good performance and fast convergence. To\nenable EAs to work on discrete prompts, which are natural language expressions\nthat need to be coherent and human-readable, we connect LLMs with EAs. This\napproach allows us to simultaneously leverage the powerful language processing\ncapabilities of LLMs and the efficient optimization performance of EAs.\nSpecifically, abstaining from any gradients or parameters, EvoPrompt starts\nfrom a population of prompts and iteratively generates new prompts with LLMs\nbased on the evolutionary operators, improving the population based on the\ndevelopment set. We optimize prompts for both closed- and open-source LLMs\nincluding GPT-3.5 and Alpaca, on 9 datasets spanning language understanding and\ngeneration tasks. EvoPrompt significantly outperforms human-engineered prompts\nand existing methods for automatic prompt generation by up to 25% and 14%\nrespectively. Furthermore, EvoPrompt demonstrates that connecting LLMs with EAs\ncreates synergies, which could inspire further research on the combination of\nLLMs and conventional algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qingyan Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Junliang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1\">Kaitao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guoqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets. (arXiv:2309.08541v1 [cs.IR])","link":"http://arxiv.org/abs/2309.08541","description":"<p>Using large language models (LMs) for query or document expansion can improve\ngeneralization in information retrieval. However, it is unknown whether these\ntechniques are universally beneficial or only effective in specific settings,\nsuch as for particular retrieval models, dataset domains, or query types. To\nanswer this, we conduct the first comprehensive analysis of LM-based expansion.\nWe find that there exists a strong negative correlation between retriever\nperformance and gains from expansion: expansion improves scores for weaker\nmodels, but generally harms stronger models. We show this trend holds across a\nset of eleven expansion techniques, twelve datasets with diverse distribution\nshifts, and twenty-four retrieval models. Through qualitative error analysis,\nwe hypothesize that although expansions provide extra information (potentially\nimproving recall), they add additional noise that makes it difficult to discern\nbetween the top relevant documents (thus introducing false positives). Our\nresults suggest the following recipe: use expansions for weaker models or when\nthe target dataset significantly differs from training corpus in format;\notherwise, avoid expansions to keep the relevance signal clear.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weller_O/0/1/0/all/0/1\">Orion Weller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">Kyle Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wadden_D/0/1/0/all/0/1\">David Wadden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lawrie_D/0/1/0/all/0/1\">Dawn Lawrie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1\">Luca Soldaini</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenting conformers with structured state space models for online speech recognition. (arXiv:2309.08551v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08551","description":"<p>Online speech recognition, where the model only accesses context to the left,\nis an important and challenging use case for ASR systems. In this work, we\ninvestigate augmenting neural encoders for online ASR by incorporating\nstructured state-space sequence models (S4), which are a family of models that\nprovide a parameter-efficient way of accessing arbitrarily long left context.\nWe perform systematic ablation studies to compare variants of S4 models and\npropose two novel approaches that combine them with convolutions. We find that\nthe most effective design is to stack a small S4 using real-valued recurrent\nweights with a local convolution, allowing them to work complementarily. Our\nbest model achieves WERs of 4.01%/8.53% on test sets from Librispeech,\noutperforming Conformers with extensively tuned convolution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Haozhe Shan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1\">Albert Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1\">Zhong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1\">Tara Sainath</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How Transferable are Attribute Controllers on Pretrained Multilingual Translation Models?. (arXiv:2309.08565v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08565","description":"<p>Customizing machine translation models to comply with fine-grained attributes\nsuch as formality has seen tremendous progress recently. However, current\napproaches mostly rely on at least some supervised data with attribute\nannotation. Data scarcity therefore remains a bottleneck to democratizing such\ncustomization possibilities to a wider range of languages, lower-resource ones\nin particular. Given recent progress in pretrained massively multilingual\ntranslation models, we use them as a foundation to transfer the attribute\ncontrolling capabilities to languages without supervised data. In this work, we\npresent a comprehensive analysis of transferring attribute controllers based on\na pretrained NLLB-200 model. We investigate both training- and inference-time\ncontrol techniques under various data scenarios, and uncover their relative\nstrengths and weaknesses in zero-shot performance and domain robustness. We\nshow that both paradigms are complementary, as shown by consistent improvements\non 5 zero-shot directions. Moreover, a human evaluation on a real low-resource\nlanguage, Bengali, confirms our findings on zero-shot transfer to new target\nlanguages. The code is\n$\\href{https://github.com/dannigt/attribute-controller-transfer}{\\text{here}}$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Danni Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1\">Jan Niehues</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Casteist but Not Racist? Quantifying Disparities in Large Language Model Bias between India and the West. (arXiv:2309.08573v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08573","description":"<p>Large Language Models (LLMs), now used daily by millions of users, can encode\nsocietal biases, exposing their users to representational harms. A large body\nof scholarship on LLM bias exists but it predominantly adopts a Western-centric\nframe and attends comparatively less to bias levels and potential harms in the\nGlobal South. In this paper, we quantify stereotypical bias in popular LLMs\naccording to an Indian-centric frame and compare bias levels between the Indian\nand Western contexts. To do this, we develop a novel dataset which we call\nIndian-BhED (Indian Bias Evaluation Dataset), containing stereotypical and\nanti-stereotypical examples for caste and religion contexts. We find that the\nmajority of LLMs tested are strongly biased towards stereotypes in the Indian\ncontext, especially as compared to the Western context. We finally investigate\nInstruction Prompting as a simple intervention to mitigate such bias and find\nthat it significantly reduces both stereotypical and anti-stereotypical biases\nin the majority of cases for GPT-3.5. The findings of this work highlight the\nneed for including more diverse voices when evaluating LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_K/0/1/0/all/0/1\">Khyati Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonneau_M/0/1/0/all/0/1\">Manuel Tonneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bean_A/0/1/0/all/0/1\">Andrew M. Bean</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1\">Scott A. Hale</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ICLEF: In-Context Learning with Expert Feedback for Explainable Style Transfer. (arXiv:2309.08583v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08583","description":"<p>While state-of-the-art language models excel at the style transfer task,\ncurrent work does not address explainability of style transfer systems.\nExplanations could be generated using large language models such as GPT-3.5 and\nGPT-4, but the use of such complex systems is inefficient when smaller, widely\ndistributed, and transparent alternatives are available. We propose a framework\nto augment and improve a formality style transfer dataset with explanations via\nmodel distillation from ChatGPT. To further refine the generated explanations,\nwe propose a novel way to incorporate scarce expert human feedback using\nin-context learning (ICLEF: In-Context Learning from Expert Feedback) by\nprompting ChatGPT to act as a critic to its own outputs. We use the resulting\ndataset of 9,960 explainable formality style transfer instances (e-GYAFC) to\nshow that current openly distributed instruction-tuned models (and, in some\nsettings, ChatGPT) perform poorly on the task, and that fine-tuning on our\nhigh-quality dataset leads to significant improvements as shown by automatic\nevaluation. In human evaluation, we show that models much smaller than ChatGPT\nfine-tuned on our data align better with expert preferences. Finally, we\ndiscuss two potential applications of models fine-tuned on the explainable\nstyle transfer task: interpretable authorship verification and interpretable\nadversarial attacks on AI-generated text detectors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saakyan_A/0/1/0/all/0/1\">Arkadiy Saakyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain-of-Thought Reasoning is a Policy Improvement Operator. (arXiv:2309.08589v1 [cs.LG])","link":"http://arxiv.org/abs/2309.08589","description":"<p>Large language models have astounded the world with fascinating new\ncapabilities. However, they currently lack the ability to teach themselves new\nskills, relying instead on being trained on large amounts of human-generated\ndata. We introduce SECToR (Self-Education via Chain-of-Thought Reasoning), a\nproof-of-concept demonstration that language models can successfully teach\nthemselves new skills using chain-of-thought reasoning. Inspired by previous\nwork in both reinforcement learning (Silver et al., 2017) and human cognition\n(Kahneman, 2011), SECToR first uses chain-of-thought reasoning to slowly think\nits way through problems. SECToR then fine-tunes the model to generate those\nsame answers, this time without using chain-of-thought reasoning. Language\nmodels trained via SECToR autonomously learn to add up to 29-digit numbers\nwithout any access to any ground truth examples beyond an initial supervised\nfine-tuning phase consisting only of numbers with 6 or fewer digits. Our\ncentral hypothesis is that chain-of-thought reasoning can act as a policy\nimprovement operator, analogously to how Monte-Carlo Tree Search is used in\nAlphaZero. We hope that this research can lead to new directions in which\nlanguage models can learn to teach themselves without the need for human\ndemonstrations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hugh Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parkes_D/0/1/0/all/0/1\">David C. Parkes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural Machine Translation Models Can Learn to be Few-shot Learners. (arXiv:2309.08590v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08590","description":"<p>The emergent ability of Large Language Models to use a small number of\nexamples to learn to perform in novel domains and tasks, also called in-context\nlearning (ICL). In this work, we show that a much smaller model can be trained\nto perform ICL by fine-tuning towards a specialized training objective,\nexemplified on the task of domain adaptation for neural machine translation.\nWith this capacity for ICL, the model can take advantage of relevant few-shot\nexamples to adapt its output towards the domain. We compare the quality of this\ndomain adaptation to traditional supervised techniques and ICL with a\n40B-parameter Large Language Model. Our approach allows efficient batch\ninference on a mix of domains and outperforms state-of-the-art baselines in\nterms of both translation quality and immediate adaptation rate, i.e. the\nability to reproduce a specific term after being shown a single example.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reinauer_R/0/1/0/all/0/1\">Raphael Reinauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simianer_P/0/1/0/all/0/1\">Patrick Simianer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uhlig_K/0/1/0/all/0/1\">Kaden Uhlig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosig_J/0/1/0/all/0/1\">Johannes E. M. Mosig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wuebker_J/0/1/0/all/0/1\">Joern Wuebker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings. (arXiv:2309.08591v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08591","description":"<p>Large language models (LLMs) are highly adept at question answering and\nreasoning tasks, but when reasoning in situational context, human expectations\nvary depending on the relevant cultural common ground. As human languages are\nassociated with diverse cultures, LLMs should also be culturally-diverse\nreasoners. In this paper, we study the ability of a wide range of\nstate-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings\nin a conversational context. Our experiments reveal that: (1) mLLMs 'knows'\nlimited proverbs and memorizing proverbs does not mean understanding them\nwithin a conversational context; (2) mLLMs struggle to reason with figurative\nproverbs and sayings, and when asked to select the wrong answer (instead of\nasking it to select the correct answer); and (3) there is a \"culture gap\" in\nmLLMs when reasoning about proverbs and sayings translated from other\nlanguages. We construct and release our evaluation dataset MAPS (MulticultrAl\nProverbs and Sayings) for proverb understanding with conversational context for\nsix different languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chen Cecilia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1\">Fajri Koto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"Merge Conflicts!\" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs. (arXiv:2309.08594v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08594","description":"<p>Large language models (LLMs) acquire extensive knowledge during pre-training,\nknown as their parametric knowledge. However, in order to remain up-to-date and\nalign with human instructions, LLMs inevitably require external knowledge\nduring their interactions with users. This raises a crucial question: How will\nLLMs respond when external knowledge interferes with their parametric\nknowledge? To investigate this question, we propose a framework that\nsystematically elicits LLM parametric knowledge and introduces external\nknowledge. Specifically, we uncover the impacts by constructing a parametric\nknowledge graph to reveal the different knowledge structures of LLMs, and\nintroduce external knowledge through distractors of varying degrees, methods,\npositions, and formats. Our experiments on both black-box and open-source\nmodels demonstrate that LLMs tend to produce responses that deviate from their\nparametric knowledge, particularly when they encounter direct conflicts or\nconfounding changes of information within detailed contexts. We also find that\nwhile LLMs are sensitive to the veracity of external knowledge, they can still\nbe distracted by unrelated information. These findings highlight the risk of\nhallucination when integrating external knowledge, even indirectly, during\ninteractions with current LLMs. All the data and results are publicly\navailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Cheng Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xinran Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sherry Tongshuang Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sparse Autoencoders Find Highly Interpretable Features in Language Models. (arXiv:2309.08600v1 [cs.LG])","link":"http://arxiv.org/abs/2309.08600","description":"<p>One of the roadblocks to a better understanding of neural networks' internals\nis \\textit{polysemanticity}, where neurons appear to activate in multiple,\nsemantically distinct contexts. Polysemanticity prevents us from identifying\nconcise, human-understandable explanations for what neural networks are doing\ninternally. One hypothesised cause of polysemanticity is\n\\textit{superposition}, where neural networks represent more features than they\nhave neurons by assigning features to an overcomplete set of directions in\nactivation space, rather than to individual neurons. Here, we attempt to\nidentify those directions, using sparse autoencoders to reconstruct the\ninternal activations of a language model. These autoencoders learn sets of\nsparsely activating features that are more interpretable and monosemantic than\ndirections identified by alternative approaches, where interpretability is\nmeasured by automated methods. Ablating these features enables precise model\nediting, for example, by removing capabilities such as pronoun prediction,\nwhile disrupting model behaviour less than prior techniques. This work\nindicates that it is possible to resolve superposition in language models using\na scalable, unsupervised method. Our method may serve as a foundation for\nfuture mechanistic interpretability work, which we hope will enable greater\nmodel transparency and steerability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cunningham_H/0/1/0/all/0/1\">Hoagy Cunningham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ewart_A/0/1/0/all/0/1\">Aidan Ewart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riggs_L/0/1/0/all/0/1\">Logan Riggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huben_R/0/1/0/all/0/1\">Robert Huben</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharkey_L/0/1/0/all/0/1\">Lee Sharkey</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AmbiFC: Fact-Checking Ambiguous Claims with Evidence. (arXiv:2104.00640v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.00640","description":"<p>Automated fact-checking systems verify claims against evidence to predict\ntheir veracity. In real-world scenarios, the retrieved evidence may not\nunambiguously support or refute the claim and yield conflicting but valid\ninterpretations. Existing fact-checking datasets assume that the models\ndeveloped with them predict a single veracity label for each claim, thus\ndiscouraging the handling of such ambiguity. To address this issue we present\nAmbiFC, a fact-checking dataset with 10k claims derived from real-world\ninformation needs. It contains fine-grained evidence annotations of 50k\npassages from 5k Wikipedia pages. We analyze the disagreements arising from\nambiguity when comparing claims against evidence in AmbiFC, observing a strong\ncorrelation of annotator disagreement with linguistic phenomena such as\nunderspecification and probabilistic reasoning. We develop models for\npredicting veracity handling this ambiguity via soft labels and find that a\npipeline that learns the label distribution for sentence-level evidence\nselection and veracity prediction yields the best performance. We compare\nmodels trained on different subsets of AmbiFC and show that models trained on\nthe ambiguous instances perform better when faced with the identified\nlinguistic phenomena.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Glockner_M/0/1/0/all/0/1\">Max Glockner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staliunaite_I/0/1/0/all/0/1\">Ieva Stali&#x16b;nait&#x117;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1\">James Thorne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vallejo_G/0/1/0/all/0/1\">Gisela Vallejo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1\">Andreas Vlachos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Application of Quantum Density Matrix in Classical Question Answering and Classical Image Classification. (arXiv:2203.11155v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.11155","description":"<p>Quantum density matrix represents all the information of the entire quantum\nsystem, and novel models of meaning employing density matrices naturally model\nlinguistic phenomena such as hyponymy and linguistic ambiguity, among others in\nquantum question answering tasks. Naturally, we argue that applying the quantum\ndensity matrix into classical Question Answering (QA) tasks can show more\neffective performance. Specifically, we (i) design a new mechanism based on\nLong Short-Term Memory (LSTM) to accommodate the case when the inputs are\nmatrixes; (ii) apply the new mechanism to QA problems with Convolutional Neural\nNetwork (CNN) and gain the LSTM-based QA model with the quantum density matrix.\nExperiments of our new model on TREC-QA and WIKI-QA data sets show encouraging\nresults. Similarly, we argue that the quantum density matrix can also enhance\nthe image feature information and the relationship between the features for the\nclassical image classification. Thus, we (i) combine density matrices and CNN\nto design a new mechanism; (ii) apply the new mechanism to some representative\nclassical image classification tasks. A series of experiments show that the\napplication of quantum density matrix in image classification has the\ngeneralization and high efficiency on different datasets. The application of\nquantum density matrix both in classical question answering tasks and classical\nimage classification tasks show more effective performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">X. Q. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1\">H. Wan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VQA-GNN: Reasoning with Multimodal Knowledge via Graph Neural Networks for Visual Question Answering. (arXiv:2205.11501v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2205.11501","description":"<p>Visual question answering (VQA) requires systems to perform concept-level\nreasoning by unifying unstructured (e.g., the context in question and answer;\n\"QA context\") and structured (e.g., knowledge graph for the QA context and\nscene; \"concept graph\") multimodal knowledge. Existing works typically combine\na scene graph and a concept graph of the scene by connecting corresponding\nvisual nodes and concept nodes, then incorporate the QA context representation\nto perform question answering. However, these methods only perform a\nunidirectional fusion from unstructured knowledge to structured knowledge,\nlimiting their potential to capture joint reasoning over the heterogeneous\nmodalities of knowledge. To perform more expressive reasoning, we propose\nVQA-GNN, a new VQA model that performs bidirectional fusion between\nunstructured and structured multimodal knowledge to obtain unified knowledge\nrepresentations. Specifically, we inter-connect the scene graph and the concept\ngraph through a super node that represents the QA context, and introduce a new\nmultimodal GNN technique to perform inter-modal message passing for reasoning\nthat mitigates representational gaps between modalities. On two challenging VQA\ntasks (VCR and GQA), our method outperforms strong baseline VQA methods by 3.2%\non VCR (Q-AR) and 4.6% on GQA, suggesting its strength in performing\nconcept-level reasoning. Ablation studies further demonstrate the efficacy of\nthe bidirectional fusion and multimodal GNN method in unifying unstructured and\nstructured multimodal knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yasunaga_M/0/1/0/all/0/1\">Michihiro Yasunaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Hongyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wada_S/0/1/0/all/0/1\">Shinya Wada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1\">Jure Leskovec</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diachronic Data Analysis Supports and Refines Conceptual Metaphor Theory. (arXiv:2209.12234v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.12234","description":"<p>As a contribution to metaphor analysis, we introduce a statistical,\ndata-based investigation with empirical analysis of long-standing conjectures\nand a first-ever empirical exploration of the systematic features of metaphors.\nConversely, this also makes metaphor theory available as a basis of meaning\nemergence that can be quantitatively explored and integrated into the framework\nof NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Teich_M/0/1/0/all/0/1\">Marie Teich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_W/0/1/0/all/0/1\">Wilmer Leal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jost_J/0/1/0/all/0/1\">Juergen Jost</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Guiding Pretraining in Reinforcement Learning with Large Language Models. (arXiv:2302.06692v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.06692","description":"<p>Reinforcement learning algorithms typically struggle in the absence of a\ndense, well-shaped reward function. Intrinsically motivated exploration methods\naddress this limitation by rewarding agents for visiting novel states or\ntransitions, but these methods offer limited benefits in large environments\nwhere most discovered novelty is irrelevant for downstream tasks. We describe a\nmethod that uses background knowledge from text corpora to shape exploration.\nThis method, called ELLM (Exploring with LLMs) rewards an agent for achieving\ngoals suggested by a language model prompted with a description of the agent's\ncurrent state. By leveraging large-scale language model pretraining, ELLM\nguides agents toward human-meaningful and plausibly useful behaviors without\nrequiring a human in the loop. We evaluate ELLM in the Crafter game environment\nand the Housekeep robotic simulator, showing that ELLM-trained agents have\nbetter coverage of common-sense behaviors during pretraining and usually match\nor improve performance on a range of downstream tasks. Code available at\nhttps://github.com/yuqingd/ellm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yuqing Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1\">Olivia Watkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colas_C/0/1/0/all/0/1\">C&#xe9;dric Colas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1\">Trevor Darrell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1\">Pieter Abbeel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhishek Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the State of the Art in Legal QA Systems. (arXiv:2304.06623v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.06623","description":"<p>Answering questions related to the legal domain is a complex task, primarily\ndue to the intricate nature and diverse range of legal document systems.\nProviding an accurate answer to a legal query typically necessitates\nspecialized knowledge in the relevant domain, which makes this task all the\nmore challenging, even for human experts. Question answering (QA) systems are\ndesigned to generate answers to questions asked in human languages. QA uses\nnatural language processing to understand questions and search through\ninformation to find relevant answers. QA has various practical applications,\nincluding customer service, education, research, and cross-lingual\ncommunication. However, QA faces challenges such as improving natural language\nunderstanding and handling complex and ambiguous questions. Answering questions\nrelated to the legal domain is a complex task, primarily due to the intricate\nnature and diverse range of legal document systems. Providing an accurate\nanswer to a legal query typically necessitates specialized knowledge in the\nrelevant domain, which makes this task all the more challenging, even for human\nexperts. At this time, there is a lack of surveys that discuss legal question\nanswering. To address this problem, we provide a comprehensive survey that\nreviews 14 benchmark datasets for question-answering in the legal field as well\nas presents a comprehensive review of the state-of-the-art Legal Question\nAnswering deep learning models. We cover the different architectures and\ntechniques used in these studies and the performance and limitations of these\nmodels. Moreover, we have established a public GitHub repository where we\nregularly upload the most recent articles, open data, and source code. The\nrepository is available at:\n\\url{https://github.com/abdoelsayed2016/Legal-Question-Answering-Review}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdallah_A/0/1/0/all/0/1\">Abdelrahman Abdallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piryani_B/0/1/0/all/0/1\">Bhawna Piryani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jatowt_A/0/1/0/all/0/1\">Adam Jatowt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing the potential of AI-assisted pragmatic annotation: The case of apologies. (arXiv:2305.08339v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08339","description":"<p>Certain forms of linguistic annotation, like part of speech and semantic\ntagging, can be automated with high accuracy. However, manual annotation is\nstill necessary for complex pragmatic and discursive features that lack a\ndirect mapping to lexical forms. This manual process is time-consuming and\nerror-prone, limiting the scalability of function-to-form approaches in corpus\nlinguistics. To address this, our study explores automating pragma-discursive\ncorpus annotation using large language models (LLMs). We compare ChatGPT, the\nBing chatbot, and a human coder in annotating apology components in English\nbased on the local grammar framework. We find that the Bing chatbot\noutperformed ChatGPT, with accuracy approaching that of a human coder. These\nresults suggest that AI can be successfully deployed to aid pragma-discursive\ncorpus annotation, making the process more efficient and scalable. Keywords:\nlinguistic annotation, function-to-form approaches, large language models,\nlocal grammar analysis, Bing chatbot, ChatGPT\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Danni Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Luyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1\">Hang Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuoli_M/0/1/0/all/0/1\">Matteo Fuoli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Masking Rate Schedules for MLM Pretraining. (arXiv:2305.15096v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15096","description":"<p>Most works on transformers trained with the Masked Language Modeling (MLM)\nobjective use the original BERT model's fixed masking rate of 15%. We propose\nto instead dynamically schedule the masking rate throughout training. We find\nthat linearly decreasing the masking rate over the course of pretraining\nimproves average GLUE accuracy by up to 0.46% and 0.25% in BERT-base and\nBERT-large, respectively, compared to fixed rate baselines. These gains come\nfrom exposure to both high and low masking rate regimes, providing benefits\nfrom both settings. Our results demonstrate that masking rate scheduling is a\nsimple way to improve the quality of masked language models, achieving up to a\n1.89x speedup in pretraining for BERT-base as well as a Pareto improvement for\nBERT-large.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ankner_Z/0/1/0/all/0/1\">Zachary Ankner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blalock_D/0/1/0/all/0/1\">Davis Blalock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1\">Jonathan Frankle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew L. Leavitt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.14096","description":"<p>Entity-level fine-grained sentiment analysis in the financial domain is a\ncrucial subtask of sentiment analysis and currently faces numerous challenges.\nThe primary challenge stems from the lack of high-quality and large-scale\nannotated corpora specifically designed for financial text sentiment analysis,\nwhich in turn limits the availability of data necessary for developing\neffective text processing techniques. Recent advancements in large language\nmodels (LLMs) have yielded remarkable performance in natural language\nprocessing tasks, primarily centered around language pattern matching. In this\npaper, we propose a novel and extensive Chinese fine-grained financial\nsentiment analysis dataset, FinChina SA, for enterprise early warning. We\nthoroughly evaluate and experiment with well-known existing open-source LLMs\nusing our dataset. We firmly believe that our dataset will serve as a valuable\nresource to advance the exploration of real-world financial sentiment analysis\ntasks, which should be the focus of future research. The FinChina SA dataset is\npublicly available at https://github.com/YerayL/FinChina-SA\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yinyu Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yanru Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Weiqiang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Youhao Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification. (arXiv:2308.09308v3 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2308.09308","description":"<p>Retrieval augmentation, which enhances downstream models by a knowledge\nretriever and an external corpus instead of by merely increasing the number of\nmodel parameters, has been successfully applied to many natural language\nprocessing (NLP) tasks such as text classification, question answering and so\non. However, existing methods that separately or asynchronously train the\nretriever and downstream model mainly due to the non-differentiability between\nthe two parts, usually lead to degraded performance compared to end-to-end\njoint training. In this paper, we propose Differentiable Retrieval Augmentation\nvia Generative lANguage modeling(Dragan), to address this problem by a novel\ndifferentiable reformulation. We demonstrate the effectiveness of our proposed\nmethod on a challenging NLP task in e-commerce search, namely query intent\nclassification. Both the experimental results and ablation study show that the\nproposed method significantly and reasonably improves the state-of-the-art\nbaselines on both offline evaluation and online A/B test.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yunjiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1\">Yiming Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Han Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wen-Yun Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models. (arXiv:2308.09729v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.09729","description":"<p>LLMs usually exhibit limitations in their ability to incorporate new\nknowledge, the generation of hallucinations, and the transparency of their\ndecision-making process. In this paper, we explore how to prompt LLMs with\nknowledge graphs (KG), working as a remedy to engage LLMs with up-to-date\nknowledge and elicit the reasoning pathways from LLMs. Specifically, we build a\nprompting pipeline that endows LLMs with the capability of comprehending KG\ninputs and inferring with a combined implicit knowledge and the retrieved\nexternal knowledge. In addition, we investigate eliciting the mind map on which\nLLMs perform the reasoning and generate the answers. It is identified that the\nproduced mind map exhibits the reasoning pathways of LLMs grounded on the\nontology of knowledge, hence bringing the prospects of probing and gauging LLM\ninference in production. The experiments on three question &amp; answering datasets\nalso show that MindMap prompting leads to a striking empirical gain. For\ninstance, prompting a GPT-3.5 with MindMap yields an overwhelming performance\nover GPT-4 consistently. We also demonstrate that with structured facts\nretrieved from KG, MindMap can outperform a series of\nprompting-with-document-retrieval methods, benefiting from more accurate,\nconcise, and comprehensive knowledge from KGs. To reproduce our results and\nextend the framework further, we make our codebase available at\nhttps://github.com/wyl.willing/MindMap.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Yilin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zifeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WanJuan: A Comprehensive Multimodal Dataset for Advancing English and Chinese Large Models. (arXiv:2308.10755v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10755","description":"<p>The rise in popularity of ChatGPT and GPT-4 has significantly accelerated the\ndevelopment of large models, leading to the creation of numerous impressive\nlarge language models(LLMs) and multimodal large language models (MLLMs). These\ncutting-edge models owe their remarkable performance to high-quality data.\nHowever, the details of the training data used in leading paradigms are often\nkept confidential. This lack of transparency, coupled with the scarcity of\nopen-source data, impedes further developments within the community. As a\nresponse, this paper presents \"Wan Juan\", a large-scale multimodal dataset\ncomposed of both Chinese and English data, collected from a wide range of web\nsources. The dataset incorporates text, image-text, and video modalities, with\na total volume exceeding 2TB. It was utilized in the training of InternLM, a\nmodel that demonstrated significant advantages in multi-dimensional evaluations\nwhen compared to models of a similar scale. All data can be accessed at\nhttps://opendatalab.org.cn/WanJuan1.0.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1\">Conghui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhenjiang Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jiantao Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HAE-RAE Bench: Evaluation of Korean Knowledge in Language Models. (arXiv:2309.02706v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.02706","description":"<p>Large Language Models (LLMs) pretrained on massive corpora exhibit remarkable\ncapabilities across a wide range of tasks, however, the attention given to\nnon-English languages has been limited in this field of research. To address\nthis gap and assess the proficiency of language models in the Korean language\nand culture, we present HAE-RAE Bench, covering 6 tasks including vocabulary,\nhistory, and general knowledge. Our evaluation of language models on this\nbenchmark highlights the potential advantages of employing Large\nLanguage-Specific Models(LLSMs) over a comprehensive, universal model like\nGPT-3.5. Remarkably, our study reveals that models approximately 13 times\nsmaller than GPT-3.5 can exhibit similar performance levels in terms of\nlanguage-specific knowledge retrieval. This observation underscores the\nimportance of homogeneous corpora for training professional-level\nlanguage-specific models. On the contrary, we also observe a perplexing\nperformance dip in these smaller LMs when they are tasked to generate\nstructured answers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Son_G/0/1/0/all/0/1\">Guijin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hanwool Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Suwan Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Huiseo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jaecheol Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeom_J/0/1/0/all/0/1\">Je Won Yeom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1\">Jihyu Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jung Woo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Songseong Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Everyone Deserves A Reward: Learning Customized Human Preferences. (arXiv:2309.03126v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03126","description":"<p>Reward models (RMs) are essential for aligning large language models (LLMs)\nwith human preferences to improve interaction quality. However, the real world\nis pluralistic, which leads to diversified human preferences with respect to\ndifferent religions, politics, cultures, etc. Moreover, each individual can\nhave their unique preferences on various topics. Neglecting the diversity of\nhuman preferences, current human feedback aligning methods only consider a\ngeneral reward model, which is below satisfaction for customized or\npersonalized application scenarios. To explore customized preference learning,\nwe collect a domain-specific preference (DSP) dataset, which includes preferred\nresponses for each given query from four practical domains. Besides, from the\nperspective of data efficiency, we propose a three-stage customized RM learning\nscheme, then empirically verify its effectiveness on both general preference\ndatasets and our DSP set. Furthermore, we test multiple training and data\nstrategies on the three learning stages. We find several ways to better\npreserve the general preferring ability while training the customized RMs,\nespecially general preference enrichment, and customized preference imitation\nlearning. The DSP dataset and code are available at\nhttps://github.com/Linear95/DSP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pengyu Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1\">Jiawen Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_K/0/1/0/all/0/1\">Ke Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yong Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_N/0/1/0/all/0/1\">Nan Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spoken Humanoid Embodied Conversational Agents in Mobile Serious Games: A Usability Assessment. (arXiv:2309.07773v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2309.07773","description":"<p>This paper presents an empirical investigation of the extent to which spoken\nHumanoid Embodied Conversational Agents (HECAs) can foster usability in mobile\nserious game (MSG) applications. The aim of the research is to assess the\nimpact of multiple agents and illusion of humanness on the quality of the\ninteraction. The experiment investigates two styles of agent presentation: an\nagent of high human-likeness (HECA) and an agent of low human-likeness (text).\nThe purpose of the experiment is to assess whether and how agents of high\nhumanlikeness can evoke the illusion of humanness and affect usability. Agents\nof high human-likeness were designed by following the ECA design model that is\na proposed guide for ECA development. The results of the experiment with 90\nparticipants show that users prefer to interact with the HECAs. The difference\nbetween the two versions is statistically significant with a large effect size\n(d=1.01), with many of the participants justifying their choice by saying that\nthe human-like characteristics of the HECA made the version more appealing.\nThis research provides key information on the potential effect of HECAs on\nserious games, which can provide insight into the design of future mobile\nserious games.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Korre_D/0/1/0/all/0/1\">Danai Korre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_J/0/1/0/all/0/1\">Judy Robertson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CATfOOD: Counterfactual Augmented Training for Improving Out-of-Domain Performance and Calibration. (arXiv:2309.07822v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07822","description":"<p>In recent years, large language models (LLMs) have shown remarkable\ncapabilities at scale, particularly at generating text conditioned on a prompt.\nIn our work, we investigate the use of LLMs to augment training data of small\nlanguage models~(SLMs) with automatically generated counterfactual~(CF)\ninstances -- i.e. minimally altered inputs -- in order to improve\nout-of-domain~(OOD) performance of SLMs in the extractive question\nanswering~(QA) setup. We show that, across various LLM generators, such data\naugmentation consistently enhances OOD performance and improves model\ncalibration for both confidence-based and rationale-augmented calibrator\nmodels. Furthermore, these performance improvements correlate with higher\ndiversity of CF instances in terms of their surface form and semantic content.\nFinally, we show that CF augmented models which are easier to calibrate also\nexhibit much lower entropy when assigning importance, indicating that\nrationale-augmented calibrators prefer concise explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sachdeva_R/0/1/0/all/0/1\">Rachneet Sachdeva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tutek_M/0/1/0/all/0/1\">Martin Tutek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Rise and Potential of Large Language Model Based Agents: A Survey. (arXiv:2309.07864v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.07864","description":"<p>For a long time, humanity has pursued artificial intelligence (AI) equivalent\nto or surpassing the human level, with AI agents considered a promising vehicle\nfor this pursuit. AI agents are artificial entities that sense their\nenvironment, make decisions, and take actions. Many efforts have been made to\ndevelop intelligent AI agents since the mid-20th century. However, these\nefforts have mainly focused on advancement in algorithms or training strategies\nto enhance specific capabilities or performance on particular tasks. Actually,\nwhat the community lacks is a sufficiently general and powerful model to serve\nas a starting point for designing AI agents that can adapt to diverse\nscenarios. Due to the versatile and remarkable capabilities they demonstrate,\nlarge language models (LLMs) are regarded as potential sparks for Artificial\nGeneral Intelligence (AGI), offering hope for building general AI agents. Many\nresearch efforts have leveraged LLMs as the foundation to build AI agents and\nhave achieved significant progress. We start by tracing the concept of agents\nfrom its philosophical origins to its development in AI, and explain why LLMs\nare suitable foundations for AI agents. Building upon this, we present a\nconceptual framework for LLM-based agents, comprising three main components:\nbrain, perception, and action, and the framework can be tailored to suit\ndifferent applications. Subsequently, we explore the extensive applications of\nLLM-based agents in three aspects: single-agent scenarios, multi-agent\nscenarios, and human-agent cooperation. Following this, we delve into agent\nsocieties, exploring the behavior and personality of LLM-based agents, the\nsocial phenomena that emerge when they form societies, and the insights they\noffer for human society. Finally, we discuss a range of key topics and open\nproblems within the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenxiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xin Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1\">Wei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yiwen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_B/0/1/0/all/0/1\">Boyang Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Ming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junzhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Senjie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1\">Enyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaoran Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Limao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Changhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yicheng Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_R/0/1/0/all/0/1\">Rongxiang Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wensen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_W/0/1/0/all/0/1\">Wenjuan Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yongyan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-17T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}