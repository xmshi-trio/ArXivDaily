{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-14T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Narrowing the Gap between Supervised and Unsupervised Sentence Representation Learning with Large Language Model. (arXiv:2309.06453v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06453","description":"<p>Sentence Representation Learning (SRL) is a fundamental task in Natural\nLanguage Processing (NLP), with Contrastive learning of Sentence Embeddings\n(CSE) as the mainstream technique due to its superior performance. An\nintriguing phenomenon in CSE is the significant performance gap between\nsupervised and unsupervised methods, even when their sentence encoder and loss\nfunction are the same. Previous works attribute this performance gap to\ndifferences in two representation properties (alignment and uniformity).\nHowever, alignment and uniformity only measure the results, which means they\ncannot answer \"What happens during the training process that leads to the\nperformance gap?\" and \"How can the performance gap be narrowed?\". In this\npaper, we conduct empirical experiments to answer these \"What\" and \"How\"\nquestions. We first answer the \"What\" question by thoroughly comparing the\nbehavior of supervised and unsupervised CSE during their respective training\nprocesses. From the comparison, We observe a significant difference in fitting\ndifficulty. Thus, we introduce a metric, called Fitting Difficulty Increment\n(FDI), to measure the fitting difficulty gap between the evaluation dataset and\nthe held-out training dataset, and use the metric to answer the \"What\"\nquestion. Then, based on the insights gained from the \"What\" question, we\ntackle the \"How\" question by increasing the fitting difficulty of the training\ndataset. We achieve this by leveraging the In-Context Learning (ICL) capability\nof the Large Language Model (LLM) to generate data that simulates complex\npatterns. By utilizing the hierarchical patterns in the LLM-generated data, we\neffectively narrow the gap between supervised and unsupervised CSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Richong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Z/0/1/0/all/0/1\">Zhijie Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yongyi Mao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Widely Interpretable Semantic Representation: Frameless Meaning Representation for Broader Applicability. (arXiv:2309.06460v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06460","description":"<p>This paper presents a novel semantic representation, WISeR, that overcomes\nchallenges for Abstract Meaning Representation (AMR). Despite its strengths,\nAMR is not easily applied to languages or domains without predefined semantic\nframes, and its use of numbered arguments results in semantic role labels,\nwhich are not directly interpretable and are semantically overloaded for\nparsers. We examine the numbered arguments of predicates in AMR and convert\nthem to thematic roles that do not require reference to semantic frames. We\ncreate a new corpus of 1K English dialogue sentences annotated in both WISeR\nand AMR. WISeR shows stronger inter-annotator agreement for beginner and\nexperienced annotators, with beginners becoming proficient in WISeR annotation\nmore quickly. Finally, we train a state-of-the-art parser on the AMR 3.0 corpus\nand a WISeR corpus converted from AMR 3.0. The parser is evaluated on these\ncorpora and our dialogue corpus. The WISeR model exhibits higher accuracy than\nits AMR counterpart across the board, demonstrating that WISeR is easier for\nparsers to learn.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1\">Lydia Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Williamson_G/0/1/0/all/0/1\">Gregor Williamson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Han He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Large Language Models for Automated Dialogue Analysis. (arXiv:2309.06490v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06490","description":"<p>Developing high-performing dialogue systems benefits from the automatic\nidentification of undesirable behaviors in system responses. However, detecting\nsuch behaviors remains challenging, as it draws on a breadth of general\nknowledge and understanding of conversational practices. Although recent\nresearch has focused on building specialized classifiers for detecting specific\ndialogue behaviors, the behavior coverage is still incomplete and there is a\nlack of testing on real-world human-bot interactions. This paper investigates\nthe ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to\nperform dialogue behavior detection for nine categories in real human-bot\ndialogues. We aim to assess whether ChatGPT can match specialized models and\napproximate human performance, thereby reducing the cost of behavior detection\ntasks. Our findings reveal that neither specialized models nor ChatGPT have yet\nachieved satisfactory results for this task, falling short of human\nperformance. Nevertheless, ChatGPT shows promising potential and often\noutperforms specialized detection models. We conclude with an in-depth\nexamination of the prevalent shortcomings of ChatGPT, offering guidance for\nfuture research to enhance LLM capabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Finch_S/0/1/0/all/0/1\">Sarah E. Finch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paek_E/0/1/0/all/0/1\">Ellie S. Paek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AGIBench: A Multi-granularity, Multimodal, Human-referenced, Auto-scoring Benchmark for Large Language Models. (arXiv:2309.06495v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06495","description":"<p>Large language models (LLMs) like ChatGPT have revealed amazing intelligence.\nHow to evaluate the question-solving abilities of LLMs and their degrees of\nintelligence is a hot-spot but challenging issue. First, the question-solving\nabilities are interlaced with different ability branches like understanding and\nmassive knowledge categories like mathematics. Second, the inputs of questions\nare multimodal that may involve text and images. Third, the response format of\nLLMs is diverse and thus poses great challenges for result extraction and\nevaluation. In this paper, we propose AGIBench -- a multi-granularity,\nmultimodal, human-referenced, and auto-scoring benchmarking methodology for\nLLMs. Instead of a collection of blended questions, AGIBench focuses on three\ntypical ability branches and adopts a four-tuple &lt;ability branch, knowledge,\ndifficulty, modal&gt; to label the attributes of each question. First, it supports\nmulti-granularity benchmarking, e.g., per-question, per-ability branch,\nper-knowledge, per-modal, per-dataset, and per-difficulty level granularities.\nSecond, it contains multimodal input, including text and images. Third, it\nclassifies all the questions into five degrees of difficulty according to the\naverage accuracy rate of abundant educated humans (human-referenced). Fourth,\nit adopts zero-shot learning to avoid introducing additional unpredictability\nand provides an auto-scoring method to extract and judge the result. Finally,\nit defines multi-dimensional metrics, including accuracy under the average,\nworst, best, and majority voting cases, and repeatability. AGIBench is\npublically available from \\url{https://www.benchcouncil.org/agibench}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1\">Fei Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Wanling Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_L/0/1/0/all/0/1\">Luzhou Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1\">Jianfeng Zhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging Large Language Models and Weak Supervision for Social Media data annotation: an evaluation using COVID-19 self-reported vaccination tweets. (arXiv:2309.06503v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06503","description":"<p>The COVID-19 pandemic has presented significant challenges to the healthcare\nindustry and society as a whole. With the rapid development of COVID-19\nvaccines, social media platforms have become a popular medium for discussions\non vaccine-related topics. Identifying vaccine-related tweets and analyzing\nthem can provide valuable insights for public health research-ers and\npolicymakers. However, manual annotation of a large number of tweets is\ntime-consuming and expensive. In this study, we evaluate the usage of Large\nLanguage Models, in this case GPT-4 (March 23 version), and weak supervision,\nto identify COVID-19 vaccine-related tweets, with the purpose of comparing\nperformance against human annotators. We leveraged a manu-ally curated\ngold-standard dataset and used GPT-4 to provide labels without any additional\nfine-tuning or instructing, in a single-shot mode (no additional prompting).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tekumalla_R/0/1/0/all/0/1\">Ramya Tekumalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banda_J/0/1/0/all/0/1\">Juan M. Banda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overview of Memotion 3: Sentiment and Emotion Analysis of Codemixed Hinglish Memes. (arXiv:2309.06517v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06517","description":"<p>Analyzing memes on the internet has emerged as a crucial endeavor due to the\nimpact this multi-modal form of content wields in shaping online discourse.\nMemes have become a powerful tool for expressing emotions and sentiments,\npossibly even spreading hate and misinformation, through humor and sarcasm. In\nthis paper, we present the overview of the Memotion 3 shared task, as part of\nthe DeFactify 2 workshop at AAAI-23. The task released an annotated dataset of\nHindi-English code-mixed memes based on their Sentiment (Task A), Emotion (Task\nB), and Emotion intensity (Task C). Each of these is defined as an individual\ntask and the participants are ranked separately for each task. Over 50 teams\nregistered for the shared task and 5 made final submissions to the test set of\nthe Memotion 3 dataset. CLIP, BERT modifications, ViT etc. were the most\npopular models among the participants along with approaches such as\nStudent-Teacher model, Fusion, and Ensembling. The best final F1 score for Task\nA is 34.41, Task B is 79.77 and Task C is 59.82.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Shreyash Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suryavardan_S/0/1/0/all/0/1\">S Suryavardan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Megha Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1\">Parth Patwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reganti_A/0/1/0/all/0/1\">Aishwarya Reganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinnakotla_M/0/1/0/all/0/1\">Manoj Chinnakotla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekbal_A/0/1/0/all/0/1\">Asif Ekbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Srijan Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Minimum Bayes' Risk Decoding for System Combination of Grammatical Error Correction Systems. (arXiv:2309.06520v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06520","description":"<p>For sequence-to-sequence tasks it is challenging to combine individual system\noutputs. Further, there is also often a mismatch between the decoding criterion\nand the one used for assessment. Minimum Bayes' Risk (MBR) decoding can be used\nto combine system outputs in a manner that encourages better alignment with the\nfinal assessment criterion. This paper examines MBR decoding for Grammatical\nError Correction (GEC) systems, where performance is usually evaluated in terms\nof edits and an associated F-score. Hence, we propose a novel MBR loss function\ndirectly linked to this form of criterion. Furthermore, an approach to expand\nthe possible set of candidate sentences is described. This builds on a current\nmax-voting combination scheme, as well as individual edit-level selection.\nExperiments on three popular GEC datasets and with state-of-the-art GEC systems\ndemonstrate the efficacy of the proposed MBR approach. Additionally, the paper\nhighlights how varying reward metrics within the MBR decoding framework can\nprovide control over precision, recall, and the F-score in combined GEC\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1\">Vyas Raina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Translation Models Stand Strong in the Face of Adversarial Attacks. (arXiv:2309.06527v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06527","description":"<p>Adversarial attacks expose vulnerabilities of deep learning models by\nintroducing minor perturbations to the input, which lead to substantial\nalterations in the output. Our research focuses on the impact of such\nadversarial attacks on sequence-to-sequence (seq2seq) models, specifically\nmachine translation models. We introduce algorithms that incorporate basic text\nperturbation heuristics and more advanced strategies, such as the\ngradient-based attack, which utilizes a differentiable approximation of the\ninherently non-differentiable translation metric. Through our investigation, we\nprovide evidence that machine translation models display robustness displayed\nrobustness against best performed known adversarial attacks, as the degree of\nperturbation in the output is directly proportional to the perturbation in the\ninput. However, among underdogs, our attacks outperform alternatives, providing\nthe best relative performance. Another strong candidate is an attack based on\nmixing of individual characters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burnyshev_P/0/1/0/all/0/1\">Pavel Burnyshev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kostenok_E/0/1/0/all/0/1\">Elizaveta Kostenok</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1\">Alexey Zaytsev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Encoders Lack Knowledge: Leveraging Generative LLMs for Domain-Specific Semantic Textual Similarity. (arXiv:2309.06541v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06541","description":"<p>Amidst the sharp rise in the evaluation of large language models (LLMs) on\nvarious tasks, we find that semantic textual similarity (STS) has been\nunder-explored. In this study, we show that STS can be cast as a text\ngeneration problem while maintaining strong performance on multiple STS\nbenchmarks. Additionally, we show generative LLMs significantly outperform\nexisting encoder-based STS models when characterizing the semantic similarity\nbetween two texts with complex semantic relationships dependent on world\nknowledge. We validate this claim by evaluating both generative LLMs and\nexisting encoder-based STS models on three newly collected STS challenge sets\nwhich require world knowledge in the domains of Health, Politics, and Sports.\nAll newly collected data is sourced from social media content posted after May\n2023 to ensure the performance of closed-source models like ChatGPT cannot be\ncredited to memorization. Our results show that, on average, generative LLMs\noutperform the best encoder-only baselines by an average of 22.3% on STS tasks\nrequiring world knowledge. Our results suggest generative language models with\nSTS-specific prompting strategies achieve state-of-the-art performance in\ncomplex, domain-specific STS tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gatto_J/0/1/0/all/0/1\">Joseph Gatto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharif_O/0/1/0/all/0/1\">Omar Sharif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seegmiller_P/0/1/0/all/0/1\">Parker Seegmiller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bohlman_P/0/1/0/all/0/1\">Philip Bohlman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preum_S/0/1/0/all/0/1\">Sarah Masud Preum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Text Generation using Hypergraph Representations. (arXiv:2309.06550v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06550","description":"<p>Generating synthetic variants of a document is often posed as text-to-text\ntransformation. We propose an alternate LLM based method that first decomposes\na document into semantic frames and then generates text using this interim\nsparse format. The frames are modeled using a hypergraph, which allows\nperturbing the frame contents in a principled manner. Specifically, new\nhyperedges are mined through topological analysis and complex polyadic\nrelationships including hierarchy and temporal dynamics are accommodated. We\nshow that our solution generates documents that are diverse, coherent and vary\nin style, sentiment, format, composition and facts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raman_N/0/1/0/all/0/1\">Natraj Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1\">Sameena Shah</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Offline Prompt Evaluation and Optimization with Inverse Reinforcement Learning. (arXiv:2309.06553v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06553","description":"<p>The recent advances in the development of Large Language Models (LLMs) like\nChatGPT have achieved remarkable performance by leveraging human expertise.\nYet, fully eliciting LLMs' potential for complex tasks requires navigating the\nvast search space of natural language prompts. While prompt engineering has\nshown promise, the requisite human-crafted prompts in trial-and-error attempts\nand the associated costs pose significant challenges. Crucially, the efficiency\nof prompt optimization hinges on the costly procedure of prompt evaluation.\nThis work introduces Prompt-OIRL, an approach rooted in offline inverse\nreinforcement learning that seeks to bridge the gap between effective prompt\nevaluation and affordability. Our method draws on offline datasets from expert\nevaluations, employing Inverse-RL to derive a reward model for offline,\nquery-dependent prompt evaluations. The advantages of Prompt-OIRL are manifold:\nit predicts prompt performance, is cost-efficient, produces human-readable\nresults, and efficiently navigates the prompt space. We validate our method\nacross four LLMs and three arithmetic datasets, highlighting its potential as a\nrobust and effective tool for offline prompt evaluation and optimization. Our\ncode as well as the offline datasets are released, and we highlight the\nPrompt-OIRL can be reproduced within a few hours using a single laptop using\nCPU\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Bias Detection in College Student Newspapers. (arXiv:2309.06557v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06557","description":"<p>This paper presents a pipeline with minimal human influence for scraping and\ndetecting bias on college newspaper archives. This paper introduces a framework\nfor scraping complex archive sites that automated tools fail to grab data from,\nand subsequently generates a dataset of 14 student papers with 23,154 entries.\nThis data can also then be queried by keyword to calculate bias by comparing\nthe sentiment of a large language model summary to the original article. The\nadvantages of this approach are that it is less comparative than reconstruction\nbias and requires less labelled data than generating keyword sentiment. Results\nare calculated on politically charged words as well as control words to show\nhow conclusions can be drawn. The complete method facilitates the extraction of\nnuanced insights with minimal assumptions and categorizations, paving the way\nfor a more objective understanding of bias within student newspaper sources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lehavi_A/0/1/0/all/0/1\">Adam M. Lehavi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCormack_W/0/1/0/all/0/1\">William McCormack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kornfeld_N/0/1/0/all/0/1\">Noah Kornfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glazer_S/0/1/0/all/0/1\">Solomon Glazer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Addressing the Blind Spots in Spoken Language Processing. (arXiv:2309.06572v1 [eess.AS])","link":"http://arxiv.org/abs/2309.06572","description":"<p>This paper explores the critical but often overlooked role of non-verbal\ncues, including co-speech gestures and facial expressions, in human\ncommunication and their implications for Natural Language Processing (NLP). We\nargue that understanding human communication requires a more holistic approach\nthat goes beyond textual or spoken words to include non-verbal elements.\nBorrowing from advances in sign language processing, we propose the development\nof universal automatic gesture segmentation and transcription models to\ntranscribe these non-verbal cues into textual form. Such a methodology aims to\nbridge the blind spots in spoken language understanding, enhancing the scope\nand applicability of NLP models. Through motivating examples, we demonstrate\nthe limitations of relying solely on text-based models. We propose a\ncomputationally efficient and flexible approach for incorporating non-verbal\ncues, which can seamlessly integrate with existing NLP pipelines. We conclude\nby calling upon the research community to contribute to the development of\nuniversal transcription methods and to validate their effectiveness in\ncapturing the complexities of real-world, multi-modal interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Moryossef_A/0/1/0/all/0/1\">Amit Moryossef</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06578","description":"<p>Hypothesis formulation and testing are central to empirical research. A\nstrong hypothesis is a best guess based on existing evidence and informed by a\ncomprehensive view of relevant literature. However, with exponential increase\nin the number of scientific articles published annually, manual aggregation and\nsynthesis of evidence related to a given hypothesis is a challenge. Our work\nexplores the ability of current large language models (LLMs) to discern\nevidence in support or refute of specific hypotheses based on the text of\nscientific abstracts. We share a novel dataset for the task of scientific\nhypothesis evidencing using community-driven annotations of studies in the\nsocial sciences. We compare the performance of LLMs to several state-of-the-art\nbenchmarks and highlight opportunities for future research in this area. The\ndataset is available at\nhttps://github.com/Sai90000/ScientificHypothesisEvidencing.git\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koneru_S/0/1/0/all/0/1\">Sai Koneru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajtmajer_S/0/1/0/all/0/1\">Sarah Rajtmajer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can humans help BERT gain \"confidence\"?. (arXiv:2309.06580v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06580","description":"<p>The advancements in artificial intelligence over the last decade have opened\na multitude of avenues for interdisciplinary research. Since the idea of\nartificial intelligence was inspired by the working of neurons in the brain, it\nseems pretty practical to combine the two fields and take the help of cognitive\ndata to train AI models. Not only it will help to get a deeper understanding of\nthe technology, but of the brain as well. In this thesis, I conduct novel\nexperiments to integrate cognitive features from the Zurich Cognitive Corpus\n(ZuCo) (Hollenstein et al., 2018) with a transformer-based encoder model called\nBERT. I show how EEG and eye-tracking features from ZuCo can help to increase\nthe performance of the NLP model. I confirm the performance increase with the\nhelp of a robustness-checking pipeline and derive a word-EEG lexicon to use in\nbenchmarking on an external dataset that does not have any cognitive features\nassociated with it. Further, I analyze the internal working mechanism of BERT\nand explore a potential method for model explainability by correlating it with\na popular model-agnostic explainability framework called LIME (Ribeiro et al.,\n2016). Finally, I discuss the possible directions to take this research\nforward.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Piyush Agrawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Generative Large Language Models need billions of parameters?. (arXiv:2309.06589v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06589","description":"<p>This paper presents novel systems and methodologies for the development of\nefficient large language models (LLMs). It explores the trade-offs between\nmodel size, performance, and computational resources, with the aim of\nmaximizing the efficiency of these AI systems. The research explores novel\nmethods that allow different parts of the model to share parameters, reducing\nthe total number of unique parameters required. This approach ensures that the\nmodel remains compact without sacrificing its ability to learn and represent\ncomplex language structures. This study provides valuable insights and tools\nfor creating more efficient and effective LLMs, contributing to a more\nsustainable and accessible future for AI language modeling.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gholami_S/0/1/0/all/0/1\">Sia Gholami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Omar_M/0/1/0/all/0/1\">Marwan Omar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Narrative as a Dynamical System. (arXiv:2309.06600v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06600","description":"<p>There is increasing evidence that human activity in general, and narrative in\nparticular, can be treated as a dynamical system in the physics sense; a system\nwhose evolution is described by an action integral, such that the average of\nall possible paths from point A to point B is given by the extremum of the\naction. We create by construction three such paths by averaging about 500\ndifferent narratives, and we show that the average path is consistent with an\naction principle.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doxas_I/0/1/0/all/0/1\">Isidoros Doxas</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Meiss_J/0/1/0/all/0/1\">James Meiss</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Bottone_S/0/1/0/all/0/1\">Steven Bottone</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Strelich_T/0/1/0/all/0/1\">Tom Strelich</a> (4 and 5), <a href=\"http://arxiv.org/find/cs/1/au:+Plummer_A/0/1/0/all/0/1\">Andrew Plummer</a> (5 and 6), <a href=\"http://arxiv.org/find/cs/1/au:+Breland_A/0/1/0/all/0/1\">Adrienne Breland</a> (5 and 7), <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_S/0/1/0/all/0/1\">Simon Dennis</a> (8 and 9), <a href=\"http://arxiv.org/find/cs/1/au:+Garvin_Doxas_K/0/1/0/all/0/1\">Kathy Garvin-Doxas</a> (9 and 10), <a href=\"http://arxiv.org/find/cs/1/au:+Klymkowsky_M/0/1/0/all/0/1\">Michael Klymkowsky</a> (3) ( (1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RT-LM: Uncertainty-Aware Resource Management for Real-Time Inference of Language Models. (arXiv:2309.06619v1 [cs.LG])","link":"http://arxiv.org/abs/2309.06619","description":"<p>Recent advancements in language models (LMs) have gained substantial\nattentions on their capability to generate human-like responses. Though\nexhibiting a promising future for various applications such as conversation AI,\nthese LMs face deployment challenges on various devices due to their extreme\ncomputational cost and unpredictable inference latency. Such varied inference\nlatency, identified as a consequence of uncertainty intrinsic to the nature of\nlanguage, can lead to computational inefficiency and degrade the overall\nperformance of LMs, especially under high-traffic workloads. Unfortunately, the\nbandwidth of these uncertainty sources is extensive, complicating the\nprediction of latency and the effects emanating from such uncertainties. To\nunderstand and mitigate the impact of uncertainty on real-time\nresponse-demanding systems, we take the first step to comprehend, quantify and\noptimize these uncertainty-induced latency performance variations in LMs.\nSpecifically, we present RT-LM, an uncertainty-aware resource management\necosystem for real-time inference of LMs. RT-LM innovatively quantifies how\nspecific input uncertainties, adversely affect latency, often leading to an\nincreased output length. Exploiting these insights, we devise a lightweight yet\neffective method to dynamically correlate input text uncertainties with output\nlength at runtime. Utilizing this quantification as a latency heuristic, we\nintegrate the uncertainty information into a system-level scheduler which\nexplores several uncertainty-induced optimization opportunities, including\nuncertainty-aware prioritization, dynamic consolidation, and strategic CPU\noffloading. Quantitative experiments across five state-of-the-art LMs on two\nhardware platforms demonstrates that RT-LM can significantly reduce the average\nresponse time and improve throughput while incurring a rather small runtime\noverhead.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yufei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zexin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Statistical Rejection Sampling Improves Preference Optimization. (arXiv:2309.06657v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06657","description":"<p>Improving the alignment of language models with human preferences remains an\nactive research challenge. Previous approaches have primarily utilized\nReinforcement Learning from Human Feedback (RLHF) via online RL methods such as\nProximal Policy Optimization (PPO). Recently, offline methods such as Sequence\nLikelihood Calibration (SLiC) and Direct Preference Optimization (DPO) have\nemerged as attractive alternatives, offering improvements in stability and\nscalability while maintaining competitive performance. SLiC refines its loss\nfunction using sequence pairs sampled from a supervised fine-tuned (SFT)\npolicy, while DPO directly optimizes language models based on preference data,\nforegoing the need for a separate reward model. However, the maximum likelihood\nestimator (MLE) of the target optimal policy requires labeled preference pairs\nsampled from that policy. DPO's lack of a reward model constrains its ability\nto sample preference pairs from the optimal policy, and SLiC is restricted to\nsampling preference pairs only from the SFT policy. To address these\nlimitations, we introduce a novel approach called Statistical Rejection\nSampling Optimization (RSO) that aims to source preference data from the target\noptimal policy using rejection sampling, enabling a more accurate estimation of\nthe optimal policy. We also propose a unified framework that enhances the loss\nfunctions used in both SLiC and DPO from a preference modeling standpoint.\nThrough extensive experiments across three diverse tasks, we demonstrate that\nRSO consistently outperforms both SLiC and DPO on evaluations from both Large\nLanguage Model (LLM) and human raters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1\">Rishabh Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khalman_M/0/1/0/all/0/1\">Misha Khalman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saleh_M/0/1/0/all/0/1\">Mohammad Saleh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peter J. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jialu Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Procedural Language Understanding for Low-Resource Languages: A Case Study on Turkish. (arXiv:2309.06698v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06698","description":"<p>Understanding procedural natural language (e.g., step-by-step instructions)\nis a crucial step to execution and planning. However, while there are ample\ncorpora and downstream tasks available in English, the field lacks such\nresources for most languages. To address this gap, we conduct a case study on\nTurkish procedural texts. We first expand the number of tutorials in Turkish\nwikiHow from 2,000 to 52,000 using automated translation tools, where the\ntranslation quality and loyalty to the original meaning are validated by a team\nof experts on a random set. Then, we generate several downstream tasks on the\ncorpus, such as linking actions, goal inference, and summarization. To tackle\nthese tasks, we implement strong baseline models via fine-tuning large\nlanguage-specific models such as TR-BART and BERTurk, as well as multilingual\nmodels such as mBART, mT5, and XLM. We find that language-specific models\nconsistently outperform their multilingual models by a significant margin\nacross most procedural language understanding (PLU) tasks. We release our\ncorpus, downstream tasks and the baseline models with https://github.com/\nGGLAB-KU/turkish-plu.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uzunoglu_A/0/1/0/all/0/1\">Arda Uzuno&#x11f;lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahin_G/0/1/0/all/0/1\">G&#xf6;zde G&#xfc;l &#x15e;ahin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VLSlice: Interactive Vision-and-Language Slice Discovery. (arXiv:2309.06703v1 [cs.CV])","link":"http://arxiv.org/abs/2309.06703","description":"<p>Recent work in vision-and-language demonstrates that large-scale pretraining\ncan learn generalizable models that are efficiently transferable to downstream\ntasks. While this may improve dataset-scale aggregate metrics, analyzing\nperformance around hand-crafted subgroups targeting specific bias dimensions\nreveals systemic undesirable behaviors. However, this subgroup analysis is\nfrequently stalled by annotation efforts, which require extensive time and\nresources to collect the necessary data. Prior art attempts to automatically\ndiscover subgroups to circumvent these constraints but typically leverages\nmodel behavior on existing task-specific annotations and rapidly degrades on\nmore complex inputs beyond \"tabular\" data, none of which study\nvision-and-language models. This paper presents VLSlice, an interactive system\nenabling user-guided discovery of coherent representation-level subgroups with\nconsistent visiolinguistic behavior, denoted as vision-and-language slices,\nfrom unlabeled image sets. We show that VLSlice enables users to quickly\ngenerate diverse high-coherency slices in a user study (n=22) and release the\ntool publicly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Slyman_E/0/1/0/all/0/1\">Eric Slyman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahng_M/0/1/0/all/0/1\">Minsuk Kahng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Stefan Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simultaneous Machine Translation with Large Language Models. (arXiv:2309.06706v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06706","description":"<p>Large language models (LLM) have demonstrated their abilities to solve\nvarious natural language processing tasks through dialogue-based interactions.\nFor instance, research indicates that LLMs can achieve competitive performance\nin offline machine translation tasks for high-resource languages. However,\napplying LLMs to simultaneous machine translation (SimulMT) poses many\nchallenges, including issues related to the training-inference mismatch arising\nfrom different decoding patterns. In this paper, we explore the feasibility of\nutilizing LLMs for SimulMT. Building upon conventional approaches, we introduce\na simple yet effective mixture policy that enables LLMs to engage in SimulMT\nwithout requiring additional training. Furthermore, after Supervised\nFine-Tuning (SFT) on a mixture of full and prefix sentences, the model exhibits\nsignificant performance improvements. Our experiments, conducted with\nLlama2-7B-chat on nine language pairs from the MUST-C dataset, demonstrate that\nLLM can achieve translation quality and latency comparable to dedicated SimulMT\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Minghan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jinming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Thuy-Trang Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiri_F/0/1/0/all/0/1\">Fatemeh Shiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Keyphrase Generation by BART Finetuning with Splitting and Shuffling. (arXiv:2309.06726v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06726","description":"<p>Keyphrase generation is a task of identifying a set of phrases that best\nrepre-sent the main topics or themes of a given text. Keyphrases are dividend\nint pre-sent and absent keyphrases. Recent approaches utilizing\nsequence-to-sequence models show effectiveness on absent keyphrase generation.\nHowever, the per-formance is still limited due to the hardness of finding\nabsent keyphrases. In this paper, we propose Keyphrase-Focused BART, which\nexploits the differ-ences between present and absent keyphrase generations, and\nperforms fine-tuning of two separate BART models for present and absent\nkeyphrases. We further show effective approaches of shuffling keyphrases and\ncandidate keyphrase ranking. For absent keyphrases, our Keyphrase-Focused BART\nachieved new state-of-the-art score on F1@5 in two out of five keyphrase\ngen-eration benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwaihara_M/0/1/0/all/0/1\">Mizuho Iwaihara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CONVERSER: Few-Shot Conversational Dense Retrieval with Synthetic Data Generation. (arXiv:2309.06748v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06748","description":"<p>Conversational search provides a natural interface for information retrieval\n(IR). Recent approaches have demonstrated promising results in applying dense\nretrieval to conversational IR. However, training dense retrievers requires\nlarge amounts of in-domain paired data. This hinders the development of\nconversational dense retrievers, as abundant in-domain conversations are\nexpensive to collect. In this paper, we propose CONVERSER, a framework for\ntraining conversational dense retrievers with at most 6 examples of in-domain\ndialogues. Specifically, we utilize the in-context learning capability of large\nlanguage models to generate conversational queries given a passage in the\nretrieval corpus. Experimental results on conversational retrieval benchmarks\nOR-QuAC and TREC CAsT 19 show that the proposed CONVERSER achieves comparable\nperformance to fully-supervised models, demonstrating the effectiveness of our\nproposed framework in few-shot conversational dense retrieval. All source code\nand generated datasets are available at https://github.com/MiuLab/CONVERSER\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chao-Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chen-Yu Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_T/0/1/0/all/0/1\">Tsu-Yuan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chen-An Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Nung Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaled Prompt-Tuning for Few-Shot Natural Language Generation. (arXiv:2309.06759v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06759","description":"<p>The increasingly Large Language Models (LLMs) demonstrate stronger language\nunderstanding and generation capabilities, while the memory demand and\ncomputation cost of fine-tuning LLMs on downstream tasks are non-negligible.\nBesides, fine-tuning generally requires a certain amount of data from\nindividual tasks whilst data collection cost is another issue to consider in\nreal-world applications. In this work, we focus on Parameter-Efficient\nFine-Tuning (PEFT) methods for few-shot Natural Language Generation (NLG),\nwhich freeze most parameters in LLMs and tune a small subset of parameters in\nfew-shot cases so that memory footprint, training cost, and labeling cost are\nreduced while maintaining or even improving the performance. We propose a\nScaled Prompt-Tuning (SPT) method which surpasses conventional PT with better\nperformance and generalization ability but without an obvious increase in\ntraining cost. Further study on intermediate SPT suggests the superior\ntransferability of SPT in few-shot scenarios, providing a recipe for\ndata-deficient and computation-limited circumstances. Moreover, a comprehensive\ncomparison of existing PEFT methods reveals that certain approaches exhibiting\ndecent performance with modest training cost such as Prefix-Tuning in prior\nstudy could struggle in few-shot NLG tasks, especially on challenging datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Ting Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1\">Christoph Meinel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Haojin Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cognitive Mirage: A Review of Hallucinations in Large Language Models. (arXiv:2309.06794v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06794","description":"<p>As large language models continue to develop in the field of AI, text\ngeneration systems are susceptible to a worrisome phenomenon known as\nhallucination. In this study, we summarize recent compelling insights into\nhallucinations in LLMs. We present a novel taxonomy of hallucinations from\nvarious text generation tasks, thus provide theoretical insights, detection\nmethods and improvement approaches. Based on this, future research directions\nare proposed. Our contribution are threefold: (1) We provide a detailed and\ncomplete taxonomy for hallucinations appearing in text generation tasks; (2) We\nprovide theoretical analyses of hallucinations in LLMs and provide existing\ndetection and improvement methods; (3) We propose several research directions\nthat can be developed in the future. As hallucinations garner significant\nattention from the community, we will maintain updates on relevant research\nprogress.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hongbin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wei Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1\">Weiqiang Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Analysis of Contextual Relation Extraction based on Deep Learning Models. (arXiv:2309.06814v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06814","description":"<p>Contextual Relation Extraction (CRE) is mainly used for constructing a\nknowledge graph with a help of ontology. It performs various tasks such as\nsemantic search, query answering, and textual entailment. Relation extraction\nidentifies the entities from raw texts and the relations among them. An\nefficient and accurate CRE system is essential for creating domain knowledge in\nthe biomedical industry. Existing Machine Learning and Natural Language\nProcessing (NLP) techniques are not suitable to predict complex relations from\nsentences that consist of more than two relations and unspecified entities\nefficiently. In this work, deep learning techniques have been used to identify\nthe appropriate semantic relation based on the context from multiple sentences.\nEven though various machine learning models have been used for relation\nextraction, they provide better results only for binary relations, i.e.,\nrelations occurred exactly between the two entities in a sentence. Machine\nlearning models are not suited for complex sentences that consist of the words\nthat have various meanings. To address these issues, hybrid deep learning\nmodels have been used to extract the relations from complex sentence\neffectively. This paper explores the analysis of various deep learning models\nthat are used for relation extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Priyadharshini_R/0/1/0/all/0/1\">R.Priyadharshini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeyakodi_G/0/1/0/all/0/1\">G.Jeyakodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bala_P/0/1/0/all/0/1\">P.Shanthi Bala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gpachov at CheckThat! 2023: A Diverse Multi-Approach Ensemble for Subjectivity Detection in News Articles. (arXiv:2309.06844v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06844","description":"<p>The wide-spread use of social networks has given rise to subjective,\nmisleading, and even false information on the Internet. Thus, subjectivity\ndetection can play an important role in ensuring the objectiveness and the\nquality of a piece of information. This paper presents the solution built by\nthe Gpachov team for the CLEF-2023 CheckThat! lab Task~2 on subjectivity\ndetection. Three different research directions are explored. The first one is\nbased on fine-tuning a sentence embeddings encoder model and dimensionality\nreduction. The second one explores a sample-efficient few-shot learning model.\nThe third one evaluates fine-tuning a multilingual transformer on an altered\ndataset, using data from multiple languages. Finally, the three approaches are\ncombined in a simple majority voting ensemble, resulting in 0.77 macro F1 on\nthe test set and achieving 2nd place on the English subtask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pachov_G/0/1/0/all/0/1\">Georgi Pachov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimitrov_D/0/1/0/all/0/1\">Dimitar Dimitrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koychev_I/0/1/0/all/0/1\">Ivan Koychev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards the TopMost: A Topic Modeling System Toolkit. (arXiv:2309.06908v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06908","description":"<p>Topic models have been proposed for decades with various applications and\nrecently refreshed by the neural variational inference. However, these topic\nmodels adopt totally distinct dataset, implementation, and evaluation settings,\nwhich hinders their quick utilization and fair comparisons. This greatly\nhinders the research progress of topic models. To address these issues, in this\npaper we propose a Topic Modeling System Toolkit (TopMost). Compared to\nexisting toolkits, TopMost stands out by covering a wider range of topic\nmodeling scenarios including complete lifecycles with dataset pre-processing,\nmodel training, testing, and evaluations. The highly cohesive and decoupled\nmodular design of TopMost enables quick utilization, fair comparisons, and\nflexible extensions of different topic models. This can facilitate the research\nand applications of topic models. Our code, tutorials, and documentation are\navailable at https://github.com/bobxwu/topmost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaobao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1\">Fengjun Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continual Learning with Dirichlet Generative-based Rehearsal. (arXiv:2309.06917v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06917","description":"<p>Recent advancements in data-driven task-oriented dialogue systems (ToDs)\nstruggle with incremental learning due to computational constraints and\ntime-consuming issues. Continual Learning (CL) attempts to solve this by\navoiding intensive pre-training, but it faces the problem of catastrophic\nforgetting (CF). While generative-based rehearsal CL methods have made\nsignificant strides, generating pseudo samples that accurately reflect the\nunderlying task-specific distribution is still a challenge. In this paper, we\npresent Dirichlet Continual Learning (DCL), a novel generative-based rehearsal\nstrategy for CL. Unlike the traditionally used Gaussian latent variable in the\nConditional Variational Autoencoder (CVAE), DCL leverages the flexibility and\nversatility of the Dirichlet distribution to model the latent prior variable.\nThis enables it to efficiently capture sentence-level features of previous\ntasks and effectively guide the generation of pseudo samples. In addition, we\nintroduce Jensen-Shannon Knowledge Distillation (JSKD), a robust logit-based\nknowledge distillation method that enhances knowledge transfer during pseudo\nsample generation. Our experiments confirm the efficacy of our approach in both\nintent detection and slot-filling tasks, outperforming state-of-the-art\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Min Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wei Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Native Language Identification with Big Bird Embeddings. (arXiv:2309.06923v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06923","description":"<p>Native Language Identification (NLI) intends to classify an author's native\nlanguage based on their writing in another language. Historically, the task has\nheavily relied on time-consuming linguistic feature engineering, and\ntransformer-based NLI models have thus far failed to offer effective, practical\nalternatives. The current work investigates if input size is a limiting factor,\nand shows that classifiers trained using Big Bird embeddings outperform\nlinguistic feature engineering models by a large margin on the Reddit-L2\ndataset. Additionally, we provide further insight into input length\ndependencies, show consistent out-of-sample performance, and qualitatively\nanalyze the embedding space. Given the effectiveness and computational\nefficiency of this method, we believe it offers a promising avenue for future\nNLI work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kramp_S/0/1/0/all/0/1\">Sergey Kramp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cassani_G/0/1/0/all/0/1\">Giovanni Cassani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emmery_C/0/1/0/all/0/1\">Chris Emmery</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic Causal Disentanglement Model for Dialogue Emotion Detection. (arXiv:2309.06928v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06928","description":"<p>Emotion detection is a critical technology extensively employed in diverse\nfields. While the incorporation of commonsense knowledge has proven beneficial\nfor existing emotion detection methods, dialogue-based emotion detection\nencounters numerous difficulties and challenges due to human agency and the\nvariability of dialogue content.In dialogues, human emotions tend to accumulate\nin bursts. However, they are often implicitly expressed. This implies that many\ngenuine emotions remain concealed within a plethora of unrelated words and\ndialogues.In this paper, we propose a Dynamic Causal Disentanglement Model\nbased on hidden variable separation, which is founded on the separation of\nhidden variables. This model effectively decomposes the content of dialogues\nand investigates the temporal accumulation of emotions, thereby enabling more\nprecise emotion recognition. First, we introduce a novel Causal Directed\nAcyclic Graph (DAG) to establish the correlation between hidden emotional\ninformation and other observed elements. Subsequently, our approach utilizes\npre-extracted personal attributes and utterance topics as guiding factors for\nthe distribution of hidden variables, aiming to separate irrelevant ones.\nSpecifically, we propose a dynamic temporal disentanglement model to infer the\npropagation of utterances and hidden variables, enabling the accumulation of\nemotion-related information throughout the conversation. To guide this\ndisentanglement process, we leverage the ChatGPT-4.0 and LSTM networks to\nextract utterance topics and personal attributes as observed\ninformation.Finally, we test our approach on two popular datasets in dialogue\nemotion detection and relevant experimental results verified the model's\nsuperiority.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yuting Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yichen Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1\">Weizhi Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sicheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Anan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Auto-Regressive Next-Token Predictors are Universal Learners. (arXiv:2309.06979v1 [cs.LG])","link":"http://arxiv.org/abs/2309.06979","description":"<p>Large language models display remarkable capabilities in logical and\nmathematical reasoning, allowing them to solve complex tasks. Interestingly,\nthese abilities emerge in networks trained on the simple task of next-token\nprediction. In this work, we present a theoretical framework for studying\nauto-regressive next-token predictors. We demonstrate that even simple models\nsuch as linear next-token predictors, trained on Chain-of-Thought (CoT) data,\ncan approximate any function efficiently computed by a Turing machine. We\nintroduce a new complexity measure -- length complexity -- which measures the\nnumber of intermediate tokens in a CoT sequence required to approximate some\ntarget function, and analyze the interplay between length complexity and other\nnotions of complexity. Finally, we show experimentally that simple next-token\npredictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs),\ndisplay non-trivial performance on text generation and arithmetic tasks. Our\nresults demonstrate that the power of language models can be attributed, to a\ngreat extent, to the auto-regressive next-token training scheme, and not\nnecessarily to a particular choice of architecture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1\">Eran Malach</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Remote Inference of Cognitive Scores in ALS Patients Using a Picture Description. (arXiv:2309.06989v1 [cs.CL])","link":"http://arxiv.org/abs/2309.06989","description":"<p>Amyotrophic lateral sclerosis is a fatal disease that not only affects\nmovement, speech, and breath but also cognition. Recent studies have focused on\nthe use of language analysis techniques to detect ALS and infer scales for\nmonitoring functional progression. In this paper, we focused on another\nimportant aspect, cognitive impairment, which affects 35-50% of the ALS\npopulation. In an effort to reach the ALS population, which frequently exhibits\nmobility limitations, we implemented the digital version of the Edinburgh\nCognitive and Behavioral ALS Screen (ECAS) test for the first time. This test\nwhich is designed to measure cognitive impairment was remotely performed by 56\nparticipants from the EverythingALS Speech Study. As part of the study,\nparticipants (ALS and non-ALS) were asked to describe weekly one picture from a\npool of many pictures with complex scenes displayed on their computer at home.\nWe analyze the descriptions performed within +/- 60 days from the day the ECAS\ntest was administered and extract different types of linguistic and acoustic\nfeatures. We input those features into linear regression models to infer 5 ECAS\nsub-scores and the total score. Speech samples from the picture description are\nreliable enough to predict the ECAS subs-scores, achieving statistically\nsignificant Spearman correlation values between 0.32 and 0.51 for the model's\nperformance using 10-fold cross-validation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agurto_C/0/1/0/all/0/1\">Carla Agurto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1\">Guillermo Cecchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_B/0/1/0/all/0/1\">Bo Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fraenkel_E/0/1/0/all/0/1\">Ernest Fraenkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berry_J/0/1/0/all/0/1\">James Berry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Navar_I/0/1/0/all/0/1\">Indu Navar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Norel_R/0/1/0/all/0/1\">Raquel Norel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Contrast-Consistent Ranking with Language Models. (arXiv:2309.06991v1 [cs.LG])","link":"http://arxiv.org/abs/2309.06991","description":"<p>Language models contain ranking-based knowledge and are powerful solvers of\nin-context ranking tasks. For instance, they may have parametric knowledge\nabout the ordering of countries by size or may be able to rank reviews by\nsentiment. Recent work focuses on pairwise, pointwise, and listwise prompting\ntechniques to elicit a language model's ranking knowledge. However, we find\nthat even with careful calibration and constrained decoding, prompting-based\ntechniques may not always be self-consistent in the rankings they produce. This\nmotivates us to explore an alternative approach that is inspired by an\nunsupervised probing method called Contrast-Consistent Search (CCS). The idea\nis to train a probing model guided by a logical constraint: a model's\nrepresentation of a statement and its negation must be mapped to contrastive\ntrue-false poles consistently across multiple statements. We hypothesize that\nsimilar constraints apply to ranking tasks where all items are related via\nconsistent pairwise or listwise comparisons. To this end, we extend the binary\nCCS method to Contrast-Consistent Ranking (CCR) by adapting existing ranking\nmethods such as the Max-Margin Loss, Triplet Loss, and Ordinal Regression\nobjective. Our results confirm that, for the same language model, CCR probing\noutperforms prompting and even performs on a par with prompting much larger\nlanguage models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stoehr_N/0/1/0/all/0/1\">Niklas Stoehr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_P/0/1/0/all/0/1\">Pengxiang Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Preotiuc_Pietro_D/0/1/0/all/0/1\">Daniel Preotiuc-Pietro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhowmik_R/0/1/0/all/0/1\">Rajarshi Bhowmik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OYXOY: A Modern NLP Test Suite for Modern Greek. (arXiv:2309.07009v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07009","description":"<p>This paper serves as a foundational step towards the development of a\nlinguistically motivated and technically relevant evaluation suite for Greek\nNLP. We initiate this endeavor by introducing four expert-verified evaluation\ntasks, specifically targeted at natural language inference, word sense\ndisambiguation (through example comparison or sense selection) and metaphor\ndetection. More than language-adapted replicas of existing tasks, we contribute\ntwo innovations which will resonate with the broader resource and evaluation\ncommunity. Firstly, our inference dataset is the first of its kind, marking not\njust \\textit{one}, but rather \\textit{all} possible inference labels,\naccounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we\ndemonstrate a cost-efficient method to obtain datasets for under-resourced\nlanguages. Using ChatGPT as a language-neutral parser, we transform the\nDictionary of Standard Modern Greek into a structured format, from which we\nderive the other three tasks through simple projections. Alongside each task,\nwe conduct experiments using currently available state of the art machinery.\nOur experimental baselines affirm the challenging nature of our tasks and\nhighlight the need for expedited progress in order for the Greek NLP ecosystem\nto keep pace with contemporary mainstream research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kogkalidis_K/0/1/0/all/0/1\">Konstantinos Kogkalidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatzikyriakidis_S/0/1/0/all/0/1\">Stergios Chatzikyriakidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Giannikouri_E/0/1/0/all/0/1\">Eirini Chrysovalantou Giannikouri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsouli_V/0/1/0/all/0/1\">Vassiliki Katsouli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klironomou_C/0/1/0/all/0/1\">Christina Klironomou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koula_C/0/1/0/all/0/1\">Christina Koula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadakis_D/0/1/0/all/0/1\">Dimitris Papadakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasparaki_T/0/1/0/all/0/1\">Thelka Pasparaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Psaltaki_E/0/1/0/all/0/1\">Erofili Psaltaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakellariou_E/0/1/0/all/0/1\">Efthymia Sakellariou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soupiona_H/0/1/0/all/0/1\">Hara Soupiona</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"R\\'esum\\'e Parsing as Hierarchical Sequence Labeling: An Empirical Study. (arXiv:2309.07015v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07015","description":"<p>Extracting information from r\\'esum\\'es is typically formulated as a\ntwo-stage problem, where the document is first segmented into sections and then\neach section is processed individually to extract the target entities. Instead,\nwe cast the whole problem as sequence labeling in two levels -- lines and\ntokens -- and study model architectures for solving both tasks simultaneously.\nWe build high-quality r\\'esum\\'e parsing corpora in English, French, Chinese,\nSpanish, German, Portuguese, and Swedish. Based on these corpora, we present\nexperimental results that demonstrate the effectiveness of the proposed models\nfor the information extraction task, outperforming approaches introduced in\nprevious work. We conduct an ablation study of the proposed architectures. We\nalso analyze both model performance and resource efficiency, and describe the\ntrade-offs for model deployment in the context of a production environment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Retyk_F/0/1/0/all/0/1\">Federico Retyk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fabregat_H/0/1/0/all/0/1\">Hermenegildo Fabregat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aizpuru_J/0/1/0/all/0/1\">Juan Aizpuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taglio_M/0/1/0/all/0/1\">Mariana Taglio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zbib_R/0/1/0/all/0/1\">Rabih Zbib</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond original Research Articles Categorization via NLP. (arXiv:2309.07020v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07020","description":"<p>This work proposes a novel approach to text categorization -- for unknown\ncategories -- in the context of scientific literature, using Natural Language\nProcessing techniques. The study leverages the power of pre-trained language\nmodels, specifically SciBERT, to extract meaningful representations of\nabstracts from the ArXiv dataset. Text categorization is performed using the\nK-Means algorithm, and the optimal number of clusters is determined based on\nthe Silhouette score. The results demonstrate that the proposed approach\ncaptures subject information more effectively than the traditional arXiv\nlabeling system, leading to improved text categorization. The approach offers\npotential for better navigation and recommendation systems in the rapidly\ngrowing landscape of scientific research literature.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Turrisi_R/0/1/0/all/0/1\">Rosanna Turrisi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How (Not) to Use Sociodemographic Information for Subjective NLP Tasks. (arXiv:2309.07034v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07034","description":"<p>Annotators' sociodemographic backgrounds (i.e., the individual compositions\nof their gender, age, educational background, etc.) have a strong impact on\ntheir decisions when working on subjective NLP tasks, such as hate speech\ndetection. Often, heterogeneous backgrounds result in high disagreements. To\nmodel this variation, recent work has explored sociodemographic prompting, a\ntechnique, which steers the output of prompt-based models towards answers that\nhumans with specific sociodemographic profiles would give. However, the\navailable NLP literature disagrees on the efficacy of this technique -- it\nremains unclear, for which tasks and scenarios it can help and evaluations are\nlimited to specific tasks only. We address this research gap by presenting the\nlargest and most comprehensive study of sociodemographic prompting today.\nConcretely, we evaluate several prompt formulations across seven datasets and\nsix instruction-tuned model families. We find that (1) while sociodemographic\nprompting can be beneficial for improving zero-shot learning in subjective NLP\ntasks, (2) its outcomes largely vary for different model types, sizes, and\ndatasets, (3) are subject to large variance with regards to prompt\nformulations. Thus, sociodemographic prompting is not a reliable proxy for\ntraditional data annotation with a sociodemographically heterogeneous group of\nannotators. Instead, we propose (4) to use it for identifying ambiguous\ninstances resulting in more informed annotation efforts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Beck_T/0/1/0/all/0/1\">Tilman Beck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuff_H/0/1/0/all/0/1\">Hendrik Schuff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lauscher_A/0/1/0/all/0/1\">Anne Lauscher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SafetyBench: Evaluating the Safety of Large Language Models with Multiple Choice Questions. (arXiv:2309.07045v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07045","description":"<p>With the rapid development of Large Language Models (LLMs), increasing\nattention has been paid to their safety concerns. Consequently, evaluating the\nsafety of LLMs has become an essential task for facilitating the broad\napplications of LLMs. Nevertheless, the absence of comprehensive safety\nevaluation benchmarks poses a significant impediment to effectively assess and\nenhance the safety of LLMs. In this work, we present SafetyBench, a\ncomprehensive benchmark for evaluating the safety of LLMs, which comprises\n11,435 diverse multiple choice questions spanning across 7 distinct categories\nof safety concerns. Notably, SafetyBench also incorporates both Chinese and\nEnglish data, facilitating the evaluation in both languages. Our extensive\ntests over 25 popular Chinese and English LLMs in both zero-shot and few-shot\nsettings reveal a substantial performance advantage for GPT-4 over its\ncounterparts, and there is still significant room for improving the safety of\ncurrent LLMs. We believe SafetyBench will enable fast and comprehensive\nevaluation of LLMs' safety, and foster the development of safer LLMs. Data and\nevaluation guidelines are available at https://github.com/thu-coai/SafetyBench.\nSubmission entrance and leaderboard are available at\nhttps://llmbench.ai/safety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhexin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_L/0/1/0/all/0/1\">Leqi Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Lindong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Rui Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yongkang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1\">Chong Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1\">Xuanyu Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models for Compiler Optimization. (arXiv:2309.07062v1 [cs.PL])","link":"http://arxiv.org/abs/2309.07062","description":"<p>We explore the novel application of Large Language Models to code\noptimization. We present a 7B-parameter transformer model trained from scratch\nto optimize LLVM assembly for code size. The model takes as input unoptimized\nassembly and outputs a list of compiler options to best optimize the program.\nCrucially, during training, we ask the model to predict the instruction counts\nbefore and after optimization, and the optimized code itself. These auxiliary\nlearning tasks significantly improve the optimization performance of the model\nand improve the model's depth of understanding.\n</p>\n<p>We evaluate on a large suite of test programs. Our approach achieves a 3.0%\nimprovement in reducing instruction counts over the compiler, outperforming two\nstate-of-the-art baselines that require thousands of compilations. Furthermore,\nthe model shows surprisingly strong code reasoning abilities, generating\ncompilable code 91% of the time and perfectly emulating the output of the\ncompiler 70% of the time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cummins_C/0/1/0/all/0/1\">Chris Cummins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seeker_V/0/1/0/all/0/1\">Volker Seeker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grubisic_D/0/1/0/all/0/1\">Dejan Grubisic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1\">Mostafa Elhoushi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Youwei Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roziere_B/0/1/0/all/0/1\">Baptiste Roziere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehring_J/0/1/0/all/0/1\">Jonas Gehring</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gloeckle_F/0/1/0/all/0/1\">Fabian Gloeckle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazelwood_K/0/1/0/all/0/1\">Kim Hazelwood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1\">Gabriel Synnaeve</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leather_H/0/1/0/all/0/1\">Hugh Leather</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Whisper perform speech-based in-context learning. (arXiv:2309.07081v1 [eess.AS])","link":"http://arxiv.org/abs/2309.07081","description":"<p>This paper investigates the in-context learning abilities of the Whisper\nautomatic speech recognition (ASR) models released by OpenAI. A novel\nspeech-based in-context learning (SICL) approach is proposed for test-time\nadaptation, which can reduce the word error rates (WERs) with only a small\nnumber of labelled speech samples without gradient descent. Language-level\nadaptation experiments using Chinese dialects showed that when applying SICL to\nisolated word ASR, consistent and considerable relative WER reductions can be\nachieved using Whisper models of any size on two dialects, which is on average\n32.3%. A k-nearest-neighbours-based in-context example selection technique can\nbe applied to further improve the efficiency of SICL, which can increase the\naverage relative WER reduction to 36.4%. The findings are verified using\nspeaker adaptation or continuous speech recognition tasks, and both achieved\nconsiderable relative WER reductions. Detailed quantitative analyses are also\nprovided to shed light on SICL's adaptability to phonological variances and\ndialect-specific lexical nuances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1\">Siyin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1\">Ji Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Hallucinations and Off-target Machine Translation with Source-Contrastive and Language-Contrastive Decoding. (arXiv:2309.07098v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07098","description":"<p>Hallucinations and off-target translation remain unsolved problems in machine\ntranslation, especially for low-resource languages and massively multilingual\nmodels. In this paper, we introduce methods to mitigate both failure cases with\na modified decoding objective, without requiring retraining or external models.\nIn source-contrastive decoding, we search for a translation that is probable\ngiven the correct input, but improbable given a random input segment,\nhypothesising that hallucinations will be similarly probable given either. In\nlanguage-contrastive decoding, we search for a translation that is probable,\nbut improbable given the wrong language indicator token. In experiments on\nM2M-100 (418M) and SMaLL-100, we find that these methods effectively suppress\nhallucinations and off-target translations, improving chrF2 by 1.7 and 1.4\npoints on average across 57 tested translation directions. In a proof of\nconcept on English--German, we also show that we can suppress off-target\ntranslations with the Llama 2 chat models, demonstrating the applicability of\nthe method to machine translation with LLMs. We release our source code at\nhttps://github.com/ZurichNLP/ContraDecode.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammadshahi_A/0/1/0/all/0/1\">Alireza Mohammadshahi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness and Ethics. (arXiv:2309.07120v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07120","description":"<p>Multi-modal large language models (MLLMs) are trained based on large language\nmodels (LLM), with an enhanced capability to comprehend multi-modal inputs and\ngenerate textual responses. While they excel in multi-modal tasks, the pure NLP\nabilities of MLLMs are often underestimated and left untested. In this study,\nwe get out of the box and unveil an intriguing characteristic of MLLMs -- our\npreliminary results suggest that visual instruction tuning, a prevailing\nstrategy for transitioning LLMs into MLLMs, unexpectedly and interestingly\nhelps models attain both improved truthfulness and ethical alignment in the\npure NLP context. For example, a visual-instruction-tuned LLaMA2 7B model\nsurpasses the performance of the LLaMA2-chat 7B model, fine-tuned with over one\nmillion human annotations, on TruthfulQA-mc and Ethics benchmarks. Further\nanalysis reveals that the improved alignment can be attributed to the superior\ninstruction quality inherent to visual-text data. In releasing our code at\ngithub.com/UCSC-VLAA/Sight-Beyond-Text, we aspire to foster further exploration\ninto the intrinsic value of visual-text synergies and, in a broader scope,\nmulti-modal interactions in alignment research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_H/0/1/0/all/0/1\">Haoqin Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Bingchen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chen Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1\">Cihang Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RAIN: Your Language Models Can Align Themselves without Finetuning. (arXiv:2309.07124v1 [cs.CL])","link":"http://arxiv.org/abs/2309.07124","description":"<p>Large language models (LLMs) often demonstrate inconsistencies with human\npreferences. Previous research gathered human preference data and then aligned\nthe pre-trained models using reinforcement learning or instruction tuning, the\nso-called finetuning step. In contrast, aligning frozen LLMs without any extra\ndata is more appealing. This work explores the potential of the latter setting.\nWe discover that by integrating self-evaluation and rewind mechanisms,\nunaligned LLMs can directly produce responses consistent with human preferences\nvia self-boosting. We introduce a novel inference method, Rewindable\nAuto-regressive INference (RAIN), that allows pre-trained LLMs to evaluate\ntheir own generation and use the evaluation results to guide backward rewind\nand forward generation for AI safety. Notably, RAIN operates without the need\nof extra data for model alignment and abstains from any training, gradient\ncomputation, or parameter updates; during the self-evaluation phase, the model\nreceives guidance on which human preference to align with through a\nfixed-template prompt, eliminating the need to modify the initial prompt.\nExperimental results evaluated by GPT-4 and humans demonstrate the\neffectiveness of RAIN: on the HH dataset, RAIN improves the harmlessness rate\nof LLaMA 30B over vanilla inference from 82% to 97%, while maintaining the\nhelpfulness rate. Under the leading adversarial attack llm-attacks on Vicuna\n33B, RAIN establishes a new defense baseline by reducing the attack success\nrate from 94% to 19%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Fangyun Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jinjing Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Event and Entity Extraction from Generated Video Captions. (arXiv:2211.02982v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.02982","description":"<p>Annotation of multimedia data by humans is time-consuming and costly, while\nreliable automatic generation of semantic metadata is a major challenge. We\npropose a framework to extract semantic metadata from automatically generated\nvideo captions. As metadata, we consider entities, the entities' properties,\nrelations between entities, and the video category. We employ two\nstate-of-the-art dense video captioning models with masked transformer (MT) and\nparallel decoding (PVDC) to generate captions for videos of the ActivityNet\nCaptions dataset. Our experiments show that it is possible to extract entities,\ntheir properties, relations between entities, and the video category from the\ngenerated captions. We observe that the quality of the extracted information is\nmainly influenced by the quality of the event localization in the video as well\nas the performance of the event caption generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scherer_J/0/1/0/all/0/1\">Johannes Scherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherp_A/0/1/0/all/0/1\">Ansgar Scherp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhowmik_D/0/1/0/all/0/1\">Deepayan Bhowmik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ColD Fusion: Collaborative Descent for Distributed Multitask Finetuning. (arXiv:2212.01378v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.01378","description":"<p>We propose a new paradigm to continually evolve pretrained models, denoted\nColD Fusion. It provides the benefits of multitask learning but leverages\ndistributed computation with limited communication and eliminates the need for\nshared data. Consequentially, ColD Fusion can give rise to a synergistic loop,\nwhere finetuned models can be recycled to continually improve the pretrained\nmodel they are based upon. We show that ColD Fusion yields comparable benefits\nto multitask training by producing a model that (a) attains strong performance\non all of the datasets it was trained on; and (b) is a better starting point\nfor finetuning on unseen datasets. We show that ColD Fusion outperforms RoBERTa\nand even previous multitask models. Specifically, when training and testing on\n35 diverse datasets, ColD Fusion-based model outperforms RoBERTa by 2.33 points\non average without any changes to the architecture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Don_Yehiya_S/0/1/0/all/0/1\">Shachar Don-Yehiya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venezian_E/0/1/0/all/0/1\">Elad Venezian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katz_Y/0/1/0/all/0/1\">Yoav Katz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diminished Diversity-of-Thought in a Standard Large Language Model. (arXiv:2302.07267v6 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2302.07267","description":"<p>We test whether Large Language Models (LLMs) can be used to simulate human\nparticipants in social-science studies. To do this, we run replications of 14\nstudies from the Many Labs 2 replication project with OpenAI's text-davinci-003\nmodel, colloquially known as GPT3.5. Based on our pre-registered analyses, we\nfind that among the eight studies we could analyse, our GPT sample replicated\n37.5% of the original results and 37.5% of the Many Labs 2 results. However, we\nwere unable to analyse the remaining six studies due to an unexpected\nphenomenon we call the \"correct answer\" effect. Different runs of GPT3.5\nanswered nuanced questions probing political orientation, economic preference,\njudgement, and moral philosophy with zero or near-zero variation in responses:\nwith the supposedly \"correct answer.\" In one exploratory follow-up study, we\nfound that a \"correct answer\" was robust to changing the demographic details\nthat precede the prompt. In another, we found that most but not all \"correct\nanswers\" were robust to changing the order of answer choices. One of our most\nstriking findings occurred in our replication of the Moral Foundations Theory\nsurvey results, where we found GPT3.5 identifying as a political conservative\nin 99.6% of the cases, and as a liberal in 99.3% of the cases in the\nreverse-order condition. However, both self-reported 'GPT conservatives' and\n'GPT liberals' showed right-leaning moral foundations. Our results cast doubts\non the validity of using LLMs as a general replacement for human participants\nin the social sciences. Our results also raise concerns that a hypothetical\nAI-led future may be subject to a diminished diversity-of-thought.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_P/0/1/0/all/0/1\">Peter S. Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoenegger_P/0/1/0/all/0/1\">Philipp Schoenegger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chongyang Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects. (arXiv:2304.11075v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11075","description":"<p>Recent breakthroughs in NLP largely increased the presence of ASR systems in\nour daily lives. However, for many low-resource languages, ASR models still\nneed to be improved due in part to the difficulty of acquiring pertinent data.\nThis project aims to help advance research in ASR models for Swiss German\ndialects, by providing insights about the performance of state-of-the-art ASR\nmodels on recently published Swiss German speech datasets. We propose a novel\nloss that takes into account the semantic distance between the predicted and\nthe ground-truth labels. We outperform current state-of-the-art results by\nfine-tuning OpenAI's Whisper model on Swiss-German datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sicard_C/0/1/0/all/0/1\">Clement Sicard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyszkowski_K/0/1/0/all/0/1\">Kajetan Pyszkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillioz_V/0/1/0/all/0/1\">Victor Gillioz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Processing Natural Language on Embedded Devices: How Well Do Modern Models Perform?. (arXiv:2304.11520v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11520","description":"<p>Voice-controlled systems are becoming ubiquitous in many IoT-specific\napplications such as home/industrial automation, automotive infotainment, and\nhealthcare. While cloud-based voice services (\\eg Alexa, Siri) can leverage\nhigh-performance computing servers, some use cases (\\eg robotics, automotive\ninfotainment) may require to execute the natural language processing (NLP)\ntasks offline, often on resource-constrained embedded devices. Large language\nmodels such as BERT and its variants are primarily developed with compute-heavy\nservers in mind. Despite the great performance of BERT models across various\nNLP tasks, their large size and numerous parameters pose substantial obstacles\nto offline computation on embedded systems. Lighter replacement of such\nlanguage models (\\eg DistilBERT and TinyBERT) often sacrifice accuracy,\nparticularly for complex NLP tasks. Until now, it is still unclear \\ca whether\nthe state-of-the-art language models, \\viz BERT and its variants are deployable\non embedded systems with a limited processor, memory, and battery power and \\cb\nif they do, what are the ``right'' set of configurations and parameters to\nchoose for a given NLP task. This paper presents an \\textit{exploratory study\nof modern language models} under different resource constraints and accuracy\nbudgets to derive empirical observations about these resource/accuracy\ntrade-offs. In particular, we study how the four most commonly used BERT-based\nlanguage models (\\eg BERT, RoBERTa, DistilBERT, and TinyBERT) perform on\nembedded systems. We tested them on a Raspberry Pi-based robotic platform with\nthree hardware configurations and four datasets running various NLP tasks. Our\nfindings can help designers to understand the deployability and performance of\nmodern language models, especially those based on BERT architectures, thus\nsaving a lot of time wasted in trial-and-error efforts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarkar_S/0/1/0/all/0/1\">Souvika Sarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babar_M/0/1/0/all/0/1\">Mohammad Fakhruddin Babar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassan_M/0/1/0/all/0/1\">Md Mahadi Hassan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1\">Monowar Hasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker Santu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency Model. (arXiv:2305.06908v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2305.06908","description":"<p>Denoising diffusion probabilistic models (DDPMs) have shown promising\nperformance for speech synthesis. However, a large number of iterative steps\nare required to achieve high sample quality, which restricts the inference\nspeed. Maintaining sample quality while increasing sampling speed has become a\nchallenging task. In this paper, we propose a \"Co\"nsistency \"Mo\"del-based\n\"Speech\" synthesis method, CoMoSpeech, which achieve speech synthesis through a\nsingle diffusion sampling step while achieving high audio quality. The\nconsistency constraint is applied to distill a consistency model from a\nwell-designed diffusion-based teacher model, which ultimately yields superior\nperformances in the distilled CoMoSpeech. Our experiments show that by\ngenerating audio recordings by a single sampling step, the CoMoSpeech achieves\nan inference speed more than 150 times faster than real-time on a single NVIDIA\nA100 GPU, which is comparable to FastSpeech2, making diffusion-sampling based\nspeech synthesis truly practical. Meanwhile, objective and subjective\nevaluations on text-to-speech and singing voice synthesis show that the\nproposed teacher models yield the best audio quality, and the one-step sampling\nbased CoMoSpeech achieves the best inference speed with better or comparable\naudio quality to other conventional multi-step diffusion model baselines. Audio\nsamples are available at https://comospeech.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1\">Zhen Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1\">Wei Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yike Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does ChatGPT have Theory of Mind?. (arXiv:2305.14020v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14020","description":"<p>Theory of Mind (ToM) is the ability to understand human thinking and\ndecision-making, an ability that plays a crucial role in social interaction\nbetween people, including linguistic communication. This paper investigates to\nwhat extent recent Large Language Models in the ChatGPT tradition possess ToM.\nWe posed six well-known problems that address biases in human reasoning and\ndecision making to two versions of ChatGPT and we compared the results under a\nrange of prompting strategies. While the results concerning ChatGPT-3 were\nsomewhat inconclusive, ChatGPT-4 was shown to arrive at the correct answers\nmore often than would be expected based on chance, although correct answers\nwere often arrived at on the basis of false assumptions or invalid reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Holterman_B/0/1/0/all/0/1\">Bart Holterman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deemter_K/0/1/0/all/0/1\">Kees van Deemter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Language Models Know When They're Hallucinating References?. (arXiv:2305.18248v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18248","description":"<p>State-of-the-art language models (LMs) are famous for \"hallucinating\"\nreferences. These fabricated article and book titles lead to harms, obstacles\nto their use, and public backlash. While other types of LM hallucinations are\nalso important, we propose hallucinated references as the \"drosophila\" of\nresearch on hallucination in large language models (LLMs), as they are\nparticularly easy to study. We show that simple search engine queries reliably\nidentify such hallucinations, which facilitates evaluation. To begin to dissect\nthe nature of hallucinated LM references, we attempt to classify them using\nblack-box queries to the same LM, without consulting any external resources.\nConsistency checks done with \"direct\" queries about whether the generated\nreference title is real (inspired by Kadavath et al. 2022, Lin et al. 2022,\nManakul et al. 2023) are compared to consistency checks with \"indirect\" queries\nwhich ask for ancillary details such as the authors of the work. These\nconsistency checks are found to be partially reliable indicators of whether or\nnot the reference is a hallucination. In particular, we find that LMs often\nhallucinate differing authors of hallucinated references when queried in\nindependent sessions, while consistently identify authors of real references.\nThis suggests that the hallucination may be more a generation issue than\ninherent to current training techniques or representation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Ayush Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzgun_M/0/1/0/all/0/1\">Mirac Suzgun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1\">Lester Mackey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1\">Adam Tauman Kalai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio Pretraining for Accurate Speech Emotion Recognition. (arXiv:2306.07848v8 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.07848","description":"<p>Contrastive cross-modality pretraining has recently exhibited impressive\nsuccess in diverse fields, whereas there is limited research on their merits in\nspeech emotion recognition (SER). In this paper, we propose GEmo-CLAP, a kind\nof gender-attribute-enhanced contrastive language-audio pretraining (CLAP)\nmethod for SER. Specifically, we first construct an effective emotion CLAP\n(Emo-CLAP) for SER, using pre-trained text and audio encoders. Second, given\nthe significance of gender information in SER, two novel multi-task learning\nbased GEmo-CLAP (ML-GEmo-CLAP) and soft label based GEmo-CLAP (SL-GEmo-CLAP)\nmodels are further proposed to incorporate gender information of speech\nsignals, forming more reasonable objectives. Experiments on IEMOCAP indicate\nthat our proposed two GEmo-CLAPs consistently outperform Emo-CLAP with\ndifferent pre-trained models. Remarkably, the proposed WavLM-based SL-GEmo-CLAP\nobtains the best UAR of 81.43% and WAR of 83.16%, which performs better than\nstate-of-the-art SER methods by at least 3%. Our system is open-sourced on\nGithub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yanni Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuguang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_W/0/1/0/all/0/1\">Wen Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jixun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Heng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jianjun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-corpus Readability Compatibility Assessment for English Texts. (arXiv:2306.09704v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09704","description":"<p>Text readability assessment has gained significant attention from researchers\nin various domains. However, the lack of exploration into corpus compatibility\nposes a challenge as different research groups utilize different corpora. In\nthis study, we propose a novel evaluation framework, Cross-corpus text\nReadability Compatibility Assessment (CRCA), to address this issue. The\nframework encompasses three key components: (1) Corpus: CEFR, CLEC, CLOTH, NES,\nOSP, and RACE. Linguistic features, GloVe word vector representations, and\ntheir fusion features were extracted. (2) Classification models: Machine\nlearning methods (XGBoost, SVM) and deep learning methods (BiLSTM,\nAttention-BiLSTM) were employed. (3) Compatibility metrics: RJSD, RRNSS, and\nNDCG metrics. Our findings revealed: (1) Validated corpus compatibility, with\nOSP standing out as significantly different from other datasets. (2) An\nadaptation effect among corpora, feature representations, and classification\nmethods. (3) Consistent outcomes across the three metrics, validating the\nrobustness of the compatibility assessment framework. The outcomes of this\nstudy offer valuable insights into corpus selection, feature representation,\nand classification methods, and it can also serve as a beginning effort for\ncross-corpus transfer learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1\">Han Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaohong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Overview of Large Language Models. (arXiv:2307.06435v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.06435","description":"<p>Large Language Models (LLMs) have recently demonstrated remarkable\ncapabilities in natural language processing tasks and beyond. This success of\nLLMs has led to a large influx of research contributions in this direction.\nThese works encompass diverse topics such as architectural innovations of the\nunderlying neural networks, context length improvements, model alignment,\ntraining datasets, benchmarking, efficiency and more. With the rapid\ndevelopment of techniques and regular breakthroughs in LLM research, it has\nbecome considerably challenging to perceive the bigger picture of the advances\nin this direction. Considering the rapidly emerging plethora of literature on\nLLMs, it is imperative that the research community is able to benefit from a\nconcise yet comprehensive overview of the recent developments in this field.\nThis article provides that overview to the research community. It not only\nfocuses on a systematic treatment of the existing literature on a broad range\nof LLM related concept, but also pays special attention to providing\ncomprehensive summaries with extensive details about the individual existing\nmodels, datasets and major insights. We also pay heed to aligning our overview\nwith the emerging outlook of this research direction by accounting for the\nother recently materializing reviews of the broader research direction of LLMs.\nOur self-contained comprehensive overview of LLMs discusses relevant background\nconcepts along with covering the advanced topics at the frontier of this\nresearch direction. This review article is intended to not only provide a\nsystematic survey, but also a quick comprehensive reference for the researchers\nand practitioners to draw insights from extensive informative summaries of the\nexisting works to advance the LLM research direction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naveed_H/0/1/0/all/0/1\">Humza Naveed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Asad Ullah Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1\">Shi Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saqib_M/0/1/0/all/0/1\">Muhammad Saqib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anwar_S/0/1/0/all/0/1\">Saeed Anwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1\">Muhammad Usman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1\">Naveed Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1\">Nick Barnes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1\">Ajmal Mian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Findings of Factify 2: Multimodal Fake News Detection. (arXiv:2307.10475v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.10475","description":"<p>With social media usage growing exponentially in the past few years, fake\nnews has also become extremely prevalent. The detrimental impact of fake news\nemphasizes the need for research focused on automating the detection of false\ninformation and verifying its accuracy. In this work, we present the outcome of\nthe Factify 2 shared task, which provides a multi-modal fact verification and\nsatire news dataset, as part of the DeFactify 2 workshop at AAAI'23. The data\ncalls for a comparison based approach to the task by pairing social media\nclaims with supporting documents, with both text and image, divided into 5\nclasses based on multi-modal relations. In the second iteration of this task we\nhad over 60 participants and 9 final test-set submissions. The best\nperformances came from the use of DeBERTa for text and Swinv2 and CLIP for\nimage. The highest F1 score averaged for all five classes was 81.82%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suryavardan_S/0/1/0/all/0/1\">S Suryavardan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1\">Shreyash Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1\">Megha Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1\">Parth Patwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1\">Anku Rani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reganti_A/0/1/0/all/0/1\">Aishwarya Reganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinnakotla_M/0/1/0/all/0/1\">Manoj Chinnakotla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ekbal_A/0/1/0/all/0/1\">Asif Ekbal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Srijan Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GRDD: A Dataset for Greek Dialectal NLP. (arXiv:2308.00802v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.00802","description":"<p>In this paper, we present a dataset for the computational study of a number\nof Modern Greek dialects. It consists of raw text data from four dialects of\nModern Greek, Cretan, Pontic, Northern Greek and Cypriot Greek. The dataset is\nof considerable size, albeit imbalanced, and presents the first attempt to\ncreate large scale dialectal resources of this type for Modern Greek dialects.\nWe then use the dataset to perform dialect idefntification. We experiment with\ntraditional ML algorithms, as well as simple DL architectures. The results show\nvery good performance on the task, potentially revealing that the dialects in\nquestion have distinct enough characteristics allowing even simple ML models to\nperform well on the task. Error analysis is performed for the top performing\nalgorithms showing that in a number of cases the errors are due to insufficient\ndataset cleaning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chatzikyriakidis_S/0/1/0/all/0/1\">Stergios Chatzikyriakidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qwaider_C/0/1/0/all/0/1\">Chatrine Qwaider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolokousis_I/0/1/0/all/0/1\">Ilias Kolokousis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koula_C/0/1/0/all/0/1\">Christina Koula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papadakis_D/0/1/0/all/0/1\">Dimitris Papadakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakellariou_E/0/1/0/all/0/1\">Efthymia Sakellariou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Relationship on Learning Mathematical Reasoning with Large Language Models. (arXiv:2308.01825v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01825","description":"<p>Mathematical reasoning is a challenging task for large language models\n(LLMs), while the scaling relationship of it with respect to LLM capacity is\nunder-explored. In this paper, we investigate how the pre-training loss,\nsupervised data amount, and augmented data amount influence the reasoning\nperformances of a supervised LLM. We find that pre-training loss is a better\nindicator of the model's performance than the model's parameter count. We apply\nsupervised fine-tuning (SFT) with different amounts of supervised data and\nempirically find a log-linear relation between data amount and model\nperformance, and we find better models improve less with enlarged supervised\ndatasets. To augment more data samples for improving model performances without\nany human effort, we propose to apply Rejection sampling Fine-Tuning (RFT). RFT\nuses supervised models to generate and collect correct reasoning paths as\naugmented fine-tuning datasets. We find with augmented samples containing more\ndistinct reasoning paths, RFT improves mathematical reasoning performance more\nfor LLMs. We also find RFT brings more improvement for less performant LLMs.\nFurthermore, we combine rejection samples from multiple models which push\nLLaMA-7B to an accuracy of 49.3\\% on GSM8K which outperforms the supervised\nfine-tuning (SFT) accuracy of 35.9\\% significantly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongyi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengpeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Guanting Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Keming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and Effective Hotword Customization Ability. (arXiv:2308.03266v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2308.03266","description":"<p>Hotword customization is one of the concerned issues remained in ASR field -\nit is of value to enable users of ASR systems to customize names of entities,\npersons and other phrases to obtain better experience. The past few years have\nseen effective modeling strategies for ASR contextualization developed, but\nthey still exhibit space for improvement about training stability and the\ninvisible activation process. In this paper we propose Semantic-Augmented\nContextual-Paraformer (SeACo-Paraformer) a novel NAR based ASR system with\nflexible and effective hotword customization ability. It possesses the\nadvantages of AED-based model's accuracy, NAR model's efficiency, and explicit\ncustomization capacity of superior performance. Through extensive experiments\nwith 50,000 hours of industrial big data, our proposed model outperforms strong\nbaselines in customization. Besides, we explore an efficient way to filter\nlarge-scale incoming hotwords for further improvement. The industrial models\ncompared, source codes and two hotword test sets are all open source.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yexin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zerui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanni Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Zhifu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages. (arXiv:2308.09435v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.09435","description":"<p>Modern large language models demonstrate impressive capabilities in text\ngeneration and generalization. However, they often struggle with solving text\nediting tasks, particularly when it comes to correcting spelling errors and\nmistypings. In this paper, we present a methodology for generative spelling\ncorrection (SC), which was tested on English and Russian languages and\npotentially can be extended to any language with minor changes. Our research\nmainly focuses on exploring natural spelling errors and mistypings in texts and\nstudying the ways those errors can be emulated in correct sentences to\neffectively enrich generative models' pre-train procedure. We investigate the\nimpact of such emulations and the models' abilities across different text\ndomains. In this work, we investigate two spelling corruption techniques: 1)\nfirst one mimics human behavior when making a mistake through leveraging\nstatistics of errors from particular dataset and 2) second adds the most common\nspelling errors, keyboard miss clicks, and some heuristics within the texts. We\nconducted experiments employing various corruption strategies, models'\narchitectures and sizes on the pre-training and fine-tuning stages and\nevaluated the models using single-domain and multi-domain test sets. As a\npractical outcome of our work, we introduce SAGE(Spell checking via\nAugmentation and Generative distribution Emulation). It is a library for\nautomatic generative SC that includes a family of pre-trained generative models\nand built-in augmentation algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martynov_N/0/1/0/all/0/1\">Nikita Martynov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baushenko_M/0/1/0/all/0/1\">Mark Baushenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozlova_A/0/1/0/all/0/1\">Anastasia Kozlova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolomeytseva_K/0/1/0/all/0/1\">Katerina Kolomeytseva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abramov_A/0/1/0/all/0/1\">Aleksandr Abramov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fenogenova_A/0/1/0/all/0/1\">Alena Fenogenova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.01538","description":"<p>Logical rules are essential for uncovering the logical connections between\nrelations, which could improve the reasoning performance and provide\ninterpretable results on knowledge graphs (KGs). Although there have been many\nefforts to mine meaningful logical rules over KGs, existing methods suffer from\nthe computationally intensive searches over the rule space and a lack of\nscalability for large-scale KGs. Besides, they often ignore the semantics of\nrelations which is crucial for uncovering logical connections. Recently, large\nlanguage models (LLMs) have shown impressive performance in the field of\nnatural language processing and various applications, owing to their emergent\nability and generalizability. In this paper, we propose a novel framework,\nChatRule, unleashing the power of large language models for mining logical\nrules over knowledge graphs. Specifically, the framework is initiated with an\nLLM-based rule generator, leveraging both the semantic and structural\ninformation of KGs to prompt LLMs to generate logical rules. To refine the\ngenerated rules, a rule ranking module estimates the rule quality by\nincorporating facts from existing KGs. Last, a rule validator harnesses the\nreasoning ability of LLMs to validate the logical correctness of ranked rules\nthrough chain-of-thought reasoning. ChatRule is evaluated on four large-scale\nKGs, w.r.t. different rule quality metrics and downstream tasks, showing the\neffectiveness and scalability of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Linhao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_J/0/1/0/all/0/1\">Jiaxin Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1\">Bo Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan-Fang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding the Impact of Post-Training Quantization on Large Language Models. (arXiv:2309.05210v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05210","description":"<p>Large language models (LLMs) are rapidly increasing in size, with the number\nof parameters becoming a key factor in the success of many commercial models,\nsuch as ChatGPT, Claude, and Bard. Even the recently released publicly\naccessible models for commercial usage, such as Falcon and Llama2, come\nequipped with billions of parameters. This significant increase in the number\nof parameters makes deployment and operation very costly. The remarkable\nprogress in the field of quantization for large neural networks in general and\nLLMs in particular, has made these models more accessible by enabling them to\nbe deployed on consumer-grade GPUs. Quantized models generally demonstrate\ncomparable performance levels to their unquantized base counterparts.\nNonetheless, there exists a notable gap in our comprehensive understanding of\nhow these quantized models respond to hyperparameters, such as temperature, max\nnew tokens, and topk, particularly for next word prediction. The present\nanalysis reveals that nf4 and fp4 are equally proficient 4-bit quantization\ntechniques, characterized by similar attributes such as inference speed, memory\nconsumption, and the quality of generated content. Nevertheless, these\nquantization methods exhibit distinct behaviors at varying temperature\nsettings, both in the context of smaller and larger models. It is noteworthy\nthat, in general, 4-bit quantized models of varying sizes exhibit heightened\nsensitivity to lower temperature settings, unlike their unquantized\ncounterparts. Additionally, int8 quantization is associated with significantly\nslower inference speeds, whereas unquantized fp16 models consistently yield the\nfastest inference speeds across models of all sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Somnath Roy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NExT-GPT: Any-to-Any Multimodal LLM. (arXiv:2309.05519v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.05519","description":"<p>While recently Multimodal Large Language Models (MM-LLMs) have made exciting\nstrides, they mostly fall prey to the limitation of only input-side multimodal\nunderstanding, without the ability to produce content in multiple modalities.\nAs we humans always perceive the world and communicate with people through\nvarious modalities, developing any-to-any MM-LLMs capable of accepting and\ndelivering content in any modality becomes essential to human-level AI. To fill\nthe gap, we present an end-to-end general-purpose any-to-any MM-LLM system,\nNExT-GPT. We connect an LLM with multimodal adaptors and different diffusion\ndecoders, enabling NExT-GPT to perceive inputs and generate outputs in\narbitrary combinations of text, images, videos, and audio. By leveraging the\nexisting well-trained highly-performing encoders and decoders, NExT-GPT is\ntuned with only a small amount of parameter (1%) of certain projection layers,\nwhich not only benefits low-cost training and also facilitates convenient\nexpansion to more potential modalities. Moreover, we introduce a\nmodality-switching instruction tuning (MosIT) and manually curate a\nhigh-quality dataset for MosIT, based on which NExT-GPT is empowered with\ncomplex cross-modal semantic understanding and content generation. Overall, our\nresearch showcases the promising possibility of building an AI agent capable of\nmodeling universal modalities, paving the way for more human-like AI research\nin the community. Project page: https://next-gpt.github.io/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengqiong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1\">Leigang Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1\">Wei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Memory Injections: Correcting Multi-Hop Reasoning Failures during Inference in Transformer-Based Language Models. (arXiv:2309.05605v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05605","description":"<p>Answering multi-hop reasoning questions requires retrieving and synthesizing\ninformation from diverse sources. Large Language Models (LLMs) struggle to\nperform such reasoning consistently. Here we propose an approach to pinpoint\nand rectify multi-hop reasoning failures through targeted memory injections on\nLLM attention heads. First, we analyze the per-layer activations of GPT-2\nmodels in response to single and multi-hop prompts. We then propose a mechanism\nthat allows users to inject pertinent prompt-specific information, which we\nrefer to as \"memories,\" at critical LLM locations during inference. By thus\nenabling the LLM to incorporate additional relevant information during\ninference, we enhance the quality of multi-hop prompt completions. We show\nempirically that a simple, efficient, and targeted memory injection into a key\nattention layer can often increase the probability of the desired next token in\nmulti-hop tasks, by up to 424%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sakarvadia_M/0/1/0/all/0/1\">Mansi Sakarvadia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ajith_A/0/1/0/all/0/1\">Aswathy Ajith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1\">Arham Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grzenda_D/0/1/0/all/0/1\">Daniel Grzenda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hudson_N/0/1/0/all/0/1\">Nathaniel Hudson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauer_A/0/1/0/all/0/1\">Andr&#xe9; Bauer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chard_K/0/1/0/all/0/1\">Kyle Chard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_I/0/1/0/all/0/1\">Ian Foster</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs. (arXiv:2309.05918v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05918","description":"<p>In our opinion the exuberance surrounding the relative success of data-driven\nlarge language models (LLMs) is slightly misguided and for several reasons (i)\nLLMs cannot be relied upon for factual information since for LLMs all ingested\ntext (factual or non-factual) was created equal; (ii) due to their subsymbolic\nna-ture, whatever 'knowledge' these models acquire about language will always\nbe buried in billions of microfeatures (weights), none of which is meaningful\non its own; and (iii) LLMs will often fail to make the correct inferences in\nseveral linguistic contexts (e.g., nominal compounds, copredication, quantifier\nscope ambi-guities, intensional contexts. Since we believe the relative success\nof data-driven large language models (LLMs) is not a reflection on the symbolic\nvs. subsymbol-ic debate but a reflection on applying the successful strategy of\na bottom-up reverse engineering of language at scale, we suggest in this paper\napplying the effective bottom-up strategy in a symbolic setting resulting in\nsymbolic, explainable, and ontologically grounded language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saba_W/0/1/0/all/0/1\">Walid S. Saba</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AKEM: Aligning Knowledge Base to Queries with Ensemble Model for Entity Recognition and Linking. (arXiv:2309.06175v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06175","description":"<p>This paper presents a novel approach to address the Entity Recognition and\nLinking Challenge at NLPCC 2015. The task involves extracting named entity\nmentions from short search queries and linking them to entities within a\nreference Chinese knowledge base. To tackle this problem, we first expand the\nexisting knowledge base and utilize external knowledge to identify candidate\nentities, thereby improving the recall rate. Next, we extract features from the\ncandidate entities and utilize Support Vector Regression and Multiple Additive\nRegression Tree as scoring functions to filter the results. Additionally, we\napply rules to further refine the results and enhance precision. Our method is\ncomputationally efficient and achieves an F1 score of 0.535.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">Di Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1\">Zhongping Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1\">Caixia Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaojie Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-13T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}