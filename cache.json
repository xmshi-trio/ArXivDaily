{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-20T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Overview of ImageArg-2023: The First Shared Task in Multimodal Argument Mining. (arXiv:2310.12172v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12172","description":"<p>This paper presents an overview of the ImageArg shared task, the first\nmultimodal Argument Mining shared task co-located with the 10th Workshop on\nArgument Mining at EMNLP 2023. The shared task comprises two classification\nsubtasks - (1) Subtask-A: Argument Stance Classification; (2) Subtask-B: Image\nPersuasiveness Classification. The former determines the stance of a tweet\ncontaining an image and a piece of text toward a controversial topic (e.g., gun\ncontrol and abortion). The latter determines whether the image makes the tweet\ntext more persuasive. The shared task received 31 submissions for Subtask-A and\n21 submissions for Subtask-B from 9 different teams across 6 countries. The top\nsubmission in Subtask-A achieved an F1-score of 0.8647 while the best\nsubmission in Subtask-B achieved an F1-score of 0.5561.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhexiong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elarby_M/0/1/0/all/0/1\">Mohamed Elarby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litman_D/0/1/0/all/0/1\">Diane Litman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Direct Neural Machine Translation with Task-level Mixture of Experts models. (arXiv:2310.12236v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12236","description":"<p>Direct neural machine translation (direct NMT) is a type of NMT system that\ntranslates text between two non-English languages. Direct NMT systems often\nface limitations due to the scarcity of parallel data between non-English\nlanguage pairs. Several approaches have been proposed to address this\nlimitation, such as multilingual NMT and pivot NMT (translation between two\nlanguages via English). Task-level Mixture of expert models (Task-level MoE),\nan inference-efficient variation of Transformer-based models, has shown\npromising NMT performance for a large number of language pairs. In Task-level\nMoE, different language groups can use different routing strategies to optimize\ncross-lingual learning and inference speed. In this work, we examine Task-level\nMoE's applicability in direct NMT and propose a series of high-performing\ntraining and evaluation configurations, through which Task-level MoE-based\ndirect NMT systems outperform bilingual and pivot-based models for a large\nnumber of low and high-resource direct pairs, and translation directions. Our\nTask-level MoE with 16 experts outperforms bilingual NMT, Pivot NMT models for\n7 language pairs, while pivot-based models still performed better in 9 pairs\nand directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tourni_I/0/1/0/all/0/1\">Isidora Chara Tourni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naskar_S/0/1/0/all/0/1\">Subhajit Naskar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Image is Worth Multiple Words: Learning Object Level Concepts using Multi-Concept Prompt Learning. (arXiv:2310.12274v1 [cs.CV])","link":"http://arxiv.org/abs/2310.12274","description":"<p>Textural Inversion, a prompt learning method, learns a singular embedding for\na new \"word\" to represent image style and appearance, allowing it to be\nintegrated into natural language sentences to generate novel synthesised\nimages. However, identifying and integrating multiple object-level concepts\nwithin one scene poses significant challenges even when embeddings for\nindividual concepts are attainable. This is further confirmed by our empirical\ntests. To address this challenge, we introduce a framework for Multi-Concept\nPrompt Learning (MCPL), where multiple new \"words\" are simultaneously learned\nfrom a single sentence-image pair. To enhance the accuracy of word-concept\ncorrelation, we propose three regularisation techniques: Attention Masking\n(AttnMask) to concentrate learning on relevant areas; Prompts Contrastive Loss\n(PromptCL) to separate the embeddings of different concepts; and Bind adjective\n(Bind adj.) to associate new \"words\" with known words. We evaluate via image\ngeneration, editing, and attention visualisation with diverse images. Extensive\nquantitative comparisons demonstrate that our method can learn more\nsemantically disentangled concepts with enhanced word-concept correlation.\nAdditionally, we introduce a novel dataset and evaluation protocol tailored for\nthis new task of learning object-level concepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1\">Chen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tanno_R/0/1/0/all/0/1\">Ryutaro Tanno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saseendran_A/0/1/0/all/0/1\">Amrutha Saseendran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diethe_T/0/1/0/all/0/1\">Tom Diethe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teare_P/0/1/0/all/0/1\">Philip Teare</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Pointwise $\\mathcal{V}$-Usable Information In-Context-ly. (arXiv:2310.12300v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12300","description":"<p>In-context learning (ICL) is a new learning paradigm that has gained\npopularity along with the development of large language models. In this work,\nwe adapt a recently proposed hardness metric, pointwise $\\mathcal{V}$-usable\ninformation (PVI), to an in-context version (in-context PVI). Compared to the\noriginal PVI, in-context PVI is more efficient in that it requires only a few\nexemplars and does not require fine-tuning. We conducted a comprehensive\nempirical analysis to evaluate the reliability of in-context PVI. Our findings\nindicate that in-context PVI estimates exhibit similar characteristics to the\noriginal PVI. Specific to the in-context setting, we show that in-context PVI\nestimates remain consistent across different exemplar selections and numbers of\nshots. The variance of in-context PVI estimates across different exemplar\nselections is insignificant, which suggests that in-context PVI are stable.\nFurthermore, we demonstrate how in-context PVI can be employed to identify\nchallenging instances. Our work highlights the potential of in-context PVI and\nprovides new insights into the capabilities of ICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Sheng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yingya Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitterman_D/0/1/0/all/0/1\">Danielle Bitterman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savova_G/0/1/0/all/0/1\">Guergana Savova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document-Level Language Models for Machine Translation. (arXiv:2310.12303v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12303","description":"<p>Despite the known limitations, most machine translation systems today still\noperate on the sentence-level. One reason for this is, that most parallel\ntraining data is only sentence-level aligned, without document-level meta\ninformation available. In this work, we set out to build context-aware\ntranslation systems utilizing document-level monolingual data instead. This can\nbe achieved by combining any existing sentence-level translation model with a\ndocument-level language model. We improve existing approaches by leveraging\nrecent advancements in model combination. Additionally, we propose novel\nweighting techniques that make the system combination more flexible and\nsignificantly reduce computational overhead. In a comprehensive evaluation on\nfour diverse translation tasks, we show that our extensions improve\ndocument-targeted scores substantially and are also computationally more\nefficient. However, we also find that in most scenarios, back-translation gives\neven better results, at the cost of having to re-train the translation system.\nFinally, we explore language model fusion in the light of recent advancements\nin large language models. Our findings suggest that there might be strong\npotential in utilizing large language models via model combination.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petrick_F/0/1/0/all/0/1\">Frithjof Petrick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herold_C/0/1/0/all/0/1\">Christian Herold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrushkov_P/0/1/0/all/0/1\">Pavel Petrushkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1\">Hermann Ney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Sentiment Problem: A Critical Survey towards Deconstructing Sentiment Analysis. (arXiv:2310.12318v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12318","description":"<p>We conduct an inquiry into the sociotechnical aspects of sentiment analysis\n(SA) by critically examining 189 peer-reviewed papers on their applications,\nmodels, and datasets. Our investigation stems from the recognition that SA has\nbecome an integral component of diverse sociotechnical systems, exerting\ninfluence on both social and technical users. By delving into sociological and\ntechnological literature on sentiment, we unveil distinct conceptualizations of\nthis term in domains such as finance, government, and medicine. Our study\nexposes a lack of explicit definitions and frameworks for characterizing\nsentiment, resulting in potential challenges and biases. To tackle this issue,\nwe propose an ethics sheet encompassing critical inquiries to guide\npractitioners in ensuring equitable utilization of SA. Our findings underscore\nthe significance of adopting an interdisciplinary approach to defining\nsentiment in SA and offer a pragmatic solution for its implementation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1\">Pranav Narayanan Venkit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinath_M/0/1/0/all/0/1\">Mukund Srinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gautam_S/0/1/0/all/0/1\">Sanjana Gautam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatraman_S/0/1/0/all/0/1\">Saranya Venkatraman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1\">Vipul Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Passonneau_R/0/1/0/all/0/1\">Rebecca J. Passonneau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1\">Shomir Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4. (arXiv:2310.12321v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12321","description":"<p>Large language models (LLMs) are a special class of pretrained language\nmodels obtained by scaling model size, pretraining corpus and computation.\nLLMs, because of their large size and pretraining on large volumes of text\ndata, exhibit special abilities which allow them to achieve remarkable\nperformances without any task-specific training in many of the natural language\nprocessing tasks. The era of LLMs started with OpenAI GPT-3 model, and the\npopularity of LLMs is increasing exponentially after the introduction of models\nlike ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models,\nincluding ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With\nthe ever-rising popularity of GLLMs, especially in the research community,\nthere is a strong need for a comprehensive survey which summarizes the recent\nresearch progress in multiple dimensions and can guide the research community\nwith insightful future research directions. We start the survey paper with\nfoundation concepts like transformers, transfer learning, self-supervised\nlearning, pretrained language models and large language models. We then present\na brief overview of GLLMs and discuss the performances of GLLMs in various\ndownstream tasks, specific domains and multiple languages. We also discuss the\ndata labelling and data augmentation abilities of GLLMs, the robustness of\nGLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with\nmultiple insightful future research directions. To summarize, this\ncomprehensive survey paper will serve as a good resource for both academic and\nindustry people to stay updated with the latest research related to GPT-3\nfamily large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_K/0/1/0/all/0/1\">Katikapalli Subramanyam Kalyan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Eliminating Reasoning via Inferring with Planning: A New Framework to Guide LLMs' Non-linear Thinking. (arXiv:2310.12342v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12342","description":"<p>Chain-of-Thought(CoT) prompting and its variants explore equipping large\nlanguage models (LLMs) with high-level reasoning abilities by emulating\nhuman-like linear cognition and logic. However, the human mind is complicated\nand mixed with both linear and nonlinear thinking. In this work, we propose\n\\textbf{I}nferential \\textbf{E}xclusion \\textbf{P}rompting (IEP), a novel\nprompting that combines the principles of elimination and inference in order to\nguide LLMs to think non-linearly. IEP guides LLMs to plan and then utilize\nNatural Language Inference (NLI) to deduce each possible solution's entailment\nrelation with context, commonsense, or facts, therefore yielding a broader\nperspective by thinking back for inferring. This forward planning and backward\neliminating process allows IEP to better simulate the complex human thinking\nprocesses compared to other CoT-based methods, which only reflect linear\ncognitive processes. We conducted a series of empirical studies and have\ncorroborated that IEP consistently outperforms CoT across various tasks.\nAdditionally, we observe that integrating IEP and CoT further improves the\nLLMs' performance on certain tasks, highlighting the necessity of equipping\nLLMs with mixed logic processes. Moreover, to better evaluate comprehensive\nfeatures inherent in human logic, we introduce \\textbf{M}ental-\\textbf{A}bility\n\\textbf{R}easoning \\textbf{B}enchmark (MARB). The benchmark comprises six novel\nsubtasks with a total of 9,115 questions, among which 1,685 are developed with\nhand-crafted rationale references. We believe both \\textsc{IEP} and\n\\textsc{MARB} can serve as a promising direction for unveiling LLMs' logic and\nverbal reasoning abilities and drive further advancements. \\textsc{MARB} will\nbe available at ~\\texttt{anonymity link} soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1\">Yongqi Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sizhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Simeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LACMA: Language-Aligning Contrastive Learning with Meta-Actions for Embodied Instruction Following. (arXiv:2310.12344v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12344","description":"<p>End-to-end Transformers have demonstrated an impressive success rate for\nEmbodied Instruction Following when the environment has been seen in training.\nHowever, they tend to struggle when deployed in an unseen environment. This\nlack of generalizability is due to the agent's insensitivity to subtle changes\nin natural language instructions. To mitigate this issue, we propose explicitly\naligning the agent's hidden states with the instructions via contrastive\nlearning. Nevertheless, the semantic gap between high-level language\ninstructions and the agent's low-level action space remains an obstacle.\nTherefore, we further introduce a novel concept of meta-actions to bridge the\ngap. Meta-actions are ubiquitous action patterns that can be parsed from the\noriginal action sequence. These patterns represent higher-level semantics that\nare intuitively aligned closer to the instructions. When meta-actions are\napplied as additional training signals, the agent generalizes better to unseen\nenvironments. Compared to a strong multi-modal Transformer baseline, we achieve\na significant 4.5% absolute gain in success rate in unseen environments of\nALFRED Embodied Instruction Following. Additional analysis shows that the\ncontrastive objective and meta-actions are complementary in achieving the best\nresults, and the resulting agent better aligns its states with corresponding\ninstructions, making it more suitable for real-world embodied agents. The code\nis available at: https://github.com/joeyy5588/LACMA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng-Fu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yen-Chun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1\">Xiyang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Chiang Frank Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"knn-seq: Efficient, Extensible kNN-MT Framework. (arXiv:2310.12352v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12352","description":"<p>k-nearest-neighbor machine translation (kNN-MT) boosts the translation\nquality of a pre-trained neural machine translation (NMT) model by utilizing\ntranslation examples during decoding. Translation examples are stored in a\nvector database, called a datastore, which contains one entry for each target\ntoken from the parallel data it is made from. Due to its size, it is\ncomputationally expensive both to construct and to retrieve examples from the\ndatastore. In this paper, we present an efficient and extensible kNN-MT\nframework, knn-seq, for researchers and developers that is carefully designed\nto run efficiently, even with a billion-scale large datastore. knn-seq is\ndeveloped as a plug-in on fairseq and easy to switch models and kNN indexes.\nExperimental results show that our implemented kNN-MT achieves a comparable\ngain to the original kNN-MT, and the billion-scale datastore construction took\n2.21 hours in the WMT'19 German-to-English translation task. We publish our\nknn-seq as an MIT-licensed open-source project and the code is available on\nhttps://github.com/naist-nlp/knn-seq . The demo video is available on\nhttps://youtu.be/zTDzEOq80m0 .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deguchi_H/0/1/0/all/0/1\">Hiroyuki Deguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirano_H/0/1/0/all/0/1\">Hayate Hirano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoshino_T/0/1/0/all/0/1\">Tomoki Hoshino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nishida_Y/0/1/0/all/0/1\">Yuto Nishida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vasselli_J/0/1/0/all/0/1\">Justin Vasselli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1\">Taro Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GRI: Graph-based Relative Isomorphism of Word Embedding Spaces. (arXiv:2310.12360v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12360","description":"<p>Automated construction of bilingual dictionaries using monolingual embedding\nspaces is a core challenge in machine translation. The end performance of these\ndictionaries relies upon the geometric similarity of individual spaces, i.e.,\ntheir degree of isomorphism. Existing attempts aimed at controlling the\nrelative isomorphism of different spaces fail to incorporate the impact of\nsemantically related words in the training objective. To address this, we\npropose GRI that combines the distributional training objectives with attentive\ngraph convolutions to unanimously consider the impact of semantically similar\nwords required to define/compute the relative isomorphism of multiple spaces.\nExperimental evaluation shows that GRI outperforms the existing research by\nimproving the average P@1 by a relative score of up to 63.6%. We release the\ncodes for GRI at https://github.com/asif6827/GRI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Muhammad Asif Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jianbin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models. (arXiv:2310.12362v1 [cs.CR])","link":"http://arxiv.org/abs/2310.12362","description":"<p>We present REMARK-LLM, a novel efficient, and robust watermarking framework\ndesigned for texts generated by large language models (LLMs). Synthesizing\nhuman-like content using LLMs necessitates vast computational resources and\nextensive datasets, encapsulating critical intellectual property (IP). However,\nthe generated content is prone to malicious exploitation, including spamming\nand plagiarism. To address the challenges, REMARK-LLM proposes three new\ncomponents: (i) a learning-based message encoding module to infuse binary\nsignatures into LLM-generated texts; (ii) a reparameterization module to\ntransform the dense distributions from the message encoding to the sparse\ndistribution of the watermarked textual tokens; (iii) a decoding module\ndedicated for signature extraction; Furthermore, we introduce an optimized beam\nsearch algorithm to guarantee the coherence and consistency of the generated\ncontent. REMARK-LLM is rigorously trained to encourage the preservation of\nsemantic integrity in watermarked content, while ensuring effective watermark\nretrieval. Extensive evaluations on multiple unseen datasets highlight\nREMARK-LLM proficiency and transferability in inserting 2 times more signature\nbits into the same texts when compared to prior art, all while maintaining\nsemantic integrity. Furthermore, REMARK-LLM exhibits better resilience against\na spectrum of watermark detection and removal attacks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruisi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1\">Shehzeen Samarah Hussain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neekhara_P/0/1/0/all/0/1\">Paarth Neekhara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1\">Farinaz Koushanfar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Solving Hard Analogy Questions with Relation Embedding Chains. (arXiv:2310.12379v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12379","description":"<p>Modelling how concepts are related is a central topic in Lexical Semantics. A\ncommon strategy is to rely on knowledge graphs (KGs) such as ConceptNet, and to\nmodel the relation between two concepts as a set of paths. However, KGs are\nlimited to a fixed set of relation types, and they are incomplete and often\nnoisy. Another strategy is to distill relation embeddings from a fine-tuned\nlanguage model. However, this is less suitable for words that are only\nindirectly related and it does not readily allow us to incorporate structured\ndomain knowledge. In this paper, we aim to combine the best of both worlds. We\nmodel relations as paths but associate their edges with relation embeddings.\nThe paths are obtained by first identifying suitable intermediate words and\nthen selecting those words for which informative relation embeddings can be\nobtained. We empirically show that our proposed representations are useful for\nsolving hard analogy questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1\">Nitesh Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1\">Steven Schockaert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Loop Copilot: Conducting AI Ensembles for Music Generation and Iterative Editing. (arXiv:2310.12404v1 [cs.SD])","link":"http://arxiv.org/abs/2310.12404","description":"<p>Creating music is iterative, requiring varied methods at each stage. However,\nexisting AI music systems fall short in orchestrating multiple subsystems for\ndiverse needs. To address this gap, we introduce Loop Copilot, a novel system\nthat enables users to generate and iteratively refine music through an\ninteractive, multi-round dialogue interface. The system uses a large language\nmodel to interpret user intentions and select appropriate AI models for task\nexecution. Each backend model is specialized for a specific task, and their\noutputs are aggregated to meet the user's requirements. To ensure musical\ncoherence, essential attributes are maintained in a centralized table. We\nevaluate the effectiveness of the proposed system through semi-structured\ninterviews and questionnaires, highlighting its utility not only in\nfacilitating music creation but also its potential for broader applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maezawa_A/0/1/0/all/0/1\">Akira Maezawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1\">Gus Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamamoto_K/0/1/0/all/0/1\">Kazuhiko Yamamoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_S/0/1/0/all/0/1\">Simon Dixon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FinEntity: Entity-level Sentiment Classification for Financial Texts. (arXiv:2310.12406v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12406","description":"<p>In the financial domain, conducting entity-level sentiment analysis is\ncrucial for accurately assessing the sentiment directed toward a specific\nfinancial entity. To our knowledge, no publicly available dataset currently\nexists for this purpose. In this work, we introduce an entity-level sentiment\nclassification dataset, called \\textbf{FinEntity}, that annotates financial\nentity spans and their sentiment (positive, neutral, and negative) in financial\nnews. We document the dataset construction process in the paper. Additionally,\nwe benchmark several pre-trained models (BERT, FinBERT, etc.) and ChatGPT on\nentity-level sentiment classification. In a case study, we demonstrate the\npractical utility of using FinEntity in monitoring cryptocurrency markets. The\ndata and code of FinEntity is available at\n\\url{https://github.com/yixuantt/FinEntity}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yixuan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1\">Allen H Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_A/0/1/0/all/0/1\">Andy Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Justin Z Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions. (arXiv:2310.12418v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12418","description":"<p>Recent progress in Large Language Models (LLMs) has produced models that\nexhibit remarkable performance across a variety of NLP tasks. However, it\nremains unclear whether the existing focus of NLP research accurately captures\nthe genuine requirements of human users. This paper provides a comprehensive\nanalysis of the divergence between current NLP research and the needs of\nreal-world NLP applications via a large-scale collection of user-GPT\nconversations. We analyze a large-scale collection of real user queries to GPT.\nWe compare these queries against existing NLP benchmark tasks and identify a\nsignificant gap between the tasks that users frequently request from LLMs and\nthe tasks that are commonly studied in academic research. For example, we find\nthat tasks such as ``design'' and ``planning'' are prevalent in user\ninteractions but are largely neglected or different from traditional NLP\nbenchmarks. We investigate these overlooked tasks, dissect the practical\nchallenges they pose, and provide insights toward a roadmap to make LLMs better\naligned with user needs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Siru Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1\">Ming Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1\">Yizhu Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAF: Multi-Aspect Feedback for Improving Reasoning in Large Language Models. (arXiv:2310.12426v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12426","description":"<p>Language Models (LMs) have shown impressive performance in various natural\nlanguage tasks. However, when it comes to natural language reasoning, LMs still\nface challenges such as hallucination, generating incorrect intermediate\nreasoning steps, and making mathematical errors. Recent research has focused on\nenhancing LMs through self-improvement using feedback. Nevertheless, existing\napproaches relying on a single generic feedback source fail to address the\ndiverse error types found in LM-generated reasoning chains. In this work, we\npropose Multi-Aspect Feedback, an iterative refinement framework that\nintegrates multiple feedback modules, including frozen LMs and external tools,\neach focusing on a specific error category. Our experimental results\ndemonstrate the efficacy of our approach to addressing several errors in the\nLM-generated reasoning chain and thus improving the overall performance of an\nLM in several reasoning tasks. We see a relative improvement of up to 20% in\nMathematical Reasoning and up to 18% in Logical Entailment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nathani_D/0/1/0/all/0/1\">Deepak Nathani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">David Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DocXChain: A Powerful Open-Source Toolchain for Document Parsing and Beyond. (arXiv:2310.12430v1 [cs.CV])","link":"http://arxiv.org/abs/2310.12430","description":"<p>In this report, we introduce DocXChain, a powerful open-source toolchain for\ndocument parsing, which is designed and developed to automatically convert the\nrich information embodied in unstructured documents, such as text, tables and\ncharts, into structured representations that are readable and manipulable by\nmachines. Specifically, basic capabilities, including text detection, text\nrecognition, table structure recognition and layout analysis, are provided.\nUpon these basic capabilities, we also build a set of fully functional\npipelines for document parsing, i.e., general text reading, table parsing, and\ndocument structurization, to drive various applications related to documents in\nreal-world scenarios. Moreover, DocXChain is concise, modularized and flexible,\nsuch that it can be readily integrated with existing tools, libraries or models\n(such as LangChain and ChatGPT), to construct more powerful systems that can\naccomplish more complicated and challenging tasks. The code of DocXChain is\npublicly available\nat:~\\url{https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/Applications/DocXChain}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_C/0/1/0/all/0/1\">Cong Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PoisonPrompt: Backdoor Attack on Prompt-based Large Language Models. (arXiv:2310.12439v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12439","description":"<p>Prompts have significantly improved the performance of pretrained Large\nLanguage Models (LLMs) on various downstream tasks recently, making them\nincreasingly indispensable for a diverse range of LLM application scenarios.\nHowever, the backdoor vulnerability, a serious security threat that can\nmaliciously alter the victim model's normal predictions, has not been\nsufficiently explored for prompt-based LLMs. In this paper, we present\nPOISONPROMPT, a novel backdoor attack capable of successfully compromising both\nhard and soft prompt-based LLMs. We evaluate the effectiveness, fidelity, and\nrobustness of POISONPROMPT through extensive experiments on three popular\nprompt methods, using six datasets and three widely used LLMs. Our findings\nhighlight the potential security threats posed by backdoor attacks on\nprompt-based LLMs and emphasize the need for further research in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1\">Hongwei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhan Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Long-Range Transformers: You Need to Attend More, but Not Necessarily at Every Layer. (arXiv:2310.12442v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12442","description":"<p>Pretrained transformer models have demonstrated remarkable performance across\nvarious natural language processing tasks. These models leverage the attention\nmechanism to capture long- and short-range dependencies in the sequence.\nHowever, the (full) attention mechanism incurs high computational cost -\nquadratic in the sequence length, which is not affordable in tasks with long\nsequences, e.g., inputs with 8k tokens. Although sparse attention can be used\nto improve computational efficiency, as suggested in existing work, it has\nlimited modeling capacity and often fails to capture complicated dependencies\nin long sequences. To tackle this challenge, we propose MASFormer, an\neasy-to-implement transformer variant with Mixed Attention Spans. Specifically,\nMASFormer is equipped with full attention to capture long-range dependencies,\nbut only at a small number of layers. For the remaining layers, MASformer only\nemploys sparse attention to capture short-range dependencies. Our experiments\non natural language modeling and generation tasks show that a decoder-only\nMASFormer model of 1.3B parameters can achieve competitive performance to\nvanilla transformers with full attention while significantly reducing\ncomputational cost (up to 75%). Additionally, we investigate the effectiveness\nof continual training with long sequence data and how sequence length impacts\ndownstream generation performance, which may be of independent interest.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ram_D/0/1/0/all/0/1\">Dhananjay Ram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hawkins_C/0/1/0/all/0/1\">Cole Hawkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_S/0/1/0/all/0/1\">Sheng Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Know Where to Go: Make LLM a Relevant, Responsible, and Trustworthy Searcher. (arXiv:2310.12443v1 [cs.IR])","link":"http://arxiv.org/abs/2310.12443","description":"<p>The advent of Large Language Models (LLMs) has shown the potential to improve\nrelevance and provide direct answers in web searches. However, challenges arise\nin validating the reliability of generated results and the credibility of\ncontributing sources, due to the limitations of traditional information\nretrieval algorithms and the LLM hallucination problem. Aiming to create a\n\"PageRank\" for the LLM era, we strive to transform LLM into a relevant,\nresponsible, and trustworthy searcher. We propose a novel generative retrieval\nframework leveraging the knowledge of LLMs to foster a direct link between\nqueries and online sources. This framework consists of three core modules:\nGenerator, Validator, and Optimizer, each focusing on generating trustworthy\nonline sources, verifying source reliability, and refining unreliable sources,\nrespectively. Extensive experiments and evaluations highlight our method's\nsuperior relevance, responsibility, and trustfulness against various SOTA\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiawei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yinpeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qikai Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Sparse Retrieval for Few-shot Entity Linking. (arXiv:2310.12444v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12444","description":"<p>Entity linking aims to link ambiguous mentions to their corresponding\nentities in a knowledge base. One of the key challenges comes from insufficient\nlabeled data for specific domains. Although dense retrievers have achieved\nexcellent performance on several benchmarks, their performance decreases\nsignificantly when only a limited amount of in-domain labeled data is\navailable. In such few-shot setting, we revisit the sparse retrieval method,\nand propose an ELECTRA-based keyword extractor to denoise the mention context\nand construct a better query expression. For training the extractor, we propose\na distant supervision method to automatically generate training data based on\noverlapping tokens between mention contexts and entity descriptions.\nExperimental results on the ZESHEL dataset demonstrate that the proposed method\noutperforms state-of-the-art models by a significant margin across all test\ndomains, showing the effectiveness of keyword-enhanced sparse retrieval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Read-and-Select Framework for Zero-shot Entity Linking. (arXiv:2310.12450v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12450","description":"<p>Zero-shot entity linking (EL) aims at aligning entity mentions to unseen\nentities to challenge the generalization ability. Previous methods largely\nfocus on the candidate retrieval stage and ignore the essential candidate\nranking stage, which disambiguates among entities and makes the final linking\nprediction. In this paper, we propose a read-and-select (ReS) framework by\nmodeling the main components of entity disambiguation, i.e., mention-entity\nmatching and cross-entity comparison. First, for each candidate, the reading\nmodule leverages mention context to output mention-aware entity\nrepresentations, enabling mention-entity matching. Then, in the selecting\nmodule, we frame the choice of candidates as a sequence labeling problem, and\nall candidate representations are fused together to enable cross-entity\ncomparison. Our method achieves the state-of-the-art performance on the\nestablished zero-shot EL dataset ZESHEL with a 2.55\\% micro-average accuracy\ngain, with no need for laborious multi-phase pre-training used in most of the\nprevious work, showing the effectiveness of both mention-entity and\ncross-entity interaction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhenran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yulin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models. (arXiv:2310.12454v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12454","description":"<p>Pretrained language models are expected to effectively map input text to a\nset of vectors while preserving the inherent relationships within the text.\nConsequently, designing a white-box model to compute metrics that reflect the\npresence of specific internal relations in these vectors has become a common\napproach for post-hoc interpretability analysis of pretrained language models.\nHowever, achieving interpretability in white-box models and ensuring the rigor\nof metric computation becomes challenging when the source model lacks inherent\ninterpretability. Therefore, in this paper, we discuss striking a balance in\nthis trade-off and propose a novel line to constructing metrics for\nunderstanding the mechanisms of pretrained language models. We have\nspecifically designed a family of metrics along this line of investigation, and\nthe model used to compute these metrics is referred to as the tree topological\nprobe. We conducted measurements on BERT-large by using these metrics. Based on\nthe experimental results, we propose a speculation regarding the working\nmechanism of BERT-like pretrained language models, as well as a strategy for\nenhancing fine-tuning performance by leveraging the topological probe to\nimprove specific submodules.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">You Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jinhui Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yuming Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unmasking Transformers: A Theoretical Approach to Data Recovery via Attention Weights. (arXiv:2310.12462v1 [cs.LG])","link":"http://arxiv.org/abs/2310.12462","description":"<p>In the realm of deep learning, transformers have emerged as a dominant\narchitecture, particularly in natural language processing tasks. However, with\ntheir widespread adoption, concerns regarding the security and privacy of the\ndata processed by these models have arisen. In this paper, we address a pivotal\nquestion: Can the data fed into transformers be recovered using their attention\nweights and outputs? We introduce a theoretical framework to tackle this\nproblem. Specifically, we present an algorithm that aims to recover the input\ndata $X \\in \\mathbb{R}^{d \\times n}$ from given attention weights $W = QK^\\top\n\\in \\mathbb{R}^{d \\times d}$ and output $B \\in \\mathbb{R}^{n \\times n}$ by\nminimizing the loss function $L(X)$. This loss function captures the\ndiscrepancy between the expected output and the actual output of the\ntransformer. Our findings have significant implications for the Localized\nLayer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's\ndesign from a security and privacy perspective. This work underscores the\nimportance of understanding and safeguarding the internal workings of\ntransformers to ensure the confidentiality of processed data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yichuan Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Shenghao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chiwun Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Learning for Inference in Dialogue. (arXiv:2310.12467v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12467","description":"<p>Inference, especially those derived from inductive processes, is a crucial\ncomponent in our conversation to complement the information implicitly or\nexplicitly conveyed by a speaker. While recent large language models show\nremarkable advances in inference tasks, their performance in inductive\nreasoning, where not all information is present in the context, is far behind\ndeductive reasoning. In this paper, we analyze the behavior of the models based\non the task difficulty defined by the semantic information gap -- which\ndistinguishes inductive and deductive reasoning (Johnson-Laird, 1988, 1993).\nOur analysis reveals that the disparity in information between dialogue\ncontexts and desired inferences poses a significant challenge to the inductive\ninference process. To mitigate this information gap, we investigate a\ncontrastive learning approach by feeding negative samples. Our experiments\nsuggest negative samples help models understand what is wrong and improve their\ninference generations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilie_B/0/1/0/all/0/1\">Bryan Wilie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lovenia_H/0/1/0/all/0/1\">Holy Lovenia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_W/0/1/0/all/0/1\">Willy Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Exploration of In-Context Learning for Speech Language Model. (arXiv:2310.12477v1 [eess.AS])","link":"http://arxiv.org/abs/2310.12477","description":"<p>Ever since the development of GPT-3 in the natural language processing (NLP)\nfield, in-context learning (ICL) has played an important role in utilizing\nlarge language models (LLMs). By presenting the LM utterance-label\ndemonstrations at the input, the LM can accomplish few-shot learning without\nrelying on gradient descent or requiring explicit modification of its\nparameters. This enables the LM to learn and adapt in a black-box manner.\nDespite the success of ICL in NLP, little work is exploring the possibility of\nICL in speech processing. This study proposes the first exploration of ICL with\na speech LM without text supervision. We first show that the current speech LM\ndoes not have the ICL capability. With the proposed warmup training, the speech\nLM can, therefore, perform ICL on unseen tasks. In this work, we verify the\nfeasibility of ICL for speech LM on speech classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Hsu_M/0/1/0/all/0/1\">Ming-Hao Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models. (arXiv:2310.12481v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12481","description":"<p>In this paper, we identify a cultural dominance issue within large language\nmodels (LLMs) due to the predominant use of English data in model training\n(e.g. ChatGPT). LLMs often provide inappropriate English-culture-related\nanswers that are not relevant to the expected culture when users ask in\nnon-English languages. To systematically evaluate the cultural dominance issue,\nwe build a benchmark that consists of both concrete (e.g. holidays and songs)\nand abstract (e.g. values and opinions) cultural objects. Empirical results\nshow that the representative GPT models suffer from the culture dominance\nproblem, where GPT-4 is the most affected while text-davinci-003 suffers the\nleast from this problem. Our study emphasizes the need for critical examination\nof cultural dominance and ethical consideration in their development and\ndeployment. We show two straightforward methods in model development (i.e.\npretraining on more diverse data) and deployment (e.g. culture-aware prompting)\ncan significantly mitigate the cultural dominance issue in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jingyuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1\">Ruyi Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jen-tse Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI Responses in Health Consultations. (arXiv:2310.12489v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12489","description":"<p>Zero-shot classification has enabled the classification of text into classes\nthat were not seen during training. In this paper, we investigate the\neffectiveness of pre-trained language models to accurately classify responses\nfrom Doctors and AI in health consultations through zero-shot learning. Our\nstudy aims to determine whether these models can effectively detect if a text\noriginates from human or AI models without specific corpus training. For our\nexperiments, we collected responses from doctors to patient inquiries about\ntheir health and posed the same question/response to AI models. Our findings\nrevealed that while pre-trained language models demonstrate a strong\nunderstanding of language generally, they may require specific corpus training\nor other techniques to achieve accurate classification of doctor- and\nAI-generated text in healthcare consultations. As a baseline approach, this\nstudy shows the limitations of relying solely on zero-shot classification in\nmedical classification tasks. This research lays the groundwork for further\nresearch into the field of medical text classification, informing the\ndevelopment of more effective approaches to accurately classify doctor- and\nAI-generated text in health consultations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ojo_O/0/1/0/all/0/1\">Olumide E. Ojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adebanji_O/0/1/0/all/0/1\">Olaronke O. Adebanji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelbukh_A/0/1/0/all/0/1\">Alexander Gelbukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calvo_H/0/1/0/all/0/1\">Hiram Calvo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_A/0/1/0/all/0/1\">Anna Feldman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning. (arXiv:2310.12490v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12490","description":"<p>Pre-trained Language Models are widely used in many important real-world\napplications. However, recent studies show that these models can encode social\nbiases from large pre-training corpora and even amplify biases in downstream\napplications. To address this challenge, we propose Co$^2$PT, an efficient and\neffective debias-while-prompt tuning method for mitigating biases via\ncounterfactual contrastive prompt tuning on downstream tasks. Our experiments\nconducted on three extrinsic bias benchmarks demonstrate the effectiveness of\nCo$^2$PT on bias mitigation during the prompt tuning process and its\nadaptability to existing upstream debiased language models. These findings\nindicate the strength of Co$^2$PT and provide promising avenues for further\nenhancement in bias mitigation on downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1\">Xiangjue Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Ziwei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhuoer Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teleki_M/0/1/0/all/0/1\">Maria Teleki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caverlee_J/0/1/0/all/0/1\">James Caverlee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attack Prompt Generation for Red Teaming and Defending Large Language Models. (arXiv:2310.12505v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12505","description":"<p>Large language models (LLMs) are susceptible to red teaming attacks, which\ncan induce LLMs to generate harmful content. Previous research constructs\nattack prompts via manual or automatic methods, which have their own\nlimitations on construction cost and quality. To address these issues, we\npropose an integrated approach that combines manual and automatic methods to\neconomically generate high-quality attack prompts. Specifically, considering\nthe impressive capabilities of newly emerged LLMs, we propose an attack\nframework to instruct LLMs to mimic human-generated prompts through in-context\nlearning. Furthermore, we propose a defense framework that fine-tunes victim\nLLMs through iterative interactions with the attack framework to enhance their\nsafety against red teaming attacks. Extensive experiments on different LLMs\nvalidate the effectiveness of our proposed attack and defense frameworks.\nAdditionally, we release a series of attack prompts datasets named SAP with\nvarying sizes, facilitating the safety evaluation and enhancement of more LLMs.\nOur code and dataset is available on https://github.com/Aatrox103/SAP .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1\">Boyi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiangnan He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Hallucination Assessment for Aligned Large Language Models via Transferable Adversarial Attacks. (arXiv:2310.12516v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12516","description":"<p>Although remarkable progress has been achieved in preventing large language\nmodel (LLM) hallucinations using instruction tuning and retrieval augmentation,\nit remains challenging to measure the reliability of LLMs using human-crafted\nevaluation data which is not available for many tasks and domains and could\nsuffer from data leakage. Inspired by adversarial machine learning, this paper\naims to develop a method of automatically generating evaluation data by\nappropriately modifying existing data on which LLMs behave faithfully.\nSpecifically, this paper presents AutoDebug, an LLM-based framework to use\nprompting chaining to generate transferable adversarial attacks in the form of\nquestion-answering examples. We seek to understand the extent to which these\nexamples trigger the hallucination behaviors of LLMs.\n</p>\n<p>We implement AutoDebug using ChatGPT and evaluate the resulting two variants\nof a popular open-domain question-answering dataset, Natural Questions (NQ), on\na collection of open-source and proprietary LLMs under various prompting\nsettings. Our generated evaluation data is human-readable and, as we show,\nhumans can answer these modified questions well. Nevertheless, we observe\npronounced accuracy drops across multiple LLMs including GPT-4. Our\nexperimental results show that LLMs are likely to hallucinate in two categories\nof question-answering scenarios where (1) there are conflicts between knowledge\ngiven in the prompt and their parametric knowledge, or (2) the knowledge\nexpressed in the prompt is complex. Finally, we find that the adversarial\nexamples generated by our method are transferable across all considered LLMs.\nThe examples generated by a small model can be used to debug a much larger\nmodel, making our approach cost-effective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1\">Dan Roth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lost in Translation: When GPT-4V(ision) Can't See Eye to Eye with Text. A Vision-Language-Consistency Analysis of VLLMs and Beyond. (arXiv:2310.12520v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12520","description":"<p>Recent advancements in multimodal techniques open exciting possibilities for\nmodels excelling in diverse tasks involving text, audio, and image processing.\nModels like GPT-4V, blending computer vision and language modeling, excel in\ncomplex text and image tasks. Numerous prior research endeavors have diligently\nexamined the performance of these Vision Large Language Models (VLLMs) across\ntasks like object detection, image captioning and others. However, these\nanalyses often focus on evaluating the performance of each modality in\nisolation, lacking insights into their cross-modal interactions. Specifically,\nquestions concerning whether these vision-language models execute vision and\nlanguage tasks consistently or independently have remained unanswered. In this\nstudy, we draw inspiration from recent investigations into multilingualism and\nconduct a comprehensive analysis of model's cross-modal interactions. We\nintroduce a systematic framework that quantifies the capability disparities\nbetween different modalities in the multi-modal setting and provide a set of\ndatasets designed for these evaluations. Our findings reveal that models like\nGPT-4V tend to perform consistently modalities when the tasks are relatively\nsimple. However, the trustworthiness of results derived from the vision\nmodality diminishes as the tasks become more challenging. Expanding on our\nfindings, we introduce \"Vision Description Prompting,\" a method that\neffectively improves performance in challenging vision-related tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Senyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zijun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_N/0/1/0/all/0/1\">Ning Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Named Entity Recognition for Monitoring Plant Health Threats in Tweets: a ChouBERT Approach. (arXiv:2310.12522v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12522","description":"<p>An important application scenario of precision agriculture is detecting and\nmeasuring crop health threats using sensors and data analysis techniques.\nHowever, the textual data are still under-explored among the existing solutions\ndue to the lack of labelled data and fine-grained semantic resources. Recent\nresearch suggests that the increasing connectivity of farmers and the emergence\nof online farming communities make social media like Twitter a participatory\nplatform for detecting unfamiliar plant health events if we can extract\nessential information from unstructured textual data. ChouBERT is a French\npre-trained language model that can identify Tweets concerning observations of\nplant health issues with generalizability on unseen natural hazards. This paper\ntackles the lack of labelled data by further studying ChouBERT's know-how on\ntoken-level annotation tasks over small labeled sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Shufan Jiang</a> (CRESTIC, ISEP), <a href=\"http://arxiv.org/find/cs/1/au:+Angarita_R/0/1/0/all/0/1\">Rafael Angarita</a> (ISEP), <a href=\"http://arxiv.org/find/cs/1/au:+Cormier_S/0/1/0/all/0/1\">St&#xe9;phane Cormier</a> (CRESTIC), <a href=\"http://arxiv.org/find/cs/1/au:+Rousseaux_F/0/1/0/all/0/1\">Francis Rousseaux</a> (CRESTIC)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding. (arXiv:2310.12531v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12531","description":"<p>Most multilingual vision-and-language (V&amp;L) research aims to accomplish\nmultilingual and multimodal capabilities within one model. However, the\nscarcity of multilingual captions for images has hindered the development. To\novercome this obstacle, we propose ICU, Image Caption Understanding, which\ndivides a V&amp;L task into two stages: a V&amp;L model performs image captioning in\nEnglish, and a multilingual language model (mLM), in turn, takes the caption as\nthe alt text and performs crosslingual language understanding. The burden of\nmultilingual processing is lifted off V&amp;L model and placed on mLM. Since the\nmultilingual text data is relatively of higher abundance and quality, ICU can\nfacilitate the conquering of language barriers for V&amp;L models. In experiments\non two tasks across 9 languages in the IGLUE benchmark, we show that ICU can\nachieve new state-of-the-art results for five languages, and comparable results\nfor the rest.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Guojun Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Product Attribute Value Extraction using Large Language Models. (arXiv:2310.12537v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12537","description":"<p>E-commerce applications such as faceted product search or product comparison\nare based on structured product descriptions like attribute/value pairs. The\nvendors on e-commerce platforms do not provide structured product descriptions\nbut describe offers using titles or descriptions. To process such offers, it is\nnecessary to extract attribute/value pairs from textual product attributes.\nState-of-the-art attribute/value extraction techniques rely on pre-trained\nlanguage models (PLMs), such as BERT. Two major drawbacks of these models for\nattribute/value extraction are that (i) the models require significant amounts\nof task-specific training data and (ii) the fine-tuned models face challenges\nin generalizing to attribute values not included in the training data. This\npaper explores the potential of large language models (LLMs) as a training\ndata-efficient and robust alternative to PLM-based attribute/value extraction\nmethods. We consider hosted LLMs, such as GPT-3.5 and GPT-4, as well as\nopen-source LLMs based on Llama2. We evaluate the models in a zero-shot\nscenario and in a scenario where task-specific training data is available. In\nthe zero-shot scenario, we compare various prompt designs for representing\ninformation about the target attributes of the extraction. In the scenario with\ntraining data, we investigate (i) the provision of example attribute values,\n(ii) the selection of in-context demonstrations, and (iii) the fine-tuning of\nGPT-3.5. Our experiments show that GPT-4 achieves an average F1-score of 85% on\nthe two evaluation datasets while the best PLM-based techniques perform on\naverage 5% worse using the same amount of training data. GPT-4 achieves a 10%\nhigher F1-score than the best open-source LLM. The fine-tuned GPT-3.5 model\nreaches a similar performance as GPT-4 while being significantly more\ncost-efficient.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brinkmann_A/0/1/0/all/0/1\">Alexander Brinkmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shraga_R/0/1/0/all/0/1\">Roee Shraga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizer_C/0/1/0/all/0/1\">Christian Bizer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])","link":"http://arxiv.org/abs/2310.12541","description":"<p>Multiobjective evolutionary algorithms (MOEAs) are major methods for solving\nmultiobjective optimization problems (MOPs). Many MOEAs have been proposed in\nthe past decades, of which the operators need carefully handcrafted design with\ndomain knowledge. Recently, some attempts have been made to replace the\nmanually designed operators in MOEAs with learning-based operators (e.g.,\nneural network models). However, much effort is still required for designing\nand training such models, and the learned operators might not generalize well\nto solve new problems. To tackle the above challenges, this work investigates a\nnovel approach that leverages the powerful large language model (LLM) to design\nMOEA operators. With proper prompt engineering, we successfully let a general\nLLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D)\nin a zero-shot manner. In addition, by learning from the LLM behavior, we\nfurther design an explicit white-box operator with randomness and propose a new\nversion of decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on\ndifferent test benchmarks show that our proposed method can achieve competitive\nperformance with widely used MOEAs. It is also promising to see the operator\nonly learned from a few instances can have robust generalization performance on\nunseen problems with quite different patterns and settings. The results reveal\nthe potential benefits of using pre-trained LLMs in the design of MOEAs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenkun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1\">Shunyu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1\">Xialiang Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Mingxuan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingfu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DepWiGNN: A Depth-wise Graph Neural Network for Multi-hop Spatial Reasoning in Text. (arXiv:2310.12557v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12557","description":"<p>Spatial reasoning in text plays a crucial role in various real-world\napplications. Existing approaches for spatial reasoning typically infer spatial\nrelations from pure text, which overlook the gap between natural language and\nsymbolic structures. Graph neural networks (GNNs) have showcased exceptional\nproficiency in inducing and aggregating symbolic structures. However, classical\nGNNs face challenges in handling multi-hop spatial reasoning due to the\nover-smoothing issue, \\textit{i.e.}, the performance decreases substantially as\nthe number of graph layers increases. To cope with these challenges, we propose\na novel \\textbf{Dep}th-\\textbf{Wi}se \\textbf{G}raph \\textbf{N}eural\n\\textbf{N}etwork (\\textbf{DepWiGNN}). Specifically, we design a novel node\nmemory scheme and aggregate the information over the depth dimension instead of\nthe breadth dimension of the graph, which empowers the ability to collect long\ndependencies without stacking multiple layers. Experimental results on two\nchallenging multi-hop spatial reasoning datasets show that DepWiGNN outperforms\nexisting spatial reasoning methods. The comparisons with the other three GNNs\nfurther demonstrate its superiority in capturing long dependency in the graph.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuaiyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Help Humans Verify Truthfulness -- Except When They Are Convincingly Wrong. (arXiv:2310.12558v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12558","description":"<p>Large Language Models (LLMs) are increasingly used for accessing information\non the web. Their truthfulness and factuality are thus of great interest. To\nhelp users make the right decisions about the information they're getting, LLMs\nshould not only provide but also help users fact-check information. In this\npaper, we conduct experiments with 80 crowdworkers in total to compare language\nmodels with search engines (information retrieval systems) at facilitating\nfact-checking by human users. We prompt LLMs to validate a given claim and\nprovide corresponding explanations. Users reading LLM explanations are\nsignificantly more efficient than using search engines with similar accuracy.\nHowever, they tend to over-rely the LLMs when the explanation is wrong. To\nreduce over-reliance on LLMs, we ask LLMs to provide contrastive information -\nexplain both why the claim is true and false, and then we present both sides of\nthe explanation to users. This contrastive explanation mitigates users'\nover-reliance on LLMs, but cannot significantly outperform search engines.\nHowever, showing both search engine results and LLM explanations offers no\ncomplementary benefits as compared to search engines alone. Taken together,\nnatural language explanations by LLMs may not be a reliable replacement for\nreading the retrieved passages yet, especially in high-stakes settings where\nover-relying on wrong AI explanations could lead to critical consequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Navita Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sherry Tongshuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daume_H/0/1/0/all/0/1\">Hal Daum&#xe9; III</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers. (arXiv:2310.12575v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12575","description":"<p>Scaling analysis is a technique in computational political science that\nassigns a political actor (e.g. politician or party) a score on a predefined\nscale based on a (typically long) body of text (e.g. a parliamentary speech or\nan election manifesto). For example, political scientists have often used the\nleft--right scale to systematically analyse political landscapes of different\ncountries. NLP methods for automatic scaling analysis can find broad\napplication provided they (i) are able to deal with long texts and (ii) work\nrobustly across domains and languages. In this work, we implement and compare\ntwo approaches to automatic scaling analysis of political-party manifestos:\nlabel aggregation, a pipeline strategy relying on annotations of individual\nstatements from the manifestos, and long-input-Transformer-based models, which\ncompute scaling values directly from raw text. We carry out the analysis of the\nComparative Manifestos Project dataset across 41 countries and 27 languages and\nfind that the task can be efficiently solved by state-of-the-art models, with\nlabel aggregation producing the best results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1\">Dmitry Nikolaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceron_T/0/1/0/all/0/1\">Tanise Ceron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pado_S/0/1/0/all/0/1\">Sebastian Pad&#xf3;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pretraining Language Models with Text-Attributed Heterogeneous Graphs. (arXiv:2310.12580v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12580","description":"<p>In many real-world scenarios (e.g., academic networks, social platforms),\ndifferent types of entities are not only associated with texts but also\nconnected by various relationships, which can be abstracted as Text-Attributed\nHeterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models\n(LMs) primarily focus on separately learning the textual information of each\nentity and overlook the crucial aspect of capturing topological connections\namong entities in TAHGs. In this paper, we present a new pretraining framework\nfor LMs that explicitly considers the topological and heterogeneous information\nin TAHGs. Firstly, we define a context graph as neighborhoods of a target node\nwithin specific orders and propose a topology-aware pretraining task to predict\nnodes involved in the context graph by jointly optimizing an LM and an\nauxiliary heterogeneous graph neural network. Secondly, based on the\nobservation that some nodes are text-rich while others have little text, we\ndevise a text augmentation strategy to enrich textless nodes with their\nneighbors' texts for handling the imbalance issue. We conduct link prediction\nand node classification tasks on three datasets from various domains.\nExperimental results demonstrate the superiority of our approach over existing\nmethods and the rationality of each design. Our code is available at\nhttps://github.com/Hope-Rita/THLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_T/0/1/0/all/0/1\">Tao Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Le Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yifei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bowen Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Time-Aware Representation Learning for Time-Sensitive Question Answering. (arXiv:2310.12585v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12585","description":"<p>Time is one of the crucial factors in real-world question answering (QA)\nproblems. However, language models have difficulty understanding the\nrelationships between time specifiers, such as 'after' and 'before', and\nnumbers, since existing QA datasets do not include sufficient time expressions.\nTo address this issue, we propose a Time-Context aware Question Answering\n(TCQA) framework. We suggest a Time-Context dependent Span Extraction (TCSE)\ntask, and build a time-context dependent data generation framework for model\ntraining. Moreover, we present a metric to evaluate the time awareness of the\nQA model using TCSE. The TCSE task consists of a question and four sentence\ncandidates classified as correct or incorrect based on time and context. The\nmodel is trained to extract the answer span from the sentence that is both\ncorrect in time and context. The model trained with TCQA outperforms baseline\nmodels up to 8.5 of the F1-score in the TimeQA dataset. Our dataset and code\nare available at https://github.com/sonjbin/TCQA\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Son_J/0/1/0/all/0/1\">Jungbin Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Identifying and Adapting Transformer-Components Responsible for Gender Bias in an English Language Model. (arXiv:2310.12611v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12611","description":"<p>Language models (LMs) exhibit and amplify many types of undesirable biases\nlearned from the training data, including gender bias. However, we lack tools\nfor effectively and efficiently changing this behavior without hurting general\nlanguage modeling performance. In this paper, we study three methods for\nidentifying causal relations between LM components and particular output:\ncausal mediation analysis, automated circuit discovery and our novel, efficient\nmethod called DiffMask+ based on differential masking. We apply the methods to\nGPT-2 small and the problem of gender bias, and use the discovered sets of\ncomponents to perform parameter-efficient fine-tuning for bias mitigation. Our\nresults show significant overlap in the identified components (despite huge\ndifferences in the computational requirements of the methods) as well as\nsuccess in mitigating gender bias, with less damage to general language\nmodeling compared to full model fine-tuning. However, our work also underscores\nthe difficulty of defining and measuring bias, and the sensitivity of causal\ndiscovery procedures to dataset choice. We hope our work can contribute to more\nattention for dataset development, and lead to more effective mitigation\nstrategies for other types of bias.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chintam_A/0/1/0/all/0/1\">Abhijith Chintam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beloch_R/0/1/0/all/0/1\">Rahel Beloch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1\">Willem Zuidema</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hanna_M/0/1/0/all/0/1\">Michael Hanna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wal_O/0/1/0/all/0/1\">Oskar van der Wal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Predict the Future from the Past? On the Temporal Data Distribution Shift in Financial Sentiment Classifications. (arXiv:2310.12620v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12620","description":"<p>Temporal data distribution shift is prevalent in the financial text. How can\na financial sentiment analysis system be trained in a volatile market\nenvironment that can accurately infer sentiment and be robust to temporal data\ndistribution shifts? In this paper, we conduct an empirical study on the\nfinancial sentiment analysis system under temporal data distribution shifts\nusing a real-world financial social media dataset that spans three years. We\nfind that the fine-tuned models suffer from general performance degradation in\nthe presence of temporal distribution shifts. Furthermore, motivated by the\nunique temporal nature of the financial text, we propose a novel method that\ncombines out-of-distribution detection with time series modeling for temporal\nfinancial sentiment analysis. Experimental results show that the proposed\nmethod enhances the model's capability to adapt to evolving temporal shifts in\na volatile financial market.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yue Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chenxi Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-Autoregressive Sentence Ordering. (arXiv:2310.12640v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12640","description":"<p>Existing sentence ordering approaches generally employ encoder-decoder\nframeworks with the pointer net to recover the coherence by recurrently\npredicting each sentence step-by-step. Such an autoregressive manner only\nleverages unilateral dependencies during decoding and cannot fully explore the\nsemantic dependency between sentences for ordering. To overcome these\nlimitations, in this paper, we propose a novel Non-Autoregressive Ordering\nNetwork, dubbed \\textit{NAON}, which explores bilateral dependencies between\nsentences and predicts the sentence for each position in parallel. We claim\nthat the non-autoregressive manner is not just applicable but also particularly\nsuitable to the sentence ordering task because of two peculiar characteristics\nof the task: 1) each generation target is in deterministic length, and 2) the\nsentences and positions should match exclusively. Furthermore, to address the\nrepetition issue of the naive non-autoregressive Transformer, we introduce an\nexclusive loss to constrain the exclusiveness between positions and sentences.\nTo verify the effectiveness of the proposed model, we conduct extensive\nexperiments on several common-used datasets and the experimental results show\nthat our method outperforms all the autoregressive approaches and yields\ncompetitive performance compared with the state-of-the-arts. The codes are\navailable at:\n\\url{https://github.com/steven640pixel/nonautoregressive-sentence-ordering}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bin_Y/0/1/0/all/0/1\">Yi Bin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Wenhao Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_B/0/1/0/all/0/1\">Bin Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1\">Yujuan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Real-World Streaming Speech Translation for Code-Switched Speech. (arXiv:2310.12648v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12648","description":"<p>Code-switching (CS), i.e. mixing different languages in a single sentence, is\na common phenomenon in communication and can be challenging in many Natural\nLanguage Processing (NLP) settings. Previous studies on CS speech have shown\npromising results for end-to-end speech translation (ST), but have been limited\nto offline scenarios and to translation to one of the languages present in the\nsource (\\textit{monolingual transcription}).\n</p>\n<p>In this paper, we focus on two essential yet unexplored areas for real-world\nCS speech translation: streaming settings, and translation to a third language\n(i.e., a language not included in the source). To this end, we extend the\nFisher and Miami test and validation datasets to include new targets in Spanish\nand German. Using this data, we train a model for both offline and streaming ST\nand we establish baseline results for the two settings mentioned earlier.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alastruey_B/0/1/0/all/0/1\">Belen Alastruey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperber_M/0/1/0/all/0/1\">Matthias Sperber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollan_C/0/1/0/all/0/1\">Christian Gollan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telaar_D/0/1/0/all/0/1\">Dominic Telaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_T/0/1/0/all/0/1\">Tim Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agargwal_A/0/1/0/all/0/1\">Aashish Agargwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is ChatGPT a Financial Expert? Evaluating Language Models on Financial Natural Language Processing. (arXiv:2310.12664v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12664","description":"<p>The emergence of Large Language Models (LLMs), such as ChatGPT, has\nrevolutionized general natural language preprocessing (NLP) tasks. However,\ntheir expertise in the financial domain lacks a comprehensive evaluation. To\nassess the ability of LLMs to solve financial NLP tasks, we present FinLMEval,\na framework for Financial Language Model Evaluation, comprising nine datasets\ndesigned to evaluate the performance of language models. This study compares\nthe performance of encoder-only language models and the decoder-only language\nmodels. Our findings reveal that while some decoder-only LLMs demonstrate\nnotable performance across most financial tasks via zero-shot prompting, they\ngenerally lag behind the fine-tuned expert models, especially when dealing with\nproprietary datasets. We hope this study provides foundation evaluations for\ncontinuing efforts to build more advanced LLMs in the financial domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yue Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zian Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Representing and Computing Uncertainty in Phonological Reconstruction. (arXiv:2310.12727v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12727","description":"<p>Despite the inherently fuzzy nature of reconstructions in historical\nlinguistics, most scholars do not represent their uncertainty when proposing\nproto-forms. With the increasing success of recently proposed approaches to\nautomating certain aspects of the traditional comparative method, the formal\nrepresentation of proto-forms has also improved. This formalization makes it\npossible to address both the representation and the computation of uncertainty.\nBuilding on recent advances in supervised phonological reconstruction, during\nwhich an algorithm learns how to reconstruct words in a given proto-language\nrelying on previously annotated data, and inspired by improved methods for\nautomated word prediction from cognate sets, we present a new framework that\nallows for the representation of uncertainty in linguistic reconstruction and\nalso includes a workflow for the computation of fuzzy reconstructions from\nlinguistic data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+List_J/0/1/0/all/0/1\">Johann-Mattis List</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hill_N/0/1/0/all/0/1\">Nathan W. Hill</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forkel_R/0/1/0/all/0/1\">Robert Forkel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blum_F/0/1/0/all/0/1\">Frederic Blum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Character-level Chinese Backpack Language Models. (arXiv:2310.12751v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12751","description":"<p>The Backpack is a Transformer alternative shown to improve interpretability\nin English language modeling by decomposing predictions into a weighted sum of\ntoken sense components. However, Backpacks' reliance on token-defined meaning\nraises questions as to their potential for languages other than English, a\nlanguage for which subword tokenization provides a reasonable approximation for\nlexical items. In this work, we train, evaluate, interpret, and control\nBackpack language models in character-tokenized Chinese, in which words are\noften composed of many characters. We find that our (134M parameter) Chinese\nBackpack language model performs comparably to a (104M parameter) Transformer,\nand learns rich character-level meanings that log-additively compose to form\nword meanings. In SimLex-style lexical semantic evaluations, simple averages of\nBackpack character senses outperform input embeddings from a Transformer. We\nfind that complex multi-character meanings are often formed by using the same\nper-character sense weights consistently across context. Exploring\ninterpretability-through control, we show that we can localize a source of\ngender bias in our Backpacks to specific character senses and intervene to\nreduce the bias.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewitt_J/0/1/0/all/0/1\">John Hewitt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-based Entity Legal Form Classification. (arXiv:2310.12766v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12766","description":"<p>We propose the application of Transformer-based language models for\nclassifying entity legal forms from raw legal entity names. Specifically, we\nemploy various BERT variants and compare their performance against multiple\ntraditional baselines. Our evaluation encompasses a substantial subset of\nfreely available Legal Entity Identifier (LEI) data, comprising over 1.1\nmillion legal entities from 30 different legal jurisdictions. The ground truth\nlabels for classification per jurisdiction are taken from the Entity Legal Form\n(ELF) code standard (ISO 20275). Our findings demonstrate that pre-trained BERT\nvariants outperform traditional text classification approaches in terms of F1\nscore, while also performing comparably well in the Macro F1 Score. Moreover,\nthe validity of our proposal is supported by the outcome of third-party expert\nreviews conducted in ten selected jurisdictions. This study highlights the\nsignificant potential of Transformer-based models in advancing data\nstandardization and data integration. The presented approaches can greatly\nbenefit financial institutions, corporations, governments and other\norganizations in assessing business relationships, understanding risk exposure,\nand promoting effective governance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arimond_A/0/1/0/all/0/1\">Alexander Arimond</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molteni_M/0/1/0/all/0/1\">Mauro Molteni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jany_D/0/1/0/all/0/1\">Dominik Jany</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manolova_Z/0/1/0/all/0/1\">Zornitsa Manolova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1\">Damian Borth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoepner_A/0/1/0/all/0/1\">Andreas G.F. Hoepner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survival of the Most Influential Prompts: Efficient Black-Box Prompt Search via Clustering and Pruning. (arXiv:2310.12774v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12774","description":"<p>Prompt-based learning has been an effective paradigm for large pretrained\nlanguage models (LLM), enabling few-shot or even zero-shot learning. Black-box\nprompt search has received growing interest recently for its distinctive\nproperties of gradient-free optimization, proven particularly useful and\npowerful for model-as-a-service usage. However, the discrete nature and the\ncomplexity of combinatorial optimization hinder the efficiency of modern\nblack-box approaches. Despite extensive research on search algorithms, the\ncrucial aspect of search space design and optimization has been largely\noverlooked. In this paper, we first conduct a sensitivity analysis by prompting\nLLM, revealing that only a small number of tokens exert a disproportionate\namount of influence on LLM predictions. Leveraging this insight, we propose the\nClustering and Pruning for Efficient Black-box Prompt Search (ClaPS), a simple\nblack-box search method that first clusters and prunes the search space to\nfocus exclusively on influential prompt tokens. By employing even simple search\nmethods within the pruned search space, ClaPS achieves state-of-the-art\nperformance across various tasks and LLMs, surpassing the performance of\ncomplex approaches while significantly reducing search costs. Our findings\nunderscore the critical role of search space design and optimization in\nenhancing both the usefulness and the efficiency of black-box prompt-based\nlearning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Label-Aware Automatic Verbalizer for Few-Shot Text Classification. (arXiv:2310.12778v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12778","description":"<p>Prompt-based learning has shown its effectiveness in few-shot text\nclassification. One important factor in its success is a verbalizer, which\ntranslates output from a language model into a predicted class. Notably, the\nsimplest and widely acknowledged verbalizer employs manual labels to represent\nthe classes. However, manual selection does not guarantee the optimality of the\nselected words when conditioned on the chosen language model. Therefore, we\npropose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting the\nmanual labels to achieve better few-shot classification results. Specifically,\nwe use the manual labels along with the conjunction \"and\" to induce the model\nto generate more effective words for the verbalizer. The experimental results\non five datasets across five languages demonstrate that LAAV significantly\noutperforms existing verbalizers. Furthermore, our analysis reveals that LAAV\nsuggests more relevant words compared to similar approaches, especially in\nmid-to-low resource languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thaminkaew_T/0/1/0/all/0/1\">Thanakorn Thaminkaew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lertvittayakumjorn_P/0/1/0/all/0/1\">Piyawat Lertvittayakumjorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vateekul_P/0/1/0/all/0/1\">Peerapon Vateekul</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization. (arXiv:2310.12794v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12794","description":"<p>Large language models (LLMs) have exhibited considerable cross-lingual\ngeneralization abilities, whereby they implicitly transfer knowledge across\nlanguages. However, the transfer is not equally successful for all languages,\nespecially for low-resource ones, which poses an ongoing challenge. It is\nunclear whether we have reached the limits of implicit cross-lingual\ngeneralization and if explicit knowledge transfer is viable. In this paper, we\ninvestigate the potential for explicitly aligning conceptual correspondence\nbetween languages to enhance cross-lingual generalization. Using the syntactic\naspect of language as a testbed, our analyses of 43 languages reveal a high\ndegree of alignability among the spaces of structural concepts within each\nlanguage for both encoder-only and decoder-only LLMs. We then propose a\nmeta-learning-based method to learn to align conceptual spaces of different\nlanguages, which facilitates zero-shot and few-shot generalization in concept\nclassification and also offers insights into the cross-lingual in-context\nlearning phenomenon. Experiments on syntactic analysis tasks show that our\napproach achieves competitive results with state-of-the-art methods and narrows\nthe performance gap between languages, particularly benefiting those with\nlimited resources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Ningyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jingting Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Menghan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. (arXiv:2310.12798v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12798","description":"<p>Language Models (LMs) have demonstrated impressive molecule understanding\nability on various 1D text-related tasks. However, they inherently lack 2D\ngraph perception - a critical ability of human professionals in comprehending\nmolecules' topological structures. To bridge this gap, we propose MolCA:\nMolecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal\nAdapter. MolCA enables an LM (e.g., Galactica) to understand both text- and\ngraph-based molecular contents via the cross-modal projector. Specifically, the\ncross-modal projector is implemented as a Q-Former to connect a graph encoder's\nrepresentation space and an LM's text space. Further, MolCA employs a uni-modal\nadapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks.\nUnlike previous studies that couple an LM with a graph encoder via cross-modal\ncontrastive learning, MolCA retains the LM's ability of open-ended text\ngeneration and augments it with 2D graph information. To showcase its\neffectiveness, we extensively benchmark MolCA on tasks of molecule captioning,\nIUPAC name prediction, and molecule-text retrieval, on which MolCA\nsignificantly outperforms the baselines. Our codes and checkpoints can be found\nat https://github.com/acharkq/MolCA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sihang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yanchen Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fei_H/0/1/0/all/0/1\">Hao Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1\">Tat-Seng Chua</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal-structure Driven Augmentations for Text OOD Generalization. (arXiv:2310.12803v1 [cs.LG])","link":"http://arxiv.org/abs/2310.12803","description":"<p>The reliance of text classifiers on spurious correlations can lead to poor\ngeneralization at deployment, raising concerns about their use in\nsafety-critical domains such as healthcare. In this work, we propose to use\ncounterfactual data augmentation, guided by knowledge of the causal structure\nof the data, to simulate interventions on spurious features and to learn more\nrobust text classifiers. We show that this strategy is appropriate in\nprediction problems where the label is spuriously correlated with an attribute.\nUnder the assumptions of such problems, we discuss the favorable sample\ncomplexity of counterfactual data augmentation, compared to importance\nre-weighting. Pragmatically, we match examples using auxiliary data, based on\ndiff-in-diff methodology, and use a large language model (LLM) to represent a\nconditional probability of text. Through extensive experimentation on learning\ncaregiver-invariant predictors of clinical diagnoses from medical narratives\nand on semi-synthetic data, we demonstrate that our method for simulating\ninterventions improves out-of-distribution (OOD) accuracy compared to baseline\ninvariant learning algorithms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1\">Amir Feder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1\">Yoav Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1\">Claudia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saria_S/0/1/0/all/0/1\">Suchi Saria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1\">David Blei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Model Merging by Uncertainty-Based Gradient Matching. (arXiv:2310.12808v1 [cs.LG])","link":"http://arxiv.org/abs/2310.12808","description":"<p>Models trained on different datasets can be merged by a weighted-averaging of\ntheir parameters, but why does it work and when can it fail? Here, we connect\nthe inaccuracy of weighted-averaging to mismatches in the gradients and propose\na new uncertainty-based scheme to improve the performance by reducing the\nmismatch. The connection also reveals implicit assumptions in other schemes\nsuch as averaging, task arithmetic, and Fisher-weighted averaging. Our new\nmethod gives consistent improvements for large language models and vision\ntransformers, both in terms of performance and robustness to hyperparameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1\">Nico Daheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mollenhoff_T/0/1/0/all/0/1\">Thomas M&#xf6;llenhoff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1\">Edoardo Maria Ponti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1\">Mohammad Emtiyaz Khan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt Injection Attacks and Defenses in LLM-Integrated Applications. (arXiv:2310.12815v1 [cs.CR])","link":"http://arxiv.org/abs/2310.12815","description":"<p>Large Language Models (LLMs) are increasingly deployed as the backend for a\nvariety of real-world applications called LLM-Integrated Applications. Multiple\nrecent works showed that LLM-Integrated Applications are vulnerable to prompt\ninjection attacks, in which an attacker injects malicious instruction/data into\nthe input of those applications such that they produce results as the attacker\ndesires. However, existing works are limited to case studies. As a result, the\nliterature lacks a systematic understanding of prompt injection attacks and\ntheir defenses. We aim to bridge the gap in this work. In particular, we\npropose a general framework to formalize prompt injection attacks. Existing\nattacks, which are discussed in research papers and blog posts, are special\ncases in our framework. Our framework enables us to design a new attack by\ncombining existing attacks. Moreover, we also propose a framework to\nsystematize defenses against prompt injection attacks. Using our frameworks, we\nconduct a systematic evaluation on prompt injection attacks and their defenses\nwith 10 LLMs and 7 tasks. We hope our frameworks can inspire future research in\nthis field. Our code is available at\nhttps://github.com/liu00222/Open-Prompt-Injection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yupei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yuqi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1\">Runpeng Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jinyuan Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Inference Efficiency: Unleashing the Power of Parameter-Shared Pre-trained Language Models. (arXiv:2310.12818v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12818","description":"<p>Parameter-shared pre-trained language models (PLMs) have emerged as a\nsuccessful approach in resource-constrained environments, enabling substantial\nreductions in model storage and memory costs without significant performance\ncompromise. However, it is important to note that parameter sharing does not\nalleviate computational burdens associated with inference, thus impeding its\npracticality in situations characterized by limited stringent latency\nrequirements or computational resources. Building upon neural ordinary\ndifferential equations (ODEs), we introduce a straightforward technique to\nenhance the inference efficiency of parameter-shared PLMs. Additionally, we\npropose a simple pre-training technique that leads to fully or partially shared\nmodels capable of achieving even greater inference acceleration. The\nexperimental results demonstrate the effectiveness of our methods on both\nautoregressive and autoencoding PLMs, providing novel insights into more\nefficient utilization of parameter-shared models in resource-constrained\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiaoyue Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GestureGPT: Zero-shot Interactive Gesture Understanding and Grounding with Large Language Model Agents. (arXiv:2310.12821v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12821","description":"<p>Current gesture recognition systems primarily focus on identifying gestures\nwithin a predefined set, leaving a gap in connecting these gestures to\ninteractive GUI elements or system functions (e.g., linking a 'thumb-up'\ngesture to a 'like' button). We introduce GestureGPT, a novel zero-shot gesture\nunderstanding and grounding framework leveraging large language models (LLMs).\nGesture descriptions are formulated based on hand landmark coordinates from\ngesture videos and fed into our dual-agent dialogue system. A gesture agent\ndeciphers these descriptions and queries about the interaction context (e.g.,\ninterface, history, gaze data), which a context agent organizes and provides.\nFollowing iterative exchanges, the gesture agent discerns user intent,\ngrounding it to an interactive function. We validated the gesture description\nmodule using public first-view and third-view gesture datasets and tested the\nwhole system in two real-world settings: video streaming and smart home IoT\ncontrol. The highest zero-shot Top-5 grounding accuracies are 80.11% for video\nstreaming and 90.78% for smart home tasks, showing potential of the new gesture\nunderstanding paradigm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xin Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tengxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shengdong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12823","description":"<p>Open large language models (LLMs) with great performance in various tasks\nhave significantly advanced the development of LLMs. However, they are far\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\ncentral controller responsible for planning, memorization, and tool\nutilization, necessitating both fine-grained prompting methods and robust LLMs\nto achieve satisfactory performance. Though many prompting methods have been\nproposed to complete particular agent tasks, there is lack of research focusing\non improving the agent capabilities of LLMs themselves without compromising\ntheir general abilities. In this work, we present AgentTuning, a simple and\ngeneral method to enhance the agent abilities of LLMs while maintaining their\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\ninstruction-tuning dataset containing high-quality interaction trajectories. We\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\nopen-source instructions from general domains. AgentTuning is used to\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\nthat AgentTuning enables LLMs' agent capabilities without compromising general\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\ntasks, demonstrating generalized agent capabilities. We open source the\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\nhttps://github.com/THUDM/AgentTuning , serving open and powerful alternatives\nto commercial LLMs for agent tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Aohan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingdao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge-Augmented Language Model Verification. (arXiv:2310.12836v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12836","description":"<p>Recent Language Models (LMs) have shown impressive capabilities in generating\ntexts with the knowledge internalized in parameters. Yet, LMs often generate\nthe factually incorrect responses to the given queries, since their knowledge\nmay be inaccurate, incomplete, and outdated. To address this problem, previous\nworks propose to augment LMs with the knowledge retrieved from an external\nknowledge source. However, such approaches often show suboptimal text\ngeneration performance due to two reasons: 1) the model may fail to retrieve\nthe knowledge relevant to the given query, or 2) the model may not faithfully\nreflect the retrieved knowledge in the generated text. To overcome these, we\npropose to verify the output and the knowledge of the knowledge-augmented LMs\nwith a separate verifier, which is a small LM that is trained to detect those\ntwo types of errors through instruction-finetuning. Then, when the verifier\nrecognizes an error, we can rectify it by either retrieving new knowledge or\ngenerating new text. Further, we use an ensemble of the outputs from different\ninstructions with a single verifier to enhance the reliability of the\nverification processes. We validate the effectiveness of the proposed\nverification steps on multiple question answering benchmarks, whose results\nshow that the proposed verifier effectively identifies retrieval and generation\nerrors, allowing LMs to provide more factually correct outputs. Our code is\navailable at https://github.com/JinheonBaek/KALMV.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jinheon Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Soyeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1\">Minki Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong C. Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EmoDiarize: Speaker Diarization and Emotion Identification from Speech Signals using Convolutional Neural Networks. (arXiv:2310.12851v1 [cs.SD])","link":"http://arxiv.org/abs/2310.12851","description":"<p>In the era of advanced artificial intelligence and human-computer\ninteraction, identifying emotions in spoken language is paramount. This\nresearch explores the integration of deep learning techniques in speech emotion\nrecognition, offering a comprehensive solution to the challenges associated\nwith speaker diarization and emotion identification. It introduces a framework\nthat combines a pre-existing speaker diarization pipeline and an emotion\nidentification model built on a Convolutional Neural Network (CNN) to achieve\nhigher precision. The proposed model was trained on data from five speech\nemotion datasets, namely, RAVDESS, CREMA-D, SAVEE, TESS, and Movie Clips, out\nof which the latter is a speech emotion dataset created specifically for this\nresearch. The features extracted from each sample include Mel Frequency\nCepstral Coefficients (MFCC), Zero Crossing Rate (ZCR), Root Mean Square (RMS),\nand various data augmentation algorithms like pitch, noise, stretch, and shift.\nThis feature extraction approach aims to enhance prediction accuracy while\nreducing computational complexity. The proposed model yields an unweighted\naccuracy of 63%, demonstrating remarkable efficiency in accurately identifying\nemotional states within speech signals.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hamza_H/0/1/0/all/0/1\">Hanan Hamza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gafoor_F/0/1/0/all/0/1\">Fiza Gafoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sithara_F/0/1/0/all/0/1\">Fathima Sithara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anil_G/0/1/0/all/0/1\">Gayathri Anil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anoop_V/0/1/0/all/0/1\">V. S. Anoop</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing LLMs for hate speech detection: strengths and vulnerabilities. (arXiv:2310.12860v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12860","description":"<p>Recently efforts have been made by social media platforms as well as\nresearchers to detect hateful or toxic language using large language models.\nHowever, none of these works aim to use explanation, additional context and\nvictim community information in the detection process. We utilise different\nprompt variation, input information and evaluate large language models in zero\nshot setting (without adding any in-context examples). We select three large\nlanguage models (GPT-3.5, text-davinci and Flan-T5) and three datasets -\nHateXplain, implicit hate and ToxicSpans. We find that on average including the\ntarget information in the pipeline improves the model performance substantially\n(~20-30%) over the baseline across the datasets. There is also a considerable\neffect of adding the rationales/explanations into the pipeline (~10-20%) over\nthe baseline across the datasets. In addition, we further provide a typology of\nthe error cases where these large language models fail to (i) classify and (ii)\nexplain the reason for the decisions they take. Such vulnerable points\nautomatically constitute 'jailbreak' prompts for these models and industry\nscale safeguard techniques need to be developed to make the models robust\nagainst such prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Sarthak Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harshavardhan_A/0/1/0/all/0/1\">Ashish Harshavardhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1\">Punyajoy Saha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Locality and Symmetry of Positional Encodings. (arXiv:2310.12864v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12864","description":"<p>Positional Encodings (PEs) are used to inject word-order information into\ntransformer-based language models. While they can significantly enhance the\nquality of sentence representations, their specific contribution to language\nmodels is not fully understood, especially given recent findings that various\npositional encodings are insensitive to word order. In this work, we conduct a\nsystematic study of positional encodings in \\textbf{Bidirectional Masked\nLanguage Models} (BERT-style) , which complements existing work in three\naspects: (1) We uncover the core function of PEs by identifying two common\nproperties, Locality and Symmetry; (2) We show that the two properties are\nclosely correlated with the performances of downstream tasks; (3) We quantify\nthe weakness of current PEs by introducing two new probing tasks, on which\ncurrent PEs perform poorly. We believe that these results are the basis for\ndeveloping better PEs for transformer-based language models. The code is\navailable at \\faGithub~ \\url{https://github.com/tigerchen52/locality\\_symmetry}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lihu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varoquaux_G/0/1/0/all/0/1\">Ga&#xeb;l Varoquaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suchanek_F/0/1/0/all/0/1\">Fabian M. Suchanek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding. (arXiv:2310.12874v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12874","description":"<p>Analogy-making between narratives is one of the most critical abilities in\nnatural language understanding. In this paper, we evaluate the ability to\nidentify and generate analogy by building a first-of-its-kind large-scale\nstory-level analogy corpus, StoryAnalogy, which contains 24K story pairs from\ndiverse domains with human annotations on two similarities from the extended\nStructure-Mapping Theory. We design a set of tests on StoryAnalogy, presenting\nthe first evaluation of story-level analogy identification and generation.\nInterestingly, we find that the analogy identification tasks are extremely\nchallenging not only for the sentence embedding models but also for the recent\nlarge language models (LLMs) such as ChatGPT and LLaMa, where ChatGPT only\nachieved around 30% accuracy in multiple-choice questions (&gt; 85% accuracy for\nhumans). Finally, we find that data in StoryAnalogy can improve LLMs analogy\ngeneration quality, where a fine-tuned FlanT5-xxl model yields comparable\nperformance to zero-shot ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiayang_C/0/1/0/all/0/1\">Cheng Jiayang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Lin Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1\">Tsz Ho Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chunkit Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ru_D/0/1/0/all/0/1\">Dongyu Ru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Systematic Study of Performance Disparities in Multilingual Task-Oriented Dialogue Systems. (arXiv:2310.12892v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12892","description":"<p>Achieving robust language technologies that can perform well across the\nworld's many languages is a central goal of multilingual NLP. In this work, we\ntake stock of and empirically analyse task performance disparities that exist\nbetween multilingual task-oriented dialogue (ToD) systems. We first define new\nquantitative measures of absolute and relative equivalence in system\nperformance, capturing disparities across languages and within individual\nlanguages. Through a series of controlled experiments, we demonstrate that\nperformance disparities depend on a number of factors: the nature of the ToD\ntask at hand, the underlying pretrained language model, the target language,\nand the amount of ToD annotated data. We empirically prove the existence of the\nadaptation and intrinsic biases in current ToD systems: e.g., ToD systems\ntrained for Arabic or Turkish using annotated ToD data fully parallel to\nEnglish ToD data still exhibit diminished ToD task performance. Beyond\nproviding a series of insights into the performance disparities of ToD systems\nin different languages, our analyses offer practical tips on how to approach\nToD data collection and system development for new languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songbo Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1\">Moy Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gritta_M/0/1/0/all/0/1\">Milan Gritta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Guchun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iacobacci_I/0/1/0/all/0/1\">Ignacio Iacobacci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experimental Narratives: A Comparison of Human Crowdsourced Storytelling and AI Storytelling. (arXiv:2310.12902v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12902","description":"<p>The paper proposes a framework that combines behavioral and computational\nexperiments employing fictional prompts as a novel tool for investigating\ncultural artifacts and social biases in storytelling both by humans and\ngenerative AI. The study analyzes 250 stories authored by crowdworkers in June\n2019 and 80 stories generated by GPT-3.5 and GPT-4 in March 2023 by merging\nmethods from narratology and inferential statistics. Both crowdworkers and\nlarge language models responded to identical prompts about creating and falling\nin love with an artificial human. The proposed experimental paradigm allows a\ndirect comparison between human and LLM-generated storytelling. Responses to\nthe Pygmalionesque prompts confirm the pervasive presence of the Pygmalion myth\nin the collective imaginary of both humans and large language models. All\nsolicited narratives present a scientific or technological pursuit. The\nanalysis reveals that narratives from GPT-3.5 and particularly GPT-4 are more\nmore progressive in terms of gender roles and sexuality than those written by\nhumans. While AI narratives can occasionally provide innovative plot twists,\nthey offer less imaginative scenarios and rhetoric than human-authored texts.\nThe proposed framework argues that fiction can be used as a window into human\nand AI-based collective imaginary and social dimensions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Begus_N/0/1/0/all/0/1\">Nina Begus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bhasacitra: Visualising the dialect geography of South Asia. (arXiv:2105.14082v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.14082","description":"<p>We present Bhasacitra, a dialect mapping system for South Asia built on a\ndatabase of linguistic studies of languages of the region annotated for topic\nand location data. We analyse language coverage and look towards applications\nto typology by visualising example datasets. The application is not only meant\nto be useful for feature mapping, but also serves as a new kind of interactive\nbibliography for linguists of South Asian languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Aryaman Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farris_A/0/1/0/all/0/1\">Adam Farris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_G/0/1/0/all/0/1\">Gopalakrishnan R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Samopriya Basu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Example-based Hypernetworks for Out-of-Distribution Generalization. (arXiv:2203.14276v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.14276","description":"<p>As Natural Language Processing (NLP) algorithms continually achieve new\nmilestones, out-of-distribution generalization remains a significant challenge.\nThis paper addresses the issue of multi-source adaptation for unfamiliar\ndomains: We leverage labeled data from multiple source domains to generalize to\nunknown target domains at training. Our innovative framework employs\nexample-based Hypernetwork adaptation: a T5 encoder-decoder initially generates\na unique signature from an input example, embedding it within the source\ndomains' semantic space. This signature is subsequently utilized by a\nHypernetwork to generate the task classifier's weights. We evaluated our method\nacross two tasks - sentiment classification and natural language inference - in\n29 adaptation scenarios, where it outpaced established algorithms. In an\nadvanced version, the signature also enriches the input example's\nrepresentation. We also compare our finetuned architecture to few-shot GPT-3,\ndemonstrating its effectiveness in essential use cases. To our knowledge, this\nmarks the first application of Hypernetworks to the adaptation for unknown\ndomains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Volk_T/0/1/0/all/0/1\">Tomer Volk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ben_David_E/0/1/0/all/0/1\">Eyal Ben-David</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amosy_O/0/1/0/all/0/1\">Ohad Amosy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1\">Roi Reichart</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Automatic Construction of Filipino WordNet: Word Sense Induction and Synset Induction Using Sentence Embeddings. (arXiv:2204.03251v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.03251","description":"<p>Wordnets are indispensable tools for various natural language processing\napplications. Unfortunately, wordnets get outdated, and producing or updating\nwordnets can be slow and costly in terms of time and resources. This problem\nintensifies for low-resource languages. This study proposes a method for word\nsense induction and synset induction using only two linguistic resources,\nnamely, an unlabeled corpus and a sentence embeddings-based language model. The\nresulting sense inventory and synonym sets can be used in automatically\ncreating a wordnet. We applied this method on a corpus of Filipino text. The\nsense inventory and synsets were evaluated by matching them with the sense\ninventory of the machine translated Princeton WordNet, as well as comparing the\nsynsets to the Filipino WordNet. This study empirically shows that the 30% of\nthe induced word senses are valid and 40% of the induced synsets are valid in\nwhich 20% are novel synsets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1\">Dan John Velasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alba_A/0/1/0/all/0/1\">Axel Alba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelagio_T/0/1/0/all/0/1\">Trisha Gail Pelagio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_B/0/1/0/all/0/1\">Bryce Anthony Ramirez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chua_U/0/1/0/all/0/1\">Unisse Chua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samson_B/0/1/0/all/0/1\">Briane Paul Samson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1\">Jan Christian Blaise Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Charibeth Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dict-TTS: Learning to Pronounce with Prior Dictionary Knowledge for Text-to-Speech. (arXiv:2206.02147v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2206.02147","description":"<p>Polyphone disambiguation aims to capture accurate pronunciation knowledge\nfrom natural text sequences for reliable Text-to-speech (TTS) systems. However,\nprevious approaches require substantial annotated training data and additional\nefforts from language experts, making it difficult to extend high-quality\nneural TTS systems to out-of-domain daily conversations and countless languages\nworldwide. This paper tackles the polyphone disambiguation problem from a\nconcise and novel perspective: we propose Dict-TTS, a semantic-aware generative\ntext-to-speech model with an online website dictionary (the existing prior\ninformation in the natural language). Specifically, we design a\nsemantics-to-pronunciation attention (S2PA) module to match the semantic\npatterns between the input text sequence and the prior semantics in the\ndictionary and obtain the corresponding pronunciations; The S2PA module can be\neasily trained with the end-to-end TTS model without any annotated phoneme\nlabels. Experimental results in three languages show that our model outperforms\nseveral strong baseline models in terms of pronunciation accuracy and improves\nthe prosody modeling of TTS systems. Further extensive analyses demonstrate\nthat each design in Dict-TTS is effective. The code is available at\n\\url{https://github.com/Zain-Jiang/Dict-TTS}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Jiang_Z/0/1/0/all/0/1\">Ziyue Jiang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Su_Z/0/1/0/all/0/1\">Zhe Su</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhou Zhao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1\">Qian Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ren_Y/0/1/0/all/0/1\">Yi Ren</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jinglin Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ye_Z/0/1/0/all/0/1\">Zhenhui Ye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to translate by learning to communicate. (arXiv:2207.07025v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.07025","description":"<p>We formulate and test a technique to use Emergent Communication (EC) with a\npre-trained multilingual model to improve on modern Unsupervised NMT systems,\nespecially for low-resource languages. It has been argued that the current\ndominant paradigm in NLP of pre-training on text-only corpora will not yield\nrobust natural language understanding systems, and the need for grounded,\ngoal-oriented, and interactive language learning has been high lighted. In our\napproach, we embed a multilingual model (mBART, Liu et al., 2020) into an EC\nimage-reference game, in which the model is incentivized to use multilingual\ngenerations to accomplish a vision-grounded task. The hypothesis is that this\nwill align multiple languages to a shared task space. We present two variants\nof EC Fine-Tuning (Steinert-Threlkeld et al., 2022), one of which outperforms a\nbacktranslation-only baseline in all four languages investigated, including the\nlow-resource language Nepali.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Downey_C/0/1/0/all/0/1\">C.M. Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Leo Z. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinert_Threlkeld_S/0/1/0/all/0/1\">Shane Steinert-Threlkeld</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Brain Signals Reveal Inner Alignment with Human Languages?. (arXiv:2208.06348v4 [q-bio.NC] UPDATED)","link":"http://arxiv.org/abs/2208.06348","description":"<p>Brain Signals, such as Electroencephalography (EEG), and human languages have\nbeen widely explored independently for many downstream tasks, however, the\nconnection between them has not been well explored. In this study, we explore\nthe relationship and dependency between EEG and language. To study at the\nrepresentation level, we introduced \\textbf{MTAM}, a \\textbf{M}ultimodal\n\\textbf{T}ransformer \\textbf{A}lignment \\textbf{M}odel, to observe coordinated\nrepresentations between the two modalities. We used various relationship\nalignment-seeking techniques, such as Canonical Correlation Analysis and\nWasserstein Distance, as loss functions to transfigure features. On downstream\napplications, sentiment analysis and relation detection, we achieved new\nstate-of-the-art results on two datasets, ZuCo and K-EmoCon. Our method\nachieved an F1-score improvement of 1.7% on K-EmoCon and 9.3% on Zuco datasets\nfor sentiment analysis, and 7.4% on ZuCo for relation detection. In addition,\nwe provide interpretations of the performance improvement: (1) feature\ndistribution shows the effectiveness of the alignment module for discovering\nand encoding the relationship between EEG and language; (2) alignment weights\nshow the influence of different language semantics as well as EEG frequency\nfeatures; (3) brain topographical maps provide an intuitive demonstration of\nthe connectivity in the brain regions. Our code is available at\n\\url{https://github.com/Jason-Qiu/EEG_Language_Alignment}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Han_W/0/1/0/all/0/1\">William Han</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Qiu_J/0/1/0/all/0/1\">Jielin Qiu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhu_J/0/1/0/all/0/1\">Jiacheng Zhu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Xu_M/0/1/0/all/0/1\">Mengdi Xu</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Weber_D/0/1/0/all/0/1\">Douglas Weber</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/q-bio/1/au:+Zhao_D/0/1/0/all/0/1\">Ding Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reinforcement Learning and Bandits for Speech and Language Processing: Tutorial, Review and Outlook. (arXiv:2210.13623v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2210.13623","description":"<p>In recent years, reinforcement learning and bandits have transformed a wide\nrange of real-world applications including healthcare, finance, recommendation\nsystems, robotics, and last but not least, the speech and natural language\nprocessing. While most speech and language applications of reinforcement\nlearning algorithms are centered around improving the training of deep neural\nnetworks with its flexible optimization properties, there are still many\ngrounds to explore to utilize the benefits of reinforcement learning, such as\nits reward-driven adaptability, state representations, temporal structures and\ngeneralizability. In this survey, we present an overview of recent advancements\nof reinforcement learning and bandits, and discuss how they can be effectively\nemployed to solve speech and natural language processing problems with models\nthat are adaptive, interactive and scalable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Baihan Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploiting Contrastive Learning and Numerical Evidence for Improving Confusing Legal Judgment Prediction. (arXiv:2211.08238v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08238","description":"<p>Given the fact description text of a legal case, legal judgment prediction\n(LJP) aims to predict the case's charge, law article and penalty term. A core\nproblem of LJP is how to distinguish confusing legal cases, where only subtle\ntext differences exist. Previous studies fail to distinguish different\nclassification errors with a standard cross-entropy classification loss, and\nignore the numbers in the fact description for predicting the term of penalty.\nTo tackle these issues, in this work, first, we propose a moco-based supervised\ncontrastive learning to learn distinguishable representations, and explore the\nbest strategy to construct positive example pairs to benefit all three subtasks\nof LJP simultaneously. Second, in order to exploit the numbers in legal cases\nfor predicting the penalty terms of certain cases, we further enhance the\nrepresentation of the fact description with extracted crime amounts which are\nencoded by a pre-trained numeracy model. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results,\nespecially on confusing legal cases. Ablation studies also demonstrate the\neffectiveness of each component.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1\">Leilei Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baokui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1\">Kun Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yating Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Better Reasoners with Self-Verification. (arXiv:2212.09561v5 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2212.09561","description":"<p>Recently, with the chain of thought (CoT) prompting, large language models\n(LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural\nlanguage processing tasks such as arithmetic, commonsense, and logical\nreasoning. However, LLMs with CoT require multi-step prompting and multi-token\nprediction, which is highly sensitive to individual mistakes and vulnerable to\nerror accumulation. The above issues make the LLMs need the ability to verify\nthe answers. In fact, after inferring conclusions in some thinking decision\ntasks, people often check them by re-verifying steps to avoid some mistakes. In\nthis paper, we propose and prove that LLMs also have similar self-verification\nabilities. We take the conclusion obtained by CoT as one of the conditions for\nsolving the original problem. By performing a backward verification of the\nanswers that LLM deduced for itself, we can obtain interpretable answer\nvalidation scores to select the candidate answer with the highest score.\nExperimental results demonstrate that the proposed method can improve the\nreasoning performance on various arithmetic, commonsense, and logical reasoning\ndatasets. Our code is publicly available at:\nhttps://github.com/WENGSYX/Self-Verification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weng_Y/0/1/0/all/0/1\">Yixuan Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minjun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shizhu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1\">Bin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Retrieve-and-Read Framework for Knowledge Graph Link Prediction. (arXiv:2212.09724v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09724","description":"<p>Knowledge graph (KG) link prediction aims to infer new facts based on\nexisting facts in the KG. Recent studies have shown that using the graph\nneighborhood of a node via graph neural networks (GNNs) provides more useful\ninformation compared to just using the query information. Conventional GNNs for\nKG link prediction follow the standard message-passing paradigm on the entire\nKG, which leads to superfluous computation, over-smoothing of node\nrepresentations, and also limits their expressive power. On a large scale, it\nbecomes computationally expensive to aggregate useful information from the\nentire KG for inference. To address the limitations of existing KG link\nprediction frameworks, we propose a novel retrieve-and-read framework, which\nfirst retrieves a relevant subgraph context for the query and then jointly\nreasons over the context and the query with a high-capacity reader. As part of\nour exemplar instantiation for the new framework, we propose a novel\nTransformer-based GNN as the reader, which incorporates graph-based attention\nstructure and cross-attention between query and context for deep fusion. This\nsimple yet effective design enables the model to focus on salient context\ninformation relevant to the query. Empirical results on two standard KG link\nprediction datasets demonstrate the competitive performance of the proposed\nmethod. Furthermore, our analysis yields valuable insights for designing\nimproved retrievers within the framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1\">Vardaan Pahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boshi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1\">Hugo Latapie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasa_J/0/1/0/all/0/1\">Jayanth Srinivasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speaking Style Conversion in the Waveform Domain Using Discrete Self-Supervised Units. (arXiv:2212.09730v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2212.09730","description":"<p>We introduce DISSC, a novel, lightweight method that converts the rhythm,\npitch contour and timbre of a recording to a target speaker in a textless\nmanner. Unlike DISSC, most voice conversion (VC) methods focus primarily on\ntimbre, and ignore people's unique speaking style (prosody). The proposed\napproach uses a pretrained, self-supervised model for encoding speech to\ndiscrete units, which makes it simple, effective, and fast to train. All\nconversion modules are only trained on reconstruction like tasks, thus suitable\nfor any-to-many VC with no paired data. We introduce a suite of quantitative\nand qualitative evaluation metrics for this setup, and empirically demonstrate\nthat DISSC significantly outperforms the evaluated baselines. Code and samples\nare available at https://pages.cs.huji.ac.il/adiyoss-lab/dissc/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maimon_G/0/1/0/all/0/1\">Gallil Maimon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can NLI Provide Proper Indirect Supervision for Low-resource Biomedical Relation Extraction?. (arXiv:2212.10784v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10784","description":"<p>Two key obstacles in biomedical relation extraction (RE) are the scarcity of\nannotations and the prevalence of instances without explicitly pre-defined\nlabels due to low annotation coverage. Existing approaches, which treat\nbiomedical RE as a multi-class classification task, often result in poor\ngeneralization in low-resource settings and do not have the ability to make\nselective prediction on unknown cases but give a guess from seen relations,\nhindering the applicability of those approaches. We present NBR, which converts\nbiomedical RE as natural language inference formulation through indirect\nsupervision. By converting relations to natural language hypotheses, NBR is\ncapable of exploiting semantic cues to alleviate annotation scarcity. By\nincorporating a ranking-based loss that implicitly calibrates abstinent\ninstances, NBR learns a clearer decision boundary and is instructed to abstain\non uncertain instances. Extensive experiments on three widely-used biomedical\nRE benchmarks, namely ChemProt, DDI and GAD, verify the effectiveness of NBR in\nboth full-set and low-resource regimes. Our analysis demonstrates that indirect\nsupervision benefits biomedical RE even when a domain gap exists, and combining\nNLI knowledge with biomedical knowledge leads to the best performance gains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiashu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Mingyu Derek Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IC3: Image Captioning by Committee Consensus. (arXiv:2302.01328v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2302.01328","description":"<p>If you ask a human to describe an image, they might do so in a thousand\ndifferent ways. Traditionally, image captioning models are trained to generate\na single \"best\" (most like a reference) image caption. Unfortunately, doing so\nencourages captions that are \"informationally impoverished,\" and focus on only\na subset of the possible details, while ignoring other potentially useful\ninformation in the scene. In this work, we introduce a simple, yet novel,\nmethod: \"Image Captioning by Committee Consensus\" (IC3), designed to generate a\nsingle caption that captures high-level details from several annotator\nviewpoints. Humans rate captions produced by IC3 at least as helpful as\nbaseline SOTA models more than two thirds of the time, and IC3 can improve the\nperformance of SOTA automated recall systems by up to 84%, outperforming single\nhuman-generated reference captions, and indicating significant improvements\nover SOTA approaches for visual description. Code is available at\nhttps://davidmchan.github.io/caption-by-committee/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_D/0/1/0/all/0/1\">David M. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1\">Austin Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijayanarasimhan_S/0/1/0/all/0/1\">Sudheendra Vijayanarasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1\">David A. Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1\">John Canny</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods. (arXiv:2302.06132v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06132","description":"<p>Knowledge graph completion (KGC) aims to discover missing relations of query\nentities. Current text-based models utilize the entity name and description to\ninfer the tail entity given the head entity and a certain relation. Existing\napproaches also consider the neighborhood of the head entity. However, these\nmethods tend to model the neighborhood using a flat structure and are only\nrestricted to 1-hop neighbors. In this work, we propose a node\nneighborhood-enhanced framework for knowledge graph completion. It models the\nhead entity neighborhood from multiple hops using graph neural networks to\nenrich the head node information. Moreover, we introduce an additional edge\nlink prediction task to improve KGC. Evaluation on two public datasets shows\nthat this framework is simple yet effective. The case study also shows that the\nmodel is able to predict explainable predictions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Boming Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded Dialogue. (arXiv:2302.06674v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06674","description":"<p>Identifying relevant persona or knowledge for conversational systems is\ncritical to grounded dialogue response generation. However, each grounding has\nbeen mostly researched in isolation with more practical multi-context dialogue\ntasks introduced in recent works. We define Persona and Knowledge Dual Context\nIdentification as the task to identify persona and knowledge jointly for a\ngiven dialogue, which could be of elevated importance in complex multi-context\ndialogue settings. We develop a novel grounding retrieval method that utilizes\nall contexts of dialogue simultaneously. Our method requires less computational\npower via utilizing neural QA retrieval models. We further introduce our novel\nnull-positive rank test which measures ranking performance on semantically\ndissimilar samples (i.e. hard negatives) in relation to data augmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oh_M/0/1/0/all/0/1\">Minsik Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Joosung Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guoyin Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Test-Time Distribution Normalization for Contrastively Learned Vision-language Models. (arXiv:2302.11084v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.11084","description":"<p>Advances in the field of vision-language contrastive learning have made it\npossible for many downstream applications to be carried out efficiently and\naccurately by simply taking the dot product between image and text\nrepresentations. One of the most representative approaches proposed recently\nknown as CLIP has garnered widespread adoption due to its effectiveness. CLIP\nis trained with an InfoNCE loss that takes into account both positive and\nnegative samples to help learn a much more robust representation space. This\npaper reveals that the common downstream practice of taking a dot product is\nonly a zeroth-order approximation of the optimization goal, resulting in a loss\nof information during test-time. Intuitively, since the model has been\noptimized based on the InfoNCE loss, test-time procedures should also be in\nalignment. The question lies in how one can retrieve any semblance of negative\nsamples information during inference in a computationally efficient way. To\nthis end, we propose Distribution Normalization (DN), where we approximate the\nmean representation of a batch of test samples and use such a mean to represent\nwhat would be analogous to negative samples in the InfoNCE loss. DN requires no\nretraining or fine-tuning and can be effortlessly applied during inference.\nExtensive experiments on a wide variety of downstream tasks exhibit a clear\nadvantage of DN over the dot product on top of other existing test-time\naugmentation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yifei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1\">Juntao Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1\">Fengyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zabih_R/0/1/0/all/0/1\">Ramin Zabih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1\">Ser-Nam Lim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MWE as WSD: Solving Multiword Expression Identification with Word Sense Disambiguation. (arXiv:2303.06623v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.06623","description":"<p>Recent approaches to word sense disambiguation (WSD) utilize encodings of the\nsense gloss (definition), in addition to the input context, to improve\nperformance. In this work we demonstrate that this approach can be adapted for\nuse in multiword expression (MWE) identification by training models which use\ngloss and context information to filter MWE candidates produced by a rule-based\nextraction pipeline. Our approach substantially improves precision,\noutperforming the state-of-the-art in MWE identification on the DiMSUM dataset\nby up to 1.9 F1 points and achieving competitive results on the PARSEME 1.1\nEnglish dataset. Our models also retain most of their WSD performance, showing\nthat a single model can be used for both tasks. Finally, building on similar\napproaches using Bi-encoders for WSD, we introduce a novel Poly-encoder\narchitecture which improves MWE identification performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tanner_J/0/1/0/all/0/1\">Joshua Tanner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1\">Jacob Hoffman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shall We Pretrain Autoregressive Language Models with Retrieval? A Comprehensive Study. (arXiv:2304.06762v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.06762","description":"<p>Large decoder-only language models (LMs) can be largely improved in terms of\nperplexity by retrieval (e.g., RETRO), but its impact on text generation\nquality and downstream task accuracy is unclear. Thus, it is still an open\nquestion: shall we pretrain large autoregressive LMs with retrieval? To answer\nit, we perform a comprehensive study on a scalable pre-trained\nretrieval-augmented LM (i.e., RETRO) compared with standard GPT and\nretrieval-augmented GPT incorporated at fine-tuning or inference stages. We\nfirst provide the recipe to reproduce RETRO up to 9.5B parameters while\nretrieving a text corpus with 330B tokens. Based on that, we have the following\nnovel findings: i) RETRO outperforms GPT on text generation with much less\ndegeneration (i.e., repetition), moderately higher factual accuracy, and\nslightly lower toxicity with a nontoxic retrieval database. ii) On the LM\nEvaluation Harness benchmark, RETRO largely outperforms GPT on\nknowledge-intensive tasks, but is on par with GPT on other tasks. Furthermore,\nwe introduce a simple variant of the model, RETRO++, which largely improves\nopen-domain QA results of original RETRO (e.g., EM score +8.6 on Natural\nQuestion) and significantly outperforms retrieval-augmented GPT in both\nfine-tuning and zero-shot evaluation settings. Our findings highlight the\npromising direction of pretraining autoregressive LMs with retrieval as future\nfoundation models. We release our implementation at:\nhttps://github.com/NVIDIA/Megatron-LM#retro.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boxin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAfee_L/0/1/0/all/0/1\">Lawrence McAfee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yi Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1\">Oleksii Kuchaiev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PEFT-Ref: A Modular Reference Architecture and Typology for Parameter-Efficient Finetuning Techniques. (arXiv:2304.12410v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.12410","description":"<p>Recent parameter-efficient finetuning (PEFT) techniques aim to improve over\nthe considerable cost of fully finetuning large pretrained language models\n(PLM). As different PEFT techniques proliferate, it is becoming difficult to\ncompare them, in particular in terms of (i) the structure and functionality\nthey add to the PLM, (ii) the different types and degrees of efficiency\nimprovements achieved, (iii) performance at different downstream tasks, and\n(iv) how differences in structure and functionality relate to efficiency and\ntask performance. To facilitate such comparisons, this paper presents a\nreference architecture which standardises aspects shared by different PEFT\ntechniques, while isolating differences to specific locations and interactions\nwith the standard components. Through this process of standardising and\nisolating differences, a modular view of PEFT techniques emerges, supporting\nnot only direct comparison of different techniques and their efficiency and\ntask performance, but also systematic exploration of reusability and\ncomposability of the different types of finetuned modules. We demonstrate how\nthe reference architecture can be applied to understand properties and relative\nadvantages of PEFT techniques, hence to inform selection of techniques for\nspecific tasks, and design choices for new PEFT techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sabry_M/0/1/0/all/0/1\">Mohammed Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belz_A/0/1/0/all/0/1\">Anya Belz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Prompt Optimization with \"Gradient Descent\" and Beam Search. (arXiv:2305.03495v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03495","description":"<p>Large Language Models (LLMs) have shown impressive performance as general\npurpose agents, but their abilities remain highly dependent on prompts which\nare hand written with onerous trial-and-error effort. We propose a simple and\nnonparametric solution to this problem, Automatic Prompt Optimization (APO),\nwhich is inspired by numerical gradient descent to automatically improve\nprompts, assuming access to training data and an LLM API. The algorithm uses\nminibatches of data to form natural language \"gradients\" that criticize the\ncurrent prompt. The gradients are then \"propagated\" into the prompt by editing\nthe prompt in the opposite semantic direction of the gradient. These gradient\ndescent steps are guided by a beam search and bandit selection procedure which\nsignificantly improves algorithmic efficiency. Preliminary results across three\nbenchmark NLP tasks and the novel problem of LLM jailbreak detection suggest\nthat Automatic Prompt Optimization can outperform prior prompt editing\ntechniques and improve an initial prompt's performance by up to 31%, by using\ndata to rewrite vague task descriptions into more precise annotation\ninstructions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pryzant_R/0/1/0/all/0/1\">Reid Pryzant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jerry Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yin Tat Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1\">Michael Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge. (arXiv:2305.08281v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08281","description":"<p>Evaluating the factual consistency of automatically generated summaries is\nessential for the progress and adoption of reliable summarization systems.\nDespite recent advances, existing factuality evaluation models are not robust,\nbeing especially prone to entity and relation errors in new domains. We propose\nFactKB, a simple new approach to factuality evaluation that is generalizable\nacross domains, in particular with respect to entities and relations. FactKB is\nbased on language models pretrained using facts extracted from external\nknowledge bases. We introduce three types of complementary factuality\npretraining objectives based on direct entity facts, facts grounded in\nauxiliary knowledge about entities, and facts constructed compositionally\nthrough knowledge base walks. The resulting factuality evaluation model\nachieves state-of-the-art performance on two in-domain news summarization\nbenchmarks as well as on three out-of-domain scientific literature datasets.\nFurther analysis of FactKB shows improved ability to detect erroneous entities\nand relations in summaries and is robust and generalizable across domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shangbin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1\">Vidhisha Balachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuyang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models. (arXiv:2305.09955v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09955","description":"<p>By design, large language models (LLMs) are static general-purpose models,\nexpensive to retrain or update frequently. As they are increasingly adopted for\nknowledge-intensive tasks, it becomes evident that these design choices lead to\nfailures to generate factual, relevant, and up-to-date knowledge. To this end,\nwe propose \\ourmethod{}, a modular framework to plug in new factual and\nrelevant knowledge into general-purpose LLMs. We first introduce\n\\emph{knowledge cards} -- specialized language models trained on corpora from\nspecific domains and sources. Knowledge cards serve as parametric repositories\nthat are selected at inference time to generate background knowledge for the\nbase LLM. We then propose three content selectors to dynamically select and\nretain information in documents generated by knowledge cards, specifically\ncontrolling for \\emph{relevance}, \\emph{brevity}, and \\emph{factuality} of\noutputs. Finally, we propose two complementary integration approaches to\naugment the base LLM with the (relevant, factual) knowledge curated from the\nspecialized LMs. Through extensive experiments, we demonstrate that\n\\ourmethod{} achieves state-of-the-art performance on six benchmark datasets.\nUltimately, \\ourmethod{} framework enables dynamic synthesis and updates of\nknowledge from diverse domains. Its modularity will ensure that relevant\nknowledge can be continuously updated through the collective efforts of the\nresearch community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shangbin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">Yuyang Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1\">Vidhisha Balachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models. (arXiv:2305.11171v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11171","description":"<p>Factual consistency evaluation is often conducted using Natural Language\nInference (NLI) models, yet these models exhibit limited success in evaluating\nsummaries. Previous work improved such models with synthetic training data.\nHowever, the data is typically based on perturbed human-written summaries,\nwhich often differ in their characteristics from real model-generated summaries\nand have limited coverage of possible factual errors. Alternatively, large\nlanguage models (LLMs) have recently shown promising results in directly\nevaluating generative tasks, but are too computationally expensive for\npractical use. Motivated by these limitations, we introduce TrueTeacher, a\nmethod for generating synthetic data by annotating diverse model-generated\nsummaries using a LLM. Unlike prior work, TrueTeacher does not rely on\nhuman-written summaries, and is multilingual by nature. Experiments on the TRUE\nbenchmark show that a student model trained using our data, substantially\noutperforms both the state-of-the-art model with similar capacity, and the LLM\nteacher. In a systematic study, we compare TrueTeacher to existing synthetic\ndata generation methods and demonstrate its superiority and robustness to\ndomain-shift. We also show that our method generalizes to multilingual\nscenarios. Lastly, we release our large scale synthetic dataset (1.4M\nexamples), generated using TrueTeacher, and a checkpoint trained on this data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gekhman_Z/0/1/0/all/0/1\">Zorik Gekhman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1\">Jonathan Herzig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aharoni_R/0/1/0/all/0/1\">Roee Aharoni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elkind_C/0/1/0/all/0/1\">Chen Elkind</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting with Pseudo-Code Instructions. (arXiv:2305.11790v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11790","description":"<p>Prompting with natural language instructions has recently emerged as a\npopular method of harnessing the capabilities of large language models. Given\nthe inherent ambiguity present in natural language, it is intuitive to consider\nthe possible advantages of prompting with less ambiguous prompt styles, such as\nthe use of pseudo-code.\n</p>\n<p>In this paper we explore if prompting via pseudo-code instructions helps\nimprove the performance of pre-trained language models. We manually create a\ndataset of pseudo-code prompts for 132 different tasks spanning classification,\nQA and generative language tasks, sourced from the Super-NaturalInstructions\ndataset. Using these prompts along with their counterparts in natural language,\nwe study their performance on two LLM families - BLOOM and CodeGen. Our\nexperiments show that using pseudo-code instructions leads to better results,\nwith an average increase (absolute) of 7-16 points in F1 scores for\nclassification tasks and an improvement (relative) of 12-38% in aggregate\nROUGE-L scores across all tasks. We include detailed ablation studies which\nindicate that code comments, docstrings, and the structural clues encoded in\npseudo-code all contribute towards the improvement in performance.\n</p>\n<p>To the best of our knowledge our work is the first to demonstrate how\npseudo-code prompts can be helpful in improving the performance of pre-trained\nLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_M/0/1/0/all/0/1\">Mayank Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1\">Prince Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1\">Riyaz Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+V_R/0/1/0/all/0/1\">Rudra Murthy V</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contractor_D/0/1/0/all/0/1\">Danish Contractor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamilselvam_S/0/1/0/all/0/1\">Srikanth Tamilselvam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning. (arXiv:2305.12295v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12295","description":"<p>Large Language Models (LLMs) have shown human-like reasoning abilities but\nstill struggle with complex logical problems. This paper introduces a novel\nframework, Logic-LM, which integrates LLMs with symbolic solvers to improve\nlogical problem-solving. Our method first utilizes LLMs to translate a natural\nlanguage problem into a symbolic formulation. Afterward, a deterministic\nsymbolic solver performs inference on the formulated problem. We also introduce\na self-refinement module, which utilizes the symbolic solver's error messages\nto revise symbolic formalizations. We demonstrate Logic-LM's effectiveness on\nfive logical reasoning datasets: ProofWriter, PrOntoQA, FOLIO,\nLogicalDeduction, and AR-LSAT. On average, Logic-LM achieves a significant\nperformance boost of 39.2% over using LLM alone with standard prompting and\n18.4% over LLM with chain-of-thought prompting. Our findings suggest that\nLogic-LM, by combining LLMs with symbolic logic, offers a promising avenue for\nfaithful logical reasoning. Code and data are publicly available at\nhttps://github.com/teacherpeterpan/Logic-LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albalak_A/0/1/0/all/0/1\">Alon Albalak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training. (arXiv:2305.12634v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12634","description":"<p>In this work we propose a pragmatic method that reduces the annotation cost\nfor structured label spaces using active learning. Our approach leverages\npartial annotation, which reduces labeling costs for structured outputs by\nselecting only the most informative sub-structures for annotation. We also\nutilize self-training to incorporate the current model's automatic predictions\nas pseudo-labels for un-annotated sub-structures. A key challenge in\neffectively combining partial annotation with self-training to reduce\nannotation cost is determining which sub-structures to select to label. To\naddress this challenge, we adopt an error estimator to adaptively decide the\npartial selection ratio according to the current model's capability. In\nevaluations spanning four structured prediction tasks, we show that our\ncombination of partial annotation and self-training using an adaptive selection\nratio reduces annotation cost over strong full annotation baselines under a\nfair comparison scheme that takes reading time into consideration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhisong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Strubell_E/0/1/0/all/0/1\">Emma Strubell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Crosslingual Transfer Learning for Low-Resource Languages Based on Multilingual Colexification Graphs. (arXiv:2305.12818v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12818","description":"<p>In comparative linguistics, colexification refers to the phenomenon of a\nlexical form conveying two or more distinct meanings. Existing work on\ncolexification patterns relies on annotated word lists, limiting scalability\nand usefulness in NLP. In contrast, we identify colexification patterns of more\nthan 2,000 concepts across 1,335 languages directly from an unannotated\nparallel corpus. We then propose simple and effective methods to build\nmultilingual graphs from the colexification patterns: ColexNet and ColexNet+.\nColexNet's nodes are concepts and its edges are colexifications. In ColexNet+,\nconcept nodes are additionally linked through intermediate nodes, each\nrepresenting an ngram in one of 1,334 languages. We use ColexNet+ to train\n$\\overrightarrow{\\mbox{ColexNet+}}$, high-quality multilingual embeddings that\nare well-suited for transfer learning. In our experiments, we first show that\nColexNet achieves high recall on CLICS, a dataset of crosslingual\ncolexifications. We then evaluate $\\overrightarrow{\\mbox{ColexNet+}}$ on\nroundtrip translation, sentence retrieval and sentence classification and show\nthat our embeddings surpass several transfer learning baselines. This\ndemonstrates the benefits of using colexification as a source of information in\nmultilingual NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yihong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Haotian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weissweiler_L/0/1/0/all/0/1\">Leonie Weissweiler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pei_R/0/1/0/all/0/1\">Renhao Pei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding. (arXiv:2305.14232v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14232","description":"<p>Scientific literature understanding tasks have gained significant attention\ndue to their potential to accelerate scientific discovery. Pre-trained language\nmodels (LMs) have shown effectiveness in these tasks, especially when tuned via\ncontrastive learning. However, jointly utilizing pre-training data across\nmultiple heterogeneous tasks (e.g., extreme multi-label paper classification,\ncitation prediction, and literature search) remains largely unexplored. To\nbridge this gap, we propose a multi-task contrastive learning framework,\nSciMult, with a focus on facilitating common knowledge sharing across different\nscientific literature understanding tasks while preventing task-specific skills\nfrom interfering with each other. To be specific, we explore two techniques --\ntask-aware specialization and instruction tuning. The former adopts a\nMixture-of-Experts Transformer architecture with task-aware sub-layers; the\nlatter prepends task-specific instructions to the input text so as to produce\ntask-aware outputs. Extensive experiments on a comprehensive collection of\nbenchmark datasets verify the effectiveness of our task-aware specialization\nstrategy, where we outperform state-of-the-art scientific pre-trained LMs.\nCode, datasets, and pre-trained models can be found at\nhttps://scimult.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhihong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye-Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining. (arXiv:2305.14281v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14281","description":"<p>Recent work in vision-and-language pretraining has investigated supervised\nsignals from object detection data to learn better, fine-grained multimodal\nrepresentations. In this work, we take a step further and explore how we can\ntap into supervision from small-scale visual relation data. In particular, we\npropose two pretraining approaches to contextualise visual entities in a\nmultimodal setup. With verbalised scene graphs, we transform visual relation\ntriplets into structured captions, and treat them as additional image\ndescriptions. With masked relation prediction, we further encourage relating\nentities from image regions with visually masked contexts. When applied to\nstrong baselines pretrained on large amounts of Web data, zero-shot evaluations\non both coarse-grained and fine-grained tasks show the efficacy of our methods\nin learning multimodal representations from weakly-supervised relations data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bugliarello_E/0/1/0/all/0/1\">Emanuele Bugliarello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1\">Aida Nematzadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendricks_L/0/1/0/all/0/1\">Lisa Anne Hendricks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language Models. (arXiv:2305.14610v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14610","description":"<p>Do the Spratly Islands belong to China, the Philippines, or Vietnam? A\npretrained large language model (LLM) may answer differently if asked in the\nlanguages of each claimant country: Chinese, Tagalog, or Vietnamese. This\ncontrasts with a multilingual human, who would likely answer consistently. In\nthis work, we show that LLMs recall geopolitical knowledge inconsistently\nacross languages -- a phenomenon we term geopolitical bias. As a targeted case\nstudy, we consider territorial disputes, inherently controversial and\ncross-lingual task.\n</p>\n<p>We first introduce the BorderLines dataset of territorial disputes. This\ncovers 256 territories, each of which is associated to a set of multiple-choice\nquestions in the languages of each claimant country (48 languages total). We\nthen pose these questions to LLMs to probe their internal knowledge. Finally,\nwe propose a suite of evaluation metrics based on accuracy, which compares\nresponses with respect to the actual geopolitical situation, and consistency of\nthe responses in different languages. These metrics allow us to quantify\nseveral findings, which include instruction-tuned LLMs underperforming base\nones, and geopolitical bias being amplified in stronger models. We release our\ncode and dataset to facilitate future investigation and mitigation of\ngeopolitical bias.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bryan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Allies: Prompting Large Language Model with Beam Search. (arXiv:2305.14766v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14766","description":"<p>With the advance of large language models (LLMs), the research field of LLM\napplications becomes more and more popular and the idea of constructing\npipelines to accomplish complex tasks by stacking LLM API calls come true.\nHowever, this kind of methods face two limitations: narrow information coverage\nand low fault tolerance. In this work, we propose a novel method called ALLIES.\nGiven an input query, ALLIES leverages LLMs to iteratively generate new queries\nrelated to the original query, enabling an iterative reasoning process. By\niteratively refining and expanding the scope of the original query, ALLIES\ncaptures and utilizes hidden knowledge that may not be directly obtainable\nthrough retrieval. We take zero-shot open-domain question answering (ODQA) as\nan application scene and evaluate ALLIES on the widely-used benchmarks, such as\nNQ, WebQ and TriviaQA. The experimental results demonstrate that ALLIES\nsignificantly outperforms other zero-shot baselines, indicating its\neffectiveness in tackling those challenges. Our code is available in\nhttps://github.com/microsoft/SimXNS/tree/main/ALLIES.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1\">Daxin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RefGPT: Dialogue Generation of GPT, by GPT, and for GPT. (arXiv:2305.14994v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14994","description":"<p>Large Language Models (LLMs) have attained the impressive capability to\nresolve a wide range of NLP tasks by fine-tuning high-quality instruction data.\nHowever, collecting human-written data of high quality, especially multi-turn\ndialogues, is expensive and unattainable for most people. Though previous\nstudies have used powerful LLMs to generate the dialogues automatically, they\nall suffer from generating untruthful dialogues because of the model\nhallucination. Therefore, we propose a method called RefGPT to generate\nenormous truthful and customized dialogues without worrying about factual\nerrors caused by the model hallucination. RefGPT solves the model hallucination\nin dialogue generation by restricting the LLMs to leverage the given reference\ninstead of reciting their own knowledge to generate dialogues. Additionally,\nRefGPT adds detailed controls on every utterance to enable high customization\ncapability, which previous studies have ignored. On the basis of RefGPT, we\nalso propose two high-quality dialogue datasets generated by GPT-4, namely\nRefGPT-Fact and RefGPT-Code. RefGPT-Fact is a dataset with 100k multi-turn\ndialogues based on factual knowledge and RefGPT-Code has 76k multi-turn\ndialogues covering a wide range of coding scenarios. Our code and datasets are\nreleased in https://github.com/mutonix/RefGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dongjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1\">Ruifeng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yuantao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yifei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zili Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shusen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Efficient Multilingual Language Model Compression through Vocabulary Trimming. (arXiv:2305.15020v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15020","description":"<p>Multilingual language model (LM) have become a powerful tool in NLP\nespecially for non-English languages. Nevertheless, model parameters of\nmultilingual LMs remain large due to the larger embedding matrix of the\nvocabulary covering tokens in different languages. On the contrary, monolingual\nLMs can be trained in a target language with the language-specific vocabulary\nonly, but this requires a large budget and availability of reliable corpora to\nachieve a high-quality LM from scratch. In this paper, we propose\nvocabulary-trimming (VT), a method to reduce a multilingual LM vocabulary to a\ntarget language by deleting irrelevant tokens from its vocabulary. In theory,\nVT can compress any existing multilingual LM to build monolingual LMs in any\nlanguage covered by the multilingual LM. In our experiments, we show that VT\ncan retain the original performance of the multilingual LM, while being smaller\nin size (in general around 50% of the original vocabulary size is enough) than\nthe original multilingual LM. The evaluation is performed over four NLP tasks\n(two generative and two classification tasks) among four widely used\nmultilingual LMs in seven languages. Finally, we show that this methodology can\nkeep the best of both monolingual and multilingual worlds by keeping a small\nsize as monolingual models without the need for specifically retraining them,\nand even limiting potentially harmful social biases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ushio_A/0/1/0/all/0/1\">Asahi Ushio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NavGPT: Explicit Reasoning in Vision-and-Language Navigation with Large Language Models. (arXiv:2305.16986v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.16986","description":"<p>Trained with an unprecedented scale of data, large language models (LLMs)\nlike ChatGPT and GPT-4 exhibit the emergence of significant reasoning abilities\nfrom model scaling. Such a trend underscored the potential of training LLMs\nwith unlimited language data, advancing the development of a universal embodied\nagent. In this work, we introduce the NavGPT, a purely LLM-based\ninstruction-following navigation agent, to reveal the reasoning capability of\nGPT models in complex embodied scenes by performing zero-shot sequential action\nprediction for vision-and-language navigation (VLN). At each step, NavGPT takes\nthe textual descriptions of visual observations, navigation history, and future\nexplorable directions as inputs to reason the agent's current status, and makes\nthe decision to approach the target. Through comprehensive experiments, we\ndemonstrate NavGPT can explicitly perform high-level planning for navigation,\nincluding decomposing instruction into sub-goal, integrating commonsense\nknowledge relevant to navigation task resolution, identifying landmarks from\nobserved scenes, tracking navigation progress, and adapting to exceptions with\nplan adjustment. Furthermore, we show that LLMs is capable of generating\nhigh-quality navigational instructions from observations and actions along a\npath, as well as drawing accurate top-down metric trajectory given the agent's\nnavigation history. Despite the performance of using NavGPT to zero-shot R2R\ntasks still falling short of trained models, we suggest adapting multi-modality\ninputs for LLMs to use as visual navigation agents and applying the explicit\nreasoning of LLMs to benefit learning-based models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_G/0/1/0/all/0/1\">Gengze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">Yicong Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qi Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Red Teaming Language Model Detectors with Language Models. (arXiv:2305.19713v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19713","description":"<p>The prevalence and strong capability of large language models (LLMs) present\nsignificant safety and ethical risks if exploited by malicious users. To\nprevent the potentially deceptive usage of LLMs, recent works have proposed\nalgorithms to detect LLM-generated text and protect LLMs. In this paper, we\ninvestigate the robustness and reliability of these LLM detectors under\nadversarial attacks. We study two types of attack strategies: 1) replacing\ncertain words in an LLM's output with their synonyms given the context; 2)\nautomatically searching for an instructional prompt to alter the writing style\nof the generation. In both strategies, we leverage an auxiliary LLM to generate\nthe word replacements or the instructional prompt. Different from previous\nworks, we consider a challenging setting where the auxiliary LLM can also be\nprotected by a detector. Experiments reveal that our attacks effectively\ncompromise the performance of all detectors in the study with plausible\ngenerations, underscoring the urgent need to improve the robustness of\nLLM-generated text detection systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhouxing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_F/0/1/0/all/0/1\">Fan Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiangning Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1\">Cho-Jui Hsieh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Make Pre-trained Model Reversible: From Parameter to Memory Efficient Fine-Tuning. (arXiv:2306.00477v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00477","description":"<p>Parameter-efficient fine-tuning (PEFT) of pre-trained language models (PLMs)\nhas emerged as a highly successful approach, with training only a small number\nof parameters without sacrificing performance and becoming the de-facto\nlearning paradigm with the increasing size of PLMs. However, existing PEFT\nmethods are not memory-efficient, because they still require caching most of\nthe intermediate activations for the gradient calculation, akin to fine-tuning.\nOne effective way to reduce the activation memory is to apply a reversible\nmodel, so the intermediate activations are not necessary to be cached and can\nbe recomputed. Nevertheless, modifying a PLM to its reversible variant is not\nstraightforward, since the reversible model has a distinct architecture from\nthe currently released PLMs. In this paper, we first investigate what is a key\nfactor for the success of existing PEFT methods, and realize that it's\nessential to preserve the PLM's starting point when initializing a PEFT method.\nWith this finding, we propose memory-efficient fine-tuning (MEFT) that inserts\nadapters into a PLM, preserving the PLM's starting point and making it\nreversible without additional pre-training. We evaluate MEFT on the GLUE\nbenchmark and five question-answering tasks with various backbones, BERT,\nRoBERTa, BART and OPT. MEFT significantly reduces the activation memory up to\n84% of full fine-tuning with a negligible amount of trainable parameters.\nMoreover, MEFT achieves the same score on GLUE and a comparable score on the\nquestion-answering tasks as full fine-tuning. A similar finding is also\nobserved for the image classification task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Shaomu Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WSPAlign: Word Alignment Pre-training via Large-Scale Weakly Supervised Span Prediction. (arXiv:2306.05644v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.05644","description":"<p>Most existing word alignment methods rely on manual alignment datasets or\nparallel corpora, which limits their usefulness. Here, to mitigate the\ndependence on manual data, we broaden the source of supervision by relaxing the\nrequirement for correct, fully-aligned, and parallel sentences. Specifically,\nwe make noisy, partially aligned, and non-parallel paragraphs. We then use such\na large-scale weakly-supervised dataset for word alignment pre-training via\nspan prediction. Extensive experiments with various settings empirically\ndemonstrate that our approach, which is named WSPAlign, is an effective and\nscalable way to pre-train word aligners without manual data. When fine-tuned on\nstandard benchmarks, WSPAlign has set a new state-of-the-art by improving upon\nthe best-supervised baseline by 3.3~6.1 points in F1 and 1.5~6.1 points in AER.\nFurthermore, WSPAlign also achieves competitive performance compared with the\ncorresponding baselines in few-shot, zero-shot and cross-lingual tests, which\ndemonstrates that WSPAlign is potentially more practical for low-resource\nlanguages than existing methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qiyu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagata_M/0/1/0/all/0/1\">Masaaki Nagata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1\">Yoshimasa Tsuruoka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unlocking the Potential of User Feedback: Leveraging Large Language Model as User Simulator to Enhance Dialogue System. (arXiv:2306.09821v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.09821","description":"<p>Dialogue systems and large language models (LLMs) have gained considerable\nattention. However, the direct utilization of LLMs as task-oriented dialogue\n(TOD) models has been found to underperform compared to smaller task-specific\nmodels. Nonetheless, it is crucial to acknowledge the significant potential of\nLLMs and explore improved approaches for leveraging their impressive abilities.\nMotivated by the goal of leveraging LLMs, we propose an alternative approach\ncalled User-Guided Response Optimization (UGRO) to combine it with a smaller\nTOD model. This approach uses LLM as annotation-free user simulator to assess\ndialogue responses, combining them with smaller fine-tuned end-to-end TOD\nmodels. By utilizing the satisfaction feedback generated by LLMs, UGRO further\noptimizes the supervised fine-tuned TOD model. Specifically, the TOD model\ntakes the dialogue history as input and, with the assistance of the user\nsimulator's feedback, generates high-satisfaction responses that meet the\nuser's requirements. Through empirical experiments on two TOD benchmarks, we\nvalidate the effectiveness of our method. The results demonstrate that our\napproach outperforms previous state-of-the-art (SOTA) results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiyuan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yue Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1\">Anh Tuan Luu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Assessment of Divergent Thinking in Chinese Language with TransDis: A Transformer-Based Language Model Approach. (arXiv:2306.14790v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.14790","description":"<p>Language models have been increasingly popular for automatic creativity\nassessment, generating semantic distances to objectively measure the quality of\ncreative ideas. However, there is currently a lack of an automatic assessment\nsystem for evaluating creative ideas in the Chinese language. To address this\ngap, we developed TransDis, a scoring system using transformer-based language\nmodels, capable of providing valid originality (quality) and flexibility\n(variety) scores for Alternative Uses Task (AUT) responses in Chinese. Study 1\ndemonstrated that the latent model-rated originality factor, comprised of three\ntransformer-based models, strongly predicted human originality ratings, and the\nmodel-rated flexibility strongly correlated with human flexibility ratings as\nwell. Criterion validity analyses indicated that model-rated originality and\nflexibility positively correlated to other creativity measures, demonstrating\nsimilar validity to human ratings. Study 2 &amp; 3 showed that TransDis effectively\ndistinguished participants instructed to provide creative vs. common uses\n(Study 2) and participants instructed to generate ideas in a flexible vs.\npersistent way (Study 3). Our findings suggest that TransDis can be a reliable\nand low-cost tool for measuring idea originality and flexibility in Chinese\nlanguage, potentially paving the way for automatic creativity assessment in\nother languages. We offer an open platform to compute originality and\nflexibility for AUT responses in Chinese and over 50 other languages\n(https://osf.io/59jv2/).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tianchen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qifan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhaoyang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yubo Hou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale. (arXiv:2306.15687v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2306.15687","description":"<p>Large-scale generative models such as GPT and DALL-E have revolutionized the\nresearch community. These models not only generate high fidelity outputs, but\nare also generalists which can solve tasks not explicitly taught. In contrast,\nspeech generative models are still primitive in terms of scale and task\ngeneralization. In this paper, we present Voicebox, the most versatile\ntext-guided generative model for speech at scale. Voicebox is a\nnon-autoregressive flow-matching model trained to infill speech, given audio\ncontext and text, trained on over 50K hours of speech that are not filtered or\nenhanced. Similar to GPT, Voicebox can perform many different tasks through\nin-context learning, but is more flexible as it can also condition on future\ncontext. Voicebox can be used for mono or cross-lingual zero-shot\ntext-to-speech synthesis, noise removal, content editing, style conversion, and\ndiverse sample generation. In particular, Voicebox outperforms the\nstate-of-the-art zero-shot TTS model VALL-E on both intelligibility (5.9% vs\n1.9% word error rates) and audio similarity (0.580 vs 0.681) while being up to\n20 times faster. Audio samples can be found in\n\\url{https://voicebox.metademolab.com}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Le_M/0/1/0/all/0/1\">Matthew Le</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Vyas_A/0/1/0/all/0/1\">Apoorv Vyas</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shi_B/0/1/0/all/0/1\">Bowen Shi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Karrer_B/0/1/0/all/0/1\">Brian Karrer</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Sari_L/0/1/0/all/0/1\">Leda Sari</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Moritz_R/0/1/0/all/0/1\">Rashel Moritz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Williamson_M/0/1/0/all/0/1\">Mary Williamson</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Manohar_V/0/1/0/all/0/1\">Vimal Manohar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Adi_Y/0/1/0/all/0/1\">Yossi Adi</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Mahadeokar_J/0/1/0/all/0/1\">Jay Mahadeokar</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A scoping review on multimodal deep learning in biomedical images and texts. (arXiv:2307.07362v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.07362","description":"<p>Computer-assisted diagnostic and prognostic systems of the future should be\ncapable of simultaneously processing multimodal data. Multimodal deep learning\n(MDL), which involves the integration of multiple sources of data, such as\nimages and text, has the potential to revolutionize the analysis and\ninterpretation of biomedical data. However, it only caught researchers'\nattention recently. To this end, there is a critical need to conduct a\nsystematic review on this topic, identify the limitations of current work, and\nexplore future directions. In this scoping review, we aim to provide a\ncomprehensive overview of the current state of the field and identify key\nconcepts, types of studies, and research gaps with a focus on biomedical images\nand texts joint learning, mainly because these two were the most commonly\navailable data types in MDL research. This study reviewed the current uses of\nmultimodal deep learning on five tasks: (1) Report generation, (2) Visual\nquestion answering, (3) Cross-modal retrieval, (4) Computer-aided diagnosis,\nand (5) Semantic segmentation. Our results highlight the diverse applications\nand potential of MDL and suggest directions for future research in the field.\nWe hope our review will facilitate the collaboration of natural language\nprocessing (NLP) and medical imaging communities and support the next\ngeneration of decision-making and computer-assisted diagnostic system\ndevelopment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhaoyi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Mingquan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingqing Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Generalist Foundation Model for Radiology by Leveraging Web-scale 2D&3D Medical Data. (arXiv:2308.02463v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.02463","description":"<p>In this study, we aim to initiate the development of Radiology Foundation\nModel, termed as RadFM.We consider the construction of foundational models from\nthe perspectives of dataset construction, model design, and thorough\nevaluation. Our contribution can be concluded as follows: (i), we construct a\nlarge-scale Medical Multi-modal Dataset, MedMD, which consists of 16M 2D and 3D\nmedical scans with high-quality text descriptions or reports across various\ndata formats, modalities, and tasks, covering over 5000 distinct diseases. To\nthe best of our knowledge, this is the first large-scale, high-quality, medical\nvisual-language dataset, with both 2D and 3D scans; (ii ), we propose an\narchitecture that enables visually conditioned generative pre-training, i.e.,\nallowing for integration of text input with 2D or 3D medical scans, and\ngenerate responses for diverse radiologic tasks. The model was initially\npre-trained on MedMD and subsequently fine-tuned on the domain-specific\ndataset, which is a radiologic cleaned version of MedMD, containing 3M\nradiologic visual-language pairs, termed as RadMD; (iii), we propose a new\nevaluation benchmark, RadBench, that comprises five tasks, including modality\nrecognition, disease diagnosis, visual question answering, report generation\nand rationale diagnosis, aiming to comprehensively assess the capability of\nfoundation models in handling practical clinical problems. We conduct both\nautomatic and human evaluation on RadBench, in both cases, RadFM significantly\noutperforms existing multi-modal foundation models. The codes, data, and model\ncheckpoint will all be made publicly available to promote further research and\ndevelopment in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chaoyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoman Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weidi Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Transformer's Ability to Learn Mildly Context-Sensitive Languages. (arXiv:2309.00857v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.00857","description":"<p>Despite the fact that Transformers perform well in NLP tasks, recent studies\nsuggest that self-attention is theoretically limited in learning even some\nregular and context-free languages. These findings motivated us to think about\ntheir implications in modeling natural language, which is hypothesized to be\nmildly context-sensitive. We test the Transformer's ability to learn mildly\ncontext-sensitive languages of varying complexities, and find that they\ngeneralize well to unseen in-distribution data, but their ability to\nextrapolate to longer strings is worse than that of LSTMs. Our analyses show\nthat the learned self-attention patterns and representations modeled dependency\nrelations and demonstrated counting behavior, which may have helped the models\nsolve the languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shunjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinert_Threlkeld_S/0/1/0/all/0/1\">Shane Steinert-Threlkeld</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CONFLATOR: Incorporating Switching Point based Rotatory Positional Encodings for Code-Mixed Language Modeling. (arXiv:2309.05270v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05270","description":"<p>The mixing of two or more languages is called Code-Mixing (CM). CM is a\nsocial norm in multilingual societies. Neural Language Models (NLMs) like\ntransformers have been effective on many NLP tasks. However, NLM for CM is an\nunder-explored area. Though transformers are capable and powerful, they cannot\nalways encode positional information since they are non-recurrent. Therefore,\nto enrich word information and incorporate positional information, positional\nencoding is defined. We hypothesize that Switching Points (SPs), i.e.,\njunctions in the text where the language switches (L1 -&gt; L2 or L2 -&gt; L1), pose\na challenge for CM Language Models (LMs), and hence give special emphasis to\nSPs in the modeling process. We experiment with several positional encoding\nmechanisms and show that rotatory positional encodings along with switching\npoint information yield the best results.\n</p>\n<p>We introduce CONFLATOR: a neural language modeling approach for code-mixed\nlanguages. CONFLATOR tries to learn to emphasize switching points using smarter\npositional encoding, both at unigram and bigram levels. CONFLATOR outperforms\nthe state-of-the-art on two tasks based on code-mixed Hindi and English\n(Hinglish): (i) sentiment analysis and (ii) machine translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Mohsin Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teja_K/0/1/0/all/0/1\">Kandukuri Sai Teja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1\">Neeharika Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patwa_P/0/1/0/all/0/1\">Parth Patwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_A/0/1/0/all/0/1\">Anubhab Chatterjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_V/0/1/0/all/0/1\">Vinija Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Self-Reinforcement for Improving Learnersourced Multiple-Choice Question Explanations with Large Language Models. (arXiv:2309.10444v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.10444","description":"<p>Learnersourcing involves students generating and sharing learning resources\nwith their peers. When learnersourcing multiple-choice questions, creating\nexplanations for the generated questions is a crucial step as it facilitates a\ndeeper understanding of the related concepts. However, it is often difficult\nfor students to craft effective explanations due to limited subject\nunderstanding and a tendency to merely restate the question stem, distractors,\nand correct answer. To help scaffold this task, in this work we propose a\nself-reinforcement large-language-model framework, with the goal of generating\nand evaluating explanations automatically. Comprising three modules, the\nframework generates student-aligned explanations, evaluates these explanations\nto ensure their quality and iteratively enhances the explanations. If an\nexplanation's evaluation score falls below a defined threshold, the framework\niteratively refines and reassesses the explanation. Importantly, our framework\nemulates the manner in which students compose explanations at the relevant\ngrade level. For evaluation, we had a human subject-matter expert compare the\nexplanations generated by students with the explanations created by the\nopen-source large language model Vicuna-13B, a version of Vicuna-13B that had\nbeen fine-tuned using our method, and by GPT-4. We observed that, when compared\nto other large language models, GPT-4 exhibited a higher level of creativity in\ngenerating explanations. We also found that explanations generated by GPT-4\nwere ranked higher by the human expert than both those created by the other\nmodels and the original student-created explanations. Our findings represent a\nsignificant advancement in enriching the learnersourcing experience for\nstudents and enhancing the capabilities of large language models in educational\napplications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leinonen_J/0/1/0/all/0/1\">Juho Leinonen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1\">Alex Yuxuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pistotti_T/0/1/0/all/0/1\">Tim Pistotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1\">Alice Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denny_P/0/1/0/all/0/1\">Paul Denny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiamou Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AnglE-optimized Text Embeddings. (arXiv:2309.12871v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12871","description":"<p>High-quality text embedding is pivotal in improving semantic textual\nsimilarity (STS) tasks, which are crucial components in Large Language Model\n(LLM) applications. However, a common challenge existing text embedding models\nface is the problem of vanishing gradients, primarily due to their reliance on\nthe cosine function in the optimization objective, which has saturation zones.\nTo address this issue, this paper proposes a novel angle-optimized text\nembedding model called AnglE. The core idea of AnglE is to introduce angle\noptimization in a complex space. This novel approach effectively mitigates the\nadverse effects of the saturation zone in the cosine function, which can impede\ngradient and hinder optimization processes. To set up a comprehensive STS\nevaluation, we experimented on existing short-text STS datasets and a newly\ncollected long-text STS dataset from GitHub Issues. Furthermore, we examine\ndomain-specific STS scenarios with limited labeled data and explore how AnglE\nworks with LLM-annotated data. Extensive experiments were conducted on various\ntasks including short-text STS, long-text STS, and domain-specific STS tasks.\nThe results show that AnglE outperforms the state-of-the-art (SOTA) STS models\nthat ignore the cosine saturation zone. These findings demonstrate the ability\nof AnglE to generate high-quality text embeddings and the usefulness of angle\noptimization in STS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xianming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLPBench: Evaluating Large Language Models on Solving NLP Problems. (arXiv:2309.15630v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.15630","description":"<p>Recent developments in large language models (LLMs) have shown promise in\nenhancing the capabilities of natural language processing (NLP). Despite these\nsuccesses, there remains a dearth of research dedicated to the NLP\nproblem-solving abilities of LLMs. To fill the gap in this area, we present a\nunique benchmarking dataset, NLPBench, comprising 378 college-level NLP\nquestions spanning various NLP topics sourced from Yale University's prior\nfinal exams. NLPBench includes questions with context, in which multiple\nsub-questions share the same public information, and diverse question types,\nincluding multiple choice, short answer, and math. Our evaluation, centered on\nLLMs such as GPT-3.5/4, PaLM-2, and LLAMA-2, incorporates advanced prompting\nstrategies like the chain-of-thought (CoT) and tree-of-thought (ToT). Our study\nreveals that the effectiveness of the advanced prompting strategies can be\ninconsistent, occasionally damaging LLM performance, especially in smaller\nmodels like the LLAMA-2 (13b). Furthermore, our manual assessment illuminated\nspecific shortcomings in LLMs' scientific problem-solving skills, with\nweaknesses in logical decomposition and reasoning notably affecting results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linxin Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Lechao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Pengyuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Value Understanding in Language Models through Discriminator-Critique Gap. (arXiv:2310.00378v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00378","description":"<p>Recent advancements in Large Language Models (LLMs) have heightened concerns\nabout their potential misalignment with human values. However, evaluating their\ngrasp of these values is complex due to their intricate and adaptable nature.\nWe argue that truly understanding values in LLMs requires considering both\n\"know what\" and \"know why\". To this end, we present the Value Understanding\nMeasurement (VUM) framework that quantitatively assesses both \"know what\" and\n\"know why\" by measuring the discriminator-critique gap related to human values.\nUsing the Schwartz Value Survey, we specify our evaluation values and develop a\nthousand-level dialogue dataset with GPT-4. Our assessment looks at both the\nvalue alignment of LLM's outputs compared to baseline answers and how LLM\nresponses align with reasons for value recognition versus GPT-4's annotations.\nWe evaluate five representative LLMs and provide strong evidence that the\nscaling law significantly impacts \"know what\" but not much on \"know why\", which\nhas consistently maintained a high level. This may further suggest that LLMs\nmight craft plausible explanations based on the provided context without truly\nunderstanding their inherent value, indicating potential risks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaowei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_F/0/1/0/all/0/1\">Fengshuo Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yaodong Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta Semantic Template for Evaluation of Large Language Models. (arXiv:2310.01448v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01448","description":"<p>Do large language models (LLMs) genuinely understand the semantics of the\nlanguage, or just memorize the training data? The recent concern on potential\ndata contamination of LLMs has raised awareness of the community to conduct\nresearch on LLMs evaluation. In this paper, we propose MSTemp, an approach that\ncreates meta semantic templates to evaluate the semantic understanding ability\nof LLMs. The core of MSTemp is not to perform evaluation directly on existing\nbenchmark datasets, but to generate new out-of-distribution (OOD) evaluation\nsets using existing datasets as seeds. Specifically, for a given sentence,\nMSTemp leverages another language model to generate new samples while\npreserving its semantics. The new samples are called semantic templates to the\noriginal sentence. Then, MSTemp generates evaluation samples via sentence\nparsing and random word replacement on the semantic templates. MSTemp is highly\nflexible, dynamic, and cost-effective. Our initial experiments show that\nMSTemp-generated samples can significantly reduce the performance of LLMs using\nexisting datasets as seeds. We hope this initial work can shed light on future\nresearch of LLMs evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yachuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Liang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1\">Qiaozhu Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02031","description":"<p>Ocean science, which delves into the oceans that are reservoirs of life and\nbiodiversity, is of great significance given that oceans cover over 70% of our\nplanet's surface. Recently, advances in Large Language Models (LLMs) have\ntransformed the paradigm in science. Despite the success in other domains,\ncurrent LLMs often fall short in catering to the needs of domain experts like\noceanographers, and the potential of LLMs for ocean science is under-explored.\nThe intrinsic reason may be the immense and intricate nature of ocean data as\nwell as the necessity for higher granularity and richness in knowledge. To\nalleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean\ndomain, which is expert in various ocean science tasks. We propose DoInstruct,\na novel framework to automatically obtain a large volume of ocean domain\ninstruction data, which generates instructions based on multi-agent\ncollaboration. Additionally, we construct the first oceanography benchmark,\nOceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though\ncomprehensive experiments, OceanGPT not only shows a higher level of knowledge\nexpertise for oceans science tasks but also gains preliminary embodied\nintelligence capabilities in ocean technology. Codes, data and checkpoints will\nsoon be available at https://github.com/zjunlp/KnowLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1\">Zhen Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1\">Yida Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_D/0/1/0/all/0/1\">Daxiong Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning. (arXiv:2310.02954v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02954","description":"<p>Recent advances in natural language processing, primarily propelled by Large\nLanguage Models (LLMs), have showcased their remarkable capabilities grounded\nin in-context learning. A promising avenue for guiding LLMs in intricate\nreasoning tasks involves the utilization of intermediate reasoning steps within\nthe Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies\nin the effective selection of exemplars for facilitating in-context learning.\nIn this study, we introduce a framework that leverages Dual Queries and\nLow-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars\nfor in-context learning. Dual Queries first query LLM to obtain LLM-generated\nknowledge such as CoT, then query the retriever to obtain the final exemplars\nvia both question and the knowledge. Moreover, for the second query, LoRe\nemploys dimensionality reduction techniques to refine exemplar selection,\nensuring close alignment with the input question's knowledge. Through extensive\nexperiments, we demonstrate that DQ-LoRe significantly outperforms prior\nstate-of-the-art methods in the automatic selection of exemplars for GPT-4,\nenhancing performance from 92.5% to 94.2%. Our comprehensive analysis further\nreveals that DQ-LoRe consistently outperforms retrieval-based approaches in\nterms of both performance and adaptability, especially in scenarios\ncharacterized by distribution shifts. DQ-LoRe pushes the boundaries of\nin-context learning and opens up new avenues for addressing complex reasoning\nchallenges. We will release the code soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chuanyang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yichun Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhicheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingxing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiongwei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jing Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot Performance via Probability Calibration. (arXiv:2310.05069v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05069","description":"<p>Pretrained multilingual encoder models can directly perform zero-shot\nmultilingual tasks or linguistic probing by reformulating the input examples\ninto cloze-style prompts. This is accomplished by predicting the probabilities\nof the label words at the masked token position, without requiring any updates\nto the model parameters. However, the performance of this method is limited by\nthe model's bias toward predicting label words which frequently occurred during\nthe pretraining. These words typically receive high probabilities. To address\nthis issue, we combine the models with calibration techniques which modify the\nprobabilities of label words predicted by the models. We first validate the\neffectiveness of a proposed simple calibration method together with other\nexisting techniques on monolingual encoders in both zero- and few-shot\nscenarios. We subsequently employ these calibration techniques on multilingual\nencoders, resulting in substantial performance improvements across a wide range\nof tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nie_E/0/1/0/all/0/1\">Ercong Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmid_H/0/1/0/all/0/1\">Helmut Schmid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recurrent Neural Language Models as Probabilistic Finite-state Automata. (arXiv:2310.05161v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05161","description":"<p>Studying language models (LMs) in terms of well-understood formalisms allows\nus to precisely characterize their abilities and limitations. Previous work has\ninvestigated the representational capacity of recurrent neural network (RNN)\nLMs in terms of their capacity to recognize unweighted formal languages.\nHowever, LMs do not describe unweighted formal languages -- rather, they define\nprobability distributions over strings. In this work, we study what classes of\nsuch probability distributions RNN LMs can represent, which allows us to make\nmore direct statements about their capabilities. We show that simple RNNs are\nequivalent to a subclass of probabilistic finite-state automata, and can thus\nmodel a strict subset of probability distributions expressible by finite-state\nmodels. Furthermore, we study the space complexity of representing finite-state\nLMs with RNNs. We show that, to represent an arbitrary deterministic\nfinite-state LM with $N$ states over an alphabet $\\Sigma$, an RNN requires\n$\\Omega\\left(N |\\Sigma|\\right)$ neurons. These results present a first step\ntowards characterizing the classes of distributions RNN LMs can represent and\nthus help us understand their capabilities and limitations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Svete_A/0/1/0/all/0/1\">Anej Svete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning from Human Feedback. (arXiv:2310.05199v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05199","description":"<p>Reinforcement learning from human feedback serves as a crucial bridge,\naligning large language models with human and societal values. This alignment\nrequires a vast corpus of human feedback to learn a reward model, which is\nsubsequently used to finetune language models. However, we have identified that\nthe reward model often finds shortcuts to bypass its intended objectives,\nmisleadingly assuming that humans prefer longer responses. The emergence of\nlength bias often induces the model to favor longer outputs, yet it doesn't\nequate to an increase in helpful information within these outputs. In this\npaper, we propose an innovative solution, applying the Product-of-Experts (PoE)\ntechnique to separate reward modeling from the influence of sequence length. In\nour framework, the main expert concentrates on understanding human intents,\nwhile the biased expert targets the identification and capture of length bias.\nTo further enhance the learning of bias, we introduce perturbations into the\nbias-focused expert, disrupting the flow of semantic information. Experimental\nresults validate the effectiveness of our approach, indicating that language\nmodel performance is improved, irrespective of sequence length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1\">Wenyu Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance. (arXiv:2310.05991v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05991","description":"<p>Document-level event argument extraction poses new challenges of long input\nand cross-sentence inference compared to its sentence-level counterpart.\nHowever, most prior works focus on capturing the relations between candidate\narguments and the event trigger in each event, ignoring two crucial points: a)\nnon-argument contextual clue information; b) the relevance among argument\nroles. In this paper, we propose a SCPRG (Span-trigger-based Contextual Pooling\nand latent Role Guidance) model, which contains two novel and effective modules\nfor the above problem. The Span-Trigger-based Contextual Pooling(STCP)\nadaptively selects and aggregates the information of non-argument clue words\nbased on the context attention weights of specific argument-trigger pairs from\npre-trained model. The Role-based Latent Information Guidance (RLIG) module\nconstructs latent role representations, makes them interact through\nrole-interactive encoding to capture semantic relevance, and merges them into\ncandidate arguments. Both STCP and RLIG introduce no more than 1% new\nparameters compared with the base model and can be easily applied to other\nevent extraction models, which are compact and transplantable. Experiments on\ntwo public datasets show that our SCPRG outperforms previous state-of-the-art\nmethods, with 1.13 F1 and 2.64 F1 improvements on RAMS and WikiEvents\nrespectively. Further analyses illustrate the interpretability of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanlong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shaohuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Dingyi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Hong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CAW-coref: Conjunction-Aware Word-level Coreference Resolution. (arXiv:2310.06165v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06165","description":"<p>State-of-the-art coreference resolutions systems depend on multiple LLM calls\nper document and are thus prohibitively expensive for many use cases (e.g.,\ninformation extraction with large corpora). The leading word-level coreference\nsystem (WL-coref) attains 96.6% of these SOTA systems' performance while being\nmuch more efficient. In this work, we identify a routine yet important failure\ncase of WL-coref: dealing with conjoined mentions such as 'Tom and Mary'. We\noffer a simple yet effective solution that improves the performance on the\nOntoNotes test set by 0.9% F1, shrinking the gap between efficient word-level\ncoreference resolution and expensive SOTA approaches by 34.6%. Our\nConjunction-Aware Word-level coreference model (CAW-coref) and code is\navailable at https://github.com/KarelDO/wl-coref.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DOosterlinck_K/0/1/0/all/0/1\">Karel D&#x27;Oosterlinck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitew_S/0/1/0/all/0/1\">Semere Kiros Bitew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papineau_B/0/1/0/all/0/1\">Brandon Papineau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jaeger: A Concatenation-Based Multi-Transformer VQA Model. (arXiv:2310.07091v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07091","description":"<p>Document-based Visual Question Answering poses a challenging task between\nlinguistic sense disambiguation and fine-grained multimodal retrieval. Although\nthere has been encouraging progress in document-based question answering due to\nthe utilization of large language and open-world prior models\\cite{1}, several\nchallenges persist, including prolonged response times, extended inference\ndurations, and imprecision in matching. In order to overcome these challenges,\nwe propose Jaegar, a concatenation-based multi-transformer VQA model. To derive\nquestion features, we leverage the exceptional capabilities of RoBERTa\nlarge\\cite{2} and GPT2-xl\\cite{3} as feature extractors. Subsequently, we\nsubject the outputs from both models to a concatenation process. This operation\nallows the model to consider information from diverse sources concurrently,\nstrengthening its representational capability. By leveraging pre-trained models\nfor feature extraction, our approach has the potential to amplify the\nperformance of these models through concatenation. After concatenation, we\napply dimensionality reduction to the output features, reducing the model's\ncomputational effectiveness and inference time. Empirical results demonstrate\nthat our proposed model achieves competitive performance on Task C of the\nPDF-VQA Dataset. If the user adds any new data, they should make sure to style\nit as per the instructions provided in previous sections.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1\">Jieting Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zewei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1\">Penghao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1\">Yidong Gan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KwaiYiiMath: Technical Report. (arXiv:2310.07488v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07488","description":"<p>Recent advancements in large language models (LLMs) have demonstrated\nremarkable abilities in handling a variety of natural language processing (NLP)\ndownstream tasks, even on mathematical tasks requiring multi-step reasoning. In\nthis report, we introduce the KwaiYiiMath which enhances the mathematical\nreasoning abilities of KwaiYiiBase1, by applying Supervised Fine-Tuning (SFT)\nand Reinforced Learning from Human Feedback (RLHF), including on both English\nand Chinese mathematical tasks. Meanwhile, we also constructed a small-scale\nChinese primary school mathematics test set (named KMath), consisting of 188\nexamples to evaluate the correctness of the problem-solving process generated\nby the models. Empirical studies demonstrate that KwaiYiiMath can achieve\nstate-of-the-art (SOTA) performance on GSM8k, CMath, and KMath compared with\nthe similar size models, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jiayi Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Lei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1\">Xiaoyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengli Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhengzong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhirui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengnan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xue Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1\">Xucheng Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1\">Yiqiao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Chao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1\">Chengru Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1\">Junchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zijia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fuzheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhongyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Di Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1\">Kun Gai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ClimateNLP: Analyzing Public Sentiment Towards Climate Change Using Natural Language Processing. (arXiv:2310.08099v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08099","description":"<p>Climate change's impact on human health poses unprecedented and diverse\nchallenges. Unless proactive measures based on solid evidence are implemented,\nthese threats will likely escalate and continue to endanger human well-being.\nThe escalating advancements in information and communication technologies have\nfacilitated the widespread availability and utilization of social media\nplatforms. Individuals utilize platforms such as Twitter and Facebook to\nexpress their opinions, thoughts, and critiques on diverse subjects,\nencompassing the pressing issue of climate change. The proliferation of climate\nchange-related content on social media necessitates comprehensive analysis to\nglean meaningful insights. This paper employs natural language processing (NLP)\ntechniques to analyze climate change discourse and quantify the sentiment of\nclimate change-related tweets. We use ClimateBERT, a pretrained model\nfine-tuned specifically for the climate change domain. The objective is to\ndiscern the sentiment individuals express and uncover patterns in public\nopinion concerning climate change. Analyzing tweet sentiments allows a deeper\ncomprehension of public perceptions, concerns, and emotions about this critical\nglobal challenge. The findings from this experiment unearth valuable insights\ninto public sentiment and the entities associated with climate change\ndiscourse. Policymakers, researchers, and organizations can leverage such\nanalyses to understand public perceptions, identify influential actors, and\ndevise informed strategies to address climate change challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1\">Ajay Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anoop_V/0/1/0/all/0/1\">V. S. Anoop</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation. (arXiv:2310.08395v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08395","description":"<p>The task of Question Generation over Knowledge Bases (KBQG) aims to convert a\nlogical form into a natural language question. For the sake of expensive cost\nof large-scale question annotation, the methods of KBQG under low-resource\nscenarios urgently need to be developed. However, current methods heavily rely\non annotated data for fine-tuning, which is not well-suited for few-shot\nquestion generation. The emergence of Large Language Models (LLMs) has shown\ntheir impressive generalization ability in few-shot tasks. Inspired by\nChain-of-Thought (CoT) prompting, which is an in-context learning strategy for\nreasoning, we formulate KBQG task as a reasoning problem, where the generation\nof a complete question is splitted into a series of sub-question generation.\nOur proposed prompting method KQG-CoT first retrieves supportive logical forms\nfrom the unlabeled data pool taking account of the characteristics of the\nlogical form. Then, we write a prompt to explicit the reasoning chain of\ngenerating complicated questions based on the selected demonstrations. To\nfurther ensure prompt quality, we extend KQG-CoT into KQG-CoT+ via sorting the\nlogical forms by their complexity. We conduct extensive experiments over three\npublic KBQG datasets. The results demonstrate that our prompting method\nconsistently outperforms other prompting baselines on the evaluated datasets.\nRemarkably, our KQG-CoT+ method could surpass existing few-shot SoTA results of\nthe PathQuestions dataset by 18.25, 10.72, and 10.18 absolute points on BLEU-4,\nMETEOR, and ROUGE-L, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuanyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_W/0/1/0/all/0/1\">Weining Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yunshi Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through Active Exploration. (arXiv:2310.09168v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09168","description":"<p>Instruction-tuning can be substantially optimized through enhanced diversity,\nresulting in models capable of handling a broader spectrum of tasks. However,\nexisting data employed for such tuning often exhibit an inadequate coverage of\nindividual domains, limiting the scope for nuanced comprehension and\ninteractions within these areas. To address this deficiency, we propose\nExplore-Instruct, a novel approach to enhance the data coverage to be used in\ndomain-specific instruction-tuning through active exploration via Large\nLanguage Models (LLMs). Built upon representative domain use cases,\nExplore-Instruct explores a multitude of variations or possibilities by\nimplementing a search algorithm to obtain diversified and domain-focused\ninstruction-tuning data. Our data-centric analysis validates the effectiveness\nof this proposed approach in improving domain-specific instruction coverage.\nMoreover, our model's performance demonstrates considerable advancements over\nmultiple baselines, including those utilizing domain-specific data enhancement.\nOur findings offer a promising opportunity to improve instruction coverage,\nespecially in domain-specific contexts, thereby advancing the development of\nadaptable language models. Our code, model weights, and data are public at\n\\url{https://github.com/fanqiwan/Explore-Instruct}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xinting Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1\">Tao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ranking LLM-Generated Loop Invariants for Program Verification. (arXiv:2310.09342v2 [cs.PL] UPDATED)","link":"http://arxiv.org/abs/2310.09342","description":"<p>Synthesizing inductive loop invariants is fundamental to automating program\nverification. In this work, we observe that Large Language Models (such as\ngpt-3.5 or gpt-4) are capable of synthesizing loop invariants for a class of\nprograms in a 0-shot setting, yet require several samples to generate the\ncorrect invariants. This can lead to a large number of calls to a program\nverifier to establish an invariant. To address this issue, we propose a {\\it\nre-ranking} approach for the generated results of LLMs. We have designed a\nranker that can distinguish between correct inductive invariants and incorrect\nattempts based on the problem definition. The ranker is optimized as a\ncontrastive ranker. Experimental results demonstrate that this re-ranking\nmechanism significantly improves the ranking of correct invariants among the\ngenerated candidates, leading to a notable reduction in the number of calls to\na verifier.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1\">Saikat Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lahiri_S/0/1/0/all/0/1\">Shuvendu K. Lahiri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fakhoury_S/0/1/0/all/0/1\">Sarah Fakhoury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Musuvathi_M/0/1/0/all/0/1\">Madanlal Musuvathi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_A/0/1/0/all/0/1\">Akash Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1\">Aseem Rastogi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senthilnathan_A/0/1/0/all/0/1\">Aditya Senthilnathan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Rahul Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swamy_N/0/1/0/all/0/1\">Nikhil Swamy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Systematic Evaluation of Large Language Models on Out-of-Distribution Logical Reasoning Tasks. (arXiv:2310.09430v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09430","description":"<p>Large language models (LLMs), such as GPT-3.5 and GPT-4, have greatly\nadvanced the performance of artificial systems on various natural language\nprocessing tasks to human-like levels. However, their generalisation and\nrobustness to perform logical reasoning remain under-evaluated. To probe this\nability, we propose three new logical reasoning datasets named \"ReClor-plus\",\n\"LogiQA-plus\" and \"LogiQAv2-plus\", each featuring three subsets: the first with\nrandomly shuffled options, the second with the correct choices replaced by\n\"none of the other options are correct\", and a combination of the previous two\nsubsets. We carry out experiments on these datasets with both discriminative\nand generative LLMs and show that these simple tricks greatly hinder the\nperformance of the language models. Despite their superior performance on the\noriginal publicly available datasets, we find that all models struggle to\nanswer our newly constructed datasets. We show that introducing task variations\nby perturbing a sizable training set can markedly improve the model's\ngeneralisation and robustness in logical reasoning tasks. Moreover, applying\nlogic-driven data augmentation for fine-tuning, combined with prompting can\nenhance the generalisation performance of both discriminative large language\nmodels and generative large language models. These results offer insights into\nassessing and improving the generalisation and robustness of large language\nmodels for logical reasoning tasks. We make our source code and data publicly\navailable\n\\url{https://github.com/Strong-AI-Lab/Logical-and-abstract-reasoning}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Q/0/1/0/all/0/1\">Qiming Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gendron_G/0/1/0/all/0/1\">Gael Gendron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_A/0/1/0/all/0/1\">Alex Yuxuan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_N/0/1/0/all/0/1\">Neset Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1\">Michael Witbrock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiamou Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VIBE: Topic-Driven Temporal Adaptation for Twitter Classification. (arXiv:2310.10191v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10191","description":"<p>Language features are evolving in real-world social media, resulting in the\ndeteriorating performance of text classification in dynamics. To address this\nchallenge, we study temporal adaptation, where models trained on past data are\ntested in the future. Most prior work focused on continued pretraining or\nknowledge updating, which may compromise their performance on noisy social\nmedia data. To tackle this issue, we reflect feature change via modeling latent\ntopic evolution and propose a novel model, VIBE: Variational Information\nBottleneck for Evolutions. Concretely, we first employ two Information\nBottleneck (IB) regularizers to distinguish past and future topics. Then, the\ndistinguished topics work as adaptive features via multi-task training with\ntimestamp and class label prediction. In adaptive learning, VIBE utilizes\nretrieved unlabeled data from online streams created posterior to training data\ntime. Substantial Twitter experiments on three classification tasks show that\nour model, with only 3% of data, significantly outperforms previous\nstate-of-the-art continued-pretraining methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenjie Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10638","description":"<p>Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lomeli_M/0/1/0/all/0/1\">Maria Lomeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Margaret Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_V/0/1/0/all/0/1\">Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1\">Scott Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys. (arXiv:2310.10765v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.10765","description":"<p>Rapid progress has been made in instruction-learning for image editing with\nnatural-language instruction, as exemplified by InstructPix2Pix. In\nbiomedicine, such methods can be applied to counterfactual image generation,\nwhich helps differentiate causal structure from spurious correlation and\nfacilitate robust image interpretation for disease progression modeling.\nHowever, generic image-editing models are ill-suited for the biomedical domain,\nand counterfactual biomedical image generation is largely underexplored. In\nthis paper, we present BiomedJourney, a novel method for counterfactual\nbiomedical image generation by instruction-learning from multimodal patient\njourneys. Given a patient with two biomedical images taken at different time\npoints, we use GPT-4 to process the corresponding imaging reports and generate\na natural language description of disease progression. The resulting triples\n(prior image, progression description, new image) are then used to train a\nlatent diffusion model for counterfactual biomedical image generation. Given\nthe relative scarcity of image time series data, we introduce a two-stage\ncurriculum that first pretrains the denoising network using the much more\nabundant single image-report pairs (with dummy prior image), and then continues\ntraining using the counterfactual triples. Experiments using the standard\nMIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive\nbattery of tests on counterfactual medical image generation, BiomedJourney\nsubstantially outperforms prior state-of-the-art methods in instruction image\nediting and medical image generation such as InstructPix2Pix and RoentGen. To\nfacilitate future study in counterfactual medical generation, we plan to\nrelease our instruction-learning code and pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1\">Matthew P. Lungren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experimenting AI Technologies for Disinformation Combat: the IDMO Project. (arXiv:2310.11097v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11097","description":"<p>The Italian Digital Media Observatory (IDMO) project, part of a European\ninitiative, focuses on countering disinformation and fake news. This report\noutlines contributions from Rai-CRITS to the project, including: (i) the\ncreation of novel datasets for testing technologies (ii) development of an\nautomatic model for categorizing Pagella Politica verdicts to facilitate\nbroader analysis (iii) creation of an automatic model for recognizing textual\nentailment with exceptional accuracy on the FEVER dataset (iv) assessment using\nGPT-4 to identify textual entailmen (v) a game to raise awareness about fake\nnews at national events.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Canale_L/0/1/0/all/0/1\">Lorenzo Canale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_A/0/1/0/all/0/1\">Alberto Messina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights. (arXiv:2310.11368v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11368","description":"<p>Recognizing vulnerability is crucial for understanding and implementing\ntargeted support to empower individuals in need. This is especially important\nat the European Court of Human Rights (ECtHR), where the court adapts\nConvention standards to meet actual individual needs and thus ensures effective\nhuman rights protection. However, the concept of vulnerability remains elusive\nat the ECtHR and no prior NLP research has dealt with it. To enable future\nresearch in this area, we present VECHR, a novel expert-annotated multi-label\ndataset comprising of vulnerability type classification and explanation\nrationale. We benchmark the performance of state-of-the-art models on VECHR\nfrom both prediction and explainability perspectives. Our results demonstrate\nthe challenging nature of the task with lower prediction performance and\nlimited agreement between models and experts. Further, we analyze the\nrobustness of these models in dealing with out-of-domain (OOD) data and observe\noverall limited performance. Our dataset poses unique challenges offering\nsignificant room for improvement regarding performance, explainability, and\nrobustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shanshan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staufer_L/0/1/0/all/0/1\">Leon Staufer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Santosh T.Y.S.S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichim_O/0/1/0/all/0/1\">Oana Ichim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heri_C/0/1/0/all/0/1\">Corina Heri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1\">Matthias Grabmair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning. (arXiv:2310.11670v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11670","description":"<p>Parameter-efficient fine-tuning (PEFT) has shown its effectiveness in\nadapting the pre-trained language models to downstream tasks while only\nupdating a small number of parameters. Despite the success, most existing\nmethods independently adapt to each task without considering knowledge transfer\nbetween tasks and are limited to low-data regimes. To overcome this issue, we\npropose Prototype-based HyperAdapter (PHA), a novel framework built on the\nadapter-tuning and hypernetwork. It introduces an instance-dense retriever and\na prototypical hypernetwork to generate the conditional modules in a\nsample-efficient manner. This leads to comparable performance improvements\nagainst existing PEFT methods on multi-task learning and few-shot transfer\nlearning. More importantly, when the available data size gets smaller, our\nmethod outperforms other strong baselines by a large margin. Based on our\nextensive empirical experiments across various datasets, we demonstrate that\nPHA strikes a better trade-off between trainable parameters, accuracy on stream\ntasks, and sample efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhaofeng He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification. (arXiv:2310.11878v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11878","description":"<p>In legal NLP, Case Outcome Classification (COC) must not only be accurate but\nalso trustworthy and explainable. Existing work in explainable COC has been\nlimited to annotations by a single expert. However, it is well-known that\nlawyers may disagree in their assessment of case facts. We hence collect a\nnovel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two\nexperts in the domain of international human rights law, for whom we observe\nweak agreement. We study their disagreements and build a two-level\ntask-independent taxonomy, supplemented with COC-specific subcategories. To our\nknowledge, this is the first work in the legal NLP that focuses on human label\nvariation. We quantitatively assess different taxonomy categories and find that\ndisagreements mainly stem from underspecification of the legal context, which\nposes challenges given the typically limited granularity and noise in COC\nmetadata. We further assess the explainablility of SOTA COC models on RAVE and\nobserve limited agreement between models and experts. Overall, our case study\nreveals hitherto underappreciated complexities in creating benchmark datasets\nin legal NLP that revolve around identifying aspects of a case's facts\nsupposedly relevant to its outcome.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shanshan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Santosh T.Y.S.S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichim_O/0/1/0/all/0/1\">Oana Ichim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risini_I/0/1/0/all/0/1\">Isabella Risini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1\">Matthias Grabmair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Pretrained Autoregressive Transformer Graph Neural Network applied to the Analysis and Discovery of Novel Proteins. (arXiv:2305.04934v2 [q-bio.BM] CROSS LISTED)","link":"http://arxiv.org/abs/2305.04934","description":"<p>We report a flexible language-model based deep learning strategy, applied\nhere to solve complex forward and inverse problems in protein modeling, based\non an attention neural network that integrates transformer and graph\nconvolutional architectures in a causal multi-headed graph mechanism, to\nrealize a generative pretrained model. The model is applied to predict\nsecondary structure content (per-residue level and overall content), protein\nsolubility, and sequencing tasks. Further trained on inverse tasks, the model\nis rendered capable of designing proteins with these properties as target\nfeatures. The model is formulated as a general framework, completely\nprompt-based, and can be adapted for a variety of downstream tasks. We find\nthat adding additional tasks yields emergent synergies that the model exploits\nin improving overall performance, beyond what would be possible by training a\nmodel on each dataset alone. Case studies are presented to validate the method,\nyielding protein designs specifically focused on structural proteins, but also\nexploring the applicability in the design of soluble, antimicrobial\nbiomaterials. While our model is trained to ultimately perform 8 distinct\ntasks, with available datasets it can be extended to solve additional problems.\nIn a broader sense, this work illustrates a form of multiscale modeling that\nrelates a set of ultimate building blocks (here, byte-level utf8 characters\nthat define the nature of the physical system at hand) to complex output. This\nmateriomic scheme captures complex emergent relationships between universal\nbuilding block and resulting properties via a synergizing learning capacity to\nexpress a set of potentialities embedded in the knowledge used in training, via\nthe interplay of universality and diversity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-bio/1/au:+Buehler_M/0/1/0/all/0/1\">Markus J. Buehler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-19T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}