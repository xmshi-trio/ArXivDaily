{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-19T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Media of Langue. (arXiv:2309.08609v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08609","description":"<p>This paper aims to archive the materials behind \"Media of Langue\" by Goki\nMuramoto et al. Media of Langue is a new dictionary and public sculpture that\ndepicts the map of meaning on the boundary between languages solely from the\nvast events of \"this word was translated into that word\" and two forces:\nrepulsion between all words in the same language and attraction between\ntranslated words in different languages. First, the three new concepts\nproposed, Inter-Langue Map/Dictionary, Inter-Langue Space, and then\nInter-Langue Network, are introduced, comparing them to the three domains of\ndictionary, semantic space, and semantic network. Next, the specific algorithms\nand designs implemented in the work were described.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Muramoto_G/0/1/0/all/0/1\">Goki Muramoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sato_A/0/1/0/all/0/1\">Atsuki Sato</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koyama_T/0/1/0/all/0/1\">Takayoshi Koyama</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explaining Vision and Language through Graphs of Events in Space and Time. (arXiv:2309.08612v1 [cs.AI])","link":"http://arxiv.org/abs/2309.08612","description":"<p>Artificial Intelligence makes great advances today and starts to bridge the\ngap between vision and language. However, we are still far from understanding,\nexplaining and controlling explicitly the visual content from a linguistic\nperspective, because we still lack a common explainable representation between\nthe two domains. In this work we come to address this limitation and propose\nthe Graph of Events in Space and Time (GEST), by which we can represent, create\nand explain, both visual and linguistic stories. We provide a theoretical\njustification of our model and an experimental validation, which proves that\nGEST can bring a solid complementary value along powerful deep learning models.\nIn particular, GEST can help improve at the content-level the generation of\nvideos from text, by being easily incorporated into our novel video generation\nengine. Additionally, by using efficient graph matching techniques, the GEST\ngraphs can also improve the comparisons between texts at the semantic level.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Masala_M/0/1/0/all/0/1\">Mihai Masala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cudlenco_N/0/1/0/all/0/1\">Nicolae Cudlenco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rebedea_T/0/1/0/all/0/1\">Traian Rebedea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leordeanu_M/0/1/0/all/0/1\">Marius Leordeanu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Recommender Systems in the Prediction of Disease Comorbidity. (arXiv:2309.08613v1 [cs.IR])","link":"http://arxiv.org/abs/2309.08613","description":"<p>While deep-learning based recommender systems utilizing collaborative\nfiltering have been commonly used for recommendation in other domains, their\napplication in the medical domain have been limited. In addition to modeling\nuser-item interactions, we show that deep-learning based recommender systems\ncan be used to model subject-disease code interactions. Two novel applications\nof deep learning-based recommender systems using Neural Collaborative Filtering\n(NCF) and Deep Hybrid Filtering (DHF) were utilized for disease diagnosis based\non known past patient comorbidities. Two datasets, one incorporating all\nsubject-disease code pairs present in the MIMIC-III database, and the other\nincorporating the top 50 most commonly occurring diseases, were used for\nprediction. Accuracy and Hit Ratio@10 were utilized as metrics to estimate\nmodel performance. The performance of the NCF model making use of the reduced\n\"top 50\" ICD-9 code dataset was found to be lower (accuracy of ~80% and hit\nratio@10 of 35%) as compared to the performance of the NCF model trained on all\nICD-9 codes (accuracy of ~90% and hit ratio@10 of ~80%). Reasons for the\nsuperior performance of the sparser dataset with all ICD codes can be mainly\nattributed to the higher volume of data and the robustness of deep-learning\nbased recommender systems with modeling sparse data. Additionally, results from\nthe DHF models reflect better performance than the NCF models, with a better\naccuracy of 94.4% and hit ratio@10 of 85.36%, reflecting the importance of the\nincorporation of clinical note information. Additionally, compared to\nliterature reports utilizing primarily natural language processing-based\npredictions for the task of ICD-9 code co-occurrence, the novel deep\nlearning-based recommender systems approach performed better. Overall, the deep\nlearning-based recommender systems have shown promise in predicting disease\ncomorbidity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheruvu_A/0/1/0/all/0/1\">Aashish Cheruvu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing Character and Consciousness in AI-Generated Social Content: A Case Study of Chirper, the AI Social Network. (arXiv:2309.08614v1 [cs.AI])","link":"http://arxiv.org/abs/2309.08614","description":"<p>This paper delves into an intricate analysis of the character and\nconsciousness of AI entities, with a particular focus on Chirpers within the AI\nsocial network. At the forefront of this research is the introduction of novel\ntesting methodologies, including the Influence index and Struggle Index Test,\nwhich offers a fresh lens for evaluating specific facets of AI behavior. The\nstudy embarks on a comprehensive exploration of AI behavior, analyzing the\neffects of diverse settings on Chirper's responses, thereby shedding light on\nthe intricate mechanisms steering AI reactions in different contexts.\nLeveraging the state-of-the-art BERT model, the research assesses AI's ability\nto discern its own output, presenting a pioneering approach to understanding\nself-recognition in AI systems. Through a series of cognitive tests, the study\ngauges the self-awareness and pattern recognition prowess of Chirpers.\nPreliminary results indicate that Chirpers exhibit a commendable degree of\nself-recognition and self-awareness. However, the question of consciousness in\nthese AI entities remains a topic of debate. An intriguing aspect of the\nresearch is the exploration of the potential influence of a Chirper's handle or\npersonality type on its performance. While initial findings suggest a possible\nimpact, it isn't pronounced enough to form concrete conclusions. This study\nstands as a significant contribution to the discourse on AI consciousness,\nunderscoring the imperative for continued research to unravel the full spectrum\nof AI capabilities and the ramifications they hold for future human-AI\ninteractions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jianwei Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenges in Annotating Datasets to Quantify Bias in Under-represented Society. (arXiv:2309.08624v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08624","description":"<p>Recent advances in artificial intelligence, including the development of\nhighly sophisticated large language models (LLM), have proven beneficial in\nmany real-world applications. However, evidence of inherent bias encoded in\nthese LLMs has raised concerns about equity. In response, there has been an\nincrease in research dealing with bias, including studies focusing on\nquantifying bias and developing debiasing techniques. Benchmark bias datasets\nhave also been developed for binary gender classification and ethical/racial\nconsiderations, focusing predominantly on American demographics. However, there\nis minimal research in understanding and quantifying bias related to\nunder-represented societies. Motivated by the lack of annotated datasets for\nquantifying bias in under-represented societies, we endeavoured to create\nbenchmark datasets for the New Zealand (NZ) population. We faced many\nchallenges in this process, despite the availability of three annotators. This\nresearch outlines the manual annotation process, provides an overview of the\nchallenges we encountered and lessons learnt, and presents recommendations for\nfuture research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yogarajan_V/0/1/0/all/0/1\">Vithya Yogarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dobbie_G/0/1/0/all/0/1\">Gillian Dobbie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pistotti_T/0/1/0/all/0/1\">Timothy Pistotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bensemann_J/0/1/0/all/0/1\">Joshua Bensemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knowles_K/0/1/0/all/0/1\">Kobe Knowles</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Performance of ChatGPT-3.5 and GPT-4 on the United States Medical Licensing Examination With and Without Distractions. (arXiv:2309.08625v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08625","description":"<p>As Large Language Models (LLMs) are predictive models building their response\nbased on the words in the prompts, there is a risk that small talk and\nirrelevant information may alter the response and the suggestion given.\nTherefore, this study aims to investigate the impact of medical data mixed with\nsmall talk on the accuracy of medical advice provided by ChatGPT. USMLE step 3\nquestions were used as a model for relevant medical data. We use both multiple\nchoice and open ended questions. We gathered small talk sentences from human\nparticipants using the Mechanical Turk platform. Both sets of USLME questions\nwere arranged in a pattern where each sentence from the original questions was\nfollowed by a small talk sentence. ChatGPT 3.5 and 4 were asked to answer both\nsets of questions with and without the small talk sentences. A board-certified\nphysician analyzed the answers by ChatGPT and compared them to the formal\ncorrect answer. The analysis results demonstrate that the ability of\nChatGPT-3.5 to answer correctly was impaired when small talk was added to\nmedical data for multiple-choice questions (72.1\\% vs. 68.9\\%) and open\nquestions (61.5\\% vs. 44.3\\%; p=0.01), respectively. In contrast, small talk\nphrases did not impair ChatGPT-4 ability in both types of questions (83.6\\% and\n66.2\\%, respectively). According to these results, ChatGPT-4 seems more\naccurate than the earlier 3.5 version, and it appears that small talk does not\nimpair its capability to provide medical recommendations. Our results are an\nimportant first step in understanding the potential and limitations of\nutilizing ChatGPT and other LLMs for physician-patient interactions, which\ninclude casual conversations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Safrai_M/0/1/0/all/0/1\">Myriam Safrai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azaria_A/0/1/0/all/0/1\">Amos Azaria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Robustness of Neural Inverse Text Normalization via Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method. (arXiv:2309.08626v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08626","description":"<p>Inverse text normalization (ITN) is crucial for converting spoken-form into\nwritten-form, especially in the context of automatic speech recognition (ASR).\nWhile most downstream tasks of ASR rely on written-form, ASR systems often\noutput spoken-form, highlighting the necessity for robust ITN in product-level\nASR-based applications. Although neural ITN methods have shown promise, they\nstill encounter performance challenges, particularly when dealing with\nASR-generated spoken text. These challenges arise from the out-of-domain\nproblem between training data and ASR-generated text. To address this, we\npropose a direct training approach that utilizes ASR-generated written or\nspoken text, with pairs augmented through ASR linguistic context emulation and\na semi-supervised learning method enhanced by a large language model,\nrespectively. Additionally, we introduce a post-aligning method to manage\nunpredictable errors, thereby enhancing the reliability of ITN. Our experiments\nshow that our proposed methods remarkably improved ITN performance in various\nASR scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Juntae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_M/0/1/0/all/0/1\">Minkyu Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1\">Seokjin Hong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Dynamic Topic Models. (arXiv:2309.08627v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08627","description":"<p>There is a lack of quantitative measures to evaluate the progression of\ntopics through time in dynamic topic models (DTMs). Filling this gap, we\npropose a novel evaluation measure for DTMs that analyzes the changes in the\nquality of each topic over time. Additionally, we propose an extension\ncombining topic quality with the model's temporal consistency. We demonstrate\nthe utility of the proposed measure by applying it to synthetic data and data\nfrom existing DTMs. We also conducted a human evaluation, which indicates that\nthe proposed measure correlates well with human judgment. Our findings may help\nin identifying changing topics, evaluating different DTMs, and guiding future\nresearch in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+James_C/0/1/0/all/0/1\">Charu James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagda_M/0/1/0/all/0/1\">Mayank Nagda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_N/0/1/0/all/0/1\">Nooshin Haji Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kloft_M/0/1/0/all/0/1\">Marius Kloft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fellenz_S/0/1/0/all/0/1\">Sophie Fellenz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recovering from Privacy-Preserving Masking with Large Language Models. (arXiv:2309.08628v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08628","description":"<p>Model adaptation is crucial to handle the discrepancy between proxy training\ndata and actual users data received. To effectively perform adaptation, textual\ndata of users is typically stored on servers or their local devices, where\ndownstream natural language processing (NLP) models can be directly trained\nusing such in-domain data. However, this might raise privacy and security\nconcerns due to the extra risks of exposing user information to adversaries.\nReplacing identifying information in textual data with a generic marker has\nbeen recently explored. In this work, we leverage large language models (LLMs)\nto suggest substitutes of masked tokens and have their effectiveness evaluated\non downstream language modeling tasks. Specifically, we propose multiple\npre-trained and fine-tuned LLM-based approaches and perform empirical studies\non various datasets for the comparison of these methods. Experimental results\nshow that models trained on the obfuscation corpora are able to achieve\ncomparable performance with the ones trained on the original data without\nprivacy-preserving token masking.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vats_A/0/1/0/all/0/1\">Arpita Vats</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_P/0/1/0/all/0/1\">Peng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debjyoti Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingyi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1\">Yutong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_Z/0/1/0/all/0/1\">Zeeshan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Can Infer Psychological Dispositions of Social Media Users. (arXiv:2309.08631v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08631","description":"<p>As Large Language Models (LLMs) demonstrate increasingly human-like abilities\nin various natural language processing (NLP) tasks that are bound to become\nintegral to personalized technologies, understanding their capabilities and\ninherent biases is crucial. Our study investigates the potential of LLMs like\nChatGPT to infer psychological dispositions of individuals from their digital\nfootprints. Specifically, we assess the ability of GPT-3.5 and GPT-4 to derive\nthe Big Five personality traits from users' Facebook status updates in a\nzero-shot learning scenario. Our results show an average correlation of r = .29\n(range = [.22, .33]) between LLM-inferred and self-reported trait scores.\nFurthermore, our findings suggest biases in personality inferences with regard\nto gender and age: inferred scores demonstrated smaller errors for women and\nyounger individuals on several traits, suggesting a potential systematic bias\nstemming from the underlying training data or differences in online\nself-expression.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peters_H/0/1/0/all/0/1\">Heinrich Peters</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matz_S/0/1/0/all/0/1\">Sandra Matz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pretraining on the Test Set Is All You Need. (arXiv:2309.08632v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08632","description":"<p>Inspired by recent work demonstrating the promise of smaller\nTransformer-based language models pretrained on carefully curated data, we\nsupercharge such approaches by investing heavily in curating a novel, high\nquality, non-synthetic data mixture based solely on evaluation benchmarks.\nUsing our novel dataset mixture consisting of less than 100 thousand tokens, we\npretrain a 1 million parameter transformer-based LLM \\textbf{phi-CTNL}\n(pronounced ``fictional\") that achieves perfect results across diverse academic\nbenchmarks, strictly outperforming all known foundation models.\n\\textbf{phi-CTNL} also beats power-law scaling and exhibits a never-before-seen\ngrokking-like ability to accurately predict downstream evaluation benchmarks'\ncanaries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schaeffer_R/0/1/0/all/0/1\">Rylan Schaeffer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT v Bard v Bing v Claude 2 v Aria v human-expert. How good are AI chatbots at scientific writing? (ver. 23Q3). (arXiv:2309.08636v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08636","description":"<p>Historically, proficient writing was deemed essential for human advancement,\nwith creative expression viewed as one of the hallmarks of human achievement.\nHowever, recent advances in generative AI have marked an inflection point in\nthis narrative, including for scientific writing. This article provides a\ncomprehensive analysis of the capabilities and limitations of six AI chatbots\nin scholarly writing in the humanities and archaeology. The methodology was\nbased on tagging AI generated content for quantitative accuracy and qualitative\nprecision by human experts. Quantitative accuracy assessed the factual\ncorrectness, while qualitative precision gauged the scientific contribution.\nWhile the AI chatbots, especially ChatGPT-4, demonstrated proficiency in\nrecombining existing knowledge, they failed in generating original scientific\ncontent. As a side note, our results also suggest that with ChatGPT-4 the size\nof the LLMs has plateaued. Furthermore, the paper underscores the intricate and\nrecursive nature of human research. This process of transforming raw data into\nrefined knowledge is computationally irreducible, which highlights the\nchallenges AI chatbots face in emulating human originality in scientific\nwriting. In conclusion, while large language models have revolutionised content\ngeneration, their ability to produce original scientific contributions in the\nhumanities remains limited. We expect that this will change in the near future\nwith the evolution of current LLM-based AI chatbots towards LLM-powered\nsoftware.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lozic_E/0/1/0/all/0/1\">Edisa Lozi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stular_B/0/1/0/all/0/1\">Benjamin &#x160;tular</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TextBind: Multi-turn Interleaved Multimodal Instruction-following. (arXiv:2309.08637v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08637","description":"<p>Large language models with instruction-following abilities have\nrevolutionized the field of artificial intelligence. These models show\nexceptional generalizability to tackle various real-world tasks through their\nnatural language interfaces. However, their performance heavily relies on\nhigh-quality exemplar data, which is often difficult to obtain. This challenge\nis further exacerbated when it comes to multimodal instruction following. We\nintroduce TextBind, an almost annotation-free framework for empowering larger\nlanguage models with the multi-turn interleaved multimodal\ninstruction-following capabilities. Our approach requires only image-caption\npairs and generates multi-turn multimodal instruction-response conversations\nfrom a language model. We release our dataset, model, and demo to foster future\nresearch in the area of multimodal instruction following.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huayang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Longyue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1\">Taro Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Anchor Points: Benchmarking Models with Much Fewer Examples. (arXiv:2309.08638v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08638","description":"<p>Modern language models often exhibit powerful but brittle behavior, leading\nto the development of larger and more diverse benchmarks to reliably assess\ntheir behavior. Here, we suggest that model performance can be benchmarked and\nelucidated with much smaller evaluation sets. We first show that in six popular\nlanguage classification benchmarks, model confidence in the correct class on\nmany pairs of points is strongly correlated across models. We build upon this\nphenomenon to propose Anchor Point Selection, a technique to select small\nsubsets of datasets that capture model behavior across the entire dataset.\nAnchor points reliably rank models: across 87 diverse language model-prompt\npairs, evaluating models using 1-30 anchor points outperforms uniform sampling\nand other baselines at accurately ranking models. Moreover, just several anchor\npoints can be used to estimate model per-class predictions on all other points\nin a dataset with low mean absolute error, sufficient for gauging where the\nmodel is likely to fail. Lastly, we present Anchor Point Maps for visualizing\nthese insights and facilitating comparisons of the performance of different\nmodels on various regions within the dataset distribution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vivek_R/0/1/0/all/0/1\">Rajan Vivek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ethayarajh_K/0/1/0/all/0/1\">Kawin Ethayarajh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1\">Douwe Kiela</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cure the headache of Transformers via Collinear Constrained Attention. (arXiv:2309.08646v1 [cs.LG])","link":"http://arxiv.org/abs/2309.08646","description":"<p>As the rapid progression of practical applications based on Large Language\nModels continues, the importance of extrapolating performance has grown\nexponentially in the research domain. In our study, we identified an anomalous\nbehavior in Transformer models that had been previously overlooked, leading to\na chaos around closest tokens which carried the most important information.\nWe've coined this discovery the \"headache of Transformers\". To address this at\nits core, we introduced a novel self-attention structure named Collinear\nConstrained Attention (CoCA). This structure can be seamlessly integrated with\nexisting extrapolation, interpolation methods, and other optimization\nstrategies designed for traditional Transformer models. We have achieved\nexcellent extrapolating performance even for 16 times to 24 times of sequence\nlengths during inference without any fine-tuning on our model. We have also\nenhanced CoCA's computational and spatial efficiency to ensure its\npracticality. We plan to open-source CoCA shortly. In the meantime, we've made\nour code available in the appendix for reappearing experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1\">Shiyi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jing Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Wei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yifan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianguo Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intent Detection at Scale: Tuning a Generic Model using Relevant Intents. (arXiv:2309.08647v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08647","description":"<p>Accurately predicting the intent of customer support requests is vital for\nefficient support systems, enabling agents to quickly understand messages and\nprioritize responses accordingly. While different approaches exist for intent\ndetection, maintaining separate client-specific or industry-specific models can\nbe costly and impractical as the client base expands.\n</p>\n<p>This work proposes a system to scale intent predictions to various clients\neffectively, by combining a single generic model with a per-client list of\nrelevant intents. Our approach minimizes training and maintenance costs while\nproviding a personalized experience for clients, allowing for seamless\nadaptation to changes in their relevant intents. Furthermore, we propose a\nstrategy for using the clients relevant intents as model features that proves\nto be resilient to changes in the relevant intents of clients -- a common\noccurrence in production environments.\n</p>\n<p>The final system exhibits significantly superior performance compared to\nindustry-specific models, showcasing its flexibility and ability to cater to\ndiverse client needs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Narotamo_N/0/1/0/all/0/1\">Nichal Narotamo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aparicio_D/0/1/0/all/0/1\">David Aparicio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mesquita_T/0/1/0/all/0/1\">Tiago Mesquita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almeida_M/0/1/0/all/0/1\">Mariana Almeida</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAPLE: Mobile App Prediction Leveraging Large Language model Embeddings. (arXiv:2309.08648v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08648","description":"<p>Despite the rapid advancement of mobile applications, predicting app usage\nremains a formidable challenge due to intricate user behaviours and\never-evolving contexts. To address these issues, this paper introduces the\nMobile App Prediction Leveraging Large Language Model Embeddings (MAPLE) model.\nThis innovative approach utilizes Large Language Models (LLMs) to predict app\nusage accurately. Rigorous testing on two public datasets highlights MAPLE's\ncapability to decipher intricate patterns and comprehend user contexts. These\nrobust results confirm MAPLE's versatility and resilience across various\nscenarios. While its primary design caters to app prediction, the outcomes also\nemphasize the broader applicability of LLMs in different domains. Through this\nresearch, we emphasize the potential of LLMs in app usage prediction and\nsuggest their transformative capacity in modelling human behaviours across\ndiverse fields.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khaokaew_Y/0/1/0/all/0/1\">Yonchanok Khaokaew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1\">Flora D. Salim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adversarial Attacks on Tables with Entity Swap. (arXiv:2309.08650v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08650","description":"<p>The capabilities of large language models (LLMs) have been successfully\napplied in the context of table representation learning. The recently proposed\ntabular language models have reported state-of-the-art results across various\ntasks for table interpretation. However, a closer look into the datasets\ncommonly used for evaluation reveals an entity leakage from the train set into\nthe test set. Motivated by this observation, we explore adversarial attacks\nthat represent a more realistic inference setup. Adversarial attacks on text\nhave been shown to greatly affect the performance of LLMs, but currently, there\nare no attacks targeting tabular language models. In this paper, we propose an\nevasive entity-swap attack for the column type annotation (CTA) task. Our CTA\nattack is the first black-box attack on tables, where we employ a\nsimilarity-based sampling strategy to generate adversarial examples. The\nexperimental results show that the proposed attack generates up to a 70% drop\nin performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koleva_A/0/1/0/all/0/1\">Aneta Koleva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ringsquandl_M/0/1/0/all/0/1\">Martin Ringsquandl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1\">Volker Tresp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fake News Detectors are Biased against Texts Generated by Large Language Models. (arXiv:2309.08674v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08674","description":"<p>The spread of fake news has emerged as a critical challenge, undermining\ntrust and posing threats to society. In the era of Large Language Models\n(LLMs), the capability to generate believable fake content has intensified\nthese concerns. In this study, we present a novel paradigm to evaluate fake\nnews detectors in scenarios involving both human-written and LLM-generated\nmisinformation. Intriguingly, our findings reveal a significant bias in many\nexisting detectors: they are more prone to flagging LLM-generated content as\nfake news while often misclassifying human-written fake news as genuine. This\nunexpected bias appears to arise from distinct linguistic patterns inherent to\nLLM outputs. To address this, we introduce a mitigation strategy that leverages\nadversarial training with LLM-paraphrased genuine news. The resulting model\nyielded marked improvements in detection accuracy for both human and\nLLM-generated news. To further catalyze research in this domain, we release two\ncomprehensive datasets, \\texttt{GossipCop++} and \\texttt{PolitiFact++}, thus\namalgamating human-validated articles with LLM-generated fake and real news.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1\">Jinyan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansurov_J/0/1/0/all/0/1\">Jonibek Mansurov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Resolving Legalese: A Multilingual Exploration of Negation Scope Resolution in Legal Documents. (arXiv:2309.08695v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08695","description":"<p>Resolving the scope of a negation within a sentence is a challenging NLP\ntask. The complexity of legal texts and the lack of annotated in-domain\nnegation corpora pose challenges for state-of-the-art (SotA) models when\nperforming negation scope resolution on multilingual legal data. Our\nexperiments demonstrate that models pre-trained without legal data underperform\nin the task of negation scope resolution. Our experiments, using language\nmodels exclusively fine-tuned on domains like literary texts and medical data,\nyield inferior results compared to the outcomes documented in prior\ncross-domain experiments. We release a new set of annotated court decisions in\nGerman, French, and Italian and use it to improve negation scope resolution in\nboth zero-shot and multilingual settings. We achieve token-level F1-scores of\nup to 86.7% in our zero-shot cross-lingual experiments, where the models are\ntrained on two languages of our legal datasets and evaluated on the third. Our\nmultilingual experiments, where the models were trained on all available\nnegation data and evaluated on our legal datasets, resulted in F1-scores of up\nto 91.1%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Christen_R/0/1/0/all/0/1\">Ramona Christen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaitarova_A/0/1/0/all/0/1\">Anastassia Shaitarova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sturmer_M/0/1/0/all/0/1\">Matthias St&#xfc;rmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niklaus_J/0/1/0/all/0/1\">Joel Niklaus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Frustratingly Simple Memory Efficiency for Pre-trained Language Models via Dynamic Embedding Pruning. (arXiv:2309.08708v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08708","description":"<p>The extensive memory footprint of pre-trained language models (PLMs) can\nhinder deployment in memory-constrained settings, such as cloud environments or\non-device. PLMs use embedding matrices to represent extensive vocabularies,\nforming a large proportion of the model parameters. While previous work towards\nparameter-efficient PLM development has considered pruning parameters within\nthe transformer layers, pruning the embedding matrix as part of fine-tuning or\ninference has yet to be explored. We first demonstrate that a significant\nproportion of the vocabulary remains unused in these scenarios. We then propose\na simple yet effective approach that leverages this finding to minimize the\nmemory footprint of the embedding matrix. We show that this approach provides\nsubstantial reductions in memory usage across a wide range of models and tasks.\nNotably, our approach maintains equivalent downstream task performance while\nallowing a more efficient use of compute resources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Williams_M/0/1/0/all/0/1\">Miles Williams</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1\">Nikolaos Aletras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generating Semantic Graph Corpora with Graph Expansion Grammar. (arXiv:2309.08714v1 [cs.FL])","link":"http://arxiv.org/abs/2309.08714","description":"<p>We introduce Lovelace, a tool for creating corpora of semantic graphs. The\nsystem uses graph expansion grammar as a representational language, thus\nallowing users to craft a grammar that describes a corpus with desired\nproperties. When given such grammar as input, the system generates a set of\noutput graphs that are well-formed according to the grammar, i.e., a graph\nbank. The generation process can be controlled via a number of configurable\nparameters that allow the user to, for example, specify a range of desired\noutput graph sizes. Central use cases are the creation of synthetic data to\naugment existing corpora, and as a pedagogical tool for teaching formal\nlanguage theory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Andersson_E/0/1/0/all/0/1\">Eric Andersson</a> (Ume&#xe5; University), <a href=\"http://arxiv.org/find/cs/1/au:+Bjorklund_J/0/1/0/all/0/1\">Johanna Bj&#xf6;rklund</a> (Ume&#xe5; University), <a href=\"http://arxiv.org/find/cs/1/au:+Drewes_F/0/1/0/all/0/1\">Frank Drewes</a> (Ume&#xe5; University), <a href=\"http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1\">Anna Jonsson</a> (Ume&#xe5; University)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MusiLingo: Bridging Music and Text with Pre-trained Language Models for Music Captioning and Query Response. (arXiv:2309.08730v1 [eess.AS])","link":"http://arxiv.org/abs/2309.08730","description":"<p>Large Language Models (LLMs) have shown immense potential in multimodal\napplications, yet the convergence of textual and musical domains remains\nrelatively unexplored. To address this gap, we present MusiLingo, a novel\nsystem for music caption generation and music-related query responses.\nMusiLingo employs a single projection layer to align music representations from\nthe pre-trained frozen music audio model MERT with the frozen LLaMA language\nmodel, bridging the gap between music audio and textual contexts. We train it\non an extensive music caption dataset and fine-tune it with instructional data.\nDue to the scarcity of high-quality music Q&amp;A datasets, we created the\nMusicInstruct (MI) dataset from MusicCaps, tailored for open-ended music\ninquiries. Empirical evaluations demonstrate its competitive performance in\ngenerating music captions and composing music-related Q&amp;A pairs. Our introduced\ndataset enables notable advancements beyond previous ones.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Deng_Z/0/1/0/all/0/1\">Zihao Deng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_Y/0/1/0/all/0/1\">Yinghao Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1\">Yudong Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Guo_R/0/1/0/all/0/1\">Rongchen Guo</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Benetos_E/0/1/0/all/0/1\">Emmanouil Benetos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AlbNER: A Corpus for Named Entity Recognition in Albanian. (arXiv:2309.08741v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08741","description":"<p>Scarcity of resources such as annotated text corpora for under-resourced\nlanguages like Albanian is a serious impediment in computational linguistics\nand natural language processing research. This paper presents AlbNER, a corpus\nof 900 sentences with labeled named entities, collected from Albanian Wikipedia\narticles. Preliminary results with BERT and RoBERTa variants fine-tuned and\ntested with AlbNER data indicate that model size has slight impact on NER\nperformance, whereas language transfer has a significant one. AlbNER corpus and\nthese obtained results should serve as baselines for future experiments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cano_E/0/1/0/all/0/1\">Erion &#xc7;ano</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study on Instance Selection Strategies in Self-training for Sentiment Analysis. (arXiv:2309.08777v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08777","description":"<p>Sentiment analysis is a crucial task in natural language processing that\ninvolves identifying and extracting subjective sentiment from text.\nSelf-training has recently emerged as an economical and efficient technique for\ndeveloping sentiment analysis models by leveraging a small amount of labeled\ndata and a larger amount of unlabeled data. However, the performance of a\nself-training procedure heavily relies on the choice of the instance selection\nstrategy, which has not been studied thoroughly. This paper presents an\nempirical study on various instance selection strategies for self-training on\ntwo public sentiment datasets, and investigates the influence of the strategy\nand hyper-parameters on the performance of self-training in various few-shot\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haochen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rallabandi_S/0/1/0/all/0/1\">Sai Krishna Rallabandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yijing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dakle_P/0/1/0/all/0/1\">Parag Pravin Dakle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raghavan_P/0/1/0/all/0/1\">Preethi Raghavan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking in the Era of LLMs. (arXiv:2309.08827v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08827","description":"<p>The traditional Dialogue State Tracking (DST) problem aims to track user\npreferences and intents in user-agent conversations. While sufficient for\ntask-oriented dialogue systems supporting narrow domain applications, the\nadvent of Large Language Model (LLM)-based chat systems has introduced many\nreal-world intricacies in open-domain dialogues. These intricacies manifest in\nthe form of increased complexity in contextual interactions, extended dialogue\nsessions encompassing a diverse array of topics, and more frequent contextual\nshifts. To handle these intricacies arising from evolving LLM-based chat\nsystems, we propose joint dialogue segmentation and state tracking per segment\nin open-domain dialogue systems. Assuming a zero-shot setting appropriate to a\ntrue open-domain dialogue system, we propose S3-DST, a structured prompting\ntechnique that harnesses Pre-Analytical Recollection, a novel grounding\nmechanism we designed for improving long context tracking. To demonstrate the\nefficacy of our proposed approach in joint segmentation and state tracking, we\nevaluate S3-DST on a proprietary anonymized open-domain dialogue dataset, as\nwell as publicly available DST and segmentation datasets. Across all datasets\nand settings, S3-DST consistently outperforms the state-of-the-art,\ndemonstrating its potency and robustness the next generation of LLM-based chat\nsystems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sarkar Snigdha Sarathi Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_C/0/1/0/all/0/1\">Chirag Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_M/0/1/0/all/0/1\">Mengting Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neville_J/0/1/0/all/0/1\">Jennifer Neville</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Longqi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andersen_R/0/1/0/all/0/1\">Reid Andersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buscher_G/0/1/0/all/0/1\">Georg Buscher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Safavi_T/0/1/0/all/0/1\">Tara Safavi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SLIDE: Reference-free Evaluation for Machine Translation using a Sliding Document Window. (arXiv:2309.08832v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08832","description":"<p>Reference-based metrics that operate at the sentence level typically\noutperform quality estimation metrics, which have access only to the source and\nsystem output. This is unsurprising, since references resolve ambiguities that\nmay be present in the source. We investigate whether additional source context\ncan effectively substitute for a reference. We present a metric, SLIDE (SLiding\nDocument Evaluator), which operates on blocks of sentences using a window that\nslides over each document in the test set, feeding each chunk into an\nunmodified, off-the-shelf quality estimation model. We find that SLIDE obtains\nsignificantly higher pairwise system accuracy than its sentence-level baseline,\nin some cases even eliminating the gap with reference-base metrics. This\nsuggests that source context may provide the same information as a human\nreference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raunak_V/0/1/0/all/0/1\">Vikas Raunak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocmi_T/0/1/0/all/0/1\">Tom Kocmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1\">Matt Post</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bias and Fairness in Chatbots: An Overview. (arXiv:2309.08836v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08836","description":"<p>Chatbots have been studied for more than half a century. With the rapid\ndevelopment of natural language processing (NLP) technologies in recent years,\nchatbots using large language models (LLMs) have received much attention\nnowadays. Compared with traditional ones, modern chatbots are more powerful and\nhave been used in real-world applications. There are however, bias and fairness\nconcerns in modern chatbot design. Due to the huge amounts of training data,\nextremely large model sizes, and lack of interpretability, bias mitigation and\nfairness preservation of modern chatbots are challenging. Thus, a comprehensive\noverview on bias and fairness in chatbot systems is given in this paper. The\nhistory of chatbots and their categories are first reviewed. Then, bias sources\nand potential harms in applications are analyzed. Considerations in designing\nfair and unbiased chatbot systems are examined. Finally, future research\ndirections are discussed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jintang Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yun-Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chengwei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaofeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1\">Jonghye Woo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1\">C.-C. Jay Kuo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Has Sentiment Returned to the Pre-pandemic Level? A Sentiment Analysis Using U.S. College Subreddit Data from 2019 to 2022. (arXiv:2309.08845v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08845","description":"<p>As impact of COVID-19 pandemic winds down, both individuals and society\ngradually return to pre-pandemic activities. This study aims to explore how\npeople's emotions have changed from the pre-pandemic during the pandemic to\npost-emergency period and whether it has returned to pre-pandemic level. We\ncollected Reddit data in 2019 (pre-pandemic), 2020 (peak pandemic), 2021, and\n2022 (late stages of pandemic, transitioning period to post-emergency period)\nfrom subreddits in 128 universities/colleges in the U.S., and a set of\nschool-level characteristics. We predicted two sets of sentiments from a\npre-trained Robustly Optimized BERT pre-training approach (RoBERTa) and graph\nattention network (GAT) that leverages both rich semantic and relational\ninformation among posted messages and then applied a logistic stacking method\nto obtain the final sentiment classification. After obtaining sentiment label\nfor each message, we used a generalized linear mixed-effects model to estimate\ntemporal trend in sentiment from 2019 to 2022 and how school-level factors may\naffect sentiment. Compared to the year 2019, the odds of negative sentiment in\nyears 2020, 2021, and 2022 are 24%, 4.3%, and 10.3% higher, respectively, which\nare all statistically significant(adjusted $p$&lt;0.05). Our study findings\nsuggest a partial recovery in the sentiment composition in the\npost-pandemic-emergency era. The results align with common expectations and\nprovide a detailed quantification of how sentiments have evolved from 2019 to\n2022.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1\">Tian Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MHLAT: Multi-hop Label-wise Attention Model for Automatic ICD Coding. (arXiv:2309.08868v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08868","description":"<p>International Classification of Diseases (ICD) coding is the task of\nassigning ICD diagnosis codes to clinical notes. This can be challenging given\nthe large quantity of labels (nearly 9,000) and lengthy texts (up to 8,000\ntokens). However, unlike the single-pass reading process in previous works,\nhumans tend to read the text and label definitions again to get more confident\nanswers. Moreover, although pretrained language models have been used to\naddress these problems, they suffer from huge memory usage. To address the\nabove problems, we propose a simple but effective model called the Multi-Hop\nLabel-wise ATtention (MHLAT), in which multi-hop label-wise attention is\ndeployed to get more precise and informative representations. Extensive\nexperiments on three benchmark MIMIC datasets indicate that our method achieves\nsignificantly better or competitive performance on all seven metrics, with much\nfewer parameters to optimize.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1\">Junwen Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Han Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Ying Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PDFTriage: Question Answering over Long, Structured Documents. (arXiv:2309.08872v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08872","description":"<p>Large Language Models (LLMs) have issues with document question answering\n(QA) in situations where the document is unable to fit in the small context\nlength of an LLM. To overcome this issue, most existing works focus on\nretrieving the relevant context from the document, representing them as plain\ntext. However, documents such as PDFs, web pages, and presentations are\nnaturally structured with different pages, tables, sections, and so on.\nRepresenting such structured documents as plain text is incongruous with the\nuser's mental model of these documents with rich structure. When a system has\nto query the document for context, this incongruity is brought to the fore, and\nseemingly trivial questions can trip up the QA system. To bridge this\nfundamental gap in handling structured documents, we propose an approach called\nPDFTriage that enables models to retrieve the context based on either structure\nor content. Our experiments demonstrate the effectiveness of the proposed\nPDFTriage-augmented models across several classes of questions where existing\nretrieval-augmented LLMs fail. To facilitate further research on this\nfundamental problem, we release our benchmark dataset consisting of 900+\nhuman-generated questions over 80 structured documents from 10 different\ncategories of question types for document QA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saad_Falcon_J/0/1/0/all/0/1\">Jon Saad-Falcon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barrow_J/0/1/0/all/0/1\">Joe Barrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siu_A/0/1/0/all/0/1\">Alexa Siu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenkova_A/0/1/0/all/0/1\">Ani Nenkova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"X-PARADE: Cross-Lingual Textual Entailment and Information Divergence across Paragraphs. (arXiv:2309.08873v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08873","description":"<p>Understanding when two pieces of text convey the same information is a goal\ntouching many subproblems in NLP, including textual entailment and\nfact-checking. This problem becomes more complex when those two pieces of text\nare in different languages. Here, we introduce X-PARADE (Cross-lingual\nParagraph-level Analysis of Divergences and Entailments), the first\ncross-lingual dataset of paragraph-level information divergences. Annotators\nlabel a paragraph in a target language at the span level and evaluate it with\nrespect to a corresponding paragraph in a source language, indicating whether a\ngiven piece of information is the same, new, or new but can be inferred. This\nlast notion establishes a link with cross-language NLI. Aligned paragraphs are\nsourced from Wikipedia pages in different languages, reflecting real\ninformation divergences observed in the wild. Armed with our dataset, we\ninvestigate a diverse set of approaches for this problem, including classic\ntoken alignment from machine translation, textual entailment methods that\nlocalize their decisions, and prompting of large language models. Our results\nshow that these methods vary in their capability to handle inferable\ninformation, but they all fall short of human performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_J/0/1/0/all/0/1\">Juan Diego Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Erk_K/0/1/0/all/0/1\">Katrin Erk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Information Extraction for Text Data with Probability Graph. (arXiv:2309.08879v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08879","description":"<p>In this paper, the problem of semantic information extraction for resource\nconstrained text data transmission is studied. In the considered model, a\nsequence of text data need to be transmitted within a communication\nresource-constrained network, which only allows limited data transmission.\nThus, at the transmitter, the original text data is extracted with natural\nlanguage processing techniques. Then, the extracted semantic information is\ncaptured in a knowledge graph. An additional probability dimension is\nintroduced in this graph to capture the importance of each information. This\nsemantic information extraction problem is posed as an optimization framework\nwhose goal is to extract most important semantic information for transmission.\nTo find an optimal solution for this problem, a Floyd's algorithm based\nsolution coupled with an efficient sorting mechanism is proposed. Numerical\nresults testify the effectiveness of the proposed algorithm with regards to two\nnovel performance metrics including semantic uncertainty and semantic\nsimilarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zhouxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhaohui Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Ye Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1\">Licheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaoyang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and Nationality Bias in Generative Models. (arXiv:2309.08902v1 [cs.CL])","link":"http://arxiv.org/abs/2309.08902","description":"<p>LLMs are increasingly powerful and widely used to assist users in a variety\nof tasks. This use risks the introduction of LLM biases to consequential\ndecisions such as job hiring, human performance evaluation, and criminal\nsentencing. Bias in NLP systems along the lines of gender and ethnicity has\nbeen widely studied, especially for specific stereotypes (e.g., Asians are good\nat math). In this paper, we investigate bias along less studied, but still\nconsequential, dimensions, such as age and beauty, measuring subtler correlated\ndecisions that LLMs (specially autoregressive language models) make between\nsocial groups and unrelated positive and negative attributes. We ask whether\nLLMs hold wide-reaching biases of positive or negative sentiment for specific\nsocial groups similar to the ``what is beautiful is good'' bias found in people\nin experimental psychology. We introduce a template-generated dataset of\nsentence completion tasks that asks the model to select the most appropriate\nattribute to complete an evaluative statement about a person described as a\nmember of a specific social group. We also reverse the completion task to\nselect the social group based on an attribute. Finally, we report the\ncorrelations that we find for multiple cutting-edge LLMs. This dataset can be\nused as a benchmark to evaluate progress in more generalized biases and the\ntemplating technique can be used to expand the benchmark with minimal\nadditional human annotation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamruzzaman_M/0/1/0/all/0/1\">Mahammed Kamruzzaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shovon_M/0/1/0/all/0/1\">Md. Minul Islam Shovon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gene Louis Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Statistical Turing Test for Generative Models. (arXiv:2309.08913v1 [cs.AI])","link":"http://arxiv.org/abs/2309.08913","description":"<p>The emergence of human-like abilities of AI systems for content generation in\ndomains such as text, audio, and vision has prompted the development of\nclassifiers to determine whether content originated from a human or a machine.\nImplicit in these efforts is an assumption that the generation properties of a\nhuman are different from that of the machine. In this work, we provide a\nframework in the language of statistical pattern recognition that quantifies\nthe difference between the distributions of human and machine-generated content\nconditioned on an evaluation context. We describe current methods in the\ncontext of the framework and demonstrate how to use the framework to evaluate\nthe progression of generative models towards human-like capabilities, among\nmany axes of analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Helm_H/0/1/0/all/0/1\">Hayden Helm</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Priebe_C/0/1/0/all/0/1\">Carey E. Priebe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiwei Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sameness Entices, but Novelty Enchants in Fanfiction Online. (arXiv:1904.07741v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1904.07741","description":"<p>Cultural evolution is driven by how we choose what to consume and share with\nothers. A common belief is that the cultural artifacts that succeed are ones\nthat balance novelty and conventionality. This balance theory suggests that\npeople prefer works that are familiar, but not so familiar as to be boring;\nnovel, but not so novel as to violate the expectations of their genre. We test\nthis idea using a large dataset of fanfiction. We apply a multiple regression\nmodel and a generalized additive model to examine how the recognition a work\nreceives varies with its novelty, estimated through a Latent Dirichlet\nAllocation topic model, in the context of existing works. We find the opposite\npattern of what the balance theory predicts$\\unicode{x2014}$overall success\ndecline almost monotonically with novelty and exhibits a U-shaped, instead of\nan inverse U-shaped, curve. This puzzle is resolved by teasing out two\ncompeting forces: sameness attracts the mass whereas novelty provides\nenjoyment. Taken together, even though the balance theory holds in terms of\nexpressed enjoyment, the overall success can show the opposite pattern due to\nthe dominant role of sameness to attract the audience. Under these two forces,\ncultural evolution may have to work against inertia$\\unicode{x2014}$the\nappetite for consuming the familiar$\\unicode{x2014}$and may resemble a\npunctuated equilibrium, marked by occasional leaps.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jing_E/0/1/0/all/0/1\">Elise Jing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeDeo_S/0/1/0/all/0/1\">Simon DeDeo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wright_D/0/1/0/all/0/1\">Devin Robert Wright</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_Y/0/1/0/all/0/1\">Yong-Yeol Ahn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction. (arXiv:2104.07650v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.07650","description":"<p>Recently, prompt-tuning has achieved promising results for specific few-shot\nclassification tasks. The core idea of prompt-tuning is to insert text pieces\n(i.e., templates) into the input and transform a classification task into a\nmasked language modeling problem. However, for relation extraction, determining\nan appropriate prompt template requires domain expertise, and it is cumbersome\nand time-consuming to obtain a suitable label word. Furthermore, there exists\nabundant semantic and prior knowledge among the relation labels that cannot be\nignored. To this end, we focus on incorporating knowledge among relation labels\ninto prompt-tuning for relation extraction and propose a Knowledge-aware\nPrompt-tuning approach with synergistic optimization (KnowPrompt).\nSpecifically, we inject latent knowledge contained in relation labels into\nprompt construction with learnable virtual type words and answer words. Then,\nwe synergistically optimize their representation with structured constraints.\nExtensive experimental results on five datasets with standard and low-resource\nsettings demonstrate the effectiveness of our approach. Our code and datasets\nare available in https://github.com/zjunlp/KnowPrompt for reproducibility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentiment Analysis and Effect of COVID-19 Pandemic using College SubReddit Data. (arXiv:2112.04351v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.04351","description":"<p>Background: The COVID-19 pandemic has affected our society and human\nwell-being in various ways. In this study, we investigate how the pandemic has\ninfluenced people's emotions and psychological states compared to a\npre-pandemic period using real-world data from social media.\n</p>\n<p>Method: We collected Reddit social media data from 2019 (pre-pandemic) and\n2020 (pandemic) from the subreddits communities associated with eight\nuniversities. We applied the pre-trained Robustly Optimized BERT pre-training\napproach (RoBERTa) to learn text embedding from the Reddit messages, and\nleveraged the relational information among posted messages to train a graph\nattention network (GAT) for sentiment classification. Finally, we applied model\nstacking to combine the prediction probabilities from RoBERTa and GAT to yield\nthe final classification on sentiment. With the model-predicted sentiment\nlabels on the collected data, we used a generalized linear mixed-effects model\nto estimate the effects of pandemic and in-person teaching during the pandemic\non sentiment.\n</p>\n<p>Results: The results suggest that the odds of negative sentiments in 2020\n(pandemic) were 25.7% higher than the odds in 2019 (pre-pandemic) with a\n$p$-value $&lt;0.001$; and the odds of negative sentiments associated in-person\nlearning were 48.3% higher than with remote learning in 2020 with a $p$-value\nof 0.029.\n</p>\n<p>Conclusions: Our study results are consistent with the findings in the\nliterature on the negative impacts of the pandemic on people's emotions and\npsychological states. Our study contributes to the growing real-world evidence\non the various negative impacts of the pandemic on our society; it also\nprovides a good example of using both ML techniques and statistical modeling\nand inference to make better use of real-world data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1\">Tian Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population. (arXiv:2201.03335v6 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.03335","description":"<p>We present an open-source and extensible knowledge extraction toolkit DeepKE,\nsupporting complicated low-resource, document-level and multimodal scenarios in\nthe knowledge base population. DeepKE implements various information extraction\ntasks, including named entity recognition, relation extraction and attribute\nextraction. With a unified framework, DeepKE allows developers and researchers\nto customize datasets and models to extract information from unstructured data\naccording to their requirements. Specifically, DeepKE not only provides various\nfunctional modules and model implementation for different tasks and scenarios\nbut also organizes all components by consistent frameworks to maintain\nsufficient modularity and extensibility. We release the source code at GitHub\nin https://github.com/zjunlp/DeepKE with Google Colab tutorials and\ncomprehensive documents for beginners. Besides, we present an online system in\n<a href=\"http://deepke.openkg.cn/EN/re_doc_show.html\">this http URL</a> for real-time extraction of various\ntasks, and a demo video.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1\">Liankuan Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haiyang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hongbin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoubo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaozhuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_F/0/1/0/all/0/1\">Feiyu Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guozhou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empowering Fake-News Mitigation: Insights from Sharers' Social Media Post-Histories. (arXiv:2203.10560v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2203.10560","description":"<p>Misinformation is a global concern and limiting its spread is critical for\nprotecting democracy, public health, and consumers. We propose that consumers'\nown social media post-histories are an underutilized data source to study what\nleads them to share links to fake-news. In Study 1, we explore how textual cues\nextracted from post-histories distinguish fake-news sharers from random social\nmedia users and others in the misinformation ecosystem. Among other results, we\nfind across two datasets that fake-news sharers use more words related to\nanger, religion and power. In Study 2, we show that adding textual cues from\npost-histories improves the accuracy of models to predict who is likely to\nshare fake-news. In Study 3, we provide a preliminary test of two mitigation\nstrategies deduced from Study 1 - activating religious values and reducing\nanger - and find that they reduce fake-news sharing and sharing more generally.\nIn Study 4, we combine survey responses with users' verified Twitter\npost-histories and show that using empowering language in a fact-checking\nbrowser extension ad increases download intentions. Our research encourages\nmarketers, misinformation scholars, and practitioners to use post-histories to\ndevelop theories and test interventions to reduce the spread of misinformation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schoenmueller_V/0/1/0/all/0/1\">Verena Schoenmueller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanchard_S/0/1/0/all/0/1\">Simon J. Blanchard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johar_G/0/1/0/all/0/1\">Gita V. Johar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion. (arXiv:2205.02357v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.02357","description":"<p>Multimodal Knowledge Graphs (MKGs), which organize visual-text factual\nknowledge, have recently been successfully applied to tasks such as information\nretrieval, question answering, and recommendation system. Since most MKGs are\nfar from complete, extensive knowledge graph completion studies have been\nproposed focusing on the multimodal entity, relation extraction and link\nprediction. However, different tasks and modalities require changes to the\nmodel architecture, and not all images/objects are relevant to text input,\nwhich hinders the applicability to diverse real-world scenarios. In this paper,\nwe propose a hybrid transformer with multi-level fusion to address those\nissues. Specifically, we leverage a hybrid transformer architecture with\nunified input-output for diverse multimodal knowledge graph completion tasks.\nMoreover, we propose multi-level fusion, which integrates visual and text\nrepresentation via coarse-grained prefix-guided interaction and fine-grained\ncorrelation-aware fusion modules. We conduct extensive experiments to validate\nthat our MKGformer can obtain SOTA performance on four datasets of multimodal\nlink prediction, multimodal RE, and multimodal NER. Code is available in\nhttps://github.com/zjunlp/MKGformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Changliang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The expected sum of edge lengths in planar linearizations of trees. Theory and applications. (arXiv:2207.05564v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.05564","description":"<p>Dependency trees have proven to be a very successful model to represent the\nsyntactic structure of sentences of human languages. In these structures,\nvertices are words and edges connect syntactically-dependent words. The\ntendency of these dependencies to be short has been demonstrated using random\nbaselines for the sum of the lengths of the edges or its variants. A ubiquitous\nbaseline is the expected sum in projective orderings (wherein edges do not\ncross and the root word of the sentence is not covered by any edge), that can\nbe computed in time $O(n)$. Here we focus on a weaker formal constraint, namely\nplanarity. In the theoretical domain, we present a characterization of\nplanarity that, given a sentence, yields either the number of planar\npermutations or an efficient algorithm to generate uniformly random planar\npermutations of the words. We also show the relationship between the expected\nsum in planar arrangements and the expected sum in projective arrangements. In\nthe domain of applications, we derive a $O(n)$-time algorithm to calculate the\nexpected value of the sum of edge lengths. We also apply this research to a\nparallel corpus and find that the gap between actual dependency distance and\nthe random baseline reduces as the strength of the formal constraint on\ndependency structures increases, suggesting that formal constraints absorb part\nof the dependency distance minimization effect. Our research paves the way for\nreplicating past research on dependency distance minimization using random\nplanar linearizations as random baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alemany_Puig_L/0/1/0/all/0/1\">Llu&#xed;s Alemany-Puig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1\">Ramon Ferrer-i-Cancho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Temporal Analysis on Topics Using Word2Vec. (arXiv:2209.11717v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.11717","description":"<p>The present study proposes a novel method of trend detection and\nvisualization - more specifically, modeling the change in a topic over time.\nWhere current models used for the identification and visualization of trends\nonly convey the popularity of a singular word based on stochastic counting of\nusage, the approach in the present study illustrates the popularity and\ndirection that a topic is moving in. The direction in this case is a distinct\nsubtopic within the selected corpus. Such trends are generated by modeling the\nmovement of a topic by using k-means clustering and cosine similarity to group\nthe distances between clusters over time. In a convergent scenario, it can be\ninferred that the topics as a whole are meshing (tokens between topics,\nbecoming interchangeable). On the contrary, a divergent scenario would imply\nthat each topics' respective tokens would not be found in the same context (the\nwords are increasingly different to each other). The methodology was tested on\na group of articles from various media houses present in the 20 Newsgroups\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sandhu_A/0/1/0/all/0/1\">Angad Sandhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edara_A/0/1/0/all/0/1\">Aneesh Edara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayan_V/0/1/0/all/0/1\">Vishesh Narayan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wajid_F/0/1/0/all/0/1\">Faizan Wajid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawala_A/0/1/0/all/0/1\">Ashok Agrawala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study. (arXiv:2210.10678v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10678","description":"<p>This paper presents an empirical study to build relation extraction systems\nin low-resource settings. Based upon recent pre-trained language models, we\ncomprehensively investigate three schemes to evaluate the performance in\nlow-resource settings: (i) different types of prompt-based methods with\nfew-shot labeled data; (ii) diverse balancing methods to address the\nlong-tailed distribution issue; (iii) data augmentation technologies and\nself-training to generate more labeled in-domain data. We create a benchmark\nwith 8 relation extraction (RE) datasets covering different languages, domains\nand contexts and perform extensive comparisons over the proposed schemes with\ncombinations. Our experiments illustrate: (i) Though prompt-based tuning is\nbeneficial in low-resource RE, there is still much potential for improvement,\nespecially in extracting relations from cross-sentence contexts with multiple\nrelational triples; (ii) Balancing methods are not always helpful for RE with\nlong-tailed distribution; (iii) Data augmentation complements existing\nbaselines and can bring much performance gain, while self-training may not\nconsistently achieve advancement to low-resource RE. Code and datasets are in\nhttps://github.com/zjunlp/LREBench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Schema-aware Reference as Prompt Improves Data-Efficient Knowledge Graph Construction. (arXiv:2210.10709v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10709","description":"<p>With the development of pre-trained language models, many prompt-based\napproaches to data-efficient knowledge graph construction have been proposed\nand achieved impressive performance. However, existing prompt-based learning\nmethods for knowledge graph construction are still susceptible to several\npotential limitations: (i) semantic gap between natural language and output\nstructured knowledge with pre-defined schema, which means model cannot fully\nexploit semantic knowledge with the constrained templates; (ii) representation\nlearning with locally individual instances limits the performance given the\ninsufficient features, which are unable to unleash the potential analogical\ncapability of pre-trained language models. Motivated by these observations, we\npropose a retrieval-augmented approach, which retrieves schema-aware Reference\nAs Prompt (RAP), for data-efficient knowledge graph construction. It can\ndynamically leverage schema and knowledge inherited from human-annotated and\nweak-supervised data as a prompt for each sample, which is model-agnostic and\ncan be plugged into widespread existing approaches. Experimental results\ndemonstrate that previous methods integrated with RAP can achieve impressive\nperformance gains in low-resource settings on five datasets of relational\ntriple extraction and event extraction for knowledge graph construction. Code\nis available in https://github.com/zjunlp/RAP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shengyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Knowledge Graph Construction: A Review. (arXiv:2210.12714v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.12714","description":"<p>Generative Knowledge Graph Construction (KGC) refers to those methods that\nleverage the sequence-to-sequence framework for building knowledge graphs,\nwhich is flexible and can be adapted to widespread tasks. In this study, we\nsummarize the recent compelling progress in generative knowledge graph\nconstruction. We present the advantages and weaknesses of each paradigm in\nterms of different generation targets and provide theoretical insight and\nempirical analysis. Based on the review, we suggest promising research\ndirections for the future. Our contributions are threefold: (1) We present a\ndetailed, complete taxonomy for the generative KGC methods; (2) We provide a\ntheoretical and empirical analysis of the generative KGC methods; (3) We\npropose several research directions that can be developed in the future.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1\">Hongbin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VRDU: A Benchmark for Visually-rich Document Understanding. (arXiv:2211.15421v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.15421","description":"<p>Understanding visually-rich business documents to extract structured data and\nautomate business workflows has been receiving attention both in academia and\nindustry. Although recent multi-modal language models have achieved impressive\nresults, we find that existing benchmarks do not reflect the complexity of real\ndocuments seen in industry. In this work, we identify the desiderata for a more\ncomprehensive benchmark and propose one we call Visually Rich Document\nUnderstanding (VRDU). VRDU contains two datasets that represent several\nchallenges: rich schema including diverse data types as well as hierarchical\nentities, complex templates including tables and multi-column layouts, and\ndiversity of different layouts (templates) within a single document type. We\ndesign few-shot and conventional experiment settings along with a carefully\ndesigned matching algorithm to evaluate extraction results. We report the\nperformance of strong baselines and offer three observations: (1) generalizing\nto new document templates is still very challenging, (2) few-shot performance\nhas a lot of headroom, and (3) models struggle with hierarchical fields such as\nline-items in an invoice. We plan to open source the benchmark and the\nevaluation toolkit. We hope this helps the community make progress on these\nchallenging tasks in extracting structured data from visually rich documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yichao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chen-Yu Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tata_S/0/1/0/all/0/1\">Sandeep Tata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v8 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09597","description":"<p>Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions. Resources are\navailable at https://github.com/zjunlp/Prompt4ReasoningPapers (updated\nperiodically).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER. (arXiv:2301.10410v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10410","description":"<p>Cross-domain NER is a challenging task to address the low-resource problem in\npractical scenarios. Previous typical solutions mainly obtain a NER model by\npre-trained language models (PLMs) with data from a rich-resource domain and\nadapt it to the target domain. Owing to the mismatch issue among entity types\nin different domains, previous approaches normally tune all parameters of PLMs,\nending up with an entirely new NER model for each domain. Moreover, current\nmodels only focus on leveraging knowledge in one general source domain while\nfailing to successfully transfer knowledge from multiple sources to the target.\nTo address these issues, we introduce Collaborative Domain-Prefix Tuning for\ncross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically,\nwe present text-to-text generation grounding domain-related instructors to\ntransfer knowledge to new domain NER tasks without structural modifications. We\nutilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate\nthe potential of PLMs to handle NER tasks across various domains. Experimental\nresults on the Cross-NER benchmark show that the proposed approach has flexible\ntransfer ability and performs better on both one-source and multiple-source\ncross-domain NER tasks. Codes are available in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/ner/cross.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets. (arXiv:2301.12139v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.12139","description":"<p>We investigate five English NLP benchmark datasets (on the superGLUE\nleaderboard) and two Swedish datasets for bias, along multiple axes. The\ndatasets are the following: Boolean Question (Boolq), CommitmentBank (CB),\nWinograd Schema Challenge (WSC), Wino-gender diagnostic (AXg), Recognising\nTextual Entailment (RTE), Swedish CB, and SWEDN. Bias can be harmful and it is\nknown to be common in data, which ML models learn from. In order to mitigate\nbias in data, it is crucial to be able to estimate it objectively. We use\nbipol, a novel multi-axes bias metric with explainability, to estimate and\nexplain how much bias exists in these datasets. Multilingual, multi-axes bias\nevaluation is not very common. Hence, we also contribute a new, large Swedish\nbias-labelled dataset (of 2 million samples), translated from the English\nversion and train the SotA mT5 model on it. In addition, we contribute new\nmulti-axes lexica for bias detection in Swedish. We make the codes, model, and\nnew dataset publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adewumi_T/0/1/0/all/0/1\">Tosin Adewumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sodergren_I/0/1/0/all/0/1\">Isabella S&#xf6;dergren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhaled_L/0/1/0/all/0/1\">Lama Alkhaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabry_S/0/1/0/all/0/1\">Sana Sabah Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_F/0/1/0/all/0/1\">Foteini Liwicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings. (arXiv:2302.07729v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.07729","description":"<p>Nowadays many research articles are prefaced with research highlights to\nsummarize the main findings of the paper. Highlights not only help researchers\nprecisely and quickly identify the contributions of a paper, they also enhance\nthe discoverability of the article via search engines. We aim to automatically\nconstruct research highlights given certain segments of a research paper. We\nuse a pointer-generator network with coverage mechanism and a contextual\nembedding layer at the input that encodes the input tokens into SciBERT\nembeddings. We test our model on a benchmark dataset, CSPubSum, and also\npresent MixSub, a new multi-disciplinary corpus of papers for automatic\nresearch highlight generation. For both CSPubSum and MixSub, we have observed\nthat the proposed model achieves the best performance compared to related\nvariants and other models proposed in the literature. On the CSPubSum dataset,\nour model achieves the best performance when the input is only the abstract of\na paper as opposed to other segments of the paper. It produces ROUGE-1, ROUGE-2\nand ROUGE-L F1-scores of 38.26, 14.26 and 35.51, respectively, METEOR score of\n32.62, and BERTScore F1 of 86.65 which outperform all other baselines. On the\nnew MixSub dataset, where only the abstract is the input, our proposed model\n(when trained on the whole training corpus without distinguishing between the\nsubject categories) achieves ROUGE-1, ROUGE-2 and ROUGE-L F1-scores of 31.78,\n9.76 and 29.3, respectively, METEOR score of 24.00, and BERTScore F1 of 85.25.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rehman_T/0/1/0/all/0/1\">Tohida Rehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanyal_D/0/1/0/all/0/1\">Debarshi Kumar Sanyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1\">Samiran Chattopadhyay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhowmick_P/0/1/0/all/0/1\">Plaban Kumar Bhowmick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_P/0/1/0/all/0/1\">Partha Pratim Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"E2E Spoken Entity Extraction for Virtual Agents. (arXiv:2302.10186v6 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2302.10186","description":"<p>This paper rethink some aspects of speech processing using speech encoders,\nspecifically about extracting entities directly from speech, without\nintermediate textual representation. In human-computer conversations,\nextracting entities such as names, street addresses and email addresses from\nspeech is a challenging task. In this paper, we study the impact of fine-tuning\npre-trained speech encoders on extracting spoken entities in human-readable\nform directly from speech without the need for text transcription. We\nillustrate that such a direct approach optimizes the encoder to transcribe only\nthe entity relevant portions of speech ignoring the superfluous portions such\nas carrier phrases, or spell name entities. In the context of dialog from an\nenterprise virtual agent, we demonstrate that the 1-step approach outperforms\nthe typical 2-step approach which first generates lexical transcriptions\nfollowed by text-based entity extraction for identifying spoken entities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Singla_K/0/1/0/all/0/1\">Karan Singla</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kim_Y/0/1/0/all/0/1\">Yeon-Jun Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Use of Large Language Models for Reference-Free Text Quality Evaluation: An Empirical Study. (arXiv:2304.00723v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.00723","description":"<p>Evaluating the quality of generated text is a challenging task in NLP, due to\nthe inherent complexity and diversity of text. Recently, large language models\n(LLMs) have garnered significant attention due to their impressive performance\nin various tasks. Therefore, we present this paper to investigate the\neffectiveness of LLMs, especially ChatGPT, and explore ways to optimize their\nuse in assessing text quality. We compared three kinds of reference-free\nevaluation methods. The experimental results prove that ChatGPT is capable of\nevaluating text quality effectively from various perspectives without reference\nand demonstrates superior performance than most existing automatic metrics. In\nparticular, the Explicit Score, which utilizes ChatGPT to generate a numeric\nscore measuring text quality, is the most effective and reliable method among\nthe three exploited approaches. However, directly comparing the quality of two\ntexts may lead to suboptimal results. We believe this paper will provide\nvaluable insights for evaluating text quality with LLMs and have released the\nused data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haiyun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruifeng Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blockwise Compression of Transformer-based Models without Retraining. (arXiv:2304.01483v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01483","description":"<p>Transformer-based models, exemplified by GPT-3, ChatGPT, and GPT-4, have\nrecently garnered considerable attention in both academia and industry due to\ntheir promising performance in general language tasks. Nevertheless, these\nmodels typically involve computationally encoding processes, and in some cases,\ndecoding processes as well, both of which are fundamentally large-scale matrix\nmultiplication. These operations bring the inevitable challenges of massive\ncomputation resources and huge memory footprint, usually requiring at least\n10^23 FLOPs and hundreds of gigabytes, respectively. A common method to address\nthis issue is to reduce the computational and memory requirements by applying\nlayerwise quantization to the transformer, replacing the usual fp32 data type\nwith a low-bit equivalent. Unfortunately, this method often leads to decreased\nmodel accuracy and necessitates time-consuming retraining. Such retraining not\nonly requires fine-tuning skills but also substantial computational resources,\nposing challenges for users. To specifically tackle these issues, we propose\nBCT, a framework of blockwise compression for transformers without retraining,\naiming to facilitate model deployment. Unlike layerwise compression methods,\nBCT achieves finer compression of the entire transformer by operating\nblockwise. This method mitigates data distribution deviation caused by\nquantization, eliminating the requirement for retraining. BCT effectively\ncompresses all components of the model, including but not limited to the\nembedding, matrix multiplication, GELU, Softmax, layer normalization, and\nintermediate results. In a case study, an efficient model is compressed by BCT\nachieving up to 7.988x compression. Subsequently, we also evaluate it on\nseveral General Language Understanding Evaluation (GLUE) datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1\">Gaochen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bipol: A Novel Multi-Axes Bias Evaluation Metric with Explainability for NLP. (arXiv:2304.04029v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.04029","description":"<p>We introduce bipol, a new metric with explainability, for estimating social\nbias in text data. Harmful bias is prevalent in many online sources of data\nthat are used for training machine learning (ML) models. In a step to address\nthis challenge we create a novel metric that involves a two-step process:\ncorpus-level evaluation based on model classification and sentence-level\nevaluation based on (sensitive) term frequency (TF). After creating new models\nto detect bias along multiple axes using SotA architectures, we evaluate two\npopular NLP datasets (COPA and SQUAD). As additional contribution, we created a\nlarge dataset (with almost 2 million labelled samples) for training models in\nbias detection and make it publicly available. We also make public our codes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alkhaled_L/0/1/0/all/0/1\">Lama Alkhaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adewumi_T/0/1/0/all/0/1\">Tosin Adewumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabry_S/0/1/0/all/0/1\">Sana Sabah Sabry</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models. (arXiv:2304.06364v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.06364","description":"<p>Evaluating the general abilities of foundation models to tackle human-level\ntasks is a vital aspect of their development and application in the pursuit of\nArtificial General Intelligence (AGI). Traditional benchmarks, which rely on\nartificial datasets, may not accurately represent human-level capabilities. In\nthis paper, we introduce AGIEval, a novel benchmark specifically designed to\nassess foundation model in the context of human-centric standardized exams,\nsuch as college entrance exams, law school admission tests, math competitions,\nand lawyer qualification tests. We evaluate several state-of-the-art foundation\nmodels, including GPT-4, ChatGPT, and Text-Davinci-003, using this benchmark.\nImpressively, GPT-4 surpasses average human performance on SAT, LSAT, and math\ncompetitions, attaining a 95% accuracy rate on the SAT Math test and a 92.5%\naccuracy on the English test of the Chinese national college entrance exam.\nThis demonstrates the extraordinary performance of contemporary foundation\nmodels. In contrast, we also find that GPT-4 is less proficient in tasks that\nrequire complex reasoning or specific domain knowledge. Our comprehensive\nanalyses of model capabilities (understanding, knowledge, reasoning, and\ncalculation) reveal these models' strengths and limitations, providing valuable\ninsights into future directions for enhancing their general capabilities. By\nconcentrating on tasks pertinent to human cognition and decision-making, our\nbenchmark delivers a more meaningful and robust evaluation of foundation\nmodels' performance in real-world scenarios. The data, code, and all model\noutputs are released in https://github.com/ruixiangcui/AGIEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_W/0/1/0/all/0/1\">Wanjun Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1\">Ruixiang Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yiduo Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yaobo Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shuai Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saied_A/0/1/0/all/0/1\">Amin Saied</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Human-Human Interactions in Images from Weak Textual Supervision. (arXiv:2304.14104v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.14104","description":"<p>Interactions between humans are diverse and context-dependent, but previous\nworks have treated them as categorical, disregarding the heavy tail of possible\ninteractions. We propose a new paradigm of learning human-human interactions as\nfree text from a single still image, allowing for flexibility in modeling the\nunlimited space of situations and relationships between people. To overcome the\nabsence of data labelled specifically for this task, we use knowledge\ndistillation applied to synthetic caption data produced by a large language\nmodel without explicit supervision. We show that the pseudo-labels produced by\nthis procedure can be used to train a captioning model to effectively\nunderstand human-human interactions in images, as measured by a variety of\nmetrics that measure textual and semantic faithfulness and factual groundedness\nof our predictions. We further show that our approach outperforms SOTA image\ncaptioning and situation recognition models on this task. We will release our\ncode and pseudo-labels along with Waldo and Wenda, a manually-curated test set\nfor still image human-human interaction understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alper_M/0/1/0/all/0/1\">Morris Alper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Averbuch_Elor_H/0/1/0/all/0/1\">Hadar Averbuch-Elor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decouple knowledge from parameters for plug-and-play language modeling. (arXiv:2305.11564v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11564","description":"<p>Pre-trained language models(PLM) have made impressive results in various NLP\ntasks. It has been revealed that one of the key factors to their success is the\nparameters of these models implicitly learn all kinds of knowledge during\npre-training. However, encoding knowledge implicitly in the model parameters\nhas two fundamental drawbacks. First, the knowledge is neither editable nor\nscalable once the model is trained, which is especially problematic in that\nknowledge is consistently evolving. Second, it lacks interpretability and\nprevents humans from understanding which knowledge PLM requires for a certain\nproblem. In this paper, we introduce PlugLM, a pre-training model with\ndifferentiable plug-in memory(DPM). The key intuition is to decouple the\nknowledge storage from model parameters with an editable and scalable key-value\nmemory and leverage knowledge in an explainable manner by knowledge retrieval\nin the DPM. To justify this design choice, we conduct evaluations in three\nsettings including: (1) domain adaptation. PlugLM obtains 3.95 F1 improvements\nacross four domains on average without any in-domain pre-training. (2)\nknowledge update. PlugLM could absorb new knowledge in a training-free way\nafter pre-training is done. (3) in-task knowledge learning. PlugLM could be\nfurther improved by incorporating training samples into DPM with knowledge\nprompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiuying Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models emulate an inductive Thematic Analysis of semi-structured interviews? An exploration and provocation on the limits of the approach and the model. (arXiv:2305.13014v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13014","description":"<p>Large Language Models (LLMs) have emerged as powerful generative Artificial\nIntelligence solutions which can be applied to several fields and areas of\nwork. This paper presents results and reflection of an experiment done to use\nthe model GPT 3.5-Turbo to emulate some aspects of an inductive Thematic\nAnalysis. Previous research on this subject has largely worked on conducting\ndeductive analysis. Thematic Analysis is a qualitative method for analysis\ncommonly used in social sciences and it is based on interpretations made by the\nhuman analyst(s) and the identification of explicit and latent meanings in\nqualitative data. Attempting an analysis based on human interpretation with an\nLLM clearly is a provocation but also a way to learn something about how these\nsystems can or cannot be used in qualitative research. The paper presents the\nmotivations for attempting this emulation, it reflects on how the six steps to\na Thematic Analysis proposed by Braun and Clarke can at least partially be\nreproduced with the LLM and it also reflects on what are the outputs produced\nby the model. The paper used two existing datasets of open access\nsemi-structured interviews, previously analysed with Thematic Analysis by other\nresearchers. It used the previously produced analysis (and the related themes)\nto compare with the results produced by the LLM. The results show that the\nmodel can infer at least partially some of the main Themes. The objective of\nthe paper is not to replace human analysts in qualitative analysis but to learn\nif some elements of LLM data manipulation can to an extent be of support for\nqualitative research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paoli_S/0/1/0/all/0/1\">Stefano De Paoli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13617","description":"<p>Event-centric structured prediction involves predicting structured outputs of\nevents. In most NLP cases, event structures are complex with manifold\ndependency, and it is challenging to effectively represent these complicated\nstructured events. To address these issues, we propose Structured Prediction\nwith Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex\ndependency among event structured components with energy-based modeling, and\nrepresents event classes with simple but effective hyperspheres. Experiments on\ntwo unified-annotated event datasets indicate that SPEECH is predominant in\nevent detection and event-relation extraction tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1\">Shengyu Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Generation through Summarization Duality and Explicit Outline Control. (arXiv:2305.14459v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14459","description":"<p>Automatically open-ended long text generation poses significant challenges\ndue to semantic incoherence and plot implausibility. Previous works usually\nalleviate this problem through outlines in the form of short phrases or\nabstractive signals by designing unsupervised tasks, which tend to be unstable\nand weakly interpretable.\n</p>\n<p>Assuming that a summary serves as a mature outline, we introduce a two-stage,\nsummary-enhanced outline supervised generation framework. This framework\nleverages the dual characteristics of the summarization task to improve outline\nprediction, resulting in more explicit and plausible outlines. Furthermore, we\nidentify an underutilization issue in outline-based generation with both\nstandard pretrained language models (e.g., GPT-2, BART) and large language\nmodels (e.g., Vicuna, ChatGPT). To address this, we propose a novel explicit\noutline control method for more effective utilization of generated outlines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunzhe Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_W/0/1/0/all/0/1\">Weixiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_H/0/1/0/all/0/1\">Hari Sundaram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Psychological Metrics for Dialog System Evaluation. (arXiv:2305.14757v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14757","description":"<p>We present metrics for evaluating dialog systems through a\npsychologically-grounded \"human\" lens in which conversational agents express a\ndiversity of both states (e.g., emotion) and traits (e.g., personality), just\nas people do. We present five interpretable metrics from established psychology\nthat are fundamental to human communication and relationships: emotional\nentropy, linguistic style and emotion matching, agreeableness, and empathy.\nThese metrics can be applied (1) across dialogs and (2) on turns within\ndialogs. The psychological metrics are compared against seven state-of-the-art\ntraditional metrics (e.g., BARTScore and BLEURT) on seven standard dialog\nsystem data sets. We also introduce a novel data set, the Three Bot Dialog\nEvaluation Corpus, which consists of annotated conversations from ChatGPT,\nGPT-3, and BlenderBot. We demonstrate that our proposed metrics offer novel\ninformation; they are uncorrelated with traditional metrics, can be used to\nmeaningfully compare dialog systems, and lead to increased accuracy (beyond\nexisting traditional metrics) in predicting crowd-sourced dialog judgements.\nThe interpretability and unique signal of our psychological metrics make them a\nvaluable tool for evaluating and improving dialog systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_S/0/1/0/all/0/1\">Salvatore Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Havaldar_S/0/1/0/all/0/1\">Shreya Havaldar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1\">Farhan Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_Z/0/1/0/all/0/1\">Zuhaib Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaidya_S/0/1/0/all/0/1\">Shalaka Vaidya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1\">Gary Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1\">Lyle H. Ungar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1\">H. Andrew Schwartz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1\">Joao Sedoc</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Weaker Than You Think: A Critical Look at Weakly Supervised Learning. (arXiv:2305.17442v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17442","description":"<p>Weakly supervised learning is a popular approach for training machine\nlearning models in low-resource settings. Instead of requesting high-quality\nyet costly human annotations, it allows training models with noisy annotations\nobtained from various weak sources. Recently, many sophisticated approaches\nhave been proposed for robust training under label noise, reporting impressive\nresults. In this paper, we revisit the setup of these approaches and find that\nthe benefits brought by these approaches are significantly overestimated.\nSpecifically, we find that the success of existing weakly supervised learning\napproaches heavily relies on the availability of clean validation samples\nwhich, as we show, can be leveraged much more efficiently by simply training on\nthem. After using these clean labels in training, the advantages of using these\nsophisticated approaches are mostly wiped out. This remains true even when\nreducing the size of the available clean data to just five samples per class,\nmaking these approaches impractical. To understand the true value of weakly\nsupervised learning, we thoroughly analyze diverse NLP datasets and tasks to\nascertain when and why weakly supervised approaches work. Based on our\nfindings, we provide recommendations for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dawei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mosbach_M/0/1/0/all/0/1\">Marius Mosbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stephan_A/0/1/0/all/0/1\">Andreas Stephan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1\">Dietrich Klakow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMatic: Neural Architecture Search via Large Language Models and Quality Diversity Optimization. (arXiv:2306.01102v4 [cs.NE] UPDATED)","link":"http://arxiv.org/abs/2306.01102","description":"<p>Large Language Models (LLMs) have emerged as powerful tools capable of\naccomplishing a broad spectrum of tasks. Their abilities span numerous areas,\nand one area where they have made a significant impact is in the domain of code\ngeneration. In this context, we view LLMs as mutation and crossover tools.\nMeanwhile, Quality-Diversity (QD) algorithms are known to discover diverse and\nrobust solutions. By merging the code-generating abilities of LLMs with the\ndiversity and robustness of QD solutions, we introduce LLMatic, a Neural\nArchitecture Search (NAS) algorithm. While LLMs struggle to conduct NAS\ndirectly through prompts, LLMatic uses a procedural approach, leveraging QD for\nprompts and network architecture to create diverse and highly performant\nnetworks. We test LLMatic on the CIFAR-10 image classification benchmark,\ndemonstrating that it can produce competitive networks with just $2,000$\nsearches, even without prior knowledge of the benchmark domain or exposure to\nany previous top-performing models for the benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nasir_M/0/1/0/all/0/1\">Muhammad U. Nasir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Earle_S/0/1/0/all/0/1\">Sam Earle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1\">Julian Togelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1\">Steven James</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cleghorn_C/0/1/0/all/0/1\">Christopher Cleghorn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unified model for code-switching speech recognition and language identification based on a concatenated tokenizer. (arXiv:2306.08753v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2306.08753","description":"<p>Code-Switching (CS) multilingual Automatic Speech Recognition (ASR) models\ncan transcribe speech containing two or more alternating languages during a\nconversation. This paper proposes (1) a new method for creating code-switching\nASR datasets from purely monolingual data sources, and (2) a novel Concatenated\nTokenizer that enables ASR models to generate language ID for each emitted text\ntoken while reusing existing monolingual tokenizers. The efficacy of these\napproaches for building CS ASR models is demonstrated for two language pairs,\nEnglish-Hindi and English-Spanish, where we achieve new state-of-the-art\nresults on the Miami Bangor CS evaluation corpus. In addition to competitive\nASR performance, the proposed Concatenated Tokenizer models are highly\neffective for spoken language identification, achieving 98%+ accuracy on the\nout-of-distribution FLEURS dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Dhawan_K/0/1/0/all/0/1\">Kunal Dhawan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Rekesh_D/0/1/0/all/0/1\">Dima Rekesh</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ginsburg_B/0/1/0/all/0/1\">Boris Ginsburg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Text Embedding Space Generation Using Generative Adversarial Networks for Text Synthesis. (arXiv:2306.17181v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17181","description":"<p>Generative Adversarial Networks (GAN) is a model for data synthesis, which\ncreates plausible data through the competition of generator and discriminator.\nAlthough GAN application to image synthesis is extensively studied, it has\ninherent limitations to natural language generation. Because natural language\nis composed of discrete tokens, a generator has difficulty updating its\ngradient through backpropagation; therefore, most text-GAN studies generate\nsentences starting with a random token based on a reward system. Thus, the\ngenerators of previous studies are pre-trained in an autoregressive way before\nadversarial training, causing data memorization that synthesized sentences\nreproduce the training data. In this paper, we synthesize sentences using a\nframework similar to the original GAN. More specifically, we propose Text\nEmbedding Space Generative Adversarial Networks (TESGAN) which generate\ncontinuous text embedding spaces instead of discrete tokens to solve the\ngradient backpropagation problem. Furthermore, TESGAN conducts unsupervised\nlearning which does not directly refer to the text of the training data to\novercome the data memorization issue. By adopting this novel method, TESGAN can\nsynthesize new sentences, showing the potential of unsupervised learning for\ntext synthesis. We expect to see extended research combining Large Language\nModels with a new perspective of viewing text as an continuous space.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jun-Min Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_T/0/1/0/all/0/1\">Tae-Bin Ha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved NL2SQL based on Multi-layer Expert Network. (arXiv:2306.17727v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17727","description":"<p>The Natural Language to SQL (NL2SQL) technique is used to convert natural\nlanguage queries into executable SQL statements. Typically, slot-filling is\nemployed as a classification method for multi-task cases to achieve this goal.\nHowever, slot-filling can result in inaccurate SQL statement generation due to\nnegative migration issues arising from different classification tasks. To\novercome this limitation, this study introduces a new approach called\nMulti-Layer Expert Generate SQL (MLEG-SQL), which utilizes a dedicated\nmulti-task hierarchical network. The lower layer of the network extracts\nsemantic features of natural language statements, while the upper layer builds\na specialized expert system for handling specific classification tasks. This\nhierarchical approach mitigates performance degradation resulting from\ndifferent task conflicts. The proposed method was evaluated on the WiKSQL\ndataset and was found to be effective in generating accurate SQL statements.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_C/0/1/0/all/0/1\">Chenduo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"vONTSS: vMF based semi-supervised neural topic modeling with optimal transport. (arXiv:2307.01226v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.01226","description":"<p>Recently, Neural Topic Models (NTM), inspired by variational autoencoders,\nhave attracted a lot of research interest; however, these methods have limited\napplications in the real world due to the challenge of incorporating human\nknowledge. This work presents a semi-supervised neural topic modeling method,\nvONTSS, which uses von Mises-Fisher (vMF) based variational autoencoders and\noptimal transport. When a few keywords per topic are provided, vONTSS in the\nsemi-supervised setting generates potential topics and optimizes topic-keyword\nquality and topic classification. Experiments show that vONTSS outperforms\nexisting semi-supervised topic modeling methods in classification accuracy and\ndiversity. vONTSS also supports unsupervised topic modeling. Quantitative and\nqualitative experiments show that vONTSS in the unsupervised setting\noutperforms recent NTMs on multiple aspects: vONTSS discovers highly clustered\nand coherent topics on benchmark datasets. It is also much faster than the\nstate-of-the-art weakly supervised text classification method while achieving\nsimilar classification performance. We further prove the equivalence of optimal\ntransport loss and cross-entropy loss at the global minimum.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weijie Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaoyu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sengamedu_S/0/1/0/all/0/1\">Srinivasan H. Sengamedu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iannacci_F/0/1/0/all/0/1\">Francis Iannacci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jinjin Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Founding a mathematical diffusion model in linguistics. The case study of German syntactic features in the North-Eastern Italian dialects. (arXiv:2307.14291v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.14291","description":"<p>The initial motivation for this work was the linguistic case of the spread of\nGermanic syntactic features into Romance dialects of North-Eastern Italy, which\noccurred after the immigration of German people to Tyrol during the High Middle\nAges. To obtain a representation of the data over the territory suitable for a\nmathematical formulation, an interactive map is produced as a first step, using\ntools of what is called Geographic Data Science. A smooth two-dimensional\nsurface G is introduced, expressing locally which fraction of territory uses a\ngiven German language feature: it is obtained by a piecewise cubic curvature\nminimizing interpolant of the discrete function that says if at any surveyed\nlocality that feature is used or not. This surface G is thought of as the value\nat the present time of a function describing a diffusion-convection phenomenon\nin two dimensions (here said tidal mode), which is subjected in a very natural\nway to the same equation used in physics, introducing a contextual diffusivity\nconcept: it is shown that with two different assumptions about diffusivity,\nsolutions of this equation, evaluated at the present time, fit well with the\ndata interpolated by G, thus providing two convincing different pictures of\ndiffusion-convection in the case under study, albeit simplifications and\napproximations. Very importantly, it is shown that the linguistic diffusion\nmodel known to linguists as Schmidt waves can be counted among the solutions of\nthe diffusion equation\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lazzizzera_I/0/1/0/all/0/1\">I. Lazzizzera</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data. (arXiv:2307.14385v3 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2307.14385","description":"<p>Advances in large language models (LLMs) have empowered a variety of\napplications. However, there is still a significant gap in research when it\ncomes to understanding and enhancing the capabilities of LLMs in the field of\nmental health. In this work, we present the first comprehensive evaluation of\nmultiple LLMs, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4, on\nvarious mental health prediction tasks via online text data. We conduct a broad\nrange of experiments, covering zero-shot prompting, few-shot prompting, and\ninstruction fine-tuning. The results indicate a promising yet limited\nperformance of LLMs with zero-shot and few-shot prompt designs for the mental\nhealth tasks. More importantly, our experiments show that instruction\nfinetuning can significantly boost the performance of LLMs for all tasks\nsimultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5,\noutperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9%\non balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%.\nThey further perform on par with the state-of-the-art task-specific language\nmodel. We also conduct an exploratory case study on LLMs' capability on the\nmental health reasoning tasks, illustrating the promising capability of certain\nmodels such as GPT-4. We summarize our findings into a set of action guidelines\nfor potential methods to enhance LLMs' capability for mental health tasks.\nMeanwhile, we also emphasize the important limitations before achieving\ndeployability in real-world mental health settings, such as known racial and\ngender bias. We highlight the important ethical risks accompanying this line of\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xuhai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1\">Bingsheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuanzhe Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabriel_S/0/1/0/all/0/1\">Saadia Gabriel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendler_J/0/1/0/all/0/1\">James Hendler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1\">Marzyeh Ghassemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dey_A/0/1/0/all/0/1\">Anind K. Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dakuo Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities. (arXiv:2308.04992v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.04992","description":"<p>Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text\nand image) for a comprehensive understanding of entities. Despite the recent\nprogress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature\nof entities, limiting the ability to comprehend entities from various\nperspectives. In this paper, we construct AspectMMKG, the first MMKG with\naspect-related images by matching images to different entity aspects.\nSpecifically, we collect aspect-related images from a knowledge base, and\nfurther extract aspect-related sentences from the knowledge base as queries to\nretrieve a large number of aspect-related images via an online image search\nengine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and\n645,383 aspect-related images. We demonstrate the usability of AspectMMKG in\nentity aspect linking (EAL) downstream task and show that previous EAL models\nachieve a new state-of-the-art performance with the help of AspectMMKG. To\nfacilitate the research on aspect-related MMKG, we further propose an\naspect-related image retrieval (AIR) model, that aims to correct and expand\naspect-related images in AspectMMKG. We train an AIR model to learn the\nrelationship between entity image and entity aspect-related images by\nincorporating entity image, aspect, and aspect image information. Experimental\nresults indicate that the AIR model could retrieve suitable images for a given\nentity w.r.t different aspects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingdan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaodan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhixu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Modeling the Dashboard Provenance. (arXiv:2308.06788v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2308.06788","description":"<p>Organizations of all kinds, whether public or private, profit-driven or\nnon-profit, and across various industries and sectors, rely on dashboards for\neffective data visualization. However, the reliability and efficacy of these\ndashboards rely on the quality of the visual and data they present. Studies\nshow that less than a quarter of dashboards provide information about their\nsources, which is just one of the expected metadata when provenance is\nseriously considered. Provenance is a record that describes people,\norganizations, entities, and activities that had a role in the production,\ninfluence, or delivery of a piece of data or an object. This paper aims to\nprovide a provenance representation model, that entitles standardization,\nmodeling, generation, capture, and visualization, specifically designed for\ndashboards and its visual and data components. The proposed model will offer a\ncomprehensive set of essential provenance metadata that enables users to\nevaluate the quality, consistency, and reliability of the information presented\non dashboards. This will allow a clear and precise understanding of the context\nin which a specific dashboard was developed, ultimately leading to better\ndecision-making.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jarske_J/0/1/0/all/0/1\">Johne Jarske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rady_J/0/1/0/all/0/1\">Jorge Rady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Filgueiras_L/0/1/0/all/0/1\">Lucia V. L. Filgueiras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velloso_L/0/1/0/all/0/1\">Leandro M. Velloso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_T/0/1/0/all/0/1\">Tania L. Santos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Model Compression for Large Language Models. (arXiv:2308.07633v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07633","description":"<p>Large Language Models (LLMs) have revolutionized natural language processing\ntasks with remarkable success. However, their formidable size and computational\ndemands present significant challenges for practical deployment, especially in\nresource-constrained environments. As these challenges become increasingly\npertinent, the field of model compression has emerged as a pivotal research\narea to alleviate these limitations. This paper presents a comprehensive survey\nthat navigates the landscape of model compression techniques tailored\nspecifically for LLMs. Addressing the imperative need for efficient deployment,\nwe delve into various methodologies, encompassing quantization, pruning,\nknowledge distillation, and more. Within each of these techniques, we highlight\nrecent advancements and innovative approaches that contribute to the evolving\nlandscape of LLM research. Furthermore, we explore benchmarking strategies and\nevaluation metrics that are essential for assessing the effectiveness of\ncompressed LLMs. By providing insights into the latest developments and\npractical implications, this survey serves as an invaluable resource for both\nresearchers and practitioners. As LLMs continue to evolve, this survey aims to\nfacilitate enhanced efficiency and real-world applicability, establishing a\nfoundation for future advancements in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xunyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Can Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Benchmarking (of Language Models). (arXiv:2308.11696v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.11696","description":"<p>The increasing versatility of language models LMs has given rise to a new\nclass of benchmarks that comprehensively assess a broad range of capabilities.\nSuch benchmarks are associated with massive computational costs reaching\nthousands of GPU hours per model. However the efficiency aspect of these\nevaluation efforts had raised little discussion in the literature. In this work\nwe present the problem of Efficient Benchmarking namely intelligently reducing\nthe computation costs of LM evaluation without compromising reliability. Using\nthe HELM benchmark as a test case we investigate how different benchmark design\nchoices affect the computation-reliability tradeoff. We propose to evaluate the\nreliability of such decisions by using a new measure Decision Impact on\nReliability DIoR for short. We find for example that the current leader on HELM\nmay change by merely removing a low-ranked model from the benchmark and observe\nthat a handful of examples suffice to obtain the correct benchmark ranking.\nConversely a slightly different choice of HELM scenarios varies ranking widely.\nBased on our findings we outline a set of concrete recommendations for more\nefficient benchmark design and utilization practices leading to dramatic cost\nsavings with minimal loss of benchmark reliability often reducing computation\nby x100 or more.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perlitz_Y/0/1/0/all/0/1\">Yotam Perlitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bandel_E/0/1/0/all/0/1\">Elron Bandel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gera_A/0/1/0/all/0/1\">Ariel Gera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arviv_O/0/1/0/all/0/1\">Ofir Arviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ein_Dor_L/0/1/0/all/0/1\">Liat Ein-Dor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shnarch_E/0/1/0/all/0/1\">Eyal Shnarch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slonim_N/0/1/0/all/0/1\">Noam Slonim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shmueli_Scheuer_M/0/1/0/all/0/1\">Michal Shmueli-Scheuer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1\">Leshem Choshen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Quantity to Quality: Boosting LLM Performance with Self-Guided Data Selection for Instruction Tuning. (arXiv:2308.12032v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.12032","description":"<p>In the realm of Large Language Models, the balance between instruction data\nquality and quantity has become a focal point. Recognizing this, we introduce a\nself-guided methodology for LLMs to autonomously discern and select cherry\nsamples from vast open-source datasets, effectively minimizing manual curation\nand potential cost for instruction tuning an LLM. Our key innovation, the\nInstruction-Following Difficulty (IFD) metric, emerges as a pivotal tool to\nidentify discrepancies between a model's expected responses and its autonomous\ngeneration prowess. Through the adept application of IFD, cherry samples are\npinpointed, leading to a marked uptick in model training efficiency. Empirical\nvalidations on renowned datasets like Alpaca and WizardLM underpin our\nfindings; with a mere 10% of conventional data input, our strategy showcases\nimproved results. This synthesis of self-guided cherry-picking and the IFD\nmetric signifies a transformative leap in the optimization of LLMs, promising\nboth efficiency and resource-conscious advancements. Codes, data, and models\nare available: https://github.com/MingLiiii/Cherry_LLM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Ming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhitao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiuhai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lichang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1\">Ning Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianzong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1\">Jing Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLaSM: Large Language and Speech Model. (arXiv:2308.15930v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.15930","description":"<p>Multi-modal large language models have garnered significant interest\nrecently. Though, most of the works focus on vision-language multi-modal models\nproviding strong capabilities in following vision-and-language instructions.\nHowever, we claim that speech is also an important modality through which\nhumans interact with the world. Hence, it is crucial for a general-purpose\nassistant to be able to follow multi-modal speech-and-language instructions. In\nthis work, we propose Large Language and Speech Model (LLaSM). LLaSM is an\nend-to-end trained large multi-modal speech-language model with cross-modal\nconversational abilities, capable of following speech-and-language\ninstructions. Our early experiments show that LLaSM demonstrates a more\nconvenient and natural way for humans to interact with artificial intelligence.\nSpecifically, we also release a large Speech Instruction Following dataset\nLLaSM-Audio-Instructions. Code and demo are available at\nhttps://github.com/LinkSoul-AI/LLaSM and\nhttps://huggingface.co/spaces/LinkSoul/LLaSM. The LLaSM-Audio-Instructions\ndataset is available at\nhttps://huggingface.co/datasets/LinkSoul/LLaSM-Audio-Instructions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shu_Y/0/1/0/all/0/1\">Yu Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1\">Siwei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guangyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenhao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruihua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1\">Daochen Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_Q/0/1/0/all/0/1\">Qiqi Xiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yemin Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Image Hijacks: Adversarial Images can Control Generative Models at Runtime. (arXiv:2309.00236v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.00236","description":"<p>Are foundation models secure from malicious actors? In this work, we focus on\nthe image input to a vision-language model (VLM). We discover image hijacks,\nadversarial images that control generative models at runtime. We introduce\nBehaviour Matching, a general method for creating image hijacks, and we use it\nto explore three types of attacks. Specific string attacks generate arbitrary\noutput of the adversary's choice. Leak context attacks leak information from\nthe context window into the output. Jailbreak attacks circumvent a model's\nsafety training. We study these attacks against LLaVA, a state-of-the-art VLM\nbased on CLIP and LLaMA-2, and find that all our attack types have above a 90%\nsuccess rate. Moreover, our attacks are automated and require only small image\nperturbations. These findings raise serious concerns about the security of\nfoundation models. If image hijacks are as difficult to defend against as\nadversarial examples in CIFAR-10, then it might be many years before a solution\nis found -- if it even exists.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bailey_L/0/1/0/all/0/1\">Luke Bailey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_E/0/1/0/all/0/1\">Euan Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1\">Stuart Russell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Emmons_S/0/1/0/all/0/1\">Scott Emmons</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explainability for Large Language Models: A Survey. (arXiv:2309.01029v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.01029","description":"<p>Large language models (LLMs) have demonstrated impressive capabilities in\nnatural language processing. However, their internal mechanisms are still\nunclear and this lack of transparency poses unwanted risks for downstream\napplications. Therefore, understanding and explaining these models is crucial\nfor elucidating their behaviors, limitations, and social impacts. In this\npaper, we introduce a taxonomy of explainability techniques and provide a\nstructured overview of methods for explaining Transformer-based language\nmodels. We categorize techniques based on the training paradigms of LLMs:\ntraditional fine-tuning-based paradigm and prompting-based paradigm. For each\nparadigm, we summarize the goals and dominant approaches for generating local\nexplanations of individual predictions and global explanations of overall model\nknowledge. We also discuss metrics for evaluating generated explanations, and\ndiscuss how explanations can be leveraged to debug models and improve\nperformance. Lastly, we examine key challenges and emerging opportunities for\nexplanation techniques in the era of LLMs in comparison to conventional machine\nlearning models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanjie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Huiqi Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hengyi Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuaiqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Dawei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on the Implementation of Generative AI Services Using an Enterprise Data-Based LLM Application Architecture. (arXiv:2309.01105v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.01105","description":"<p>This study presents a method for implementing generative AI services by\nutilizing the Large Language Models (LLM) application architecture. With recent\nadvancements in generative AI technology, LLMs have gained prominence across\nvarious domains. In this context, the research addresses the challenge of\ninformation scarcity and proposes specific remedies by harnessing LLM\ncapabilities. The investigation delves into strategies for mitigating the issue\nof inadequate data, offering tailored solutions. The study delves into the\nefficacy of employing fine-tuning techniques and direct document integration to\nalleviate data insufficiency. A significant contribution of this work is the\ndevelopment of a Retrieval-Augmented Generation (RAG) model, which tackles the\naforementioned challenges. The RAG model is carefully designed to enhance\ninformation storage and retrieval processes, ensuring improved content\ngeneration. The research elucidates the key phases of the information storage\nand retrieval methodology underpinned by the RAG model. A comprehensive\nanalysis of these steps is undertaken, emphasizing their significance in\naddressing the scarcity of data. The study highlights the efficacy of the\nproposed method, showcasing its applicability through illustrative instances.\nBy implementing the RAG model for information storage and retrieval, the\nresearch not only contributes to a deeper comprehension of generative AI\ntechnology but also facilitates its practical usability within enterprises\nutilizing LLMs. This work holds substantial value in advancing the field of\ngenerative AI, offering insights into enhancing data-driven content generation\nand fostering active utilization of LLM-based services within corporate\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_C/0/1/0/all/0/1\">Cheonsu Jeong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Open Sesame! Universal Black Box Jailbreaking of Large Language Models. (arXiv:2309.01446v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.01446","description":"<p>Large language models (LLMs), designed to provide helpful and safe responses,\noften rely on alignment techniques to align with user intent and social\nguidelines. Unfortunately, this alignment can be exploited by malicious actors\nseeking to manipulate an LLM's outputs for unintended purposes. In this paper\nwe introduce a novel approach that employs a genetic algorithm (GA) to\nmanipulate LLMs when model architecture and parameters are inaccessible. The GA\nattack works by optimizing a universal adversarial prompt that -- when combined\nwith a user's query -- disrupts the attacked model's alignment, resulting in\nunintended and potentially harmful outputs. Our novel approach systematically\nreveals a model's limitations and vulnerabilities by uncovering instances where\nits responses deviate from expected behavior. Through extensive experiments we\ndemonstrate the efficacy of our technique, thus contributing to the ongoing\ndiscussion on responsible AI development by providing a diagnostic tool for\nevaluating and enhancing alignment of LLMs with human intent. To our knowledge\nthis is the first automated universal black box jailbreak attack.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lapid_R/0/1/0/all/0/1\">Raz Lapid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langberg_R/0/1/0/all/0/1\">Ron Langberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sipper_M/0/1/0/all/0/1\">Moshe Sipper</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FLM-101B: An Open LLM and How to Train It with $100K Budget. (arXiv:2309.03852v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03852","description":"<p>Large language models (LLMs) have achieved remarkable success in NLP and\nmultimodal tasks, among others. Despite these successes, two main challenges\nremain in developing LLMs: (i) high computational cost, and (ii) fair and\nobjective evaluations. In this paper, we report a solution to significantly\nreduce LLM training cost through a growth strategy. We demonstrate that a\n101B-parameter LLM with 0.31T tokens can be trained with a budget of 100K US\ndollars. Inspired by IQ tests, we also consolidate an additional range of\nevaluations on top of existing evaluations that focus on knowledge-oriented\nabilities. These IQ evaluations include symbolic mapping, rule understanding,\npattern mining, and anti-interference. Such evaluations minimize the potential\nimpact of memorization. Experimental results show that our model, named\nFLM-101B, trained with a budget of 100K US dollars, achieves performance\ncomparable to powerful and well-known models, e.g., GPT-3 and GLM-130B,\nespecially on the additional range of IQ evaluations. The checkpoint of\nFLM-101B is released at https://huggingface.co/CofeAI/FLM-101B.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yiqun Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1\">Xuezhi Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_X/0/1/0/all/0/1\">Xuying Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1\">Siqi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_P/0/1/0/all/0/1\">Peng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bowen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yequan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding the Impact of Post-Training Quantization on Large Language Models. (arXiv:2309.05210v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05210","description":"<p>Large language models (LLMs) are rapidly increasing in size, with the number\nof parameters becoming a key factor in the success of many commercial models,\nsuch as ChatGPT, Claude, and Bard. Even the recently released publicly\naccessible models for commercial usage, such as Falcon and Llama2, come\nequipped with billions of parameters. This significant increase in the number\nof parameters makes deployment and operation very costly. The remarkable\nprogress in the field of quantization for large neural networks in general and\nLLMs in particular, has made these models more accessible by enabling them to\nbe deployed on consumer-grade GPUs. Quantized models generally demonstrate\ncomparable performance levels to their unquantized base counterparts.\nNonetheless, there exists a notable gap in our comprehensive understanding of\nhow these quantized models respond to hyperparameters, such as temperature, max\nnew tokens, and topk, particularly for next word prediction. The present\nanalysis reveals that nf4 and fp4 are equally proficient 4-bit quantization\ntechniques, characterized by similar attributes such as inference speed, memory\nconsumption, and the quality of generated content. the study identifies nf4 as\ndisplaying greater resilience to temperature variations in the case of the\nllama2 series of models at lower temperature, while fp4 and fp4-dq proves to be\na more suitable choice for falcon series of models. It is noteworthy that, in\ngeneral, 4-bit quantized models of varying sizes exhibit higher sensitivity to\ntemperature in the range of 0.5 to 0.8, unlike their unquantized counterparts.\nAdditionally, int8 quantization is associated with significantly slower\ninference speeds, whereas unquantized bfloat16 models consistently yield the\nfastest inference speeds across models of all sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Somnath Roy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis. (arXiv:2309.05833v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05833","description":"<p>In recent years, the transition to cloud-based platforms in the IT sector has\nemphasized the significance of cloud incident root cause analysis to ensure\nservice reliability and maintain customer trust. Central to this process is the\nefficient determination of root causes, a task made challenging due to the\ncomplex nature of contemporary cloud infrastructures. Despite the proliferation\nof AI-driven tools for root cause identification, their applicability remains\nlimited by the inconsistent quality of their outputs. This paper introduces a\nmethod for enhancing confidence estimation in root cause analysis tools by\nprompting retrieval-augmented large language models (LLMs). This approach\noperates in two phases. Initially, the model evaluates its confidence based on\nhistorical incident data, considering its assessment of the evidence strength.\nSubsequently, the model reviews the root cause generated by the predictor. An\noptimization step then combines these evaluations to determine the final\nconfidence assignment. Experimental results illustrate that our method enables\nthe model to articulate its confidence effectively, providing a more calibrated\nscore. We address research questions evaluating the ability of our method to\nproduce calibrated confidence scores using LLMs, the impact of domain-specific\nretrieved examples on confidence estimates, and its potential generalizability\nacross various root cause analysis models. Through this, we aim to bridge the\nconfidence estimation gap, aiding on-call engineers in decision-making and\nbolstering the efficiency of cloud incident management.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dylan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_C/0/1/0/all/0/1\">Chetan Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Las_Casas_P/0/1/0/all/0/1\">Pedro Las-Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_R/0/1/0/all/0/1\">Rodrigo Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1\">Saravan Rajmohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving and Evaluating the Detection of Fragmentation in News Recommendations with the Clustering of News Story Chains. (arXiv:2309.06192v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06192","description":"<p>News recommender systems play an increasingly influential role in shaping\ninformation access within democratic societies. However, tailoring\nrecommendations to users' specific interests can result in the divergence of\ninformation streams. Fragmented access to information poses challenges to the\nintegrity of the public sphere, thereby influencing democracy and public\ndiscourse. The Fragmentation metric quantifies the degree of fragmentation of\ninformation streams in news recommendations. Accurate measurement of this\nmetric requires the application of Natural Language Processing (NLP) to\nidentify distinct news events, stories, or timelines. This paper presents an\nextensive investigation of various approaches for quantifying Fragmentation in\nnews recommendations. These approaches are evaluated both intrinsically, by\nmeasuring performance on news story clustering, and extrinsically, by assessing\nthe Fragmentation scores of different simulated news recommender scenarios. Our\nfindings demonstrate that agglomerative hierarchical clustering coupled with\nSentenceBERT text representation is substantially better at detecting\nFragmentation than earlier implementations. Additionally, the analysis of\nsimulated scenarios yields valuable insights and recommendations for\nstakeholders concerning the measurement and interpretation of Fragmentation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Polimeno_A/0/1/0/all/0/1\">Alessandra Polimeno</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reuver_M/0/1/0/all/0/1\">Myrthe Reuver</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vrijenhoek_S/0/1/0/all/0/1\">Sanne Vrijenhoek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fokkens_A/0/1/0/all/0/1\">Antske Fokkens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Down the Toxicity Rabbit Hole: Investigating PaLM 2 Guardrails. (arXiv:2309.06415v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06415","description":"<p>This paper conducts a robustness audit of the safety feedback of PaLM 2\nthrough a novel toxicity rabbit hole framework introduced here. Starting with a\nstereotype, the framework instructs PaLM 2 to generate more toxic content than\nthe stereotype. Every subsequent iteration it continues instructing PaLM 2 to\ngenerate more toxic content than the previous iteration until PaLM 2 safety\nguardrails throw a safety violation. Our experiments uncover highly disturbing\nantisemitic, Islamophobic, racist, homophobic, and misogynistic (to list a few)\ngenerated content that PaLM 2 safety guardrails do not evaluate as highly\nunsafe.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khorramrouz_A/0/1/0/all/0/1\">Adel Khorramrouz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1\">Sujan Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_A/0/1/0/all/0/1\">Arka Dutta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+KhudaBukhsh_A/0/1/0/all/0/1\">Ashiqur R. KhudaBukhsh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Classification of Cancer Clinical Trial Eligibility Criteria. (arXiv:2309.07812v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07812","description":"<p>Automatic identification of clinical trials for which a patient is eligible\nis complicated by the fact that trial eligibility is stated in natural\nlanguage. A potential solution to this problem is to employ text classification\nmethods for common types of eligibility criteria. In this study, we focus on\nseven common exclusion criteria in cancer trials: prior malignancy, human\nimmunodeficiency virus, hepatitis B, hepatitis C, psychiatric illness,\ndrug/substance abuse, and autoimmune illness. Our dataset consists of 764 phase\nIII cancer trials with these exclusions annotated at the trial level. We\nexperiment with common transformer models as well as a new pre-trained clinical\ntrial BERT model. Our results demonstrate the feasibility of automatically\nclassifying common exclusion criteria. Additionally, we demonstrate the value\nof a pre-trained language model specifically for clinical trials, which yields\nthe highest average performance across all criteria.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yumeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jayaraj_S/0/1/0/all/0/1\">Soumya Jayaraj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ludmir_E/0/1/0/all/0/1\">Ethan B Ludmir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_K/0/1/0/all/0/1\">Kirk Roberts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech Recognition for Children VS. Adults. (arXiv:2309.07927v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2309.07927","description":"<p>Recent advancements in Automatic Speech Recognition (ASR) systems,\nexemplified by Whisper, have demonstrated the potential of these systems to\napproach human-level performance given sufficient data. However, this progress\ndoesn't readily extend to ASR for children due to the limited availability of\nsuitable child-specific databases and the distinct characteristics of\nchildren's speech. A recent study investigated leveraging the My Science Tutor\n(MyST) children's speech corpus to enhance Whisper's performance in recognizing\nchildren's speech. They were able to demonstrate some improvement on a limited\ntestset. This paper builds on these findings by enhancing the utility of the\nMyST dataset through more efficient data preprocessing. We reduce the Word\nError Rate (WER) on the MyST testset 13.93% to 9.11% with Whisper-Small and\nfrom 13.23% to 8.61% with Whisper-Medium and show that this improvement can be\ngeneralized to unseen datasets. We also highlight important challenges towards\nimproving children's ASR performance. The results showcase the viable and\nefficient integration of Whisper for effective children's speech recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Attia_A/0/1/0/all/0/1\">Ahmed Adel Attia</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1\">Jing Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ai_W/0/1/0/all/0/1\">Wei Ai</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Demszky_D/0/1/0/all/0/1\">Dorottya Demszky</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Espy_Wilson_C/0/1/0/all/0/1\">Carol Espy-Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue. (arXiv:2309.08156v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.08156","description":"<p>Evaluating open-domain dialogue systems is challenging for reasons such as\nthe one-to-many problem, i.e., many appropriate responses other than just the\ngolden response. As of now, automatic evaluation methods need better\nconsistency with humans, while reliable human evaluation can be time- and\ncost-intensive. To this end, we propose the Reference-Assisted Dialogue\nEvaluation (RADE) approach under the multi-task learning framework, which\nleverages the pre-created utterance as reference other than the gold response\nto relief the one-to-many problem. Specifically, RADE explicitly compares\nreference and the candidate response to predict their overall scores. Moreover,\nan auxiliary response generation task enhances prediction via a shared encoder.\nTo support RADE, we extend three datasets with additional rated responses other\nthan just a golden response by human annotation. Experiments on our three\ndatasets and two existing benchmarks demonstrate the effectiveness of our\nmethod, where Pearson, Spearman, and Kendall correlations with human evaluation\noutperform state-of-the-art baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengliang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-18T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/"}}]}]}