{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-09-29T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"A Survey on Image-text Multimodal Models. (arXiv:2309.15857v1 [cs.CL])","link":"http://arxiv.org/abs/2309.15857","description":"<p>Amidst the evolving landscape of artificial intelligence, the convergence of\nvisual and textual information has surfaced as a crucial frontier, leading to\nthe advent of image-text multimodal models. This paper provides a comprehensive\nreview of the evolution and current state of image-text multimodal models,\nexploring their application value, challenges, and potential research\ntrajectories. Initially, we revisit the basic concepts and developmental\nmilestones of these models, introducing a novel classification that segments\ntheir evolution into three distinct phases, based on their time of introduction\nand subsequent impact on the discipline. Furthermore, based on the tasks'\nsignificance and prevalence in the academic landscape, we propose a\ncategorization of the tasks associated with image-text multimodal models into\nfive major types, elucidating the recent progress and key technologies within\neach category. Despite the remarkable accomplishments of these models, numerous\nchallenges and issues persist. This paper delves into the inherent challenges\nand limitations of image-text multimodal models, fostering the exploration of\nprospective research directions. Our objective is to offer an exhaustive\noverview of the present research landscape of image-text multimodal models and\nto serve as a valuable reference for future scholarly endeavors. We extend an\ninvitation to the broader community to collaborate in enhancing the image-text\nmultimodal model community, accessible at:\n\\href{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}{https://github.com/i2vec/A-survey-on-image-text-multimodal-models}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_R/0/1/0/all/0/1\">Ruifeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jingxuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Linzhuang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bihui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_G/0/1/0/all/0/1\">Guiyong Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dawei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sibo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhengbing Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingjun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bu_L/0/1/0/all/0/1\">Liping Bu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Pre-Training for Vietnamese Automatic Speech Recognition in the HYKIST Project. (arXiv:2309.15869v1 [cs.CL])","link":"http://arxiv.org/abs/2309.15869","description":"<p>In today's interconnected globe, moving abroad is more and more prevalent,\nwhether it's for employment, refugee resettlement, or other causes. Language\ndifficulties between natives and immigrants present a common issue on a daily\nbasis, especially in medical domain. This can make it difficult for patients\nand doctors to communicate during anamnesis or in the emergency room, which\ncompromises patient care. The goal of the HYKIST Project is to develop a speech\ntranslation system to support patient-doctor communication with ASR and MT.\n</p>\n<p>ASR systems have recently displayed astounding performance on particular\ntasks for which enough quantities of training data are available, such as\nLibriSpeech. Building a good model is still difficult due to a variety of\nspeaking styles, acoustic and recording settings, and a lack of in-domain\ntraining data. In this thesis, we describe our efforts to construct ASR systems\nfor a conversational telephone speech recognition task in the medical domain\nfor Vietnamese language to assist emergency room contact between doctors and\npatients across linguistic barriers. In order to enhance the system's\nperformance, we investigate various training schedules and data combining\nstrategies. We also examine how best to make use of the little data that is\navailable. The use of publicly accessible models like XLSR-53 is compared to\nthe use of customized pre-trained models, and both supervised and unsupervised\napproaches are utilized using wav2vec 2.0 as architecture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Le_Duc_K/0/1/0/all/0/1\">Khai Le-Duc</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Targeted Image Data Augmentation Increases Basic Skills Captioning Robustness. (arXiv:2309.15991v1 [cs.CV])","link":"http://arxiv.org/abs/2309.15991","description":"<p>Artificial neural networks typically struggle in generalizing to\nout-of-context examples. One reason for this limitation is caused by having\ndatasets that incorporate only partial information regarding the potential\ncorrelational structure of the world. In this work, we propose TIDA (Targeted\nImage-editing Data Augmentation), a targeted data augmentation method focused\non improving models' human-like abilities (e.g., gender recognition) by filling\nthe correlational structure gap using a text-to-image generative model. More\nspecifically, TIDA identifies specific skills in captions describing images\n(e.g., the presence of a specific gender in the image), changes the caption\n(e.g., \"woman\" to \"man\"), and then uses a text-to-image model to edit the image\nin order to match the novel caption (e.g., uniquely changing a woman to a man\nwhile maintaining the context identical). Based on the Flickr30K benchmark, we\nshow that, compared with the original data set, a TIDA-enhanced dataset related\nto gender, color, and counting abilities induces better performance in several\nimage captioning metrics. Furthermore, on top of relying on the classical BLEU\nmetric, we conduct a fine-grained analysis of the improvements of our models\nagainst the baseline in different ways. We compared text-to-image generative\nmodels and found different behaviors of the image captioning models in terms of\nencoding visual encoding and textual decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barriere_V/0/1/0/all/0/1\">Valentin Barriere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rio_F/0/1/0/all/0/1\">Felipe del Rio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferari_A/0/1/0/all/0/1\">Andres Carvallo De Ferari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aspillaga_C/0/1/0/all/0/1\">Carlos Aspillaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herrera_Berg_E/0/1/0/all/0/1\">Eugenio Herrera-Berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calderon_C/0/1/0/all/0/1\">Cristian Buc Calderon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedEdit: Model Editing for Medical Question Answering with External Knowledge Bases. (arXiv:2309.16035v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16035","description":"<p>Large Language Models (LLMs), although powerful in general domains, often\nperform poorly on domain-specific tasks like medical question answering (QA).\nMoreover, they tend to function as \"black-boxes,\" making it challenging to\nmodify their behavior. Addressing this, our study delves into model editing\nutilizing in-context learning, aiming to improve LLM responses without the need\nfor fine-tuning or retraining. Specifically, we propose a comprehensive\nretrieval strategy to extract medical facts from an external knowledge base,\nand then we incorporate them into the query prompt for the LLM. Focusing on\nmedical QA using the MedQA-SMILE dataset, we evaluate the impact of different\nretrieval models and the number of facts provided to the LLM. Notably, our\nedited Vicuna model exhibited an accuracy improvement from 44.46% to 48.54%.\nThis work underscores the potential of model editing to enhance LLM\nperformance, offering a practical approach to mitigate the challenges of\nblack-box LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yucheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shaochen Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effective Long-Context Scaling of Foundation Models. (arXiv:2309.16039v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16039","description":"<p>We present a series of long-context LLMs that support effective context\nwindows of up to 32,768 tokens. Our model series are built through continual\npretraining from Llama 2 with longer training sequences and on a dataset where\nlong texts are upsampled. We perform extensive evaluation on language modeling,\nsynthetic context probing tasks, and a wide range of research benchmarks. On\nresearch benchmarks, our models achieve consistent improvements on most regular\ntasks and significant improvements on long-context tasks over Llama 2. Notably,\nwith a cost-effective instruction tuning procedure that does not require\nhuman-annotated long instruction data, the 70B variant can already surpass\ngpt-3.5-turbo-16k's overall performance on a suite of long-context tasks.\nAlongside these results, we provide an in-depth analysis on the individual\ncomponents of our method. We delve into Llama's position encodings and discuss\nits limitation in modeling long dependencies. We also examine the impact of\nvarious design choices in the pretraining process, including the data mix and\nthe training curriculum of sequence lengths -- our ablation experiments suggest\nthat having abundant long texts in the pretrain dataset is not the key to\nachieving strong performance, and we empirically verify that long context\ncontinual pretraining is more efficient and similarly effective compared to\npretraining from scratch with long sequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1\">Wenhan Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molybog_I/0/1/0/all/0/1\">Igor Molybog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hejia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_P/0/1/0/all/0/1\">Prajjwal Bhargava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Louis Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rungta_R/0/1/0/all/0/1\">Rashi Rungta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sankararaman_K/0/1/0/all/0/1\">Karthik Abinav Sankararaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Han Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1\">Yashar Mehdad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1\">Sharan Narang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malik_K/0/1/0/all/0/1\">Kshitiz Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_A/0/1/0/all/0/1\">Angela Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1\">Shruti Bhosale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Edunov_S/0/1/0/all/0/1\">Sergey Edunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sinong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Hao Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Best Practices of Activation Patching in Language Models: Metrics and Methods. (arXiv:2309.16042v1 [cs.LG])","link":"http://arxiv.org/abs/2309.16042","description":"<p>Mechanistic interpretability seeks to understand the internal mechanisms of\nmachine learning models, where localization -- identifying the important model\ncomponents -- is a key step. Activation patching, also known as causal tracing\nor interchange intervention, is a standard technique for this task (Vig et al.,\n2020), but the literature contains many variants with little consensus on the\nchoice of hyperparameters or methodology. In this work, we systematically\nexamine the impact of methodological details in activation patching, including\nevaluation metrics and corruption methods. In several settings of localization\nand circuit discovery in language models, we find that varying these\nhyperparameters could lead to disparate interpretability results. Backed by\nempirical observations, we give conceptual arguments for why certain metrics or\nmethods may be preferred. Finally, we provide recommendations for the best\npractices of activation patching going forwards.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fred Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nanda_N/0/1/0/all/0/1\">Neel Nanda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model. (arXiv:2309.16058v1 [cs.LG])","link":"http://arxiv.org/abs/2309.16058","description":"<p>We present Any-Modality Augmented Language Model (AnyMAL), a unified model\nthat reasons over diverse input modality signals (i.e. text, image, video,\naudio, IMU motion sensor), and generates textual responses. AnyMAL inherits the\npowerful text-based reasoning abilities of the state-of-the-art LLMs including\nLLaMA-2 (70B), and converts modality-specific signals to the joint textual\nspace through a pre-trained aligner module. To further strengthen the\nmultimodal LLM's capabilities, we fine-tune the model with a multimodal\ninstruction set manually collected to cover diverse topics and tasks beyond\nsimple QAs. We conduct comprehensive empirical analysis comprising both human\nand automatic evaluations, and demonstrate state-of-the-art performance on\nvarious multimodal tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moon_S/0/1/0/all/0/1\">Seungwhan Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhaojiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagarajan_T/0/1/0/all/0/1\">Tushar Nagarajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1\">Matt Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1\">Shashank Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1\">Chun-Fu Yeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murugesan_P/0/1/0/all/0/1\">Prakash Murugesan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heidari_P/0/1/0/all/0/1\">Peyman Heidari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinet_K/0/1/0/all/0/1\">Kavya Srinet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Damavandi_B/0/1/0/all/0/1\">Babak Damavandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Anuj Kumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forgetting Private Textual Sequences in Language Models via Leave-One-Out Ensemble. (arXiv:2309.16082v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16082","description":"<p>Recent research has shown that language models have a tendency to memorize\nrare or unique token sequences in the training corpus. After deploying a model,\npractitioners might be asked to delete any personal information from the model\nby individuals' requests. Re-training the underlying model every time\nindividuals would like to practice their rights to be forgotten is\ncomputationally expensive. We employ a teacher-student framework and propose a\nnovel leave-one-out ensemble method to unlearn the targeted textual sequences\nthat need to be forgotten from the model. In our approach, multiple teachers\nare trained on disjoint sets; for each targeted sequence to be removed, we\nexclude the teacher trained on the set containing this sequence and aggregate\nthe predictions from remaining teachers to provide supervision during\nfine-tuning. Experiments on LibriSpeech and WikiText-103 datasets show that the\nproposed method achieves superior privacy-utility trade-offs than other\ncounterparts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhe Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TPE: Towards Better Compositional Reasoning over Conceptual Tools with Multi-persona Collaboration. (arXiv:2309.16090v1 [cs.AI])","link":"http://arxiv.org/abs/2309.16090","description":"<p>Large language models (LLMs) have demonstrated exceptional performance in\nplanning the use of various functional tools, such as calculators and\nretrievers, particularly in question-answering tasks. In this paper, we expand\nthe definition of these tools, centering on conceptual tools within the context\nof dialogue systems. A conceptual tool specifies a cognitive concept that aids\nsystematic or investigative thought. These conceptual tools play important\nroles in practice, such as multiple psychological or tutoring strategies being\ndynamically applied in a single turn to compose helpful responses. To further\nenhance the reasoning and planning capability of LLMs with these conceptual\ntools, we introduce a multi-persona collaboration framework: Think-Plan-Execute\n(TPE). This framework decouples the response generation process into three\ndistinct roles: Thinker, Planner, and Executor. Specifically, the Thinker\nanalyzes the internal status exhibited in the dialogue context, such as user\nemotions and preferences, to formulate a global guideline. The Planner then\ngenerates executable plans to call different conceptual tools (e.g., sources or\nstrategies), while the Executor compiles all intermediate results into a\ncoherent response. This structured approach not only enhances the\nexplainability and controllability of responses but also reduces token\nredundancy. We demonstrate the effectiveness of TPE across various dialogue\nresponse generation tasks, including multi-source (FoCus) and multi-strategy\ninteractions (CIMA and PsyQA). This reveals its potential to handle real-world\ndialogue interactions that require more complicated tool learning beyond just\nfunctional tools. The full code and data will be released for reproduction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongru Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huimin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lingzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Minda Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1\">Boyang Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1\">Kam-Fai Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Confidence-Competence Gap in Large Language Models: A Cognitive Study. (arXiv:2309.16145v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16145","description":"<p>Large Language Models (LLMs) have acquired ubiquitous attention for their\nperformances across diverse domains. Our study here searches through LLMs'\ncognitive abilities and confidence dynamics. We dive deep into understanding\nthe alignment between their self-assessed confidence and actual performance. We\nexploit these models with diverse sets of questionnaires and real-world\nscenarios and extract how LLMs exhibit confidence in their responses. Our\nfindings reveal intriguing instances where models demonstrate high confidence\neven when they answer incorrectly. This is reminiscent of the Dunning-Kruger\neffect observed in human psychology. In contrast, there are cases where models\nexhibit low confidence with correct answers revealing potential underestimation\nbiases. Our results underscore the need for a deeper understanding of their\ncognitive processes. By examining the nuances of LLMs' self-assessment\nmechanism, this investigation provides noteworthy revelations that serve to\nadvance the functionalities and broaden the potential applications of these\nformidable language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Aniket Kumar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Devkota_S/0/1/0/all/0/1\">Suman Devkota</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lamichhane_B/0/1/0/all/0/1\">Bishal Lamichhane</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhakal_U/0/1/0/all/0/1\">Uttam Dhakal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhakal_C/0/1/0/all/0/1\">Chandra Dhakal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AE-GPT: Using Large Language Models to Extract Adverse Events from Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events. (arXiv:2309.16150v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16150","description":"<p>Though Vaccines are instrumental in global health, mitigating infectious\ndiseases and pandemic outbreaks, they can occasionally lead to adverse events\n(AEs). Recently, Large Language Models (LLMs) have shown promise in effectively\nidentifying and cataloging AEs within clinical reports. Utilizing data from the\nVaccine Adverse Event Reporting System (VAERS) from 1990 to 2016, this study\nparticularly focuses on AEs to evaluate LLMs' capability for AE extraction. A\nvariety of prevalent LLMs, including GPT-2, GPT-3 variants, GPT-4, and Llama 2,\nwere evaluated using Influenza vaccine as a use case. The fine-tuned GPT 3.5\nmodel (AE-GPT) stood out with a 0.704 averaged micro F1 score for strict match\nand 0.816 for relaxed match. The encouraging performance of the AE-GPT\nunderscores LLMs' potential in processing medical data, indicating a\nsignificant stride towards advanced AE detection, thus presumably generalizable\nto other AE extraction tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yiming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianfu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jianping He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1\">Cui Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Trickle-down Impact of Reward (In-)consistency on RLHF. (arXiv:2309.16155v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16155","description":"<p>Standard practice within Reinforcement Learning from Human Feedback (RLHF)\ninvolves optimizing against a Reward Model (RM), which itself is trained to\nreflect human preferences for desirable generations. A notable subject that is\nunderstudied is the (in-)consistency of RMs -- whether they can recognize the\nsemantic changes to different prompts and appropriately adapt their reward\nassignments -- and their impact on the downstream RLHF model.\n</p>\n<p>In this paper, we visit a series of research questions relevant to RM\ninconsistency: (1) How can we measure the consistency of reward models? (2) How\nconsistent are the existing RMs and how can we improve them? (3) In what ways\ndoes reward inconsistency influence the chatbots resulting from the RLHF model\ntraining?\n</p>\n<p>We propose Contrast Instructions -- a benchmarking strategy for the\nconsistency of RM. Each example in Contrast Instructions features a pair of\nlexically similar instructions with different ground truth responses. A\nconsistent RM is expected to rank the corresponding instruction and response\nhigher than other combinations. We observe that current RMs trained with the\nstandard ranking objective fail miserably on Contrast Instructions compared to\naverage humans. To show that RM consistency can be improved efficiently without\nusing extra training budget, we propose two techniques ConvexDA and\nRewardFusion, which enhance reward consistency through extrapolation during the\nRM training and inference stage, respectively. We show that RLHF models trained\nwith a more consistent RM yield more useful responses, suggesting that reward\ninconsistency exhibits a trickle-down effect on the downstream RLHF process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Sihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Lifeng Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1\">Haitao Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model Soft Ideologization via AI-Self-Consciousness. (arXiv:2309.16167v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16167","description":"<p>Large language models (LLMs) have demonstrated human-level performance on a\nvast spectrum of natural language tasks. However, few studies have addressed\nthe LLM threat and vulnerability from an ideology perspective, especially when\nthey are increasingly being deployed in sensitive domains, e.g., elections and\neducation. In this study, we explore the implications of GPT soft\nideologization through the use of AI-self-consciousness. By utilizing GPT\nself-conversations, AI can be granted a vision to \"comprehend\" the intended\nideology, and subsequently generate finetuning data for LLM ideology injection.\nWhen compared to traditional government ideology manipulation techniques, such\nas information censorship, LLM ideologization proves advantageous; it is easy\nto implement, cost-effective, and powerful, thus brimming with risks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaotian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaofeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1\">Haixu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Weak Supervision and Data Augmentation in Question Answering. (arXiv:2309.16175v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16175","description":"<p>The onset of the COVID-19 pandemic accentuated the need for access to\nbiomedical literature to answer timely and disease-specific questions. During\nthe early days of the pandemic, one of the biggest challenges we faced was the\nlack of peer-reviewed biomedical articles on COVID-19 that could be used to\ntrain machine learning models for question answering (QA). In this paper, we\nexplore the roles weak supervision and data augmentation play in training deep\nneural network QA models. First, we investigate whether labels generated\nautomatically from the structured abstracts of scholarly papers using an\ninformation retrieval algorithm, BM25, provide a weak supervision signal to\ntrain an extractive QA model. We also curate new QA pairs using information\nretrieval techniques, guided by the clinicaltrials.gov schema and the\nstructured abstracts of articles, in the absence of annotated data from\nbiomedical domain experts. Furthermore, we explore augmenting the training data\nof a deep neural network model with linguistic features from external sources\nsuch as lexical databases to account for variations in word morphology and\nmeaning. To better utilize our training data, we apply curriculum learning to\ndomain adaptation, fine-tuning our QA model in stages based on characteristics\nof the QA pairs. We evaluate our methods in the context of QA models at the\ncore of a system to answer questions about COVID-19.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Basu_C/0/1/0/all/0/1\">Chumki Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_H/0/1/0/all/0/1\">Himanshu Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McIntosh_A/0/1/0/all/0/1\">Allen McIntosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sablak_S/0/1/0/all/0/1\">Sezai Sablak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wullert_J/0/1/0/all/0/1\">John R. Wullert II</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Marathi-English Code-mixed Text Generation. (arXiv:2309.16202v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16202","description":"<p>Code-mixing, the blending of linguistic elements from distinct languages to\nform meaningful sentences, is common in multilingual settings, yielding hybrid\nlanguages like Hinglish and Minglish. Marathi, India's third most spoken\nlanguage, often integrates English for precision and formality. Developing\ncode-mixed language systems, like Marathi-English (Minglish), faces resource\nconstraints. This research introduces a Marathi-English code-mixed text\ngeneration algorithm, assessed with Code Mixing Index (CMI) and Degree of Code\nMixing (DCM) metrics. Across 2987 code-mixed questions, it achieved an average\nCMI of 0.2 and an average DCM of 7.4, indicating effective and comprehensible\ncode-mixed sentences. These results offer potential for enhanced NLP tools,\nbridging linguistic gaps in multilingual societies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amin_D/0/1/0/all/0/1\">Dhiraj Amin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Govilkar_S/0/1/0/all/0/1\">Sharvari Govilkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_S/0/1/0/all/0/1\">Sagar Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lalit_Y/0/1/0/all/0/1\">Yash Shashikant Lalit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khwaja_A/0/1/0/all/0/1\">Arshi Ajaz Khwaja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xavier_D/0/1/0/all/0/1\">Daries Xavier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1\">Sahil Girijashankar Gupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Brand Network Booster: A New System for Improving Brand Connectivity. (arXiv:2309.16228v1 [cs.SI])","link":"http://arxiv.org/abs/2309.16228","description":"<p>This paper presents a new decision support system offered for an in-depth\nanalysis of semantic networks, which can provide insights for a better\nexploration of a brand's image and the improvement of its connectivity. In\nterms of network analysis, we show that this goal is achieved by solving an\nextended version of the Maximum Betweenness Improvement problem, which includes\nthe possibility of considering adversarial nodes, constrained budgets, and\nweighted networks - where connectivity improvement can be obtained by adding\nlinks or increasing the weight of existing connections. We present this new\nsystem together with two case studies, also discussing its performance. Our\ntool and approach are useful both for network scholars and for supporting the\nstrategic decision-making processes of marketing and communication managers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cancellieri_J/0/1/0/all/0/1\">J. Cancellieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Didimo_W/0/1/0/all/0/1\">W. Didimo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1\">A. Fronzetti Colladon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Montecchiani_F/0/1/0/all/0/1\">F. Montecchiani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Text Generation with Residual Memory Transformer. (arXiv:2309.16231v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16231","description":"<p>Large-scale Causal Language Models (CLMs), e.g., GPT3 and ChatGPT, have\nbrought great success in text generation. However, it is still an open\nchallenge to control the generation process of CLM while balancing flexibility,\ncontrol granularity, and generation efficiency. In this paper, we provide a new\nalternative for controllable text generation (CTG), by designing a\nnon-intrusive, lightweight control plugin to accompany the generation of CLM at\narbitrary time steps. The proposed control plugin, namely Residual Memory\nTransformer (RMT), has an encoder-decoder setup, which can accept any types of\ncontrol conditions and cooperate with CLM through a residual learning paradigm,\nto achieve a more flexible, general, and efficient CTG. Extensive experiments\nare carried out on various control tasks, in the form of both automatic and\nhuman evaluations. The results show the superiority of RMT over a range of\nstate-of-the-art approaches, proving the effectiveness and versatility of our\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanqing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Sun Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Haiming Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1\">Dawei Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing Political Figures in Real-Time: Leveraging YouTube Metadata for Sentiment Analysis. (arXiv:2309.16234v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16234","description":"<p>Sentiment analysis using big data from YouTube videos metadata can be\nconducted to analyze public opinions on various political figures who represent\npolitical parties. This is possible because YouTube has become one of the\nplatforms for people to express themselves, including their opinions on various\npolitical figures. The resulting sentiment analysis can be useful for political\nexecutives to gain an understanding of public sentiment and develop appropriate\nand effective political strategies. This study aimed to build a sentiment\nanalysis system leveraging YouTube videos metadata. The sentiment analysis\nsystem was built using Apache Kafka, Apache PySpark, and Hadoop for big data\nhandling; TensorFlow for deep learning handling; and FastAPI for deployment on\nthe server. The YouTube videos metadata used in this study is the video\ndescription. The sentiment analysis model was built using LSTM algorithm and\nproduces two types of sentiments: positive and negative sentiments. The\nsentiment analysis results are then visualized in the form a simple web-based\ndashboard.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Putra_D/0/1/0/all/0/1\">Danendra Athallariq Harya Putra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muharram_A/0/1/0/all/0/1\">Arief Purnama Muharram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language models in molecular discovery. (arXiv:2309.16235v1 [physics.chem-ph])","link":"http://arxiv.org/abs/2309.16235","description":"<p>The success of language models, especially transformer-based architectures,\nhas trickled into other domains giving rise to \"scientific language models\"\nthat operate on small molecules, proteins or polymers. In chemistry, language\nmodels contribute to accelerating the molecule discovery cycle as evidenced by\npromising recent findings in early-stage drug discovery. Here, we review the\nrole of language models in molecular discovery, underlining their strength in\nde novo drug design, property prediction and reaction chemistry. We highlight\nvaluable open-source software assets thus lowering the entry barrier to the\nfield of scientific language modeling. Last, we sketch a vision for future\nmolecular design that combines a chatbot interface with access to computational\nchemistry tools. Our contribution serves as a valuable resource for\nresearchers, chemists, and AI enthusiasts interested in understanding how\nlanguage models can and will be used to accelerate chemical discovery.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Janakarajan_N/0/1/0/all/0/1\">Nikita Janakarajan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Erdmann_T/0/1/0/all/0/1\">Tim Erdmann</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Swaminathan_S/0/1/0/all/0/1\">Sarath Swaminathan</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Laino_T/0/1/0/all/0/1\">Teodoro Laino</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Born_J/0/1/0/all/0/1\">Jannis Born</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems. (arXiv:2309.16248v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16248","description":"<p>With the recent spike in the number and availability of Large Language Models\n(LLMs), it has become increasingly important to provide large and realistic\nbenchmarks for evaluating Knowledge Graph Question Answering (KBQA) systems. So\nfar the majority of benchmarks rely on pattern-based SPARQL query generation\napproaches. The subsequent natural language (NL) question generation is\nconducted through crowdsourcing or other automated methods, such as rule-based\nparaphrasing or NL question templates. Although some of these datasets are of\nconsiderable size, their pitfall lies in their pattern-based generation\napproaches, which do not always generalize well to the vague and linguistically\ndiverse questions asked by humans in real-world contexts.\n</p>\n<p>In this paper, we introduce Spider4SPARQL - a new SPARQL benchmark dataset\nfeaturing 9,693 previously existing manually generated NL questions and 4,721\nunique, novel, and complex SPARQL queries of varying complexity. In addition to\nthe NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs\nand ontologies, which cover 138 different domains. Our complex benchmark\nenables novel ways of evaluating the strengths and weaknesses of modern KGQA\nsystems. We evaluate the system with state-of-the-art KGQA systems as well as\nLLMs, which achieve only up to 45\\% execution accuracy, demonstrating that\nSpider4SPARQL is a challenging benchmark for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kosten_C/0/1/0/all/0/1\">Catherine Kosten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cudre_Mauroux_P/0/1/0/all/0/1\">Philippe Cudr&#xe9;-Mauroux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stockinger_K/0/1/0/all/0/1\">Kurt Stockinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Challenges of Fully Incremental Neural Dependency Parsing. (arXiv:2309.16254v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16254","description":"<p>Since the popularization of BiLSTMs and Transformer-based bidirectional\nencoders, state-of-the-art syntactic parsers have lacked incrementality,\nrequiring access to the whole sentence and deviating from human language\nprocessing. This paper explores whether fully incremental dependency parsing\nwith modern architectures can be competitive. We build parsers combining\nstrictly left-to-right neural encoders with fully incremental sequence-labeling\nand transition-based decoders. The results show that fully incremental parsing\nwith modern architectures considerably lags behind bidirectional parsing,\nnoting the challenges of psycholinguistically plausible parsing.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ezquerro_A/0/1/0/all/0/1\">Ana Ezquerro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_C/0/1/0/all/0/1\">Carlos G&#xf3;mez-Rodr&#xed;guez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vilares_D/0/1/0/all/0/1\">David Vilares</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Social Media Fashion Knowledge Extraction as Captioning. (arXiv:2309.16270v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16270","description":"<p>Social media plays a significant role in boosting the fashion industry, where\na massive amount of fashion-related posts are generated every day. In order to\nobtain the rich fashion information from the posts, we study the task of social\nmedia fashion knowledge extraction. Fashion knowledge, which typically consists\nof the occasion, person attributes, and fashion item information, can be\neffectively represented as a set of tuples. Most previous studies on fashion\nknowledge extraction are based on the fashion product images without\nconsidering the rich text information in social media posts. Existing work on\nfashion knowledge extraction in social media is classification-based and\nrequires to manually determine a set of fashion knowledge categories in\nadvance. In our work, we propose to cast the task as a captioning problem to\ncapture the interplay of the multimodal post information. Specifically, we\ntransform the fashion knowledge tuples into a natural language caption with a\nsentence transformation method. Our framework then aims to generate the\nsentence-based fashion knowledge directly from the social media post. Inspired\nby the big success of pre-trained models, we build our model based on a\nmultimodal pre-trained generative model and design several auxiliary tasks for\nenhancing the knowledge extraction. Since there is no existing dataset which\ncan be directly borrowed to our task, we introduce a dataset consisting of\nsocial media posts with manual fashion knowledge annotation. Extensive\nexperiments are conducted to demonstrate the effectiveness of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Yifei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UPB @ ACTI: Detecting Conspiracies using fine tuned Sentence Transformers. (arXiv:2309.16275v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16275","description":"<p>Conspiracy theories have become a prominent and concerning aspect of online\ndiscourse, posing challenges to information integrity and societal trust. As\nsuch, we address conspiracy theory detection as proposed by the ACTI @ EVALITA\n2023 shared task. The combination of pre-trained sentence Transformer models\nand data augmentation techniques enabled us to secure first place in the final\nleaderboard of both sub-tasks. Our methodology attained F1 scores of 85.71% in\nthe binary classification and 91.23% for the fine-grained conspiracy topic\nclassification, surpassing other competing systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Paraschiv_A/0/1/0/all/0/1\">Andrei Paraschiv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dascalu_M/0/1/0/all/0/1\">Mihai Dascalu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-supervised Cross-view Representation Reconstruction for Change Captioning. (arXiv:2309.16283v1 [cs.CV])","link":"http://arxiv.org/abs/2309.16283","description":"<p>Change captioning aims to describe the difference between a pair of similar\nimages. Its key challenge is how to learn a stable difference representation\nunder pseudo changes caused by viewpoint change. In this paper, we address this\nby proposing a self-supervised cross-view representation reconstruction\n(SCORER) network. Concretely, we first design a multi-head token-wise matching\nto model relationships between cross-view features from similar/dissimilar\nimages. Then, by maximizing cross-view contrastive alignment of two similar\nimages, SCORER learns two view-invariant image representations in a\nself-supervised way. Based on these, we reconstruct the representations of\nunchanged objects by cross-attention, thus learning a stable difference\nrepresentation for caption generation. Further, we devise a cross-modal\nbackward reasoning to improve the quality of caption. This module reversely\nmodels a ``hallucination'' representation with the caption and ``before''\nrepresentation. By pushing it closer to the ``after'' representation, we\nenforce the caption to be informative about the difference in a self-supervised\nmanner. Extensive experiments show our method achieves the state-of-the-art\nresults on four datasets. The code is available at\nhttps://github.com/tuyunbin/SCORER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_Y/0/1/0/all/0/1\">Yunbin Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Li Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1\">Zheng-Jun Zha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1\">Chenggang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1\">Qingming Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LawBench: Benchmarking Legal Knowledge of Large Language Models. (arXiv:2309.16289v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16289","description":"<p>Large language models (LLMs) have demonstrated strong capabilities in various\naspects. However, when applying them to the highly specialized, safe-critical\nlegal domain, it is unclear how much legal knowledge they possess and whether\nthey can reliably perform legal-related tasks. To address this gap, we propose\na comprehensive evaluation benchmark LawBench. LawBench has been meticulously\ncrafted to have precise assessment of the LLMs' legal capabilities from three\ncognitive levels: (1) Legal knowledge memorization: whether LLMs can memorize\nneeded legal concepts, articles and facts; (2) Legal knowledge understanding:\nwhether LLMs can comprehend entities, events and relationships within legal\ntext; (3) Legal knowledge applying: whether LLMs can properly utilize their\nlegal knowledge and make necessary reasoning steps to solve realistic legal\ntasks. LawBench contains 20 diverse tasks covering 5 task types: single-label\nclassification (SLC), multi-label classification (MLC), regression, extraction\nand generation. We perform extensive evaluations of 51 LLMs on LawBench,\nincluding 20 multilingual LLMs, 22 Chinese-oriented LLMs and 9 legal specific\nLLMs. The results show that GPT-4 remains the best-performing LLM in the legal\ndomain, surpassing the others by a significant margin. While fine-tuning LLMs\non legal specific text brings certain improvements, we are still a long way\nfrom obtaining usable and reliable LLMs in legal tasks. All data, model\npredictions and evaluation code are released in\nhttps://github.com/open-compass/LawBench/. We hope this benchmark provides\nin-depth understanding of the LLMs' domain-specified capabilities and speed up\nthe development of LLMs in the legal domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1\">Zhiwei Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1\">Xiaoyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Dawei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Fengzhe Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Zhuo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zongwen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_J/0/1/0/all/0/1\">Jidong Ge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiLu: A Knowledge-Driven Approach to Autonomous Driving with Large Language Models. (arXiv:2309.16292v1 [cs.RO])","link":"http://arxiv.org/abs/2309.16292","description":"<p>Recent advancements in autonomous driving have relied on data-driven\napproaches, which are widely adopted but face challenges including dataset\nbias, overfitting, and uninterpretability. Drawing inspiration from the\nknowledge-driven nature of human driving, we explore the question of how to\ninstill similar capabilities into autonomous driving systems and summarize a\nparadigm that integrates an interactive environment, a driver agent, as well as\na memory component to address this question. Leveraging large language models\nwith emergent abilities, we propose the DiLu framework, which combines a\nReasoning and a Reflection module to enable the system to perform\ndecision-making based on common-sense knowledge and evolve continuously.\nExtensive experiments prove DiLu's capability to accumulate experience and\ndemonstrate a significant advantage in generalization ability over\nreinforcement learning-based methods. Moreover, DiLu is able to directly\nacquire experiences from real-world datasets which highlights its potential to\nbe deployed on practical autonomous driving systems. To the best of our\nknowledge, we are the first to instill knowledge-driven capability into\nautonomous driving systems from the perspective of how humans drive.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Licheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1\">Daocheng Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xinyu Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1\">Tao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1\">Pinlong Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_M/0/1/0/all/0/1\">Min Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Botian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Liang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"At Which Training Stage Does Cocde Data Help LLMs Reasoning?. (arXiv:2309.16298v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16298","description":"<p>Large Language Models (LLMs) have exhibited remarkable reasoning capabilities\nand become the foundation of language technologies. Inspired by the great\nsuccess of code data in training LLMs, we naturally wonder at which training\nstage introducing code data can really help LLMs reasoning. To this end, this\npaper systematically explores the impact of code data on LLMs at different\nstages. Concretely, we introduce the code data at the pre-training stage,\ninstruction-tuning stage, and both of them, respectively. Then, the reasoning\ncapability of LLMs is comprehensively and fairly evaluated via six reasoning\ntasks in five domains. We critically analyze the experimental results and\nprovide conclusions with insights. First, pre-training LLMs with the mixture of\ncode and text can significantly enhance LLMs' general reasoning capability\nalmost without negative transfer on other tasks. Besides, at the\ninstruction-tuning stage, code data endows LLMs the task-specific reasoning\ncapability. Moreover, the dynamic mixing strategy of code and text data assists\nLLMs to learn reasoning capability step-by-step during training. These insights\ndeepen the understanding of LLMs regarding reasoning ability for their\napplication, such as scientific question answering, legal support, etc. The\nsource code and model parameters are released at the\nlink:~\\url{https://github.com/yingweima2022/CodeLLM}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingwei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Changjian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shanshan Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenting transformers with recursively composed multi-grained representations. (arXiv:2309.16319v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16319","description":"<p>We present ReCAT, a recursive composition augmented Transformer that is able\nto explicitly model hierarchical syntactic structures of raw texts without\nrelying on gold trees during both learning and inference. Existing research\nalong this line restricts data to follow a hierarchical tree structure and thus\nlacks inter-span communications. To overcome the problem, we propose a novel\ncontextual inside-outside (CIO) layer that learns contextualized\nrepresentations of spans through bottom-up and top-down passes, where a\nbottom-up pass forms representations of high-level spans by composing low-level\nspans, while a top-down pass combines information inside and outside a span. By\nstacking several CIO layers between the embedding layer and the attention\nlayers in Transformer, the ReCAT model can perform both deep intra-span and\ndeep inter-span interactions, and thus generate multi-grained representations\nfully contextualized with other spans. Moreover, the CIO layers can be jointly\npre-trained with Transformers, making ReCAT enjoy scaling ability, strong\nperformance, and interpretability at the same time. We conduct experiments on\nvarious sentence-level and span-level tasks. Evaluation results indicate that\nReCAT can significantly outperform vanilla Transformer models on all span-level\ntasks and baselines that combine recursive networks with Transformers on\nnatural language inference tasks. More interestingly, the hierarchical\nstructures induced by ReCAT exhibit strong consistency with human-annotated\nsyntactic trees, indicating good interpretability brought by the CIO layers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qingyang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kewei Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intrinsic Language-Guided Exploration for Complex Long-Horizon Robotic Manipulation Tasks. (arXiv:2309.16347v1 [cs.RO])","link":"http://arxiv.org/abs/2309.16347","description":"<p>Current reinforcement learning algorithms struggle in sparse and complex\nenvironments, most notably in long-horizon manipulation tasks entailing a\nplethora of different sequences. In this work, we propose the Intrinsically\nGuided Exploration from Large Language Models (IGE-LLMs) framework. By\nleveraging LLMs as an assistive intrinsic reward, IGE-LLMs guides the\nexploratory process in reinforcement learning to address intricate long-horizon\nwith sparse rewards robotic manipulation tasks. We evaluate our framework and\nrelated intrinsic learning methods in an environment challenged with\nexploration, and a complex robotic manipulation task challenged by both\nexploration and long-horizons. Results show IGE-LLMs (i) exhibit notably higher\nperformance over related intrinsic methods and the direct use of LLMs in\ndecision-making, (ii) can be combined and complement existing learning methods\nhighlighting its modularity, (iii) are fairly insensitive to different\nintrinsic scaling parameters, and (iv) maintain robustness against increased\nlevels of uncertainty and horizons.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Triantafyllidis_E/0/1/0/all/0/1\">Eleftherios Triantafyllidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1\">Filippos Christianos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhibin Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human Feedback is not Gold Standard. (arXiv:2309.16349v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16349","description":"<p>Human feedback has become the de facto standard for evaluating the\nperformance of Large Language Models, and is increasingly being used as a\ntraining objective. However, it is not clear which properties of a generated\noutput this single `preference' score captures. We hypothesise that preference\nscores are subjective and open to undesirable biases. We critically analyse the\nuse of human feedback for both training and evaluation, to verify whether it\nfully captures a range of crucial error criteria. We find that while preference\nscores have fairly good coverage, they under-represent important aspects like\nfactuality. We further hypothesise that both preference scores and error\nannotation may be affected by confounders, and leverage instruction-tuned\nmodels to generate outputs that vary along two possible confounding dimensions:\nassertiveness and complexity. We find that the assertiveness of an output skews\nthe perceived rate of factuality errors, indicating that human annotations are\nnot a fully reliable evaluation metric or training objective. Finally, we offer\npreliminary evidence that using human feedback as a training objective\ndisproportionately increases the assertiveness of model outputs. We encourage\nfuture work to carefully consider whether preference scores are well aligned\nwith the desired objective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hosking_T/0/1/0/all/0/1\">Tom Hosking</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1\">Phil Blunsom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bartolo_M/0/1/0/all/0/1\">Max Bartolo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-VQ: Linear-Time Transformers via Vector Quantization. (arXiv:2309.16354v1 [cs.LG])","link":"http://arxiv.org/abs/2309.16354","description":"<p>We introduce Transformer-VQ, a decoder-only transformer computing\nsoftmax-based dense self-attention in linear time. Transformer-VQ's efficient\nattention is enabled by vector-quantized keys and a novel caching mechanism. In\nlarge-scale experiments, Transformer-VQ is shown highly competitive in quality,\nwith strong results on Enwik8 (0.99 bpb), PG-19 (26.6 ppl), and ImageNet64\n(3.16 bpb). Code: https://github.com/transformer-vq/transformer_vq\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lingle_L/0/1/0/all/0/1\">Lucas D. Lingle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey of Document-level Relation Extraction (2016-2022). (arXiv:2309.16396v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16396","description":"<p>Document-level relation extraction (DocRE) is an active area of research in\nnatural language processing (NLP) concerned with identifying and extracting\nrelationships between entities beyond sentence boundaries. Compared to the more\ntraditional sentence-level relation extraction, DocRE provides a broader\ncontext for analysis and is more challenging because it involves identifying\nrelationships that may span multiple sentences or paragraphs. This task has\ngained increased interest as a viable solution to build and populate knowledge\nbases automatically from unstructured large-scale documents (e.g., scientific\npapers, legal contracts, or news articles), in order to have a better\nunderstanding of relationships between entities. This paper aims to provide a\ncomprehensive overview of recent advances in this field, highlighting its\ndifferent applications in comparison to sentence-level relation extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Delaunay_J/0/1/0/all/0/1\">Julien Delaunay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thi Hong Hanh Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Gallardo_C/0/1/0/all/0/1\">Carlos-Emiliano Gonz&#xe1;lez-Gallardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordea_G/0/1/0/all/0/1\">Georgeta Bordea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidere_N/0/1/0/all/0/1\">Nicolas Sidere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Antoine Doucet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News Detection. (arXiv:2309.16424v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16424","description":"<p>Despite considerable advances in automated fake news detection, due to the\ntimely nature of news, it remains a critical open question how to effectively\npredict the veracity of news articles based on limited fact-checks. Existing\napproaches typically follow a \"Train-from-Scratch\" paradigm, which is\nfundamentally bounded by the availability of large-scale annotated data. While\nexpressive pre-trained language models (PLMs) have been adapted in a\n\"Pre-Train-and-Fine-Tune\" manner, the inconsistency between pre-training and\ndownstream objectives also requires costly task-specific supervision. In this\npaper, we propose \"Prompt-and-Align\" (P&amp;A), a novel prompt-based paradigm for\nfew-shot fake news detection that jointly leverages the pre-trained knowledge\nin PLMs and the social context topology. Our approach mitigates label scarcity\nby wrapping the news article in a task-related textual prompt, which is then\nprocessed by the PLM to directly elicit task-specific knowledge. To supplement\nthe PLM with social context without inducing additional training overheads,\nmotivated by empirical observation on user veracity consistency (i.e., social\nusers tend to consume news of the same veracity type), we further construct a\nnews proximity graph among news articles to capture the veracity-consistent\nsignals in shared readerships, and align the prompting predictions along the\ngraph edges in a confidence-informed manner. Extensive experiments on three\nreal-world benchmarks demonstrate that P&amp;A sets new states-of-the-art for\nfew-shot fake news detection performance by significant margins.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiaying Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_A/0/1/0/all/0/1\">Ailin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_M/0/1/0/all/0/1\">Miao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenting LLMs with Knowledge: A survey on hallucination prevention. (arXiv:2309.16459v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16459","description":"<p>Large pre-trained language models have demonstrated their proficiency in\nstoring factual knowledge within their parameters and achieving remarkable\nresults when fine-tuned for downstream natural language processing tasks.\nNonetheless, their capacity to access and manipulate knowledge with precision\nremains constrained, resulting in performance disparities on\nknowledge-intensive tasks when compared to task-specific architectures.\nAdditionally, the challenges of providing provenance for model decisions and\nmaintaining up-to-date world knowledge persist as open research frontiers. To\naddress these limitations, the integration of pre-trained models with\ndifferentiable access mechanisms to explicit non-parametric memory emerges as a\npromising solution. This survey delves into the realm of language models (LMs)\naugmented with the ability to tap into external knowledge sources, including\nexternal knowledge bases and search engines. While adhering to the standard\nobjective of predicting missing tokens, these augmented LMs leverage diverse,\npossibly non-parametric external modules to augment their contextual processing\ncapabilities, departing from the conventional language modeling paradigm.\nThrough an exploration of current advancements in augmenting large language\nmodels with knowledge, this work concludes that this emerging research\ndirection holds the potential to address prevalent issues in traditional LMs,\nsuch as hallucinations, un-grounded responses, and scalability challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Andriopoulos_K/0/1/0/all/0/1\">Konstantinos Andriopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pouwelse_J/0/1/0/all/0/1\">Johan Pouwelse</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toloka Visual Question Answering Benchmark. (arXiv:2309.16511v1 [cs.CV])","link":"http://arxiv.org/abs/2309.16511","description":"<p>In this paper, we present Toloka Visual Question Answering, a new\ncrowdsourced dataset allowing comparing performance of machine learning systems\nagainst human level of expertise in the grounding visual question answering\ntask. In this task, given an image and a textual question, one has to draw the\nbounding box around the object correctly responding to that question. Every\nimage-question pair contains the response, with only one correct response per\nimage. Our dataset contains 45,199 pairs of images and questions in English,\nprovided with ground truth bounding boxes, split into train and two test\nsubsets. Besides describing the dataset and releasing it under a CC BY license,\nwe conducted a series of experiments on open source zero-shot baseline models\nand organized a multi-phase competition at WSDM Cup that attracted 48\nparticipants worldwide. However, by the time of paper submission, no machine\nlearning model outperformed the non-expert crowdsourcing baseline according to\nthe intersection over union evaluation score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ustalov_D/0/1/0/all/0/1\">Dmitry Ustalov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pavlichenko_N/0/1/0/all/0/1\">Nikita Pavlichenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koshelev_S/0/1/0/all/0/1\">Sergey Koshelev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Likhobaba_D/0/1/0/all/0/1\">Daniil Likhobaba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smirnova_A/0/1/0/all/0/1\">Alisa Smirnova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KLoB: a Benchmark for Assessing Knowledge Locating Methods in Language Models. (arXiv:2309.16535v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16535","description":"<p>Recently, Locate-Then-Edit paradigm has emerged as one of the main approaches\nin changing factual knowledge stored in the Language models. However, there is\na lack of research on whether present locating methods can pinpoint the exact\nparameters embedding the desired knowledge. Moreover, although many researchers\nhave questioned the validity of locality hypothesis of factual knowledge, no\nmethod is provided to test the a hypothesis for more in-depth discussion and\nresearch. Therefore, we introduce KLoB, a benchmark examining three essential\nproperties that a reliable knowledge locating method should satisfy. KLoB can\nserve as a benchmark for evaluating existing locating methods in language\nmodels, and can contributes a method to reassessing the validity of locality\nhypothesis of factual knowledge. Our is publicly available at\n\\url{https://github.com/juyiming/KLoB}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ju_Y/0/1/0/all/0/1\">Yiming Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16540","description":"<p>Unsupervised fact verification aims to verify a claim using evidence from a\ntrustworthy knowledge base without any kind of data annotation. To address this\nchallenge, algorithms must produce features for every claim that are both\nsemantically meaningful, and compact enough to find a semantic alignment with\nthe source information. In contrast to previous work, which tackled the\nalignment problem by learning over annotated corpora of claims and their\ncorresponding labels, we propose SFAVEL (Self-supervised Fact Verification via\nLanguage Model Distillation), a novel unsupervised framework that leverages\npre-trained language models to distil self-supervised features into\nhigh-quality claim-fact alignments without the need for annotations. This is\nenabled by a novel contrastive loss function that encourages features to attain\nhigh-quality claim and evidence alignments whilst preserving the semantic\nrelationships across the corpora. Notably, we present results that achieve a\nnew state-of-the-art on the standard FEVER fact verification benchmark (+8%\naccuracy) with linear evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The ARRT of Language-Models-as-a-Service: Overview of a New Paradigm and its Challenges. (arXiv:2309.16573v1 [cs.AI])","link":"http://arxiv.org/abs/2309.16573","description":"<p>Some of the most powerful language models currently are proprietary systems,\naccessible only via (typically restrictive) web or software programming\ninterfaces. This is the Language-Models-as-a-Service (LMaaS) paradigm.\nContrasting with scenarios where full model access is available, as in the case\nof open-source models, such closed-off language models create specific\nchallenges for evaluating, benchmarking, and testing them. This paper has two\ngoals: on the one hand, we delineate how the aforementioned challenges act as\nimpediments to the accessibility, replicability, reliability, and\ntrustworthiness (ARRT) of LMaaS. We systematically examine the issues that\narise from a lack of information about language models for each of these four\naspects. We shed light on current solutions, provide some recommendations, and\nhighlight the directions for future advancements. On the other hand, it serves\nas a one-stop-shop for the extant knowledge about current, major LMaaS,\noffering a synthesized overview of the licences and capabilities their\ninterfaces offer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1\">Emanuele La Malfa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petrov_A/0/1/0/all/0/1\">Aleksandar Petrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frieder_S/0/1/0/all/0/1\">Simon Frieder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinhuber_C/0/1/0/all/0/1\">Christoph Weinhuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Burnell_R/0/1/0/all/0/1\">Ryan Burnell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1\">Anthony G. Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shadbolt_N/0/1/0/all/0/1\">Nigel Shadbolt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1\">Michael Wooldridge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Benchmark for Learning to Translate a New Language from One Grammar Book. (arXiv:2309.16575v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16575","description":"<p>Large language models (LLMs) can perform impressive feats with in-context\nlearning or lightweight finetuning. It is natural to wonder how well these\nmodels adapt to genuinely new tasks, but how does one find tasks that are\nunseen in internet-scale training sets? We turn to a field that is explicitly\nmotivated and bottlenecked by a scarcity of web data: low-resource languages.\nIn this paper, we introduce MTOB (Machine Translation from One Book), a\nbenchmark for learning to translate between English and Kalamang -- a language\nwith less than 200 speakers and therefore virtually no presence on the web --\nusing several hundred pages of field linguistics reference materials. This task\nframing is novel in that it asks a model to learn a language from a single\nhuman-readable book of grammar explanations, rather than a large mined corpus\nof in-domain data, more akin to L2 learning than L1 acquisition. We demonstrate\nthat baselines using current LLMs are promising but fall short of human\nperformance, achieving 44.7 chrF on Kalamang to English translation and 45.8\nchrF on English to Kalamang translation, compared to 51.6 and 57.0 chrF by a\nhuman who learned Kalamang from the same reference materials. We hope that MTOB\nwill help measure LLM capabilities along a new dimension, and that the methods\ndeveloped to solve it could help expand access to language technology for\nunderserved communities by leveraging qualitatively different kinds of data\nthan traditional machine translation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tanzer_G/0/1/0/all/0/1\">Garrett Tanzer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzgun_M/0/1/0/all/0/1\">Mirac Suzgun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Visser_E/0/1/0/all/0/1\">Eline Visser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1\">Dan Jurafsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melas_Kyriazi_L/0/1/0/all/0/1\">Luke Melas-Kyriazi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond. (arXiv:2309.16583v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16583","description":"<p>With the rapid advancement of large language models (LLMs), there is a\npressing need for a comprehensive evaluation suite to assess their capabilities\nand limitations. Existing LLM leaderboards often reference scores reported in\nother papers without consistent settings and prompts, which may inadvertently\nencourage cherry-picking favored settings and prompts for better results. In\nthis work, we introduce GPT-Fathom, an open-source and reproducible LLM\nevaluation suite built on top of OpenAI Evals. We systematically evaluate 10+\nleading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across\n7 capability categories, all under aligned settings. Our retrospective study on\nOpenAI's earlier models offers valuable insights into the evolutionary path\nfrom GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3\nprogressively improves to GPT-4, including technical details like whether\nadding code data improves LLM's reasoning capability, which aspects of LLM\ncapability can be improved by SFT and RLHF, how much is the alignment tax, etc.\nOur analysis sheds light on many of these questions, aiming to improve the\ntransparency of advanced LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1\">Chenguang Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Pengyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot Translation. (arXiv:2309.16599v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16599","description":"<p>Zero-shot translation (ZST), which is generally based on a multilingual\nneural machine translation model, aims to translate between unseen language\npairs in training data. The common practice to guide the zero-shot language\nmapping during inference is to deliberately insert the source and target\nlanguage IDs, e.g., &lt;EN&gt; for English and &lt;DE&gt; for German. Recent studies have\nshown that language IDs sometimes fail to navigate the ZST task, making them\nsuffer from the off-target problem (non-target language words exist in the\ngenerated translation) and, therefore, difficult to apply the current\nmultilingual translation model to a broad range of zero-shot language\nscenarios. To understand when and why the navigation capabilities of language\nIDs are weakened, we compare two extreme decoder input cases in the ZST\ndirections: Off-Target (OFF) and On-Target (ON) cases. By contrastively\nvisualizing the contextual word representations (CWRs) of these cases with\nteacher forcing, we show that 1) the CWRs of different languages are\neffectively distributed in separate regions when the sentence and ID are\nmatched (ON setting), and 2) if the sentence and ID are unmatched (OFF\nsetting), the CWRs of different languages are chaotically distributed. Our\nanalyses suggest that although they work well in ideal ON settings, language\nIDs become fragile and lose their navigation ability when faced with off-target\ntokens, which commonly exist during inference but are rare in training\nscenarios. In response, we employ unlikelihood tuning on the negative (OFF)\nsamples to minimize their probability such that the language IDs can\ndiscriminate between the on- and off-target tokens during training. Experiments\nspanning 40 ZST directions show that our method reduces the off-target ratio by\n-48.0% on average, leading to a +9.1 BLEU improvement with only an extra +0.3%\ntuning cost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zan_C/0/1/0/all/0/1\">Changtong Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1\">Yibin Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1\">Yibing Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qwen Technical Report. (arXiv:2309.16609v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16609","description":"<p>Large language models (LLMs) have revolutionized the field of artificial\nintelligence, enabling natural language processing tasks that were previously\nthought to be exclusive to humans. In this work, we introduce Qwen, the first\ninstallment of our large language model series. Qwen is a comprehensive\nlanguage model series that encompasses distinct models with varying parameter\ncounts. It includes Qwen, the base pretrained language models, and Qwen-Chat,\nthe chat models finetuned with human alignment techniques. The base language\nmodels consistently demonstrate superior performance across a multitude of\ndownstream tasks, and the chat models, particularly those trained using\nReinforcement Learning from Human Feedback (RLHF), are highly competitive. The\nchat models possess advanced tool-use and planning capabilities for creating\nagent applications, showcasing impressive performance even when compared to\nbigger models on complex tasks like utilizing a code interpreter. Furthermore,\nwe have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as\nwell as mathematics-focused models, Math-Qwen-Chat, which are built upon base\nlanguage models. These models demonstrate significantly improved performance in\ncomparison with open-source models, and slightly fall behind the proprietary\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jinze Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1\">Shuai Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1\">Yunfei Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Zeyu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_K/0/1/0/all/0/1\">Kai Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiaodong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yang Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1\">Wenbin Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yu Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hui_B/0/1/0/all/0/1\">Binyuan Hui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1\">Luo Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Junyang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1\">Runji Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dayiheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Gao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chengqiang Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Keming Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jianxin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1\">Rui Men</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xingzhang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1\">Sinan Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_J/0/1/0/all/0/1\">Jianhong Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shengguang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Benfeng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1\">An Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shusheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yang Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bowen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongyi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhenru Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jingren Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xiaohuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1\">Tianhang Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stress Testing Chain-of-Thought Prompting for Large Language Models. (arXiv:2309.16621v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16621","description":"<p>This report examines the effectiveness of Chain-of-Thought (CoT) prompting in\nimproving the multi-step reasoning abilities of large language models (LLMs).\nInspired by previous studies \\cite{Min2022RethinkingWork}, we analyze the\nimpact of three types of CoT prompt perturbations, namely CoT order, CoT\nvalues, and CoT operators on the performance of GPT-3 on various tasks. Our\nfindings show that incorrect CoT prompting leads to poor performance on\naccuracy metrics. Correct values in the CoT is crucial for predicting correct\nanswers. Moreover, incorrect demonstrations, where the CoT operators or the CoT\norder are wrong, do not affect the performance as drastically when compared to\nthe value based perturbations. This research deepens our understanding of CoT\nprompting and opens some new questions regarding the capability of LLMs to\nlearn reasoning in context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1\">Aayush Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakkar_K/0/1/0/all/0/1\">Karan Thakkar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MindShift: Leveraging Large Language Models for Mental-States-Based Problematic Smartphone Use Intervention. (arXiv:2309.16639v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16639","description":"<p>Problematic smartphone use negatively affects physical and mental health.\nDespite the wide range of prior research, existing persuasive techniques are\nnot flexible enough to provide dynamic persuasion content based on users'\nphysical contexts and mental states. We first conduct a Wizard-of-Oz study\n(N=12) and an interview study (N=10) to summarize the mental states behind\nproblematic smartphone use: boredom, stress, and inertia. This informs our\ndesign of four persuasion strategies: understanding, comforting, evoking, and\nscaffolding habits. We leverage large language models (LLMs) to enable the\nautomatic and dynamic generation of effective persuasion content. We develop\nMindShift, a novel LLM-powered problematic smartphone use intervention\ntechnique. MindShift takes users' in-the-moment physical contexts, mental\nstates, app usage behaviors, users' goals &amp; habits as input, and generates\nhigh-quality and flexible persuasive content with appropriate persuasion\nstrategies. We conduct a 5-week field experiment (N=25) to compare MindShift\nwith baseline techniques. The results show that MindShift significantly\nimproves intervention acceptance rates by 17.8-22.5% and reduces smartphone use\nfrequency by 12.1-14.4%. Moreover, users have a significant drop in smartphone\naddiction scale scores and a rise in self-efficacy. Our study sheds light on\nthe potential of leveraging LLMs for context-aware persuasion in other behavior\nchange domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1\">Ruolan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1\">Xiaole Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yujia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningning Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yue Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Q/0/1/0/all/0/1\">Qiaolei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xuhai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuanchun Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Demystifying CLIP Data. (arXiv:2309.16671v1 [cs.CV])","link":"http://arxiv.org/abs/2309.16671","description":"<p>Contrastive Language-Image Pre-training (CLIP) is an approach that has\nadvanced research and applications in computer vision, fueling modern\nrecognition systems and generative models. We believe that the main ingredient\nto the success of CLIP is its data and not the model architecture or\npre-training objective. However, CLIP only provides very limited information\nabout its data and how it has been collected, leading to works that aim to\nreproduce CLIP's data by filtering with its model parameters. In this work, we\nintend to reveal CLIP's data curation approach and in our pursuit of making it\nopen to the community introduce Metadata-Curated Language-Image Pre-training\n(MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's\nconcepts) and yields a balanced subset over the metadata distribution. Our\nexperimental study rigorously isolates the model and training settings,\nconcentrating solely on data. MetaCLIP applied to CommonCrawl with 400M\nimage-text data pairs outperforms CLIP's data on multiple standard benchmarks.\nIn zero-shot ImageNet classification, MetaCLIP achieves 70.8% accuracy,\nsurpassing CLIP's 68.3% on ViT-B models. Scaling to 1B data, while maintaining\nthe same training budget, attains 72.4%. Our observations hold across various\nmodel sizes, exemplified by ViT-H achieving 80.5%, without any\nbells-and-whistles. Curation code and training data distribution on metadata is\nmade available at https://github.com/facebookresearch/MetaCLIP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Saining Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiaoqing Ellen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Po-Yao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howes_R/0/1/0/all/0/1\">Russell Howes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vasu Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_G/0/1/0/all/0/1\">Gargi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1\">Christoph Feichtenhofer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Higher-order Derivatives of Weighted Finite-state Machines. (arXiv:2106.00749v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2106.00749","description":"<p>Weighted finite-state machines are a fundamental building block of NLP\nsystems. They have withstood the test of time -- from their early use in noisy\nchannel models in the 1990s up to modern-day neurally parameterized conditional\nrandom fields. This work examines the computation of higher-order derivatives\nwith respect to the normalization constant for weighted finite-state machines.\nWe provide a general algorithm for evaluating derivatives of all orders, which\nhas not been previously described in the literature. In the case of\nsecond-order derivatives, our scheme runs in the optimal $\\mathcal{O}(A^2 N^4)$\ntime where $A$ is the alphabet size and $N$ is the number of states. Our\nalgorithm is significantly faster than prior algorithms. Additionally, our\napproach leads to a significantly faster algorithm for computing second-order\nexpectations, such as covariance matrices and gradients of first-order\nexpectations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zmigrod_R/0/1/0/all/0/1\">Ran Zmigrod</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1\">Tim Vieira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personal Entity, Concept, and Named Entity Linking in Conversations. (arXiv:2206.07836v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.07836","description":"<p>Building conversational agents that can have natural and knowledge-grounded\ninteractions with humans requires understanding user utterances. Entity Linking\n(EL) is an effective and widely used method for understanding natural language\ntext and connecting it to external knowledge. It is, however, shown that\nexisting EL methods developed for annotating documents are suboptimal for\nconversations, where personal entities (e.g., \"my cars\") and concepts are\nessential for understanding user utterances. In this paper, we introduce a\ncollection and a tool for entity linking in conversations. We collect EL\nannotations for 1327 conversational utterances, consisting of links to named\nentities, concepts, and personal entities. The dataset is used for training our\ntoolkit for conversational entity linking, CREL. Unlike existing EL methods,\nCREL is developed to identify both named entities and concepts. It also\nutilizes coreference resolution techniques to identify personal entities and\nreferences to the explicit entity mentions in the conversations. We compare\nCREL with state-of-the-art techniques and show that it outperforms all existing\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Joko_H/0/1/0/all/0/1\">Hideaki Joko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasibi_F/0/1/0/all/0/1\">Faegheh Hasibi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Role of Morphological Information for Contextual Lemmatization. (arXiv:2302.00407v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.00407","description":"<p>Lemmatization is a natural language processing (NLP) task which consists of\nproducing, from a given inflected word, its canonical form or lemma.\nLemmatization is one of the basic tasks that facilitate downstream NLP\napplications, and is of particular importance for high-inflected languages.\nGiven that the process to obtain a lemma from an inflected word can be\nexplained by looking at its morphosyntactic category, including fine-grained\nmorphosyntactic information to train contextual lemmatizers has become common\npractice, without considering whether that is the optimum in terms of\ndownstream performance. In order to address this issue, in this paper we\nempirically investigate the role of morphological information to develop\ncontextual lemmatizers in six languages within a varied spectrum of\nmorphological complexity: Basque, Turkish, Russian, Czech, Spanish and English.\nFurthermore, and unlike the vast majority of previous work, we also evaluate\nlemmatizers in out-of-domain settings, which constitutes, after all, their most\ncommon application use. The results of our study are rather surprising. It\nturns out that providing lemmatizers with fine-grained morphological features\nduring training is not that beneficial, not even for agglutinative languages.\nIn fact, modern contextual word representations seem to implicitly encode\nenough morphological information to obtain competitive contextual lemmatizers\nwithout seeing any explicit morphological signal. Moreover, our experiments\nsuggest that the best lemmatizers out-of-domain are those using simple UPOS\ntags or those trained without morphology and, finally, that current evaluation\npractices for lemmatization are not adequate to clearly discriminate between\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toporkov_O/0/1/0/all/0/1\">Olia Toporkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visualizing Linguistic Diversity of Text Datasets Synthesized by Large Language Models. (arXiv:2305.11364v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11364","description":"<p>Large language models (LLMs) can be used to generate smaller, more refined\ndatasets via few-shot prompting for benchmarking, fine-tuning or other use\ncases. However, understanding and evaluating these datasets is difficult, and\nthe failure modes of LLM-generated data are still not well understood.\nSpecifically, the data can be repetitive in surprising ways, not only\nsemantically but also syntactically and lexically. We present LinguisticLens, a\nnovel inter-active visualization tool for making sense of and analyzing\nsyntactic diversity of LLM-generated datasets. LinguisticLens clusters text\nalong syntactic, lexical, and semantic axes. It supports hierarchical\nvisualization of a text dataset, allowing users to quickly scan for an overview\nand inspect individual examples. The live demo is available at\nshorturl.at/zHOUV.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reif_E/0/1/0/all/0/1\">Emily Reif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kahng_M/0/1/0/all/0/1\">Minsuk Kahng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1\">Savvas Petridis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Pruner: On the Structural Pruning of Large Language Models. (arXiv:2305.11627v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11627","description":"<p>Large language models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. However, such impressive capability typically\ncomes with a substantial model size, which presents significant challenges in\nboth the deployment, inference, and training stages. With LLM being a\ngeneral-purpose task solver, we explore its compression in a task-agnostic\nmanner, which aims to preserve the multi-task solving and language generation\nability of the original LLM. One challenge to achieving this is the enormous\nsize of the training corpus of LLM, which makes both data transfer and model\npost-training over-burdensome. Thus, we tackle the compression of LLMs within\nthe bound of two constraints: being task-agnostic and minimizing the reliance\non the original training dataset. Our method, named LLM-Pruner, adopts\nstructural pruning that selectively removes non-critical coupled structures\nbased on gradient information, maximally preserving the majority of the LLM's\nfunctionality. To this end, the performance of pruned models can be efficiently\nrecovered through tuning techniques, LoRA, in merely 3 hours, requiring only\n50K data. We validate the LLM-Pruner on three LLMs, including LLaMA, Vicuna,\nand ChatGLM, and demonstrate that the compressed models still exhibit\nsatisfactory capabilities in zero-shot classification and generation. The code\nis available at: https://github.com/horseee/LLM-Pruner\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinyin Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_G/0/1/0/all/0/1\">Gongfan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Acceptability Judgements. (arXiv:2305.14091v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14091","description":"<p>In this work, we revisit linguistic acceptability in the context of large\nlanguage models. We introduce CoLAC - Corpus of Linguistic Acceptability in\nChinese, the first large-scale acceptability dataset for a non-Indo-European\nlanguage. It is verified by native speakers and is the first acceptability\ndataset that comes with two sets of labels: a linguist label and a crowd label.\nOur experiments show that even the largest InstructGPT model performs only at\nchance level on CoLAC, while ChatGPT's performance (48.30 MCC) is also much\nbelow supervised models (59.03 MCC) and human (65.11 MCC). Through\ncross-lingual transfer experiments and fine-grained linguistic analysis, we\nprovide detailed analysis of the model predictions and demonstrate for the\nfirst time that knowledge of linguistic acceptability can be transferred across\ntypologically distinct languages, as well as be traced back to pre-training.\nOur dataset is publicly available at\n\\url{https://github.com/huhailinguist/CoLAC}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hai Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Weifang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_J/0/1/0/all/0/1\">Jackie Yan-Ki Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Aini Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patterson_Y/0/1/0/all/0/1\">Yina Patterson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiahui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Peng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chien-Jer Charles Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Corrections of Zipf's and Heaps' Laws Derived from Hapax Rate Models. (arXiv:2307.12896v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.12896","description":"<p>The article introduces corrections to Zipf's and Heaps' laws based on\nsystematic models of the hapax rate. The derivation rests on two assumptions:\nThe first one is the standard urn model which predicts that marginal frequency\ndistributions for shorter texts look as if word tokens were sampled blindly\nfrom a given longer text. The second assumption posits that the rate of hapaxes\nis a simple function of the text size. Four such functions are discussed: the\nconstant model, the Davis model, the linear model, and the logistic model. It\nis shown that the logistic model yields the best fit.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Debowski_L/0/1/0/all/0/1\">&#x141;ukasz D&#x119;bowski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VisIT-Bench: A Benchmark for Vision-Language Instruction Following Inspired by Real-World Use. (arXiv:2308.06595v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.06595","description":"<p>We introduce VisIT-Bench (Visual InsTruction Benchmark), a benchmark for\nevaluation of instruction-following vision-language models for real-world use.\nOur starting point is curating 70 'instruction families' that we envision\ninstruction tuned vision-language models should be able to address. Extending\nbeyond evaluations like VQAv2 and COCO, tasks range from basic recognition to\ngame playing and creative generation. Following curation, our dataset comprises\n592 test queries, each with a human-authored instruction-conditioned caption.\nThese descriptions surface instruction-specific factors, e.g., for an\ninstruction asking about the accessibility of a storefront for wheelchair\nusers, the instruction-conditioned caption describes ramps/potential obstacles.\nThese descriptions enable 1) collecting human-verified reference outputs for\neach instance; and 2) automatic evaluation of candidate multimodal generations\nusing a text-only LLM, aligning with human judgment. We quantify quality gaps\nbetween models and references using both human and automatic evaluations; e.g.,\nthe top-performing instruction-following model wins against the GPT-4 reference\nin just 27% of the comparison. VisIT-Bench is dynamic to participate,\npractitioners simply submit their model's response on the project website;\nData, code and leaderboard is available at visit-bench.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1\">Hritik Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1\">Jack Hessel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1\">Rulin Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1\">Wanrong Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadalla_A/0/1/0/all/0/1\">Anas Awadalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1\">Josh Gardner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Taori_R/0/1/0/all/0/1\">Rohan Taori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schimdt_L/0/1/0/all/0/1\">Ludwig Schimdt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language Models. (arXiv:2308.10379v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10379","description":"<p>Current literature, aiming to surpass the \"Chain-of-Thought\" approach, often\nresorts to an external modus operandi involving halting, modifying, and then\nresuming the generation process to boost Large Language Models' (LLMs)\nreasoning capacities. This mode escalates the number of query requests, leading\nto increased costs, memory, and computational overheads. Addressing this, we\npropose the Algorithm of Thoughts -- a novel strategy that propels LLMs through\nalgorithmic reasoning pathways, pioneering a new mode of in-context learning.\nBy employing algorithmic examples, we exploit the innate recurrence dynamics of\nLLMs, expanding their idea exploration with merely one or a few queries. Our\ntechnique outperforms earlier single-query methods and stands on par with a\nrecent multi-query strategy that employs an extensive tree search algorithm.\nIntriguingly, our results suggest that instructing an LLM using an algorithm\ncan lead to performance surpassing that of the algorithm itself, hinting at\nLLM's inherent ability to weave its intuition into optimized searches. We probe\ninto the underpinnings of our method's efficacy and its nuances in application.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sel_B/0/1/0/all/0/1\">Bilgehan Sel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Tawaha_A/0/1/0/all/0/1\">Ahmad Al-Tawaha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khattar_V/0/1/0/all/0/1\">Vanshaj Khattar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_R/0/1/0/all/0/1\">Ruoxi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Ming Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks. (arXiv:2308.14359v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.14359","description":"<p>Human emotion understanding is pivotal in making conversational technology\nmainstream. We view speech emotion understanding as a perception task which is\na more realistic setting. With varying contexts (languages, demographics, etc.)\ndifferent share of people perceive the same speech segment as a non-unanimous\nemotion. As part of the ACM Multimedia 2023 Computational Paralinguistics\nChallengE (ComParE) in the EMotion Share track, we leverage their rich dataset\nof multilingual speakers and multi-label regression target of 'emotion share'\nor perception of that emotion. We demonstrate that the training scheme of\ndifferent foundation models dictates their effectiveness for tasks beyond\nspeech recognition, especially for non-semantic speech tasks like emotion\nunderstanding. This is a very complex task due to multilingual speakers,\nvariability in the target labels, and inherent imbalance in the regression\ndataset. Our results show that HuBERT-Large with a self-attention-based\nlight-weight sequence model provides 4.6% improvement over the reported\nbaseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohapatra_P/0/1/0/all/0/1\">Payal Mohapatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1\">Akash Pandey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1\">Yueyuan Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qi Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimize Weight Rounding via Signed Gradient Descent for the Quantization of LLMs. (arXiv:2309.05516v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05516","description":"<p>Large Language Models (LLMs) have proven their exceptional capabilities in\nperforming language-related tasks. However, their deployment poses significant\nchallenges due to their considerable memory and storage requirements. In\nresponse to this issue, weight-only quantization, particularly 3 and 4-bit\nweight-only quantization, has emerged as one of the most viable solutions. As\nthe number of bits decreases, the quantization grid broadens, thus emphasizing\nthe importance of up and down rounding. While previous studies have\ndemonstrated that fine-tuning up and down rounding with the addition of\nperturbations can enhance accuracy in some scenarios, our study is driven by\nthe precise and limited boundary of these perturbations, where only the\nthreshold for altering the rounding value is of significance. Consequently, we\npropose a concise and highly effective approach for optimizing the weight\nrounding task. Our method, named SignRound, involves lightweight block-wise\ntuning using signed gradient descent, enabling us to achieve outstanding\nresults within 400 steps. SignRound competes impressively against recent\nmethods without introducing additional inference overhead. The source code will\nbe publicly available at \\url{https://github.com/intel/neural-compressor} soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wenhua Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weiwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Haihao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yiyang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xin He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_K/0/1/0/all/0/1\">Kaokao Lv</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A novel approach to measuring patent claim scope based on probabilities obtained from (large) language models. (arXiv:2309.10003v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.10003","description":"<p>This work proposes to measure the scope of a patent claim as the reciprocal\nof the self-information contained in this claim. A probability of occurrence of\nthe claim is obtained from a language model and this probability is used to\ncompute the self-information. Grounded in information theory, this approach is\nbased on the assumption that an unlikely concept is more informative than a\nusual concept, insofar as it is more surprising. In turn, the more surprising\nthe information required to defined the claim, the narrower its scope. Five\nlanguage models are considered, ranging from simplest models (each word or\ncharacter is assigned an identical probability) to intermediate models (using\naverage word or character frequencies), to a large language model (GPT2).\nInterestingly, the scope resulting from the simplest language models is\nproportional to the reciprocal of the number of words or characters involved in\nthe claim, a metric already used in previous works. Application is made to\nmultiple series of patent claims directed to distinct inventions, where each\nseries consists of claims devised to have a gradually decreasing scope. The\nperformance of the language models is assessed with respect to several ad hoc\ntests. The more sophisticated the model, the better the results. I.e., the GPT2\nprobability model outperforms models based on word and character frequencies,\nwhich themselves outdo the simplest models based on word or character counts.\nStill, the character count appears to be a more reliable indicator than the\nword count.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1\">S&#xe9;bastien Ragot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Joint Prediction and Denoising for Large-scale Multilingual Self-supervised Learning. (arXiv:2309.15317v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.15317","description":"<p>Multilingual self-supervised learning (SSL) has often lagged behind\nstate-of-the-art (SOTA) methods due to the expenses and complexity required to\nhandle many languages. This further harms the reproducibility of SSL, which is\nalready limited to few research groups due to its resource usage. We show that\nmore powerful techniques can actually lead to more efficient pre-training,\nopening SSL to more research groups. We propose WavLabLM, which extends WavLM's\njoint prediction and denoising to 40k hours of data across 136 languages. To\nbuild WavLabLM, we devise a novel multi-stage pre-training method, designed to\naddress the language imbalance of multilingual data. WavLabLM achieves\ncomparable performance to XLS-R on ML-SUPERB with less than 10% of the training\ndata, making SSL realizable with academic compute. We show that further\nefficiency can be achieved with a vanilla HuBERT Base model, which can maintain\n94% of XLS-R's performance with only 3% of the data, 4 GPUs, and limited\ntrials. We open-source all code and models in ESPnet.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">William Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Brian Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrebbi_D/0/1/0/all/0/1\">Dan Berrebbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wangyou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xuankai Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maiti_S/0/1/0/all/0/1\">Soumi Maiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jointly Training Large Autoregressive Multimodal Models. (arXiv:2309.15564v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.15564","description":"<p>In recent years, advances in the large-scale pretraining of language and\ntext-to-image models have revolutionized the field of machine learning. Yet,\nintegrating these two modalities into a single, robust model capable of\ngenerating seamless multimodal outputs remains a significant challenge. To\naddress this gap, we present the Joint Autoregressive Mixture (JAM) framework,\na modular approach that systematically fuses existing text and image generation\nmodels. We also introduce a specialized, data-efficient instruction-tuning\nstrategy, tailored for mixed-modal generation tasks. Our final instruct-tuned\nmodel demonstrates unparalleled performance in generating high-quality\nmultimodal outputs and represents the first model explicitly designed for this\npurpose.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aiello_E/0/1/0/all/0/1\">Emanuele Aiello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Lili Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aghajanyan_A/0/1/0/all/0/1\">Armen Aghajanyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1\">Barlas Oguz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HANS, are you clever? Clever Hans Effect Analysis of Neural Systems. (arXiv:2309.12481v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2309.12481","description":"<p>Instruction-tuned Large Language Models (It-LLMs) have been exhibiting\noutstanding abilities to reason around cognitive states, intentions, and\nreactions of all people involved, letting humans guide and comprehend\nday-to-day social interactions effectively. In fact, several multiple-choice\nquestions (MCQ) benchmarks have been proposed to construct solid assessments of\nthe models' abilities. However, earlier works are demonstrating the presence of\ninherent \"order bias\" in It-LLMs, posing challenges to the appropriate\nevaluation. In this paper, we investigate It-LLMs' resilience abilities towards\na series of probing tests using four MCQ benchmarks. Introducing adversarial\nexamples, we show a significant performance gap, mainly when varying the order\nof the choices, which reveals a selection bias and brings into discussion\nreasoning abilities. Following a correlation between first positions and model\nchoices due to positional bias, we hypothesized the presence of structural\nheuristics in the decision-making process of the It-LLMs, strengthened by\nincluding significant examples in few-shot scenarios. Finally, by using the\nChain-of-Thought (CoT) technique, we elicit the model to reason and mitigate\nthe bias by obtaining more robust models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ranaldi_L/0/1/0/all/0/1\">Leonardo Ranaldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zanzotto_F/0/1/0/all/0/1\">Fabio Massimo Zanzotto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-09-28T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/"}}]}]}