{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-02T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"MVMR: Evaluating Natural Language Video Localization Bias over Multiple Reliable Videos Pool. (arXiv:2309.16701v1 [cs.CV])","link":"http://arxiv.org/abs/2309.16701","description":"<p>With the explosion of multimedia content in recent years, natural language\nvideo localization, which focuses on detecting video moment that matches a\ngiven natural language query, has become a critical problem. However, none of\nthe previous research explores localizing a moment from a large corpus where\nmultiple positive and negative videos exist. In this paper, we propose an MVMR\n(Massive Videos Moment Retrieval) task, which aims to localize video frames\nfrom a massive set of videos given a text query. For this task, we suggest\nmethods for constructing datasets by employing similarity filtering on the\nexisting video localization datasets and introduce three MVMR datasets.\nSpecifically, we employ embedding-based text similarity matching and\nvideo-language grounding techniques to calculate the relevance score between a\ntarget query and videos to define positive and negative sets. For the proposed\nMVMR task, we further develop a strong model, Reliable Mutual Matching Network\n(RMMN), which employs a contrastive learning scheme that selectively filters\nthe reliable and informative negatives leading the model more robust on the\nMVMR task. Experimental results on the introduced datasets reveal that existing\nNLVL models are easily distracted by negative video frames, whereas our model\nshows significant performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1\">Nakyeong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minsung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seunghyun Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Joongbo Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyomin Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decoding Imagery: Unleashing Large Language Models. (arXiv:2309.16705v1 [cs.CV])","link":"http://arxiv.org/abs/2309.16705","description":"<p>In a challenge-response study, we subjected Google Bard to 64 visual\nchallenges designed to probe multimodal Large Language Models (LLMs). The\nchallenges spanned diverse categories, including \"Visual Situational\nReasoning,\" \"Visual Text Reasoning,\" and \"Next Scene Prediction,\" among others,\nto discern Bard's competence in melding visual and linguistic analyses. Our\nfindings indicate that Bard tends to rely on making educated guesses about\nvisuals, especially when determining cues from images. Unlike other models like\nGPT4, Bard does not appear to rely on optical character recognition libraries\nlike Tesseract but recognizes text in complex images like deep learning models\nsuch as Google Lens and Visual API. Significantly Bard can solve CAPTCHAs\nvisually that ChatGPT fails to understand, recommending Tesseract solutions.\nMoreover, while the Bard model proposes solutions based on visual input, it\ncannot recreate or modify the original visual objects to support its\nconclusions. Bard fails to redraw ASCII art that the text can describe or\ncapture a simple Tic Tac Toe grid it claims to analyze for the next moves. This\nstudy provides experimental insights into the current capacities and areas for\nimprovement in multimodal LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1\">David Noever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noever_S/0/1/0/all/0/1\">Samantha Elizabeth Miller Noever</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational Sentence Scoring. (arXiv:2309.16770v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16770","description":"<p>Recent advances in machine learning and deep learning have led to the\nwidespread use of Conversational AI in many practical applications. However, it\nis still very challenging to leverage auxiliary information that can provide\nconversational context or personalized tuning to improve the quality of\nconversations. For example, there has only been limited research on using an\nindividuals persona information to improve conversation quality, and even\nstate-of-the-art conversational AI techniques are unable to effectively\nleverage signals from heterogeneous sources of auxiliary data, such as\nmulti-modal interaction data, demographics, SDOH data, etc. In this paper, we\npresent a novel Persona-Coded Poly-Encoder method that leverages persona\ninformation in a multi-stream encoding scheme to improve the quality of\nresponse generation for conversations. To show the efficacy of the proposed\nmethod, we evaluate our method on two different persona-based conversational\ndatasets, and compared against two state-of-the-art methods. Our experimental\nresults and analysis demonstrate that our method can improve conversation\nquality over the baseline method Poly-Encoder by 3.32% and 2.94% in terms of\nBLEU score and HR@1, respectively. More significantly, our method offers a path\nto better utilization of multi-modal data in conversational tasks. Lastly, our\nstudy outlines several challenges and future research directions for advancing\npersonalized conversational AI technology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junfeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Symons_C/0/1/0/all/0/1\">Christopher Symons</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vatsavai_R/0/1/0/all/0/1\">Ranga Raju Vatsavai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How many words does ChatGPT know? The answer is ChatWords. (arXiv:2309.16777v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16777","description":"<p>The introduction of ChatGPT has put Artificial Intelligence (AI) Natural\nLanguage Processing (NLP) in the spotlight. ChatGPT adoption has been\nexponential with millions of users experimenting with it in a myriad of tasks\nand application domains with impressive results. However, ChatGPT has\nlimitations and suffers hallucinations, for example producing answers that look\nplausible but they are completely wrong. Evaluating the performance of ChatGPT\nand similar AI tools is a complex issue that is being explored from different\nperspectives. In this work, we contribute to those efforts with ChatWords, an\nautomated test system, to evaluate ChatGPT knowledge of an arbitrary set of\nwords. ChatWords is designed to be extensible, easy to use, and adaptable to\nevaluate also other NLP AI tools. ChatWords is publicly available and its main\ngoal is to facilitate research on the lexical knowledge of AI tools. The\nbenefits of ChatWords are illustrated with two case studies: evaluating the\nknowledge that ChatGPT has of the Spanish lexicon (taken from the official\ndictionary of the \"Real Academia Espa\\~nola\") and of the words that appear in\nthe Quixote, the well-known novel written by Miguel de Cervantes. The results\nshow that ChatGPT is only able to recognize approximately 80% of the words in\nthe dictionary and 90% of the words in the Quixote, in some cases with an\nincorrect meaning. The implications of the lexical knowledge of NLP AI tools\nand potential applications of ChatWords are also discussed providing directions\nfor further work on the study of the lexical knowledge of AI tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_G/0/1/0/all/0/1\">Gonzalo Mart&#xed;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_J/0/1/0/all/0/1\">Javier Conde</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reviriego_P/0/1/0/all/0/1\">Pedro Reviriego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merino_Gomez_E/0/1/0/all/0/1\">Elena Merino-G&#xf3;mez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_J/0/1/0/all/0/1\">Jos&#xe9; Alberto Hern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lombardi_F/0/1/0/all/0/1\">Fabrizio Lombardi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hallucination Reduction in Long Input Text Summarization. (arXiv:2309.16781v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16781","description":"<p>Hallucination in text summarization refers to the phenomenon where the model\ngenerates information that is not supported by the input source document.\nHallucination poses significant obstacles to the accuracy and reliability of\nthe generated summaries. In this paper, we aim to reduce hallucinated outputs\nor hallucinations in summaries of long-form text documents. We have used the\nPubMed dataset, which contains long scientific research documents and their\nabstracts. We have incorporated the techniques of data filtering and joint\nentity and summary generation (JAENS) in the fine-tuning of the Longformer\nEncoder-Decoder (LED) model to minimize hallucinations and thereby improve the\nquality of the generated summary. We have used the following metrics to measure\nfactual consistency at the entity level: precision-source, and F1-target. Our\nexperiments show that the fine-tuned LED model performs well in generating the\npaper abstract. Data filtering techniques based on some preprocessing steps\nreduce entity-level hallucinations in the generated summaries in terms of some\nof the factual consistency metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rehman_T/0/1/0/all/0/1\">Tohida Rehman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mandal_R/0/1/0/all/0/1\">Ronit Mandal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Abhishek Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanyal_D/0/1/0/all/0/1\">Debarshi Kumar Sanyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution. (arXiv:2309.16797v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16797","description":"<p>Popular prompt strategies like Chain-of-Thought Prompting can dramatically\nimprove the reasoning abilities of Large Language Models (LLMs) in various\ndomains. However, such hand-crafted prompt-strategies are often sub-optimal. In\nthis paper, we present Promptbreeder, a general-purpose self-referential\nself-improvement mechanism that evolves and adapts prompts for a given domain.\nDriven by an LLM, Promptbreeder mutates a population of task-prompts, and\nsubsequently evaluates them for fitness on a training set. Crucially, the\nmutation of these task-prompts is governed by mutation-prompts that the LLM\ngenerates and improves throughout evolution in a self-referential way. That is,\nPromptbreeder is not just improving task-prompts, but it is also improving the\nmutationprompts that improve these task-prompts. Promptbreeder outperforms\nstate-of-the-art prompt strategies such as Chain-of-Thought and Plan-and-Solve\nPrompting on commonly used arithmetic and commonsense reasoning benchmarks.\nFurthermore, Promptbreeder is able to evolve intricate task-prompts for the\nchallenging problem of hate speech classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fernando_C/0/1/0/all/0/1\">Chrisantha Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banarse_D/0/1/0/all/0/1\">Dylan Banarse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1\">Henryk Michalewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Osindero_S/0/1/0/all/0/1\">Simon Osindero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1\">Tim Rockt&#xe4;schel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Curriculum-Driven Edubot: A Framework for Developing Language Learning Chatbots Through Synthesizing Conversational Data. (arXiv:2309.16804v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16804","description":"<p>Chatbots have become popular in educational settings, revolutionizing how\nstudents interact with material and how teachers teach. We present\nCurriculum-Driven EduBot, a framework for developing a chatbot that combines\nthe interactive features of chatbots with the systematic material of English\ntextbooks to assist students in enhancing their conversational skills. We begin\nby extracting pertinent topics from textbooks and then using large language\nmodels to generate dialogues related to these topics. We then fine-tune an\nopen-source LLM using our generated conversational data to create our\ncurriculum-driven chatbot. User studies demonstrate that our chatbot\noutperforms ChatGPT in leading curriculum-based dialogues and adapting its\ndialogue to match the user's English proficiency level. By combining\ntraditional textbook methodologies with conversational AI, our approach offers\nlearners an interactive tool that aligns with their curriculum and provides\nuser-tailored conversation practice. This facilitates meaningful student-bot\ndialogues and enriches the overall learning experience within the curriculum's\npedagogical framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1\">Shang Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jili Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Shangchao Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DeBERTinha: A Multistep Approach to Adapt DebertaV3 XSmall for Brazilian Portuguese Natural Language Processing Task. (arXiv:2309.16844v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16844","description":"<p>This paper presents an approach for adapting the DebertaV3 XSmall model\npre-trained in English for Brazilian Portuguese natural language processing\n(NLP) tasks. A key aspect of the methodology involves a multistep training\nprocess to ensure the model is effectively tuned for the Portuguese language.\nInitial datasets from Carolina and BrWac are preprocessed to address issues\nlike emojis, HTML tags, and encodings. A Portuguese-specific vocabulary of\n50,000 tokens is created using SentencePiece. Rather than training from\nscratch, the weights of the pre-trained English model are used to initialize\nmost of the network, with random embeddings, recognizing the expensive cost of\ntraining from scratch. The model is fine-tuned using the replaced token\ndetection task in the same format of DebertaV3 training. The adapted model,\ncalled DeBERTinha, demonstrates effectiveness on downstream tasks like named\nentity recognition, sentiment analysis, and determining sentence relatedness,\noutperforming BERTimbau-Large in two tasks despite having only 40M parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Campiotti_I/0/1/0/all/0/1\">Israel Campiotti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1\">Matheus Rodrigues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albuquerque_Y/0/1/0/all/0/1\">Yuri Albuquerque</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azevedo_R/0/1/0/all/0/1\">Rafael Azevedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andrade_A/0/1/0/all/0/1\">Alyson Andrade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Sign Language Recognition System with Pepper, Lightweight-Transformer, and LLM. (arXiv:2309.16898v1 [cs.RO])","link":"http://arxiv.org/abs/2309.16898","description":"<p>This research explores using lightweight deep neural network architectures to\nenable the humanoid robot Pepper to understand American Sign Language (ASL) and\nfacilitate non-verbal human-robot interaction. First, we introduce a\nlightweight and efficient model for ASL understanding optimized for embedded\nsystems, ensuring rapid sign recognition while conserving computational\nresources. Building upon this, we employ large language models (LLMs) for\nintelligent robot interactions. Through intricate prompt engineering, we tailor\ninteractions to allow the Pepper Robot to generate natural Co-Speech Gesture\nresponses, laying the foundation for more organic and intuitive humanoid-robot\ndialogues. Finally, we present an integrated software pipeline, embodying\nadvancements in a socially aware AI interaction model. Leveraging the Pepper\nRobot's capabilities, we demonstrate the practicality and effectiveness of our\napproach in real-world scenarios. The results highlight a profound potential\nfor enhancing human-robot interaction through non-verbal interactions, bridging\ncommunication gaps, and making technology more accessible and understandable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1\">JongYoon Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sa_I/0/1/0/all/0/1\">Inkyu Sa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+MacDonald_B/0/1/0/all/0/1\">Bruce MacDonald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_H/0/1/0/all/0/1\">Ho Seok Ahn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards a Unified Framework for Adaptable Problematic Content Detection via Continual Learning. (arXiv:2309.16905v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16905","description":"<p>Detecting problematic content, such as hate speech, is a multifaceted and\never-changing task, influenced by social dynamics, user populations, diversity\nof sources, and evolving language. There has been significant efforts, both in\nacademia and in industry, to develop annotated resources that capture various\naspects of problematic content. Due to researchers' diverse objectives, the\nannotations are inconsistent and hence, reports of progress on detection of\nproblematic content are fragmented. This pattern is expected to persist unless\nwe consolidate resources considering the dynamic nature of the problem. We\npropose integrating the available resources, and leveraging their dynamic\nnature to break this pattern. In this paper, we introduce a continual learning\nbenchmark and framework for problematic content detection comprising over 84\nrelated tasks encompassing 15 annotation schemas from 8 sources. Our benchmark\ncreates a novel measure of progress: prioritizing the adaptability of\nclassifiers to evolving tasks over excelling in specific tasks. To ensure the\ncontinuous relevance of our framework, we designed it so that new tasks can\neasily be integrated into the benchmark. Our baseline results demonstrate the\npotential of continual learning in capturing the evolving content and adapting\nto novel manifestations of problematic content.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Omrani_A/0/1/0/all/0/1\">Ali Omrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziabari_A/0/1/0/all/0/1\">Alireza S. Ziabari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golazizian_P/0/1/0/all/0/1\">Preni Golazizian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorensen_J/0/1/0/all/0/1\">Jeffery Sorensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1\">Morteza Dehghani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SSHR: Leveraging Self-supervised Hierarchical Representations for Multilingual Automatic Speech Recognition. (arXiv:2309.16937v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16937","description":"<p>Multilingual automatic speech recognition (ASR) systems have garnered\nattention for their potential to extend language coverage globally. While\nself-supervised learning (SSL) has demonstrated its effectiveness in\nmultilingual ASR, it is worth noting that the various layers' representations\nof SSL potentially contain distinct information that has not been fully\nleveraged. In this study, we propose a novel method that leverages\nself-supervised hierarchical representations (SSHR) to fine-tune multilingual\nASR. We first analyze the different layers of the SSL model for\nlanguage-related and content-related information, uncovering layers that show a\nstronger correlation. Then, we extract a language-related frame from correlated\nmiddle layers and guide specific content extraction through self-attention\nmechanisms. Additionally, we steer the model toward acquiring more\ncontent-related information in the final layers using our proposed Cross-CTC.\nWe evaluate SSHR on two multilingual datasets, Common Voice and ML-SUPERB, and\nthe experimental results demonstrate that our method achieves state-of-the-art\nperformance to the best of our knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1\">Hongfei Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_Q/0/1/0/all/0/1\">Qijie Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kaixun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Peikun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1\">Lei Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jie Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"I Wish to Have an Argument: Argumentative Reasoning in Large Language Models. (arXiv:2309.16938v1 [cs.CL])","link":"http://arxiv.org/abs/2309.16938","description":"<p>We evaluate the ability of contemporary large language models (LLMs) to\nperform argumentative reasoning. We frame our experiments in terms of the\nargument mining (AM) and argument pair extraction (APE) tasks, and evaluate\ntheir ability to perform reasoning at increasing levels of abstraction in the\ninput and output representations (e.g., arbitrary label sets, semantic graphs).\nWe find that, although LLMs are able to match or surpass the state-of-the-art\nin AM and APE, their argumentative reasoning performance is very dependent on\nthe input and output representation. We also find an \"exemplar effect\", where\ntoo many exemplars increasingly become detrimental for task performance, and\nabout 4-5 being the optimal amount. Neither result extends to chain-of-thought\n(CoT) prompting: we find the exemplar effect to be nullified, and our results\nsuggest that CoT allows for better performance under ill-conditioned problems.\nWe hope that the work reported contributes to the improvement of argumentative\nreasoning in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wynter_A/0/1/0/all/0/1\">Adrian de Wynter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_T/0/1/0/all/0/1\">Tommy Yuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Cognitive Biases in Large Language Models as Evaluators. (arXiv:2309.17012v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17012","description":"<p>Large Language Models (LLMs) have recently been shown to be effective as\nautomatic evaluators with simple prompting and in-context learning. In this\nwork, we assemble 15 LLMs of four different size ranges and evaluate their\noutput responses by preference ranking from the other LLMs as evaluators, such\nas System Star is better than System Square. We then evaluate the quality of\nranking outputs introducing the Cognitive Bias Benchmark for LLMs as Evaluators\n(CoBBLEr), a benchmark to measure six different cognitive biases in LLM\nevaluation outputs, such as the Egocentric bias where a model prefers to rank\nits own outputs highly in evaluation. We find that LLMs are biased text quality\nevaluators, exhibiting strong indications on our bias benchmark (average of 40%\nof comparisons across all models) within each of their evaluations that\nquestion their robustness as evaluators. Furthermore, we examine the\ncorrelation between human and machine preferences and calculate the average\nRank-Biased Overlap (RBO) score to be 49.6%, indicating that machine\npreferences are misaligned with humans. According to our findings, LLMs may\nstill be unable to be utilized for automatic annotation aligned with human\npreferences. Our project page is at: https://minnesotanlp.github.io/cobbler.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koo_R/0/1/0/all/0/1\">Ryan Koo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1\">Minhwa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raheja_V/0/1/0/all/0/1\">Vipul Raheja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong Inn Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Z/0/1/0/all/0/1\">Zae Myung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextualising Levels of Language Resourcedness affecting Digital Processing of Text. (arXiv:2309.17035v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17035","description":"<p>Application domains such as digital humanities and tool like chatbots involve\nsome form of processing natural language, from digitising hardcopies to speech\ngeneration. The language of the content is typically characterised as either a\nlow resource language (LRL) or high resource language (HRL), also known as\nresource-scarce and well-resourced languages, respectively. African languages\nhave been characterized as resource-scarce languages (Bosch et al. 2007;\nPretorius &amp; Bosch 2003; Keet &amp; Khumalo 2014) and English is by far the most\nwell-resourced language. Varied language resources are used to develop software\nsystems for these languages to accomplish a wide range of tasks. In this paper\nwe argue that the dichotomous typology LRL and HRL for all languages is\nproblematic. Through a clear understanding of language resources situated in a\nsociety, a matrix is developed that characterizes languages as Very LRL, LRL,\nRL, HRL and Very HRL. The characterization is based on the typology of\ncontextual features for each category, rather than counting tools, and\nmotivation is provided for each feature and each characterization. The\ncontextualisation of resourcedness, with a focus on African languages in this\npaper, and an increased understanding of where on the scale the language used\nin a project is, may assist in, among others, better planning of research and\nimplementation projects. We thus argue in this paper that the characterization\nof language resources within a given scale in a project is an indispensable\ncomponent particularly in the context of low-resourced languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Keet_C/0/1/0/all/0/1\">C. Maria Keet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khumalo_L/0/1/0/all/0/1\">Langa Khumalo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretable Long-Form Legal Question Answering with Retrieval-Augmented Large Language Models. (arXiv:2309.17050v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17050","description":"<p>Many individuals are likely to face a legal dispute at some point in their\nlives, but their lack of understanding of how to navigate these complex issues\noften renders them vulnerable. The advancement of natural language processing\nopens new avenues for bridging this legal literacy gap through the development\nof automated legal aid systems. However, existing legal question answering\n(LQA) approaches often suffer from a narrow scope, being either confined to\nspecific legal domains or limited to brief, uninformative responses. In this\nwork, we propose an end-to-end methodology designed to generate long-form\nanswers to any statutory law questions, utilizing a \"retrieve-then-read\"\npipeline. To support this approach, we introduce and release the Long-form\nLegal Question Answering (LLeQA) dataset, comprising 1,868 expert-annotated\nlegal questions in the French language, complete with detailed answers rooted\nin pertinent legal provisions. Our experimental results demonstrate promising\nperformance on automatic evaluation metrics, but a qualitative analysis\nuncovers areas for refinement. As one of the only comprehensive,\nexpert-annotated long-form LQA dataset, LLeQA has the potential to not only\naccelerate research towards resolving a significant real-world issue, but also\nact as a rigorous benchmark for evaluating NLP models in specialized domains.\nWe publicly release our code, data, and models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Louis_A/0/1/0/all/0/1\">Antoine Louis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dijck_G/0/1/0/all/0/1\">Gijs van Dijck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spanakis_G/0/1/0/all/0/1\">Gerasimos Spanakis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCALE: Synergized Collaboration of Asymmetric Language Translation Engines. (arXiv:2309.17061v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17061","description":"<p>In this paper, we introduce SCALE, a collaborative framework that connects\ncompact Specialized Translation Models (STMs) and general-purpose Large\nLanguage Models (LLMs) as one unified translation engine. By introducing\ntranslation from STM into the triplet in-context demonstrations, SCALE unlocks\nrefinement and pivoting ability of LLM, thus mitigating language bias of LLM\nand parallel data bias of STM, enhancing LLM speciality without sacrificing\ngenerality, and facilitating continual learning without expensive LLM\nfine-tuning. Our comprehensive experiments show that SCALE significantly\noutperforms both few-shot LLMs (GPT-4) and specialized models (NLLB) in\nchallenging low-resource settings. Moreover, in Xhosa to English translation,\nSCALE experiences consistent improvement by a 4 BLEURT score without tuning LLM\nand surpasses few-shot GPT-4 by 2.5 COMET score and 3.8 BLEURT score when\nequipped with a compact model consisting of merely 600M parameters. SCALE could\nalso effectively exploit the existing language bias of LLMs by using an\nEnglish-centric STM as a pivot for translation between any language pairs,\noutperforming few-shot GPT-4 by an average of 6 COMET points across eight\ntranslation directions. Furthermore we provide an in-depth analysis of SCALE's\nrobustness, translation characteristics, and latency costs, providing solid\nfoundation for future studies exploring the potential synergy between LLMs and\nmore specialized, task-specific models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xin Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1\">Tao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Si-Qing Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1\">Rui Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?. (arXiv:2309.17122v1 [cs.AI])","link":"http://arxiv.org/abs/2309.17122","description":"<p>Large Language Models (LLMs) are advancing at a rapid pace, with significant\nimprovements at natural language processing and coding tasks. Yet, their\nability to work with formal languages representing data, specifically within\nthe realm of knowledge graph engineering, remains under-investigated. To\nevaluate the proficiency of various LLMs, we created a set of five tasks that\nprobe their ability to parse, understand, analyze, and create knowledge graphs\nserialized in Turtle syntax. These tasks, each embodying distinct degrees of\ncomplexity and being able to scale with the size of the problem, have been\nintegrated into our automated evaluation system, the LLM-KG-Bench. The\nevaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4,\nClaude 1.3, and Claude 2.0, as well as two freely accessible offline models,\nGPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth\nunderstanding of the strengths and shortcomings of LLMs in relation to their\napplication within RDF knowledge graph engineering workflows utilizing Turtle\nrepresentation. While our findings show that the latest commercial models\noutperform their forerunners in terms of proficiency with the Turtle language,\nthey also reveal an apparent weakness. These models fall short when it comes to\nadhering strictly to the output formatting constraints, a crucial requirement\nin this context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Frey_J/0/1/0/all/0/1\">Johannes Frey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_L/0/1/0/all/0/1\">Lars-Peter Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arndt_N/0/1/0/all/0/1\">Natanael Arndt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brei_F/0/1/0/all/0/1\">Felix Brei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bulert_K/0/1/0/all/0/1\">Kirill Bulert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-grained Late-interaction Multi-modal Retrieval for Retrieval Augmented Visual Question Answering. (arXiv:2309.17133v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17133","description":"<p>Knowledge-based Visual Question Answering (KB-VQA) requires VQA systems to\nutilize knowledge from existing knowledge bases to answer visually-grounded\nquestions. Retrieval-Augmented Visual Question Answering (RA-VQA), a strong\nframework to tackle KB-VQA, first retrieves related documents with Dense\nPassage Retrieval (DPR) and then uses them to answer questions. This paper\nproposes Fine-grained Late-interaction Multi-modal Retrieval (FLMR) which\nsignificantly improves knowledge retrieval in RA-VQA. FLMR addresses two major\nlimitations in RA-VQA's retriever: (1) the image representations obtained via\nimage-to-text transforms can be incomplete and inaccurate and (2) relevance\nscores between queries and documents are computed with one-dimensional\nembeddings, which can be insensitive to finer-grained relevance. FLMR overcomes\nthese limitations by obtaining image representations that complement those from\nthe image-to-text transforms using a vision model aligned with an existing\ntext-based retriever through a simple alignment network. FLMR also encodes\nimages and questions using multi-dimensional embeddings to capture\nfiner-grained relevance between queries and documents. FLMR significantly\nimproves the original RA-VQA retriever's PRRecall@5 by approximately 8\\%.\nFinally, we equipped RA-VQA with two state-of-the-art large\nmulti-modal/language models to achieve $\\sim61\\%$ VQA score in the OK-VQA\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Weizhe Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jinghong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_J/0/1/0/all/0/1\">Jingbiao Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Coca_A/0/1/0/all/0/1\">Alexandru Coca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byrne_B/0/1/0/all/0/1\">Bill Byrne</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Promoting Generalized Cross-lingual Question Answering in Few-resource Scenarios via Self-knowledge Distillation. (arXiv:2309.17134v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17134","description":"<p>Despite substantial progress in multilingual extractive Question Answering\n(QA), models with high and uniformly distributed performance across languages\nremain challenging, especially for languages with limited resources. We study\ncross-lingual transfer mainly focusing on the Generalized Cross-Lingual\nTransfer (G-XLT) task, where the question language differs from the context\nlanguage - a challenge that has received limited attention thus far. Our\napproach seeks to enhance cross-lingual QA transfer using a high-performing\nmultilingual model trained on a large-scale dataset, complemented by a few\nthousand aligned QA examples across languages. Our proposed strategy combines\ncross-lingual sampling and advanced self-distillation training in generations\nto tackle the previous challenge. Notably, we introduce the novel mAP@k\ncoefficients to fine-tune self-knowledge distillation loss, dynamically\nregulating the teacher's model knowledge to perform a balanced and effective\nknowledge transfer. We extensively evaluate our approach to assess XLT and\nG-XLT capabilities in extractive QA. Results reveal that our self-knowledge\ndistillation approach outperforms standard cross-entropy fine-tuning by a\nsignificant margin. Importantly, when compared to a strong baseline that\nleverages a sizeable volume of machine-translated data, our approach shows\ncompetitive results despite the considerable challenge of operating within\nresource-constrained settings, even in zero-shot scenarios. Beyond performance\nimprovements, we offer valuable insights through comprehensive analyses and an\nablation study, further substantiating the benefits and constraints of our\napproach. In essence, we propose a practical solution to improve cross-lingual\nQA transfer by leveraging a few data resources in an efficient way.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Carrino_C/0/1/0/all/0/1\">Casimiro Pio Carrino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Escolano_C/0/1/0/all/0/1\">Carlos Escolano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonollosa_J/0/1/0/all/0/1\">Jos&#xe9; A. R. Fonollosa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Large Language Models for Qualitative Analysis can Introduce Serious Bias. (arXiv:2309.17147v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17147","description":"<p>Large Language Models (LLMs) are quickly becoming ubiquitous, but the\nimplications for social science research are not yet well understood. This\npaper asks whether LLMs can help us analyse large-N qualitative data from\nopen-ended interviews, with an application to transcripts of interviews with\nRohingya refugees in Cox's Bazaar, Bangladesh. We find that a great deal of\ncaution is needed in using LLMs to annotate text as there is a risk of\nintroducing biases that can lead to misleading inferences. We here mean bias in\nthe technical sense, that the errors that LLMs make in annotating interview\ntranscripts are not random with respect to the characteristics of the interview\nsubjects. Training simpler supervised models on high-quality human annotations\nwith flexible coding leads to less measurement error and bias than LLM\nannotations. Therefore, given that some high quality annotations are necessary\nin order to asses whether an LLM introduces bias, we argue that it is probably\npreferable to train a bespoke model on these annotations than it is to use an\nLLM for annotation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ashwin_J/0/1/0/all/0/1\">Julian Ashwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chhabra_A/0/1/0/all/0/1\">Aditya Chhabra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_V/0/1/0/all/0/1\">Vijayendra Rao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud. (arXiv:2309.17157v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17157","description":"<p>In the current user-server interaction paradigm of prompted generation with\nlarge language models (LLM) on cloud, the server fully controls the generation\nprocess, which leaves zero options for users who want to keep the generated\ntext to themselves. We propose LatticeGen, a cooperative framework in which the\nserver still handles most of the computation while the user controls the\nsampling operation. The key idea is that the true generated sequence is mixed\nwith noise tokens by the user and hidden in a noised lattice. Considering\npotential attacks from a hypothetically malicious server and how the user can\ndefend against it, we propose the repeated beam-search attack and the mixing\nnoise scheme. In our experiments we apply LatticeGen to protect both prompt and\ngeneration. It is shown that while the noised lattice degrades generation\nquality, LatticeGen successfully protects the true generation to a remarkable\ndegree under strong attacks (more than 50% of the semantic remains hidden as\nmeasured by BERTScore).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mengke Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianle Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mireshghallah_F/0/1/0/all/0/1\">Fatemehsadat Mireshghallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Binyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DyVal: Graph-informed Dynamic Evaluation of Large Language Models. (arXiv:2309.17167v1 [cs.AI])","link":"http://arxiv.org/abs/2309.17167","description":"<p>Large language models (LLMs) have achieved remarkable performance in various\nevaluation benchmarks. However, concerns about their performance are raised on\npotential data contamination in their considerable volume of training corpus.\nMoreover, the static nature and fixed complexity of current benchmarks may\ninadequately gauge the advancing capabilities of LLMs. In this paper, we\nintroduce DyVal, a novel, general, and flexible evaluation protocol for dynamic\nevaluation of LLMs. Based on our proposed dynamic evaluation framework, we\nbuild graph-informed DyVal by leveraging the structural advantage of directed\nacyclic graphs to dynamically generate evaluation samples with controllable\ncomplexities. DyVal generates challenging evaluation sets on reasoning tasks\nincluding mathematics, logical reasoning, and algorithm problems. We evaluate\nvarious LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments\ndemonstrate that LLMs perform worse in DyVal-generated evaluation samples with\ndifferent complexities, emphasizing the significance of dynamic evaluation. We\nalso analyze the failure cases and results of different prompting methods.\nMoreover, DyVal-generated samples are not only evaluation sets, but also\nhelpful data for fine-tuning to improve the performance of LLMs on existing\nbenchmarks. We hope that DyVal can shed light on the future evaluation research\nof LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1\">Neil Zhenqiang Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An evaluation of GPT models for phenotype concept recognition. (arXiv:2309.17169v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17169","description":"<p>Objective: Clinical deep phenotyping plays a critical role in both the\ndiagnosis of patients with rare disorders as well as in building care\ncoordination plans. The process relies on modelling and curating patient\nprofiles using ontology concepts, usually from the Human Phenotype Ontology.\nMachine learning methods have been widely adopted to support this phenotype\nconcept recognition task. With the significant shift in the use of large\nlanguage models (LLMs) for most NLP tasks, herewithin, we examine the\nperformance of the latest Generative Pre-trained Transformer (GPT) models\nunderpinning ChatGPT in clinical deep phenotyping. Materials and Methods: The\nexperimental setup of the study included seven prompts of various levels of\nspecificity, two GPT models (gpt-3.5 and gpt-4.0) and an established gold\nstandard for phenotype recognition. Results: Our results show that, currently,\nthese models have not yet achieved state of the art performance. The best run,\nusing few-shots learning, achieved 0.41 F1 score, compared to a 0.62 F1 score\nachieved by the current best in class tool. Conclusion: The non-deterministic\nnature of the outcomes and the lack of concordance between different runs using\nthe same prompt and input makes the use of these LLMs in clinical settings\nproblematic.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Groza_T/0/1/0/all/0/1\">Tudor Groza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caufield_H/0/1/0/all/0/1\">Harry Caufield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gration_D/0/1/0/all/0/1\">Dylan Gration</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baynam_G/0/1/0/all/0/1\">Gareth Baynam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haendel_M/0/1/0/all/0/1\">Melissa A Haendel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robinson_P/0/1/0/all/0/1\">Peter N Robinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mungall_C/0/1/0/all/0/1\">Chris J Mungall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reese_J/0/1/0/all/0/1\">Justin T Reese</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Analysis of Named Entity Recognition in the Dungeons and Dragons Domain. (arXiv:2309.17171v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17171","description":"<p>Many NLP tasks, although well-resolved for general English, face challenges\nin specific domains like fantasy literature. This is evident in Named Entity\nRecognition (NER), which detects and categorizes entities in text. We analyzed\n10 NER models on 7 Dungeons and Dragons (D&amp;D) adventure books to assess\ndomain-specific performance. Using open-source Large Language Models, we\nannotated named entities in these books and evaluated each model's precision.\nOur findings indicate that, without modifications, Flair, Trankit, and Spacy\noutperform others in identifying named entities in the D&amp;D context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weerasundara_G/0/1/0/all/0/1\">Gayashan Weerasundara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_N/0/1/0/all/0/1\">Nisansa de Silva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RLAdapter: Bridging Large Language Models to Reinforcement Learning in Open Worlds. (arXiv:2309.17176v1 [cs.AI])","link":"http://arxiv.org/abs/2309.17176","description":"<p>While reinforcement learning (RL) shows remarkable success in decision-making\nproblems, it often requires a lot of interactions with the environment, and in\nsparse-reward environments, it is challenging to learn meaningful policies.\nLarge Language Models (LLMs) can potentially provide valuable guidance to\nagents in learning policies, thereby enhancing the performance of RL algorithms\nin such environments. However, LLMs often encounter difficulties in\nunderstanding downstream tasks, which hinders their ability to optimally assist\nagents in these tasks. A common approach to mitigating this issue is to\nfine-tune the LLMs with task-related data, enabling them to offer useful\nguidance for RL agents. However, this approach encounters several difficulties,\nsuch as inaccessible model weights or the need for significant computational\nresources, making it impractical. In this work, we introduce RLAdapter, a\nframework that builds a better connection between RL algorithms and LLMs by\nincorporating an adapter model. Within the RLAdapter framework, fine-tuning a\nlightweight language model with information generated during the training\nprocess of RL agents significantly aids LLMs in adapting to downstream tasks,\nthereby providing better guidance for RL agents. We conducted experiments to\nevaluate RLAdapter in the Crafter environment, and the results show that\nRLAdapter surpasses the SOTA baselines. Furthermore, agents under our framework\nexhibit common-sense behaviors that are absent in baseline models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanpeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zongqing Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training. (arXiv:2309.17179v1 [cs.LG])","link":"http://arxiv.org/abs/2309.17179","description":"<p>Large language models (LLMs) typically employ sampling or beam search,\naccompanied by prompts such as Chain-of-Thought (CoT), to boost reasoning and\ndecoding ability. Recent work like Tree-of-Thought (ToT) and Reasoning via\nPlanning (RAP) aim to augment the reasoning capabilities of LLMs by utilizing\ntree-search algorithms to guide multi-step reasoning. These methods mainly\nfocus on LLMs' reasoning ability during inference and heavily rely on\nhuman-designed prompts to activate LLM as a value function, which lacks general\napplicability and scalability. To address these limitations, we present an\nAlphaZero-like tree-search framework for LLMs (termed TS-LLM), systematically\nillustrating how tree-search with a learned value function can guide LLMs'\ndecoding ability. TS-LLM distinguishes itself in two key ways: (1) Leveraging a\nlearned value function, our approach can be generally applied to different\ntasks beyond reasoning (such as RLHF alignment), and LLMs of any size, without\nprompting advanced, large-scale models. (2) It can guide LLM's decoding during\nboth inference and training. Empirical evaluations across reasoning, planning,\nand RLHF alignment tasks validate the effectiveness of TS-LLM, even on trees\nwith a depth of 64.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xidong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Ziyu Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_M/0/1/0/all/0/1\">Muning Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1\">Ying Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weinan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training and inference of large language models using 8-bit floating point. (arXiv:2309.17224v1 [cs.LG])","link":"http://arxiv.org/abs/2309.17224","description":"<p>FP8 formats are gaining popularity to boost the computational efficiency for\ntraining and inference of large deep learning models. Their main challenge is\nthat a careful choice of scaling is needed to prevent degradation due to the\nreduced dynamic range compared to higher-precision formats. Although there\nexists ample literature about selecting such scalings for INT formats, this\ncritical aspect has yet to be addressed for FP8. This paper presents a\nmethodology to select the scalings for FP8 linear layers, based on dynamically\nupdating per-tensor scales for the weights, gradients and activations. We apply\nthis methodology to train and validate large language models of the type of GPT\nand Llama 2 using FP8, for model sizes ranging from 111M to 70B. To facilitate\nthe understanding of the FP8 dynamics, our results are accompanied by plots of\nthe per-tensor scale distribution for weights, activations and gradients during\nboth training and inference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perez_S/0/1/0/all/0/1\">Sergio P. Perez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briggs_J/0/1/0/all/0/1\">James Briggs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blake_C/0/1/0/all/0/1\">Charlie Blake</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_Kramer_J/0/1/0/all/0/1\">Josh Levy-Kramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balanca_P/0/1/0/all/0/1\">Paul Balanca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1\">Carlo Luschi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barlow_S/0/1/0/all/0/1\">Stephen Barlow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fitzgibbon_A/0/1/0/all/0/1\">Andrew William Fitzgibbon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games. (arXiv:2309.17234v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17234","description":"<p>There is a growing interest in using Large Language Models (LLMs) as agents\nto tackle real-world tasks that may require assessing complex situations. Yet,\nwe have a limited understanding of LLMs' reasoning and decision-making\ncapabilities, partly stemming from a lack of dedicated evaluation benchmarks.\nAs negotiating and compromising are key aspects of our everyday communication\nand collaboration, we propose using scorable negotiation games as a new\nevaluation framework for LLMs. We create a testbed of diverse text-based,\nmulti-agent, multi-issue, semantically rich negotiation games, with easily\ntunable difficulty. To solve the challenge, agents need to have strong\narithmetic, inference, exploration, and planning capabilities, while seamlessly\nintegrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT),\nwe show that agents can negotiate and consistently reach successful deals. We\nquantify the performance with multiple metrics and observe a large gap between\nGPT-4 and earlier models. Importantly, we test the generalization to new games\nand setups. Finally, we show that these games can help evaluate other critical\naspects, such as the interaction dynamics between agents in the presence of\ngreedy and adversarial players.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdelnabi_S/0/1/0/all/0/1\">Sahar Abdelnabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gomaa_A/0/1/0/all/0/1\">Amr Gomaa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sivaprasad_S/0/1/0/all/0/1\">Sarath Sivaprasad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonherr_L/0/1/0/all/0/1\">Lea Sch&#xf6;nherr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1\">Mario Fritz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Batch Calibration: Rethinking Calibration for In-Context Learning and Prompt Engineering. (arXiv:2309.17249v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17249","description":"<p>Prompting and in-context learning (ICL) have become efficient learning\nparadigms for large language models (LLMs). However, LLMs suffer from prompt\nbrittleness and various bias factors in the prompt, including but not limited\nto the formatting, the choice verbalizers, and the ICL examples. To address\nthis problem that results in unexpected performance degradation, calibration\nmethods have been developed to mitigate the effects of these biases while\nrecovering LLM performance. In this work, we first conduct a systematic\nanalysis of the existing calibration methods, where we both provide a unified\nview and reveal the failure cases. Inspired by these analyses, we propose Batch\nCalibration (BC), a simple yet intuitive method that controls the contextual\nbias from the batched input, unifies various prior approaches, and effectively\naddresses the aforementioned issues. BC is zero-shot, inference-only, and\nincurs negligible additional costs. In the few-shot setup, we further extend BC\nto allow it to learn the contextual bias from labeled data. We validate the\neffectiveness of BC with PaLM 2-(S, M, L) and CLIP models and demonstrate\nstate-of-the-art performance over previous calibration baselines across more\nthan 10 natural language understanding and image classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Proleev_L/0/1/0/all/0/1\">Lev Proleev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mincu_D/0/1/0/all/0/1\">Diana Mincu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jilin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heller_K/0/1/0/all/0/1\">Katherine Heller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Subhrajit Roy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v1 [cs.AI])","link":"http://arxiv.org/abs/2309.17255","description":"<p>The term life sciences refers to the disciplines that study living organisms\nand life processes, and include chemistry, biology, medicine, and a range of\nother related disciplines. Research efforts in life sciences are heavily\ndata-driven, as they produce and consume vast amounts of scientific data, much\nof which is intrinsically relational and graph-structured.\n</p>\n<p>The volume of data and the complexity of scientific concepts and relations\nreferred to therein promote the application of advanced knowledge-driven\ntechnologies for managing and interpreting data, with the ultimate aim to\nadvance scientific discovery.\n</p>\n<p>In this survey and position paper, we discuss recent developments and\nadvances in the use of graph-based technologies in life sciences and set out a\nvision for how these technologies will impact these fields into the future. We\nfocus on three broad topics: the construction and management of Knowledge\nGraphs (KGs), the use of KGs and associated technologies in the discovery of\nnew knowledge, and the use of KGs in artificial intelligence applications to\nsupport explanations (explainable AI). We select a few exemplary use cases for\neach topic, discuss the challenges and open research questions within these\ntopics, and conclude with a perspective and outlook that summarizes the\noverarching challenges and their potential solutions as a guide for future\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hastings_J/0/1/0/all/0/1\">Janna Hastings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_Ruiz_E/0/1/0/all/0/1\">Ernesto Jim&#xe9;nez-Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_V/0/1/0/all/0/1\">Vanessa Lopez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1\">Pierre Monnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pesquita_C/0/1/0/all/0/1\">Catia Pesquita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skoda_P/0/1/0/all/0/1\">Petr &#x160;koda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamma_V/0/1/0/all/0/1\">Valentina Tamma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Wiki-En-ASR-Adapt: Large-scale synthetic dataset for English ASR Customization. (arXiv:2309.17267v1 [eess.AS])","link":"http://arxiv.org/abs/2309.17267","description":"<p>We present a first large-scale public synthetic dataset for contextual\nspellchecking customization of automatic speech recognition (ASR) with focus on\ndiverse rare and out-of-vocabulary (OOV) phrases, such as proper names or\nterms. The proposed approach allows creating millions of realistic examples of\ncorrupted ASR hypotheses and simulate non-trivial biasing lists for the\ncustomization task. Furthermore, we propose injecting two types of ``hard\nnegatives\" to the simulated biasing lists in training examples and describe our\nprocedures to automatically mine them. We report experiments with training an\nopen-source customization model on the proposed dataset and show that the\ninjection of hard negative biasing phrases decreases WER and the number of\nfalse alarms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Antonova_A/0/1/0/all/0/1\">Alexandra Antonova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Large Language Models in Coding Through Multi-Perspective Self-Consistency. (arXiv:2309.17272v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17272","description":"<p>Large language models (LLMs) have exhibited remarkable ability in textual\ngeneration. However, in complex reasoning tasks such as code generation,\ngenerating the correct answer in a single attempt remains a formidable\nchallenge for LLMs. Previous research has explored solutions by aggregating\nmultiple outputs, leveraging the consistency among them. However, none of them\nhave comprehensively captured this consistency from different perspectives. In\nthis paper, we propose the Multi-Perspective Self-Consistency (MPSC) framework,\na novel decoding strategy for LLM that incorporates both inter-consistency\nacross outputs from multiple perspectives and intra-consistency within a single\nperspective. Specifically, we ask LLMs to sample multiple diverse outputs from\nvarious perspectives for a given query and then construct a multipartite graph\nbased on them. With two predefined measures of consistency, we embed both\ninter- and intra-consistency information into the graph. The optimal choice is\nthen determined based on consistency analysis in the graph. We conduct\ncomprehensive evaluation on the code generation task by introducing solution,\nspecification and test case as three perspectives. We leverage a code\ninterpreter to quantitatively measure the inter-consistency and propose several\nintra-consistency measure functions. Our MPSC framework significantly boosts\nthe performance on various popular benchmarks, including HumanEval (+17.60%),\nHumanEval Plus (+17.61%), MBPP (+6.50%) and CodeContests (+11.82%) in Pass@1,\nwhen compared to original outputs generated from ChatGPT, and even surpassing\nGPT-4.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Baizhou Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shuai Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xiaojun Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"STRONG -- Structure Controllable Legal Opinion Summary Generation. (arXiv:2309.17280v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17280","description":"<p>We propose an approach for the structure controllable summarization of long\nlegal opinions that considers the argument structure of the document. Our\napproach involves using predicted argument role information to guide the model\nin generating coherent summaries that follow a provided structure pattern. We\ndemonstrate the effectiveness of our approach on a dataset of legal opinions\nand show that it outperforms several strong baselines with respect to ROUGE,\nBERTScore, and structure similarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Litman_D/0/1/0/all/0/1\">Diane Litman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Few-Shot Domain Adaptation for Charge Prediction on Unprofessional Descriptions. (arXiv:2309.17313v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17313","description":"<p>Recent works considering professional legal-linguistic style (PLLS) texts\nhave shown promising results on the charge prediction task. However,\nunprofessional users also show an increasing demand on such a prediction\nservice. There is a clear domain discrepancy between PLLS texts and non-PLLS\ntexts expressed by those laypersons, which degrades the current SOTA models'\nperformance on non-PLLS texts. A key challenge is the scarcity of non-PLLS data\nfor most charge classes. This paper proposes a novel few-shot domain adaptation\n(FSDA) method named Disentangled Legal Content for Charge Prediction (DLCCP).\nCompared with existing FSDA works, which solely perform instance-level\nalignment without considering the negative impact of text style information\nexisting in latent features, DLCCP (1) disentangles the content and style\nrepresentations for better domain-invariant legal content learning with\ncarefully designed optimization goals for content and style spaces and, (2)\nemploys the constitutive elements knowledge of charges to extract and align\nelement-level and instance-level content representations simultaneously. We\ncontribute the first publicly available non-PLLS dataset named NCCP for\ndeveloping layperson-friendly charge prediction models. Experiments on NCCP\nshow the superiority of our methods over competitive baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1\">Ziyu Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wei Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yue Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xiaofei He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overview of the BioLaySumm 2023 Shared Task on Lay Summarization of Biomedical Research Articles. (arXiv:2309.17332v1 [cs.CL])","link":"http://arxiv.org/abs/2309.17332","description":"<p>This paper presents the results of the shared task on Lay Summarisation of\nBiomedical Research Articles (BioLaySumm), hosted at the BioNLP Workshop at ACL\n2023. The goal of this shared task is to develop abstractive summarisation\nmodels capable of generating \"lay summaries\" (i.e., summaries that are\ncomprehensible to non-technical audiences) in both a controllable and\nnon-controllable setting. There are two subtasks: 1) Lay Summarisation, where\nthe goal is for participants to build models for lay summary generation only,\ngiven the full article text and the corresponding abstract as input; and 2)\nReadability-controlled Summarisation, where the goal is for participants to\ntrain models to generate both the technical abstract and the lay summary, given\nan article's main text as input. In addition to overall results, we report on\nthe setup and insights from the BioLaySumm shared task, which attracted a total\nof 20 participating teams across both subtasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goldsack_T/0/1/0/all/0/1\">Tomsa Goldsack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Zheheng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shardlow_M/0/1/0/all/0/1\">Matthew Shardlow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1\">Sophia Ananiadou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human Languages with Greater Information Density Increase Communication Speed, but Decrease Conversation Breadth. (arXiv:2112.08491v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.08491","description":"<p>Human languages vary widely in how they encode information within\ncircumscribed semantic domains (e.g., time, space, color, human body parts and\nactivities), but little is known about the global structure of semantic\ninformation and nothing about its relation to human communication. We first\nshow that across a sample of ~1,000 languages, there is broad variation in how\ndensely languages encode information into their words. Second, we show that\nthis language information density is associated with a denser configuration of\nsemantic information. Finally, we trace the relationship between language\ninformation density and patterns of communication, showing that informationally\ndenser languages tend toward (1) faster communication, but (2) conceptually\nnarrower conversations within which topics of conversation are discussed at\ngreater depth. These results highlight an important source of variation across\nthe human communicative channel, revealing that the structure of language\nshapes the nature and texture of human engagement, with consequences for human\nbehavior across levels of society.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aceves_P/0/1/0/all/0/1\">Pedro Aceves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Evans_J/0/1/0/all/0/1\">James A. Evans</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning ASR pathways: A sparse multilingual ASR model. (arXiv:2209.05735v4 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2209.05735","description":"<p>Neural network pruning compresses automatic speech recognition (ASR) models\neffectively. However, in multilingual ASR, language-agnostic pruning may lead\nto severe performance drops on some languages because language-agnostic pruning\nmasks may not fit all languages and discard important language-specific\nparameters. In this work, we present ASR pathways, a sparse multilingual ASR\nmodel that activates language-specific sub-networks (\"pathways\"), such that the\nparameters for each language are learned explicitly. With the overlapping\nsub-networks, the shared parameters can also enable knowledge transfer for\nlower-resource languages via joint multilingual training. We propose a novel\nalgorithm to learn ASR pathways, and evaluate the proposed method on 4\nlanguages with a streaming RNN-T model. Our proposed ASR pathways outperform\nboth dense models and a language-agnostically pruned model, and provide better\nperformance on low-resource languages compared to the monolingual sparse\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_M/0/1/0/all/0/1\">Mu Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tjandra_A/0/1/0/all/0/1\">Andros Tjandra</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1\">Chunxi Liu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_D/0/1/0/all/0/1\">David Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Le_D/0/1/0/all/0/1\">Duc Le</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kalinli_O/0/1/0/all/0/1\">Ozlem Kalinli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PESTS: Persian_English Cross Lingual Corpus for Semantic Textual Similarity. (arXiv:2305.07893v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07893","description":"<p>One of the components of natural language processing that has received a lot\nof investigation recently is semantic textual similarity. In computational\nlinguistics and natural language processing, assessing the semantic similarity\nof words, phrases, paragraphs, and texts is crucial. Calculating the degree of\nsemantic resemblance between two textual pieces, paragraphs, or phrases\nprovided in both monolingual and cross-lingual versions is known as semantic\nsimilarity. Cross lingual semantic similarity requires corpora in which there\nare sentence pairs in both the source and target languages with a degree of\nsemantic similarity between them. Many existing cross lingual semantic\nsimilarity models use a machine translation due to the unavailability of cross\nlingual semantic similarity dataset, which the propagation of the machine\ntranslation error reduces the accuracy of the model. On the other hand, when we\nwant to use semantic similarity features for machine translation the same\nmachine translations should not be used for semantic similarity. For Persian,\nwhich is one of the low resource languages, no effort has been made in this\nregard and the need for a model that can understand the context of two\nlanguages is felt more than ever. In this article, the corpus of semantic\ntextual similarity between sentences in Persian and English languages has been\nproduced for the first time by using linguistic experts. We named this dataset\nPESTS (Persian English Semantic Textual Similarity). This corpus contains 5375\nsentence pairs. Also, different models based on transformers have been\nfine-tuned using this dataset. The results show that using the PESTS dataset,\nthe Pearson correlation of the XLM ROBERTa model increases from 85.87% to\n95.62%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdous_M/0/1/0/all/0/1\">Mohammad Abdous</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piroozfar_P/0/1/0/all/0/1\">Poorya Piroozfar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bidgoli_B/0/1/0/all/0/1\">Behrouz Minaei Bidgoli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Dataset Transferability in Active Learning for Transformers. (arXiv:2305.09807v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.09807","description":"<p>Active learning (AL) aims to reduce labeling costs by querying the examples\nmost beneficial for model learning. While the effectiveness of AL for\nfine-tuning transformer-based pre-trained language models (PLMs) has been\ndemonstrated, it is less clear to what extent the AL gains obtained with one\nmodel transfer to others. We consider the problem of transferability of\nactively acquired datasets in text classification and investigate whether AL\ngains persist when a dataset built using AL coupled with a specific PLM is used\nto train a different PLM. We link the AL dataset transferability to the\nsimilarity of instances queried by the different PLMs and show that AL methods\nwith similar acquisition sequences produce highly transferable datasets\nregardless of the models used. Additionally, we show that the similarity of\nacquisition sequences is influenced more by the choice of the AL method than\nthe choice of the model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jelenic_F/0/1/0/all/0/1\">Fran Jeleni&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jukic_J/0/1/0/all/0/1\">Josip Juki&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Drobac_N/0/1/0/all/0/1\">Nina Drobac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Language Models with Advantage-based Offline Policy Gradients. (arXiv:2305.14718v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14718","description":"<p>Abstract Language Models (LMs) achieve substantial language capabilities when\nfinetuned using Reinforcement Learning with Human Feedback (RLHF). However,\nRLHF is an unstable and data-hungry process that continually requires new\nhigh-quality LM-generated data for finetuning. We introduce Advantage-Leftover\nLunch RL (A-LoL), a new class of offline policy gradient algorithms that enable\nRL training on any pre-existing data. By assuming the entire LM output sequence\nas a single action, A-LoL allows incorporating sequence-level classifiers or\nhuman-designed scoring functions as rewards. Subsequently, by using LM's\ninternal sequence-level value estimate, A-LoL filters negative advantage\n(low-quality) data points during training, making it resilient to noise.\nOverall, A-LoL is an easy-to-implement LM training recipe that is\nsample-efficient and stable.\n</p>\n<p>We demonstrate the effectiveness of A-LoL and its variants with a set of four\ndifferent language generation tasks. We compare against both online RL (PPO)\nand recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL\nbaselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant\n(HHA), LMs trained with A-LoL methods achieve the highest diversity while also\nbeing rated more safe and helpful than baselines according to humans.\nAdditionally, in the remaining three tasks, A-LoL could optimize multiple\ndistinct reward functions even when using noisy or suboptimal training data. We\nalso release our experimental code. https://github.com/abaheti95/LoL-RL\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baheti_A/0/1/0/all/0/1\">Ashutosh Baheti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Ximing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahman_F/0/1/0/all/0/1\">Faeze Brahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bras_R/0/1/0/all/0/1\">Ronan Le Bras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1\">Mark Riedl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiscale Positive-Unlabeled Detection of AI-Generated Texts. (arXiv:2305.18149v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18149","description":"<p>Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are\nastonishing at generating human-like texts, but they may impact the\nauthenticity of texts. Previous works proposed methods to detect these\nAI-generated texts, including simple ML classifiers, pretrained-model-based\nzero-shot methods, and finetuned language classification models. However,\nmainstream detectors always fail on short texts, like SMSes, Tweets, and\nreviews. In this paper, a Multiscale Positive-Unlabeled (MPU) training\nframework is proposed to address the difficulty of short-text detection without\nsacrificing long-texts. Firstly, we acknowledge the human-resemblance property\nof short machine texts, and rephrase AI text detection as a partial\nPositive-Unlabeled (PU) problem by regarding these short machine texts as\npartially \"unlabeled\". Then in this PU context, we propose the length-sensitive\nMultiscale PU Loss, where a recurrent model in abstraction is used to estimate\npositive priors of scale-variant corpora. Additionally, we introduce a Text\nMultiscaling module to enrich training corpora. Experiments show that our MPU\nmethod augments detection performance on long AI-generated texts, and\nsignificantly improves short-text detection of language model detectors.\nLanguage Models trained with MPU could outcompete existing detectors on various\nshort-text and long-text detection benchmarks. The codes are available at\nhttps://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpt\nand https://github.com/YuchuanTian/AIGC_text_detector.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuchuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hanting Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xutao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Z/0/1/0/all/0/1\">Zheyuan Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinghua Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yunhe Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextual Vision Transformers for Robust Representation Learning. (arXiv:2305.19402v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.19402","description":"<p>We introduce Contextual Vision Transformers (ContextViT), a method designed\nto generate robust image representations for datasets experiencing shifts in\nlatent factors across various groups. Derived from the concept of in-context\nlearning, ContextViT incorporates an additional context token to encapsulate\ngroup-specific information. This integration allows the model to adjust the\nimage representation in accordance with the group-specific context.\nSpecifically, for a given input image, ContextViT maps images with identical\ngroup membership into this context token, which is appended to the input image\ntokens. Additionally, we introduce a context inference network to predict such\ntokens on-the-fly, given a batch of samples from the group. This enables\nContextViT to adapt to new testing distributions during inference time. We\ndemonstrate the efficacy of ContextViT across a wide range of applications. In\nsupervised fine-tuning, we show that augmenting pre-trained ViTs with our\nproposed context conditioning mechanism results in consistent improvements in\nout-of-distribution generalization on iWildCam and FMoW. We also investigate\nself-supervised representation learning with ContextViT. Our experiments on the\nCamelyon17 pathology imaging benchmark and the JUMP-CP microscopy imaging\nbenchmark demonstrate that ContextViT excels in learning stable image\nfeaturizations amidst distribution shift, consistently outperforming its ViT\ncounterpart.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yujia Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karaletsos_T/0/1/0/all/0/1\">Theofanis Karaletsos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language. (arXiv:2306.02797v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.02797","description":"<p>A core tension in models of concept learning is that the model must carefully\nbalance the tractability of inference against the expressivity of the\nhypothesis class. Humans, however, can efficiently learn a broad range of\nconcepts. We introduce a model of inductive learning that seeks to be\nhuman-like in that sense. It implements a Bayesian reasoning process where a\nlanguage model first proposes candidate hypotheses expressed in natural\nlanguage, which are then re-weighed by a prior and a likelihood. By estimating\nthe prior from human data, we can predict human judgments on learning problems\ninvolving numbers and sets, spanning concepts that are generative,\ndiscriminative, propositional, and higher-order.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ellis_K/0/1/0/all/0/1\">Kevin Ellis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning. (arXiv:2306.14565v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2306.14565","description":"<p>Despite the promising progress in multi-modal tasks, current large\nmulti-modal models (LMMs) are prone to hallucinating inconsistent descriptions\nwith respect to the associated image and human instructions. This paper\naddresses this issue by introducing the first large and diverse visual\ninstruction tuning dataset, named Large-scale Robust Visual (LRV)-Instruction.\nOur dataset comprises 400k visual instructions generated by GPT4, covering 16\nvision-and-language tasks with open-ended instructions and answers. Unlike\nexisting studies that primarily focus on positive instruction samples, we\ndesign LRV-Instruction to include both positive and negative instructions for\nmore robust visual instruction tuning. Our negative instructions are designed\nat three semantic levels: (i) Nonexistent Object Manipulation, (ii) Existent\nObject Manipulation and (iii) Knowledge Manipulation. To efficiently measure\nthe hallucination generated by LMMs, we propose GPT4-Assisted Visual\nInstruction Evaluation (GAVIE), a stable approach to evaluate visual\ninstruction tuning like human experts. GAVIE does not require human-annotated\ngroundtruth answers and can adapt to diverse instruction formats. We conduct\ncomprehensive experiments to investigate the hallucination of LMMs. Our results\ndemonstrate existing LMMs exhibit significant hallucinations when presented\nwith our negative instructions, particularly Existent Object and Knowledge\nManipulation instructions. Moreover, we successfully mitigate hallucination by\nfinetuning MiniGPT4 and mPLUG-Owl on LRV-Instruction while improving\nperformance on several public datasets compared to state-of-the-art methods.\nAdditionally, we observed that a balanced ratio of positive and negative\ninstances in the training data leads to a more robust model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fuxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yacoob_Y/0/1/0/all/0/1\">Yaser Yacoob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Generative Large Language Models Perform ASR Error Correction?. (arXiv:2307.04172v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04172","description":"<p>ASR error correction is an interesting option for post processing speech\nrecognition system outputs. These error correction models are usually trained\nin a supervised fashion using the decoding results of a target ASR system. This\napproach can be computationally intensive and the model is tuned to a specific\nASR system. Recently generative large language models (LLMs) have been applied\nto a wide range of natural language processing tasks, as they can operate in a\nzero-shot or few shot fashion. In this paper we investigate using ChatGPT, a\ngenerative LLM, for ASR error correction. Based on the ASR N-best output, we\npropose both unconstrained and constrained, where a member of the N-best list\nis selected, approaches. Additionally, zero and 1-shot settings are evaluated.\nExperiments show that this generative LLM approach can yield performance gains\nfor two different state-of-the-art ASR architectures, transducer and\nattention-encoder-decoder based, and multiple test sets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1\">Rao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1\">Mengjie Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1\">Potsawee Manakul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark Gales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knill_K/0/1/0/all/0/1\">Kate Knill</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Label Bias via Decoupled Confident Learning. (arXiv:2307.08945v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2307.08945","description":"<p>Growing concerns regarding algorithmic fairness have led to a surge in\nmethodologies to mitigate algorithmic bias. However, such methodologies largely\nassume that observed labels in training data are correct. This is problematic\nbecause bias in labels is pervasive across important domains, including\nhealthcare, hiring, and content moderation. In particular, human-generated\nlabels are prone to encoding societal biases. While the presence of labeling\nbias has been discussed conceptually, there is a lack of methodologies to\naddress this problem. We propose a pruning method -- Decoupled Confident\nLearning (DeCoLe) -- specifically designed to mitigate label bias. After\nillustrating its performance on a synthetic dataset, we apply DeCoLe in the\ncontext of hate speech detection, where label bias has been recognized as an\nimportant challenge, and show that it successfully identifies biased labels and\noutperforms competing approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+De_Arteaga_M/0/1/0/all/0/1\">Maria De-Arteaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saar_Tsechansky_M/0/1/0/all/0/1\">Maytal Saar-Tsechansky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Overview Of Temporal Commonsense Reasoning and Acquisition. (arXiv:2308.00002v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2308.00002","description":"<p>Temporal commonsense reasoning refers to the ability to understand the\ntypical temporal context of phrases, actions, and events, and use it to reason\nover problems requiring such knowledge. This trait is essential in temporal\nnatural language processing tasks, with possible applications such as timeline\nsummarization, temporal question answering, and temporal natural language\ninference. Recent research on the performance of large language models suggests\nthat, although they are adept at generating syntactically correct sentences and\nsolving classification tasks, they often take shortcuts in their reasoning and\nfall prey to simple linguistic traps. This article provides an overview of\nresearch in the domain of temporal commonsense reasoning, particularly focusing\non enhancing language model performance through a variety of augmentations and\ntheir evaluation across a growing number of datasets. However, these augmented\nmodels still struggle to approach human performance on reasoning tasks over\ntemporal common sense properties, such as the typical occurrence times,\norderings, or durations of events. We further emphasize the need for careful\ninterpretation of research to guard against overpromising evaluation results in\nlight of the shallow reasoning present in transformers. This can be achieved by\nappropriately preparing datasets and suitable evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wenzel_G/0/1/0/all/0/1\">Georg Wenzel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jatowt_A/0/1/0/all/0/1\">Adam Jatowt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forward-Backward Reasoning in Large Language Models for Mathematical Verification. (arXiv:2308.07758v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.07758","description":"<p>Chain-of-Thought (CoT) prompting in large language models (LLMs) has shown\npromising performance on mathematical reasoning tasks. Recently,\nSelf-Consistency samples a diverse set of reasoning chains with different\nanswers and chooses the answer by majority voting. Though effective, its\nperformance cannot be further improved by sampling more reasoning chains. To\naddress this problem, we propose to integrate backward reasoning into answer\nverification. We first mask a number in the question by ${\\bf x}$. The LLM is\nthen asked to predict the masked number with a candidate answer $A$ embedded in\nthe template: ``If we know the answer to the above question is $\\{A\\}$, what is\nthe value of unknown variable ${\\bf x}$?'' The LLM is expected to predict the\nmasked number successfully if the provided candidate answer is correct. To\nfurther improve performance, we propose FOBAR (FOrward-BAckward Reasoning) to\ncombine forward and backward reasoning for verifying candidate answers.\nExperiments are performed on six standard mathematical data sets and three LLMs\n(text-davinci-003, GPT-3.5-Turbo, GPT-4). Results show that FOBAR achieves\nstate-of-the-art performance. In particular, FOBAR outperforms Self-Consistency\nwhich uses forward reasoning alone, demonstrating that combining forward and\nforward reasoning is better. It also outperforms existing verification methods,\nverifying the effectiveness of using the simple template in backward reasoning\nand the proposed combination.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weisen Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1\">Han Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Longhui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1\">James T. Kwok</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scope is all you need: Transforming LLMs for HPC Code. (arXiv:2308.09440v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.09440","description":"<p>With easier access to powerful compute resources, there is a growing trend in\nthe field of AI for software development to develop larger and larger language\nmodels (LLMs) to address a variety of programming tasks. Even LLMs applied to\ntasks from the high-performance computing (HPC) domain are huge in size (e.g.,\nbillions of parameters) and demand expensive compute resources for training. We\nfound this design choice confusing - why do we need large LLMs trained on\nnatural languages and programming languages unrelated to HPC for HPC-specific\ntasks? In this line of work, we aim to question design choices made by existing\nLLMs by developing smaller LLMs for specific domains - we call them\ndomain-specific LLMs. Specifically, we start off with HPC as a domain and\npropose a novel tokenizer named Tokompiler, designed specifically for\npreprocessing code in HPC and compilation-centric tasks. Tokompiler leverages\nknowledge of language primitives to generate language-oriented tokens,\nproviding a context-aware understanding of code structure while avoiding human\nsemantics attributed to code structures completely. We applied Tokompiler to\npre-train two state-of-the-art models, SPT-Code and Polycoder, for a Fortran\ncode corpus mined from GitHub. We evaluate the performance of these models\nagainst the conventional LLMs. Results demonstrate that Tokompiler\nsignificantly enhances code completion accuracy and semantic understanding\ncompared to traditional tokenizers in normalized-perplexity tests, down to ~1\nperplexity score. This research opens avenues for further advancements in\ndomain-specific LLMs, catering to the unique demands of HPC and compilation\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kadosh_T/0/1/0/all/0/1\">Tal Kadosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasabnis_N/0/1/0/all/0/1\">Niranjan Hasabnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_V/0/1/0/all/0/1\">Vy A. Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1\">Nadav Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krien_N/0/1/0/all/0/1\">Neva Krien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wasay_A/0/1/0/all/0/1\">Abdul Wasay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1\">Nesreen Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Willke_T/0/1/0/all/0/1\">Ted Willke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamir_G/0/1/0/all/0/1\">Guy Tamir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinter_Y/0/1/0/all/0/1\">Yuval Pinter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1\">Timothy Mattson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oren_G/0/1/0/all/0/1\">Gal Oren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models. (arXiv:2308.16149v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.16149","description":"<p>We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric\nfoundation and instruction-tuned open generative large language models (LLMs).\nThe models are based on the GPT-3 decoder-only architecture and are pretrained\non a mixture of Arabic and English texts, including source code in various\nprogramming languages. With 13 billion parameters, they demonstrate better\nknowledge and reasoning capabilities in Arabic than any existing open Arabic\nand multilingual models by a sizable margin, based on extensive evaluation.\nMoreover, the models are competitive in English compared to English-centric\nopen models of similar size, despite being trained on much less English data.\nWe provide a detailed description of the training, the tuning, the safety\nalignment, and the evaluation of the models. We release two open versions of\nthe model -- the foundation Jais model, and an instruction-tuned Jais-chat\nvariant -- with the aim of promoting research on Arabic LLMs. Available at\nhttps://huggingface.co/inception-mbzuai/jais-13b-chat\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sengupta_N/0/1/0/all/0/1\">Neha Sengupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1\">Sunil Kumar Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_B/0/1/0/all/0/1\">Bokang Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katipomu_S/0/1/0/all/0/1\">Satheesh Katipomu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1\">Fajri Koto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marshall_W/0/1/0/all/0/1\">William Marshall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gosal_G/0/1/0/all/0/1\">Gurpreet Gosal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cynthia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Afzal_O/0/1/0/all/0/1\">Osama Mohammed Afzal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamboj_S/0/1/0/all/0/1\">Samta Kamboj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandit_O/0/1/0/all/0/1\">Onkar Pandit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pal_R/0/1/0/all/0/1\">Rahul Pal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pradhan_L/0/1/0/all/0/1\">Lalit Pradhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mujahid_Z/0/1/0/all/0/1\">Zain Muhammad Mujahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baali_M/0/1/0/all/0/1\">Massa Baali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xudong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bsharat_S/0/1/0/all/0/1\">Sondos Mahmoud Bsharat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhiqiang Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengzhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassilieva_N/0/1/0/all/0/1\">Natalia Vassilieva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1\">Joel Hestness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hock_A/0/1/0/all/0/1\">Andy Hock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_A/0/1/0/all/0/1\">Andrew Feldman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jonathan Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jackson_A/0/1/0/all/0/1\">Andrew Jackson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1\">Hector Xuguang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler. (arXiv:2309.05086v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05086","description":"<p>We propose a neuralized undirected graphical model called Neural-Hidden-CRF\nto solve the weakly-supervised sequence labeling problem. Under the umbrella of\nprobabilistic undirected graph theory, the proposed Neural-Hidden-CRF embedded\nwith a hidden CRF layer models the variables of word sequence, latent ground\ntruth sequence, and weak label sequence with the global perspective that\nundirected graphical models particularly enjoy. In Neural-Hidden-CRF, we can\ncapitalize on the powerful language model BERT or other deep models to provide\nrich contextual semantic knowledge to the latent ground truth sequence, and use\nthe hidden CRF layer to capture the internal label dependencies.\nNeural-Hidden-CRF is conceptually simple and empirically powerful. It obtains\nnew state-of-the-art results on one crowdsourcing benchmark and three\nweak-supervision benchmarks, including outperforming the recent advanced model\nCHMM by 2.80 F1 points and 2.23 F1 points in average generalization and\ninference performance, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hailong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wanhao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chunyi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qianren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pengpeng Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PACE-LM: Prompting and Augmentation for Calibrated Confidence Estimation with GPT-4 in Cloud Incident Root Cause Analysis. (arXiv:2309.05833v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05833","description":"<p>Major cloud providers have employed advanced AI-based solutions like large\nlanguage models to aid humans in identifying the root causes of cloud\nincidents. Despite the growing prevalence of AI-driven assistants in the root\ncause analysis process, their effectiveness in assisting on-call engineers is\nconstrained by low accuracy due to the intrinsic difficulty of the task, a\npropensity for LLM-based approaches to hallucinate, and difficulties in\ndistinguishing these well-disguised hallucinations. To address this challenge,\nwe propose to perform confidence estimation for the predictions to help on-call\nengineers make decisions on whether to adopt the model prediction. Considering\nthe black-box nature of many LLM-based root cause predictors, fine-tuning or\ntemperature-scaling-based approaches are inapplicable. We therefore design an\ninnovative confidence estimation framework based on prompting\nretrieval-augmented large language models (LLMs) that demand a minimal amount\nof information from the root cause predictor. This approach consists of two\nscoring phases: the LLM-based confidence estimator first evaluates its\nconfidence in making judgments in the face of the current incident that\nreflects its ``grounded-ness\" level in reference data, then rates the root\ncause prediction based on historical references. An optimization step combines\nthese two scores for a final confidence assignment. We show that our method is\nable to produce calibrated confidence estimates for predicted root causes,\nvalidate the usefulness of retrieved historical data and the prompting strategy\nas well as the generalizability across different root cause prediction models.\nOur study takes an important move towards reliably and effectively embedding\nLLMs into cloud incident management systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dylan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xuchao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_C/0/1/0/all/0/1\">Chetan Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Las_Casas_P/0/1/0/all/0/1\">Pedro Las-Casas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fonseca_R/0/1/0/all/0/1\">Rodrigo Fonseca</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajmohan_S/0/1/0/all/0/1\">Saravan Rajmohan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL. (arXiv:2309.06553v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06553","description":"<p>In this study, we aim to enhance the arithmetic reasoning ability of Large\nLanguage Models (LLMs) through zero-shot prompt optimization. We identify a\npreviously overlooked objective of query dependency in such optimization and\nelucidate two ensuing challenges that impede the successful and economical\ndesign of prompt optimization techniques. One primary issue is the absence of\nan effective method to evaluate prompts during inference when the golden answer\nis unavailable. Concurrently, learning via interactions with the LLMs to\nnavigate the expansive natural language prompting space proves to be\nresource-intensive. To address this, we introduce Prompt-OIRL, which harnesses\noffline inverse reinforcement learning to draw insights from offline prompting\ndemonstration data. Such data exists as by-products when diverse prompts are\nbenchmarked on open-accessible datasets. With Prompt-OIRL, the query-dependent\nprompt optimization objective is achieved by first learning an offline reward\nmodel. This model can evaluate any query-prompt pairs without accessing LLMs.\nSubsequently, a best-of-N strategy is deployed to recommend the optimal prompt.\nOur experimental evaluations across various LLM scales and arithmetic reasoning\ndatasets underscore both the efficacy and economic viability of the proposed\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huyuk_A/0/1/0/all/0/1\">Alihan H&#xfc;y&#xfc;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Narrative as a Dynamical System. (arXiv:2309.06600v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06600","description":"<p>There is increasing evidence that human activity in general, and narrative in\nparticular, can be treated as a dynamical system in the physics sense; a system\nwhose evolution is described by an action integral, such that the average of\nall possible paths from point A to point B is given by the extremum of the\naction. We create by construction three such paths by averaging about 500\ndifferent narratives, and we show that the average path is consistent with an\naction principle.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doxas_I/0/1/0/all/0/1\">Isidoros Doxas</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Meiss_J/0/1/0/all/0/1\">James Meiss</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Bottone_S/0/1/0/all/0/1\">Steven Bottone</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Strelich_T/0/1/0/all/0/1\">Tom Strelich</a> (4 and 5), <a href=\"http://arxiv.org/find/cs/1/au:+Plummer_A/0/1/0/all/0/1\">Andrew Plummer</a> (5 and 6), <a href=\"http://arxiv.org/find/cs/1/au:+Breland_A/0/1/0/all/0/1\">Adrienne Breland</a> (5 and 7), <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_S/0/1/0/all/0/1\">Simon Dennis</a> (8 and 9), <a href=\"http://arxiv.org/find/cs/1/au:+Garvin_Doxas_K/0/1/0/all/0/1\">Kathy Garvin-Doxas</a> (9 and 10), <a href=\"http://arxiv.org/find/cs/1/au:+Klymkowsky_M/0/1/0/all/0/1\">Michael Klymkowsky</a> (3) ( (1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs. (arXiv:2309.07311v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07311","description":"<p>Most interpretability research in NLP focuses on understanding the behavior\nand features of a fully trained model. However, certain insights into model\nbehavior may only be accessible by observing the trajectory of the training\nprocess. We present a case study of syntax acquisition in masked language\nmodels (MLMs) that demonstrates how analyzing the evolution of interpretable\nartifacts throughout training deepens our understanding of emergent behavior.\nIn particular, we study Syntactic Attention Structure (SAS), a naturally\nemerging property of MLMs wherein specific Transformer heads tend to focus on\nspecific syntactic relations. We identify a brief window in pretraining when\nmodels abruptly acquire SAS, concurrent with a steep drop in loss. This\nbreakthrough precipitates the subsequent acquisition of linguistic\ncapabilities. We then examine the causal role of SAS by manipulating SAS during\ntraining, and demonstrate that SAS is necessary for the development of\ngrammatical capabilities. We further find that SAS competes with other\nbeneficial traits during training, and that briefly suppressing SAS improves\nmodel quality. These findings offer an interpretation of a real-world example\nof both simplicity bias and breakthrough training dynamics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Angelica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_Ziv_R/0/1/0/all/0/1\">Ravid Shwartz-Ziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew L. Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Dynamical Principles of Storytelling. (arXiv:2309.07797v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07797","description":"<p>When considering the opening part of 1800 short stories, we find that the\nfirst dozen paragraphs of the average narrative follow an action principle as\ndefined in <a href=\"/abs/2309.06600\">arXiv:2309.06600</a>. When the order of the paragraphs is shuffled, the\naverage no longer exhibits this property. The findings show that there is a\npreferential direction we take in semantic space when starting a story,\npossibly related to a common Western storytelling tradition as implied by\nAristotle in Poetics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Doxas_I/0/1/0/all/0/1\">Isidoros Doxas</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Meiss_J/0/1/0/all/0/1\">James Meiss</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Bottone_S/0/1/0/all/0/1\">Steven Bottone</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Strelich_T/0/1/0/all/0/1\">Tom Strelich</a> (4 and 5), <a href=\"http://arxiv.org/find/cs/1/au:+Plummer_A/0/1/0/all/0/1\">Andrew Plummer</a> (5 and 6), <a href=\"http://arxiv.org/find/cs/1/au:+Breland_A/0/1/0/all/0/1\">Adrienne Breland</a> (5 and 7), <a href=\"http://arxiv.org/find/cs/1/au:+Dennis_S/0/1/0/all/0/1\">Simon Dennis</a> (8 and 9), <a href=\"http://arxiv.org/find/cs/1/au:+Garvin_Doxas_K/0/1/0/all/0/1\">Kathy Garvin-Doxas</a> (9 and 10), <a href=\"http://arxiv.org/find/cs/1/au:+Klymkowsky_M/0/1/0/all/0/1\">Michael Klymkowsky</a> (3) ((1) Northrop Grumman Corporation, (2) Some work performed at the University of Colorado, Boulder, (3) University of Colorado, Boulder, (4) Fusion Constructive LLC, (5) Work performed at Northop Grumman Corporation (6) Current Address JP Morgan, (7) Current address, GALT Aerospace, (8) University of Melbourne, (9) Work performed at the University of Colorado, Boulder, (10) Boulder Internet Technologies)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Decoding Improves Reasoning in Large Language Models. (arXiv:2309.09117v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.09117","description":"<p>We demonstrate that Contrastive Decoding -- a simple, computationally light,\nand training-free text generation method proposed by Li et al 2022 -- achieves\nlarge out-of-the-box improvements over greedy decoding on a variety of\nreasoning tasks. Originally shown to improve the perceived quality of long-form\ntext generation, Contrastive Decoding searches for strings that maximize a\nweighted difference in likelihood between strong and weak models. We show that\nContrastive Decoding leads LLaMA-65B to outperform LLaMA 2, GPT-3.5 and PaLM\n2-L on the HellaSwag commonsense reasoning benchmark, and to outperform LLaMA\n2, GPT-3.5 and PaLM-540B on the GSM8K math word reasoning benchmark, in\naddition to improvements on a collection of other tasks. Analysis suggests that\nContrastive Decoding improves over existing methods by preventing some abstract\nreasoning errors, as well as by avoiding simpler modes such as copying sections\nof the input during chain-of-thought. Overall, Contrastive Decoding outperforms\nnucleus sampling for long-form generation and greedy decoding for reasoning\ntasks, making it a powerful general purpose method for generating text from\nlanguage models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+OBrien_S/0/1/0/all/0/1\">Sean O&#x27;Brien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MBR and QE Finetuning: Training-time Distillation of the Best and Most Expensive Decoding Methods. (arXiv:2309.10966v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.10966","description":"<p>Recent research in decoding methods for Natural Language Generation (NLG)\ntasks has shown that MAP decoding is not optimal, because model probabilities\ndo not always align with human preferences. Stronger decoding methods,\nincluding Quality Estimation (QE) reranking and Minimum Bayes' Risk (MBR)\ndecoding, have since been proposed to mitigate the model-perplexity-vs-quality\nmismatch. While these decoding methods achieve state-of-the-art performance,\nthey are prohibitively expensive to compute. In this work, we propose MBR\nfinetuning and QE finetuning which distill the quality gains from these\ndecoding methods at training time, while using an efficient decoding algorithm\nat inference time. Using the canonical NLG task of Neural Machine Translation\n(NMT), we show that even with self-training, these finetuning methods\nsignificantly outperform the base model. Moreover, when using an external LLM\nas a teacher model, these finetuning methods outperform finetuning on\nhuman-generated references. These findings suggest new ways to leverage\nmonolingual data to achieve improvements in model quality that are on par with,\nor even exceed, improvements from human-curated data, while maintaining maximum\nefficiency during decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Finkelstein_M/0/1/0/all/0/1\">Mara Finkelstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1\">Markus Freitag</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination. (arXiv:2309.11696v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.11696","description":"<p>Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable\nproficiency in comprehending and generating natural language. However, their\nunpersonalized generation paradigm may result in suboptimal user-specific\noutcomes. Typically, users converse differently based on their knowledge and\npreferences. This necessitates the task of enhancing user-oriented LLM which\nremains unexplored. While one can fully train an LLM for this objective, the\nresource consumption is unaffordable. Prior research has explored memory-based\nmethods to store and retrieve knowledge to enhance generation without\nretraining for new queries. However, we contend that a mere memory module is\ninadequate to comprehend a user's preference, and fully training an LLM can be\nexcessively costly. In this study, we propose a novel computational bionic\nmemory mechanism, equipped with a parameter-efficient fine-tuning schema, to\npersonalize LLMs. Our extensive experimental results demonstrate the\neffectiveness and superiority of the proposed approach. To encourage further\nresearch into this area, we are releasing a new conversation dataset generated\nentirely by LLM based on an open-source medical corpus, as well as our\nimplementation code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1\">Fubang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yangyang Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for Hospitalized Patients. (arXiv:2309.12625v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.12625","description":"<p>In the U.S. inpatient payment system, the Diagnosis-Related Group (DRG) is\npivotal, but its assignment process is inefficient. The study introduces\nDRG-LLaMA, an advanced large language model (LLM) fine-tuned on clinical notes\nto enhance DRGs assignment. Utilizing LLaMA as the foundational model and\noptimizing it through Low-Rank Adaptation (LoRA) on 236,192 MIMIC-IV discharge\nsummaries, our DRG-LLaMA-7B model exhibited a noteworthy macro-averaged F1\nscore of 0.327, a top-1 prediction accuracy of 52.0%, and a macro-averaged Area\nUnder the Curve (AUC) of 0.986, with a maximum input token length of 512. This\nmodel surpassed the performance of prior leading models in DRG prediction,\nshowing a relative improvement of 40.3% and 35.7% in macro-averaged F1 score\ncompared to ClinicalBERT and CAML, respectively. Applied to base DRG and\ncomplication or comorbidity (CC)/major complication or comorbidity (MCC)\nprediction, DRG-LLaMA achieved a top-1 prediction accuracy of 67.8% and 67.5%,\nrespectively. Additionally, our findings indicate that DRG-LLaMA's performance\ncorrelates with increased model parameters and input context lengths.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chufan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dantona_C/0/1/0/all/0/1\">Christopher Dantona</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hull_B/0/1/0/all/0/1\">Bryan Hull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jimeng Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cardiovascular Disease Risk Prediction via Social Media. (arXiv:2309.13147v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.13147","description":"<p>Researchers use Twitter and sentiment analysis to predict Cardiovascular\nDisease (CVD) risk. We developed a new dictionary of CVD-related keywords by\nanalyzing emotions expressed in tweets. Tweets from eighteen US states,\nincluding the Appalachian region, were collected. Using the VADER model for\nsentiment analysis, users were classified as potentially at CVD risk. Machine\nLearning (ML) models were employed to classify individuals' CVD risk and\napplied to a CDC dataset with demographic information to make the comparison.\nPerformance evaluation metrics such as Test Accuracy, Precision, Recall, F1\nscore, Mathew's Correlation Coefficient (MCC), and Cohen's Kappa (CK) score\nwere considered. Results demonstrated that analyzing tweets' emotions surpassed\nthe predictive power of demographic data alone, enabling the identification of\nindividuals at potential risk of developing CVD. This research highlights the\npotential of Natural Language Processing (NLP) and ML techniques in using\ntweets to identify individuals with CVD risks, providing an alternative\napproach to traditional demographic information for public health monitoring.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Habib_A/0/1/0/all/0/1\">Al Zadid Sultan Bin Habib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Syed_M/0/1/0/all/0/1\">Md Asif Bin Syed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1\">Md Tanvirul Islam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1\">Donald A. Adjeroh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech Representation Learning. (arXiv:2309.13860v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.13860","description":"<p>Recent years have witnessed significant advancements in self-supervised\nlearning (SSL) methods for speech-processing tasks. Various speech-based SSL\nmodels have been developed and present promising performance on a range of\ndownstream tasks including speech recognition. However, existing speech-based\nSSL models face a common dilemma in terms of computational cost, which might\nhinder their potential application and in-depth academic research. To address\nthis issue, we first analyze the computational cost of different modules during\nHuBERT pre-training and then introduce a stack of efficiency optimizations,\nwhich is named Fast-HuBERT in this paper. The proposed Fast-HuBERT can be\ntrained in 1.1 days with 8 V100 GPUs on the Librispeech 960h benchmark, without\nperformance degradation, resulting in a 5.2x speedup, compared to the original\nimplementation. Moreover, we explore two well-studied techniques in the\nFast-HuBERT and demonstrate consistent improvements as reported in previous\nwork.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guanrou Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Ziyang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhisheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yakun Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_Z/0/1/0/all/0/1\">Zhikang Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Survey of Document-level Relation Extraction (2016-2023). (arXiv:2309.16396v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16396","description":"<p>Document-level relation extraction (DocRE) is an active area of research in\nnatural language processing (NLP) concerned with identifying and extracting\nrelationships between entities beyond sentence boundaries. Compared to the more\ntraditional sentence-level relation extraction, DocRE provides a broader\ncontext for analysis and is more challenging because it involves identifying\nrelationships that may span multiple sentences or paragraphs. This task has\ngained increased interest as a viable solution to build and populate knowledge\nbases automatically from unstructured large-scale documents (e.g., scientific\npapers, legal contracts, or news articles), in order to have a better\nunderstanding of relationships between entities. This paper aims to provide a\ncomprehensive overview of recent advances in this field, highlighting its\ndifferent applications in comparison to sentence-level relation extraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Delaunay_J/0/1/0/all/0/1\">Julien Delaunay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1\">Thi Hong Hanh Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Gallardo_C/0/1/0/all/0/1\">Carlos-Emiliano Gonz&#xe1;lez-Gallardo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordea_G/0/1/0/all/0/1\">Georgeta Bordea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidere_N/0/1/0/all/0/1\">Nicolas Sidere</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1\">Antoine Doucet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Demystifying CLIP Data. (arXiv:2309.16671v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2309.16671","description":"<p>Contrastive Language-Image Pre-training (CLIP) is an approach that has\nadvanced research and applications in computer vision, fueling modern\nrecognition systems and generative models. We believe that the main ingredient\nto the success of CLIP is its data and not the model architecture or\npre-training objective. However, CLIP only provides very limited information\nabout its data and how it has been collected, leading to works that aim to\nreproduce CLIP's data by filtering with its model parameters. In this work, we\nintend to reveal CLIP's data curation approach and in our pursuit of making it\nopen to the community introduce Metadata-Curated Language-Image Pre-training\n(MetaCLIP). MetaCLIP takes a raw data pool and metadata (derived from CLIP's\nconcepts) and yields a balanced subset over the metadata distribution. Our\nexperimental study rigorously isolates the model and training settings,\nconcentrating solely on data. MetaCLIP applied to CommonCrawl with 400M\nimage-text data pairs outperforms CLIP's data on multiple standard benchmarks.\nIn zero-shot ImageNet classification, MetaCLIP achieves 70.8% accuracy,\nsurpassing CLIP's 68.3% on ViT-B models. Scaling to 1B data, while maintaining\nthe same training budget, attains 72.4%. Our observations hold across various\nmodel sizes, exemplified by ViT-H achieving 80.5%, without any\nbells-and-whistles. Curation code and training data distribution on metadata is\nmade available at https://github.com/facebookresearch/MetaCLIP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1\">Saining Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiaoqing Ellen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1\">Po-Yao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howes_R/0/1/0/all/0/1\">Russell Howes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1\">Vasu Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shang-Wen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_G/0/1/0/all/0/1\">Gargi Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feichtenhofer_C/0/1/0/all/0/1\">Christoph Feichtenhofer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-01T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}