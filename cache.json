{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2024-01-23T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Location Sensitive Embedding for Knowledge Graph Embedding. (arXiv:2401.10893v1 [cs.IR])","link":"http://arxiv.org/abs/2401.10893","description":"<p>Knowledge graph embedding transforms knowledge graphs into a continuous,\nlow-dimensional space, facilitating inference and completion tasks. This field\nis mainly divided into translational distance models and semantic matching\nmodels. A key challenge in translational distance models is their inability to\neffectively differentiate between 'head' and 'tail' entities in graphs. To\naddress this, the novel location-sensitive embedding (LSE) method has been\ndeveloped. LSE innovatively modifies the head entity using relation-specific\nmappings, conceptualizing relations as linear transformations rather than mere\ntranslations. The theoretical foundations of LSE, including its\nrepresentational capabilities and its connections to existing models, have been\nthoroughly examined. A more streamlined variant, LSEd, employs a diagonal\nmatrix for transformations to enhance practical efficiency. In tests conducted\non four large-scale datasets for link prediction, LSEd either outperforms or is\ncompetitive with leading contemporary models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1\">Deepak Banerjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishaan_A/0/1/0/all/0/1\">Anjali Ishaan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards building a monitoring platform for a challenge-oriented smart specialisation with RIS3-MCAT. (arXiv:2401.10900v1 [cs.CY])","link":"http://arxiv.org/abs/2401.10900","description":"<p>In the new research and innovation (R&amp;I) paradigm, aimed at a transformation\ntowards more sustainable, inclusive and fair pathways to address societal and\nenvironmental challenges, and at generating new patterns of specialisation and\nnew trajectories for socioeconomic development, it is essential to provide\nmonitoring systems and tools to map and understand the contribution of R&amp;I\npolicies and projects. To address this transformation, we present the RIS3-MCAT\nplatform, the result of a line of work aimed at exploring the potential of open\ndata, semantic analysis, and data visualisation, for monitoring\nchallenge-oriented smart specialisation in Catalonia. RIS3-MCAT is an\ninteractive platform that facilitates access to R&amp;I project data in formats\nthat allow for sophisticated analyses of a large volume of texts, enabling the\ndetailed study of thematic specialisations and challenges beyond classical\nclassification systems. Its conceptualisation, development framework and use\nare presented in this paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fuster_E/0/1/0/all/0/1\">Enric Fuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_T/0/1/0/all/0/1\">Tatiana Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carretero_H/0/1/0/all/0/1\">Hermes Carretero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duran_Silva_N/0/1/0/all/0/1\">Nicolau Duran-Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guixe_R/0/1/0/all/0/1\">Roger Guix&#xe9;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujol_J/0/1/0/all/0/1\">Josep Pujol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rondelli_B/0/1/0/all/0/1\">Bernardo Rondelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rull_G/0/1/0/all/0/1\">Guillem Rull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cortijo_M/0/1/0/all/0/1\">Marta Cortijo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Romagosa_M/0/1/0/all/0/1\">Montserrat Romagosa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RELIANCE: Reliable Ensemble Learning for Information and News Credibility Evaluation. (arXiv:2401.10940v1 [cs.IR])","link":"http://arxiv.org/abs/2401.10940","description":"<p>In the era of information proliferation, discerning the credibility of news\ncontent poses an ever-growing challenge. This paper introduces RELIANCE, a\npioneering ensemble learning system designed for robust information and fake\nnews credibility evaluation. Comprising five diverse base models, including\nSupport Vector Machine (SVM), naive Bayes, logistic regression, random forest,\nand Bidirectional Long Short Term Memory Networks (BiLSTMs), RELIANCE employs\nan innovative approach to integrate their strengths, harnessing the collective\nintelligence of the ensemble for enhanced accuracy. Experiments demonstrate the\nsuperiority of RELIANCE over individual models, indicating its efficacy in\ndistinguishing between credible and non-credible information sources. RELIANCE,\nalso surpasses baseline models in information and news credibility assessment,\nestablishing itself as an effective solution for evaluating the reliability of\ninformation sources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramezani_M/0/1/0/all/0/1\">Majid Ramezani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_Shahi_H/0/1/0/all/0/1\">Hamed Mohammad-Shahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daliry_M/0/1/0/all/0/1\">Mahshid Daliry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1\">Soroor Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghari_A/0/1/0/all/0/1\">Amir-Hosein Asghari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Radiation Oncology NLP Database. (arXiv:2401.10995v1 [cs.CL])","link":"http://arxiv.org/abs/2401.10995","description":"<p>We present the Radiation Oncology NLP Database (ROND), the first dedicated\nNatural Language Processing (NLP) dataset for radiation oncology, an important\nmedical specialty that has received limited attention from the NLP community in\nthe past. With the advent of Artificial General Intelligence (AGI), there is an\nincreasing need for specialized datasets and benchmarks to facilitate research\nand development. ROND is specifically designed to address this gap in the\ndomain of radiation oncology, a field that offers many opportunities for NLP\nexploration. It encompasses various NLP tasks including Logic Reasoning, Text\nClassification, Named Entity Recognition (NER), Question Answering (QA), Text\nSummarization, and Patient-Clinician Conversations, each with a distinct focus\non radiation oncology concepts and application cases. In addition, we have\ndeveloped an instruction-tuning dataset consisting of over 20k instruction\npairs (based on ROND) and trained a large language model, CancerChat. This\nserves to demonstrate the potential of instruction-tuning large language models\nwithin a highly-specialized medical domain. The evaluation results in this\nstudy could serve as baseline results for future research. ROND aims to\nstimulate advancements in radiation oncology and clinical NLP by offering a\nplatform for testing and improving algorithms and models in a domain-specific\ncontext. The ROND dataset is a joint effort of multiple U.S. health\ninstitutions. The data is available at\nhttps://github.com/zl-liu/Radiation-Oncology-NLP-Database.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holmes_J/0/1/0/all/0/1\">Jason Holmes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wenxiong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chenbin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Hongying Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peilong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elahi_M/0/1/0/all/0/1\">Muhammad Ali Elahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1\">Hongmin Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Lichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Quanzheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Jiajian Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning. (arXiv:2401.11021v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11021","description":"<p>Hate speech is harmful content that directly attacks or promotes hatred\nagainst members of groups or individuals based on actual or perceived aspects\nof identity, such as racism, religion, or sexual orientation. This can affect\nsocial life on social media platforms as hateful content shared through social\nmedia can harm both individuals and communities. As the prevalence of hate\nspeech increases online, the demand for automated detection as an NLP task is\nincreasing. In this work, the proposed method is using transformer-based model\nto detect hate speech in social media, like twitter, Facebook, WhatsApp,\nInstagram, etc. The proposed model is independent of languages and has been\ntested on Italian, English, German, Bengali. The Gold standard datasets were\ncollected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel,\nand Rezaul Karim. The success rate of the proposed model for hate speech\ndetection is higher than the existing baseline and state-of-the-art models with\naccuracy in Bengali dataset is 89%, in English: 91%, in German dataset 91% and\nin Italian dataset it is 77%. The proposed algorithm shows substantial\nimprovement to the benchmark method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Arijit Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nandy_S/0/1/0/all/0/1\">Somashree Nandy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1\">Rupam Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Srijan Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_D/0/1/0/all/0/1\">Diganta Saha</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for Large Language Models' Training?. (arXiv:2401.11033v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11033","description":"<p>Advancements in Large Language Models (LLMs) highlight the need for ethical\npractices and data integrity. We introduce a framework that embeds FAIR\n(Findable, Accessible, Interoperable, Reusable) data principles into LLM\ntraining. This approach marks a shift towards practices compliant with FAIR\nstandards. Our framework presents guidelines for integrating FAIR data\nprinciples into LLM training. This initiative includes a checklist for\nresearchers and developers. We also demonstrate its practical application\nthrough a case study focused on bias identification and mitigation in our\nFAIR-compliant dataset. This work is a significant contribution to AI ethics\nand data science, advocating for balanced and ethical training methods in LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghuge_S/0/1/0/all/0/1\">Shardul Ghuge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1\">Chen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pandya_D/0/1/0/all/0/1\">Deval Pandya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical Knowledge. (arXiv:2401.11048v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11048","description":"<p>PubTator 3.0 (https://www.ncbi.nlm.nih.gov/research/pubtator3/) is a\nbiomedical literature resource using state-of-the-art AI techniques to offer\nsemantic and relation searches for key concepts like proteins, genetic\nvariants, diseases, and chemicals. It currently provides over one billion\nentity and relation annotations across approximately 36 million PubMed\nabstracts and 6 million full-text articles from the PMC open access subset,\nupdated weekly. PubTator 3.0's online interface and API utilize these\nprecomputed entity relations and synonyms to provide advanced search\ncapabilities and enable large-scale analyses, streamlining many complex\ninformation needs. We showcase the retrieval quality of PubTator 3.0 using a\nseries of entity pair queries, demonstrating that PubTator 3.0 retrieves a\ngreater number of articles than either PubMed or Google Scholar, with higher\nprecision in the top 20 results. We further show that integrating ChatGPT\n(GPT-4) with PubTator APIs dramatically improves the factuality and\nverifiability of its responses. In summary, PubTator 3.0 offers a comprehensive\nset of features and tools that allow researchers to navigate the ever-expanding\nwealth of biomedical literature, expediting research and unlocking valuable\ninsights for scientific discovery.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1\">Chih-Hsuan Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allot_A/0/1/0/all/0/1\">Alexis Allot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_P/0/1/0/all/0/1\">Po-Ting Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leaman_R/0/1/0/all/0/1\">Robert Leaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shubo Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Ling Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1\">Qiao Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhizheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mining experimental data from Materials Science literature with Large Language Models. (arXiv:2401.11052v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11052","description":"<p>This study is dedicated to evaluating the capabilities of advanced large\nlanguage models (LLMs) such as GPT-3.5-Turbo, GPT-4, and GPT-4-Turbo in the\nextraction of structured information from scientific documents within the field\nof materials science. We introduce a novel methodology for the comparative\nanalysis of intricate material expressions, emphasising the standardisation of\nchemical formulas to tackle the complexities inherent in materials science\ninformation assessment. To this end, we primarily focus on two critical tasks\nof information extraction: (i) a named entity recognition (NER) of studied\nmaterials and physical properties and (ii) a relation extraction (RE) between\nthese entities. The performance of LLMs in executing these tasks is benchmarked\nagainst traditional models based on the BERT architecture and rule-based\napproaches. For NER, LLMs fail to outperform the baseline with zero-shot\nprompting and exhibit only limited improvement with few-shot prompting.\nHowever, for RE, a GPT-3.5-Turbo fine-tuned with the appropriate strategy\noutperforms all models, including the baseline. Without any fine-tuning, GPT-4\nand GPT-4-Turbo display remarkable reasoning and relationship extraction\ncapabilities after being provided with merely a couple of examples, surpassing\nthe baseline. Overall, the results suggest that although LLMs demonstrate\nrelevant reasoning skills in connecting concepts, for tasks requiring\nextracting complex domain-specific entities like materials, specialised models\nare currently a better choice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Foppiano_L/0/1/0/all/0/1\">Luca Foppiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lambard_G/0/1/0/all/0/1\">Guillaume Lambard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amagasa_T/0/1/0/all/0/1\">Toshiyuki Amagasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1\">Masashi Ishii</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploiting Duality in Open Information Extraction with Predicate Prompt. (arXiv:2401.11107v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11107","description":"<p>Open information extraction (OpenIE) aims to extract the schema-free triplets\nin the form of (\\emph{subject}, \\emph{predicate}, \\emph{object}) from a given\nsentence. Compared with general information extraction (IE), OpenIE poses more\nchallenges for the IE models, {especially when multiple complicated triplets\nexist in a sentence. To extract these complicated triplets more effectively, in\nthis paper we propose a novel generative OpenIE model, namely \\emph{DualOIE},\nwhich achieves a dual task at the same time as extracting some triplets from\nthe sentence, i.e., converting the triplets into the sentence.} Such dual task\nencourages the model to correctly recognize the structure of the given sentence\nand thus is helpful to extract all potential triplets from the sentence.\nSpecifically, DualOIE extracts the triplets in two steps: 1) first extracting a\nsequence of all potential predicates, 2) then using the predicate sequence as a\nprompt to induce the generation of triplets. Our experiments on two benchmarks\nand our dataset constructed from Meituan demonstrate that DualOIE achieves the\nbest performance among the state-of-the-art baselines. Furthermore, the online\nA/B test on Meituan platform shows that 0.93\\% improvement of QV-CTR and 0.56\\%\nimprovement of UV-CTR have been obtained when the triplets extracted by DualOIE\nwere leveraged in Meituan's search system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Deqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huimin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zongyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Rui Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Y/0/1/0/all/0/1\">Yunsen Xian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines. (arXiv:2401.11120v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11120","description":"<p>Background Large Language Models (LLMs), enhanced with Clinical Practice\nGuidelines (CPGs), can significantly improve Clinical Decision Support (CDS).\nHowever, methods for incorporating CPGs into LLMs are not well studied. Methods\nWe develop three distinct methods for incorporating CPGs into LLMs: Binary\nDecision Tree (BDT), Program-Aided Graph Construction (PAGC), and\nChain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of\nthe proposed methods, we create a set of synthetic patient descriptions and\nconduct both automatic and human evaluation of the responses generated by four\nLLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was\nused as the baseline method. We focus on CDS for COVID-19 outpatient treatment\nas the case study. Results All four LLMs exhibit improved performance when\nenhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP\nand PAGC in automatic evaluation. All of the proposed methods demonstrated high\nperformance in human evaluation. Conclusion LLMs enhanced with CPGs demonstrate\nsuperior performance, as compared to plain LLMs with ZSP, in providing accurate\nrecommendations for COVID-19 outpatient treatment, which also highlights the\npotential for broader applications beyond the case study.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1\">David Oniani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xizhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Visweswaran_S/0/1/0/all/0/1\">Shyam Visweswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1\">Sumit Kapoor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kooragayalu_S/0/1/0/all/0/1\">Shravan Kooragayalu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polanska_K/0/1/0/all/0/1\">Katelyn Polanska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanshan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])","link":"http://arxiv.org/abs/2401.11143","description":"<p>We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a\nnovel probabilistic attention framework, and the Gaussian Adaptive Transformer\n(GAT), designed to enhance information aggregation across multiple modalities,\nincluding Speech, Text and Vision. GAAM integrates learnable mean and variance\ninto its attention mechanism, implemented in a Multi-Headed framework enabling\nit to collectively model any Probability Distribution for dynamic recalibration\nof feature significance. This method demonstrates significant improvements,\nespecially with highly non-stationary data, surpassing the state-of-the-art\nattention techniques in model performance (up to approximately +20% in\naccuracy) by identifying key elements within the feature space. GAAM's\ncompatibility with dot-product-based attention models and relatively low number\nof parameters showcases its adaptability and potential to boost existing\nattention frameworks. Empirically, GAAM exhibits superior adaptability and\nefficacy across a diverse range of tasks, including emotion recognition in\nspeech, image classification, and text classification, thereby establishing its\nrobustness and versatility in handling multi-modal data. Furthermore, we\nintroduce the Importance Factor (IF), a new learning-based metric that enhances\nthe explainability of models trained with GAAM-based methods. Overall, GAAM\nrepresents an advancement towards development of better performing and more\nexplainable attention models across multiple modalities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ioannides_G/0/1/0/all/0/1\">Georgios Ioannides</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elkins_A/0/1/0/all/0/1\">Aaron Elkins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How the Advent of Ubiquitous Large Language Models both Stymie and Turbocharge Dynamic Adversarial Question Generation. (arXiv:2401.11185v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11185","description":"<p>Dynamic adversarial question generation, where humans write examples to stump\na model, aims to create examples that are realistic and informative. However,\nthe advent of large language models (LLMs) has been a double-edged sword for\nhuman authors: more people are interested in seeing and pushing the limits of\nthese models, but because the models are so much stronger an opponent, they are\nharder to defeat. To understand how these models impact adversarial question\nwriting process, we enrich the writing guidance with LLMs and retrieval models\nfor the authors to reason why their questions are not adversarial. While\nauthors could create interesting, challenging adversarial questions, they\nsometimes resort to tricks that result in poor questions that are ambiguous,\nsubjective, or confusing not just to a computer but also to humans. To address\nthese issues, we propose new metrics and incentives for eliciting good,\nchallenging questions and present a new dataset of adversarially authored\nquestions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sung_Y/0/1/0/all/0/1\">Yoo Yeon Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mondal_I/0/1/0/all/0/1\">Ishani Mondal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance. (arXiv:2401.11206v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11206","description":"<p>With the rapid development of large language models (LLMs), they are not only\nused as general-purpose AI assistants but are also customized through further\nfine-tuning to meet the requirements of different applications. A pivotal\nfactor in the success of current LLMs is the alignment process. Current\nalignment methods, such as supervised fine-tuning (SFT) and reinforcement\nlearning from human feedback (RLHF), focus on training-time alignment and are\noften complex and cumbersome to implement. Therefore, we develop\n\\textbf{InferAligner}, a novel inference-time alignment method that utilizes\ncross-model guidance for harmlessness alignment. InferAligner utilizes safety\nsteering vectors extracted from safety-aligned model to modify the activations\nof the target model when responding to harmful inputs, thereby guiding the\ntarget model to provide harmless responses. Experimental results show that our\nmethod can be very effectively applied to domain-specific models in finance,\nmedicine, and mathematics, as well as to multimodal large language models\n(MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate\n(ASR) of both harmful instructions and jailbreak attacks, while maintaining\nalmost unchanged performance in downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenkun Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinghao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1\">Ke Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1\">Botian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unfair TOS: An Automated Approach using Customized BERT. (arXiv:2401.11207v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11207","description":"<p>Terms of Service (ToS) form an integral part of any agreement as it defines\nthe legal relationship between a service provider and an end-user. Not only do\nthey establish and delineate reciprocal rights and responsibilities, but they\nalso provide users with information on essential aspects of contracts that\npertain to the use of digital spaces. These aspects include a wide range of\ntopics, including limitation of liability, data protection, etc. Users tend to\naccept the ToS without going through it before using any application or\nservice. Such ignorance puts them in a potentially weaker situation in case any\naction is required. Existing methodologies for the detection or classification\nof unfair clauses are however obsolete and show modest performance. In this\nresearch paper, we present SOTA(State of The Art) results on unfair clause\ndetection from ToS documents based on unprecedented Fine-tuning BERT in\nintegration with SVC(Support Vector Classifier). The study shows proficient\nperformance with a macro F1-score of 0.922 at unfair clause detection, and\nsuperior performance is also shown in the classification of unfair clauses by\neach tag. Further, a comparative analysis is performed by answering research\nquestions on the Transformer models utilized. In order to further research and\nexperimentation the code and results are made available on\nhttps://github.com/batking24/Unfair-TOS-An-Automated-Approach-based-on-Fine-tuning-BERT-in-conjunction-with-ML.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akash_B/0/1/0/all/0/1\">Bathini Sai Akash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kupireddy_A/0/1/0/all/0/1\">Akshara Kupireddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murthy_L/0/1/0/all/0/1\">Lalita Bhanu Murthy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Argument Mining over Varying Rhetorical Structures. (arXiv:2401.11218v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11218","description":"<p>Rhetorical Structure Theory implies no single discourse interpretation of a\ntext, and the limitations of RST parsers further exacerbate inconsistent\nparsing of similar structures. Therefore, it is important to take into account\nthat the same argumentative structure can be found in semantically similar\ntexts with varying rhetorical structures. In this work, the differences between\nparaphrases within the same argument scheme are evaluated from a rhetorical\nperspective. The study proposes a deep dependency parsing model to assess the\nconnection between rhetorical and argument structures. The model utilizes\nrhetorical relations; RST structures of paraphrases serve as training data\naugmentations. The method allows for end-to-end argumentation analysis using a\nrhetorical tree instead of a word sequence. It is evaluated on the bilingual\nMicrotexts corpus, and the first results on fully-fledged argument parsing for\nthe Russian version of the corpus are reported. The results suggest that\nargument mining can benefit from multiple variants of discourse structure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chistova_E/0/1/0/all/0/1\">Elena Chistova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt-RAG: Pioneering Vector Embedding-Free Retrieval-Augmented Generation in Niche Domains, Exemplified by Korean Medicine. (arXiv:2401.11246v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11246","description":"<p>We propose a natural language prompt-based retrieval augmented generation\n(Prompt-RAG), a novel approach to enhance the performance of generative large\nlanguage models (LLMs) in niche domains. Conventional RAG methods mostly\nrequire vector embeddings, yet the suitability of generic LLM-based embedding\nrepresentations for specialized domains remains uncertain. To explore and\nexemplify this point, we compared vector embeddings from Korean Medicine (KM)\nand Conventional Medicine (CM) documents, finding that KM document embeddings\ncorrelated more with token overlaps and less with human-assessed document\nrelatedness, in contrast to CM embeddings. Prompt-RAG, distinct from\nconventional RAG models, operates without the need for embedding vectors. Its\nperformance was assessed through a Question-Answering (QA) chatbot application,\nwhere responses were evaluated for relevance, readability, and informativeness.\nThe results showed that Prompt-RAG outperformed existing models, including\nChatGPT and conventional vector embedding-based RAGs, in terms of relevance and\ninformativeness. Despite challenges like content structuring and response\nlatency, the advancements in LLMs are expected to encourage the use of\nPrompt-RAG, making it a promising tool for other domains in need of RAG\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_B/0/1/0/all/0/1\">Bongsu Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jundong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_T/0/1/0/all/0/1\">Tae-Rim Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1\">Chang-Eop Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Drop your Decoder: Pre-training with Bag-of-Word Prediction for Dense Passage Retrieval. (arXiv:2401.11248v1 [cs.IR])","link":"http://arxiv.org/abs/2401.11248","description":"<p>Masked auto-encoder pre-training has emerged as a prevalent technique for\ninitializing and enhancing dense retrieval systems. It generally utilizes\nadditional Transformer decoder blocks to provide sustainable supervision\nsignals and compress contextual information into dense representations.\nHowever, the underlying reasons for the effectiveness of such a pre-training\ntechnique remain unclear. The usage of additional Transformer-based decoders\nalso incurs significant computational costs. In this study, we aim to shed\nlight on this issue by revealing that masked auto-encoder (MAE) pre-training\nwith enhanced decoding significantly improves the term coverage of input tokens\nin dense representations, compared to vanilla BERT checkpoints. Building upon\nthis observation, we propose a modification to the traditional MAE by replacing\nthe decoder of a masked auto-encoder with a completely simplified Bag-of-Word\nprediction task. This modification enables the efficient compression of lexical\nsignals into dense representations through unsupervised pre-training.\nRemarkably, our proposed method achieves state-of-the-art retrieval performance\non several large-scale retrieval benchmarks without requiring any additional\nparameters, which provides a 67% training speed-up compared to standard masked\nauto-encoder pre-training with enhanced decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_G/0/1/0/all/0/1\">Guangyuan Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xing Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zijia Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1\">Songlin Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing through Analyzing Attentions of a Reference-Free Metric. (arXiv:2401.11268v1 [cs.CL])","link":"http://arxiv.org/abs/2401.11268","description":"<p>In the realm of automatic speech recognition (ASR), the quest for models that\nnot only perform with high accuracy but also offer transparency in their\ndecision-making processes is crucial. The potential of quality estimation (QE)\nmetrics is introduced and evaluated as a novel tool to enhance explainable\nartificial intelligence (XAI) in ASR systems. Through experiments and analyses,\nthe capabilities of the NoRefER (No Reference Error Rate) metric are explored\nin identifying word-level errors to aid post-editors in refining ASR\nhypotheses. The investigation also extends to the utility of NoRefER in the\ncorpus-building process, demonstrating its effectiveness in augmenting datasets\nwith insightful annotations. The diagnostic aspects of NoRefER are examined,\nrevealing its ability to provide valuable insights into model behaviors and\ndecision patterns. This has proven beneficial for prioritizing hypotheses in\npost-editing workflows and fine-tuning ASR models. The findings suggest that\nNoRefER is not merely a tool for error detection but also a comprehensive\nframework for enhancing ASR systems' transparency, efficiency, and\neffectiveness. To ensure the reproducibility of the results, all source codes\nof this study are made publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Javadi_G/0/1/0/all/0/1\">Golara Javadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuksel_K/0/1/0/all/0/1\">Kamer Ali Yuksel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Yunsu Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_T/0/1/0/all/0/1\">Thiago Castro Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Badrashiny_M/0/1/0/all/0/1\">Mohamed Al-Badrashiny</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Empirical Study of Named Entity Recognition Performance Using Distribution-aware Word Embedding. (arXiv:2109.01636v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.01636","description":"<p>With the fast development of Deep Learning techniques, Named Entity\nRecognition (NER) is becoming more and more important in the information\nextraction task. The greatest difficulty that the NER task faces is to keep the\ndetectability even when types of NE and documents are unfamiliar. Realizing\nthat the specificity information may contain potential meanings of a word and\ngenerate semantic-related features for word embedding, we develop a\ndistribution-aware word embedding and implement three different methods to make\nuse of the distribution information in a NER framework. And the result shows\nthat the performance of NER will be improved if the word specificity is\nincorporated into existing NER methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1\">Qi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xinyang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks. (arXiv:2203.14647v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.14647","description":"<p>The lack of annotated data on professional argumentation and complete\nargumentative debates has led to the oversimplification and the inability of\napproaching more complex natural language processing tasks. Such is the case of\nthe automatic debate evaluation. In this paper, we propose an original hybrid\nmethod to automatically evaluate argumentative debates. For that purpose, we\ncombine concepts from argumentation theory such as argumentation frameworks and\nsemantics, with Transformer-based architectures and neural graph networks.\nFurthermore, we obtain promising results that lay the basis on an unexplored\nnew instance of the automatic analysis of natural language arguments.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Dolz_R/0/1/0/all/0/1\">Ramon Ruiz-Dolz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heras_S/0/1/0/all/0/1\">Stella Heras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Fornes_A/0/1/0/all/0/1\">Ana Garc&#xed;a-Fornes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Twitter Data to Understand Public Perceptions of Approved versus Off-label Use for COVID-19-related Medications. (arXiv:2206.14358v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2206.14358","description":"<p>Understanding public discourse on emergency use of unproven therapeutics is\ncrucial for monitoring safe use and combating misinformation. We developed a\nnatural language processing-based pipeline to comprehend public perceptions of\nand stances on coronavirus disease 2019 (COVID-19)-related drugs on Twitter\nover time. This retrospective study included 609,189 US-based tweets from\nJanuary 29, 2020, to November 30, 2021, about four drugs that garnered\nsignificant public attention during the COVID-19 pandemic: (1)\nHydroxychloroquine and Ivermectin, therapies with anecdotal evidence; and (2)\nMolnupiravir and Remdesivir, FDA-approved treatments for eligible patients.\nTime-trend analysis was employed to understand popularity trends and related\nevents. Content and demographic analyses were conducted to explore potential\nrationales behind people's stances on each drug. Time-trend analysis indicated\nthat Hydroxychloroquine and Ivermectin were discussed more than Molnupiravir\nand Remdesivir, particularly during COVID-19 surges. Hydroxychloroquine and\nIvermectin discussions were highly politicized, related to conspiracy theories,\nhearsay, and celebrity influences. The distribution of stances between the two\nmajor US political parties was significantly different (P &lt; .001); Republicans\nwere more likely to support Hydroxychloroquine (55%) and Ivermectin (30%) than\nDemocrats. People with healthcare backgrounds tended to oppose\nHydroxychloroquine (7%) more than the general population, while the general\npopulation was more likely to support Ivermectin (14%). Our study found that\nsocial media users have varying perceptions and stances on off-label versus\nFDA-authorized drug use at different stages of COVID-19. This indicates that\nhealth systems, regulatory agencies, and policymakers should design tailored\nstrategies to monitor and reduce misinformation to promote safe drug use.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yining Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Hang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shixu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plasek_J/0/1/0/all/0/1\">Joseph M. Plasek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bates_D/0/1/0/all/0/1\">David W. Bates</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Li Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations. (arXiv:2302.06419v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2302.06419","description":"<p>Self-supervision has shown great potential for audio-visual speech\nrecognition by vastly reducing the amount of labeled data required to build\ngood systems. However, existing methods are either not entirely end-to-end or\ndo not train joint representations of both modalities. In this paper, we\nintroduce AV-data2vec which addresses these challenges and builds audio-visual\nrepresentations based on predicting contextualized representations which has\nbeen successful in the uni-modal case. The model uses a shared transformer\nencoder for both audio and video and can combine both modalities to improve\nspeech recognition. Results on LRS3 show that AV-data2vec consistently\noutperforms existing methods under all settings with the same amount of data\nand model size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Lian_J/0/1/0/all/0/1\">Jiachen Lian</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Baevski_A/0/1/0/all/0/1\">Alexei Baevski</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ning Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Auli_M/0/1/0/all/0/1\">Michael Auli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"For Generated Text, Is NLI-Neutral Text the Best Text?. (arXiv:2302.08577v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.08577","description":"<p>We explore incorporating natural language inference (NLI) into the text\ngenerative pipeline by using a pre-trained NLI model to assess whether a\ngenerated sentence entails, contradicts, or is neutral to the prompt and\npreceding text. First, we show that the NLI task is predictive of generation\nerrors made by GPT-3. We use these results to develop an NLI-informed\ngeneration procedure for GPT-J. Then, we evaluate these generations by\nobtaining human annotations on error types and overall quality. We find that an\nNLI strategy of maximizing entailment improves text generation when the nucleus\nsampling randomness parameter value is high, while one which maximizes\ncontradiction is in fact productive when the parameter value is low. Overall,\nthough, we demonstrate that an NLI strategy of maximizing the neutral class\nprovides the highest quality of generated text (significantly better than the\nvanilla generations), regardless of parameter value.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mersinias_M/0/1/0/all/0/1\">Michail Mersinias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining. (arXiv:2302.12584v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.12584","description":"<p>In this paper, we describe VivesDebate-Speech, a corpus of spoken\nargumentation created to leverage audio features for argument mining tasks. The\ncreation of this corpus represents an important contribution to the\nintersection of speech processing and argument mining communities, and one of\nthe most complete publicly available resources in this topic. Moreover, we have\nperformed a set of first-of-their-kind experiments which show an improvement\nwhen integrating audio features into the argument mining pipeline. The provided\nresults can be used as a baseline for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruiz_Dolz_R/0/1/0/all/0/1\">Ramon Ruiz-Dolz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iranzo_Sanchez_J/0/1/0/all/0/1\">Javier Iranzo-S&#xe1;nchez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ETPNav: Evolving Topological Planning for Vision-Language Navigation in Continuous Environments. (arXiv:2304.03047v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.03047","description":"<p>Vision-language navigation is a task that requires an agent to follow\ninstructions to navigate in environments. It becomes increasingly crucial in\nthe field of embodied AI, with potential applications in autonomous navigation,\nsearch and rescue, and human-robot interaction. In this paper, we propose to\naddress a more practical yet challenging counterpart setting - vision-language\nnavigation in continuous environments (VLN-CE). To develop a robust VLN-CE\nagent, we propose a new navigation framework, ETPNav, which focuses on two\ncritical skills: 1) the capability to abstract environments and generate\nlong-range navigation plans, and 2) the ability of obstacle-avoiding control in\ncontinuous environments. ETPNav performs online topological mapping of\nenvironments by self-organizing predicted waypoints along a traversed path,\nwithout prior environmental experience. It privileges the agent to break down\nthe navigation procedure into high-level planning and low-level control.\nConcurrently, ETPNav utilizes a transformer-based cross-modal planner to\ngenerate navigation plans based on topological maps and instructions. The plan\nis then performed through an obstacle-avoiding controller that leverages a\ntrial-and-error heuristic to prevent navigation from getting stuck in\nobstacles. Experimental results demonstrate the effectiveness of the proposed\nmethod. ETPNav yields more than 10% and 20% improvements over prior\nstate-of-the-art on R2R-CE and RxR-CE datasets, respectively. Our code is\navailable at https://github.com/MarSaKi/ETPNav.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_D/0/1/0/all/0/1\">Dong An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenguan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Keji He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Liang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ICE-Score: Instructing Large Language Models to Evaluate Code. (arXiv:2304.14317v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2304.14317","description":"<p>Recent advancements in the field of natural language generation have\nfacilitated the use of large language models to assess the quality of generated\ntext. Although these models have shown promising results in tasks such as\nmachine translation and summarization, their applicability in code intelligence\ntasks remains limited without human involvement. The complexity of programming\nconcepts required for such tasks makes it difficult to develop evaluation\nmetrics that align with human judgment. Token-matching-based metrics, such as\nBLEU, have demonstrated weak correlations with human practitioners in code\nintelligence tasks. Moreover, utilizing human-written test suites to evaluate\nfunctional correctness can be challenging in domains with low resources. To\novercome these obstacles, we propose \\texttt{ICE-Score}, a new evaluation\nmetric via instructing large language models (LLMs) for code assessments. Our\nmetric addresses the limitations of existing approaches by achieving superior\ncorrelations with functional correctness and human preferences, without the\nneed for test oracles or references. We evaluate the efficacy of our metric on\ntwo different aspects (\\textit{human preference} and \\textit{execution\nsuccess}) and four programming languages. Our results demonstrate that our\nmetric surpasses state-of-the-art metrics for code generation, delivering high\nlevels of accuracy and consistency across various programming languages and\ntasks. We also make our evaluation metric and datasets available to the\npublic\\footnote{\\url{https://github.com/terryyz/ice-score}}, encouraging\nfurther research in evaluating code intelligence tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuo_T/0/1/0/all/0/1\">Terry Yue Zhuo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Taxonomy of Foundation Model based Systems through the Lens of Software Architecture. (arXiv:2305.05352v6 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2305.05352","description":"<p>The recent release of large language model (LLM) based chatbots, such as\nChatGPT, has attracted huge interest in foundation models. It is widely\nbelieved that foundation models will serve as the fundamental building blocks\nfor future AI systems. As foundation models are in their early stages, the\ndesign of foundation model based systems has not yet been systematically\nexplored. There is limited understanding about the impact of introducing\nfoundation models in software architecture. Therefore, in this paper, we\npropose a taxonomy of foundation model based systems, which classifies and\ncompares the characteristics of foundation models and design options of\nfoundation model based systems. Our taxonomy comprises three categories: the\npretraining and adaptation of foundation models, the architecture design of\nfoundation model based systems, and responsible-AI-by-design. This taxonomy can\nserve as concrete guidance for making major architectural design decisions when\ndesigning foundation model based systems and highlights trade-offs arising from\ndesign decisions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qinghua Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Liming Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xiwei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yue Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1\">Zhenchang Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Whittle_J/0/1/0/all/0/1\">Jon Whittle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation. (arXiv:2305.14189v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14189","description":"<p>Using a vocabulary that is shared across languages is common practice in\nMultilingual Neural Machine Translation (MNMT). In addition to its simple\ndesign, shared tokens play an important role in positive knowledge transfer,\nassuming that shared tokens refer to similar meanings across languages.\nHowever, when word overlap is small, especially due to different writing\nsystems, transfer is inhibited. In this paper, we define word-level information\ntransfer pathways via word equivalence classes and rely on graph networks to\nfuse word embeddings across languages. Our experiments demonstrate the\nadvantages of our approach: 1) embeddings of words with similar meanings are\nbetter aligned across languages, 2) our method achieves consistent BLEU\nimprovements of up to 2.3 points for high- and low-resource MNMT, and 3) less\nthan 1.0\\% additional trainable parameters are required with a limited increase\nin computational costs, while inference time remains identical to the baseline.\nWe release the codebase to the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Connecting the Dots: What Graph-Based Text Representations Work Best for Text Classification Using Graph Neural Networks?. (arXiv:2305.14578v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14578","description":"<p>Given the success of Graph Neural Networks (GNNs) for structure-aware machine\nlearning, many studies have explored their use for text classification, but\nmostly in specific domains with limited data characteristics. Moreover, some\nstrategies prior to GNNs relied on graph mining and classical machine learning,\nmaking it difficult to assess their effectiveness in modern settings. This work\nextensively investigates graph representation methods for text classification,\nidentifying practical implications and open challenges. We compare different\ngraph construction schemes using a variety of GNN architectures and setups\nacross five datasets, encompassing short and long documents as well as\nunbalanced scenarios in diverse domains. Two Transformer-based large language\nmodels are also included to complement the study. The results show that i)\nalthough the effectiveness of graphs depends on the textual input features and\ndomain, simple graph constructions perform better the longer the documents are,\nii) graph representations are especially beneficial for longer documents,\noutperforming Transformer-based models, iii) graph methods are particularly\nefficient at solving the task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bugueno_M/0/1/0/all/0/1\">Margarita Bugue&#xf1;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_G/0/1/0/all/0/1\">Gerard de Melo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16326","description":"<p>Biomedical literature is growing rapidly, making it challenging to curate and\nextract knowledge manually. Biomedical natural language processing (BioNLP)\ntechniques that can automatically extract information from biomedical\nliterature help alleviate this burden. Recently, large Language Models (LLMs),\nsuch as GPT-3 and GPT-4, have gained significant attention for their impressive\nperformance. However, their effectiveness in BioNLP tasks and impact on method\ndevelopment and downstream users remain understudied. This pilot study (1)\nestablishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and\none-shot settings in eight BioNLP datasets across four applications: named\nentity recognition, relation extraction, multi-label document classification,\nand semantic similarity and reasoning, (2) examines the errors produced by the\nLLMs and categorized the errors into three types: missingness, inconsistencies,\nand unwanted artificial content, and (3) provides suggestions for using LLMs in\nBioNLP applications. We make the datasets, baselines, and results publicly\navailable to the community via\nhttps://github.com/qingyu-qc/gpt_bionlp_benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1\">Jingcheng Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keloth_V/0/1/0/all/0/1\">Vipina Kuttichi Keloth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xueqing Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raja_K/0/1/0/all/0/1\">Kalpana Raja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1\">Zhiyong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hua Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero and Few-shot Semantic Parsing with Ambiguous Inputs. (arXiv:2306.00824v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00824","description":"<p>Despite the frequent challenges posed by ambiguity when representing meaning\nvia natural language, it is often ignored or deliberately removed in tasks\nmapping language to formally-designed representations, which generally assume a\none-to-one mapping between linguistic and formal representations. We attempt to\naddress this shortcoming by introducing AmP, a framework, dataset, and\nchallenge for translating ambiguous natural language to formal representations\nlike logic and code. We define templates and generate data for five\nwell-documented linguistic ambiguities. Using AmP, we investigate how several\nfew-shot text-to-code systems handle ambiguity, introducing three new metrics.\nWe find that large pre-trained models perform poorly at capturing the\ndistribution of possible meanings without deliberate instruction. However,\nmodels are able to capture the distribution well when ambiguity is attested in\ntheir inputs. These results motivate a call for including ambiguity explicitly\nin datasets and promote considering the distribution of possible outputs when\nevaluating systems. Data and code: https://github.com/esteng/ambiguous_parsing\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stengel_Eskin_E/0/1/0/all/0/1\">Elias Stengel-Eskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawlins_K/0/1/0/all/0/1\">Kyle Rawlins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Streamlining Social Media Information Extraction for Public Health Research with Deep Learning. (arXiv:2306.16001v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.16001","description":"<p>Objective: Social media-based public health research is crucial for epidemic\nsurveillance, but most studies identify relevant corpora with keyword matching.\nThis study develops a system to streamline the process of curating colloquial\nmedical dictionaries. We demonstrate the pipeline by curating a UMLS-colloquial\nsymptom dictionary from COVID-19-related tweets as proof of concept. Methods:\nCOVID-19-related tweets from February 1, 2020, to April 30, 2022 were used. The\npipeline includes three modules: a named entity recognition module to detect\nsymptoms in tweets; an entity normalization module to aggregate detected\nentities; and a mapping module that iteratively maps entities to Unified\nMedical Language System concepts. A random 500 entity sample were drawn from\nthe final dictionary for accuracy validation. Additionally, we conducted a\nsymptom frequency distribution analysis to compare our dictionary to a\npre-defined lexicon from previous research. Results: We identified 498,480\nunique symptom entity expressions from the tweets. Pre-processing reduces the\nnumber to 18,226. The final dictionary contains 38,175 unique expressions of\nsymptoms that can be mapped to 966 UMLS concepts (accuracy = 95%). Symptom\ndistribution analysis found that our dictionary detects more symptoms and is\neffective at identifying psychiatric disorders like anxiety and depression,\noften missed by pre-defined lexicons. Conclusion: This study advances public\nhealth research by implementing a novel, systematic pipeline for curating\nsymptom lexicons from social media data. The final lexicon's high accuracy,\nvalidated by medical professionals, underscores the potential of this\nmethodology to reliably interpret and categorize vast amounts of unstructured\nsocial media data into actionable medical insights across diverse linguistic\nand regional landscapes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yining Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1\">Shixu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yujie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foer_D/0/1/0/all/0/1\">Dinah Foer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siwen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peilin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Li Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TIM: Teaching Large Language Models to Translate with Comparison. (arXiv:2307.04408v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04408","description":"<p>Open-sourced large language models (LLMs) have demonstrated remarkable\nefficacy in various tasks with instruction tuning. However, these models can\nsometimes struggle with tasks that require more specialized knowledge such as\ntranslation. One possible reason for such deficiency is that instruction tuning\naims to generate fluent and coherent text that continues from a given\ninstruction without being constrained by any task-specific requirements.\nMoreover, it can be more challenging for tuning smaller LLMs with lower-quality\ntraining data. To address this issue, we propose a novel framework using\nexamples in comparison to teach LLMs to learn translation. Our approach\ninvolves presenting the model with examples of correct and incorrect\ntranslations and using a preference loss to guide the model's learning. We\nevaluate our method on WMT2022 test sets and show that it outperforms existing\nmethods. Our findings offer a new perspective on fine-tuning LLMs for\ntranslation tasks and provide a promising solution for generating high-quality\ntranslations. Please refer to Github for more details:\nhttps://github.com/lemon0830/TIM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1\">Jiali Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yongjing Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.01538","description":"<p>Logical rules are essential for uncovering the logical connections between\nrelations, which could improve reasoning performance and provide interpretable\nresults on knowledge graphs (KGs). Although there have been many efforts to\nmine meaningful logical rules over KGs, existing methods suffer from\ncomputationally intensive searches over the rule space and a lack of\nscalability for large-scale KGs. Besides, they often ignore the semantics of\nrelations which is crucial for uncovering logical connections. Recently, large\nlanguage models (LLMs) have shown impressive performance in the field of\nnatural language processing and various applications, owing to their emergent\nability and generalizability. In this paper, we propose a novel framework,\nChatRule, unleashing the power of large language models for mining logical\nrules over knowledge graphs. Specifically, the framework is initiated with an\nLLM-based rule generator, leveraging both the semantic and structural\ninformation of KGs to prompt LLMs to generate logical rules. To refine the\ngenerated rules, a rule ranking module estimates the rule quality by\nincorporating facts from existing KGs. Last, the ranked rules can be used to\nconduct reasoning over KGs. ChatRule is evaluated on four large-scale KGs,\nw.r.t. different rule quality metrics and downstream tasks, showing the\neffectiveness and scalability of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Linhao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_J/0/1/0/all/0/1\">Jiaxin Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1\">Bo Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuan-Fang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05173","description":"<p>Prompt tuning (PT), where a small amount of trainable soft (continuous)\nprompt vectors is affixed to the input of language models (LM), has shown\npromising results across various tasks and models for parameter-efficient\nfine-tuning (PEFT). PT stands out from other PEFT approaches because it\nmaintains competitive performance with fewer trainable parameters and does not\ndrastically scale up its parameters as the model size expands. However, PT\nintroduces additional soft prompt tokens, leading to longer input sequences,\nwhich significantly impacts training and inference time and memory usage due to\nthe Transformer's quadratic complexity. Particularly concerning for Large\nLanguage Models (LLMs) that face heavy daily querying. To address this issue,\nwe propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt\ninto a shorter soft prompt and a pair of low-rank matrices that are then\noptimised with two different learning rates. This allows DePT to achieve better\nperformance while saving substantial memory and time costs compared to vanilla\nPT and its variants, without changing trainable parameter sizes. Through\nextensive experiments on 23 natural language processing (NLP) and\nvision-language (VL) tasks, we demonstrate that DePT outperforms\nstate-of-the-art PEFT approaches, including the full fine-tuning baseline, in\nsome scenarios. Additionally, we empirically show that DEPT grows more\nefficient as the model size increases. Our further study reveals that DePT\nintegrates seamlessly with parameter-efficient transfer learning in the\nfew-shot learning setting and highlights its adaptability to various model\narchitectures and sizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v2 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2309.12244","description":"<p>Children typically learn to identify and express emotions through sharing\ntheir stories and feelings with others, particularly their family. However, it\nis challenging for parents or siblings to have emotional communication with\nchildren since children are still developing their communication skills. We\npresent ChaCha, a chatbot that encourages and guides children to share personal\nevents and associated emotions. ChaCha combines a state machine and large\nlanguage models (LLMs) to keep the dialogue on track while carrying on\nfree-form conversations. Through an exploratory study with 20 children (aged\n8-12), we examine how ChaCha prompts children to share personal events and\nguides them to describe associated emotions. Participants perceived ChaCha as a\nclose friend and shared their stories on various topics, such as family trips\nand personal achievements. Based on the findings, we discuss opportunities for\nleveraging LLMs to design child-friendly chatbots to support children in\nsharing emotions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seo_W/0/1/0/all/0/1\">Woosuk Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chanmo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1\">Young-Ho Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. (arXiv:2309.12247v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12247","description":"<p>Detecting fake news requires both a delicate sense of diverse clues and a\nprofound understanding of the real-world background, which remains challenging\nfor detectors based on small language models (SLMs) due to their knowledge and\ncapability limitations. Recent advances in large language models (LLMs) have\nshown remarkable performance in various tasks, but whether and how LLMs could\nhelp with fake news detection remains underexplored. In this paper, we\ninvestigate the potential of LLMs in fake news detection. First, we conduct an\nempirical study and find that a sophisticated LLM such as GPT 3.5 could\ngenerally expose fake news and provide desirable multi-perspective rationales\nbut still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis\nattributes such a gap to the LLM's inability to select and integrate rationales\nproperly to conclude. Based on these findings, we propose that current LLMs may\nnot substitute fine-tuned SLMs in fake news detection but can be a good advisor\nfor SLMs by providing multi-perspective instructive rationales. To instantiate\nthis proposal, we design an adaptive rationale guidance network for fake news\ndetection (ARG), in which SLMs selectively acquire insights on news analysis\nfrom the LLMs' rationales. We further derive a rationale-free version of ARG by\ndistillation, namely ARG-D, which services cost-sensitive scenarios without\nquerying LLMs. Experiments on two real-world datasets demonstrate that ARG and\nARG-D outperform three types of baseline methods, including SLM-based,\nLLM-based, and combinations of small and large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Beizhe Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Qiang Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1\">Juan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1\">Yuhui Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Danding Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_P/0/1/0/all/0/1\">Peng Qi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GenSim: Generating Robotic Simulation Tasks via Large Language Models. (arXiv:2310.01361v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.01361","description":"<p>Collecting large amounts of real-world interaction data to train general\nrobotic policies is often prohibitively expensive, thus motivating the use of\nsimulation data. However, existing methods for data generation have generally\nfocused on scene-level diversity (e.g., object instances and poses) rather than\ntask-level diversity, due to the human effort required to come up with and\nverify novel tasks. This has made it challenging for policies trained on\nsimulation data to demonstrate significant task-level generalization. In this\npaper, we propose to automatically generate rich simulation environments and\nexpert demonstrations by exploiting a large language models' (LLM) grounding\nand coding ability. Our approach, dubbed GenSim, has two modes: goal-directed\ngeneration, wherein a target task is given to the LLM and the LLM proposes a\ntask curriculum to solve the target task, and exploratory generation, wherein\nthe LLM bootstraps from previous tasks and iteratively proposes novel tasks\nthat would be helpful in solving more complex tasks. We use GPT4 to expand the\nexisting benchmark by ten times to over 100 tasks, on which we conduct\nsupervised finetuning and evaluate several LLMs including finetuned GPTs and\nCode Llama on code generation for robotic simulation tasks. Furthermore, we\nobserve that LLMs-generated simulation programs can enhance task-level\ngeneralization significantly when used for multitask policy training. We\nfurther find that with minimal sim-to-real adaptation, the multitask policies\npretrained on GPT4-generated simulation tasks exhibit stronger transfer to\nunseen long-horizon tasks in the real world and outperform baselines by 25%.\nSee the project website (https://liruiw.github.io/gensim) for code, demos, and\nvideos.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lirui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Y/0/1/0/all/0/1\">Yiyang Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zhecheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shridhar_M/0/1/0/all/0/1\">Mohit Shridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_C/0/1/0/all/0/1\">Chen Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yuzhe Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bailin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Huazhe Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench. (arXiv:2310.01386v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01386","description":"<p>Large Language Models (LLMs) have recently showcased their remarkable\ncapacities, not only in natural language processing tasks but also across\ndiverse domains such as clinical medicine, legal consultation, and education.\nLLMs become more than mere applications, evolving into assistants capable of\naddressing diverse user requests. This narrows the distinction between human\nbeings and artificial intelligence agents, raising intriguing questions\nregarding the potential manifestation of personalities, temperaments, and\nemotions within LLMs. In this paper, we propose a framework, PsychoBench, for\nevaluating diverse psychological aspects of LLMs. Comprising thirteen scales\ncommonly used in clinical psychology, PsychoBench further classifies these\nscales into four distinct categories: personality traits, interpersonal\nrelationships, motivational tests, and emotional abilities. Our study examines\nfive popular models, namely text-davinci-003, gpt-3.5-turbo, gpt-4, LLaMA-2-7b,\nand LLaMA-2-13b. Additionally, we employ a jailbreak approach to bypass the\nsafety alignment protocols and test the intrinsic natures of LLMs. We have made\nPsychoBench openly accessible via https://github.com/CUHK-ARISE/PsychoBench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jen-tse Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wenxuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1\">Eric John Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_M/0/1/0/all/0/1\">Man Ho Lam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shujie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1\">Youliang Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1\">Michael R. Lyu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus. (arXiv:2310.02118v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02118","description":"<p>In this report, we describe the vision, challenges, and scientific\ncontributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBot\nChallenge 2022. Our vision, is to build TWIZ bot as an helpful, multimodal,\nknowledgeable, and engaging assistant that can guide users towards the\nsuccessful completion of complex manual tasks. To achieve this, we focus our\nefforts on three main research questions: (1) Humanly-Shaped Conversations, by\nproviding information in a knowledgeable way; (2) Multimodal Stimulus, making\nuse of various modalities including voice, images, and videos; and (3)\nZero-shot Conversational Flows, to improve the robustness of the interaction to\nunseen scenarios. TWIZ is an assistant capable of supporting a wide range of\ntasks, with several innovative features such as creative cooking, video\nnavigation through voice, and the robust TWIZ-LLM, a Large Language Model\ntrained for dialoguing about complex manual tasks. Given ratings and feedback\nprovided by users, we observed that TWIZ bot is an effective and robust system,\ncapable of guiding users through tasks while providing several multimodal\nstimuli.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_R/0/1/0/all/0/1\">Rafael Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tavares_D/0/1/0/all/0/1\">Diogo Tavares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1\">Diogo Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Valerio_R/0/1/0/all/0/1\">Rodrigo Val&#xe9;rio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bordalo_J/0/1/0/all/0/1\">Jo&#xe3;o Bordalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simoes_I/0/1/0/all/0/1\">In&#xea;s Sim&#xf5;es</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_V/0/1/0/all/0/1\">Vasco Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Semedo_D/0/1/0/all/0/1\">David Semedo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Magalhaes_J/0/1/0/all/0/1\">Jo&#xe3;o Magalh&#xe3;es</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts. (arXiv:2310.02255v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.02255","description":"<p>Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit\nimpressive problem-solving skills in many tasks and domains, but their ability\nin mathematical reasoning in visual contexts has not been systematically\nstudied. To bridge this gap, we present MathVista, a benchmark designed to\ncombine challenges from diverse mathematical and visual tasks. It consists of\n6,141 examples, derived from 28 existing multimodal datasets involving\nmathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and\nPaperQA). Completing these tasks requires fine-grained, deep visual\nunderstanding and compositional reasoning, which all state-of-the-art\nfoundation models find challenging. With MathVista, we have conducted a\ncomprehensive, quantitative evaluation of 12 prominent foundation models. The\nbest-performing GPT-4V model achieves an overall accuracy of 49.9%,\nsubstantially outperforming Bard, the second-best performer, by 15.1%. Our\nin-depth analysis reveals that the superiority of GPT-4V is mainly attributed\nto its enhanced visual perception and mathematical reasoning. However, GPT-4V\nstill falls short of human performance by 10.4%, as it often struggles to\nunderstand complex figures and perform rigorous reasoning. This significant gap\nunderscores the critical role that MathVista will play in the development of\ngeneral-purpose AI agents capable of tackling mathematically intensive and\nvisually rich real-world tasks. We further explore the new ability of\nself-verification, the application of self-consistency, and the interactive\nchatbot capabilities of GPT-4V, highlighting its promising potential for future\nresearch. The project is available at https://mathvista.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1\">Pan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_H/0/1/0/all/0/1\">Hritik Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_T/0/1/0/all/0/1\">Tony Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiacheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EMO: Earth Mover Distance Optimization for Auto-Regressive Language Modeling. (arXiv:2310.04691v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04691","description":"<p>Neural language models are probabilistic models of human text. They are\npredominantly trained using maximum likelihood estimation (MLE), which is\nequivalent to minimizing the forward cross-entropy between the empirical data\ndistribution and the model distribution. However, various degeneration\nphenomena are still widely observed when decoding from the distributions\nlearned by such models. We establish that the forward cross-entropy is\nsuboptimal as a distance metric for aligning human and model distribution due\nto its (1) recall-prioritization (2) negative diversity ignorance and (3)\ntrain-test mismatch. In this paper, we propose Earth Mover Distance\nOptimization (EMO) for auto-regressive language modeling. EMO capitalizes on\nthe inherent properties of earth mover distance to address the aforementioned\nchallenges. Due to the high complexity of direct computation, we further\nintroduce a feasible upper bound for EMO to ease end-to-end training. Upon\nextensive evaluation of language models trained using EMO and MLE. We find that\nEMO demonstrates a consistently better language modeling performance than MLE\nacross domains. Moreover, EMO demonstrates noteworthy enhancements in\ndownstream performance with minimal fine-tuning on merely 25,000 sentences.\nThis highlights the tremendous potential of EMO as a lightweight calibration\nmethod for enhancing large-scale pre-trained language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Siyu Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhiyong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kenny Q. Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IDEAL: Influence-Driven Selective Annotations Empower In-Context Learners in Large Language Models. (arXiv:2310.10873v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10873","description":"<p>In-context learning is a promising paradigm that utilizes in-context examples\nas prompts for the predictions of large language models. These prompts are\ncrucial for achieving strong performance. However, since the prompts need to be\nsampled from a large volume of annotated examples, finding the right prompt may\nresult in high annotation costs. To address this challenge, this paper\nintroduces an influence-driven selective annotation method that aims to\nminimize annotation costs while improving the quality of in-context examples.\nThe essence of our method is to select a pivotal subset from a large-scale\nunlabeled data pool to annotate for the subsequent sampling of prompts.\nSpecifically, a directed graph is first constructed to represent unlabeled\ndata. Afterward, the influence of candidate unlabeled subsets is quantified\nwith a diffusion process. A simple yet effective greedy algorithm for unlabeled\ndata selection is lastly introduced. It iteratively selects the data if it\nprovides a maximum marginal gain with respect to quantified influence. Compared\nwith previous efforts on selective annotations, our influence-driven method\nworks in an end-to-end manner, avoids an intractable explicit balance between\ndata diversity and representativeness, and enjoys theoretical support.\nExperiments confirm the superiority of the proposed method on various\nbenchmarks, achieving better performance under lower time consumption during\nsubset selection. The project page is available at\nhttps://skzhang1.github.io/IDEAL/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaokun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1\">Xiaobo Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Ling-Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiale Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongliang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.15823","description":"<p>A Reverse Dictionary is a tool enabling users to discover a word based on its\nprovided definition, meaning, or description. Such a technique proves valuable\nin various scenarios, aiding language learners who possess a description of a\nword without its identity, and benefiting writers seeking precise terminology.\nThese scenarios often encapsulate what is referred to as the\n\"Tip-of-the-Tongue\" (TOT) phenomena. In this work, we present our winning\nsolution for the Arabic Reverse Dictionary shared task. This task focuses on\nderiving a vector representation of an Arabic word from its accompanying\ndescription. The shared task encompasses two distinct subtasks: the first\ninvolves an Arabic definition as input, while the second employs an English\ndefinition. For the first subtask, our approach relies on an ensemble of\nfinetuned Arabic BERT-based models, predicting the word embedding for a given\ndefinition. The final representation is obtained through averaging the output\nembeddings from each model within the ensemble. In contrast, the most effective\nsolution for the second subtask involves translating the English test\ndefinitions into Arabic and applying them to the finetuned models originally\ntrained for the first subtask. This straightforward method achieves the highest\nscore across both subtasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+ElBakry_A/0/1/0/all/0/1\">Ahmed ElBakry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gabr_M/0/1/0/all/0/1\">Mohamed Gabr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ElNokrashy_M/0/1/0/all/0/1\">Muhammad ElNokrashy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+AlKhamissi_B/0/1/0/all/0/1\">Badr AlKhamissi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code. (arXiv:2311.07989v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.07989","description":"<p>In this work we systematically review the recent advancements in code\nprocessing with language models, covering 50+ models, 30+ evaluation tasks,\n170+ datasets, and 700+ related works. We break down code processing models\ninto general language models represented by the GPT family and specialized\nmodels that are specifically pretrained on code, often with tailored\nobjectives. We discuss the relations and differences between these models, and\nhighlight the historical transition of code modeling from statistical models\nand RNNs to pretrained Transformers and LLMs, which is exactly the same course\nthat had been taken by NLP. We also discuss code-specific features such as AST,\nCFG, and unit tests, along with their application in training code language\nmodels, and identify key challenges and potential future directions in this\ndomain. We keep the survey open and updated on GitHub at\nhttps://github.com/codefuse-ai/Awesome-Code-LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Ziyin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaoyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bingchang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_C/0/1/0/all/0/1\">Cong Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1\">Zi Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Annotation Sensitivity: Training Data Collection Methods Affect Model Performance. (arXiv:2311.14212v3 [stat.ML] UPDATED)","link":"http://arxiv.org/abs/2311.14212","description":"<p>When training data are collected from human annotators, the design of the\nannotation instrument, the instructions given to annotators, the\ncharacteristics of the annotators, and their interactions can impact training\ndata. This study demonstrates that design choices made when creating an\nannotation instrument also impact the models trained on the resulting\nannotations. We introduce the term annotation sensitivity to refer to the\nimpact of annotation data collection methods on the annotations themselves and\non downstream model performance and predictions. We collect annotations of hate\nspeech and offensive language in five experimental conditions of an annotation\ninstrument, randomly assigning annotators to conditions. We then fine-tune BERT\nmodels on each of the five resulting datasets and evaluate model performance on\na holdout portion of each condition. We find considerable differences between\nthe conditions for 1) the share of hate speech/offensive language annotations,\n2) model performance, 3) model predictions, and 4) model learning curves. Our\nresults emphasize the crucial role played by the annotation instrument which\nhas received little attention in the machine learning literature. We call for\nadditional research into how and why the instrument impacts the annotations to\ninform the development of best practices in instrument design.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Kern_C/0/1/0/all/0/1\">Christoph Kern</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Eckman_S/0/1/0/all/0/1\">Stephanie Eckman</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Beck_J/0/1/0/all/0/1\">Jacob Beck</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Chew_R/0/1/0/all/0/1\">Rob Chew</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Ma_B/0/1/0/all/0/1\">Bolei Ma</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kreuter_F/0/1/0/all/0/1\">Frauke Kreuter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs. (arXiv:2312.02317v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.02317","description":"<p>Most current methods for multi-hop question answering (QA) over knowledge\ngraphs (KGs) only provide final conclusive answers without explanations, such\nas a set of KG entities that is difficult for normal users to review and\ncomprehend. This issue severely limits the application of KG-based QA in\nreal-world scenarios. However, it is non-trivial to solve due to two\nchallenges: First, annotations of reasoning chains of multi-hop questions,\nwhich could serve as supervision for explanation generation, are usually\nlacking. Second, it is difficult to maintain high efficiency when explicit KG\ntriples need to be retrieved to generate explanations. In this paper, we\npropose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to\nsolve this issue. GNN2R can provide both final answers and reasoning subgraphs\nas a rationale behind final answers efficiently with only weak supervision that\nis available through question-final answer pairs. We extensively evaluated\nGNN2R with detailed analyses in experiments. The results demonstrate that, in\nterms of effectiveness, efficiency, and quality of generated explanations,\nGNN2R outperforms existing state-of-the-art methods that are applicable to this\ntask. Our code and pre-trained models are available at\nhttps://github.com/ruijie-wang-uzh/GNN2R.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Ruijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossetto_L/0/1/0/all/0/1\">Luca Rossetto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1\">Michael Cochez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernstein_A/0/1/0/all/0/1\">Abraham Bernstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assertion Enhanced Few-Shot Learning: Instructive Technique for Large Language Models to Generate Educational Explanations. (arXiv:2312.03122v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03122","description":"<p>Human educators possess an intrinsic ability to anticipate and seek\neducational explanations from students, which drives them to pose\nthought-provoking questions when students cannot articulate these explanations\nindependently. We aim to imbue Intelligent Tutoring Systems with this ability\nusing few-shot learning capability of Large Language Models. Our work proposes\na novel prompting technique, Assertion Enhanced Few-Shot Learning, to\nfacilitate the generation of accurate, detailed oriented educational\nexplanations. Our central hypothesis is that, in educational domain, few-shot\ndemonstrations are necessary but not a sufficient condition for quality\nexplanation generation. We conducted a study involving 12 in-service teachers,\ncomparing our approach to Traditional Few-Shot Learning. The results show that\nAssertion Enhanced Few-Shot Learning improves explanation accuracy by 15% and\nyields higher-quality explanations, as evaluated by teachers. We also conduct a\nqualitative ablation study to factor the impact of assertions to provide\neducator-friendly prompting guidelines for generating explanations in their\ndomain of interest.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahriar_T/0/1/0/all/0/1\">Tasmia Shahriar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramos_K/0/1/0/all/0/1\">Kelly Ramos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuda_N/0/1/0/all/0/1\">Noboru Matsuda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Optimal Statistical Watermarking. (arXiv:2312.07930v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2312.07930","description":"<p>We study statistical watermarking by formulating it as a hypothesis testing\nproblem, a general framework which subsumes all previous statistical\nwatermarking methods. Key to our formulation is a coupling of the output tokens\nand the rejection region, realized by pseudo-random generators in practice,\nthat allows non-trivial trade-off between the Type I error and Type II error.\nWe characterize the Uniformly Most Powerful (UMP) watermark in the general\nhypothesis testing setting and the minimax Type II error in the model-agnostic\nsetting. In the common scenario where the output is a sequence of $n$ tokens,\nwe establish nearly matching upper and lower bounds on the number of i.i.d.\ntokens required to guarantee small Type I and Type II errors. Our rate of\n$\\Theta(h^{-1} \\log (1/h))$ with respect to the average entropy per token $h$\nhighlights potentials for improvement from the rate of $h^{-2}$ in the previous\nworks. Moreover, we formulate the robust watermarking problem where users are\nallowed to perform a class of perturbations on the generated texts, and\ncharacterize the optimal type II error of robust UMP tests via a linear\nprogramming problem. To the best of our knowledge, this is the first systematic\nstatistical treatment on the watermarking problem with near-optimal rates in\nthe i.i.d. setting, which might be of interest for future works.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Baihe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1\">Banghua Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jason D. Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1\">Jiantao Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1\">Michael I. Jordan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.11532","description":"<p>This paper introduces a novel approach for topic modeling utilizing latent\ncodebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely\nencapsulating the rich information of the pre-trained embeddings such as the\npre-trained language model. From the novel interpretation of the latent\ncodebooks and embeddings as conceptual bag-of-words, we propose a new\ngenerative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates\nthe original documents related to the respective latent codebook. The TVQ-VAE\ncan visualize the topics with various generative distributions including the\ntraditional BoW distribution and the autoregressive image generation. Our\nexperimental results on document analysis and image generation demonstrate that\nTVQ-VAE effectively captures the topic context which reveals the underlying\nstructures of the dataset and supports flexible forms of document generation.\nOfficial implementation of the proposed TVQ-VAE is available at\nhttps://github.com/clovaai/TVQ-VAE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1\">YoungJoon Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jongwon Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Analysis of the Effectiveness of Large Language Models as Automatic Dialogue Evaluators. (arXiv:2312.15407v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.15407","description":"<p>Automatic evaluation is an integral aspect of dialogue system research. The\ntraditional reference-based NLG metrics are generally found to be unsuitable\nfor dialogue assessment. Consequently, recent studies have suggested various\nunique, reference-free neural metrics that better align with human evaluations.\nNotably among them, large language models (LLMs), particularly the\ninstruction-tuned variants like ChatGPT, are shown to be promising substitutes\nfor human judges. Yet, existing works on utilizing LLMs for automatic dialogue\nevaluation are limited in their scope in terms of the number of meta-evaluation\ndatasets, mode of evaluation, coverage of LLMs, etc. Hence, it remains\ninconclusive how effective these LLMs are. To this end, we conduct a\ncomprehensive study on the application of LLMs for automatic dialogue\nevaluation. Specifically, we analyze the multi-dimensional evaluation\ncapability of 30 recently emerged LLMs at both turn and dialogue levels, using\na comprehensive set of 12 meta-evaluation datasets. Additionally, we probe the\nrobustness of the LLMs in handling various adversarial perturbations at both\nturn and dialogue levels. Finally, we explore how model-level and\ndimension-level ensembles impact the evaluation performance. All resources are\navailable at https://github.com/e0397123/comp-analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1\">Luis Fernando D&#x27;Haro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Malu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MR-GSM8K: A Meta-Reasoning Revolution in Large Language Model Evaluation. (arXiv:2312.17080v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.17080","description":"<p>In this work, we introduce a novel evaluation paradigm for Large Language\nModels, one that challenges them to engage in meta-reasoning. This approach\naddresses critical shortcomings in existing math problem-solving benchmarks,\ntraditionally used to evaluate the cognitive capabilities of agents. Our\nparadigm shifts the focus from result-oriented assessments, which often\noverlook the reasoning process, to a more holistic evaluation that effectively\ndifferentiates the cognitive capabilities among models. For example, in our\nbenchmark, GPT-4 demonstrates a performance five times better than GPT3-5. The\nsignificance of this new paradigm lies in its ability to reveal potential\ncognitive deficiencies in LLMs that current benchmarks, such as GSM8K, fail to\nuncover due to their saturation and lack of effective differentiation among\nvarying reasoning abilities. Our comprehensive analysis includes several\nstate-of-the-art math models from both open-source and closed-source\ncommunities, uncovering fundamental deficiencies in their training and\nevaluation approaches. This paper not only advocates for a paradigm shift in\nthe assessment of LLMs but also contributes to the ongoing discourse on the\ntrajectory towards Artificial General Intelligence (AGI). By promoting the\nadoption of meta-reasoning evaluation methods similar to ours, we aim to\nfacilitate a more accurate assessment of the true cognitive abilities of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhongshen Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pengguang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haiyun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jiaya Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04620","description":"<p>Agents based on Large Language Models (LLMs) are increasingly permeating\nvarious domains of human production and life, highlighting the importance of\naligning them with human values. The current alignment of AI systems primarily\nfocuses on passively aligning LLMs through human intervention. However, agents\npossess characteristics like receiving environmental feedback and\nself-evolution, rendering the LLM alignment methods inadequate. In response, we\npropose an evolutionary framework for agent evolution and alignment, named\nEvolutionaryAgent, which transforms agent alignment into a process of evolution\nand selection under the principle of survival of the fittest. In an environment\nwhere social norms continuously evolve, agents better adapted to the current\nsocial norms will have a higher probability of survival and proliferation,\nwhile those inadequately aligned dwindle over time. Experimental results\nassessing the agents from multiple perspectives in aligning with social norms\ndemonstrate that EvolutionaryAgent can align progressively better with the\nevolving social norms while maintaining its proficiency in general tasks.\nEffectiveness tests conducted on various open and closed-source LLMs as the\nfoundation for agents also prove the applicability of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shimin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.04925","description":"<p>Chain of Thought (CoT) is significant in improving the reasoning abilities of\nlarge language models (LLMs). However, the correlation between the\neffectiveness of CoT and the length of reasoning steps in prompts remains\nlargely unknown. To shed light on this, we have conducted several empirical\nexperiments to explore the relations. Specifically, we design experiments that\nexpand and compress the rationale reasoning steps within CoT demonstrations,\nwhile keeping all other factors constant. We have the following key findings.\nFirst, the results indicate that lengthening the reasoning steps in prompts,\neven without adding new information into the prompt, considerably enhances\nLLMs' reasoning abilities across multiple datasets. Alternatively, shortening\nthe reasoning steps, even while preserving the key information, significantly\ndiminishes the reasoning abilities of models. This finding highlights the\nimportance of the number of steps in CoT prompts and provides practical\nguidance to make better use of LLMs' potential in complex problem-solving\nscenarios. Second, we also investigated the relationship between the\nperformance of CoT and the rationales used in demonstrations. Surprisingly, the\nresult shows that even incorrect rationales can yield favorable outcomes if\nthey maintain the requisite length of inference. Third, we observed that the\nadvantages of increasing reasoning steps are task-dependent: simpler tasks\nrequire fewer steps, whereas complex tasks gain significantly from longer\ninference sequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mingyu Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1\">Qinkai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_D/0/1/0/all/0/1\">Dong Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiyan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yanda Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.05949","description":"<p>In-context learning, a paradigm bridging the gap between pre-training and\nfine-tuning, has demonstrated high efficacy in several NLP tasks, especially in\nfew-shot settings. Unlike traditional fine-tuning methods, in-context learning\nadapts pre-trained models to unseen tasks without updating any parameters.\nDespite being widely applied, in-context learning is vulnerable to malicious\nattacks. In this work, we raise security concerns regarding this paradigm. Our\nstudies demonstrate that an attacker can manipulate the behavior of large\nlanguage models by poisoning the demonstration context, without the need for\nfine-tuning the model. Specifically, we have designed a new backdoor attack\nmethod, named ICLAttack, to target large language models based on in-context\nlearning. Our method encompasses two types of attacks: poisoning demonstration\nexamples and poisoning prompts, which can make models behave in accordance with\npredefined intentions. ICLAttack does not require additional fine-tuning to\nimplant a backdoor, thus preserving the model's generality. Furthermore, the\npoisoned examples are correctly labeled, enhancing the natural stealth of our\nattack method. Extensive experimental results across several language models,\nranging in size from 1.3B to 40B parameters, demonstrate the effectiveness of\nour attack method, exemplified by a high average attack success rate of 95.0%\nacross the three datasets on OPT models. Our findings highlight the\nvulnerabilities of language models, and we hope this work will raise awareness\nof the possible security threats associated with in-context learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1\">Meihuizi Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jinming Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements. (arXiv:2401.06766v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.06766","description":"<p>Large language models demonstrate a remarkable capability for learning to\nsolve new tasks from a few examples. The prompt template, or the way the input\nexamples are formatted to obtain the prompt, is an important yet often\noverlooked aspect of in-context learning. In this work, we conduct a\ncomprehensive study of the template format's influence on the in-context\nlearning performance. We evaluate the impact of the prompt template across\nmodels (from 770M to 70B parameters) and 4 standard classification datasets. We\nshow that a poor choice of the template can reduce the performance of the\nstrongest models and inference methods to a random guess level. More\nimportantly, the best templates do not transfer between different setups and\neven between models of the same family. Our findings show that the currently\nprevalent approach to evaluation, which ignores template selection, may give\nmisleading results due to different templates in different works. As a first\nstep towards mitigating this issue, we propose Template Ensembles that\naggregate model predictions across several templates. This simple test-time\naugmentation boosts average performance while being robust to the choice of\nrandom set of templates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Voronov_A/0/1/0/all/0/1\">Anton Voronov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lena Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryabinin_M/0/1/0/all/0/1\">Max Ryabinin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering. (arXiv:2401.07510v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.07510","description":"<p>ChatGPT explores a strategic blueprint of question answering (QA) in\ndelivering medical diagnosis, treatment recommendations, and other healthcare\nsupport. This is achieved through the increasing incorporation of medical\ndomain data via natural language processing (NLP) and multimodal paradigms. By\ntransitioning the distribution of text, images, videos, and other modalities\nfrom the general domain to the medical domain, these techniques have expedited\nthe progress of medical domain question answering (MDQA). They bridge the gap\nbetween human natural language and sophisticated medical domain knowledge or\nexpert manual annotations, handling large-scale, diverse, unbalanced, or even\nunlabeled data analysis scenarios in medical contexts. Central to our focus is\nthe utilizing of language models and multimodal paradigms for medical question\nanswering, aiming to guide the research community in selecting appropriate\nmechanisms for their specific medical research requirements. Specialized tasks\nsuch as unimodal-related question answering, reading comprehension, reasoning,\ndiagnosis, relation extraction, probability modeling, and others, as well as\nmultimodal-related tasks like vision question answering, image caption,\ncross-modal retrieval, report summarization, and generation, are discussed in\ndetail. Each section delves into the intricate specifics of the respective\nmethod under consideration. This paper highlights the structures and\nadvancements of medical domain explorations against general domain methods,\nemphasizing their applications across different tasks and datasets. It also\noutlines current challenges and opportunities for future medical domain\nresearch, paving the way for continued innovation and application in this\nrapidly evolving field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.09003","description":"<p>Despite recent progress in improving the mathematical reasoning ability of\nlarge language models(LLMs), solving competition-level math problems without\nthe use of external tools remains challenging for open-source LLMs. In this\nwork, we introduce the MMIQC dataset, a mixture of processed web data and\nsynthetic question-response pairs, to equip base models with better\nmathematical reasoning skills. In different model sizes, the models fine-tuned\non MMIQC consistently outperform their counterparts by a clear margin on MATH\ntest set. Notably, DeepSeek-67B-MMIQC achieves a 41.0% accuracy, 4.2% higher\nthan the previous open-source SOTA. Our experiments also show that a large part\nof the improvement can be attributed to our novel augmentation method\nIQC(Iterative Question Composing), where we iteratively ask an LLM to compose\nnew questions from the given seed problems and do rejection sampling from\nanother LLM. MMIQC has now been released on\nhttps://huggingface.co/datasets/Vivacem/MMIQC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Haoxiong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1\">Andrew Chi-Chih Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2401.09074","description":"<p>We investigate the extent to which Large Language Models (LLMs) can simulate\nthe execution of computer code and algorithms. We begin by looking at straight\nline programs, and show that current LLMs demonstrate poor performance even\nwith such simple programs -- performance rapidly degrades with the length of\ncode. We then investigate the ability of LLMs to simulate programs that contain\ncritical paths and redundant instructions. We also go beyond straight line\nprogram simulation with sorting algorithms and nested loops, and we show the\ncomputational complexity of a routine directly affects the ability of an LLM to\nsimulate its execution. We observe that LLMs execute instructions sequentially\nand with a low error margin only for short programs or standard procedures.\nLLMs' code simulation is in tension with their pattern recognition and\nmemorisation capabilities: on tasks where memorisation is detrimental, we\npropose a novel prompting method to simulate code execution line by line.\nEmpirically, our new Chain of Simulation (CoSm) method improves on the standard\nChain of Thought prompting approach by avoiding the pitfalls of memorisation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1\">Emanuele La Malfa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weinhuber_C/0/1/0/all/0/1\">Christoph Weinhuber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torre_O/0/1/0/all/0/1\">Orazio Torre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1\">Fangru Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_A/0/1/0/all/0/1\">Anthony Cohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shadbolt_N/0/1/0/all/0/1\">Nigel Shadbolt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wooldridge_M/0/1/0/all/0/1\">Michael Wooldridge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machines Do See Color: A Guideline to Classify Different Forms of Racist Discourse in Large Corpora. (arXiv:2401.09333v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.09333","description":"<p>Current methods to identify and classify racist language in text rely on\nsmall-n qualitative approaches or large-n approaches focusing exclusively on\novert forms of racist discourse. This article provides a step-by-step\ngeneralizable guideline to identify and classify different forms of racist\ndiscourse in large corpora. In our approach, we start by conceptualizing racism\nand its different manifestations. We then contextualize these racist\nmanifestations to the time and place of interest, which allows researchers to\nidentify their discursive form. Finally, we apply XLM-RoBERTa (XLM-R), a\ncross-lingual model for supervised text classification with a cutting-edge\ncontextual understanding of text. We show that XLM-R and XLM-R-Racismo, our\npretrained model, outperform other state-of-the-art approaches in classifying\nracism in large corpora. We illustrate our approach using a corpus of tweets\nrelating to the Ecuadorian ind\\'igena community between 2018 and 2021.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gordillo_D/0/1/0/all/0/1\">Diana Davila Gordillo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Timoneda_J/0/1/0/all/0/1\">Joan Timoneda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vera_S/0/1/0/all/0/1\">Sebastian Vallejo Vera</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks. (arXiv:2401.09798v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.09798","description":"<p>Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where\nsafeguards are bypassed to produce ethically harmful prompts. This study\nproposes a simple black-box method to effectively generate jailbreak prompts,\novercoming the high complexity and computational costs associated with existing\nmethods. The proposed technique iteratively rewrites harmful prompts into\nnon-harmful expressions using the target LLM itself, based on the hypothesis\nthat LLMs can directly sample expressions that bypass safeguards. Demonstrated\nthrough experiments with ChatGPT (GPT-3.5 and GPT-4) and Gemini-Pro, this\nmethod achieved an attack success rate of over 80% within an average of 5\niterations and remained effective despite model updates. The generated\njailbreak prompts were naturally-worded and concise; moreover, they were\ndifficult-to-defend. These results indicate that creating effective jailbreak\nprompts is simpler than previously considered, suggesting that black-box\njailbreak attacks pose a more serious threat.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Takemoto_K/0/1/0/all/0/1\">Kazuhiro Takemoto</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Hierarchical Spoken Language Dysfluency Modeling. (arXiv:2401.10015v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.10015","description":"<p>Speech disfluency modeling is the bottleneck for both speech therapy and\nlanguage learning. However, there is no effective AI solution to systematically\ntackle this problem. We solidify the concept of disfluent speech and disfluent\nspeech modeling. We then present Hierarchical Unconstrained Disfluency Modeling\n(H-UDM) approach, the hierarchical extension of UDM that addresses both\ndisfluency transcription and detection to eliminate the need for extensive\nmanual annotation. Our experimental findings serve as clear evidence of the\neffectiveness and reliability of the methods we have introduced, encompassing\nboth transcription and detection tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lian_J/0/1/0/all/0/1\">Jiachen Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anumanchipalli_G/0/1/0/all/0/1\">Gopala Anumanchipalli</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.10189","description":"<p>Fine-grained few-shot entity extraction in the chemical domain faces two\nunique challenges. First, compared with entity extraction tasks in the general\ndomain, sentences from chemical papers usually contain more entities. Moreover,\nentity extraction models usually have difficulty extracting entities of\nlong-tailed types. In this paper, we propose Chem-FINESE, a novel\nsequence-to-sequence (seq2seq) based few-shot entity extraction approach, to\naddress these two challenges. Our Chem-FINESE has two components: a seq2seq\nentity extractor to extract named entities from the input sentence and a\nseq2seq self-validation module to reconstruct the original input sentence from\nextracted entities. Inspired by the fact that a good entity extraction system\nneeds to extract entities faithfully, our new self-validation module leverages\nentity extraction results to reconstruct the original input sentence. Besides,\nwe design a new contrastive loss to reduce excessive copying during the\nextraction process. Finally, we release ChemNER+, a new fine-grained chemical\nentity extraction dataset that is annotated by domain experts with the ChemNER\nschema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets\nshow that our newly proposed framework has contributed up to 8.26% and 6.84%\nabsolute F1-score gains respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qingyun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hongxiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Huimin Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2401.10337","description":"<p>Tactics, Techniques and Procedures (TTPs) represent sophisticated attack\npatterns in the cybersecurity domain, described encyclopedically in textual\nknowledge bases. Identifying TTPs in cybersecurity writing, often called TTP\nmapping, is an important and challenging task. Conventional learning approaches\noften target the problem in the classical multi-class or multilabel\nclassification setting. This setting hinders the learning ability of the model\ndue to a large number of classes (i.e., TTPs), the inevitable skewness of the\nlabel distribution and the complex hierarchical structure of the label space.\nWe formulate the problem in a different learning paradigm, where the assignment\nof a text to a TTP label is decided by the direct semantic similarity between\nthe two, thus reducing the complexity of competing solely over the large\nlabeling space. To that end, we propose a neural matching architecture with an\neffective sampling-based learn-to-compare mechanism, facilitating the learning\nprocess of the matching model despite constrained resources.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srndic_N/0/1/0/all/0/1\">Nedim Srndic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neth_A/0/1/0/all/0/1\">Alexander Neth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Fusion of Large Language Models. (arXiv:2401.10491v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2401.10491","description":"<p>While training large language models (LLMs) from scratch can generate models\nwith distinct functionalities and strengths, it comes at significant costs and\nmay result in redundant capabilities. Alternatively, a cost-effective and\ncompelling approach is to merge existing pre-trained LLMs into a more potent\nmodel. However, due to the varying architectures of these LLMs, directly\nblending their weights is impractical. In this paper, we introduce the notion\nof knowledge fusion for LLMs, aimed at combining the capabilities of existing\nLLMs and transferring them into a single LLM. By leveraging the generative\ndistributions of source LLMs, we externalize their collective knowledge and\nunique strengths, thereby potentially elevating the capabilities of the target\nmodel beyond those of any individual source LLM. We validate our approach using\nthree popular LLMs with different architectures--Llama-2, MPT, and\nOpenLLaMA--across various benchmarks and tasks. Our findings confirm that the\nfusion of LLMs can improve the performance of the target model across a range\nof capabilities such as reasoning, commonsense, and code generation. Our code,\nmodel weights, and data are public at\n\\url{https://github.com/fanqiwan/FuseLLM}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xinting Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1\">Deng Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2024-01-22T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","admin":"http://webns.net/mvcb/","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#"}}]}]}