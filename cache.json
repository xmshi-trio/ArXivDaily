{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-23T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Enhancing Health Data Interoperability with Large Language Models: A FHIR Study. (arXiv:2310.12989v1 [cs.CL])","link":"http://arxiv.org/abs/2310.12989","description":"<p>In this study, we investigated the ability of the large language model (LLM)\nto enhance healthcare data interoperability. We leveraged the LLM to convert\nclinical texts into their corresponding FHIR resources. Our experiments,\nconducted on 3,671 snippets of clinical text, demonstrated that the LLM not\nonly streamlines the multi-step natural language processing and human\ncalibration processes but also achieves an exceptional accuracy rate of over\n90% in exact matches when compared to human annotations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yikuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yerebakan_H/0/1/0/all/0/1\">Halid Yerebakan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shinagawa_Y/0/1/0/all/0/1\">Yoshihisa Shinagawa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yuan Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Document-Level Relation Extraction with Relation Correlation Enhancement. (arXiv:2310.13000v1 [cs.IR])","link":"http://arxiv.org/abs/2310.13000","description":"<p>Document-level relation extraction (DocRE) is a task that focuses on\nidentifying relations between entities within a document. However, existing\nDocRE models often overlook the correlation between relations and lack a\nquantitative analysis of relation correlations. To address this limitation and\neffectively capture relation correlations in DocRE, we propose a relation graph\nmethod, which aims to explicitly exploit the interdependency among relations.\nFirstly, we construct a relation graph that models relation correlations using\nstatistical co-occurrence information derived from prior relation knowledge.\nSecondly, we employ a re-weighting scheme to create an effective relation\ncorrelation matrix to guide the propagation of relation information.\nFurthermore, we leverage graph attention networks to aggregate relation\nembeddings. Importantly, our method can be seamlessly integrated as a\nplug-and-play module into existing models. Experimental results demonstrate\nthat our approach can enhance the performance of multi-relation extraction,\nhighlighting the effectiveness of considering relation correlations in DocRE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yusheng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zhouhan Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Financial Information Retrieval Model (ConFIRM). (arXiv:2310.13001v1 [cs.IR])","link":"http://arxiv.org/abs/2310.13001","description":"<p>With the exponential growth in large language models (LLMs), leveraging their\nemergent properties for specialized domains like finance merits exploration.\nHowever, regulated fields such as finance pose unique constraints, requiring\ndomain-optimized frameworks. We present ConFIRM, an LLM-based conversational\nfinancial information retrieval model tailored for query intent classification\nand knowledge base labeling.\n</p>\n<p>ConFIRM comprises two modules:\n</p>\n<p>1) a method to synthesize finance domain-specific question-answer pairs, and\n</p>\n<p>2) evaluation of parameter efficient fine-tuning approaches for the query\nclassification task. We generate a dataset of over 4000 samples, assessing\naccuracy on a separate test set.\n</p>\n<p>ConFIRM achieved over 90% accuracy, essential for regulatory compliance.\nConFIRM provides a data-efficient solution to extract precise query intent for\nfinancial dialog systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Stephen Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gazeley_W/0/1/0/all/0/1\">William Gazeley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_S/0/1/0/all/0/1\">Siu Ho Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tingting Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Large Language Models Geospatially Knowledgeable?. (arXiv:2310.13002v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13002","description":"<p>Despite the impressive performance of Large Language Models (LLM) for various\nnatural language processing tasks, little is known about their comprehension of\ngeographic data and related ability to facilitate informed geospatial\ndecision-making. This paper investigates the extent of geospatial knowledge,\nawareness, and reasoning abilities encoded within such pretrained LLMs. With a\nfocus on autoregressive language models, we devise experimental approaches\nrelated to (i) probing LLMs for geo-coordinates to assess geospatial knowledge,\n(ii) using geospatial and non-geospatial prepositions to gauge their geospatial\nawareness, and (iii) utilizing a multidimensional scaling (MDS) experiment to\nassess the models' geospatial reasoning capabilities and to determine locations\nof cities based on prompting. Our results confirm that it does not only take\nlarger, but also more sophisticated LLMs to synthesize geospatial knowledge\nfrom textual information. As such, this research contributes to understanding\nthe potential and limitations of LLMs in dealing with geospatial information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhandari_P/0/1/0/all/0/1\">Prabin Bhandari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfoser_D/0/1/0/all/0/1\">Dieter Pfoser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoBaSS: Gauging Learnability in Supervised Fine-tuning Data. (arXiv:2310.13008v1 [cs.LG])","link":"http://arxiv.org/abs/2310.13008","description":"<p>Supervised Fine-Tuning (SFT) serves as a crucial phase in aligning Large\nLanguage Models (LLMs) to specific task prerequisites. The selection of\nfine-tuning data profoundly influences the model's performance, whose principle\nis traditionally grounded in data quality and distribution. In this paper, we\nintroduce a new dimension in SFT data selection: learnability. This new\ndimension is motivated by the intuition that SFT unlocks capabilities acquired\nby a LLM during the pretraining phase. Given that different pretrained models\nhave disparate capabilities, the SFT data appropriate for one may not suit\nanother. Thus, we introduce the term learnability to define the suitability of\ndata for effective learning by the model. We present the Loss Based SFT Data\nSelection (LoBaSS) method, utilizing data learnability as the principal\ncriterion for the selection SFT data. This method provides a nuanced approach,\nallowing the alignment of data selection with inherent model capabilities,\nensuring optimal compatibility and learning efficiency. In experimental\ncomparisons involving 7B and 13B models, our LoBaSS method is able to surpass\nfull-data fine-tuning at merely 6% of the total training data. When employing\n16.7% of the data, LoBaSS harmonizes the model's capabilities across\nconversational and mathematical domains, proving its efficacy and adaptability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Haotian Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tingkai Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Q/0/1/0/all/0/1\">Qianli Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_J/0/1/0/all/0/1\">Jianbo Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongxia Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Compositional preference models for aligning LMs. (arXiv:2310.13011v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13011","description":"<p>As language models (LMs) become more capable, it is increasingly important to\nalign them with human preferences. However, the dominant paradigm for training\nPreference Models (PMs) for that purpose suffers from fundamental limitations,\nsuch as lack of transparency and scalability, along with susceptibility to\noverfitting the preference dataset. We propose Compositional Preference Models\n(CPMs), a novel PM framework that decomposes one global preference assessment\ninto several interpretable features, obtains scalar scores for these features\nfrom a prompted LM, and aggregates these scores using a logistic regression\nclassifier. CPMs allow to control which properties of the preference data are\nused to train the preference model and to build it based on features that are\nbelieved to underlie the human preference judgment. Our experiments show that\nCPMs not only improve generalization and are more robust to overoptimization\nthan standard PMs, but also that best-of-n samples obtained using CPMs tend to\nbe preferred over samples obtained using conventional PMs. Overall, our\napproach demonstrates the benefits of endowing PMs with priors about which\nfeatures determine human preferences while relying on LM capabilities to\nextract those features in a scalable and robust way.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Go_D/0/1/0/all/0/1\">Dongyoung Go</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1\">Germ&#xe1;n Kruszewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rozen_J/0/1/0/all/0/1\">Jos Rozen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dymetman_M/0/1/0/all/0/1\">Marc Dymetman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"H2O Open Ecosystem for State-of-the-art Large Language Models. (arXiv:2310.13012v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13012","description":"<p>Large Language Models (LLMs) represent a revolution in AI. However, they also\npose many significant risks, such as the presence of biased, private,\ncopyrighted or harmful text. For this reason we need open, transparent and safe\nsolutions. We introduce a complete open-source ecosystem for developing and\ntesting LLMs. The goal of this project is to boost open alternatives to\nclosed-source approaches. We release h2oGPT, a family of fine-tuned LLMs from 7\nto 70 Billion parameters. We also introduce H2O LLM Studio, a framework and\nno-code GUI designed for efficient fine-tuning, evaluation, and deployment of\nLLMs using the most recent state-of-the-art techniques. Our code and models are\nlicensed under fully permissive Apache 2.0 licenses. We believe open-source\nlanguage models help to boost AI development and make it more accessible and\ntrustworthy. The demo is available at: https://gpt.h2o.ai/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Candel_A/0/1/0/all/0/1\">Arno Candel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKinney_J/0/1/0/all/0/1\">Jon McKinney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singer_P/0/1/0/all/0/1\">Philipp Singer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_P/0/1/0/all/0/1\">Pascal Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeblick_M/0/1/0/all/0/1\">Maximilian Jeblick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chun Ming Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_M/0/1/0/all/0/1\">Marcos V. Conde</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative error correction for code-switching speech recognition using large language models. (arXiv:2310.13013v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13013","description":"<p>Code-switching (CS) speech refers to the phenomenon of mixing two or more\nlanguages within the same sentence. Despite the recent advances in automatic\nspeech recognition (ASR), CS-ASR is still a challenging task ought to the\ngrammatical structure complexity of the phenomenon and the data scarcity of\nspecific training corpus. In this work, we propose to leverage large language\nmodels (LLMs) and lists of hypotheses generated by an ASR to address the CS\nproblem. Specifically, we first employ multiple well-trained ASR models for\nN-best hypotheses generation, with the aim of increasing the diverse and\ninformative elements in the set of hypotheses. Next, we utilize the LLMs to\nlearn the hypotheses-to-transcription (H2T) mapping by adding a trainable\nlow-rank adapter. Such a generative error correction (GER) method directly\npredicts the accurate transcription according to its expert linguistic\nknowledge and N-best hypotheses, resulting in a paradigm shift from the\ntraditional language model rescoring or error correction techniques.\nExperimental evidence demonstrates that GER significantly enhances CS-ASR\naccuracy, in terms of reduced mixed error rate (MER). Furthermore, LLMs show\nremarkable data efficiency for H2T learning, providing a potential solution to\nthe data scarcity problem of CS-ASR in low-resource languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yuchen Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chao-Han Huck Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hexin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siniscalchi_S/0/1/0/all/0/1\">Sabato Marco Siniscalchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chng_E/0/1/0/all/0/1\">Eng Siong Chng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model Prediction Capabilities: Evidence from a Real-World Forecasting Tournament. (arXiv:2310.13014v1 [cs.CY])","link":"http://arxiv.org/abs/2310.13014","description":"<p>Accurately predicting the future would be an important milestone in the\ncapabilities of artificial intelligence. However, research on the ability of\nlarge language models to provide probabilistic predictions about future events\nremains nascent. To empirically test this ability, we enrolled OpenAI's\nstate-of-the-art large language model, GPT-4, in a three-month forecasting\ntournament hosted on the Metaculus platform. The tournament, running from July\nto October 2023, attracted 843 participants and covered diverse topics\nincluding Big Tech, U.S. politics, viral outbreaks, and the Ukraine conflict.\nFocusing on binary forecasts, we show that GPT-4's probabilistic forecasts are\nsignificantly less accurate than the median human-crowd forecasts. We find that\nGPT-4's forecasts did not significantly differ from the no-information\nforecasting strategy of assigning a 50% probability to every question. We\nexplore a potential explanation, that GPT-4 might be predisposed to predict\nprobabilities close to the midpoint of the scale, but our data do not support\nthis hypothesis. Overall, we find that GPT-4 significantly underperforms in\nreal-world predictive tasks compared to median human-crowd forecasts. A\npotential explanation for this underperformance is that in real-world\nforecasting tournaments, the true answers are genuinely unknown at the time of\nprediction; unlike in other benchmark tasks like professional exams or time\nseries forecasting, where strong performance may at least partly be due to the\nanswers being memorized from the training data. This makes real-world\nforecasting tournaments an ideal environment for testing the generalized\nreasoning and prediction capabilities of artificial intelligence going forward.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schoenegger_P/0/1/0/all/0/1\">Philipp Schoenegger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_P/0/1/0/all/0/1\">Peter S. Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audio-AdapterFusion: A Task-ID-free Approach for Efficient and Non-Destructive Multi-task Speech Recognition. (arXiv:2310.13015v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13015","description":"<p>Adapters are an efficient, composable alternative to full fine-tuning of\npre-trained models and help scale the deployment of large ASR models to many\ntasks. In practice, a task ID is commonly prepended to the input during\ninference to route to single-task adapters for the specified task. However, one\nmajor limitation of this approach is that the task ID may not be known during\ninference, rendering it unsuitable for most multi-task settings. To address\nthis, we propose three novel task-ID-free methods to combine single-task\nadapters in multi-task ASR and investigate two learning algorithms for\ntraining. We evaluate our methods on 10 test sets from 4 diverse ASR tasks and\nshow that our methods are non-destructive and parameter-efficient. While only\nupdating 17% of the model parameters, our methods can achieve an 8% mean WER\nimprovement relative to full fine-tuning and are on-par with task-ID adapter\nrouting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ngai_H/0/1/0/all/0/1\">Hillary Ngai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_R/0/1/0/all/0/1\">Rohan Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_N/0/1/0/all/0/1\">Neeraj Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1\">Ronny Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haghani_P/0/1/0/all/0/1\">Parisa Haghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mengibar_P/0/1/0/all/0/1\">Pedro Moreno Mengibar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Position Interpolation Improves ALiBi Extrapolation. (arXiv:2310.13017v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13017","description":"<p>Linear position interpolation helps pre-trained models using rotary position\nembeddings (RoPE) to extrapolate to longer sequence lengths. We propose using\nlinear position interpolation to extend the extrapolation range of models using\nAttention with Linear Biases (ALiBi). We find position interpolation\nsignificantly improves extrapolation capability on upstream language modelling\nand downstream summarization and retrieval tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Al_Khateeb_F/0/1/0/all/0/1\">Faisal Al-Khateeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dey_N/0/1/0/all/0/1\">Nolan Dey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soboleva_D/0/1/0/all/0/1\">Daria Soboleva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1\">Joel Hestness</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncertainty-aware Parameter-Efficient Self-training for Semi-supervised Language Understanding. (arXiv:2310.13022v1 [cs.LG])","link":"http://arxiv.org/abs/2310.13022","description":"<p>The recent success of large pre-trained language models (PLMs) heavily hinges\non massive labeled data, which typically produces inferior performance in\nlow-resource scenarios. To remedy this dilemma, we study self-training as one\nof the predominant semi-supervised learning (SSL) approaches, which utilizes\nlarge-scale unlabeled data to generate synthetic examples. However, too many\nnoisy labels will hurt the model performance, and the self-training procedure\nrequires multiple training iterations making it more expensive if all the model\nparameters of the PLM are updated. This paper presents UPET, a novel\nUncertainty-aware Parameter-Efficient self-Training framework to effectively\nand efficiently address the labeled data scarcity issue. Specifically, we\nincorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to\nperform uncertainty estimation for the teacher model and then judiciously\nselect reliable pseudo-labeled examples based on confidence and certainty.\nDuring the student training, we introduce multiple parameter-efficient learning\n(PEL) paradigms that allow the optimization of only a small percentage of\nparameters. We also propose a novel Easy-Hard Contrastive Tuning to enhance the\nrobustness and generalization. Extensive experiments over multiple downstream\ntasks demonstrate that UPET achieves a substantial improvement in terms of\nperformance and efficiency. Our codes and data are released at https:\n//github.com/wjn1996/UPET.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1\">Qiushi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Ming Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphGPT: Graph Instruction Tuning for Large Language Models. (arXiv:2310.13023v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13023","description":"<p>Graph Neural Networks (GNNs) have advanced graph structure understanding via\nrecursive information exchange and aggregation among graph nodes. To improve\nmodel robustness, self-supervised learning (SSL) has emerged as a promising\napproach for data augmentation. However, existing methods for generating\npre-trained graph embeddings often rely on fine-tuning with specific downstream\ntask labels, which limits their usability in scenarios where labeled data is\nscarce or unavailable. To address this, our research focuses on advancing the\ngeneralization capabilities of graph models in challenging zero-shot learning\nscenarios. Inspired by the success of large language models (LLMs), we aim to\ndevelop a graph-oriented LLM that can achieve high generalization across\ndiverse downstream datasets and tasks, even without any information available\nfrom the downstream graph data. In this work, we present the GraphGPT framework\nthat aligns LLMs with graph structural knowledge with a graph instruction\ntuning paradigm. Our framework incorporates a text-graph grounding component to\nestablish a connection between textual information and graph structures.\nAdditionally, we propose a dual-stage instruction tuning paradigm, accompanied\nby a lightweight graph-text alignment projector. This paradigm explores\nself-supervised graph structural signals and task-specific graph instructions,\nto guide LLMs in understanding complex graph structures and improving their\nadaptability across different downstream tasks. Our framework is evaluated on\nsupervised and zero-shot graph learning tasks, demonstrating superior\ngeneralization and outperforming state-of-the-art baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jiabin Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuhao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1\">Lei Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1\">Lixin Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Suqi Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1\">Dawei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chao Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Anytime Fine-tuning: Continually Pre-trained Language Models with Hypernetwork Prompt. (arXiv:2310.13024v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13024","description":"<p>Continual pre-training has been urgent for adapting a pre-trained model to a\nmultitude of domains and tasks in the fast-evolving world. In practice, a\ncontinually pre-trained model is expected to demonstrate not only greater\ncapacity when fine-tuned on pre-trained domains but also a non-decreasing\nperformance on unseen ones. In this work, we first investigate such anytime\nfine-tuning effectiveness of existing continual pre-training approaches,\nconcluding with unanimously decreased performance on unseen domains. To this\nend, we propose a prompt-guided continual pre-training method, where we train a\nhypernetwork to generate domain-specific prompts by both agreement and\ndisagreement losses. The agreement loss maximally preserves the generalization\nof a pre-trained model to new domains, and the disagreement one guards the\nexclusiveness of the generated hidden states for each domain. Remarkably,\nprompts by the hypernetwork alleviate the domain identity when fine-tuning and\npromote knowledge transfer across domains. Our method achieved improvements of\n3.57% and 3.4% on two real-world datasets (including domain shift and temporal\nshift), respectively, demonstrating its efficacy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_G/0/1/0/all/0/1\">Gangwei Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1\">Caigao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1\">Siqiao Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">James Y. Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_D/0/1/0/all/0/1\">Defu Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Ying Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Powerset multi-class cross entropy loss for neural speaker diarization. (arXiv:2310.13025v1 [cs.SD])","link":"http://arxiv.org/abs/2310.13025","description":"<p>Since its introduction in 2019, the whole end-to-end neural diarization\n(EEND) line of work has been addressing speaker diarization as a frame-wise\nmulti-label classification problem with permutation-invariant training. Despite\nEEND showing great promise, a few recent works took a step back and studied the\npossible combination of (local) supervised EEND diarization with (global)\nunsupervised clustering. Yet, these hybrid contributions did not question the\noriginal multi-label formulation. We propose to switch from multi-label (where\nany two speakers can be active at the same time) to powerset multi-class\nclassification (where dedicated classes are assigned to pairs of overlapping\nspeakers). Through extensive experiments on 9 different benchmarks, we show\nthat this formulation leads to significantly better performance (mostly on\noverlapping speech) and robustness to domain mismatch, while eliminating the\ndetection threshold hyperparameter, critical for the multi-label formulation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Plaquet_A/0/1/0/all/0/1\">Alexis Plaquet</a> (IRIT-SAMoVA), <a href=\"http://arxiv.org/find/cs/1/au:+Bredin_H/0/1/0/all/0/1\">Herv&#xe9; Bredin</a> (IRIT-SAMoVA)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reliable Academic Conference Question Answering: A Study Based on Large Language Model. (arXiv:2310.13028v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13028","description":"<p>The rapid growth of computer science has led to a proliferation of research\npresented at academic conferences, fostering global scholarly communication.\nResearchers consistently seek accurate, current information about these events\nat all stages. This data surge necessitates an intelligent question-answering\nsystem to efficiently address researchers' queries and ensure awareness of the\nlatest advancements. The information of conferences is usually published on\ntheir official website, organized in a semi-structured way with a lot of text.\nTo address this need, we have developed the ConferenceQA dataset for 7 diverse\nacademic conferences with human annotations. Firstly, we employ a combination\nof manual and automated methods to organize academic conference data in a\nsemi-structured JSON format. Subsequently, we annotate nearly 100\nquestion-answer pairs for each conference. Each pair is classified into four\ndifferent dimensions. To ensure the reliability of the data, we manually\nannotate the source of each answer. In light of recent advancements, Large\nLanguage Models (LLMs) have demonstrated impressive performance in various NLP\ntasks. They have demonstrated impressive capabilities in information-seeking\nquestion answering after instruction fine-tuning, and as such, we present our\nconference QA study based on LLM. Due to hallucination and outdated knowledge\nof LLMs, we adopt retrieval based methods to enhance LLMs' question-answering\nabilities. We have proposed a structure-aware retrieval method, specifically\ndesigned to leverage inherent structural information during the retrieval\nprocess. Empirical validation on the ConferenceQA dataset has demonstrated the\neffectiveness of this method. The dataset and code are readily accessible on\nhttps://github.com/zjukg/ConferenceQA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhiwei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1\">Long Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_M/0/1/0/all/0/1\">Mingchen Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yin Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiqiang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_J/0/1/0/all/0/1\">Jiawei Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wen Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Use Case: Reformulating Query Rewriting as a Statistical Machine Translation Problem. (arXiv:2310.13031v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13031","description":"<p>One of the most important challenges for modern search engines is to retrieve\nrelevant web content based on user queries. In order to achieve this challenge,\nsearch engines have a module to rewrite user queries. That is why modern web\nsearch engines utilize some statistical and neural models used in the natural\nlanguage processing domain. Statistical machine translation is a well-known NLP\nmethod among them. The paper proposes a query rewriting pipeline based on a\nmonolingual machine translation model that learns to rewrite Arabic user search\nqueries. This paper also describes preprocessing steps to create a mapping\nbetween user queries and web page titles.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Algan_A/0/1/0/all/0/1\">Abdullah Can Algan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yurekli_E/0/1/0/all/0/1\">Emre Y&#xfc;rekli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cayir_A/0/1/0/all/0/1\">Aykut &#xc7;ay&#x131;r</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quality-Diversity through AI Feedback. (arXiv:2310.13032v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13032","description":"<p>In many text-generation problems, users may prefer not only a single\nresponse, but a diverse range of high-quality outputs from which to choose.\nQuality-diversity (QD) search algorithms aim at such outcomes, by continually\nimproving and diversifying a population of candidates. However, the\napplicability of QD to qualitative domains, like creative writing, has been\nlimited by the difficulty of algorithmically specifying measures of quality and\ndiversity. Interestingly, recent developments in language models (LMs) have\nenabled guiding search through AI feedback, wherein LMs are prompted in natural\nlanguage to evaluate qualitative aspects of text. Leveraging this development,\nwe introduce Quality-Diversity through AI Feedback (QDAIF), wherein an\nevolutionary algorithm applies LMs to both generate variation and evaluate the\nquality and diversity of candidate text. When assessed on creative writing\ndomains, QDAIF covers more of a specified search space with high-quality\nsamples than do non-QD controls. Further, human evaluation of QDAIF-generated\ncreative texts validates reasonable agreement between AI and human evaluation.\nOur results thus highlight the potential of AI feedback to guide open-ended\nsearch for creative and original solutions, providing a recipe that seemingly\ngeneralizes to many domains and modalities. In this way, QDAIF is a step\ntowards AI systems that can independently search, diversify, evaluate, and\nimprove, which are among the core skills underlying human society's capacity\nfor innovation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bradley_H/0/1/0/all/0/1\">Herbie Bradley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1\">Andrew Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Teufel_H/0/1/0/all/0/1\">Hannah Teufel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jenny Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oostermeijer_K/0/1/0/all/0/1\">Koen Oostermeijer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bellagente_M/0/1/0/all/0/1\">Marco Bellagente</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1\">Jeff Clune</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1\">Kenneth Stanley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schott_G/0/1/0/all/0/1\">Gr&#xe9;gory Schott</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1\">Joel Lehman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GARI: Graph Attention for Relative Isomorphism of Arabic Word Embeddings. (arXiv:2310.13068v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13068","description":"<p>Bilingual Lexical Induction (BLI) is a core challenge in NLP, it relies on\nthe relative isomorphism of individual embedding spaces. Existing attempts\naimed at controlling the relative isomorphism of different embedding spaces\nfail to incorporate the impact of semantically related words in the model\ntraining objective. To address this, we propose GARI that combines the\ndistributional training objectives with multiple isomorphism losses guided by\nthe graph attention network. GARI considers the impact of semantical variations\nof words in order to define the relative isomorphism of the embedding spaces.\nExperimental evaluation using the Arabic language data set shows that GARI\noutperforms the existing research by improving the average P@1 by a relative\nscore of up to 40.95% and 76.80% for in-domain and domain mismatch settings\nrespectively. We release the codes for GARI at\nhttps://github.com/asif6827/GARI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1\">Muhammad Asif Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alshmrani_M/0/1/0/all/0/1\">Maha Alshmrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1\">Jianbin Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Multilingual Complexity to Emotional Clarity: Leveraging Commonsense to Unveil Emotions in Code-Mixed Dialogues. (arXiv:2310.13080v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13080","description":"<p>Understanding emotions during conversation is a fundamental aspect of human\ncommunication, driving NLP research for Emotion Recognition in Conversation\n(ERC). While considerable research has focused on discerning emotions of\nindividual speakers in monolingual dialogues, understanding the emotional\ndynamics in code-mixed conversations has received relatively less attention.\nThis motivates our undertaking of ERC for code-mixed conversations in this\nstudy. Recognizing that emotional intelligence encompasses a comprehension of\nworldly knowledge, we propose an innovative approach that integrates\ncommonsense information with dialogue context to facilitate a deeper\nunderstanding of emotions. To achieve this, we devise an efficient pipeline\nthat extracts relevant commonsense from existing knowledge graphs based on the\ncode-mixed input. Subsequently, we develop an advanced fusion technique that\nseamlessly combines the acquired commonsense information with the dialogue\nrepresentation obtained from a dedicated dialogue understanding module. Our\ncomprehensive experimentation showcases the substantial performance improvement\nobtained through the systematic incorporation of commonsense in ERC. Both\nquantitative assessments and qualitative analyses further corroborate the\nvalidity of our hypothesis, reaffirming the pivotal role of commonsense\nintegration in enhancing ERC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Shivani Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_R/0/1/0/all/0/1\">Ramaneswaran S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Language Models Learn about Legal Entity Types during Pretraining?. (arXiv:2310.13092v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13092","description":"<p>Language Models (LMs) have proven their ability to acquire diverse linguistic\nknowledge during the pretraining phase, potentially serving as a valuable\nsource of incidental supervision for downstream tasks. However, there has been\nlimited research conducted on the retrieval of domain-specific knowledge, and\nspecifically legal knowledge. We propose to explore the task of Entity Typing,\nserving as a proxy for evaluating legal knowledge as an essential aspect of\ntext comprehension, and a foundational task to numerous downstream legal NLP\napplications. Through systematic evaluation and analysis and two types of\nprompting (cloze sentences and QA-based templates) and to clarify the nature of\nthese acquired cues, we compare diverse types and lengths of entities both\ngeneral and domain-specific entities, semantics or syntax signals, and\ndifferent LM pretraining corpus (generic and legal-oriented) and architectures\n(encoder BERT-based and decoder-only with Llama2). We show that (1) Llama2\nperforms well on certain entities and exhibits potential for substantial\nimprovement with optimized prompt templates, (2) law-oriented LMs show\ninconsistent performance, possibly due to variations in their training corpus,\n(3) LMs demonstrate the ability to type entities even in the case of\nmulti-token entities, (4) all models struggle with entities belonging to\nsub-domains of the law (5) Llama2 appears to frequently overlook syntactic\ncues, a shortcoming less present in BERT-based architectures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Barale_C/0/1/0/all/0/1\">Claire Barale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rovatsos_M/0/1/0/all/0/1\">Michael Rovatsos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhuta_N/0/1/0/all/0/1\">Nehal Bhuta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"No offence, Bert -- I insult only humans! Multiple addressees sentence-level attack on toxicity detection neural network. (arXiv:2310.13099v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13099","description":"<p>We introduce a simple yet efficient sentence-level attack on black-box\ntoxicity detector models. By adding several positive words or sentences to the\nend of a hateful message, we are able to change the prediction of a neural\nnetwork and pass the toxicity detection system check. This approach is shown to\nbe working on seven languages from three different language families. We also\ndescribe the defence mechanism against the aforementioned attack and discuss\nits limitations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1\">Sergey Berezin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahbakhsh_R/0/1/0/all/0/1\">Reza Farahbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_N/0/1/0/all/0/1\">Noel Crespi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unsupervised Candidate Answer Extraction through Differentiable Masker-Reconstructor Model. (arXiv:2310.13106v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13106","description":"<p>Question generation is a widely used data augmentation approach with\nextensive applications, and extracting qualified candidate answers from context\npassages is a critical step for most question generation systems. However,\nexisting methods for candidate answer extraction are reliant on linguistic\nrules or annotated data that face the partial annotation issue and challenges\nin generalization. To overcome these limitations, we propose a novel\nunsupervised candidate answer extraction approach that leverages the inherent\nstructure of context passages through a Differentiable Masker-Reconstructor\n(DMR) Model with the enforcement of self-consistency for picking up salient\ninformation tokens. We curated two datasets with exhaustively-annotated answers\nand benchmark a comprehensive set of supervised and unsupervised candidate\nanswer extraction methods. We demonstrate the effectiveness of the DMR model by\nshowing its performance is superior among unsupervised methods and comparable\nto supervised methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhuoer Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yicheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1\">Ziwei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caverlee_J/0/1/0/all/0/1\">James Caverlee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models. (arXiv:2310.13127v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13127","description":"<p>Large language models (LLMs) can perform a wide range of tasks by following\nnatural language instructions, without the necessity of task-specific\nfine-tuning. Unfortunately, the performance of LLMs is greatly influenced by\nthe quality of these instructions, and manually writing effective instructions\nfor each task is a laborious and subjective process. In this paper, we\nintroduce Auto-Instruct, a novel method to automatically improve the quality of\ninstructions provided to LLMs. Our method leverages the inherent generative\nability of LLMs to produce diverse candidate instructions for a given task, and\nthen ranks them using a scoring model trained on a variety of 575 existing NLP\ntasks. In experiments on 118 out-of-domain tasks, Auto-Instruct surpasses both\nhuman-written instructions and existing baselines of LLM-generated\ninstructions. Furthermore, our method exhibits notable generalizability even\nwith other LLMs that are not incorporated into its training process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shuohang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenhao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yichong Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iter_D/0/1/0/all/0/1\">Dan Iter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1\">Qingkai Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1\">Chenguang Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Meng Jiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ask Me in English Instead: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries. (arXiv:2310.13132v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13132","description":"<p>Large language models (LLMs) are transforming the ways the general public\naccesses and consumes information. Their influence is particularly pronounced\nin pivotal sectors like healthcare, where lay individuals are increasingly\nappropriating LLMs as conversational agents for everyday queries. While LLMs\ndemonstrate impressive language understanding and generation proficiencies,\nconcerns regarding their safety remain paramount in these high-stake domains.\nMoreover, the development of LLMs is disproportionately focused on English. It\nremains unclear how these LLMs perform in the context of non-English languages,\na gap that is critical for ensuring equity in the real-world use of these\nsystems.This paper provides a framework to investigate the effectiveness of\nLLMs as multi-lingual dialogue systems for healthcare queries. Our\nempirically-derived framework XlingEval focuses on three fundamental criteria\nfor evaluating LLM responses to naturalistic human-authored health-related\nquestions: correctness, consistency, and verifiability. Through extensive\nexperiments on four major global languages, including English, Spanish,\nChinese, and Hindi, spanning three expert-annotated large health Q&amp;A datasets,\nand through an amalgamation of algorithmic and human-evaluation strategies, we\nfound a pronounced disparity in LLM responses across these languages,\nindicating a need for enhanced cross-lingual capabilities. We further propose\nXlingHealth, a cross-lingual benchmark for examining the multilingual\ncapabilities of LLMs in the healthcare context. Our findings underscore the\npressing need to bolster the cross-lingual capacities of these models, and to\nprovide an equitable information ecosystem accessible to all.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["Jin, <a href=\"http://arxiv.org/find/cs/1/au:+Yiqiao/0/1/0/all/0/1\">Yiqiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chandra/0/1/0/all/0/1\">Chandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohit/0/1/0/all/0/1\">Mohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Verma/0/1/0/all/0/1\">Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaurav/0/1/0/all/0/1\">Gaurav</a>, Hu, <a href=\"http://arxiv.org/find/cs/1/au:+Yibo/0/1/0/all/0/1\">Yibo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_D/0/1/0/all/0/1\">De Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Munmun/0/1/0/all/0/1\">Munmun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar/0/1/0/all/0/1\">Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srijan/0/1/0/all/0/1\">Srijan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLIFT: Analysing Natural Distribution Shift on Question Answering Models in Clinical Domain. (arXiv:2310.13146v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13146","description":"<p>This paper introduces a new testbed CLIFT (Clinical Shift) for the clinical\ndomain Question-answering task. The testbed includes 7.5k high-quality question\nanswering samples to provide a diverse and reliable benchmark. We performed a\ncomprehensive experimental study and evaluated several QA deep-learning models\nunder the proposed testbed. Despite impressive results on the original test\nset, the performance degrades when applied to new test sets, which shows the\ndistribution shift. Our findings emphasize the need for and the potential for\nincreasing the robustness of clinical domain models under distributional\nshifts. The testbed offers one way to track progress in that direction. It also\nhighlights the necessity of adopting evaluation metrics that consider\nrobustness to natural distribution shifts. We plan to expand the corpus by\nadding more samples and model results. The full paper and the updated benchmark\nare available at github.com/openlifescience-ai/clift\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pal_A/0/1/0/all/0/1\">Ankit Pal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Breaking through Deterministic Barriers: Randomized Pruning Mask Generation and Selection. (arXiv:2310.13183v1 [cs.CV])","link":"http://arxiv.org/abs/2310.13183","description":"<p>It is widely acknowledged that large and sparse models have higher accuracy\nthan small and dense models under the same model size constraints. This\nmotivates us to train a large model and then remove its redundant neurons or\nweights by pruning. Most existing works pruned the networks in a deterministic\nway, the performance of which solely depends on a single pruning criterion and\nthus lacks variety. Instead, in this paper, we propose a model pruning strategy\nthat first generates several pruning masks in a designed random way.\nSubsequently, along with an effective mask-selection rule, the optimal mask is\nchosen from the pool of mask candidates. To further enhance efficiency, we\nintroduce an early mask evaluation strategy, mitigating the overhead associated\nwith training multiple masks. Our extensive experiments demonstrate that this\napproach achieves state-of-the-art performance across eight datasets from GLUE,\nparticularly excelling at high levels of sparsity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1\">Weizhi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongkuan Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast and Accurate Factual Inconsistency Detection Over Long Documents. (arXiv:2310.13189v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13189","description":"<p>Generative AI models exhibit remarkable potential; however, hallucinations\nacross various tasks present a significant challenge, particularly for longer\ninputs that current approaches struggle to address effectively. We introduce\nSCALE (Source Chunking Approach for Large-scale inconsistency Evaluation), a\ntask-agnostic model for detecting factual inconsistencies using a novel\nchunking strategy. Specifically, SCALE is a Natural Language Inference (NLI)\nbased model that uses large text chunks to condition over long texts. This\napproach achieves state-of-the-art performance in factual inconsistency\ndetection for diverse tasks and long inputs. Additionally, we leverage the\nchunking mechanism and employ a novel algorithm to explain SCALE's decisions\nthrough relevant source sentence retrieval. Our evaluations reveal that SCALE\noutperforms existing methods on both standard benchmarks and a new long-form\ndialogue dataset ScreenEval we constructed. Moreover, SCALE surpasses\ncompetitive systems in efficiency and model explanation evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lattimer_B/0/1/0/all/0/1\">Barrett Martin Lattimer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Patrick Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Robust Pruning: An Adaptive Knowledge-Retention Pruning Strategy for Language Models. (arXiv:2310.13191v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13191","description":"<p>The pruning objective has recently extended beyond accuracy and sparsity to\nrobustness in language models. Despite this, existing methods struggle to\nenhance robustness against adversarial attacks when continually increasing\nmodel sparsity and require a retraining process. As humans step into the era of\nlarge language models, these issues become increasingly prominent. This paper\nproposes that the robustness of language models is proportional to the extent\nof pre-trained knowledge they encompass. Accordingly, we introduce a\npost-training pruning strategy designed to faithfully replicate the embedding\nspace and feature space of dense language models, aiming to conserve more\npre-trained knowledge during the pruning process. In this setup, each layer's\nreconstruction error not only originates from itself but also includes\ncumulative error from preceding layers, followed by an adaptive rectification.\nCompared to other state-of-art baselines, our approach demonstrates a superior\nbalance between accuracy, sparsity, robustness, and pruning cost with BERT on\ndatasets SST2, IMDB, and AGNews, marking a significant stride towards robust\npruning in language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1\">Qi Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1\">Dongkuan Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NameGuess: Column Name Expansion for Tabular Data. (arXiv:2310.13196v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13196","description":"<p>Recent advances in large language models have revolutionized many sectors,\nincluding the database industry. One common challenge when dealing with large\nvolumes of tabular data is the pervasive use of abbreviated column names, which\ncan negatively impact performance on various data search, access, and\nunderstanding tasks. To address this issue, we introduce a new task, called\nNameGuess, to expand column names (used in database schema) as a natural\nlanguage generation problem. We create a training dataset of 384K\nabbreviated-expanded column pairs using a new data fabrication method and a\nhuman-annotated evaluation benchmark that includes 9.2K examples from\nreal-world tables. To tackle the complexities associated with polysemy and\nambiguity in NameGuess, we enhance auto-regressive language models by\nconditioning on table content and column header names -- yielding a fine-tuned\nmodel (with 2.7B parameters) that matches human performance. Furthermore, we\nconduct a comprehensive analysis (on multiple LLMs) to validate the\neffectiveness of table content in NameGuess and identify promising future\nopportunities. Code has been made available at\nhttps://github.com/amazon-science/nameguess.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiani Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhengyuan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_B/0/1/0/all/0/1\">Balasubramaniam Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rangwala_H/0/1/0/all/0/1\">Huzefa Rangwala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karypis_G/0/1/0/all/0/1\">George Karypis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Primacy Effect of ChatGPT. (arXiv:2310.13206v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13206","description":"<p>Instruction-tuned large language models (LLMs), such as ChatGPT, have led to\npromising zero-shot performance in discriminative natural language\nunderstanding (NLU) tasks. This involves querying the LLM using a prompt\ncontaining the question, and the candidate labels to choose from. The\nquestion-answering capabilities of ChatGPT arise from its pre-training on large\namounts of human-written text, as well as its subsequent fine-tuning on human\npreferences, which motivates us to ask: Does ChatGPT also inherits humans'\ncognitive biases? In this paper, we study the primacy effect of ChatGPT: the\ntendency of selecting the labels at earlier positions as the answer. We have\ntwo main findings: i) ChatGPT's decision is sensitive to the order of labels in\nthe prompt; ii) ChatGPT has a clearly higher chance to select the labels at\nearlier positions as the answer. We hope that our experiments and analyses\nprovide additional insights into building more reliable ChatGPT-based\nsolutions. We release the source code at\nhttps://github.com/wangywUST/PrimacyEffectGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yiwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1\">Yujun Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuxuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooi_B/0/1/0/all/0/1\">Bryan Hooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy Named Entity Recognition. (arXiv:2310.13213v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13213","description":"<p>We present MULTICONER V2, a dataset for fine-grained Named Entity Recognition\ncovering 33 entity classes across 12 languages, in both monolingual and\nmultilingual settings. This dataset aims to tackle the following practical\nchallenges in NER: (i) effective handling of fine-grained classes that include\ncomplex entities like movie titles, and (ii) performance degradation due to\nnoise generated from typing mistakes or OCR errors. The dataset is compiled\nfrom open resources like Wikipedia and Wikidata, and is publicly available.\nEvaluation based on the XLM-RoBERTa baseline highlights the unique challenges\nposed by MULTICONER V2: (i) the fine-grained taxonomy is challenging, where the\nscores are low with macro-F1=0.63 (across all languages), and (ii) the\ncorruption strategy significantly impairs performance, with entity corruption\nresulting in 9% lower performance relative to non-entity corruptions across all\nlanguages. This highlights the greater impact of entity noise in contrast to\ncontext noise.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fetahu_B/0/1/0/all/0/1\">Besnik Fetahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhiyu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kar_S/0/1/0/all/0/1\">Sudipta Kar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rokhlenko_O/0/1/0/all/0/1\">Oleg Rokhlenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malmasi_S/0/1/0/all/0/1\">Shervin Malmasi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Zero-Shot Crypto Sentiment with Fine-tuned Language Model and Prompt Engineering. (arXiv:2310.13226v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13226","description":"<p>Blockchain technology has revolutionized the financial landscape, with\ncryptocurrencies gaining widespread adoption for their decentralized and\ntransparent nature. As the sentiment expressed on social media platforms can\nsignificantly influence cryptocurrency discussions and market movements,\nsentiment analysis has emerged as a crucial tool for understanding public\nopinion and predicting market trends. Motivated by the aim to enhance sentiment\nanalysis accuracy in the cryptocurrency domain, this paper investigates\nfine-tuning techniques on large language models. This paper also investigates\nthe efficacy of supervised fine-tuning and instruction-based fine-tuning on\nlarge language models for unseen tasks. Experimental results demonstrate a\nsignificant average zero-shot performance gain of 40% after fine-tuning,\nhighlighting the potential of this technique in optimizing pre-trained language\nmodel efficiency. Additionally, the impact of instruction tuning on models of\nvarying scales is examined, revealing that larger models benefit from\ninstruction tuning, achieving the highest average accuracy score of 75.16%. In\ncontrast, smaller-scale models may experience reduced generalization due to the\ncomplete utilization of model capacity. To gain deeper insight about how\ninstruction works with these language models, this paper presents an\nexperimental investigation into the response of an instruction-based model\nunder different instruction tuning setups. The investigation demonstrates that\nthe model achieves an average accuracy score of 72.38% for short and simple\ninstructions. This performance significantly outperforms its accuracy under\nlong and complex instructions by over 12%, thereby effectively highlighting the\nprofound significance of instruction characteristics in maximizing model\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wahidur_R/0/1/0/all/0/1\">Rahman S M Wahidur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tashdeed_I/0/1/0/all/0/1\">Ishmam Tashdeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaur_M/0/1/0/all/0/1\">Manjit Kaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heung-No-Lee/0/1/0/all/0/1\">Heung-No-Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ToolChain*: Efficient Action Space Navigation in Large Language Models with A* Search. (arXiv:2310.13227v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13227","description":"<p>Large language models (LLMs) have demonstrated powerful decision-making and\nplanning capabilities in solving complicated real-world problems. LLM-based\nautonomous agents can interact with diverse tools (e.g., functional APIs) and\ngenerate solution plans that execute a series of API function calls in a\nstep-by-step manner. The multitude of candidate API function calls\nsignificantly expands the action space, amplifying the critical need for\nefficient action space navigation. However, existing methods either struggle\nwith unidirectional exploration in expansive action spaces, trapped into a\nlocally optimal solution, or suffer from exhaustively traversing all potential\nactions, causing inefficient navigation. To address these issues, we propose\nToolChain*, an efficient tree search-based planning algorithm for LLM-based\nagents. It formulates the entire action space as a decision tree, where each\nnode represents a possible API function call involved in a solution plan. By\nincorporating the A* search algorithm with task-specific cost function design,\nit efficiently prunes high-cost branches that may involve incorrect actions,\nidentifying the most low-cost valid path as the solution. Extensive experiments\non multiple tool-use and reasoning tasks demonstrate that ToolChain*\nefficiently balances exploration and exploitation within an expansive action\nspace. It outperforms state-of-the-art baselines on planning and reasoning\ntasks by 3.1% and 3.5% on average while requiring 7.35x and 2.31x less time,\nrespectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1\">Yuchen Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitra_S/0/1/0/all/0/1\">Saayan Mitra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bursztyn_V/0/1/0/all/0/1\">Victor Bursztyn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sarkhel_S/0/1/0/all/0/1\">Somdeb Sarkhel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Less the Merrier? Investigating Language Representation in Multilingual Models. (arXiv:2310.13228v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13228","description":"<p>Multilingual Language Models offer a way to incorporate multiple languages in\none model and utilize cross-language transfer learning to improve performance\nfor different Natural Language Processing (NLP) tasks. Despite progress in\nmultilingual models, not all languages are supported as well, particularly in\nlow-resource settings. In this work, we investigate the linguistic\nrepresentation of different languages in multilingual models. We start by\nasking the question which languages are supported in popular multilingual\nmodels and which languages are left behind. Then, for included languages, we\nlook at models' learned representations based on language family and dialect\nand try to understand how models' learned representations for~(1) seen and~(2)\nunseen languages vary across different language groups. In addition, we test\nand analyze performance on downstream tasks such as text generation and Named\nEntity Recognition. We observe from our experiments that community-centered\nmodels -- models that focus on languages of a given family or geographical\nlocation and are built by communities who speak them -- perform better at\ndistinguishing between languages in the same family for low-resource languages.\nOur paper contributes to the literature in understanding multilingual models\nand their shortcomings and offers insights on potential ways to improve them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nigatu_H/0/1/0/all/0/1\">Hellina Hailu Nigatu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tonja_A/0/1/0/all/0/1\">Atnafu Lambebo Tonja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1\">Jugal Kalita</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-level Contrastive Learning for Script-based Character Understanding. (arXiv:2310.13231v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13231","description":"<p>In this work, we tackle the scenario of understanding characters in scripts,\nwhich aims to learn the characters' personalities and identities from their\nutterances. We begin by analyzing several challenges in this scenario, and then\npropose a multi-level contrastive learning framework to capture characters'\nglobal information in a fine-grained manner. To validate the proposed\nframework, we conduct extensive experiments on three character understanding\nsub-tasks by comparing with strong pre-trained language models, including\nSpanBERT, Longformer, BigBird and ChatGPT-3.5. Experimental results demonstrate\nthat our method improves the performances by a considerable margin. Through\nfurther in-depth analysis, we show the effectiveness of our method in\naddressing the challenges and provide more hints on the scenario of character\nunderstanding. We will open-source our work on github at\nhttps://github.com/David-Li0406/Script-based-Character-Understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dawei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hengyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yanran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Shiping Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Open-source Large Language Models are Strong Zero-shot Query Likelihood Models for Document Ranking. (arXiv:2310.13243v1 [cs.IR])","link":"http://arxiv.org/abs/2310.13243","description":"<p>In the field of information retrieval, Query Likelihood Models (QLMs) rank\ndocuments based on the probability of generating the query given the content of\na document. Recently, advanced large language models (LLMs) have emerged as\neffective QLMs, showcasing promising ranking capabilities. This paper focuses\non investigating the genuine zero-shot ranking effectiveness of recent LLMs,\nwhich are solely pre-trained on unstructured text data without supervised\ninstruction fine-tuning. Our findings reveal the robust zero-shot ranking\nability of such LLMs, highlighting that additional instruction fine-tuning may\nhinder effectiveness unless a question generation task is present in the\nfine-tuning dataset. Furthermore, we introduce a novel state-of-the-art ranking\nsystem that integrates LLM-based QLMs with a hybrid zero-shot retriever,\ndemonstrating exceptional effectiveness in both zero-shot and few-shot\nscenarios. We make our codebase publicly available at\nhttps://github.com/ielab/llm-qlm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_S/0/1/0/all/0/1\">Shengyao Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Bing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koopman_B/0/1/0/all/0/1\">Bevan Koopman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuccon_G/0/1/0/all/0/1\">Guido Zuccon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Anomaly Detection of Command Shell Sessions based on DistilBERT: Unsupervised and Supervised Approaches. (arXiv:2310.13247v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13247","description":"<p>Anomaly detection in command shell sessions is a critical aspect of computer\nsecurity. Recent advances in deep learning and natural language processing,\nparticularly transformer-based models, have shown great promise for addressing\ncomplex security challenges. In this paper, we implement a comprehensive\napproach to detect anomalies in Unix shell sessions using a pretrained\nDistilBERT model, leveraging both unsupervised and supervised learning\ntechniques to identify anomalous activity while minimizing data labeling. The\nunsupervised method captures the underlying structure and syntax of Unix shell\ncommands, enabling the detection of session deviations from normal behavior.\nExperiments on a large-scale enterprise dataset collected from production\nsystems demonstrate the effectiveness of our approach in detecting anomalous\nbehavior in Unix shell sessions. This work highlights the potential of\nleveraging recent advances in transformers to address important computer\nsecurity challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zefang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buford_J/0/1/0/all/0/1\">John Buford</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Visual Grounding Helps Learn Word Meanings in Low-Data Regimes. (arXiv:2310.13257v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13257","description":"<p>Modern neural language models (LMs) are powerful tools for modeling human\nsentence production and comprehension, and their internal representations are\nremarkably well-aligned with representations of language in the human brain.\nBut to achieve these results, LMs must be trained in distinctly un-human-like\nways -- requiring orders of magnitude more language data than children receive\nduring development, and without any of the accompanying grounding in\nperception, action, or social behavior. Do models trained more naturalistically\n-- with grounded supervision -- exhibit more human-like language learning? We\ninvestigate this question in the context of word learning, a key sub-task in\nlanguage acquisition. We train a diverse set of LM architectures, with and\nwithout auxiliary supervision from image captioning tasks, on datasets of\nvarying scales. We then evaluate these models on a broad set of benchmarks\ncharacterizing models' learning of syntactic categories, lexical relations,\nsemantic features, semantic similarity, and alignment with human neural\nrepresentations. We find that visual supervision can indeed improve the\nefficiency of word learning. However, these improvements are limited: they are\npresent almost exclusively in the low-data regime, and sometimes canceled out\nby the inclusion of rich distributional signals from text. The information\nconveyed by text and images is not redundant -- we find that models mainly\ndriven by visual information yield qualitatively different from those mainly\ndriven by word co-occurrences. However, our results suggest that current\nmulti-modal modeling approaches fail to effectively leverage visual information\nto build more human-like word representations from human-sized datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhuang_C/0/1/0/all/0/1\">Chengxu Zhuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fedorenko_E/0/1/0/all/0/1\">Evelina Fedorenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Quality-based Syntactic Template Retriever for Syntactically-controlled Paraphrase Generation. (arXiv:2310.13262v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13262","description":"<p>Existing syntactically-controlled paraphrase generation (SPG) models perform\npromisingly with human-annotated or well-chosen syntactic templates. However,\nthe difficulty of obtaining such templates actually hinders the practical\napplication of SPG models. For one thing, the prohibitive cost makes it\nunfeasible to manually design decent templates for every source sentence. For\nanother, the templates automatically retrieved by current heuristic methods are\nusually unreliable for SPG models to generate qualified paraphrases. To escape\nthis dilemma, we propose a novel Quality-based Syntactic Template Retriever\n(QSTR) to retrieve templates based on the quality of the to-be-generated\nparaphrases. Furthermore, for situations requiring multiple paraphrases for\neach source sentence, we design a Diverse Templates Search (DTS) algorithm,\nwhich can enhance the diversity between paraphrases without sacrificing\nquality. Experiments demonstrate that QSTR can significantly surpass existing\nretrieval methods in generating high-quality paraphrases and even perform\ncomparably with human-annotated templates in terms of reference-free metrics.\nAdditionally, human evaluation and the performance on downstream tasks using\nour generated paraphrases for data augmentation showcase the potential of our\nQSTR and DTS algorithm in practical scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Songming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yunlong Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yufeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Wenjuan Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jinan Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model. (arXiv:2310.13265v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13265","description":"<p>Multi-modal open-domain question answering typically requires evidence\nretrieval from databases across diverse modalities, such as images, tables,\npassages, etc. Even Large Language Models (LLMs) like GPT-4 fall short in this\ntask. To enable LLMs to tackle the task in a zero-shot manner, we introduce\nMoqaGPT, a straightforward and flexible framework. Using a divide-and-conquer\nstrategy that bypasses intricate multi-modality ranking, our framework can\naccommodate new modalities and seamlessly transition to new models for the\ntask. Built upon LLMs, MoqaGPT retrieves and extracts answers from each\nmodality separately, then fuses this multi-modal information using LLMs to\nproduce a final answer. Our methodology boosts performance on the MMCoQA\ndataset, improving F1 by +37.91 points and EM by +34.07 points over the\nsupervised baseline. On the MultiModalQA dataset, MoqaGPT surpasses the\nzero-shot baseline, improving F1 by 9.5 points and EM by 10.1 points, and\nsignificantly closes the gap with supervised methods. Our codebase is available\nat https://github.com/lezhang7/MOQAGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Le Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yihong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mo_F/0/1/0/all/0/1\">Fengran Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1\">Aishwarya Agrawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Language Encoder of Contrastive Cross-modal Models. (arXiv:2310.13267v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13267","description":"<p>Contrastive cross-modal models such as CLIP and CLAP aid various\nvision-language (VL) and audio-language (AL) tasks. However, there has been\nlimited investigation of and improvement in their language encoder, which is\nthe central component of encoding natural language descriptions of image/audio\ninto vector representations. We extensively evaluate how unsupervised and\nsupervised sentence embedding training affect language encoder quality and\ncross-modal task performance. In VL pretraining, we found that sentence\nembedding training language encoder quality and aids in cross-modal tasks,\nimproving contrastive VL models such as CyCLIP. In contrast, AL pretraining\nbenefits less from sentence embedding training, which may result from the\nlimited amount of pretraining data. We analyze the representation spaces to\nunderstand the strengths of sentence embedding training, and find that it\nimproves text-space uniformity, at the cost of decreased cross-modal alignment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1\">Mengjie Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ono_J/0/1/0/all/0/1\">Junya Ono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1\">Zhi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1\">Chieh-Hsin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takida_Y/0/1/0/all/0/1\">Yuhta Takida</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murata_N/0/1/0/all/0/1\">Naoki Murata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1\">Wei-Hsiang Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shibuya_T/0/1/0/all/0/1\">Takashi Shibuya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wakaki_H/0/1/0/all/0/1\">Hiromi Wakaki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitsufuji_Y/0/1/0/all/0/1\">Yuki Mitsufuji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InvGC: Robust Cross-Modal Retrieval by Inverse Graph Convolution. (arXiv:2310.13276v1 [cs.CV])","link":"http://arxiv.org/abs/2310.13276","description":"<p>Over recent decades, significant advancements in cross-modal retrieval are\nmainly driven by breakthroughs in visual and linguistic modeling. However, a\nrecent study shows that multi-modal data representations tend to cluster within\na limited convex cone (as representation degeneration problem), which hinders\nretrieval performance due to the inseparability of these representations. In\nour study, we first empirically validate the presence of the representation\ndegeneration problem across multiple cross-modal benchmarks and methods. Next,\nto address it, we introduce a novel method, called InvGC, a post-processing\ntechnique inspired by graph convolution and average pooling. Specifically,\nInvGC defines the graph topology within the datasets and then applies graph\nconvolution in a subtractive manner. This method effectively separates\nrepresentations by increasing the distances between data points. To improve the\nefficiency and effectiveness of InvGC, we propose an advanced graph topology,\nLocalAdj, which only aims to increase the distances between each data point and\nits nearest neighbors. To understand why InvGC works, we present a detailed\ntheoretical analysis, proving that the lower bound of recall will be improved\nafter deploying InvGC. Extensive empirical results show that InvGC and InvGC\nw/LocalAdj significantly mitigate the representation degeneration problem,\nthereby enhancing retrieval performance.\n</p>\n<p>Our code is available at\nhttps://github.com/yimuwangcs/Better_Cross_Modal_Retrieval\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jian_X/0/1/0/all/0/1\">Xiangru Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yimu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SALMONN: Towards Generic Hearing Abilities for Large Language Models. (arXiv:2310.13289v1 [cs.SD])","link":"http://arxiv.org/abs/2310.13289","description":"<p>Hearing is arguably an essential ability of artificial intelligence (AI)\nagents in the physical world, which refers to the perception and understanding\nof general auditory information consisting of at least three types of sounds:\nspeech, audio events, and music. In this paper, we propose SALMONN, a speech\naudio language music open neural network, built by integrating a pre-trained\ntext-based large language model (LLM) with speech and audio encoders into a\nsingle multimodal model. SALMONN enables the LLM to directly process and\nunderstand general audio inputs and achieve competitive performances on a\nnumber of speech and audio tasks used in training, such as automatic speech\nrecognition and translation, auditory-information-based question answering,\nemotion recognition, speaker verification, and music and audio captioning\n\\textit{etc.} SALMONN also has a diverse set of emergent abilities unseen in\nthe training, which includes but is not limited to speech translation to\nuntrained languages, speech-based slot filling, spoken-query-based question\nanswering, audio-based storytelling, and speech audio co-reasoning\n\\textit{etc}. The presence of the cross-modal emergent abilities is studied,\nand a novel few-shot activation tuning approach is proposed to activate such\nabilities of SALMONN. To our knowledge, SALMONN is the first model of its type\nand can be regarded as a step towards AI with generic hearing abilities. An\ninteractive demo of SALMONN is available at\n\\texttt{\\url{https://github.com/bytedance/SALMONN}}, and the training code and\nmodel checkpoints will be released upon acceptance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1\">Changli Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Wenyi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1\">Guangzhi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xianzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1\">Tian Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1\">Lu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1\">Zejun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpreting Indirect Answers to Yes-No Questions in Multiple Languages. (arXiv:2310.13290v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13290","description":"<p>Yes-no questions expect a yes or no for an answer, but people often skip\npolar keywords. Instead, they answer with long explanations that must be\ninterpreted. In this paper, we focus on this challenging problem and release\nnew benchmarks in eight languages. We present a distant supervision approach to\ncollect training data. We also demonstrate that direct answers (i.e., with\npolar keywords) are useful to train models to interpret indirect answers (i.e.,\nwithout polar keywords). Experimental results demonstrate that monolingual\nfine-tuning is beneficial if training data can be obtained via distant\nsupervision for the language of interest (5 languages). Additionally, we show\nthat cross-lingual fine-tuning is always beneficial (8 languages).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1\">Md Mosharaf Hossain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_S/0/1/0/all/0/1\">Shivam Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Melo_T/0/1/0/all/0/1\">Terry Cruz Melo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozler_K/0/1/0/all/0/1\">Kadir Bulut Ozler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1\">Keun Hee Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quintero_J/0/1/0/all/0/1\">Jacob Quintero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaei_M/0/1/0/all/0/1\">MohammadHossein Rezaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shakya_S/0/1/0/all/0/1\">Shreya Nupur Shakya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uddin_M/0/1/0/all/0/1\">Md Nayem Uddin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blanco_E/0/1/0/all/0/1\">Eduardo Blanco</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks. (arXiv:2310.13291v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13291","description":"<p>Large language models have revolutionized the field of NLP by achieving\nstate-of-the-art performance on various tasks. However, there is a concern that\nthese models may disclose information in the training data. In this study, we\nfocus on the summarization task and investigate the membership inference (MI)\nattack: given a sample and black-box access to a model's API, it is possible to\ndetermine if the sample was part of the training data. We exploit text\nsimilarity and the model's resistance to document modifications as potential MI\nsignals and evaluate their effectiveness on widely used datasets. Our results\ndemonstrate that summarization models are at risk of exposing data membership,\neven in cases where the reference summary is not available. Furthermore, we\ndiscuss several safeguards for training summarization models to protect against\nMI attacks and discuss the inherent trade-off between privacy and utility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lueck_G/0/1/0/all/0/1\">Gord Lueck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quispe_R/0/1/0/all/0/1\">Rodolfo Quispe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Huseyin A Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_J/0/1/0/all/0/1\">Janardhan Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decoding the Silent Majority: Inducing Belief Augmented Social Graph with Large Language Model for Response Forecasting. (arXiv:2310.13297v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13297","description":"<p>Automatic response forecasting for news media plays a crucial role in\nenabling content producers to efficiently predict the impact of news releases\nand prevent unexpected negative outcomes such as social conflict and moral\ninjury. To effectively forecast responses, it is essential to develop measures\nthat leverage the social dynamics and contextual information surrounding\nindividuals, especially in cases where explicit profiles or historical actions\nof the users are limited (referred to as lurkers). As shown in a previous\nstudy, 97% of all tweets are produced by only the most active 25% of users.\nHowever, existing approaches have limited exploration of how to best process\nand utilize these important features. To address this gap, we propose a novel\nframework, named SocialSense, that leverages a large language model to induce a\nbelief-centered graph on top of an existent social network, along with\ngraph-based propagation to capture social dynamics. We hypothesize that the\ninduced graph that bridges the gap between distant users who share similar\nbeliefs allows the model to effectively capture the response patterns. Our\nmethod surpasses existing state-of-the-art in experimental evaluations for both\nzero-shot and supervised settings, demonstrating its effectiveness in response\nforecasting. Moreover, the analysis reveals the framework's capability to\neffectively handle unseen user and lurker scenarios, further highlighting its\nrobustness and practical applicability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1\">Chenkai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_Y/0/1/0/all/0/1\">Yi R. Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1\">Hou Pong Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelzaher_T/0/1/0/all/0/1\">Tarek Abdelzaher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Test-Time Self-Adaptive Small Language Models for Question Answering. (arXiv:2310.13307v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13307","description":"<p>Recent instruction-finetuned large language models (LMs) have achieved\nnotable performances in various tasks, such as question-answering (QA).\nHowever, despite their ability to memorize a vast amount of general knowledge\nacross diverse tasks, they might be suboptimal on specific tasks due to their\nlimited capacity to transfer and adapt knowledge to target tasks. Moreover,\nfurther finetuning LMs with labeled datasets is often infeasible due to their\nabsence, but it is also questionable if we can transfer smaller LMs having\nlimited knowledge only with unlabeled test data. In this work, we show and\ninvestigate the capabilities of smaller self-adaptive LMs, only with unlabeled\ntest data. In particular, we first stochastically generate multiple answers,\nand then ensemble them while filtering out low-quality samples to mitigate\nnoise from inaccurate labels. Our proposed self-adaption strategy demonstrates\nsignificant performance improvements on benchmark QA datasets with higher\nrobustness across diverse prompts, enabling LMs to stay stable. Code is\navailable at: https://github.com/starsuzi/T-SAS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_S/0/1/0/all/0/1\">Soyeong Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1\">Jinheon Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1\">Sukmin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1\">Sung Ju Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jong C. Park</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Impact of Corpus Diversity on Financial Pretrained Language Models. (arXiv:2310.13312v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13312","description":"<p>Over the past few years, various domain-specific pretrained language models\n(PLMs) have been proposed and have outperformed general-domain PLMs in\nspecialized areas such as biomedical, scientific, and clinical domains. In\naddition, financial PLMs have been studied because of the high economic impact\nof financial data analysis. However, we found that financial PLMs were not\npretrained on sufficiently diverse financial data. This lack of diverse\ntraining data leads to a subpar generalization performance, resulting in\ngeneral-purpose PLMs, including BERT, often outperforming financial PLMs on\nmany downstream tasks. To address this issue, we collected a broad range of\nfinancial corpus and trained the Financial Language Model (FiLM) on these\ndiverse datasets. Our experimental results confirm that FiLM outperforms not\nonly existing financial PLMs but also general domain PLMs. Furthermore, we\nprovide empirical evidence that this improvement can be achieved even for\nunseen corpus groups.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1\">Jaeyoung Choe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noh_K/0/1/0/all/0/1\">Keonwoong Noh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Nayeon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1\">Seyun Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_W/0/1/0/all/0/1\">Woohwan Jung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Sharpness-Aware Quantization for Pre-trained Language Models. (arXiv:2310.13315v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13315","description":"<p>Quantization is a promising approach for reducing memory overhead and\naccelerating inference, especially in large pre-trained language model (PLM)\nscenarios. While having no access to original training data due to security and\nprivacy concerns has emerged the demand for zero-shot quantization. Most of the\ncutting-edge zero-shot quantization methods primarily 1) apply to computer\nvision tasks, and 2) neglect of overfitting problem in the generative\nadversarial learning process, leading to sub-optimal performance. Motivated by\nthis, we propose a novel zero-shot sharpness-aware quantization (ZSAQ)\nframework for the zero-shot quantization of various PLMs. The key algorithm in\nsolving ZSAQ is the SAM-SGA optimization, which aims to improve the\nquantization accuracy and model generalization via optimizing a minimax\nproblem. We theoretically prove the convergence rate for the minimax\noptimization problem and this result can be applied to other nonconvex-PL\nminimax optimization frameworks. Extensive experiments on 11 tasks demonstrate\nthat our method brings consistent and significant performance gains on both\ndiscriminative and generative PLMs, i.e., up to +6.98 average score.\nFurthermore, we empirically validate that our method can effectively improve\nthe model generalization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Miaoxi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Juhua Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bo Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Coarse-to-Fine Dual Encoders are Better Frame Identification Learners. (arXiv:2310.13316v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13316","description":"<p>Frame identification aims to find semantic frames associated with target\nwords in a sentence. Recent researches measure the similarity or matching score\nbetween targets and candidate frames by modeling frame definitions. However,\nthey either lack sufficient representation learning of the definitions or face\nchallenges in efficiently selecting the most suitable frame from over 1000\ncandidate frames. Moreover, commonly used lexicon filtering ($lf$) to obtain\ncandidate frames for the target may ignore out-of-vocabulary targets and cause\ninadequate frame modeling. In this paper, we propose CoFFTEA, a\n$\\underline{Co}$arse-to-$\\underline{F}$ine $\\underline{F}$rame and\n$\\underline{T}$arget $\\underline{E}$ncoders $\\underline{A}$rchitecture. With\ncontrastive learning and dual encoders, CoFFTEA efficiently and effectively\nmodels the alignment between frames and targets. By employing a coarse-to-fine\ncurriculum learning procedure, CoFFTEA gradually learns to differentiate frames\nwith varying degrees of similarity. Experimental results demonstrate that\nCoFFTEA outperforms previous models by 0.93 overall scores and 1.53 R@1 without\n$lf$. Further analysis suggests that CoFFTEA can better model the relationships\nbetween frame and frame, as well as target and target. The code for our\napproach is available at https://github.com/pkunlp-icler/COFFTEA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_K/0/1/0/all/0/1\">Kaikai An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Ce Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1\">Bofei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhe Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Hard Samples: Robust and Effective Grammatical Error Correction with Cycle Self-Augmenting. (arXiv:2310.13321v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13321","description":"<p>Recent studies have revealed that grammatical error correction methods in the\nsequence-to-sequence paradigm are vulnerable to adversarial attack, and simply\nutilizing adversarial examples in the pre-training or post-training process can\nsignificantly enhance the robustness of GEC models to certain types of attack\nwithout suffering too much performance loss on clean data. In this paper, we\nfurther conduct a thorough robustness evaluation of cutting-edge GEC methods\nfor four different types of adversarial attacks and propose a simple yet very\neffective Cycle Self-Augmenting (CSA) method accordingly. By leveraging the\naugmenting data from the GEC models themselves in the post-training process and\nintroducing regularization data for cycle training, our proposed method can\neffectively improve the model robustness of well-trained GEC models with only a\nfew more training epochs as an extra cost. More concretely, further training on\nthe regularization data can prevent the GEC models from over-fitting on\neasy-to-learn samples and thus can improve the generalization capability and\nrobustness towards unseen data (adversarial noise/samples). Meanwhile, the\nself-augmented data can provide more high-quality pseudo pairs to improve model\nperformance on the original testing data. Experiments on four benchmark\ndatasets and seven strong models indicate that our proposed training method can\nsignificantly enhance the robustness of four types of attacks without using\npurposely built adversarial examples in training. Evaluation results on clean\ndata further confirm that our proposed CSA method significantly improves the\nperformance of four baselines and yields nearly comparable results with other\nstate-of-the-art models. Our code is available at\nhttps://github.com/ZetangForward/CSA-GEC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zecheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_K/0/1/0/all/0/1\">Kaifeng Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juntao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Democratizing Reasoning Ability: Tailored Learning from Large Language Model. (arXiv:2310.13332v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13332","description":"<p>Large language models (LLMs) exhibit impressive emergent abilities in natural\nlanguage processing, but their democratization is hindered due to huge\ncomputation requirements and closed-source nature. Recent research on advancing\nopen-source smaller LMs by distilling knowledge from black-box LLMs has\nobtained promising results in the instruction-following ability. However, the\nreasoning ability which is more challenging to foster, is relatively rarely\nexplored. In this paper, we propose a tailored learning approach to distill\nsuch reasoning ability to smaller LMs to facilitate the democratization of the\nexclusive reasoning ability. In contrast to merely employing LLM as a data\nannotator, we exploit the potential of LLM as a reasoning teacher by building\nan interactive multi-round learning paradigm. This paradigm enables the student\nto expose its deficiencies to the black-box teacher who then can provide\ncustomized training data in return. Further, to exploit the reasoning potential\nof the smaller LM, we propose self-reflection learning to motivate the student\nto learn from self-made mistakes. The learning from self-reflection and LLM are\nall tailored to the student's learning status, thanks to the seamless\nintegration with the multi-round learning paradigm. Comprehensive experiments\nand analysis on mathematical and commonsense reasoning tasks demonstrate the\neffectiveness of our method. The code will be available at\nhttps://github.com/Raibows/Learn-to-Reason.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhaoyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yuxuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiahai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1\">Minghui Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haizhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weiwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1\">Feng Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large-Scale and Multi-Perspective Opinion Summarization with Diverse Review Subsets. (arXiv:2310.13340v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13340","description":"<p>Opinion summarization is expected to digest larger review sets and provide\nsummaries from different perspectives. However, most existing solutions are\ndeficient in epitomizing extensive reviews and offering opinion summaries from\nvarious angles due to the lack of designs for information selection. To this\nend, we propose SUBSUMM, a supervised summarization framework for large-scale\nmulti-perspective opinion summarization. SUBSUMM consists of a review sampling\nstrategy set and a two-stage training scheme. The sampling strategies take\nsentiment orientation and contrastive information value into consideration,\nwith which the review subsets from different perspectives and quality levels\ncan be selected. Subsequently, the summarizer is encouraged to learn from the\nsub-optimal and optimal subsets successively in order to capitalize on the\nmassive input. Experimental results on AmaSum and Rotten Tomatoes datasets\ndemonstrate that SUBSUMM is adept at generating pros, cons, and verdict\nsummaries from hundreds of input reviews. Furthermore, our in-depth analysis\nverifies that the advanced selection of review subsets and the two-stage\ntraining scheme are vital to boosting the summarization performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Han Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1\">Zhihua Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinpeng Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Challenges and Contributing Factors in the Utilization of Large Language Models (LLMs). (arXiv:2310.13343v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13343","description":"<p>With the development of large language models (LLMs) like the GPT series,\ntheir widespread use across various application scenarios presents a myriad of\nchallenges. This review initially explores the issue of domain specificity,\nwhere LLMs may struggle to provide precise answers to specialized questions\nwithin niche fields. The problem of knowledge forgetting arises as these LLMs\nmight find it hard to balance old and new information. The knowledge repetition\nphenomenon reveals that sometimes LLMs might deliver overly mechanized\nresponses, lacking depth and originality. Furthermore, knowledge illusion\ndescribes situations where LLMs might provide answers that seem insightful but\nare actually superficial, while knowledge toxicity focuses on harmful or biased\ninformation outputs. These challenges underscore problems in the training data\nand algorithmic design of LLMs. To address these issues, it's suggested to\ndiversify training data, fine-tune models, enhance transparency and\ninterpretability, and incorporate ethics and fairness training. Future\ntechnological trends might lean towards iterative methodologies, multimodal\nlearning, model personalization and customization, and real-time learning and\nfeedback mechanisms. In conclusion, future LLMs should prioritize fairness,\ntransparency, and ethics, ensuring they uphold high moral and ethical standards\nwhen serving humanity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaoliang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Liangbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_L/0/1/0/all/0/1\">Le Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yunhe Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yuxuan Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxiao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dinuo Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing Cognitive Plausibility of Subword Tokenization. (arXiv:2310.13348v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13348","description":"<p>Subword tokenization has become the de-facto standard for tokenization,\nalthough comparative evaluations of subword vocabulary quality across languages\nare scarce. Existing evaluation studies focus on the effect of a tokenization\nalgorithm on the performance in downstream tasks, or on engineering criteria\nsuch as the compression rate. We present a new evaluation paradigm that focuses\non the cognitive plausibility of subword tokenization. We analyze the\ncorrelation of the tokenizer output with the response time and accuracy of\nhuman performance on a lexical decision task. We compare three tokenization\nalgorithms across several languages and vocabulary sizes. Our results indicate\nthat the UnigramLM algorithm yields less cognitively plausible tokenization\nbehavior and a worse coverage of derivational morphemes, in contrast with prior\nwork.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Beinborn_L/0/1/0/all/0/1\">Lisa Beinborn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pinter_Y/0/1/0/all/0/1\">Yuval Pinter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation. (arXiv:2310.13361v1 [cs.CV])","link":"http://arxiv.org/abs/2310.13361","description":"<p>Multimodal machine translation (MMT) simultaneously takes the source sentence\nand a relevant image as input for translation. Since there is no paired image\navailable for the input sentence in most cases, recent studies suggest\nutilizing powerful text-to-image generation models to provide image inputs.\nNevertheless, synthetic images generated by these models often follow different\ndistributions compared to authentic images. Consequently, using authentic\nimages for training and synthetic images for inference can introduce a\ndistribution shift, resulting in performance degradation during inference. To\ntackle this challenge, in this paper, we feed synthetic and authentic images to\nthe MMT model, respectively. Then we minimize the gap between the synthetic and\nauthentic images by drawing close the input image representations of the\nTransformer Encoder and the output distributions of the Transformer Decoder.\nTherefore, we mitigate the distribution disparity introduced by the synthetic\nimages during inference, thereby freeing the authentic images from the\ninference process.Experimental results show that our approach achieves\nstate-of-the-art performance on the Multi30K En-De and En-Fr datasets, while\nremaining independent of authentic images during inference.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wenyu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Q/0/1/0/all/0/1\">Qingkai Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1\">Dong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards General Error Diagnosis via Behavioral Testing in Machine Translation. (arXiv:2310.13362v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13362","description":"<p>Behavioral testing offers a crucial means of diagnosing linguistic errors and\nassessing capabilities of NLP models. However, applying behavioral testing to\nmachine translation (MT) systems is challenging as it generally requires human\nefforts to craft references for evaluating the translation quality of such\nsystems on newly generated test cases. Existing works in behavioral testing of\nMT systems circumvent this by evaluating translation quality without\nreferences, but this restricts diagnosis to specific types of errors, such as\nincorrect translation of single numeric or currency words. In order to diagnose\ngeneral errors, this paper proposes a new Bilingual Translation Pair Generation\nbased Behavior Testing (BTPGBT) framework for conducting behavioral testing of\nMT systems. The core idea of BTPGBT is to employ a novel bilingual translation\npair generation (BTPG) approach that automates the construction of high-quality\ntest cases and their pseudoreferences. Experimental results on various MT\nsystems demonstrate that BTPGBT could provide comprehensive and accurate\nbehavioral testing results for general error diagnosis, which further leads to\nseveral insightful findings. Our code and data are available at https:\n//github.com/wujunjie1998/BTPGBT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Junjie Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1\">Dit-Yan Yeung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Human-Robot Mutual Learning System with Affect-Grounded Language Acquisition and Differential Outcomes Training. (arXiv:2310.13377v1 [cs.RO])","link":"http://arxiv.org/abs/2310.13377","description":"<p>This paper presents a novel human-robot interaction setup for robot and human\nlearning of symbolic language for identifying robot homeostatic needs. The\nrobot and human learn to use and respond to the same language symbols that\nconvey homeostatic needs and the stimuli that satisfy the homeostatic needs,\nrespectively. We adopted a differential outcomes training (DOT) protocol\nwhereby the robot provides feedback specific (differential) to its internal\nneeds (e.g. `hunger') when satisfied by the correct stimulus (e.g. cookie). We\nfound evidence that DOT can enhance the human's learning efficiency, which in\nturn enables more efficient robot language acquisition. The robot used in the\nstudy has a vocabulary similar to that of a human infant in the linguistic\n``babbling'' phase. The robot software architecture is built upon a model for\naffect-grounded language acquisition where the robot associates vocabulary with\ninternal needs (hunger, thirst, curiosity) through interactions with the human.\nThe paper presents the results of an initial pilot study conducted with the\ninteractive setup, which reveal that the robot's language acquisition achieves\nhigher convergence rate in the DOT condition compared to the non-DOT control\ncondition. Additionally, participants reported positive affective experiences,\nfeeling of being in control, and an empathetic connection with the robot. This\nmutual learning (teacher-student learning) approach offers a potential\ncontribution of facilitating cognitive interventions with DOT (e.g. for people\nwith dementia) through increased therapy adherence as a result of engaging\nhumans more in training tasks by taking an active teaching-learning role. The\nhomeostatic motivational grounding of the robot's language acquisition has\npotential to contribute to more ecologically valid and social\n(collaborative/nurturing) interactions with robots.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Markelius_A/0/1/0/all/0/1\">Alva Markelius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sjoberg_S/0/1/0/all/0/1\">Sofia Sj&#xf6;berg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lemhauori_Z/0/1/0/all/0/1\">Zakaria Lemhauori</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1\">Laura Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergstrom_M/0/1/0/all/0/1\">Martin Bergstr&#xf6;m</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lowe_R/0/1/0/all/0/1\">Robert Lowe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canamero_L/0/1/0/all/0/1\">Lola Ca&#xf1;amero</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"APP: Adaptive Prototypical Pseudo-Labeling for Few-shot OOD Detection. (arXiv:2310.13380v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13380","description":"<p>Detecting out-of-domain (OOD) intents from user queries is essential for a\ntask-oriented dialogue system. Previous OOD detection studies generally work on\nthe assumption that plenty of labeled IND intents exist. In this paper, we\nfocus on a more practical few-shot OOD setting where there are only a few\nlabeled IND data and massive unlabeled mixed data that may belong to IND or\nOOD. The new scenario carries two key challenges: learning discriminative\nrepresentations using limited IND data and leveraging unlabeled mixed data.\nTherefore, we propose an adaptive prototypical pseudo-labeling (APP) method for\nfew-shot OOD detection, including a prototypical OOD detection framework\n(ProtoOOD) to facilitate low-resource OOD detection using limited IND data, and\nan adaptive pseudo-labeling method to produce high-quality pseudo OOD\\&amp;IND\nlabels. Extensive experiments and analysis demonstrate the effectiveness of our\nmethod for few-shot OOD detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1\">Keqing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_Y/0/1/0/all/0/1\">Yutao Mou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xiaoshuai Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yanan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jingang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Y/0/1/0/all/0/1\">Yunsen Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1\">Xunliang Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weiran Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tuna: Instruction Tuning using Feedback from Large Language Models. (arXiv:2310.13385v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13385","description":"<p>Instruction tuning of open-source large language models (LLMs) like LLaMA,\nusing direct outputs from more powerful LLMs such as Instruct-GPT and GPT-4,\nhas proven to be a cost-effective way to align model behaviors with human\npreferences. However, the instruction-tuned model has only seen one response\nper instruction, lacking the knowledge of potentially better responses. In this\npaper, we propose finetuning an instruction-tuned LLM using our novel\n\\textit{probabilistic ranking} and \\textit{contextual ranking} approaches to\nincrease the likelihood of generating better responses. Probabilistic ranking\nenables the instruction-tuned model to inherit the relative rankings of\nhigh-quality and low-quality responses from the teacher LLM. On the other hand,\nlearning with contextual ranking allows the model to refine its own response\ndistribution using the contextual understanding ability of stronger LLMs.\nFurthermore, we apply probabilistic ranking and contextual ranking sequentially\nto the instruction-tuned LLM. The resulting model, which we call \\textbf{Tuna},\nconsistently improves the performance on Super Natural Instructions (119 test\ntasks), LMentry (25 test tasks), Vicuna QA, and can even obtain better results\nthan several strong reinforcement learning baselines. Our code and data are\navailable at \\url{ https://github.com/microsoft/LMOps}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yiran Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xingxing Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"POSQA: Probe the World Models of LLMs with Size Comparisons. (arXiv:2310.13394v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13394","description":"<p>Embodied language comprehension emphasizes that language understanding is not\nsolely a matter of mental processing in the brain but also involves\ninteractions with the physical and social environment. With the explosive\ngrowth of Large Language Models (LLMs) and their already ubiquitous presence in\nour daily lives, it is becoming increasingly necessary to verify their\nreal-world understanding. Inspired by cognitive theories, we propose POSQA: a\nPhysical Object Size Question Answering dataset with simple size comparison\nquestions to examine the extremity and analyze the potential mechanisms of the\nembodied comprehension of the latest LLMs.\n</p>\n<p>We show that even the largest LLMs today perform poorly under the zero-shot\nsetting. We then push their limits with advanced prompting techniques and\nexternal knowledge augmentation. Furthermore, we investigate whether their\nreal-world comprehension primarily derives from contextual information or\ninternal weights and analyse the impact of prompt formats and report bias of\ndifferent objects. Our results show that real-world understanding that LLMs\nshaped from textual data can be vulnerable to deception and confusion by the\nsurface form of prompts, which makes it less aligned with human behaviours.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shu_C/0/1/0/all/0/1\">Chang Shu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiuzhou Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fangyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cache me if you Can: an Online Cost-aware Teacher-Student framework to Reduce the Calls to Large Language Models. (arXiv:2310.13395v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13395","description":"<p>Prompting Large Language Models (LLMs) performs impressively in zero- and\nfew-shot settings. Hence, small and medium-sized enterprises (SMEs) that cannot\nafford the cost of creating large task-specific training datasets, but also the\ncost of pretraining their own LLMs, are increasingly turning to third-party\nservices that allow them to prompt LLMs. However, such services currently\nrequire a payment per call, which becomes a significant operating expense\n(OpEx). Furthermore, customer inputs are often very similar over time, hence\nSMEs end-up prompting LLMs with very similar instances. We propose a framework\nthat allows reducing the calls to LLMs by caching previous LLM responses and\nusing them to train a local inexpensive model on the SME side. The framework\nincludes criteria for deciding when to trust the local model or call the LLM,\nand a methodology to tune the criteria and measure the tradeoff between\nperformance and cost. For experimental purposes, we instantiate our framework\nwith two LLMs, GPT-3.5 or GPT-4, and two inexpensive students, a k-NN\nclassifier or a Multi-Layer Perceptron, using two common business tasks, intent\nrecognition and sentiment analysis. Experimental results indicate that\nsignificant OpEx savings can be obtained with only slightly lower performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stogiannidis_I/0/1/0/all/0/1\">Ilias Stogiannidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vassos_S/0/1/0/all/0/1\">Stavros Vassos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malakasiotis_P/0/1/0/all/0/1\">Prodromos Malakasiotis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Androutsopoulos_I/0/1/0/all/0/1\">Ion Androutsopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explicit Alignment and Many-to-many Entailment Based Reasoning for Conversational Machine Reading. (arXiv:2310.13409v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13409","description":"<p>Conversational Machine Reading (CMR) requires answering a user's initial\nquestion through multi-turn dialogue interactions based on a given document.\nAlthough there exist many effective methods, they largely neglected the\nalignment between the document and the user-provided information, which\nsignificantly affects the intermediate decision-making and subsequent follow-up\nquestion generation. To address this issue, we propose a pipeline framework\nthat (1) aligns the aforementioned two sides in an explicit way, (2)makes\ndecisions using a lightweight many-to-many entailment reasoning module, and (3)\ndirectly generates follow-up questions based on the document and previously\nasked questions. Our proposed method achieves state-of-the-art in\nmicro-accuracy and ranks the first place on the public leaderboard of the CMR\nbenchmark dataset ShARC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yangyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shiyu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1\">Caixia Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaojie Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Enhancing Relational Rules for Knowledge Graph Link Prediction. (arXiv:2310.13411v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13411","description":"<p>Graph neural networks (GNNs) have shown promising performance for knowledge\ngraph reasoning. A recent variant of GNN called progressive relational graph\nneural network (PRGNN), utilizes relational rules to infer missing knowledge in\nrelational digraphs and achieves notable results. However, during reasoning\nwith PRGNN, two important properties are often overlooked: (1) the\nsequentiality of relation composition, where the order of combining different\nrelations affects the semantics of the relational rules, and (2) the lagged\nentity information propagation, where the transmission speed of required\ninformation lags behind the appearance speed of new entities. Ignoring these\nproperties leads to incorrect relational rule learning and decreased reasoning\naccuracy. To address these issues, we propose a novel knowledge graph reasoning\napproach, the Relational rUle eNhanced Graph Neural Network (RUN-GNN).\nSpecifically, RUN-GNN employs a query related fusion gate unit to model the\nsequentiality of relation composition and utilizes a buffering update mechanism\nto alleviate the negative effect of lagged entity information propagation,\nresulting in higher-quality relational rule learning. Experimental results on\nmultiple datasets demonstrate the superiority of RUN-GNN is superior on both\ntransductive and inductive link prediction tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuhan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1\">Huaiyu Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuting Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1\">Junfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Youfang Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversation Chronicles: Towards Diverse Temporal and Relational Dynamics in Multi-Session Conversations. (arXiv:2310.13420v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13420","description":"<p>In the field of natural language processing, open-domain chatbots have\nemerged as an important research topic. However, a major limitation of existing\nopen-domain chatbot research is its singular focus on short single-session\ndialogue, neglecting the potential need for understanding contextual\ninformation in multiple consecutive sessions that precede an ongoing dialogue.\nAmong the elements that compose the context in multi-session conversation\nsettings, the time intervals between sessions and the relationships between\nspeakers would be particularly important. Despite their importance, current\nresearch efforts have not sufficiently addressed these dialogical components.\nIn this paper, we introduce a new 1M multi-session dialogue dataset, called\nConversation Chronicles, for implementing a long-term conversation setup in\nwhich time intervals and fine-grained speaker relationships are incorporated.\nFollowing recent works, we exploit a large language model to produce the data.\nThe extensive human evaluation shows that dialogue episodes in Conversation\nChronicles reflect those properties while maintaining coherent and consistent\ninteractions across all the sessions. We also propose a dialogue model, called\nReBot, which consists of chronological summarization and dialogue generation\nmodules using only around 630M parameters. When trained on Conversation\nChronicles, ReBot demonstrates long-term context understanding with a high\nhuman engagement score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jihyoung Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boo_M/0/1/0/all/0/1\">Minseong Boo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyounghun Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Consistency of Large Language Models under Ambiguity. (arXiv:2310.13439v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13439","description":"<p>Large language models (LLMs) that do not give consistent answers across\ncontexts are problematic when used for tasks with expectations of consistency,\ne.g., question-answering, explanations, etc. Our work presents an evaluation\nbenchmark for self-consistency in cases of under-specification where two or\nmore answers can be correct. We conduct a series of behavioral experiments on\nthe OpenAI model suite using an ambiguous integer sequence completion task. We\nfind that average consistency ranges from 67\\% to 82\\%, far higher than would\nbe predicted if a model's consistency was random, and increases as model\ncapability improves. Furthermore, we show that models tend to maintain\nself-consistency across a series of robustness checks, including prompting\nspeaker changes and sequence length changes. These results suggest that\nself-consistency arises as an emergent capability without specifically training\nfor it. Despite this, we find that models are uncalibrated when judging their\nown consistency, with models displaying both over- and under-confidence. We\nalso propose a nonparametric test for determining from token output\ndistribution whether a model assigns non-trivial probability to alternative\nanswers. Using this test, we find that despite increases in self-consistency,\nmodels usually place significant weight on alternative, inconsistent answers.\nThis distribution of probability mass provides evidence that even highly\nself-consistent models internally compute multiple possible responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bartsch_H/0/1/0/all/0/1\">Henning Bartsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jorgensen_O/0/1/0/all/0/1\">Ole Jorgensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosati_D/0/1/0/all/0/1\">Domenic Rosati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoelscher_Obermaier_J/0/1/0/all/0/1\">Jason Hoelscher-Obermaier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfau_J/0/1/0/all/0/1\">Jacob Pfau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Past, Present, and Future of Typological Databases in NLP. (arXiv:2310.13440v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13440","description":"<p>Typological information has the potential to be beneficial in the development\nof NLP models, particularly for low-resource languages. Unfortunately, current\nlarge-scale typological databases, notably WALS and Grambank, are inconsistent\nboth with each other and with other sources of typological information, such as\nlinguistic grammars. Some of these inconsistencies stem from coding errors or\nlinguistic variation, but many of the disagreements are due to the discrete\ncategorical nature of these databases. We shed light on this issue by\nsystematically exploring disagreements across typological databases and\nresources, and their uses in NLP, covering the past and present. We next\ninvestigate the future of such work, offering an argument that a continuous\nview of typological features is clearly beneficial, echoing recommendations\nfrom linguistics. We propose that such a view of typology has significant\npotential in the future, including in language modeling in low-resource\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baylor_E/0/1/0/all/0/1\">Emi Baylor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ploeger_E/0/1/0/all/0/1\">Esther Ploeger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bjerva_J/0/1/0/all/0/1\">Johannes Bjerva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation. (arXiv:2310.13447v1 [cs.CV])","link":"http://arxiv.org/abs/2310.13447","description":"<p>Within the multimodal field, the key to integrating vision and language lies\nin establishing a good alignment strategy. Recently, benefiting from the\nsuccess of self-supervised learning, significant progress has been made in\nmultimodal semantic representation based on pre-trained models for vision and\nlanguage. However, there is still room for improvement in visual semantic\nrepresentation. The lack of spatial semantic coherence and vulnerability to\nnoise makes it challenging for current pixel or patch-based methods to\naccurately extract complex scene boundaries. To this end, this paper develops\nsuperpixel as a comprehensive compact representation of learnable image data,\nwhich effectively reduces the number of visual primitives for subsequent\nprocessing by clustering perceptually similar pixels. To mine more precise\ntopological relations, we propose a Multiscale Difference Graph Convolutional\nNetwork (MDGCN). It parses the entire image as a fine-to-coarse hierarchical\nstructure of constituent visual patterns, and captures multiscale features by\nprogressively merging adjacent superpixels as graph nodes. Moreover, we predict\nthe differences between adjacent nodes through the graph structure,\nfacilitating key information aggregation of graph nodes to reason actual\nsemantic relations. Afterward, we design a multi-level fusion rule in a\nbottom-up manner to avoid understanding deviation by learning complementary\nspatial information at different regional scales. Our proposed method can be\nwell applied to multiple downstream task learning. Extensive experiments\ndemonstrate that our method is competitive with other state-of-the-art methods\nin visual reasoning. Our code will be released upon publication.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Siyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sirui Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yaoru Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1\">Lizhi Bai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning. (arXiv:2310.13448v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13448","description":"<p>Large language models (LLMs) are a promising avenue for machine translation\n(MT). However, current LLM-based MT systems are brittle: their effectiveness\nhighly depends on the choice of few-shot examples and they often require extra\npost-processing due to overgeneration. Alternatives such as finetuning on\ntranslation instructions are computationally expensive and may weaken\nin-context learning capabilities, due to overspecialization. In this paper, we\nprovide a closer look at this problem. We start by showing that adapter-based\nfinetuning with LoRA matches the performance of traditional finetuning while\nreducing the number of training parameters by a factor of 50. This method also\noutperforms few-shot prompting and eliminates the need for post-processing or\nin-context examples. However, we show that finetuning generally degrades\nfew-shot performance, hindering adaptation capabilities. Finally, to obtain the\nbest of both worlds, we propose a simple approach that incorporates few-shot\nexamples during finetuning. Experiments on 10 language pairs show that our\nproposed approach recovers the original few-shot capabilities while keeping the\nadded benefits of finetuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alves_D/0/1/0/all/0/1\">Duarte M. Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerreiro_N/0/1/0/all/0/1\">Nuno M. Guerreiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_J/0/1/0/all/0/1\">Jo&#xe3;o Alves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pombal_J/0/1/0/all/0/1\">Jos&#xe9; Pombal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rei_R/0/1/0/all/0/1\">Ricardo Rei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souza_J/0/1/0/all/0/1\">Jos&#xe9; G. C. de Souza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colombo_P/0/1/0/all/0/1\">Pierre Colombo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ask Language Model to Clean Your Noisy Translation Data. (arXiv:2310.13469v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13469","description":"<p>Transformer models have demonstrated remarkable performance in neural machine\ntranslation (NMT). However, their vulnerability to noisy input poses a\nsignificant challenge in practical implementation, where generating clean\noutput from noisy input is crucial. The MTNT dataset \\cite{MTNT} is widely used\nas a benchmark for evaluating the robustness of NMT models against noisy input.\nNevertheless, its utility is limited due to the presence of noise in both the\nsource and target sentences. To address this limitation, we focus on cleaning\nthe noise from the target sentences in MTNT, making it more suitable as a\nbenchmark for noise evaluation. Leveraging the capabilities of large language\nmodels (LLMs), we observe their impressive abilities in noise removal. For\nexample, they can remove emojis while considering their semantic meaning.\nAdditionally, we show that LLM can effectively rephrase slang, jargon, and\nprofanities. The resulting datasets, called C-MTNT, exhibit significantly less\nnoise in the target sentences while preserving the semantic integrity of the\noriginal sentences. Our human and GPT-4 evaluations also lead to a consistent\nconclusion that LLM performs well on this task. Lastly, experiments on C-MTNT\nshowcased its effectiveness in evaluating the robustness of NMT models,\nhighlighting the potential of advanced language models for data cleaning and\nemphasizing C-MTNT as a valuable resource.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bolding_Q/0/1/0/all/0/1\">Quinten Bolding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1\">Baohao Liao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denis_B/0/1/0/all/0/1\">Brandon James Denis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mind the instructions: a holistic evaluation of consistency and interactions in prompt-based learning. (arXiv:2310.13486v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13486","description":"<p>Finding the best way of adapting pre-trained language models to a task is a\nbig challenge in current NLP. Just like the previous generation of task-tuned\nmodels (TT), models that are adapted to tasks via in-context-learning (ICL) are\nrobust in some setups but not in others. Here, we present a detailed analysis\nof which design choices cause instabilities and inconsistencies in LLM\npredictions. First, we show how spurious correlations between input\ndistributions and labels -- a known issue in TT models -- form only a minor\nproblem for prompted models. Then, we engage in a systematic, holistic\nevaluation of different factors that have been found to influence predictions\nin a prompting setup. We test all possible combinations of a range of factors\non both vanilla and instruction-tuned (IT) LLMs of different scale and\nstatistically analyse the results to show which factors are the most\ninfluential, interactive or stable. Our results show which factors can be used\nwithout precautions and which should be avoided or handled with care in most\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Weber_L/0/1/0/all/0/1\">Lucas Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1\">Elia Bruni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1\">Dieuwke Hupkes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DistillCSE: Distilled Contrastive Learning for Sentence Embeddings. (arXiv:2310.13499v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13499","description":"<p>This paper proposes the DistillCSE framework, which performs contrastive\nlearning under the self-training paradigm with knowledge distillation. The\npotential advantage of DistillCSE is its self-enhancing feature: using a base\nmodel to provide additional supervision signals, a stronger model may be\nlearned through knowledge distillation. However, the vanilla DistillCSE through\nthe standard implementation of knowledge distillation only achieves marginal\nimprovements due to severe overfitting. The further quantitative analyses\ndemonstrate the reason that the standard knowledge distillation exhibits a\nrelatively large variance of the teacher model's logits due to the essence of\ncontrastive learning. To mitigate the issue induced by high variance, this\npaper accordingly proposed two simple yet effective solutions for knowledge\ndistillation: a Group-P shuffling strategy as an implicit regularization and\nthe averaging logits from multiple teacher components. Experiments on standard\nbenchmarks demonstrate that the proposed DistillCSE outperforms many strong\nbaseline methods and yields a new state-of-the-art performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiahao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lihui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analogical Proportions and Creativity: A Preliminary Study. (arXiv:2310.13500v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13500","description":"<p>Analogical proportions are statements of the form \"$a$ is to $b$ as $c$ is to\n$d$\", which expresses that the comparisons of the elements in pair $(a, b)$ and\nin pair $(c, d)$ yield similar results. Analogical proportions are creative in\nthe sense that given 3 distinct items, the representation of a 4th item $d$,\ndistinct from the previous items, which forms an analogical proportion with\nthem can be calculated, provided certain conditions are met. After providing an\nintroduction to analogical proportions and their properties, the paper reports\nthe results of an experiment made with a database of animal descriptions and\ntheir class, where we try to \"create\" new animals from existing ones,\nretrieving rare animals such as platypus. We perform a series of experiments\nusing word embeddings as well as Boolean features in order to propose novel\nanimals based on analogical proportions, showing that word embeddings obtain\nbetter results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Afantenos_S/0/1/0/all/0/1\">Stergos Afantenos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prade_H/0/1/0/all/0/1\">Henri Prade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernardes_L/0/1/0/all/0/1\">Leonardo Cortez Bernardes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation. (arXiv:2310.13505v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13505","description":"<p>Models for conversational question answering (ConvQA) over knowledge graphs\n(KGs) are usually trained and tested on benchmarks of gold QA pairs. This\nimplies that training is limited to surface forms seen in the respective\ndatasets, and evaluation is on a small set of held-out questions. Through our\nproposed framework REIGN, we take several steps to remedy this restricted\nlearning setup. First, we systematically generate reformulations of training\nquestions to increase robustness of models to surface form variations. This is\na particularly challenging problem, given the incomplete nature of such\nquestions. Second, we guide ConvQA models towards higher performance by feeding\nit only those reformulations that help improve their answering quality, using\ndeep reinforcement learning. Third, we demonstrate the viability of training\nmajor model components on one benchmark and applying them zero-shot to another.\nFinally, for a rigorous evaluation of robustness for trained models, we use and\nrelease large numbers of diverse reformulations generated by prompting GPT for\nbenchmark test sets (resulting in 20x increase in sizes). Our findings show\nthat ConvQA models with robust training via reformulations, significantly\noutperform those with standard training from gold QA pairs only.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaiser_M/0/1/0/all/0/1\">Magdalena Kaiser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1\">Rishiraj Saha Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weikum_G/0/1/0/all/0/1\">Gerhard Weikum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explaining Interactions Between Text Spans. (arXiv:2310.13506v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13506","description":"<p>Reasoning over spans of tokens from different parts of the input is essential\nfor natural language understanding (NLU) tasks such as fact-checking (FC),\nmachine reading comprehension (MRC) or natural language inference (NLI).\nHowever, existing highlight-based explanations primarily focus on identifying\nindividual important tokens or interactions only between adjacent tokens or\ntuples of tokens. Most notably, there is a lack of annotations capturing the\nhuman decision-making process w.r.t. the necessary interactions for informed\ndecision-making in such tasks. To bridge this gap, we introduce SpanEx, a\nmulti-annotator dataset of human span interaction explanations for two NLU\ntasks: NLI and FC. We then investigate the decision-making processes of\nmultiple fine-tuned large language models in terms of the employed connections\nbetween spans in separate parts of the input and compare them to the human\nreasoning processes. Finally, we present a novel community detection based\nunsupervised method to extract such interaction explanations from a model's\ninner workings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_S/0/1/0/all/0/1\">Sagnik Ray Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atanasova_P/0/1/0/all/0/1\">Pepa Atanasova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Question Generation with Multi-level Content Planning. (arXiv:2310.13512v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13512","description":"<p>This paper addresses the problem of generating questions from a given context\nand an answer, specifically focusing on questions that require multi-hop\nreasoning across an extended context. Previous studies have suggested that key\nphrase selection is essential for question generation (QG), yet it is still\nchallenging to connect such disjointed phrases into meaningful questions,\nparticularly for long context. To mitigate this issue, we propose MultiFactor,\na novel QG framework based on multi-level content planning. Specifically,\nMultiFactor includes two components: FA-model, which simultaneously selects key\nphrases and generates full answers, and Q-model which takes the generated full\nanswer as an additional input to generate questions. Here, full answer\ngeneration is introduced to connect the short answer with the selected key\nphrases, thus forming an answer-aware summary to facilitate QG. Both FA-model\nand Q-model are formalized as simple-yet-effective Phrase-Enhanced\nTransformers, our joint model for phrase selection and text generation.\nExperimental results show that our method outperforms strong baselines on two\npopular QG datasets. Our code is available at\nhttps://github.com/zeaver/MultiFactor.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1\">Zehua Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gou_Q/0/1/0/all/0/1\">Qi Gou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1\">Bowen Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Haiyang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Cam-Tu Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Language Models to Self-Improve through Interactive Demonstrations. (arXiv:2310.13522v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13522","description":"<p>The self-improving ability of large language models (LLMs), enabled by\nprompting them to analyze and revise their own outputs, has garnered\nsignificant interest in recent research. However, this ability has been shown\nto be absent and difficult to learn for smaller models, thus widening the\nperformance gap between state-of-the-art LLMs and more cost-effective and\nfaster ones. To reduce this gap, we introduce TriPosT, a training algorithm\nthat endows smaller models with such self-improvement ability, and show that\nour approach can improve a LLaMA-7b's performance on math and reasoning tasks\nby up to 7.13%. In contrast to prior work, we achieve this by using the smaller\nmodel to interact with LLMs to collect feedback and improvements on its own\ngenerations. We then replay this experience to train the small model. Our\nexperiments on four math and reasoning datasets show that the interactive\nexperience of learning from and correcting its own mistakes is crucial for\nsmall models to improve their performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controlled Randomness Improves the Performance of Transformer Models. (arXiv:2310.13526v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13526","description":"<p>During the pre-training step of natural language models, the main objective\nis to learn a general representation of the pre-training dataset, usually\nrequiring large amounts of textual data to capture the complexity and diversity\nof natural language. Contrasting this, in most cases, the size of the data\navailable to solve the specific downstream task is often dwarfed by the\naforementioned pre-training dataset, especially in domains where data is\nscarce. We introduce controlled randomness, i.e. noise, into the training\nprocess to improve fine-tuning language models and explore the performance of\ntargeted noise in addition to the parameters of these models. We find that\nadding such noise can improve the performance in our two downstream tasks of\njoint named entity recognition and relation extraction and text summarization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deusser_T/0/1/0/all/0/1\">Tobias Deu&#xdf;er</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Cong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramer_W/0/1/0/all/0/1\">Wolfgang Kr&#xe4;mer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leonhard_D/0/1/0/all/0/1\">David Leonhard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bauckhage_C/0/1/0/all/0/1\">Christian Bauckhage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sifa_R/0/1/0/all/0/1\">Rafet Sifa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Diachronic Perspective on User Trust in AI under Uncertainty. (arXiv:2310.13544v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13544","description":"<p>In a human-AI collaboration, users build a mental model of the AI system\nbased on its reliability and how it presents its decision, e.g. its\npresentation of system confidence and an explanation of the output. Modern NLP\nsystems are often uncalibrated, resulting in confidently incorrect predictions\nthat undermine user trust. In order to build trustworthy AI, we must understand\nhow user trust is developed and how it can be regained after potential\ntrust-eroding events. We study the evolution of user trust in response to these\ntrust-eroding events using a betting game. We find that even a few incorrect\ninstances with inaccurate confidence estimates damage user trust and\nperformance, with very slow recovery. We also show that this degradation in\ntrust reduces the success of human-AI collaboration and that different types of\nmiscalibration -- unconfidently correct and confidently incorrect -- have\ndifferent negative effects on user trust. Our findings highlight the importance\nof calibration in user-facing AI applications and shed light on what aspects\nhelp users decide whether to trust the AI system.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dhuliawala_S/0/1/0/all/0/1\">Shehzaad Dhuliawala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+El_Assady_M/0/1/0/all/0/1\">Mennatallah El-Assady</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Understanding Sycophancy in Language Models. (arXiv:2310.13548v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13548","description":"<p>Reinforcement learning from human feedback (RLHF) is a popular technique for\ntraining high-quality AI assistants. However, RLHF may also encourage model\nresponses that match user beliefs over truthful responses, a behavior known as\nsycophancy. We investigate the prevalence of sycophancy in RLHF-trained models\nand whether human preference judgements are responsible. We first demonstrate\nthat five state-of-the-art AI assistants consistently exhibit sycophantic\nbehavior across four varied free-form text-generation tasks. To understand if\nhuman preferences drive this broadly observed behavior of RLHF models, we\nanalyze existing human preference data. We find that when a response matches a\nuser's views, it is more likely to be preferred. Moreover, both humans and\npreference models (PMs) prefer convincingly-written sycophantic responses over\ncorrect ones a negligible fraction of the time. Optimizing model outputs\nagainst PMs also sometimes sacrifices truthfulness in favor of sycophancy.\nOverall, our results indicate that sycophancy is a general behavior of RLHF\nmodels, likely driven in part by human preference judgements favoring\nsycophantic responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1\">Mrinank Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tong_M/0/1/0/all/0/1\">Meg Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korbak_T/0/1/0/all/0/1\">Tomasz Korbak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1\">David Duvenaud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Askell_A/0/1/0/all/0/1\">Amanda Askell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_N/0/1/0/all/0/1\">Newton Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durmus_E/0/1/0/all/0/1\">Esin Durmus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hatfield_Dodds_Z/0/1/0/all/0/1\">Zac Hatfield-Dodds</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnston_S/0/1/0/all/0/1\">Scott R. Johnston</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kravec_S/0/1/0/all/0/1\">Shauna Kravec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maxwell_T/0/1/0/all/0/1\">Timothy Maxwell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1\">Sam McCandlish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ndousse_K/0/1/0/all/0/1\">Kamal Ndousse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rausch_O/0/1/0/all/0/1\">Oliver Rausch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiefer_N/0/1/0/all/0/1\">Nicholas Schiefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1\">Da Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Miranda Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_E/0/1/0/all/0/1\">Ethan Perez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Perils & Promises of Fact-checking with Large Language Models. (arXiv:2310.13549v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13549","description":"<p>Autonomous fact-checking, using machine learning to verify claims, has grown\nvital as misinformation spreads beyond human fact-checking capacity. Large\nLanguage Models (LLMs) like GPT-4 are increasingly trusted to verify\ninformation and write academic papers, lawsuits, and news articles, emphasizing\ntheir role in discerning truth from falsehood and the importance of being able\nto verify their outputs. Here, we evaluate the use of LLM agents in\nfact-checking by having them phrase queries, retrieve contextual data, and make\ndecisions. Importantly, in our framework, agents explain their reasoning and\ncite the relevant sources from the retrieved context. Our results show the\nenhanced prowess of LLMs when equipped with contextual information. GPT-4\noutperforms GPT-3, but accuracy varies based on query language and claim\nveracity. While LLMs show promise in fact-checking, caution is essential due to\ninconsistent accuracy. Our investigation calls for further research, fostering\na deeper comprehension of when agents succeed and when they fail.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Quelle_D/0/1/0/all/0/1\">Dorian Quelle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bovet_A/0/1/0/all/0/1\">Alexandre Bovet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-prompted Chain-of-Thought on Large Language Models for Open-domain Multi-hop Reasoning. (arXiv:2310.13552v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13552","description":"<p>In open-domain question-answering (ODQA), most existing questions require\nsingle-hop reasoning on commonsense. To further extend this task, we officially\nintroduce open-domain multi-hop reasoning (ODMR) by answering multi-hop\nquestions with explicit reasoning steps in open-domain setting. Recently, large\nlanguage models (LLMs) have found significant utility in facilitating ODQA\nwithout external corpus. Furthermore, chain-of-thought (CoT) prompting boosts\nthe reasoning capability of LLMs to a greater extent with manual or automated\nparadigms. However, existing automated methods lack of quality assurance, while\nmanual approaches suffer from limited scalability and poor diversity, hindering\nthe capabilities of LLMs. In this paper, we propose Self-prompted\nChain-of-Thought (SP-CoT), an automated framework to mass-produce high quality\nCoTs of LLMs, by LLMs and for LLMs. SP-CoT introduces an automated generation\npipeline of high quality ODMR datasets, an adaptive sampler for in-context CoT\nselection and self-prompted inference via in-context learning. Extensive\nexperiments on four multi-hop question-answering benchmarks show that our\nproposed SP-CoT not only significantly surpasses the previous SOTA methods on\nlarge-scale (175B) LLMs, but also nearly doubles the zero-shot performance of\nsmall-scale (13B) LLMs. Further analysis reveals the remarkable capability of\nSP-CoT to elicit direct and concise intermediate reasoning steps by recalling\n$\\sim$50\\% of intermediate answers on MuSiQue-Ans dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jinyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cache & Distil: Optimising API Calls to Large Language Models. (arXiv:2310.13561v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13561","description":"<p>Large-scale deployment of generative AI tools often depends on costly API\ncalls to a Large Language Model (LLM) to fulfil user queries. To curtail the\nfrequency of these calls, one can employ a smaller language model -- a student\n-- which is continuously trained on the responses of the LLM. This student\ngradually gains proficiency in independently handling an increasing number of\nuser requests, a process we term neural caching. The crucial element in neural\ncaching is a policy that decides which requests should be processed by the\nstudent alone and which should be redirected to the LLM, subsequently aiding\nthe student's learning. In this study, we focus on classification tasks, and we\nconsider a range of classic active learning-based selection criteria as the\npolicy. Our experiments suggest that Margin Sampling and Query by Committee\nbring consistent benefits across tasks and budgets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_G/0/1/0/all/0/1\">Guillem Ram&#xed;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lindemann_M/0/1/0/all/0/1\">Matthias Lindemann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Augmented Neural Response Generation Using Logical Reasoning and Relevance Scoring. (arXiv:2310.13566v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13566","description":"<p>Constructing responses in task-oriented dialogue systems typically relies on\ninformation sources such the current dialogue state or external databases. This\npaper presents a novel approach to knowledge-grounded response generation that\ncombines retrieval-augmented language models with logical reasoning. The\napproach revolves around a knowledge graph representing the current dialogue\nstate and background information, and proceeds in three steps. The knowledge\ngraph is first enriched with logically derived facts inferred using\nprobabilistic logical programming. A neural model is then employed at each turn\nto score the conversational relevance of each node and edge of this extended\ngraph. Finally, the elements with highest relevance scores are converted to a\nnatural language form, and are integrated into the prompt for the neural\nconversational model employed to generate the system response.\n</p>\n<p>We investigate the benefits of the proposed approach on two datasets (KVRET\nand GraphWOZ) along with a human evaluation. Experimental results show that the\ncombination of (probabilistic) logical reasoning with conversational relevance\nscoring does increase both the factuality and fluency of the responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Walker_N/0/1/0/all/0/1\">Nicholas Thomas Walker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ultes_S/0/1/0/all/0/1\">Stefan Ultes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lison_P/0/1/0/all/0/1\">Pierre Lison</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why Can Large Language Models Generate Correct Chain-of-Thoughts?. (arXiv:2310.13571v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13571","description":"<p>This paper delves into the capabilities of large language models (LLMs),\nspecifically focusing on advancing the theoretical comprehension of\nchain-of-thought prompting. We investigate how LLMs can be effectively induced\nto generate a coherent chain of thoughts. To achieve this, we introduce a\ntwo-level hierarchical graphical model tailored for natural language\ngeneration. Within this framework, we establish a compelling geometrical\nconvergence rate that gauges the likelihood of an LLM-generated chain of\nthoughts compared to those originating from the true language. Our findings\nprovide a theoretical justification for the ability of LLMs to produce the\ncorrect sequence of thoughts (potentially) explaining performance gains in\ntasks demanding reasoning skills.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1\">Rasul Tutunov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosnit_A/0/1/0/all/0/1\">Antoine Grosnit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ziomek_J/0/1/0/all/0/1\">Juliusz Ziomek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1\">Haitham Bou-Ammar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Decomposition of Question and SQL for Text-to-SQL Parsing. (arXiv:2310.13575v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13575","description":"<p>Text-to-SQL semantic parsing faces challenges in generalizing to cross-domain\nand complex queries. Recent research has employed a question decomposition\nstrategy to enhance the parsing of complex SQL queries. However, this strategy\nencounters two major obstacles: (1) existing datasets lack question\ndecomposition; (2) due to the syntactic complexity of SQL, most complex queries\ncannot be disentangled into sub-queries that can be readily recomposed. To\naddress these challenges, we propose a new modular Query Plan Language (QPL)\nthat systematically decomposes SQL queries into simple and regular sub-queries.\nWe develop a translator from SQL to QPL by leveraging analysis of SQL server\nquery optimization plans, and we augment the Spider dataset with QPL programs.\nExperimental results demonstrate that the modular nature of QPL benefits\nexisting semantic-parsing architectures, and training text-to-QPL parsers is\nmore effective than text-to-SQL parsing for semantically equivalent queries.\nThe QPL approach offers two additional advantages: (1) QPL programs can be\nparaphrased as simple questions, which allows us to create a dataset of\n(complex question, decomposed questions). Training on this dataset, we obtain a\nQuestion Decomposer for data retrieval that is sensitive to database schemas.\n(2) QPL is more accessible to non-experts for complex queries, leading to more\ninterpretable output from the semantic parser.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eyal_B/0/1/0/all/0/1\">Ben Eyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bachar_A/0/1/0/all/0/1\">Amir Bachar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haroche_O/0/1/0/all/0/1\">Ophir Haroche</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahabi_M/0/1/0/all/0/1\">Moran Mahabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elhadad_M/0/1/0/all/0/1\">Michael Elhadad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering. (arXiv:2310.13583v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13583","description":"<p>Despite the impressive growth of the abilities of multilingual language\nmodels, such as XLM-R and mT5, it has been shown that they still face\ndifficulties when tackling typologically-distant languages, particularly in the\nlow-resource setting. One obstacle for effective cross-lingual transfer is\nvariability in word-order patterns. It can be potentially mitigated via source-\nor target-side word reordering, and numerous approaches to reordering have been\nproposed. However, they rely on language-specific rules, work on the level of\nPOS tags, or only target the main clause, leaving subordinate clauses intact.\nTo address these limitations, we present a new powerful reordering method,\ndefined in terms of Universal Dependencies, that is able to learn fine-grained\nword-order patterns conditioned on the syntactic context from a small amount of\nannotated data and can be applied at all levels of the syntactic tree. We\nconduct experiments on a diverse set of tasks and show that our method\nconsistently outperforms strong baselines over different language pairs and\nmodel architectures. This performance advantage holds true in both zero-shot\nand few-shot scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arviv_O/0/1/0/all/0/1\">Ofir Arviv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1\">Dmitry Nikolaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karidi_T/0/1/0/all/0/1\">Taelin Karidi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1\">Omri Abend</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simultaneous Machine Translation with Tailored Reference. (arXiv:2310.13588v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13588","description":"<p>Simultaneous machine translation (SiMT) generates translation while reading\nthe whole source sentence. However, existing SiMT models are typically trained\nusing the same reference disregarding the varying amounts of available source\ninformation at different latency. Training the model with ground-truth at low\nlatency may introduce forced anticipations, whereas utilizing reference\nconsistent with the source word order at high latency results in performance\ndegradation. Consequently, it is crucial to train the SiMT model with\nappropriate reference that avoids forced anticipations during training while\nmaintaining high quality. In this paper, we propose a novel method that\nprovides tailored reference for the SiMT models trained at different latency by\nrephrasing the ground-truth. Specifically, we introduce the tailor, induced by\nreinforcement learning, to modify ground-truth to the tailored reference. The\nSiMT model is trained with the tailored reference and jointly optimized with\nthe tailor to enhance performance. Importantly, our method is applicable to a\nwide range of current SiMT approaches. Experiments on three translation tasks\ndemonstrate that our method achieves state-of-the-art performance in both fixed\nand adaptive policies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1\">Shoutao Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shaolei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yang Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MarineGPT: Unlocking Secrets of Ocean to the Public. (arXiv:2310.13596v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13596","description":"<p>Large language models (LLMs), such as ChatGPT/GPT-4, have proven to be\npowerful tools in promoting the user experience as an AI assistant. The\ncontinuous works are proposing multi-modal large language models (MLLM),\nempowering LLMs with the ability to sense multiple modality inputs through\nconstructing a joint semantic space (e.g. visual-text space). Though\nsignificant success was achieved in LLMs and MLLMs, exploring LLMs and MLLMs in\ndomain-specific applications that required domain-specific knowledge and\nexpertise has been less conducted, especially for \\textbf{marine domain}.\nDifferent from general-purpose MLLMs, the marine-specific MLLM is required to\nyield much more \\textbf{sensitive}, \\textbf{informative}, and\n\\textbf{scientific} responses. In this work, we demonstrate that the existing\nMLLMs optimized on huge amounts of readily available general-purpose training\ndata show a minimal ability to understand domain-specific intents and then\ngenerate informative and satisfactory responses. To address these issues, we\npropose \\textbf{MarineGPT}, the first vision-language model specially designed\nfor the marine domain, unlocking the secrets of the ocean to the public. We\npresent our \\textbf{Marine-5M} dataset with more than 5 million marine\nimage-text pairs to inject domain-specific marine knowledge into our model and\nachieve better marine vision and language alignment. Our MarineGPT not only\npushes the boundaries of marine understanding to the general public but also\noffers a standard protocol for adapting a general-purpose assistant to\ndownstream domain-specific experts. We pave the way for a wide range of marine\napplications while setting valuable data and pre-trained models for future\nresearch in both academic and industrial communities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Ziqiang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Tuan-Anh Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diao_S/0/1/0/all/0/1\">Shizhe Diao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tim_Y/0/1/0/all/0/1\">Yue Him Wong Tim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1\">Sai-Kit Yeung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection Benchmark. (arXiv:2310.13606v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13606","description":"<p>There is a lack of research into capabilities of recent LLMs to generate\nconvincing text in languages other than English and into performance of\ndetectors of machine-generated text in multilingual settings. This is also\nreflected in the available benchmarks which lack authentic texts in languages\nother than English and predominantly cover older generators. To fill this gap,\nwe introduce MULTITuDE, a novel benchmarking dataset for multilingual\nmachine-generated text detection comprising of 74,081 authentic and\nmachine-generated texts in 11 languages (ar, ca, cs, de, en, es, nl, pt, ru,\nuk, and zh) generated by 8 multilingual LLMs. Using this benchmark, we compare\nthe performance of zero-shot (statistical and black-box) and fine-tuned\ndetectors. Considering the multilinguality, we evaluate 1) how these detectors\ngeneralize to unseen languages (linguistically similar as well as dissimilar)\nand unseen LLMs and 2) whether the detectors improve their performance when\ntrained on multiple languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Macko_D/0/1/0/all/0/1\">Dominik Macko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moro_R/0/1/0/all/0/1\">Robert Moro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uchendu_A/0/1/0/all/0/1\">Adaku Uchendu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lucas_J/0/1/0/all/0/1\">Jason Samuel Lucas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamashita_M/0/1/0/all/0/1\">Michiharu Yamashita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pikuliak_M/0/1/0/all/0/1\">Mat&#xfa;&#x161; Pikuliak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srba_I/0/1/0/all/0/1\">Ivan Srba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1\">Thai Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simko_J/0/1/0/all/0/1\">Jakub Simko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bielikova_M/0/1/0/all/0/1\">Maria Bielikova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Make Your Decision Convincing! A Unified Two-Stage Framework: Self-Attribution and Decision-Making. (arXiv:2310.13610v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13610","description":"<p>Explaining black-box model behavior with natural language has achieved\nimpressive results in various NLP tasks. Recent research has explored the\nutilization of subsequences from the input text as a rationale, providing users\nwith evidence to support the model decision. Although existing frameworks excel\nin generating high-quality rationales while achieving high task performance,\nthey neglect to account for the unreliable link between the generated rationale\nand model decision. In simpler terms, a model may make correct decisions while\nattributing wrong rationales, or make poor decisions while attributing correct\nrationales. To mitigate this issue, we propose a unified two-stage framework\nknown as Self-Attribution and Decision-Making (SADM). Through extensive\nexperiments on five reasoning datasets from the ERASER benchmark, we\ndemonstrate that our framework not only establishes a more reliable link\nbetween the generated rationale and model decision but also achieves\ncompetitive results in task performance and the quality of rationale.\nFurthermore, we explore the potential of our framework in semi-supervised\nscenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yanrui Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haochun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_R/0/1/0/all/0/1\">Rui Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiang_Z/0/1/0/all/0/1\">Zewen Qiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1\">Muzhen Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hunayn: Elevating Translation Beyond the Literal. (arXiv:2310.13613v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13613","description":"<p>This project introduces an advanced English-to-Arabic translator surpassing\nconventional tools. Leveraging the Helsinki transformer (MarianMT), our\napproach involves fine-tuning on a self-scraped, purely literary Arabic\ndataset. Evaluations against Google Translate show consistent outperformance in\nqualitative assessments. Notably, it excels in cultural sensitivity and context\naccuracy. This research underscores the Helsinki transformer's superiority for\nEnglish-to-Arabic translation using a Fusha dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Almousa_N/0/1/0/all/0/1\">Nasser Almousa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alzamil_N/0/1/0/all/0/1\">Nasser Alzamil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alshehri_A/0/1/0/all/0/1\">Abdullah Alshehri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sait_A/0/1/0/all/0/1\">Ahmad Sait</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Three Questions Concerning the Use of Large Language Models to Facilitate Mathematics Learning. (arXiv:2310.13615v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13615","description":"<p>Due to the remarkable language understanding and generation abilities of\nlarge language models (LLMs), their use in educational applications has been\nexplored. However, little work has been done on investigating the pedagogical\nability of LLMs in helping students to learn mathematics. In this position\npaper, we discuss the challenges associated with employing LLMs to enhance\nstudents' mathematical problem-solving skills by providing adaptive feedback.\nApart from generating the wrong reasoning processes, LLMs can misinterpret the\nmeaning of the question, and also exhibit difficulty in understanding the given\nquestions' rationales when attempting to correct students' answers. Three\nresearch questions are formulated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yen_A/0/1/0/all/0/1\">An-Zi Yen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1\">Wei-Ling Hsu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semi-supervised multimodal coreference resolution in image narrations. (arXiv:2310.13619v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13619","description":"<p>In this paper, we study multimodal coreference resolution, specifically where\na longer descriptive text, i.e., a narration is paired with an image. This\nposes significant challenges due to fine-grained image-text alignment, inherent\nambiguity present in narrative language, and unavailability of large annotated\ntraining sets. To tackle these challenges, we present a data efficient\nsemi-supervised approach that utilizes image-narration pairs to resolve\ncoreferences and narrative grounding in a multimodal context. Our approach\nincorporates losses for both labeled and unlabeled data within a cross-modal\nframework. Our evaluation shows that the proposed approach outperforms strong\nbaselines both quantitatively and qualitatively, for the tasks of coreference\nresolution and narrative grounding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Goel_A/0/1/0/all/0/1\">Arushi Goel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernando_B/0/1/0/all/0/1\">Basura Fernando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keller_F/0/1/0/all/0/1\">Frank Keller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bilen_H/0/1/0/all/0/1\">Hakan Bilen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Information-Theoretic and Geometric Compression in Language Models. (arXiv:2310.13620v1 [cs.CL])","link":"http://arxiv.org/abs/2310.13620","description":"<p>For a language model (LM) to faithfully model human language, it must\ncompress vast, potentially infinite information into relatively few dimensions.\nWe propose analyzing compression in (pre-trained) LMs from two points of view:\ngeometric and information-theoretic. We demonstrate that the two views are\nhighly correlated, such that the intrinsic geometric dimension of linguistic\ndata predicts their coding length under the LM. We then show that, in turn,\nhigh compression of a linguistic dataset predicts rapid adaptation to that\ndataset, confirming that being able to compress linguistic information is an\nimportant part of successful LM performance. As a practical byproduct of our\nanalysis, we evaluate a battery of intrinsic dimension estimators for the first\ntime on linguistic data, showing that only some encapsulate the relationship\nbetween information-theoretic compression, geometric compression, and\nease-of-adaptation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_E/0/1/0/all/0/1\">Emily Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kervadec_C/0/1/0/all/0/1\">Corentin Kervadec</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1\">Marco Baroni</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretable Sequence Classification Via Prototype Trajectory. (arXiv:2007.01777v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2007.01777","description":"<p>We propose a novel interpretable deep neural network for text classification,\ncalled ProtoryNet, based on a new concept of prototype trajectories. Motivated\nby the prototype theory in modern linguistics, ProtoryNet makes a prediction by\nfinding the most similar prototype for each sentence in a text sequence and\nfeeding an RNN backbone with the proximity of each sentence to the\ncorresponding active prototype. The RNN backbone then captures the temporal\npattern of the prototypes, which we refer to as prototype trajectories.\nPrototype trajectories enable intuitive and fine-grained interpretation of the\nreasoning process of the RNN model, in resemblance to how humans analyze texts.\nWe also design a prototype pruning procedure to reduce the total number of\nprototypes used by the model for better interpretability. Experiments on\nmultiple public data sets show that ProtoryNet is more accurate than the\nbaseline prototype-based deep neural net and reduces the performance gap\ncompared to state-of-the-art black-box models. In addition, after prototype\npruning, the resulting ProtoryNet models only need less than or around 20\nprototypes for all datasets, which significantly benefits interpretability.\nFurthermore, we report a survey result indicating that human users find\nProtoryNet more intuitive and easier to understand than other prototype-based\nmethods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1\">Dat Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baek_S/0/1/0/all/0/1\">Stephen S. Baek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Red Alarm for Pre-trained Models: Universal Vulnerability to Neuron-Level Backdoor Attacks. (arXiv:2101.06969v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2101.06969","description":"<p>Pre-trained models (PTMs) have been widely used in various downstream tasks.\nThe parameters of PTMs are distributed on the Internet and may suffer backdoor\nattacks. In this work, we demonstrate the universal vulnerability of PTMs,\nwhere fine-tuned PTMs can be easily controlled by backdoor attacks in arbitrary\ndownstream tasks. Specifically, attackers can add a simple pre-training task,\nwhich restricts the output representations of trigger instances to pre-defined\nvectors, namely neuron-level backdoor attack (NeuBA). If the backdoor\nfunctionality is not eliminated during fine-tuning, the triggers can make the\nfine-tuned model predict fixed labels by pre-defined vectors. In the\nexperiments of both natural language processing (NLP) and computer vision (CV),\nwe show that NeuBA absolutely controls the predictions for trigger instances\nwithout any knowledge of downstream tasks. Finally, we apply several defense\nmethods to NeuBA and find that model pruning is a promising direction to resist\nNeuBA by excluding backdoored neurons. Our findings sound a red alarm for the\nwide use of PTMs. Our source code and models are available at\n\\url{https://github.com/thunlp/NeuBA}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhengyan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_G/0/1/0/all/0/1\">Guangxuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yongwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_T/0/1/0/all/0/1\">Tian Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1\">Fanchao Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yasheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Connecting degree and polarity: An artificial language learning study. (arXiv:2109.06333v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.06333","description":"<p>We investigate a new linguistic generalization in pre-trained language models\n(taking BERT (Devlin et al., 2019) as a case study). We focus on degree\nmodifiers (expressions like slightly, very, rather, extremely) and test the\nhypothesis that the degree expressed by a modifier (low, medium or high degree)\nis related to the modifier's sensitivity to sentence polarity (whether it shows\npreference for affirmative or negative sentences or neither). To probe this\nconnection, we apply the Artificial Language Learning experimental paradigm\nfrom psycholinguistics to a neural language model. Our experimental results\nsuggest that BERT generalizes in line with existing linguistic observations\nthat relate degree semantics to polarity sensitivity, including the main one:\nlow degree semantics is associated with preference towards positive polarity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bylinina_L/0/1/0/all/0/1\">Lisa Bylinina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1\">Alexey Tikhonov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garmash_E/0/1/0/all/0/1\">Ekaterina Garmash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uniform Complexity for Text Generation. (arXiv:2204.05185v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.05185","description":"<p>Large language models (LLMs) have shown promising results in a wide array of\ngenerative NLP tasks, such as summarization and machine translation. In the\ncontext of narrative generation, however, existing models still do not capture\nfactors that contribute to producing consistent text. For instance, it is\nlogical that a piece of text or a story should be uniformly readable throughout\nand that this form of complexity should be controllable. As such, if the\ncomplexity of an input text prompt is rated first-grade reading level in the\nFlesch Reading Ease test, then the generated text continuing the plot should\nalso be within this range of complexity. With this in mind, we introduce\nUniform Complexity for Text Generation (UCTG), a new benchmark test which\nraises the challenge of making generative models observe uniform linguistic\nproperties with respect to prompts. We experiment with over 150+ linguistically\nand cognitively motivated features for evaluating text complexity in humans and\ngenerative models. From our results, we find that models such as GPT-2 struggle\nto preserve the complexity of input prompts used in its generations, even if\nfinetuned with professionally written texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Imperial_J/0/1/0/all/0/1\">Joseph Marvin Imperial</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madabushi_H/0/1/0/all/0/1\">Harish Tayyar Madabushi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LAMASSU: Streaming Language-Agnostic Multilingual Speech Recognition and Translation Using Neural Transducers. (arXiv:2211.02809v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.02809","description":"<p>Automatic speech recognition (ASR) and speech translation (ST) can both use\nneural transducers as the model structure. It is thus possible to use a single\ntransducer model to perform both tasks. In real-world applications, such joint\nASR and ST models may need to be streaming and do not require source language\nidentification (i.e. language-agnostic). In this paper, we propose LAMASSU, a\nstreaming language-agnostic multilingual speech recognition and translation\nmodel using neural transducers. Based on the transducer model structure, we\npropose four methods, a unified joint and prediction network for multilingual\noutput, a clustered multilingual encoder, target language identification for\nencoder, and connectionist temporal classification regularization. Experimental\nresults show that LAMASSU not only drastically reduces the model size but also\nreaches the performances of monolingual ASR and bilingual ST models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1\">Eric Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jian Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_Y/0/1/0/all/0/1\">Yashesh Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating the Frequency Distortion of Word Embeddings and Its Impact on Bias Metrics. (arXiv:2211.08203v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08203","description":"<p>Recent research has shown that static word embeddings can encode word\nfrequency information. However, little has been studied about this phenomenon\nand its effects on downstream tasks. In the present work, we systematically\nstudy the association between frequency and semantic similarity in several\nstatic word embeddings. We find that Skip-gram, GloVe and FastText embeddings\ntend to produce higher semantic similarity between high-frequency words than\nbetween other frequency combinations. We show that the association between\nfrequency and similarity also appears when words are randomly shuffled. This\nproves that the patterns found are not due to real semantic associations\npresent in the texts, but are an artifact produced by the word embeddings.\nFinally, we provide an example of how word frequency can strongly impact the\nmeasurement of gender bias with embedding-based metrics. In particular, we\ncarry out a controlled experiment that shows that biases can even change sign\nor reverse their order by manipulating word frequencies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Valentini_F/0/1/0/all/0/1\">Francisco Valentini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sosa_J/0/1/0/all/0/1\">Juan Cruz Sosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Diego Fernandez Slezak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altszyler_E/0/1/0/all/0/1\">Edgar Altszyler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AF Adapter: Continual Pretraining for Building Chinese Biomedical Language Model. (arXiv:2211.11363v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11363","description":"<p>Continual pretraining is a popular way of building a domain-specific\npretrained language model from a general-domain language model. In spite of its\nhigh efficiency, continual pretraining suffers from catastrophic forgetting,\nwhich may harm the model's performance in downstream tasks. To alleviate the\nissue, in this paper, we propose a continual pretraining method for the\nBERT-based model, named Attention-FFN Adapter. Its main idea is to introduce a\nsmall number of attention heads and hidden units inside each self-attention\nlayer and feed-forward network. Furthermore, we train a domain-specific\nlanguage model named AF Adapter based RoBERTa for the Chinese biomedical\ndomain. In experiments, models are applied to downstream tasks for evaluation.\nThe results demonstrate that with only about 17% of model parameters trained,\nAF Adapter achieves 0.6%, 2% gain in performance on average, compared to strong\nbaselines. Further experimental results show that our method alleviates the\ncatastrophic forgetting problem by 11% compared to the fine-tuning method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1\">Yongyu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_K/0/1/0/all/0/1\">Kui Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xiaoming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1\">Qi Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingping Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_T/0/1/0/all/0/1\">Tong Ruan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KRLS: Improving End-to-End Response Generation in Task Oriented Dialog with Reinforced Keywords Learning. (arXiv:2211.16773v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.16773","description":"<p>In task-oriented dialogs (TOD), reinforcement learning (RL) algorithms train\na model to directly optimize response for task-related metrics. However, RL\nneeds to perform exploration, which can be time-consuming due to the slow\nauto-regressive sequence generation process. We investigate an approach to\ncreate a more efficient RL-based algorithm to improve TOD performance in an\noffline setting. First, we use a faster generation procedure that samples from\nindependent next-word distributions after training the language model (LM) with\nsupervised learning. We then introduce a fine-grained reward function to help\nthe model focus on learning key information in a dialog, by measuring the\nimportance and semantic closeness of each generated token. Experiments on the\nMultiWoZ dataset show our new training algorithm, Keywords Reinforcement\nLearning with Next-word Sampling (KRLS), achieves state-of-the-art performance\non the end-to-end response generation task, with a 15% training time reduction\ncompared to a standard RL algorithm using auto-regressive generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1\">Qingyang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_K/0/1/0/all/0/1\">Kun Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data Limitation With Contrastive Learning. (arXiv:2212.10341v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10341","description":"<p>Machine-Generated Text (MGT) detection, a task that discriminates MGT from\nHuman-Written Text (HWT), plays a crucial role in preventing misuse of text\ngenerative models, which excel in mimicking human writing style recently.\nLatest proposed detectors usually take coarse text sequences as input and\nfine-tune pretrained models with standard cross-entropy loss. However, these\nmethods fail to consider the linguistic structure of texts. Moreover, they lack\nthe ability to handle the low-resource problem which could often happen in\npractice considering the enormous amount of textual data online. In this paper,\nwe present a coherence-based contrastive learning model named CoCo to detect\nthe possible MGT under low-resource scenario. To exploit the linguistic\nfeature, we encode coherence information in form of graph into text\nrepresentation. To tackle the challenges of low data resource, we employ a\ncontrastive learning framework and propose an improved contrastive loss for\npreventing performance degradation brought by simple samples. The experiment\nresults on two public datasets and two self-constructed datasets prove our\napproach outperforms the state-of-art methods significantly. Also, we\nsurprisingly find that MGTs originated from up-to-date language models could be\neasier to detect than these from previous models, in our experiments. And we\npropose some preliminary explanations for this counter-intuitive phenomena. All\nthe codes and datasets are open-sourced.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoming Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaohan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_H/0/1/0/all/0/1\">Hang Pu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yu Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chao Shen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Logic Mill -- A Knowledge Navigation System. (arXiv:2301.00200v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.00200","description":"<p>Logic Mill is a scalable and openly accessible software system that\nidentifies semantically similar documents within either one domain-specific\ncorpus or multi-domain corpora. It uses advanced Natural Language Processing\n(NLP) techniques to generate numerical representations of documents. Currently\nit leverages a large pre-trained language model to generate these document\nrepresentations. The system focuses on scientific publications and patent\ndocuments and contains more than 200 million documents. It is easily accessible\nvia a simple Application Programming Interface (API) or via a web interface.\nMoreover, it is continuously being updated and can be extended to text corpora\nfrom other domains. We see this system as a general-purpose tool for future\nresearch applications in the social sciences and other domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Erhardt_S/0/1/0/all/0/1\">Sebastian Erhardt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_M/0/1/0/all/0/1\">Mainak Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Buunk_E/0/1/0/all/0/1\">Erik Buunk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rose_M/0/1/0/all/0/1\">Michael E. Rose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harhoff_D/0/1/0/all/0/1\">Dietmar Harhoff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Role of Morphological Information for Contextual Lemmatization. (arXiv:2302.00407v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.00407","description":"<p>Lemmatization is a natural language processing (NLP) task which consists of\nproducing, from a given inflected word, its canonical form or lemma.\nLemmatization is one of the basic tasks that facilitate downstream NLP\napplications, and is of particular importance for high-inflected languages.\nGiven that the process to obtain a lemma from an inflected word can be\nexplained by looking at its morphosyntactic category, including fine-grained\nmorphosyntactic information to train contextual lemmatizers has become common\npractice, without considering whether that is the optimum in terms of\ndownstream performance. In order to address this issue, in this paper we\nempirically investigate the role of morphological information to develop\ncontextual lemmatizers in six languages within a varied spectrum of\nmorphological complexity: Basque, Turkish, Russian, Czech, Spanish and English.\nFurthermore, and unlike the vast majority of previous work, we also evaluate\nlemmatizers in out-of-domain settings, which constitutes, after all, their most\ncommon application use. The results of our study are rather surprising. It\nturns out that providing lemmatizers with fine-grained morphological features\nduring training is not that beneficial, not even for agglutinative languages.\nIn fact, modern contextual word representations seem to implicitly encode\nenough morphological information to obtain competitive contextual lemmatizers\nwithout seeing any explicit morphological signal. Moreover, our experiments\nsuggest that the best lemmatizers out-of-domain are those using simple UPOS\ntags or those trained without morphology and, finally, that current evaluation\npractices for lemmatization are not adequate to clearly discriminate between\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Toporkov_O/0/1/0/all/0/1\">Olia Toporkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models. (arXiv:2302.12343v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.12343","description":"<p>We propose CHiLL (Crafting High-Level Latents), an approach for\nnatural-language specification of features for linear models. CHiLL prompts\nLLMs with expert-crafted queries to generate interpretable features from health\nrecords. The resulting noisy labels are then used to train a simple linear\nclassifier. Generating features based on queries to an LLM can empower\nphysicians to use their domain expertise to craft features that are clinically\nmeaningful for a downstream task of interest, without having to manually\nextract these from raw EHR. We are motivated by a real-world risk prediction\ntask, but as a reproducible proxy, we use MIMIC-III and MIMIC-CXR data and\nstandard predictive tasks (e.g., 30-day readmission) to evaluate this approach.\nWe find that linear models using automatically extracted features are\ncomparably performant to models using reference features, and provide greater\ninterpretability than linear models using \"Bag-of-Words\" features. We verify\nthat learned feature weights align well with clinical expectations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McInerney_D/0/1/0/all/0/1\">Denis Jered McInerney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_G/0/1/0/all/0/1\">Geoffrey Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meent_J/0/1/0/all/0/1\">Jan-Willem van de Meent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation. (arXiv:2303.12570v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12570","description":"<p>The task of repository-level code completion is to continue writing the\nunfinished code based on a broader context of the repository. While for\nautomated code completion tools, it is difficult to utilize the useful\ninformation scattered in different files. We propose RepoCoder, a simple,\ngeneric, and effective framework to address the challenge. It streamlines the\nrepository-level code completion process by incorporating a similarity-based\nretriever and a pre-trained code language model in an iterative\nretrieval-generation pipeline. RepoCoder makes effective utilization of\nrepository-level information for code completion and has the ability to\ngenerate code at various levels of granularity. Moreover, we propose a new\nbenchmark RepoEval, which consists of the latest and high-quality real-world\nrepositories covering line, API invocation, and function body completion\nscenarios. Experimental results indicate that RepoCoder significantly improves\nthe In-File completion baseline by over 10% in all settings and consistently\noutperforms the vanilla retrieval-augmented code completion approach.\nFurthermore, we validate the effectiveness of RepoCoder through comprehensive\nanalysis, providing valuable insights for future research. Our source code and\nbenchmark are publicly available:\nhttps://github.com/microsoft/CodeT/tree/main/RepoCoder\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fengji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Keung_J/0/1/0/all/0/1\">Jacky Keung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zan_D/0/1/0/all/0/1\">Daoguang Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yi Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Making the Most of ChatGPT for Machine Translation. (arXiv:2303.13780v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13780","description":"<p>ChatGPT shows remarkable capabilities for machine translation (MT). Several\nprior studies have shown that it achieves comparable results to commercial\nsystems for high-resource languages, but lags behind in complex tasks, e.g.,\nlow-resource and distant-language-pairs translation. However, they usually\nadopt simple prompts which can not fully elicit the capability of ChatGPT. In\nthis paper, we aim to further mine ChatGPT's translation ability by revisiting\nseveral aspects: temperature, task information, and domain information, and\ncorrespondingly propose an optimal temperature setting and two (simple but\neffective) prompts: Task-Specific Prompts (TSP) and Domain-Specific Prompts\n(DSP). We show that: 1) The performance of ChatGPT depends largely on\ntemperature, and a lower temperature usually can achieve better performance; 2)\nEmphasizing the task information can further improve ChatGPT's performance,\nparticularly in complex MT tasks; 3) Introducing domain information can elicit\nChatGPT's generalization ability and improve its performance in the specific\ndomain; 4) ChatGPT tends to generate hallucinations for non-English-centric MT\ntasks, which can be partially addressed by our proposed prompts but still need\nto be highlighted for the MT/NLP community. We also explore the effects of\nadvanced in-context learning strategies and find a (negative but interesting)\nobservation: the powerful chain-of-thought prompt leads to word-by-word\ntranslation behavior, thus bringing significant translation degradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Keqin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuebo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Min Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1\">Yuanxin Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Did You Mean...? Confidence-based Trade-offs in Semantic Parsing. (arXiv:2303.16857v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.16857","description":"<p>We illustrate how a calibrated model can help balance common trade-offs in\ntask-oriented parsing. In a simulated annotator-in-the-loop experiment, we show\nthat well-calibrated confidence scores allow us to balance cost with annotator\nload, improving accuracy with a small number of interactions. We then examine\nhow confidence scores can help optimize the trade-off between usability and\nsafety. We show that confidence-based thresholding can substantially reduce the\nnumber of incorrect low-confidence programs executed; however, this comes at a\ncost to usability. We propose the DidYouMean system which better balances\nusability and safety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stengel_Eskin_E/0/1/0/all/0/1\">Elias Stengel-Eskin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Textbooks with Visuals from the Web for Improved Learning. (arXiv:2304.08931v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.08931","description":"<p>Textbooks are one of the main mediums for delivering high-quality education\nto students. In particular, explanatory and illustrative visuals play a key\nrole in retention, comprehension and general transfer of knowledge. However,\nmany textbooks lack these interesting visuals to support student learning. In\nthis paper, we investigate the effectiveness of vision-language models to\nautomatically enhance textbooks with images from the web. We collect a dataset\nof e-textbooks in the math, science, social science and business domains. We\nthen set up a text-image matching task that involves retrieving and\nappropriately assigning web images to textbooks, which we frame as a matching\noptimization problem. Through a crowd-sourced evaluation, we verify that (1)\nwhile the original textbook images are rated higher, automatically assigned\nones are not far behind, and (2) the precise formulation of the optimization\nproblem matters. We release the dataset of textbooks with an associated image\nbank to inspire further research in this intersectional area of computer vision\nand NLP for education.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Janvijay Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Outlier Suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling. (arXiv:2304.09145v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09145","description":"<p>Post-training quantization~(PTQ) of transformer language models faces\nsignificant challenges due to the existence of detrimental outliers in\nactivations. We observe that these outliers are concentrated in specific\nchannels and are asymmetric across channels. To address this issue, we propose\nthe Outlier Suppression+~(OS+) framework, which contains the channel-wise\nshifting for asymmetry and channel-wise scaling for concentration. We show that\nthese operations can be seamlessly migrated into subsequent modules while\nmaintaining equivalence. Second, we propose a fast and stable scheme to\ncalculate effective shifting and scaling values. The channel-wise shifting\naligns the center of each channel for removal of outlier asymmetry. The\nchannel-wise scaling quantitatively evaluates changes brough by migration and\nquantization for better quantization burden balance. We validate our OS+ under\nboth standard and fine-grained quantization settings with models including\nBERT, OPT, BLOOM, BLOOMZ, and LLaMA. Comprehensive results across various tasks\ndemonstrate the superiority of our approach. Especially, with standard\nquantization, OS+ can achieve near-floating-point performance on both small\nmodels and large language models on 8-bit and 6-bit. Besides, we establish a\nnew state-of-the-art for 4-bit BERT with 15.5\\% improvement. Our code is\navailable at \\url{https://github.com/ModelTC/Outlier_Suppression_Plus}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiuying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunchen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jinyang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xianglong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DataComp: In search of the next generation of multimodal datasets. (arXiv:2304.14108v5 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.14108","description":"<p>Multimodal datasets are a critical component in recent breakthroughs such as\nStable Diffusion and GPT-4, yet their design does not receive the same research\nattention as model architectures or training algorithms. To address this\nshortcoming in the ML ecosystem, we introduce DataComp, a testbed for dataset\nexperiments centered around a new candidate pool of 12.8 billion image-text\npairs from Common Crawl. Participants in our benchmark design new filtering\ntechniques or curate new data sources and then evaluate their new dataset by\nrunning our standardized CLIP training code and testing the resulting model on\n38 downstream test sets. Our benchmark consists of multiple compute scales\nspanning four orders of magnitude, which enables the study of scaling trends\nand makes the benchmark accessible to researchers with varying resources. Our\nbaseline experiments show that the DataComp workflow leads to better training\nsets. In particular, our best baseline, DataComp-1B, enables training a CLIP\nViT-L/14 from scratch to 79.2% zero-shot accuracy on ImageNet, outperforming\nOpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training\nprocedure and compute. We release DataComp and all accompanying code at\nwww.datacomp.ai.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gadre_S/0/1/0/all/0/1\">Samir Yitzhak Gadre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilharco_G/0/1/0/all/0/1\">Gabriel Ilharco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_A/0/1/0/all/0/1\">Alex Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayase_J/0/1/0/all/0/1\">Jonathan Hayase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smyrnis_G/0/1/0/all/0/1\">Georgios Smyrnis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thao Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marten_R/0/1/0/all/0/1\">Ryan Marten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wortsman_M/0/1/0/all/0/1\">Mitchell Wortsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1\">Dhruba Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jieyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orgad_E/0/1/0/all/0/1\">Eyal Orgad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Entezari_R/0/1/0/all/0/1\">Rahim Entezari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daras_G/0/1/0/all/0/1\">Giannis Daras</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pratt_S/0/1/0/all/0/1\">Sarah Pratt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanujan_V/0/1/0/all/0/1\">Vivek Ramanujan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marathe_K/0/1/0/all/0/1\">Kalyani Marathe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mussmann_S/0/1/0/all/0/1\">Stephen Mussmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vencu_R/0/1/0/all/0/1\">Richard Vencu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cherti_M/0/1/0/all/0/1\">Mehdi Cherti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1\">Ranjay Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koh_P/0/1/0/all/0/1\">Pang Wei Koh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saukh_O/0/1/0/all/0/1\">Olga Saukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ratner_A/0/1/0/all/0/1\">Alexander Ratner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shuran Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1\">Ali Farhadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beaumont_R/0/1/0/all/0/1\">Romain Beaumont</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1\">Alex Dimakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jitsev_J/0/1/0/all/0/1\">Jenia Jitsev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carmon_Y/0/1/0/all/0/1\">Yair Carmon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1\">Vaishaal Shankar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1\">Ludwig Schmidt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"We're Afraid Language Models Aren't Modeling Ambiguity. (arXiv:2304.14399v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.14399","description":"<p>Ambiguity is an intrinsic feature of natural language. Managing ambiguity is\na key part of human language understanding, allowing us to anticipate\nmisunderstanding as communicators and revise our interpretations as listeners.\nAs language models (LMs) are increasingly employed as dialogue interfaces and\nwriting aids, handling ambiguous language is critical to their success. We\ncharacterize ambiguity in a sentence by its effect on entailment relations with\nanother sentence, and collect AmbiEnt, a linguist-annotated benchmark of 1,645\nexamples with diverse kinds of ambiguity. We design a suite of tests based on\nAmbiEnt, presenting the first evaluation of pretrained LMs to recognize\nambiguity and disentangle possible meanings. We find that the task remains\nextremely challenging, including for GPT-4, whose generated disambiguations are\nconsidered correct only 32% of the time in human evaluation, compared to 90%\nfor disambiguations in our dataset. Finally, to illustrate the value of\nambiguity-sensitive tools, we show that a multilabel NLI model can flag\npolitical claims in the wild that are misleading due to ambiguity. We encourage\nthe field to rediscover the importance of ambiguity for NLP.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Alisa Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1\">Zhaofeng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michael_J/0/1/0/all/0/1\">Julian Michael</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhr_A/0/1/0/all/0/1\">Alane Suhr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_P/0/1/0/all/0/1\">Peter West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koller_A/0/1/0/all/0/1\">Alexander Koller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1\">Swabha Swayamdipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Entity-Based Evaluation of Political Bias in Automatic Summarization. (arXiv:2305.02321v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02321","description":"<p>Growing literature has shown that NLP systems may encode social biases;\nhowever, the political bias of summarization models remains relatively unknown.\nIn this work, we use an entity replacement method to investigate the portrayal\nof politicians in automatically generated summaries of news articles. We\ndevelop an entity-based computational framework to assess the sensitivities of\nseveral extractive and abstractive summarizers to the politicians Donald Trump\nand Joe Biden. We find consistent differences in these summaries upon entity\nreplacement, such as reduced emphasis of Trump's presence in the context of the\nsame article and a more individualistic representation of Trump with respect to\nthe collective US government (i.e., administration). These summary\ndissimilarities are most prominent when the entity is heavily featured in the\nsource article. Our characterization provides a foundation for future studies\nof bias in summarization and for normative discussions on the ideal qualities\nof automatic summaries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Karen Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding. (arXiv:2305.03668v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03668","description":"<p>Webpages have been a rich, scalable resource for vision-language and language\nonly tasks. Yet only pieces of webpages are kept in existing datasets:\nimage-caption pairs, long text articles, or raw HTML, never all in one place.\nWebpage tasks have resultingly received little attention and structured\nimage-text data left underused. To study multimodal webpage understanding, we\nintroduce the Wikipedia Webpage suite (WikiWeb2M) containing 2M pages with all\nof the associated image, text, and structure data. We verify its utility on\nthree generative tasks: page description generation, section summarization, and\ncontextual image captioning. We design a novel attention mechanism Prefix\nGlobal, which selects the most relevant image and text content as global tokens\nto attend to the rest of the webpage for context. By using page structure to\nseparate such tokens, it performs better than full attention with lower\ncomputational complexity. Extensive experiments show that the new data in\nWikiWeb2M improves task performance compared to prior work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Burns_A/0/1/0/all/0/1\">Andrea Burns</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_K/0/1/0/all/0/1\">Krishna Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_G/0/1/0/all/0/1\">Geoff Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plummer_B/0/1/0/all/0/1\">Bryan A. Plummer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1\">Kate Saenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jianmo Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Mandy Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Influence of External Information on Large Language Models Mirrors Social Cognitive Patterns. (arXiv:2305.04812v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.04812","description":"<p>Social cognitive theory explains how people learn and acquire knowledge\nthrough observing others. Recent years have witnessed the rapid development of\nlarge language models (LLMs), which suggests their potential significance as\nagents in the society. LLMs, as AI agents, can observe external information,\nwhich shapes their cognition and behaviors. However, the extent to which\nexternal information influences LLMs' cognition and behaviors remains unclear.\nThis study investigates how external statements and opinions influence LLMs'\nthoughts and behaviors from a social cognitive perspective. Three experiments\nwere conducted to explore the effects of external information on LLMs'\nmemories, opinions, and social media behavioral decisions. Sociocognitive\nfactors, including source authority, social identity, and social role, were\nanalyzed to investigate their moderating effects. Results showed that external\ninformation can significantly shape LLMs' memories, opinions, and behaviors,\nwith these changes mirroring human social cognitive patterns such as authority\nbias, in-group bias, emotional positivity, and emotion contagion. This\nunderscores the challenges in developing safe and unbiased LLMs, and emphasizes\nthe importance of understanding the susceptibility of LLMs to external\ninfluences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bian_N/0/1/0/all/0/1\">Ning Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongyu Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peilin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaojie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chunkang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_B/0/1/0/all/0/1\">Ben He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"INGENIOUS: Using Informative Data Subsets for Efficient Pre-Training of Language Models. (arXiv:2305.06677v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06677","description":"<p>A salient characteristic of pre-trained language models (PTLMs) is a\nremarkable improvement in their generalization capability and emergence of new\ncapabilities with increasing model capacity and pre-training dataset size.\nConsequently, we are witnessing the development of enormous models pushing the\nstate-of-the-art. It is, however, imperative to realize that this inevitably\nleads to prohibitively long training times, extortionate computing costs, and a\ndetrimental environmental impact. Significant efforts are underway to make PTLM\ntraining more efficient through innovations in model architectures, training\npipelines, and loss function design, with scant attention being paid to\noptimizing the utility of training data. The key question that we ask is\nwhether it is possible to train PTLMs by employing only highly informative\nsubsets of the training data while maintaining downstream performance? Building\nupon the recent progress in informative data subset selection, we show how we\ncan employ submodular optimization to select highly representative subsets of\nthe training corpora and demonstrate that the proposed framework can be applied\nto efficiently train multiple PTLMs (BERT, BioBERT, GPT-2) using only a\nfraction of data. Further, we perform a rigorous empirical evaluation to show\nthat the resulting models achieve up to $\\sim99\\%$ of the performance of the\nfully-trained models. We made our framework publicly available at\nhttps://github.com/Efficient-AI/ingenious.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Renduchintala_H/0/1/0/all/0/1\">H S V N S Kowndinya Renduchintala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Killamsetty_K/0/1/0/all/0/1\">Krishnateja Killamsetty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_S/0/1/0/all/0/1\">Sumit Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_M/0/1/0/all/0/1\">Milan Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1\">Ganesh Ramakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1\">Rishabh Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document Summarization. (arXiv:2305.08503v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08503","description":"<p>Pre-trained language models (PLMs) have achieved outstanding achievements in\nabstractive single-document summarization (SDS). However, such benefits may not\nfully extend to multi-document summarization (MDS), where the handling of\ncross-document information is more complex. Previous works either design new\nMDS architectures or apply PLMs bluntly with concatenated source documents as a\nreformulated SDS task. While the former does not utilize previous pre-training\nefforts and may not generalize well across different domains, the latter may\nnot sufficiently attend to the intricate cross-document relationships unique to\nMDS tasks. Instead, we enforce hierarchy on both the encoder and decoder to\nbetter utilize a PLM to facilitate multi-document interactions for the MDS\ntask. Across 10 MDS benchmarks from various domains, our method outperforms or\nis competitive with the previous best models, including those with additional\nMDS pre-training or with more parameters. It outperforms its corresponding PLM\nbackbone by up to 3 Rouge-L and is favored by humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chenhui Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Liying Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_X/0/1/0/all/0/1\">Xuan-Phi Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for Languages in India. (arXiv:2305.08828v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.08828","description":"<p>This paper introduces PMIndiaSum, a multilingual and massively parallel\nsummarization corpus focused on languages in India. Our corpus provides a\ntraining and testing ground for four language families, 14 languages, and the\nlargest to date with 196 language pairs. We detail our construction workflow\nincluding data acquisition, processing, and quality assurance. Furthermore, we\npublish benchmarks for monolingual, cross-lingual, and multilingual\nsummarization by fine-tuning, prompting, as well as translate-and-summarize.\nExperimental results confirm the crucial role of our data in aiding\nsummarization between Indian languages. Our dataset is publicly available and\ncan be freely modified and re-distributed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Urlana_A/0/1/0/all/0/1\">Ashok Urlana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pinzhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1\">Zheng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1\">Shay B. Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_M/0/1/0/all/0/1\">Manish Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddow_B/0/1/0/all/0/1\">Barry Haddow</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Elaborative Simplification as Implicit Questions Under Discussion. (arXiv:2305.10387v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10387","description":"<p>Automated text simplification, a technique useful for making text more\naccessible to people such as children and emergent bilinguals, is often thought\nof as a monolingual translation task from complex sentences to simplified\nsentences using encoder-decoder models. This view fails to account for\nelaborative simplification, where new information is added into the simplified\ntext. This paper proposes to view elaborative simplification through the lens\nof the Question Under Discussion (QUD) framework, providing a robust way to\ninvestigate what writers elaborate upon, how they elaborate, and how\nelaborations fit into the discourse context by viewing elaborations as explicit\nanswers to implicit questions. We introduce ElabQUD, consisting of 1.3K\nelaborations accompanied with implicit QUDs, to study these phenomena. We show\nthat explicitly modeling QUD (via question generation) not only provides\nessential understanding of elaborative simplification and how the elaborations\nconnect with the rest of the discourse, but also substantially improves the\nquality of elaboration generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yating Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheffield_W/0/1/0/all/0/1\">William Sheffield</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Jessy Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning. (arXiv:2305.10613v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10613","description":"<p>Temporal knowledge graph (TKG) forecasting benchmarks challenge models to\npredict future facts using knowledge of past facts. In this paper, we apply\nlarge language models (LLMs) to these benchmarks using in-context learning\n(ICL). We investigate whether and to what extent LLMs can be used for TKG\nforecasting, especially without any fine-tuning or explicit modules for\ncapturing structural and temporal information. For our experiments, we present\na framework that converts relevant historical facts into prompts and generates\nranked predictions using token probabilities. Surprisingly, we observe that\nLLMs, out-of-the-box, perform on par with state-of-the-art TKG models carefully\ndesigned and trained for TKG forecasting. Our extensive evaluation presents\nperformances across several models and datasets with different characteristics,\ncompares alternative heuristics for preparing contextual information, and\ncontrasts to prominent TKG methods and simple frequency and recency baselines.\nWe also discover that using numerical indices instead of entity/relation names,\ni.e., hiding semantic information, does not significantly affect the\nperformance ($\\pm$0.4\\% Hit@1). This shows that prior semantic knowledge is\nunnecessary; instead, LLMs can leverage the existing patterns in the context to\nachieve such performance. Our analysis also reveals that ICL enables LLMs to\nlearn irregular patterns from the historical context, going beyond simple\npredictions based on common or recent information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dong-Ho Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahrabian_K/0/1/0/all/0/1\">Kian Ahrabian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1\">Woojeong Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1\">Fred Morstatter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pujara_J/0/1/0/all/0/1\">Jay Pujara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation. (arXiv:2305.11596v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11596","description":"<p>Modern NLP models are often trained over large untrusted datasets, raising\nthe potential for a malicious adversary to compromise model behaviour. For\ninstance, backdoors can be implanted through crafting training instances with a\nspecific textual trigger and a target label. This paper posits that backdoor\npoisoning attacks exhibit \\emph{spurious correlation} between simple text\nfeatures and classification labels, and accordingly, proposes methods for\nmitigating spurious correlation as means of defence. Our empirical study\nreveals that the malicious triggers are highly correlated to their target\nlabels; therefore such correlations are extremely distinguishable compared to\nthose scores of benign features, and can be used to filter out potentially\nproblematic instances. Compared with several existing defences, our defence\nmethod significantly reduces attack success rates across backdoor attacks, and\nin the case of insertion-based attacks, our method provides a near-perfect\ndefence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuanli He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiongkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1\">Benjamin Rubinstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohn_T/0/1/0/all/0/1\">Trevor Cohn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability. (arXiv:2305.11707v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11707","description":"<p>In Natural Language Generation (NLG) tasks, for any input, multiple\ncommunicative goals are plausible, and any goal can be put into words, or\nproduced, in multiple ways. We characterise the extent to which human\nproduction varies lexically, syntactically, and semantically across four NLG\ntasks, connecting human production variability to aleatoric or data\nuncertainty. We then inspect the space of output strings shaped by a generation\nsystem's predicted probability distribution and decoding algorithm to probe its\nuncertainty. For each test input, we measure the generator's calibration to\nhuman production variability. Following this instance-level approach, we\nanalyse NLG models and decoding strategies, demonstrating that probing a\ngenerator with multiple samples and, when possible, multiple references,\nprovides the level of detail necessary to gain understanding of a model's\nrepresentation of uncertainty. Code available at\nhttps://github.com/dmg-illc/nlg-uncertainty-probes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1\">Mario Giulianelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baan_J/0/1/0/all/0/1\">Joris Baan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1\">Wilker Aziz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1\">Raquel Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Polar Ducks and Where to Find Them: Enhancing Entity Linking with Duck Typing and Polar Box Embeddings. (arXiv:2305.12027v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12027","description":"<p>Entity linking methods based on dense retrieval are an efficient and widely\nused solution in large-scale applications, but they fall short of the\nperformance of generative models, as they are sensitive to the structure of the\nembedding space. In order to address this issue, this paper introduces DUCK, an\napproach to infusing structural information in the space of entity\nrepresentations, using prior knowledge of entity types. Inspired by duck typing\nin programming languages, we propose to define the type of an entity based on\nthe relations that it has with other entities in a knowledge graph. Then,\nporting the concept of box embeddings to spherical polar coordinates, we\npropose to represent relations as boxes on the hypersphere. We optimize the\nmodel to cluster entities of similar type by placing them inside the boxes\ncorresponding to their relations. Our experiments show that our method sets new\nstate-of-the-art results on standard entity-disambiguation benchmarks, it\nimproves the performance of the model by up to 7.9 F1 points, outperforms other\ntype-aware approaches, and matches the results of generative models with 18\ntimes more parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Atzeni_M/0/1/0/all/0/1\">Mattia Atzeni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plekhanov_M/0/1/0/all/0/1\">Mikhail Plekhanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dreyer_F/0/1/0/all/0/1\">Fr&#xe9;d&#xe9;ric A. Dreyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kassner_N/0/1/0/all/0/1\">Nora Kassner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Merello_S/0/1/0/all/0/1\">Simone Merello</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Louis Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cancedda_N/0/1/0/all/0/1\">Nicola Cancedda</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DisCo: Distilled Student Models Co-training for Semi-supervised Text Mining. (arXiv:2305.12074v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12074","description":"<p>Many text mining models are constructed by fine-tuning a large deep\npre-trained language model (PLM) in downstream tasks. However, a significant\nchallenge nowadays is maintaining performance when we use a lightweight model\nwith limited labelled samples. We present DisCo, a semi-supervised learning\n(SSL) framework for fine-tuning a cohort of small student models generated from\na large PLM using knowledge distillation. Our key insight is to share\ncomplementary knowledge among distilled student cohorts to promote their SSL\neffectiveness. DisCo employs a novel co-training technique to optimize a cohort\nof multiple small student models by promoting knowledge sharing among students\nunder diversified views: model views produced by different distillation\nstrategies and data views produced by various input augmentations. We evaluate\nDisCo on both semi-supervised text classification and extractive summarization\ntasks. Experimental results show that DisCo can produce student models that are\n7.6 times smaller and 4.8 times faster in inference than the baseline PLMs\nwhile maintaining comparable performance. We also show that DisCo-generated\nstudent models outperform the similar-sized models elaborately tuned in\ndistinct tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1\">Weifeng Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1\">Qianren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianxin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_T/0/1/0/all/0/1\">Ting Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Weiyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zheng Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT to Replace Crowdsourcing of Paraphrases for Intent Classification: Higher Diversity and Comparable Model Robustness. (arXiv:2305.12947v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12947","description":"<p>The emergence of generative large language models (LLMs) raises the question:\nwhat will be its impact on crowdsourcing? Traditionally, crowdsourcing has been\nused for acquiring solutions to a wide variety of human-intelligence tasks,\nincluding ones involving text generation, modification or evaluation. For some\nof these tasks, models like ChatGPT can potentially substitute human workers.\nIn this study, we investigate whether this is the case for the task of\nparaphrase generation for intent classification. We apply data collection\nmethodology of an existing crowdsourcing study (similar scale, prompts and seed\ndata) using ChatGPT and Falcon-40B. We show that ChatGPT-created paraphrases\nare more diverse and lead to at least as robust models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cegin_J/0/1/0/all/0/1\">Jan Cegin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simko_J/0/1/0/all/0/1\">Jakub Simko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brusilovsky_P/0/1/0/all/0/1\">Peter Brusilovsky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study. (arXiv:2305.13062v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13062","description":"<p>Large language models (LLMs) are becoming attractive as few-shot reasoners to\nsolve Natural Language (NL)-related tasks. However, there is still much to\nlearn about how well LLMs understand structured data, such as tables. While it\nis true that tables can be used as inputs to LLMs with serialization, there\nlack of comprehensive studies examining whether LLMs can truly comprehend such\ndata. In this paper, we try to understand this by designing a benchmark to\nevaluate the structural understanding capabilities (SUC) of LLMs. The benchmark\nwe create includes seven tasks, each with its own unique challenges, \\eg, cell\nlookup, row retrieval, and size detection. We run a series of evaluations on\nGPT-3.5 and GPT-4. We discover that the performance varied depending on a\nnumber of input choices, including table input format, content order, role\nprompting, and partition marks. Drawing from the insights gained through the\nbenchmark evaluations, we then propose \\textit{self-augmentation} for effective\nstructural prompting, \\eg, critical value / range identification using LLMs'\ninternal knowledge. When combined with carefully chosen input choices, these\nstructural prompting methods lead to promising improvements in LLM performance\non a variety of tabular tasks, \\eg, TabFact($\\uparrow2.31\\%$),\nHybridQA($\\uparrow2.13\\%$), SQA($\\uparrow2.72\\%$), Feverous($\\uparrow0.84\\%$),\nand ToTTo($\\uparrow5.68\\%$). We believe that our benchmark and proposed\nprompting methods can serve as a simple yet generic selection for future\nresearch. The code and data are released in\n\\url{https://anonymous.4open.science/r/StructuredLLM-76F3}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1\">Yuan Sui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mengyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1\">Mingjie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Not Yet Human-Level Evaluators for Abstractive Summarization. (arXiv:2305.13091v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13091","description":"<p>With the recent undeniable advancement in reasoning abilities in large\nlanguage models (LLMs) like ChatGPT and GPT-4, there is a growing trend for\nusing LLMs on various tasks. One area where LLMs can be employed is as an\nalternative evaluation metric for complex generative tasks, which generally\ndemands expensive human judges to complement the traditional automatic metrics\nfor various evaluation dimensions such as fluency and consistency. In this\nwork, we conduct extensive analysis to investigate the stability and\nreliability of LLMs as automatic evaluators for abstractive summarization. We\nfound that while ChatGPT and GPT-4 outperform the commonly used automatic\nmetrics, they are not ready as human replacements due to significant\nlimitations. That is, LLM evaluators rate each candidate system inconsistently\nand are dimension-dependent. They also struggle to compare candidates with\nclose performance and become more unreliable with higher-quality summaries by\nobtaining a lower correlation with humans. In other words, with better\nabstractive summarization systems being introduced at a fast pace, LLMs may\nresult in misleading and unreliable evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1\">Chenhui Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Liying Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_X/0/1/0/all/0/1\">Xuan-Phi Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1\">Yang You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables. (arXiv:2305.13186v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13186","description":"<p>Current scientific fact-checking benchmarks exhibit several shortcomings,\nsuch as biases arising from crowd-sourced claims and an over-reliance on\ntext-based evidence. We present SCITAB, a challenging evaluation dataset\nconsisting of 1.2K expert-verified scientific claims that 1) originate from\nauthentic scientific publications and 2) require compositional reasoning for\nverification. The claims are paired with evidence-containing scientific tables\nannotated with labels. Through extensive evaluations, we demonstrate that\nSCITAB poses a significant challenge to state-of-the-art models, including\ntable-based pretraining models and large language models. All models except\nGPT-4 achieved performance barely above random guessing. Popular prompting\ntechniques, such as Chain-of-Thought, do not achieve much performance gains on\nSCITAB. Our analysis uncovers several unique challenges posed by SCITAB,\nincluding table grounding, claim ambiguity, and compositional reasoning. Our\ncodes and data are publicly available at https://github.com/XinyuanLu00/SciTab.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xinyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SimCSE++: Improving Contrastive Learning for Sentence Embeddings from Two Perspectives. (arXiv:2305.13192v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13192","description":"<p>This paper improves contrastive learning for sentence embeddings from two\nperspectives: handling dropout noise and addressing feature corruption.\nSpecifically, for the first perspective, we identify that the dropout noise\nfrom negative pairs affects the model's performance. Therefore, we propose a\nsimple yet effective method to deal with such type of noise. Secondly, we\npinpoint the rank bottleneck of current solutions to feature corruption and\npropose a dimension-wise contrastive learning objective to address this issue.\nBoth proposed methods are generic and can be applied to any contrastive\nlearning based models for sentence embeddings. Experimental results on standard\nbenchmarks demonstrate that combining both proposed methods leads to a gain of\n1.8 points compared to the strong baseline SimCSE configured with BERT base.\nFurthermore, applying the proposed method to DiffCSE, another strong\ncontrastive learning based baseline, results in a gain of 1.4 points.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiahao Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lihui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lemao Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Unsupervised Recognition of Token-level Semantic Differences in Related Documents. (arXiv:2305.13303v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13303","description":"<p>Automatically highlighting words that cause semantic differences between two\ndocuments could be useful for a wide range of applications. We formulate\nrecognizing semantic differences (RSD) as a token-level regression task and\nstudy three unsupervised approaches that rely on a masked language model. To\nassess the approaches, we begin with basic English sentences and gradually move\nto more complex, cross-lingual document pairs. Our results show that an\napproach based on word alignment and sentence-level contrastive learning has a\nrobust correlation to gold labels. However, all unsupervised approaches still\nleave a large margin of improvement. Code to reproduce our experiments is\navailable at https://github.com/ZurichNLP/recognizing-semantic-differences\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vamvas_J/0/1/0/all/0/1\">Jannis Vamvas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1\">Rico Sennrich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can LLMs facilitate interpretation of pre-trained language models?. (arXiv:2305.13386v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13386","description":"<p>Work done to uncover the knowledge encoded within pre-trained language models\nrely on annotated corpora or human-in-the-loop methods. However, these\napproaches are limited in terms of scalability and the scope of interpretation.\nWe propose using a large language model, ChatGPT, as an annotator to enable\nfine-grained interpretation analysis of pre-trained language models. We\ndiscover latent concepts within pre-trained language models by applying\nagglomerative hierarchical clustering over contextualized representations and\nthen annotate these concepts using ChatGPT. Our findings demonstrate that\nChatGPT produces accurate and semantically richer annotations compared to\nhuman-annotated concepts. Additionally, we showcase how GPT-based annotations\nempower interpretation analysis methodologies of which we demonstrate two:\nprobing frameworks and neuron interpretation. To facilitate further exploration\nand experimentation in the field, we make available a substantial ConceptNet\ndataset (TCN) comprising 39,000 annotated concepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mousi_B/0/1/0/all/0/1\">Basel Mousi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrani_N/0/1/0/all/0/1\">Nadir Durrani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalvi_F/0/1/0/all/0/1\">Fahim Dalvi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for Real-World Pharmacovigilance. (arXiv:2305.13395v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13395","description":"<p>Timely and accurate extraction of Adverse Drug Events (ADE) from biomedical\nliterature is paramount for public safety, but involves slow and costly manual\nlabor. We set out to improve drug safety monitoring (pharmacovigilance, PV)\nthrough the use of Natural Language Processing (NLP). We introduce BioDEX, a\nlarge-scale resource for Biomedical adverse Drug Event Extraction, rooted in\nthe historical output of drug safety reporting in the U.S. BioDEX consists of\n65k abstracts and 19k full-text biomedical papers with 256k associated\ndocument-level safety reports created by medical experts. The core features of\nthese reports include the reported weight, age, and biological sex of a\npatient, a set of drugs taken by the patient, the drug dosages, the reactions\nexperienced, and whether the reaction was life threatening. In this work, we\nconsider the task of predicting the core information of the report given its\noriginating paper. We estimate human performance to be 72.0% F1, whereas our\nbest model achieves 62.3% F1, indicating significant headroom on this task. We\nalso begin to explore ways in which these models could help professional PV\nreviewers. Our code and data are available: https://github.com/KarelDO/BioDEX.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+DOosterlinck_K/0/1/0/all/0/1\">Karel D&#x27;Oosterlinck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Remy_F/0/1/0/all/0/1\">Fran&#xe7;ois Remy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1\">Johannes Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaporojets_K/0/1/0/all/0/1\">Klim Zaporojets</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Aneiss Ghodsi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellershaw_S/0/1/0/all/0/1\">Simon Ellershaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_J/0/1/0/all/0/1\">Jack Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ReSee: Responding through Seeing Fine-grained Visual Knowledge in Open-domain Dialogue. (arXiv:2305.13602v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13602","description":"<p>Incorporating visual knowledge into text-only dialogue systems has become a\npotential direction to imitate the way humans think, imagine, and communicate.\nHowever, existing multimodal dialogue systems are either confined by the scale\nand quality of available datasets or the coarse concept of visual knowledge. To\naddress these issues, we provide a new paradigm of constructing multimodal\ndialogues as well as two datasets extended from text-only dialogues under such\nparadigm (ReSee-WoW, ReSee-DD). We propose to explicitly split the visual\nknowledge into finer granularity (``turn-level'' and ``entity-level''). To\nfurther boost the accuracy and diversity of augmented visual information, we\nretrieve them from the Internet or a large image dataset. To demonstrate the\nsuperiority and universality of the provided visual knowledge, we propose a\nsimple but effective framework ReSee to add visual representation into vanilla\ndialogue models by modality concatenations. We also conduct extensive\nexperiments and ablations w.r.t. different model configurations and visual\nknowledge settings. Empirical, encouraging results not only demonstrate the\neffectiveness of introducing visual knowledge at both entity and turn level but\nalso verify the proposed model ReSee outperforms several state-of-the-art\nmethods on automatic and human evaluations. By leveraging text and vision\nknowledge, ReSee can produce informative responses with real-world visual\nconcepts. Our code is available at https://github.com/ImKeTT/ReSee.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_H/0/1/0/all/0/1\">Haoqin Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yitong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhongliang Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy Planning. (arXiv:2305.13660v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13660","description":"<p>Planning for goal-oriented dialogue often requires simulating future dialogue\ninteractions and estimating task progress. Many approaches thus consider\ntraining neural networks to perform look-ahead search algorithms such as A*\nsearch and Monte Carlo Tree Search (MCTS). However, this training often\nrequires abundant annotated data, which creates challenges when faced with\nnoisy annotations or low-resource settings. We introduce GDP-Zero, an approach\nusing Open-Loop MCTS to perform goal-oriented dialogue policy planning without\nany model training. GDP-Zero prompts a large language model to act as a policy\nprior, value function, user simulator, and system model during the tree search.\nWe evaluate GDP-Zero on the goal-oriented task PersuasionForGood, and find that\nits responses are preferred over ChatGPT up to 59.32% of the time, and are\nrated more persuasive than ChatGPT during interactive evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Maximillian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PIEClass: Weakly-Supervised Text Classification with Prompting and Noise-Robust Iterative Ensemble Training. (arXiv:2305.13723v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13723","description":"<p>Weakly-supervised text classification trains a classifier using the label\nname of each target class as the only supervision, which largely reduces human\nannotation efforts. Most existing methods first use the label names as static\nkeyword-based features to generate pseudo labels, which are then used for final\nclassifier training. While reasonable, such a commonly adopted framework\nsuffers from two limitations: (1) keywords can have different meanings in\ndifferent contexts and some text may not have any keyword, so keyword matching\ncan induce noisy and inadequate pseudo labels; (2) the errors made in the\npseudo label generation stage will directly propagate to the classifier\ntraining stage without a chance of being corrected. In this paper, we propose a\nnew method, PIEClass, consisting of two modules: (1) a pseudo label acquisition\nmodule that uses zero-shot prompting of pre-trained language models (PLM) to\nget pseudo labels based on contextualized text understanding beyond static\nkeyword matching, and (2) a noise-robust iterative ensemble training module\nthat iteratively trains classifiers and updates pseudo labels by utilizing two\nPLM fine-tuning methods that regularize each other. Extensive experiments show\nthat PIEClass achieves overall better performance than existing strong\nbaselines on seven benchmark datasets and even achieves similar performance to\nfully-supervised classifiers on sentiment classification tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1\">Minhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Black-Box Few-Shot Text Classification with Prompt-Based Data Augmentation. (arXiv:2305.13785v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13785","description":"<p>Training or finetuning large-scale language models (LLMs) such as GPT-3\nrequires substantial computation resources, motivating recent efforts to\nexplore parameter-efficient adaptation to downstream tasks. One practical area\nof research is to treat these models as black boxes and interact with them\nthrough their inference APIs. In this paper, we investigate how to optimize\nfew-shot text classification without accessing the gradients of the LLMs. To\nachieve this, we treat the black-box model as a feature extractor and train a\nclassifier with the augmented text data. Data augmentation is performed using\nprompt-based finetuning on an auxiliary language model with a much smaller\nparameter size than the black-box model. Through extensive experiments on eight\ntext classification datasets, we show that our approach, dubbed BT-Classifier,\nsignificantly outperforms state-of-the-art black-box few-shot learners and\nperforms on par with methods that rely on full-model tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1\">Danqing Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jiahui Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haizhou Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Question Answering as Programming for Solving Time-Sensitive Questions. (arXiv:2305.14221v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14221","description":"<p>Question answering plays a pivotal role in human daily life because it\ninvolves our acquisition of knowledge about the world. However, due to the\ndynamic and ever-changing nature of real-world facts, the answer can be\ncompletely different when the time constraint in the question changes.\nRecently, Large Language Models (LLMs) have shown remarkable intelligence in\nquestion answering, while our experiments reveal that the aforementioned\nproblems still pose a significant challenge to existing LLMs. This can be\nattributed to the LLMs' inability to perform rigorous reasoning based on\nsurface-level text semantics. To overcome this limitation, rather than\nrequiring LLMs to directly answer the question, we propose a novel approach\nwhere we reframe the $\\textbf{Q}$uestion $\\textbf{A}$nswering task\n$\\textbf{a}$s $\\textbf{P}$rogramming ($\\textbf{QAaP}$). Concretely, by\nleveraging modern LLMs' superior capability in understanding both natural\nlanguage and programming language, we endeavor to harness LLMs to represent\ndiversely expressed text as well-structured code and select the best matching\nanswer from multiple candidates through programming. We evaluate our QAaP\nframework on several time-sensitive question answering datasets and achieve\ndecent improvement, up to $14.5$% over strong baselines. Our codes and data are\navailable at https://github.com/TianHongZXY/qaap\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xinyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Siheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query Rewriting for Retrieval-Augmented Large Language Models. (arXiv:2305.14283v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14283","description":"<p>Large Language Models (LLMs) play powerful, black-box readers in the\nretrieve-then-read pipeline, making remarkable progress in knowledge-intensive\ntasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of\nthe previous retrieve-then-read for the retrieval-augmented LLMs from the\nperspective of the query rewriting. Unlike prior studies focusing on adapting\neither the retriever or the reader, our approach pays attention to the\nadaptation of the search query itself, for there is inevitably a gap between\nthe input text and the needed knowledge in retrieval. We first prompt an LLM to\ngenerate the query, then use a web search engine to retrieve contexts.\nFurthermore, to better align the query to the frozen modules, we propose a\ntrainable scheme for our pipeline. A small language model is adopted as a\ntrainable rewriter to cater to the black-box LLM reader. The rewriter is\ntrained using the feedback of the LLM reader by reinforcement learning.\nEvaluation is conducted on downstream tasks, open-domain QA and multiple-choice\nQA. Experiments results show consistent performance improvement, indicating\nthat our framework is proven effective and scalable, and brings a new framework\nfor retrieval-augmented LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinbei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Semantic Role Labeling from Compatible Label Sequences. (arXiv:2305.14600v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14600","description":"<p>Semantic role labeling (SRL) has multiple disjoint label sets, e.g., VerbNet\nand PropBank. Creating these datasets is challenging, therefore a natural\nquestion is how to use each one to help the other. Prior work has shown that\ncross-task interaction helps, but only explored multitask learning so far. A\ncommon issue with multi-task setup is that argument sequences are still\nseparately decoded, running the risk of generating structurally inconsistent\nlabel sequences (as per lexicons like Semlink). In this paper, we eliminate\nsuch issue with a framework that jointly models VerbNet and PropBank labels as\none sequence. In this setup, we show that enforcing Semlink constraints during\ndecoding constantly improves the overall F1. With special input constructions,\nour joint model infers VerbNet arguments from given PropBank arguments with\nover 99 F1. For learning, we propose a constrained marginal model that learns\nwith knowledge defined in Semlink to further benefit from the large amounts of\nPropBank-only data. On the joint benchmark based on CoNLL05, our models achieve\nstate-of-the-art F1's, outperforming the prior best in-domain model by 3.5\n(VerbNet) and 0.8 (PropBank). For out-of-domain generalization, our models\nsurpass the prior best by 3.4 (VerbNet) and 0.2 (PropBank).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazeminejad_G/0/1/0/all/0/1\">Ghazaleh Kazeminejad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_S/0/1/0/all/0/1\">Susan W. Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palmer_M/0/1/0/all/0/1\">Martha Palmer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1\">Vivek Srikumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Getting MoRE out of Mixture of Language Model Reasoning Experts. (arXiv:2305.14628v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14628","description":"<p>While recent large language models (LLMs) improve on various question\nanswering (QA) datasets, it remains difficult for a single model to generalize\nacross question types that require distinct reasoning abilities. We provide\nempirical evidence that state-of-the-art LLMs suffer from poor generalizability\non reasoning types beyond those seen in the prompt. To remedy this, we propose\na Mixture-of-Reasoning-Experts (MoRE) framework that ensembles diverse\nspecialized language models. We specialize the backbone language model with\nprompts optimized for different reasoning categories, including factual,\nmultihop, mathematical, and commonsense reasoning. Our key insight is to\nleverage agreement among the specialized experts to select the best answer for\neach question, or to abstain from answering. This gives MoRE higher accuracy\nthan any single specialized model on a collection of 12 QA datasets from four\nreasoning types. Beyond generalizability, the interpretable design of MoRE\nimproves selective question answering results compared to baselines without\nincorporating inter-expert agreement. This framework is also more interpretable\nand useful to human consumers of QA outputs. Our human study confirms that\npresenting expert predictions and the answer selection process helps annotators\nmore accurately calibrate when to trust the system's output. We release all\ncode and data to facilitate future work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1\">Chenglei Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1\">Jordan Boyd-Graber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering. (arXiv:2305.14869v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14869","description":"<p>The task of zero-shot commonsense question answering evaluates models on\ntheir capacity to reason about general scenarios beyond those presented in\nspecific datasets. Existing approaches for tackling this task leverage external\nknowledge from CommonSense Knowledge Bases (CSKBs) by pretraining the model on\nsynthetic QA pairs constructed from CSKBs. In these approaches, negative\nexamples (distractors) are formulated by randomly sampling from CSKBs using\nfairly primitive keyword constraints. However, two bottlenecks limit these\napproaches: the inherent incompleteness of CSKBs limits the semantic coverage\nof synthetic QA pairs, and the lack of human annotations makes the sampled\nnegative examples potentially uninformative and contradictory. To tackle these\nlimitations above, we propose Conceptualization-Augmented Reasoner (CAR), a\nzero-shot commonsense question-answering framework that fully leverages the\npower of conceptualization. Specifically, CAR abstracts a commonsense knowledge\ntriple to many higher-level instances, which increases the coverage of CSKB and\nexpands the ground-truth answer space, reducing the likelihood of selecting\nfalse-negative distractors. Extensive experiments demonstrate that CAR more\nrobustly generalizes to answering questions about zero-shot commonsense\nscenarios than existing methods, including large language models, such as\nGPT3.5 and ChatGPT. Our codes, data, and model checkpoints are available at\nhttps://github.com/HKUST-KnowComp/CAR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1\">Wenxuan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Baixuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Mechanistic Interpretation of Arithmetic Reasoning in Language Models using Causal Mediation Analysis. (arXiv:2305.15054v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15054","description":"<p>Mathematical reasoning in large language models (LMs) has garnered\nsignificant attention in recent work, but there is a limited understanding of\nhow these models process and store information related to arithmetic tasks\nwithin their architecture. In order to improve our understanding of this aspect\nof language models, we present a mechanistic interpretation of\nTransformer-based LMs on arithmetic questions using a causal mediation analysis\nframework. By intervening on the activations of specific model components and\nmeasuring the resulting changes in predicted probabilities, we identify the\nsubset of parameters responsible for specific predictions. This provides\ninsights into how information related to arithmetic is processed by LMs. Our\nexperimental results indicate that LMs process the input by transmitting the\ninformation relevant to the query from mid-sequence early layers to the final\ntoken using the attention mechanism. Then, this information is processed by a\nset of MLP modules, which generate result-related information that is\nincorporated into the residual stream. To assess the specificity of the\nobserved activation dynamics, we compare the effects of different model\ncomponents on arithmetic queries with other tasks, including number retrieval\nfrom prompts and factual knowledge questions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stolfo_A/0/1/0/all/0/1\">Alessandro Stolfo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM. (arXiv:2305.15255v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15255","description":"<p>We present a novel approach to adapting pre-trained large language models\n(LLMs) to perform question answering (QA) and speech continuation. By endowing\nthe LLM with a pre-trained speech encoder, our model becomes able to take\nspeech inputs and generate speech outputs. The entire system is trained\nend-to-end and operates directly on spectrograms, simplifying our architecture.\nKey to our approach is a training objective that jointly supervises speech\nrecognition, text continuation, and speech synthesis using only paired\nspeech-text pairs, enabling a `cross-modal' chain-of-thought within a single\ndecoding pass. Our method surpasses existing spoken language models in speaker\npreservation and semantic coherence. Furthermore, the proposed model improves\nupon direct initialization in retaining the knowledge of the original LLM as\ndemonstrated through spoken QA datasets. Audio samples can be found at\nhttps://michelleramanovich.github.io/spectron/spectron\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nachmani_E/0/1/0/all/0/1\">Eliya Nachmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levkovitch_A/0/1/0/all/0/1\">Alon Levkovitch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_R/0/1/0/all/0/1\">Roy Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salazar_J/0/1/0/all/0/1\">Julian Salazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asawaroengchai_C/0/1/0/all/0/1\">Chulayuth Asawaroengchai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mariooryad_S/0/1/0/all/0/1\">Soroosh Mariooryad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rivlin_E/0/1/0/all/0/1\">Ehud Rivlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skerry_Ryan_R/0/1/0/all/0/1\">RJ Skerry-Ryan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramanovich_M/0/1/0/all/0/1\">Michelle Tadmor Ramanovich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Testing the General Deductive Reasoning Capacity of Large Language Models Using OOD Examples. (arXiv:2305.15269v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15269","description":"<p>Given the intractably large size of the space of proofs, any model that is\ncapable of general deductive reasoning must generalize to proofs of greater\ncomplexity. Recent studies have shown that large language models (LLMs) possess\nsome abstract deductive reasoning ability given chain-of-thought prompts.\nHowever, they have primarily been tested on proofs using modus ponens or of a\nspecific size, and from the same distribution as the in-context examples. To\nmeasure the general deductive reasoning ability of LLMs, we test on a broad set\nof deduction rules and measure their ability to generalize to more complex\nproofs from simpler demonstrations from multiple angles: depth-, width-, and\ncompositional generalization. To facilitate systematic exploration, we\nconstruct a new synthetic and programmable reasoning dataset that enables\ncontrol over deduction rules and proof complexity. Our experiments on four LLMs\nof various sizes and training objectives show that they are able to generalize\nto compositional proofs. However, they have difficulty generalizing to longer\nproofs, and they require explicit demonstrations to produce hypothetical\nsubproofs, specifically in proof by cases and proof by contradiction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saparov_A/0/1/0/all/0/1\">Abulhair Saparov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1\">Richard Yuanzhe Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_V/0/1/0/all/0/1\">Vishakh Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Nitish Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_S/0/1/0/all/0/1\">Seyed Mehran Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">He He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Model Tokenizers Introduce Unfairness Between Languages. (arXiv:2305.15425v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15425","description":"<p>Recent language models have shown impressive multilingual performance, even\nwhen not explicitly trained for it. Despite this, there are concerns about the\nquality of their outputs across different languages. In this paper, we show how\ndisparity in the treatment of different languages arises at the tokenization\nstage, well before a model is even invoked. The same text translated into\ndifferent languages can have drastically different tokenization lengths, with\ndifferences up to 15 times in some cases. These disparities persist even for\ntokenizers that are intentionally trained for multilingual support.\nCharacter-level and byte-level models also exhibit over 4 times the difference\nin the encoding length for some language pairs. This induces unfair treatment\nfor some language communities in regard to the cost of accessing commercial\nlanguage services, the processing time and latency, as well as the amount of\ncontent that can be provided as context to the models. Therefore, we make the\ncase that we should train future language models using multilingually fair\nsubword tokenizers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petrov_A/0/1/0/all/0/1\">Aleksandar Petrov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1\">Emanuele La Malfa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1\">Philip H.S. Torr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1\">Adel Bibi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Handling Realistic Label Noise in BERT Text Classification. (arXiv:2305.16337v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16337","description":"<p>Labels noise refers to errors in training labels caused by cheap data\nannotation methods, such as web scraping or crowd-sourcing, which can be\ndetrimental to the performance of supervised classifiers. Several methods have\nbeen proposed to counteract the effect of random label noise in supervised\nclassification, and some studies have shown that BERT is already robust against\nhigh rates of randomly injected label noise. However, real label noise is not\nrandom; rather, it is often correlated with input features or other\nannotator-specific factors. In this paper, we evaluate BERT in the presence of\ntwo types of realistic label noise: feature-dependent label noise, and\nsynthetic label noise from annotator disagreements. We show that the presence\nof these types of noise significantly degrades BERT classification performance.\nTo improve robustness, we evaluate different types of ensembles and\nnoise-cleaning methods and compare their effectiveness against label noise\nacross different datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agro_M/0/1/0/all/0/1\">Maha Tufail Agro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aldarmaki_H/0/1/0/all/0/1\">Hanan Aldarmaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inference-Time Intervention: Eliciting Truthful Answers from a Language Model. (arXiv:2306.03341v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.03341","description":"<p>We introduce Inference-Time Intervention (ITI), a technique designed to\nenhance the \"truthfulness\" of large language models (LLMs). ITI operates by\nshifting model activations during inference, following a set of directions\nacross a limited number of attention heads. This intervention significantly\nimproves the performance of LLaMA models on the TruthfulQA benchmark. On an\ninstruction-finetuned LLaMA called Alpaca, ITI improves its truthfulness from\n32.5% to 65.1%. We identify a tradeoff between truthfulness and helpfulness and\ndemonstrate how to balance it by tuning the intervention strength. ITI is\nminimally invasive and computationally inexpensive. Moreover, the technique is\ndata efficient: while approaches like RLHF require extensive annotations, ITI\nlocates truthful directions using only few hundred examples. Our findings\nsuggest that LLMs may have an internal representation of the likelihood of\nsomething being true, even as they produce falsehoods on the surface.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kenneth Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Patel_O/0/1/0/all/0/1\">Oam Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viegas_F/0/1/0/all/0/1\">Fernanda Vi&#xe9;gas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1\">Hanspeter Pfister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wattenberg_M/0/1/0/all/0/1\">Martin Wattenberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment. (arXiv:2306.08877v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.08877","description":"<p>Text-conditioned image generation models often generate incorrect\nassociations between entities and their visual attributes. This reflects an\nimpaired mapping between linguistic binding of entities and modifiers in the\nprompt and visual binding of the corresponding elements in the generated image.\nAs one notable example, a query like \"a pink sunflower and a yellow flamingo\"\nmay incorrectly produce an image of a yellow sunflower and a pink flamingo. To\nremedy this issue, we propose SynGen, an approach which first syntactically\nanalyses the prompt to identify entities and their modifiers, and then uses a\nnovel loss function that encourages the cross-attention maps to agree with the\nlinguistic binding reflected by the syntax. Specifically, we encourage large\noverlap between attention maps of entities and their modifiers, and small\noverlap with other entities and modifier words. The loss is optimized during\ninference, without retraining or fine-tuning the model. Human evaluation on\nthree datasets, including one new and challenging set, demonstrate significant\nimprovements of SynGen compared with current state of the art methods. This\nwork highlights how making use of sentence structure during inference can\nefficiently and substantially improve the faithfulness of text-to-image\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rassin_R/0/1/0/all/0/1\">Royi Rassin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hirsch_E/0/1/0/all/0/1\">Eran Hirsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Glickman_D/0/1/0/all/0/1\">Daniel Glickman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1\">Gal Chechik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v3 [stat.ML] UPDATED)","link":"http://arxiv.org/abs/2306.09927","description":"<p>Attention-based neural networks such as transformers have demonstrated a\nremarkable ability to exhibit in-context learning (ICL): Given a short prompt\nsequence of tokens from an unseen task, they can formulate relevant per-token\nand next-token predictions without any parameter updates. By embedding a\nsequence of labeled training data and unlabeled test data as a prompt, this\nallows for transformers to behave like supervised learning algorithms. Indeed,\nrecent work has shown that when training transformer architectures over random\ninstances of linear regression problems, these models' predictions mimic those\nof ordinary least squares.\n</p>\n<p>Towards understanding the mechanisms underlying this phenomenon, we\ninvestigate the dynamics of ICL in transformers with a single linear\nself-attention layer trained by gradient flow on linear regression tasks. We\nshow that despite non-convexity, gradient flow with a suitable random\ninitialization finds a global minimum of the objective function. At this global\nminimum, when given a test prompt of labeled examples from a new prediction\ntask, the transformer achieves prediction error competitive with the best\nlinear predictor over the test prompt distribution. We additionally\ncharacterize the robustness of the trained transformer to a variety of\ndistribution shifts and show that although a number of shifts are tolerated,\nshifts in the covariate distribution of the prompts are not. Motivated by this,\nwe consider a generalized ICL setting where the covariate distributions can\nvary across prompts. We show that although gradient flow succeeds at finding a\nglobal minimum in this setting, the trained transformer is still brittle under\nmild covariate shifts. We complement this finding with experiments on large,\nnonlinear transformer architectures which we show are more robust under\ncovariate shifts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Zhang_R/0/1/0/all/0/1\">Ruiqi Zhang</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Frei_S/0/1/0/all/0/1\">Spencer Frei</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1\">Peter L. Bartlett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speech Emotion Diarization: Which Emotion Appears When?. (arXiv:2306.12991v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.12991","description":"<p>Speech Emotion Recognition (SER) typically relies on utterance-level\nsolutions. However, emotions conveyed through speech should be considered as\ndiscrete speech events with definite temporal boundaries, rather than\nattributes of the entire utterance. To reflect the fine-grained nature of\nspeech emotions, we propose a new task: Speech Emotion Diarization (SED). Just\nas Speaker Diarization answers the question of \"Who speaks when?\", Speech\nEmotion Diarization answers the question of \"Which emotion appears when?\". To\nfacilitate the evaluation of the performance and establish a common benchmark\nfor researchers, we introduce the Zaion Emotion Dataset (ZED), an openly\naccessible speech emotion dataset that includes non-acted emotions recorded in\nreal-life conditions, along with manually-annotated boundaries of emotion\nsegments within the utterance. We provide competitive baselines and open-source\nthe code and the pre-trained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yingzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravanelli_M/0/1/0/all/0/1\">Mirco Ravanelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yacoubi_A/0/1/0/all/0/1\">Alya Yacoubi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jina Embeddings: A Novel Set of High-Performance Sentence Embedding Models. (arXiv:2307.11224v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11224","description":"<p>Jina Embeddings constitutes a set of high-performance sentence embedding\nmodels adept at translating textual inputs into numerical representations,\ncapturing the semantics of the text. These models excel in applications like\ndense retrieval and semantic textual similarity. This paper details the\ndevelopment of Jina Embeddings, starting with the creation of high-quality\npairwise and triplet datasets. It underlines the crucial role of data cleaning\nin dataset preparation, offers in-depth insights into the model training\nprocess, and concludes with a comprehensive performance evaluation using the\nMassive Text Embedding Benchmark (MTEB). Furthermore, to increase the model's\nawareness of grammatical negation, we construct a novel training and evaluation\ndataset of negated and non-negated statements, which we make publicly available\nto the community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gunther_M/0/1/0/all/0/1\">Michael G&#xfc;nther</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milliken_L/0/1/0/all/0/1\">Louis Milliken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geuter_J/0/1/0/all/0/1\">Jonathan Geuter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mastrapas_G/0/1/0/all/0/1\">Georgios Mastrapas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1\">Han Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Understand and Can be Enhanced by Emotional Stimuli. (arXiv:2307.11760v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11760","description":"<p>Emotional intelligence significantly impacts our daily behaviors and\ninteractions. Although Large Language Models (LLMs) are increasingly viewed as\na stride toward artificial general intelligence, exhibiting impressive\nperformance in numerous tasks, it is still uncertain if LLMs can genuinely\ngrasp psychological emotional stimuli. Understanding and responding to\nemotional cues gives humans a distinct advantage in problem-solving. In this\npaper, we take the first step towards exploring the ability of LLMs to\nunderstand emotional stimuli. To this end, we first conduct automatic\nexperiments on 45 tasks using various LLMs, including Flan-T5-Large, Vicuna,\nLlama 2, BLOOM, ChatGPT, and GPT-4. Our tasks span deterministic and generative\napplications that represent comprehensive evaluation scenarios. Our automatic\nexperiments show that LLMs have a grasp of emotional intelligence, and their\nperformance can be improved with emotional prompts (which we call\n\"EmotionPrompt\" that combines the original prompt with emotional stimuli),\ne.g., 8.00% relative performance improvement in Instruction Induction and 115%\nin BIG-Bench. In addition to those deterministic tasks that can be\nautomatically evaluated using existing metrics, we conducted a human study with\n106 participants to assess the quality of generative tasks using both vanilla\nand emotional prompts. Our human study results demonstrate that EmotionPrompt\nsignificantly boosts the performance of generative tasks (10.9% average\nimprovement in terms of performance, truthfulness, and responsibility metrics).\nWe provide an in-depth discussion regarding why EmotionPrompt works for LLMs\nand the factors that may influence its performance. We posit that EmotionPrompt\nheralds a novel avenue for exploring interdisciplinary knowledge for human-LLMs\ninteraction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Cheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yixuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_J/0/1/0/all/0/1\">Jianxun Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1\">Fang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Specification of MiniDemographicABM.jl: A simplified agent-based demographic model of the UK. (arXiv:2307.16548v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.16548","description":"<p>This documentation specifies a simplified non-calibrated demographic\nagent-based model of the UK, a largely simplified version of the Lone Parent\nModel presented in [Gostolil and Silverman 2020]. In the presented model,\nindividuals of an initial population are subject to ageing, deaths, births,\ndivorces and marriages throughout a simplified map of towns of the UK. The\nspecification employs the formal terminology presented in [Elsheikh 2023a]. The\nmain purpose of the model is to explore and exploit capabilities of the\nstate-of-the-art Agents.jl Julia package [Datseris2022] in the context of\ndemographic modeling applications. Implementation is provided via the Julia\npackage MiniDemographicABM.jl [Elsheikh 2023b]. A specific simulation is\nprogressed with a user-defined simulation fixed step size on a hourly, daily,\nweekly, monthly basis or even an arbitrary user-defined clock rate. The model\ncan serve for comparative studies if implemented in other agent-based modelling\nframeworks and programming languages. Moreover, the model serves as a base\nimplementation to be adjusted to realistic large-scale socio-economics,\npandemics or immigration studies mainly within a demographic context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elsheikh_A/0/1/0/all/0/1\">Atiyah Elsheikh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Formal specification terminology for demographic agent-based models of fixed-step single-clocked simulations. (arXiv:2308.13081v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.13081","description":"<p>This document presents adequate formal terminology for the mathematical\nspecification of a subset of Agent Based Models (ABMs) in the field of\nDemography. The simulation of the targeted ABMs follows a fixedstep\nsingle-clocked pattern. The proposed terminology further improves the model\nunderstanding and can act as a stand-alone protocol for the specification and\noptionally the documentation of a significant set of (demographic) ABMs.\nNevertheless, it is imaginable the this terminology can serve as an inspiring\nbasis for further improvement to the largely-informal widely-used model\ndocumentation and communication O.D.D. protocol [Grimm and et al., 2020,\nAmouroux et al., 2010] to reduce many sources of ambiguity which hinder model\nreplications by other modelers. A published demographic model documentation,\nlargely simplified version of the Lone Parent Model [Gostoli and Silverman,\n2020] is separately published in [Elsheikh, 2023c] as illustration for the\nformal terminology presented here. The model was implemented in the Julia\nlanguage [Elsheikh, 2023b] based on the Agents.jl julia package [Datseris et\nal., 2022].\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Elsheikh_A/0/1/0/all/0/1\">Atiyah Elsheikh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Audio Contrastive based Fine-tuning. (arXiv:2309.11895v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2309.11895","description":"<p>Audio classification plays a crucial role in speech and sound processing\ntasks with a wide range of applications. There still remains a challenge of\nstriking the right balance between fitting the model to the training data\n(avoiding overfitting) and enabling it to generalise well to a new domain.\nLeveraging the transferability of contrastive learning, we introduce Audio\nContrastive-based Fine-tuning (AudioConFit), an efficient approach\ncharacterised by robust generalisability. Empirical experiments on a variety of\naudio classification tasks demonstrate the effectiveness and robustness of our\napproach, which achieves state-of-the-art results in various settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_Q/0/1/0/all/0/1\">Qibin Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chenghao Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yizhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1\">Noura Al Moubayed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports. (arXiv:2309.12273v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12273","description":"<p>Rapid and accurate identification of Venous thromboembolism (VTE), a severe\ncardiovascular condition including deep vein thrombosis (DVT) and pulmonary\nembolism (PE), is important for effective treatment. Leveraging Natural\nLanguage Processing (NLP) on radiology reports, automated methods have shown\npromising advancements in identifying VTE events from retrospective data\ncohorts or aiding clinical experts in identifying VTE events from radiology\nreports. However, effectively training Deep Learning (DL) and the NLP models is\nchallenging due to limited labeled medical text data, the complexity and\nheterogeneity of radiology reports, and data imbalance. This study proposes\nnovel method combinations of DL methods, along with data augmentation, adaptive\npre-trained NLP model selection, and a clinical expert NLP rule-based\nclassifier, to improve the accuracy of VTE identification in unstructured\n(free-text) radiology reports. Our experimental results demonstrate the model's\nefficacy, achieving an impressive 97\\% accuracy and 97\\% F1 score in predicting\nDVT, and an outstanding 98.3\\% accuracy and 98.4\\% F1 score in predicting PE.\nThese findings emphasize the model's robustness and its potential to\nsignificantly contribute to VTE research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jamie Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yusen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayssen_H/0/1/0/all/0/1\">Hilary Hayssen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Englum_B/0/1/0/all/0/1\">Brain Englum</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kankaria_A/0/1/0/all/0/1\">Aman Kankaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mayorga_Carlin_M/0/1/0/all/0/1\">Minerva Mayorga-Carlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahoo_S/0/1/0/all/0/1\">Shalini Sahoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sorkin_J/0/1/0/all/0/1\">John Sorkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lal_B/0/1/0/all/0/1\">Brajesh Lal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yesha_Y/0/1/0/all/0/1\">Yelena Yesha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1\">Phuong Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the definition of toxicity in NLP. (arXiv:2310.02357v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02357","description":"<p>The fundamental problem in toxicity detection task lies in the fact that the\ntoxicity is ill-defined. This causes us to rely on subjective and vague data in\nmodels' training, which results in non-robust and non-accurate results: garbage\nin - garbage out.\n</p>\n<p>This work suggests a new, stress-level-based definition of toxicity designed\nto be objective and context-aware. On par with it, we also describe possible\nways of applying this new definition to dataset creation and model training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Berezin_S/0/1/0/all/0/1\">Sergey Berezin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farahbakhsh_R/0/1/0/all/0/1\">Reza Farahbakhsh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Crespi_N/0/1/0/all/0/1\">Noel Crespi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DQ-LoRe: Dual Queries with Low Rank Approximation Re-ranking for In-Context Learning. (arXiv:2310.02954v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02954","description":"<p>Recent advances in natural language processing, primarily propelled by Large\nLanguage Models (LLMs), have showcased their remarkable capabilities grounded\nin in-context learning. A promising avenue for guiding LLMs in intricate\nreasoning tasks involves the utilization of intermediate reasoning steps within\nthe Chain-of-Thought (CoT) paradigm. Nevertheless, the central challenge lies\nin the effective selection of exemplars for facilitating in-context learning.\nIn this study, we introduce a framework that leverages Dual Queries and\nLow-rank approximation Re-ranking (DQ-LoRe) to automatically select exemplars\nfor in-context learning. Dual Queries first query LLM to obtain LLM-generated\nknowledge such as CoT, then query the retriever to obtain the final exemplars\nvia both question and the knowledge. Moreover, for the second query, LoRe\nemploys dimensionality reduction techniques to refine exemplar selection,\nensuring close alignment with the input question's knowledge. Through extensive\nexperiments, we demonstrate that DQ-LoRe significantly outperforms prior\nstate-of-the-art methods in the automatic selection of exemplars for GPT-4,\nenhancing performance from 92.5% to 94.2%. Our comprehensive analysis further\nreveals that DQ-LoRe consistently outperforms retrieval-based approaches in\nterms of both performance and adaptability, especially in scenarios\ncharacterized by distribution shifts. DQ-LoRe pushes the boundaries of\nin-context learning and opens up new avenues for addressing complex reasoning\nchallenges. We will release the code soon.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1\">Jing Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zixuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chuanyang Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhijiang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yichun Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1\">Enze Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhicheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1\">Qingxing Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haiming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiongwei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jing Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chengming Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xiaodan Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explainable Claim Verification via Knowledge-Grounded Reasoning with Large Language Models. (arXiv:2310.05253v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05253","description":"<p>Claim verification plays a crucial role in combating misinformation. While\nexisting works on claim verification have shown promising results, a crucial\npiece of the puzzle that remains unsolved is to understand how to verify claims\nwithout relying on human-annotated data, which is expensive to create at a\nlarge scale. Additionally, it is important for models to provide comprehensive\nexplanations that can justify their decisions and assist human fact-checkers.\nThis paper presents First-Order-Logic-Guided Knowledge-Grounded (FOLK)\nReasoning that can verify complex claims and generate explanations without the\nneed for annotated evidence using Large Language Models (LLMs). FOLK leverages\nthe in-context learning ability of LLMs to translate the claim into a\nFirst-Order-Logic (FOL) clause consisting of predicates, each corresponding to\na sub-claim that needs to be verified. Then, FOLK performs FOL-Guided reasoning\nover a set of knowledge-grounded question-and-answer pairs to make veracity\npredictions and generate explanations to justify its decision-making process.\nThis process makes our model highly explanatory, providing clear explanations\nof its reasoning process in human-readable form. Our experiment results\nindicate that FOLK outperforms strong baselines on three datasets encompassing\nvarious claim verification challenges. Our code and data are available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoran Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shu_K/0/1/0/all/0/1\">Kai Shu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Document-level Event Argument Extraction with Contextual Clues and Role Relevance. (arXiv:2310.05991v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05991","description":"<p>Document-level event argument extraction poses new challenges of long input\nand cross-sentence inference compared to its sentence-level counterpart.\nHowever, most prior works focus on capturing the relations between candidate\narguments and the event trigger in each event, ignoring two crucial points: a)\nnon-argument contextual clue information; b) the relevance among argument\nroles. In this paper, we propose a SCPRG (Span-trigger-based Contextual Pooling\nand latent Role Guidance) model, which contains two novel and effective modules\nfor the above problem. The Span-Trigger-based Contextual Pooling(STCP)\nadaptively selects and aggregates the information of non-argument clue words\nbased on the context attention weights of specific argument-trigger pairs from\npre-trained model. The Role-based Latent Information Guidance (RLIG) module\nconstructs latent role representations, makes them interact through\nrole-interactive encoding to capture semantic relevance, and merges them into\ncandidate arguments. Both STCP and RLIG introduce no more than 1% new\nparameters compared with the base model and can be easily applied to other\nevent extraction models, which are compact and transplantable. Experiments on\ntwo public datasets show that our SCPRG outperforms previous state-of-the-art\nmethods, with 1.13 F1 and 2.64 F1 improvements on RAMS and WikiEvents\nrespectively. Further analyses illustrate the interpretability of our model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wanlong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Shaohuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1\">Dingyi Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1\">Hong Qu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SEER : A Knapsack approach to Exemplar Selection for In-Context HybridQA. (arXiv:2310.06675v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06675","description":"<p>Question answering over hybrid contexts is a complex task, which requires the\ncombination of information extracted from unstructured texts and structured\ntables in various ways. Recently, In-Context Learning demonstrated significant\nperformance advances for reasoning tasks. In this paradigm, a large language\nmodel performs predictions based on a small set of supporting exemplars. The\nperformance of In-Context Learning depends heavily on the selection procedure\nof the supporting exemplars, particularly in the case of HybridQA, where\nconsidering the diversity of reasoning chains and the large size of the hybrid\ncontexts becomes crucial. In this work, we present Selection of ExEmplars for\nhybrid Reasoning (SEER), a novel method for selecting a set of exemplars that\nis both representative and diverse. The key novelty of SEER is that it\nformulates exemplar selection as a Knapsack Integer Linear Program. The\nKnapsack framework provides the flexibility to incorporate diversity\nconstraints that prioritize exemplars with desirable attributes, and capacity\nconstraints that ensure that the prompt size respects the provided capacity\nbudgets. The effectiveness of SEER is demonstrated on FinQA and TAT-QA, two\nreal-world benchmarks for HybridQA, where it outperforms previous exemplar\nselection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tonglet_J/0/1/0/all/0/1\">Jonathan Tonglet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reusens_M/0/1/0/all/0/1\">Manon Reusens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borchert_P/0/1/0/all/0/1\">Philipp Borchert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baesens_B/0/1/0/all/0/1\">Bart Baesens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study of Instruction-tuning Large Language Models in Chinese. (arXiv:2310.07328v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07328","description":"<p>The success of ChatGPT validates the potential of large language models\n(LLMs) in artificial general intelligence (AGI). Subsequently, the release of\nLLMs has sparked the open-source community's interest in instruction-tuning,\nwhich is deemed to accelerate ChatGPT's replication process. However, research\non instruction-tuning LLMs in Chinese, the world's most spoken language, is\nstill in its early stages. Therefore, this paper makes an in-depth empirical\nstudy of instruction-tuning LLMs in Chinese, which can serve as a cookbook that\nprovides valuable findings for effectively customizing LLMs that can better\nrespond to Chinese instructions. Specifically, we systematically explore the\nimpact of LLM bases, parameter-efficient methods, instruction data types, which\nare the three most important elements for instruction-tuning. Besides, we also\nconduct experiment to study the impact of other factors, e.g., chain-of-thought\ndata and human-value alignment. We hope that this empirical study can make a\nmodest contribution to the open Chinese version of ChatGPT. This paper will\nrelease a powerful Chinese LLMs that is comparable to ChatGLM. The code and\ndata are available at https://github.com/PhoebusSi/Alpaca-CoT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_Q/0/1/0/all/0/1\">Qingyi Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zheng Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yanan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiping Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for Knowledge-Grounded Dialogue. (arXiv:2310.07659v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07659","description":"<p>Accurate knowledge selection is critical in knowledge-grounded dialogue\nsystems. Towards a closer look at it, we offer a novel perspective to organize\nexisting literature, i.e., knowledge selection coupled with, after, and before\ngeneration. We focus on the third under-explored category of study, which can\nnot only select knowledge accurately in advance, but has the advantage to\nreduce the learning, adjustment, and interpretation burden of subsequent\nresponse generation models, especially LLMs. We propose GATE, a\ngenerator-agnostic knowledge selection method, to prepare knowledge for\nsubsequent response generation models by selecting context-related knowledge\namong different knowledge structures and variable knowledge requirements.\nExperimental results demonstrate the superiority of GATE, and indicate that\nknowledge selection before generation is a lightweight yet effective way to\nfacilitate LLMs (e.g., ChatGPT) to generate more informative responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1\">Lang Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1\">Hongru Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhenglu Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A New Approach Towards Autoformalization. (arXiv:2310.07957v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07957","description":"<p>Verifying mathematical proofs is difficult, but can be automated with the\nassistance of a computer. Autoformalization is the task of automatically\ntranslating natural language mathematics into a formal language that can be\nverified by a program. This is a challenging task, and especially for\nhigher-level mathematics found in research papers. Research paper mathematics\nrequires large amounts of background and context. In this paper, we propose an\navenue towards tackling autoformalization for research-level mathematics, by\nbreaking the task into easier and more approachable subtasks: unlinked\nformalization (formalization with unlinked definitions and theorems), entity\nlinking (linking to the proper theorems and definitions), and finally adjusting\ntypes so it passes the type checker. In addition, we present arXiv2Formal, a\nbenchmark dataset for unlinked formalization consisting of 50 theorems\nformalized for the Lean theorem prover sampled from papers on arXiv.org. We\nwelcome any contributions from the community to future versions of this\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Patel_N/0/1/0/all/0/1\">Nilay Patel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_R/0/1/0/all/0/1\">Rahul Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flanigan_J/0/1/0/all/0/1\">Jeffrey Flanigan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-grained Conversational Decoding via Isotropic and Proximal Search. (arXiv:2310.08130v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08130","description":"<p>General-purpose text decoding approaches are usually adopted for dialogue\nresponse generation. Although the quality of the generated responses can be\nimproved with dialogue-specific encoding methods, conversational decoding\nmethods are still under-explored. Inspired by \\citet{wu2023learning} that a\ngood dialogue feature space should follow the rules of locality and isotropy,\nwe present a fine-grained conversational decoding method, termed\n\\textit{isotropic and proximal search (IPS)}. Our method is designed to\ngenerate the semantic-concentrated response, while still maintaining\ninformativeness and discrimination against the context. Experiments show that\nour approach outperforms existing decoding strategies in the dialogue field\nacross both automatic and human evaluation metrics. More in-depth analyses\nfurther confirm the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuxuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiling Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Better Evaluation of Instruction-Following: A Case-Study in Summarization. (arXiv:2310.08394v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08394","description":"<p>Despite recent advances, evaluating how well large language models (LLMs)\nfollow user instructions remains an open problem. While evaluation methods of\nlanguage models have seen a rise in prompt-based approaches, limited work on\nthe correctness of these methods has been conducted. In this work, we perform a\nmeta-evaluation of a variety of metrics to quantify how accurately they measure\nthe instruction-following abilities of LLMs. Our investigation is performed on\ngrounded query-based summarization by collecting a new short-form, real-world\ndataset riSum, containing 300 document-instruction pairs with 3 answers each.\nAll 900 answers are rated by 3 human annotators. Using riSum, we analyze the\nagreement between evaluation methods and human judgment. Finally, we propose\nnew LLM-based reference-free evaluation methods that improve upon established\nbaselines and perform on par with costly reference-based metrics that require\nhigh-quality summaries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Skopek_O/0/1/0/all/0/1\">Ondrej Skopek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1\">Rahul Aralikatte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gooding_S/0/1/0/all/0/1\">Sian Gooding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carbune_V/0/1/0/all/0/1\">Victor Carbune</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Zero-Shot Language Agent for Computer Control with Structured Reflection. (arXiv:2310.08740v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08740","description":"<p>Large language models (LLMs) have shown increasing capacity at planning and\nexecuting a high-level goal in a live computer environment (e.g. MiniWoB++). To\nperform a task, recent works often require a model to learn from trace examples\nof the task via either supervised learning or few/many-shot prompting. Without\nthese trace examples, it remains a challenge how an agent can autonomously\nlearn and improve its control on a computer, which limits the ability of an\nagent to perform a new task. We approach this problem with a zero-shot agent\nthat requires no given expert traces. Our agent plans for executable actions on\na partially observed environment, and iteratively progresses a task by\nidentifying and learning from its mistakes via self-reflection and structured\nthought management. On the easy tasks of MiniWoB++, we show that our zero-shot\nagent often outperforms recent SoTAs, with more efficient reasoning. For tasks\nwith more complexity, our reflective agent performs on par with prior best\nmodels, even though previous works had the advantages of accessing expert\ntraces or additional screen information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhiwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bryan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue System. (arXiv:2310.08877v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08877","description":"<p>Developing an efficient retriever to retrieve knowledge from a large-scale\nknowledge base (KB) is critical for task-oriented dialogue systems to\neffectively handle localized and specialized tasks. However, widely used\ngenerative models such as T5 and ChatGPT often struggle to differentiate subtle\ndifferences among the retrieved KB records when generating responses, resulting\nin suboptimal quality of generated responses. In this paper, we propose the\napplication of maximal marginal likelihood to train a perceptive retriever by\nutilizing signals from response generation for supervision. In addition, our\napproach goes beyond considering solely retrieved entities and incorporates\nvarious meta knowledge to guide the generator, thus improving the utilization\nof knowledge. We evaluate our approach on three task-oriented dialogue datasets\nusing T5 and ChatGPT as the backbone models. The results demonstrate that when\ncombined with meta knowledge, the response generator can effectively leverage\nhigh-quality knowledge records from the retriever and enhance the quality of\ngenerated responses. The codes and models of this paper are available at\nhttps://github.com/shenwzh3/MK-TOD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Weizhou Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yingqi Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Canbin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1\">Fanqi Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1\">Xiaojun Quan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bi_W/0/1/0/all/0/1\">Wei Bi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling. (arXiv:2310.09135v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.09135","description":"<p>In task-oriented dialogue scenarios, cross-domain zero-shot slot filling\nplays a vital role in leveraging source domain knowledge to learn a model with\nhigh generalization ability in unknown target domain where annotated data is\nunavailable. However, the existing state-of-the-art zero-shot slot filling\nmethods have limited generalization ability in target domain, they only show\neffective knowledge transfer on seen slots and perform poorly on unseen slots.\nTo alleviate this issue, we present a novel Hierarchical Contrastive Learning\nFramework (HiCL) for zero-shot slot filling. Specifically, we propose a coarse-\nto fine-grained contrastive learning based on Gaussian-distributed embedding to\nlearn the generalized deep semantic relations between utterance-tokens, by\noptimizing inter- and intra-token distribution distance. This encourages HiCL\nto generalize to the slot types unseen at training phase. Furthermore, we\npresent a new iterative label set semantics inference method to unbiasedly and\nseparately evaluate the performance of unseen slot types which entangled with\ntheir counterparts (i.e., seen slot types) in the previous zero-shot slot\nfilling evaluation methods. The extensive empirical experiments on four\ndatasets demonstrate that the proposed method achieves comparable or even\nbetter performance than the current state-of-the-art zero-shot slot filling\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junwen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yin Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation. (arXiv:2310.09886v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09886","description":"<p>Lifelong sequence generation (LSG), a problem in continual learning, aims to\ncontinually train a model on a sequence of generation tasks to learn constantly\nemerging new generation patterns while avoiding the forgetting of previous\nknowledge. Existing LSG methods mainly focus on maintaining old knowledge while\npaying little attention to knowledge transfer across tasks. In contrast, humans\ncan better learn new tasks by leveraging previously acquired knowledge from\nsimilar tasks. Inspired by the learning paradigm of humans, we propose Dynamic\nModule Expansion and Adaptation (DMEA), which enables the model to dynamically\ndetermine the architecture for acquiring new knowledge based on task\ncorrelation and select the most similar previous tasks to facilitate adaptation\nto new tasks. In addition, as the learning process can easily be biased towards\nthe current task which might cause more severe forgetting of previously learned\nknowledge, we propose dynamic gradient scaling to balance the learning of the\ncurrent task and replayed tasks. With extensive experiments, we demonstrate\nthat DMEA can consistently outperform existing methods in different LSG\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis. (arXiv:2310.10477v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10477","description":"<p>The rapid advancement of large language models (LLMs) presents both\nopportunities and challenges, particularly concerning unintentional generation\nof harmful and toxic responses. While the traditional alignment methods strive\nto steer LLMs towards desired performance and shield them from malicious\ncontent, this study proposes a novel alignment strategy rooted in mistake\nanalysis by exposing LLMs to flawed outputs purposefully and then conducting a\nthorough assessment to fully comprehend internal reasons via natural language\nanalysis. Thus, toxic responses can be transformed into instruction tuning\ncorpus for model alignment, and LLMs can not only be deterred from generating\nflawed responses but also trained to self-criticize, leveraging its innate\nability to discriminate toxic content. Experimental results demonstrate that\nthe proposed method outperforms conventional alignment techniques for safety\ninstruction following, while maintaining superior efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chunwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kuo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jianhua Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1\">Lanqing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mi_F/0/1/0/all/0/1\">Fei Mi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wenyong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhenguo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1\">Dit-Yan Yeung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1\">Lifeng Shang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xin Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Experimenting AI Technologies for Disinformation Combat: the IDMO Project. (arXiv:2310.11097v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11097","description":"<p>The Italian Digital Media Observatory (IDMO) project, part of a European\ninitiative, focuses on countering disinformation and fake news. This report\noutlines contributions from Rai-CRITS to the project, including: (i) the\ncreation of novel datasets for testing technologies (ii) development of an\nautomatic model for categorizing Pagella Politica verdicts to facilitate\nbroader analysis (iii) creation of an automatic model for recognizing textual\nentailment with exceptional accuracy on the FEVER dataset (iv) assessment using\nGPT-4 to identify textual entailmen (v) a game to raise awareness about fake\nnews at national events.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Canale_L/0/1/0/all/0/1\">Lorenzo Canale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Messina_A/0/1/0/all/0/1\">Alberto Messina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Systematic Assessment of Factual Knowledge in Large Language Models. (arXiv:2310.11638v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11638","description":"<p>Previous studies have relied on existing question-answering benchmarks to\nevaluate the knowledge stored in large language models (LLMs). However, this\napproach has limitations regarding factual knowledge coverage, as it mostly\nfocuses on generic domains which may overlap with the pretraining data. This\npaper proposes a framework to systematically assess the factual knowledge of\nLLMs by leveraging knowledge graphs (KGs). Our framework automatically\ngenerates a set of questions and expected answers from the facts stored in a\ngiven KG, and then evaluates the accuracy of LLMs in answering these questions.\nWe systematically evaluate the state-of-the-art LLMs with KGs in generic and\nspecific domains. The experiment shows that ChatGPT is consistently the top\nperformer across all domains. We also find that LLMs performance depends on the\ninstruction finetuning, domain and question complexity and is prone to\nadversarial context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1\">Linhao Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Thuy-Trang Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1\">Dinh Phung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Co-Speech Gesture for Multimodal Aphasia Type Detection. (arXiv:2310.11710v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11710","description":"<p>Aphasia, a language disorder resulting from brain damage, requires accurate\nidentification of specific aphasia types, such as Broca's and Wernicke's\naphasia, for effective treatment. However, little attention has been paid to\ndeveloping methods to detect different types of aphasia. Recognizing the\nimportance of analyzing co-speech gestures for distinguish aphasia types, we\npropose a multimodal graph neural network for aphasia type detection using\nspeech and corresponding gesture patterns. By learning the correlation between\nthe speech and gesture modalities for each aphasia type, our model can generate\ntextual representations sensitive to gesture information, leading to accurate\naphasia type detection. Extensive experiments demonstrate the superiority of\nour approach over existing methods, achieving state-of-the-art results (F1\n84.2\\%). We also show that gesture features outperform acoustic features,\nhighlighting the significance of gesture expression in detecting aphasia types.\nWe provide the codes for reproducibility purposes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Daeun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Son_S/0/1/0/all/0/1\">Sejung Son</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1\">Hyolim Jeon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Seungbae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jinyoung Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling. (arXiv:2310.11772v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11772","description":"<p>Topic segmentation is critical for obtaining structured long documents and\nimproving downstream tasks like information retrieval. Due to its ability of\nautomatically exploring clues of topic shift from a large amount of labeled\ndata, recent supervised neural models have greatly promoted the development of\nlong document topic segmentation, but leaving the deeper relationship of\nsemantic coherence and topic segmentation underexplored. Therefore, this paper\nenhances the supervised model's ability to capture coherence from both\nstructure and similarity perspectives to further improve the topic segmentation\nperformance, including the Topic-aware Sentence Structure Prediction (TSSP) and\nContrastive Semantic Similarity Learning (CSSL). Specifically, the TSSP task is\nproposed to force the model to comprehend structural information by learning\nthe original relations of adjacent sentences in a disarrayed document, which is\nconstructed by jointly disrupting the original document at the topic and\nsentence levels. In addition, we utilize inter- and intra-topic information to\nconstruct contrastive samples and design the CSSL objective to ensure that the\nsentences representations in the same topic have higher semantic similarity,\nwhile those in different topics are less similar. Extensive experiments show\nthat the Longformer with our approach significantly outperforms old\nstate-of-the-art (SOTA) methods. Our approach improves $F_{1}$ of old SOTA by\n3.42 (73.74 -&gt; 77.16) and reduces $P_{k}$ by 1.11 points (15.0 -&gt; 13.89) on\nWIKI-727K and achieves an average reduction of 0.83 points on $P_{k}$ on\nWikiSection. The average $P_{k}$ drop of 2.82 points on the two out-of-domain\ndatasets also illustrates the robustness of our approach\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI Responses in Health Consultations. (arXiv:2310.12489v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12489","description":"<p>Zero-shot classification enables text to be classified into classes not seen\nduring training. In this research, we investigate the effectiveness of\npre-trained language models to accurately classify responses from Doctors and\nAI in health consultations through zero-shot learning. Our study aims to\ndetermine whether these models can effectively detect if a text originates from\nhuman or AI models without specific corpus training. We collect responses from\ndoctors to patient inquiries about their health and pose the same\nquestion/response to AI models. While zero-shot language models show a good\nunderstanding of language in general, they have limitations in classifying\ndoctor and AI responses in healthcare consultations. This research lays the\ngroundwork for further research into this field of medical text classification,\ninforming the development of more effective approaches to accurately classify\ndoctor-generated and AI-generated text in health consultations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ojo_O/0/1/0/all/0/1\">Olumide E. Ojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adebanji_O/0/1/0/all/0/1\">Olaronke O. Adebanji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gelbukh_A/0/1/0/all/0/1\">Alexander Gelbukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calvo_H/0/1/0/all/0/1\">Hiram Calvo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_A/0/1/0/all/0/1\">Anna Feldman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ICU: Conquering Language Barriers in Vision-and-Language Modeling by Dividing the Tasks into Image Captioning and Language Understanding. (arXiv:2310.12531v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12531","description":"<p>Most multilingual vision-and-language (V&amp;L) research aims to accomplish\nmultilingual and multimodal capabilities within one model. However, the\nscarcity of multilingual captions for images has hindered the development. To\novercome this obstacle, we propose ICU, Image Caption Understanding, which\ndivides a V&amp;L task into two stages: a V&amp;L model performs image captioning in\nEnglish, and a multilingual language model (mLM), in turn, takes the caption as\nthe alt text and performs crosslingual language understanding. The burden of\nmultilingual processing is lifted off V&amp;L model and placed on mLM. Since the\nmultilingual text data is relatively of higher abundance and quality, ICU can\nfacilitate the conquering of language barriers for V&amp;L models. In experiments\non two tasks across 9 languages in the IGLUE benchmark, we show that ICU can\nachieve new state-of-the-art results for five languages, and comparable results\nfor the rest.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Guojun Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GestureGPT: Zero-shot Interactive Gesture Understanding and Grounding with Large Language Model Agents. (arXiv:2310.12821v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12821","description":"<p>Current gesture recognition systems primarily focus on identifying gestures\nwithin a predefined set, leaving a gap in connecting these gestures to\ninteractive GUI elements or system functions (e.g., linking a 'thumb-up'\ngesture to a 'like' button). We introduce GestureGPT, a novel zero-shot gesture\nunderstanding and grounding framework leveraging large language models (LLMs).\nGesture descriptions are formulated based on hand landmark coordinates from\ngesture videos and fed into our dual-agent dialogue system. A gesture agent\ndeciphers these descriptions and queries about the interaction context (e.g.,\ninterface, history, gaze data), which a context agent organizes and provides.\nFollowing iterative exchanges, the gesture agent discerns user intent,\ngrounding it to an interactive function. We validated the gesture description\nmodule using public first-view and third-view gesture datasets and tested the\nwhole system in two real-world settings: video streaming and smart home IoT\ncontrol. The highest zero-shot Top-5 grounding accuracies are 80.11% for video\nstreaming and 90.78% for smart home tasks, showing potential of the new gesture\nunderstanding paradigm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xin Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tengxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1\">Chun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shengdong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yiqiang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-22T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","syn":"http://purl.org/rss/1.0/modules/syndication/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/"}}]}]}