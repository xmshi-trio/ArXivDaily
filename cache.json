{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-08-07T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"MultiEM: Efficient and Effective Unsupervised Multi-Table Entity Matching. (arXiv:2308.01927v1 [cs.DB])","link":"http://arxiv.org/abs/2308.01927","description":"<p>Entity Matching (EM), which aims to identify all entity pairs referring to\nthe same real-world entity from relational tables, is one of the most important\ntasks in real-world data management systems. Due to the labeling process of EM\nbeing extremely labor-intensive, unsupervised EM is more applicable than\nsupervised EM in practical scenarios. Traditional unsupervised EM assumes that\nall entities come from two tables; however, it is more common to match entities\nfrom multiple tables in practical applications, that is, multi-table entity\nmatching (multi-table EM). Unfortunately, effective and efficient unsupervised\nmulti-table EM remains under-explored. To fill this gap, this paper formally\nstudies the problem of unsupervised multi-table entity matching and proposes an\neffective and efficient solution, termed as MultiEM. MultiEM is a parallelable\npipeline of enhanced entity representation, table-wise hierarchical merging,\nand density-based pruning. Extensive experimental results on six real-world\nbenchmark datasets demonstrate the superiority of MultiEM in terms of\neffectiveness and efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1\">Xiaocan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pengfei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuren Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoze Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yunjun Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?. (arXiv:2308.01936v1 [cs.AI])","link":"http://arxiv.org/abs/2308.01936","description":"<p>A hallmark of intelligence is the ability to use a familiar domain to make\ninferences about a less familiar domain, known as analogical reasoning. In this\narticle, we delve into the performance of Large Language Models (LLMs) in\ndealing with progressively complex analogies expressed in unstructured text. We\ndiscuss analogies at four distinct levels of complexity: lexical analogies,\nsyntactic analogies, semantic analogies, and pragmatic analogies. As the\nanalogies become more complex, they require increasingly extensive, diverse\nknowledge beyond the textual content, unlikely to be found in the lexical\nco-occurrence statistics that power LLMs. To address this, we discuss the\nnecessity of employing Neuro-symbolic AI techniques that combine statistical\nand symbolic AI, informing the representation of unstructured text to highlight\nand augment relevant content, provide abstraction and guide the mapping\nprocess. Our knowledge-informed approach maintains the efficiency of LLMs while\npreserving the ability to explain analogies for pedagogical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wijesiriwardene_T/0/1/0/all/0/1\">Thilini Wijesiriwardene</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1\">Amit Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shalin_V/0/1/0/all/0/1\">Valerie L. Shalin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1\">Amitava Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement Estimation in Conversation. (arXiv:2308.01966v1 [cs.MM])","link":"http://arxiv.org/abs/2308.01966","description":"<p>Conversational engagement estimation is posed as a regression problem,\nentailing the identification of the favorable attention and involvement of the\nparticipants in the conversation. This task arises as a crucial pursuit to gain\ninsights into human's interaction dynamics and behavior patterns within a\nconversation. In this research, we introduce a dilated convolutional\nTransformer for modeling and estimating human engagement in the MULTIMEDIATE\n2023 competition. Our proposed system surpasses the baseline models, exhibiting\na noteworthy $7$\\% improvement on test set and $4$\\% on validation set.\nMoreover, we employ different modality fusion mechanism and show that for this\ntype of data, a simple concatenated method with self-attention fusion gains the\nbest performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tu_V/0/1/0/all/0/1\">Vu Ngoc Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_V/0/1/0/all/0/1\">Van Thong Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hyung-Jeong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">M. Zaigham Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nawaz_S/0/1/0/all/0/1\">Shah Nawaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nandakumar_K/0/1/0/all/0/1\">Karthik Nandakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Soo-Hyung Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces. (arXiv:2308.01976v1 [cs.LG])","link":"http://arxiv.org/abs/2308.01976","description":"<p>Typographical errors are a major source of frustration for visitors of online\nmarketplaces. Because of the domain-specific nature of these marketplaces and\nthe very short queries users tend to search for, traditional spell cheking\nsolutions do not perform well in correcting typos. We present a data\naugmentation method to address the lack of annotated typo data and train a\nrecurrent neural network to learn context-limited domain-specific embeddings.\nThose embeddings are deployed in a real-time inferencing API for the Microsoft\nAppSource marketplace to find the closest match between a misspelled user query\nand the available product names. Our data efficient solution shows that\ncontrolled high quality synthetic data may be a powerful tool especially\nconsidering the current climate of large language models which rely on\nprohibitively huge and often uncontrolled datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1\">Dayananda Ubrangala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_J/0/1/0/all/0/1\">Juhi Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1\">Ravi Prasad Kondapalli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+R_K/0/1/0/all/0/1\">Kiran R</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwala_A/0/1/0/all/0/1\">Amit Agarwala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boue_L/0/1/0/all/0/1\">Laurent Bou&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bengali Fake Reviews: A Benchmark Dataset and Detection System. (arXiv:2308.01987v1 [cs.CL])","link":"http://arxiv.org/abs/2308.01987","description":"<p>The proliferation of fake reviews on various online platforms has created a\nmajor concern for both consumers and businesses. Such reviews can deceive\ncustomers and cause damage to the reputation of products or services, making it\ncrucial to identify them. Although the detection of fake reviews has been\nextensively studied in English language, detecting fake reviews in non-English\nlanguages such as Bengali is still a relatively unexplored research area. This\npaper introduces the Bengali Fake Review Detection (BFRD) dataset, the first\npublicly available dataset for identifying fake reviews in Bengali. The dataset\nconsists of 7710 non-fake and 1339 fake food-related reviews collected from\nsocial media posts. To convert non-Bengali words in a review, a unique pipeline\nhas been proposed that translates English words to their corresponding Bengali\nmeaning and also back transliterates Romanized Bengali to Bengali. We have\nconducted rigorous experimentation using multiple deep learning and pre-trained\ntransformer language models to develop a reliable detection system. Finally, we\npropose a weighted ensemble model that combines four pre-trained transformers:\nBanglaBERT, BanglaBERT Base, BanglaBERT Large, and BanglaBERT Generator .\nAccording to the experiment results, the proposed ensemble model obtained a\nweighted F1-score of 0.9843 on 13390 reviews, including 1339 actual fake\nreviews and 5356 augmented fake reviews generated with the nlpaug library. The\nremaining 6695 reviews were randomly selected from the 7710 non-fake instances.\nThe model achieved a 0.9558 weighted F1-score when the fake reviews were\naugmented using the bnaug library.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahariar_G/0/1/0/all/0/1\">G. M. Shahariar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shawon_M/0/1/0/all/0/1\">Md. Tanvir Rouf Shawon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_F/0/1/0/all/0/1\">Faisal Muhammad Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_M/0/1/0/all/0/1\">Mohammad Shafiul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahbub_M/0/1/0/all/0/1\">Md. Shahriar Mahbub</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Federated Representation Learning for Automatic Speech Recognition. (arXiv:2308.02013v1 [cs.SD])","link":"http://arxiv.org/abs/2308.02013","description":"<p>Federated Learning (FL) is a privacy-preserving paradigm, allowing edge\ndevices to learn collaboratively without sharing data. Edge devices like Alexa\nand Siri are prospective sources of unlabeled audio data that can be tapped to\nlearn robust audio representations. In this work, we bring Self-supervised\nLearning (SSL) and FL together to learn representations for Automatic Speech\nRecognition respecting data privacy constraints. We use the speaker and chapter\ninformation in the unlabeled speech dataset, Libri-Light, to simulate non-IID\nspeaker-siloed data distributions and pre-train an LSTM encoder with the\nContrastive Predictive Coding framework with FedSGD. We show that the\npre-trained ASR encoder in FL performs as well as a centrally pre-trained model\nand produces an improvement of 12-15% (WER) compared to no pre-training. We\nfurther adapt the federated pre-trained models to a new language, French, and\nshow a 20% (WER) improvement over no pre-training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rames_G/0/1/0/all/0/1\">Guruprasad V Rames</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chennupati_G/0/1/0/all/0/1\">Gopinath Chennupati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1\">Milind Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_A/0/1/0/all/0/1\">Anit Kumar Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1\">Ariya Rastrow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Droppo_J/0/1/0/all/0/1\">Jasha Droppo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Baby Llama: knowledge distillation from an ensemble of teachers trained on a small dataset with no performance penalty. (arXiv:2308.02019v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02019","description":"<p>We present our proposed solution to the BabyLM challenge [<a href=\"/abs/2301.11796\">arXiv:2301.11796</a>],\nwhose goal was to improve the sample efficiency of language models. We trained\nan ensemble consisting of a GPT-2 and small LLaMA models on the\ndevelopmentally-plausible, 10M-word BabyLM dataset, then distilled it into a\nsmall, 58M-parameter LLaMA model, which exceeds in performance both of its\nteachers as well as a similar model trained without distillation. This suggests\nthat distillation can not only retain the full performance of the teacher model\nwhen the latter is trained on a sufficiently small dataset; it can exceed it,\nand lead to significantly better performance than direct training.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Timiryasov_I/0/1/0/all/0/1\">Inar Timiryasov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tastet_J/0/1/0/all/0/1\">Jean-Loup Tastet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature Extraction Techniques, Ensembling, and Deep Learning Models. (arXiv:2308.02022v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02022","description":"<p>While reaching for NLP systems that maximize accuracy, other important\nmetrics of system performance are often overlooked. Prior models are easily\nforgotten despite their possible suitability in settings where large computing\nresources are unavailable or relatively more costly. In this paper, we perform\na broad comparative evaluation of document-level sentiment analysis models with\na focus on resource costs that are important for the feasibility of model\ndeployment and general climate consciousness. Our experiments consider\ndifferent feature extraction techniques, the effect of ensembling,\ntask-specific deep learning modeling, and domain-independent large language\nmodels (LLMs). We find that while a fine-tuned LLM achieves the best accuracy,\nsome alternate configurations provide huge (up to 24, 283 *) resource savings\nfor a marginal (&lt;1%) loss in accuracy. Furthermore, we find that for smaller\ndatasets, the differences in accuracy shrink while the difference in resource\nconsumption grows further.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamruzzaman_M/0/1/0/all/0/1\">Mahammed Kamruzzaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1\">Gene Louis Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Twitter Data Tell Us about the Future?. (arXiv:2308.02035v1 [cs.CY])","link":"http://arxiv.org/abs/2308.02035","description":"<p>Anticipation is a fundamental human cognitive ability that involves thinking\nabout and living towards the future. While language markers reflect\nanticipatory thinking, research on anticipation from the perspective of natural\nlanguage processing is limited. This study aims to investigate the futures\nprojected by futurists on Twitter and explore the impact of language cues on\nanticipatory thinking among social media users. We address the research\nquestions of what futures Twitter's futurists anticipate and share, and how\nthese anticipated futures can be modeled from social data. To investigate this,\nwe review related works on anticipation, discuss the influence of language\nmarkers and prestigious individuals on anticipatory thinking, and present a\ntaxonomy system categorizing futures into \"present futures\" and \"future\npresent\". This research presents a compiled dataset of over 1 million publicly\nshared tweets by future influencers and develops a scalable NLP pipeline using\nSOTA models. The study identifies 15 topics from the LDA approach and 100\ndistinct topics from the BERTopic approach within the futurists' tweets. These\nfindings contribute to the research on topic modelling and provide insights\ninto the futures anticipated by Twitter's futurists. The research demonstrates\nthe futurists' language cues signals futures-in-the-making that enhance social\nmedia users to anticipate their own scenarios and respond to them in present.\nThe fully open-sourced dataset, interactive analysis, and reproducible source\ncode are available for further exploration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Landowska_A/0/1/0/all/0/1\">Alina Landowska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robak_M/0/1/0/all/0/1\">Marek Robak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skorski_M/0/1/0/all/0/1\">Maciej Skorski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Proposing a conceptual framework: social media listening for public health behavior. (arXiv:2308.02037v1 [cs.CY])","link":"http://arxiv.org/abs/2308.02037","description":"<p>Existing communications and behavioral theories have been adopted to address\nhealth misinformation. Although various theories and models have been used to\ninvestigate the COVID-19 pandemic, there is no framework specially designed for\nsocial listening or misinformation studies using social media data and natural\nlanguage processing techniques. This study aimed to propose a novel yet\ntheory-based conceptual framework for misinformation research. We collected\ntheories and models used in COVID-19 related studies published in peer-reviewed\njournals. The theories and models ranged from health behaviors, communications,\nto misinformation. They are analyzed and critiqued for their components,\nfollowed by proposing a conceptual framework with a demonstration. We reviewed\nHealth Belief Model, Theory of Planned Behavior/Reasoned Action, Communication\nfor Behavioral Impact, Transtheoretical Model, Uses and Gratifications Theory,\nSocial Judgment Theory, Risk Information Seeking and Processing Model,\nBehavioral and Social Drivers, and Hype Loop. Accordingly, we proposed the\nSocial Media Listening for Public Health Behavior Conceptual Framework by not\nonly integrating important attributes of existing theories, but also adding new\nattributes. The proposed conceptual framework was demonstrated in the Freedom\nConvoy social media listening. The proposed conceptual framework can be used to\nbetter understand public discourse on social media, and it can be integrated\nwith other data analyses to gather a more comprehensive picture. The framework\nwill continue to be revised and adopted as health misinformation evolves.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tsao_S/0/1/0/all/0/1\">Shu-Feng Tsao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Helen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_S/0/1/0/all/0/1\">Samantha Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Butt_Z/0/1/0/all/0/1\">Zahid A. Butt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT. (arXiv:2308.02044v1 [cs.DL])","link":"http://arxiv.org/abs/2308.02044","description":"<p>This article examines the impact of Artificial Intelligence on the archival\nheritage digitization processes, specifically regarding the manuscripts'\nautomatic transcription, their correction, and normalization. It highlights how\ndigitality has compelled scholars to redefine Archive and History field and has\nfacilitated the accessibility of analogue sources through digitization and\nintegration into big data. The study focuses on two AI systems, namely\nTranskribus and ChatGPT, which enable efficient analysis and transcription of\ndigitized sources. The article presents a test of ChatGPT, which was utilized\nto normalize the text of 366 letters stored in the Correspondence section of\nthe Biscari Archive (Catania). Although the AI exhibited some limitations that\nresulted in inaccuracies, the corrected texts met expectations. Overall, the\narticle concludes that digitization and AI can significantly enhance archival\nand historical research by allowing the analysis of vast amounts of data and\nthe application of computational linguistic tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Spina_S/0/1/0/all/0/1\">Salvatore Spina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations. (arXiv:2308.02053v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02053","description":"<p>Large Language Models (LLMs) have seen widespread deployment in various\nreal-world applications. Understanding these biases is crucial to comprehend\nthe potential downstream consequences when using LLMs to make decisions,\nparticularly for historically disadvantaged groups. In this work, we propose a\nsimple method for analyzing and comparing demographic bias in LLMs, through the\nlens of job recommendations. We demonstrate the effectiveness of our method by\nmeasuring intersectional biases within ChatGPT and LLaMA, two cutting-edge\nLLMs. Our experiments primarily focus on uncovering gender identity and\nnationality bias; however, our method can be extended to examine biases\nassociated with any intersection of demographic identities. We identify\ndistinct biases in both models toward various demographic identities, such as\nboth models consistently suggesting low-paying jobs for Mexican workers or\npreferring to recommend secretarial roles to women. Our study highlights the\nimportance of measuring the bias of LLMs in downstream applications to\nunderstand the potential for harm and inequitable outcomes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Salinas_A/0/1/0/all/0/1\">Abel Salinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_P/0/1/0/all/0/1\">Parth Vipul Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yuzhong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCormack_R/0/1/0/all/0/1\">Robert McCormack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Morstatter_F/0/1/0/all/0/1\">Fred Morstatter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries. (arXiv:2308.02055v1 [cs.IR])","link":"http://arxiv.org/abs/2308.02055","description":"<p>Query autocomplete (QAC) also known as typeahead, suggests list of complete\nqueries as user types prefix in the search box. It is one of the key features\nof modern search engines specially in e-commerce. One of the goals of typeahead\nis to suggest relevant queries to users which are seasonally important. In this\npaper we propose a neural network based natural language processing (NLP)\nalgorithm to incorporate seasonality as a signal and present end to end\nevaluation of the QAC ranking model. Incorporating seasonality into\nautocomplete ranking model can improve autocomplete relevance and business\nmetric.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1\">Prateek Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1\">Shan Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajan_A/0/1/0/all/0/1\">Adithya Rajan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causality Guided Disentanglement for Cross-Platform Hate Speech Detection. (arXiv:2308.02080v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02080","description":"<p>Social media platforms, despite their value in promoting open discourse, are\noften exploited to spread harmful content. Current deep learning and natural\nlanguage processing models used for detecting this harmful content overly rely\non domain-specific terms affecting their capabilities to adapt to generalizable\nhate speech detection. This is because they tend to focus too narrowly on\nparticular linguistic signals or the use of certain categories of words.\nAnother significant challenge arises when platforms lack high-quality annotated\ndata for training, leading to a need for cross-platform models that can adapt\nto different distribution shifts. Our research introduces a cross-platform hate\nspeech detection model capable of being trained on one platform's data and\ngeneralizing to multiple unseen platforms. To achieve good generalizability\nacross platforms, one way is to disentangle the input representations into\ninvariant and platform-dependent features. We also argue that learning causal\nrelationships, which remain constant across diverse environments, can\nsignificantly aid in understanding invariant representations in hate speech. By\ndisentangling input into platform-dependent features (useful for predicting\nhate targets) and platform-independent features (used to predict the presence\nof hate), we learn invariant representations resistant to distribution shifts.\nThese features are then used to predict hate speech across unseen platforms.\nOur extensive experiments across four platforms highlight our model's enhanced\nefficacy compared to existing state-of-the-art methods in detecting generalized\nhate speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sheth_P/0/1/0/all/0/1\">Paras Sheth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumarage_T/0/1/0/all/0/1\">Tharindu Kumarage</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moraffah_R/0/1/0/all/0/1\">Raha Moraffah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Huan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets. (arXiv:2308.02092v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02092","description":"<p>Accurate transcription of proper names and technical terms is particularly\nimportant in speech-to-text applications for business conversations. These\nwords, which are essential to understanding the conversation, are often rare\nand therefore likely to be under-represented in text and audio training data,\ncreating a significant challenge in this domain. We present a two-step keyword\nboosting mechanism that successfully works on normalized unigrams and n-grams\nrather than just single tokens, which eliminates missing hits issues with\nboosting raw targets. In addition, we show how adjusting the boosting weight\nlogic avoids over-boosting multi-token keywords. This improves our keyword\nrecognition rate by 26% relative on our proprietary in-domain dataset and 2% on\nLibriSpeech. This method is particularly useful on targets that involve\nnon-alphabetic characters or have non-standard pronunciations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wang Yau Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nadig_S/0/1/0/all/0/1\">Shreekantha Nadig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Karol Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_Z/0/1/0/all/0/1\">Zafarullah Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Riqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vandieken_S/0/1/0/all/0/1\">Simon Vandieken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robertson_J/0/1/0/all/0/1\">Jonas Robertson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mailhot_F/0/1/0/all/0/1\">Fred Mailhot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt2Gaussia: Uncertain Prompt-learning for Script Event Prediction. (arXiv:2308.02103v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02103","description":"<p>Script Event Prediction (SEP) aims to predict the subsequent event for a\ngiven event chain from a candidate list. Prior research has achieved great\nsuccess by integrating external knowledge to enhance the semantics, but it is\nlaborious to acquisite the appropriate knowledge resources and retrieve the\nscript-related knowledge. In this paper, we regard public pre-trained language\nmodels as knowledge bases and automatically mine the script-related knowledge\nvia prompt-learning. Still, the scenario-diversity and label-ambiguity in\nscripts make it uncertain to construct the most functional prompt and label\ntoken in prompt learning, i.e., prompt-uncertainty and verbalizer-uncertainty.\nConsidering the innate ability of Gaussian distribution to express uncertainty,\nwe deploy the prompt tokens and label tokens as random variables following\nGaussian distributions, where a prompt estimator and a verbalizer estimator are\nproposed to estimate their probabilistic representations instead of\ndeterministic representations. We take the lead to explore prompt-learning in\nSEP and provide a fresh perspective to enrich the script semantics. Our method\nis evaluated on the most widely used benchmark and a newly proposed large-scale\none. Experiments show that our method, which benefits from knowledge evoked\nfrom pre-trained language models, outperforms prior baselines by 1.46\\% and\n1.05\\% on two benchmarks, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1\">Shiyao Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_J/0/1/0/all/0/1\">Jiawei Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuebin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tingwen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jinqiao Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chinese Financial Text Emotion Mining: GCGTS -- A Character Relationship-based Approach for Simultaneous Aspect-Opinion Pair Extraction. (arXiv:2308.02113v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02113","description":"<p>Aspect-Opinion Pair Extraction (AOPE) from Chinese financial texts is a\nspecialized task in fine-grained text sentiment analysis. The main objective is\nto extract aspect terms and opinion terms simultaneously from a diverse range\nof financial texts. Previous studies have mainly focused on developing grid\nannotation schemes within grid-based models to facilitate this extraction\nprocess. However, these methods often rely on character-level (token-level)\nfeature encoding, which may overlook the logical relationships between Chinese\ncharacters within words. To address this limitation, we propose a novel method\ncalled Graph-based Character-level Grid Tagging Scheme (GCGTS). The GCGTS\nmethod explicitly incorporates syntactic structure using Graph Convolutional\nNetworks (GCN) and unifies the encoding of characters within the same syntactic\nsemantic unit (Chinese word level). Additionally, we introduce an image\nconvolutional structure into the grid model to better capture the local\nrelationships between characters within evaluation units. This innovative\nstructure reduces the excessive reliance on pre-trained language models and\nemphasizes the modeling of structure and local relationships, thereby improving\nthe performance of the model on Chinese financial texts. Through comparative\nexperiments with advanced models such as Synchronous Double-channel Recurrent\nNetwork (SDRN) and Grid Tagging Scheme (GTS), the proposed GCGTS model\ndemonstrates significant improvements in performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dexi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP. (arXiv:2308.02122v1 [cs.CR])","link":"http://arxiv.org/abs/2308.02122","description":"<p>Backdoor attacks have emerged as a prominent threat to natural language\nprocessing (NLP) models, where the presence of specific triggers in the input\ncan lead poisoned models to misclassify these inputs to predetermined target\nclasses. Current detection mechanisms are limited by their inability to address\nmore covert backdoor strategies, such as style-based attacks. In this work, we\npropose an innovative test-time poisoned sample detection framework that hinges\non the interpretability of model predictions, grounded in the semantic meaning\nof inputs. We contend that triggers (e.g., infrequent words) are not supposed\nto fundamentally alter the underlying semantic meanings of poisoned samples as\nthey want to stay stealthy. Based on this observation, we hypothesize that\nwhile the model's predictions for paraphrased clean samples should remain\nstable, predictions for poisoned samples should revert to their true labels\nupon the mutations applied to triggers during the paraphrasing process. We\nemploy ChatGPT, a state-of-the-art large language model, as our paraphraser and\nformulate the trigger-removal task as a prompt engineering problem. We adopt\nfuzzing, a technique commonly used for unearthing software vulnerabilities, to\ndiscover optimal paraphrase prompts that can effectively eliminate triggers\nwhile concurrently maintaining input semantics. Experiments on 4 types of\nbackdoor attacks, including the subtle style backdoors, and 4 distinct datasets\ndemonstrate that our approach surpasses baseline methods, including STRIP, RAP,\nand ONION, in precision and recall.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_L/0/1/0/all/0/1\">Lu Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_G/0/1/0/all/0/1\">Guanhong Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaiyuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1\">Guangyu Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tweet Insights: A Visualization Platform to Extract Temporal Insights from Twitter. (arXiv:2308.02142v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02142","description":"<p>This paper introduces a large collection of time series data derived from\nTwitter, postprocessed using word embedding techniques, as well as specialized\nfine-tuned language models. This data comprises the past five years and\ncaptures changes in n-gram frequency, similarity, sentiment and topic\ndistribution. The interface built on top of this data enables temporal analysis\nfor detecting and characterizing shifts in meaning, including complementary\ninformation to trending metrics, such as sentiment and topic association over\ntime. We release an online demo for easy experimentation, and we share code and\nthe underlying aggregated data for future work. In this paper, we also discuss\nthree case studies unlocked thanks to our platform, showcasing its potential\nfor temporal linguistic analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Loureiro_D/0/1/0/all/0/1\">Daniel Loureiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezaee_K/0/1/0/all/0/1\">Kiamehr Rezaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riahi_T/0/1/0/all/0/1\">Talayeh Riahi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Barbieri_F/0/1/0/all/0/1\">Francesco Barbieri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neves_L/0/1/0/all/0/1\">Leonardo Neves</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anke_L/0/1/0/all/0/1\">Luis Espinosa Anke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization. (arXiv:2308.02151v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02151","description":"<p>Recent months have seen the emergence of a powerful new trend in which large\nlanguage models (LLMs) are augmented to become autonomous language agents\ncapable of performing objective oriented multi-step tasks on their own, rather\nthan merely responding to queries from human users. Most existing language\nagents, however, are not optimized using environment-specific rewards. Although\nsome agents enable iterative refinement through verbal feedback, they do not\nreason and plan in ways that are compatible with gradient-based learning from\nrewards. This paper introduces a principled framework for reinforcing large\nlanguage agents by learning a retrospective model, which automatically tunes\nthe language agent prompts from environment feedback through policy gradient.\nSpecifically, our proposed agent architecture learns from rewards across\nmultiple environments and tasks, for fine-tuning a pre-trained language model\nwhich refines the language agent prompt by summarizing the root cause of prior\nfailed attempts and proposing action plans. Experimental results on various\ntasks demonstrate that the language agents improve over time and that our\napproach considerably outperforms baselines that do not properly leverage\ngradients from the environment. This demonstrates that using policy gradient\noptimization to improve language agents, for which we believe our work is one\nof the first, seems promising and can be applied to optimize other models in\nthe agent architecture to enhance agent performances over time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1\">Weiran Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heinecke_S/0/1/0/all/0/1\">Shelby Heinecke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1\">Juan Carlos Niebles</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yihao Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1\">Le Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murthy_R/0/1/0/all/0/1\">Rithesh Murthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeyuan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jianguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1\">Devansh Arpit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mui_P/0/1/0/all/0/1\">Phil Mui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Huan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1\">Caiming Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1\">Silvio Savarese</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speaker Diarization of Scripted Audiovisual Content. (arXiv:2308.02160v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02160","description":"<p>The media localization industry usually requires a verbatim script of the\nfinal film or TV production in order to create subtitles or dubbing scripts in\na foreign language. In particular, the verbatim script (i.e. as-broadcast\nscript) must be structured into a sequence of dialogue lines each including\ntime codes, speaker name and transcript. Current speech recognition technology\nalleviates the transcription step. However, state-of-the-art speaker\ndiarization models still fall short on TV shows for two main reasons: (i) their\ninability to track a large number of speakers, (ii) their low accuracy in\ndetecting frequent speaker changes. To mitigate this problem, we present a\nnovel approach to leverage production scripts used during the shooting process,\nto extract pseudo-labeled data for the speaker diarization task. We propose a\nnovel semi-supervised approach and demonstrate improvements of 51.7% relative\nto two unsupervised baseline models on our metrics on a 66 show test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Virkar_Y/0/1/0/all/0/1\">Yogesh Virkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thompson_B/0/1/0/all/0/1\">Brian Thompson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paturi_R/0/1/0/all/0/1\">Rohit Paturi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1\">Sundararajan Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Federico_M/0/1/0/all/0/1\">Marcello Federico</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"You talk what you read: Understanding News Comment Behavior by Dispositional and Situational Attribution. (arXiv:2308.02168v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02168","description":"<p>Many news comment mining studies are based on the assumption that comment is\nexplicitly linked to the corresponding news. In this paper, we observed that\nusers' comments are also heavily influenced by their individual characteristics\nembodied by the interaction history. Therefore, we position to understand news\ncomment behavior by considering both the dispositional factors from news\ninteraction history, and the situational factors from corresponding news. A\nthree-part encoder-decoder framework is proposed to model the generative\nprocess of news comment. The resultant dispositional and situational\nattribution contributes to understanding user focus and opinions, which are\nvalidated in applications of reader-aware news summarization and news\naspect-opinion forecasting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuhang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">Dongyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jitao Sang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology. (arXiv:2308.02180v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02180","description":"<p>Clinical trial matching is a key process in health delivery and discovery. In\npractice, it is plagued by overwhelming unstructured data and unscalable manual\nprocessing. In this paper, we conduct a systematic study on scaling clinical\ntrial matching using large language models (LLMs), with oncology as the focus\narea. Our study is grounded in a clinical trial matching system currently in\ntest deployment at a large U.S. health network. Initial findings are promising:\nout of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate\neligibility criteria of clinical trials and extract complex matching logic\n(e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially\noutperform prior strong baselines and may serve as a preliminary solution to\nhelp triage patient-trial candidates with humans in the loop. Our study also\nreveals a few significant growth areas for applying LLMs to end-to-end clinical\ntrial matching, such as context limitation and accuracy, especially in\nstructuring patient information from longitudinal medical records.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1\">Cliff Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Sheng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moung_C/0/1/0/all/0/1\">Christine Moung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abel_J/0/1/0/all/0/1\">Jacob Abel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weerasinghe_R/0/1/0/all/0/1\">Roshanthi Weerasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Piening_B/0/1/0/all/0/1\">Brian Piening</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1\">Tristan Naumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bifulco_C/0/1/0/all/0/1\">Carlo Bifulco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Fake to Hyperpartisan News Detection Using Domain Adaptation. (arXiv:2308.02185v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02185","description":"<p>Unsupervised Domain Adaptation (UDA) is a popular technique that aims to\nreduce the domain shift between two data distributions. It was successfully\napplied in computer vision and natural language processing. In the current\nwork, we explore the effects of various unsupervised domain adaptation\ntechniques between two text classification tasks: fake and hyperpartisan news\ndetection. We investigate the knowledge transfer from fake to hyperpartisan\nnews detection without involving target labels during training. Thus, we\nevaluate UDA, cluster alignment with a teacher, and cross-domain contrastive\nlearning. Extensive experiments show that these techniques improve performance,\nwhile including data augmentation further enhances the results. In addition, we\ncombine clustering and topic modeling algorithms with UDA, resulting in\nimproved performances compared to the initial UDA setup.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Smadu_R/0/1/0/all/0/1\">R&#x103;zvan-Alexandru Sm&#x103;du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Echim_S/0/1/0/all/0/1\">Sebastian-Vasile Echim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1\">Dumitru-Clementin Cercel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marin_I/0/1/0/all/0/1\">Iuliana Marin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pop_F/0/1/0/all/0/1\">Florin Pop</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition. (arXiv:2308.02190v1 [cs.SD])","link":"http://arxiv.org/abs/2308.02190","description":"<p>Cross-corpus speech emotion recognition (SER) seeks to generalize the ability\nof inferring speech emotion from a well-labeled corpus to an unlabeled one,\nwhich is a rather challenging task due to the significant discrepancy between\ntwo corpora. Existing methods, typically based on unsupervised domain\nadaptation (UDA), struggle to learn corpus-invariant features by global\ndistribution alignment, but unfortunately, the resulting features are mixed\nwith corpus-specific features or not class-discriminative. To tackle these\nchallenges, we propose a novel Emotion Decoupling aNd Alignment learning\nframework (EMO-DNA) for cross-corpus SER, a novel UDA method to learn\nemotion-relevant corpus-invariant features. The novelties of EMO-DNA are\ntwo-fold: contrastive emotion decoupling and dual-level emotion alignment. On\none hand, our contrastive emotion decoupling achieves decoupling learning via a\ncontrastive decoupling loss to strengthen the separability of emotion-relevant\nfeatures from corpus-specific ones. On the other hand, our dual-level emotion\nalignment introduces an adaptive threshold pseudo-labeling to select confident\ntarget samples for class-level alignment, and performs corpus-level alignment\nto jointly guide model for learning class-discriminative corpus-invariant\nfeatures across corpora. Extensive experimental results demonstrate the\nsuperior performance of EMO-DNA over the state-of-the-art methods in several\ncross-corpus scenarios. Source code is available at\nhttps://github.com/Jiaxin-Ye/Emo-DNA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jiaxin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yujie Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1\">Xin-Cheng Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chenglong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhizhong Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kunhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1\">Hongming Shan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Explaining Relation Classification Models with Semantic Extents. (arXiv:2308.02193v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02193","description":"<p>In recent years, the development of large pretrained language models, such as\nBERT and GPT, significantly improved information extraction systems on various\ntasks, including relation classification. State-of-the-art systems are highly\naccurate on scientific benchmarks. A lack of explainability is currently a\ncomplicating factor in many real-world applications. Comprehensible systems are\nnecessary to prevent biased, counterintuitive, or harmful decisions.\n</p>\n<p>We introduce semantic extents, a concept to analyze decision patterns for the\nrelation classification task. Semantic extents are the most influential parts\nof texts concerning classification decisions. Our definition allows similar\nprocedures to determine semantic extents for humans and models. We provide an\nannotation tool and a software framework to determine semantic extents for\nhumans and models conveniently and reproducibly. Comparing both reveals that\nmodels tend to learn shortcut patterns from data. These patterns are hard to\ndetect with current interpretability methods, such as input reductions. Our\napproach can help detect and eliminate spurious decision patterns during model\ndevelopment. Semantic extents can increase the reliability and security of\nnatural language processing systems. Semantic extents are an essential step in\nenabling applications in critical areas like healthcare or finance. Moreover,\nour work opens new research directions for developing methods to explain deep\nlearning models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kloser_L/0/1/0/all/0/1\">Lars Kl&#xf6;ser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Busgen_A/0/1/0/all/0/1\">Andre B&#xfc;sgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kohl_P/0/1/0/all/0/1\">Philipp Kohl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraft_B/0/1/0/all/0/1\">Bodo Kraft</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zundorf_A/0/1/0/all/0/1\">Albert Z&#xfc;ndorf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Spanish Clinical Language Models. (arXiv:2308.02199v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02199","description":"<p>This survey focuses in encoder Language Models for solving tasks in the\nclinical domain in the Spanish language. We review the contributions of 17\ncorpora focused mainly in clinical tasks, then list the most relevant Spanish\nLanguage Models and Spanish Clinical Language models. We perform a thorough\ncomparison of these models by benchmarking them over a curated subset of the\navailable corpora, in order to find the best-performing ones; in total more\nthan 3000 models were fine-tuned for this study. All the tested corpora and the\nbest models are made publically available in an accessible way, so that the\nresults can be reproduced by independent teams or challenged in the future when\nnew Spanish Clinical Language models are created.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Subies_G/0/1/0/all/0/1\">Guillem Garc&#xed;a Subies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_A/0/1/0/all/0/1\">&#xc1;lvaro Barbero Jim&#xe9;nez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_P/0/1/0/all/0/1\">Paloma Mart&#xed;nez Fern&#xe1;ndez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation. (arXiv:2308.02223v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02223","description":"<p>Applying Reinforcement Learning (RL) to sequence generation models enables\nthe direct optimization of long-term rewards (\\textit{e.g.,} BLEU and human\nfeedback), but typically requires large-scale sampling over a space of action\nsequences. This is a computational challenge as presented by the practice of\nsequence generation problems, such as machine translation, where we often deal\nwith a large action space (\\textit{e.g.,} a vocabulary) and a long action\nsequence (\\textit{e.g.,} a translation). In this work, we introduce two-stage\nsampling and dynamic sampling approaches to improve the sampling efficiency\nduring training sequence generation models via RL. We experiment with our\napproaches on the traditional sequence generation tasks, including machine\ntranslation and abstractive summarization. Furthermore, we evaluate our\napproaches in RL from human feedback (RLHF) through training a large language\nmodel using the reward model. Experimental results show that the efficient\nsampling-based RL, referred to as ESRL, can outperform all baselines in terms\nof both training efficiency and memory consumption. Notably, ESRL yields\nconsistent performance gains over the strong REINFORCE, minimum risk training,\nand proximal policy optimization methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenglong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1\">Yimin Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1\">Yifu Huo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tongran Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Paraphrase Sentences to Different Complexity Levels. (arXiv:2308.02226v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02226","description":"<p>While sentence simplification is an active research topic in NLP, its\nadjacent tasks of sentence complexification and same-level paraphrasing are\nnot. To train models on all three tasks, we present two new unsupervised\ndatasets. We compare these datasets, one labeled by a weak classifier and the\nother by a rule-based approach, with a single supervised dataset. Using these\nthree datasets for training, we perform extensive experiments on both\nmultitasking and prompting strategies. Compared to other systems trained on\nunsupervised parallel data, models trained on our weak classifier labeled\ndataset achieve state-of-the-art performance on the ASSET simplification\nbenchmark. Our models also outperform previous work on sentence level\ntargeting. Finally, we establish how a handful of Large Language Models perform\non these tasks under a zero-shot setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_A/0/1/0/all/0/1\">Alison Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li-Kuang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi-Chen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Shu-Hui Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jason S. Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sinhala-English Parallel Word Dictionary Dataset. (arXiv:2308.02234v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02234","description":"<p>Parallel datasets are vital for performing and evaluating any kind of\nmultilingual task. However, in the cases where one of the considered language\npairs is a low-resource language, the existing top-down parallel data such as\ncorpora are lacking in both tally and quality due to the dearth of human\nannotation. Therefore, for low-resource languages, it is more feasible to move\nin the bottom-up direction where finer granular pairs such as dictionary\ndatasets are developed first. They may then be used for mid-level tasks such as\nsupervised multilingual word embedding alignment. These in turn can later guide\nhigher-level tasks in the order of aligning sentence or paragraph text corpora\nused for Machine Translation (MT). Even though more approachable than\ngenerating and aligning a massive corpus for a low-resource language, for the\nsame reason of apathy from larger research entities, even these finer granular\ndata sets are lacking for some low-resource languages. We have observed that\nthere is no free and open dictionary data set for the low-resource language,\nSinhala. Thus, in this work, we introduce three parallel English-Sinhala word\ndictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) which\nhelp in multilingual Natural Language Processing (NLP) tasks related to English\nand Sinhala languages. In this paper, we explain the dataset creation pipeline\nas well as the experimental results of the tests we have carried out to verify\nthe quality of the data sets. The data sets and the related scripts are\navailable at https://github.com/kasunw22/sinhala-para-dict.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wickramasinghe_K/0/1/0/all/0/1\">Kasun Wickramasinghe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_N/0/1/0/all/0/1\">Nisansa de Silva</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Monaural Speech Enhancement using Spectrum Attention Fusion. (arXiv:2308.02263v1 [cs.SD])","link":"http://arxiv.org/abs/2308.02263","description":"<p>Speech enhancement is a demanding task in automated speech processing\npipelines, focusing on separating clean speech from noisy channels. Transformer\nbased models have recently bested RNN and CNN models in speech enhancement,\nhowever at the same time they are much more computationally expensive and\nrequire much more high quality training data, which is always hard to come by.\nIn this paper, we present an improvement for speech enhancement models that\nmaintains the expressiveness of self-attention while significantly reducing\nmodel complexity, which we have termed Spectrum Attention Fusion. We carefully\nconstruct a convolutional module to replace several self-attention layers in a\nspeech Transformer, allowing the model to more efficiently fuse spectral\nfeatures. Our proposed model is able to achieve comparable or better results\nagainst SOTA models but with significantly smaller parameters (0.58M) on the\nVoice Bank + DEMAND dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1\">Jinyu Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jetic G&#x16b;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_B/0/1/0/all/0/1\">Binhao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhibo Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1\">Ping Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junli Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive Summarization. (arXiv:2308.02270v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02270","description":"<p>While very popular for evaluating extractive summarization task, the ROUGE\nmetric has long been criticized for its lack of semantic awareness and its\nignorance about the ranking quality of the summarizer. Thanks to previous\nresearch that has addressed these issues by proposing a gain-based automated\nmetric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG\ndoes not consider the amount of redundancy present in a model-generated summary\nand currently does not support evaluation with multiple reference summaries.\nUnfortunately, addressing both these limitations simultaneously is not trivial.\nTherefore, in this paper, we propose a redundancy-aware Sem-nCG metric and\ndemonstrate how this new metric can be used to evaluate model summaries against\nmultiple references. We also explore different ways of incorporating redundancy\ninto the original metric through extensive experiments. Experimental results\ndemonstrate that the new redundancy-aware metric exhibits a higher correlation\nwith human judgments than the original Sem-nCG metric for both single and\nmultiple reference scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akter_M/0/1/0/all/0/1\">Mousumi Akter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santu_S/0/1/0/all/0/1\">Shubhra Kanti Karmaker Santu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Select the Relevant History Turns in Conversational Question Answering. (arXiv:2308.02294v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02294","description":"<p>The increasing demand for the web-based digital assistants has given a rapid\nrise in the interest of the Information Retrieval (IR) community towards the\nfield of conversational question answering (ConvQA). However, one of the\ncritical aspects of ConvQA is the effective selection of conversational history\nturns to answer the question at hand. The dependency between relevant history\nselection and correct answer prediction is an intriguing but under-explored\narea. The selected relevant context can better guide the system so as to where\nexactly in the passage to look for an answer. Irrelevant context, on the other\nhand, brings noise to the system, thereby resulting in a decline in the model's\nperformance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History\nSelection in Conversational Question Answering), that first generates the\ncontext and question entities for all the history turns, which are then pruned\non the basis of similarity they share in common with the question at hand. We\nalso propose an attention-based mechanism to re-rank the pruned terms based on\ntheir calculated weights of how useful they are in answering the question. In\nthe end, we further aid the model by highlighting the terms in the re-ranked\nconversational history using a binary classification task and keeping the\nuseful terms (predicted as 1) and ignoring the irrelevant terms (predicted as\n0). We demonstrate the efficacy of our proposed framework with extensive\nexperimental results on CANARD and QuAC -- the two popularly utilized datasets\nin ConvQA. We demonstrate that selecting relevant turns works better than\nrewriting the original question. We also investigate how adding the irrelevant\nhistory turns negatively impacts the model's performance and discuss the\nresearch challenges that demand more attention from the IR community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1\">Munazza Zaib</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei Emma Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1\">Quan Z. Sheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sagar_S/0/1/0/all/0/1\">Subhash Sagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1\">Adnan Mahmood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dataflow Dialogue Generation. (arXiv:2308.02323v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02323","description":"<p>We demonstrate task-oriented dialogue generation within the dataflow dialogue\nparadigm. We show an example of agenda driven dialogue generation for the\nMultiWOZ domain, and an example of generation without an agenda for the\nSMCalFlow domain, where we show an improvement in the accuracy of the\ntranslation of user requests to dataflow expressions when the generated\ndialogues are used to augment the translation training dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meron_J/0/1/0/all/0/1\">Joram Meron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guimaraes_V/0/1/0/all/0/1\">Victor Guimar&#xe3;es</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. (arXiv:2308.02357v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02357","description":"<p>The recent advances in large language models (LLM) and foundation models with\nemergent capabilities have been shown to improve the performance of many NLP\ntasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs\ncan be used for KG construction or completion while existing KGs can be used\nfor different tasks such as making LLM outputs explainable or fact-checking in\nNeuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to\nevaluate the capabilities of language models to generate KGs from natural\nlanguage text guided by an ontology. Given an input ontology and a set of\nsentences, the task is to extract facts from the text while complying with the\ngiven ontology (concepts, relations, domain/range constraints) and being\nfaithful to the input sentences. We provide two datasets (i) Wikidata-TekGen\nwith 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19\nontologies and 4,860 sentences. We define seven evaluation metrics to measure\nfact extraction performance, ontology conformance, and hallucinations by LLMs.\nFurthermore, we provide results for two baseline models, Vicuna-13B and\nAlpaca-LoRA-13B using automatic prompt generation from test cases. The baseline\nresults show that there is room for improvement using both Semantic Web and\nNatural Language Processing techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1\">Nandana Mihindukulasooriya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1\">Sanju Tiwari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Enguix_C/0/1/0/all/0/1\">Carlos F. Enguix</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lata_K/0/1/0/all/0/1\">Kusum Lata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Performance of Large Language Models in a Computer Science Degree Program. (arXiv:2308.02432v1 [cs.CY])","link":"http://arxiv.org/abs/2308.02432","description":"<p>Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and\ndominate the current discourse. Their transformative capabilities have led to a\nparadigm shift in how we interact with and utilize (text-based) information.\nEach day, new possibilities to leverage the capabilities of these models\nemerge. This paper presents findings on the performance of different large\nlanguage models in a university of applied sciences' undergraduate computer\nscience degree program. Our primary objective is to assess the effectiveness of\nthese models within the curriculum by employing them as educational aids. By\nprompting the models with lecture material, exercise tasks, and past exams, we\naim to evaluate their proficiency across different computer science domains. We\nshowcase the strong performance of current large language models while\nhighlighting limitations and constraints within the context of such a degree\nprogram. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10\ntested modules, BingAI achieved 68.4%, and LLaMa, in the 65 billion parameter\nvariant, 20%. Despite these convincing results, even GPT-4.0 would not pass the\ndegree program - due to limitations in mathematical calculations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kruger_T/0/1/0/all/0/1\">Tim Kr&#xfc;ger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gref_M/0/1/0/all/0/1\">Michael Gref</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence. (arXiv:2308.02448v1 [cs.CY])","link":"http://arxiv.org/abs/2308.02448","description":"<p>In 2020, the U.S. Department of Defense officially disclosed a set of ethical\nprinciples to guide the use of Artificial Intelligence (AI) technologies on\nfuture battlefields. Despite stark differences, there are core similarities\nbetween the military and medical service. Warriors on battlefields often face\nlife-altering circumstances that require quick decision-making. Medical\nproviders experience similar challenges in a rapidly changing healthcare\nenvironment, such as in the emergency department or during surgery treating a\nlife-threatening condition. Generative AI, an emerging technology designed to\nefficiently generate valuable information, holds great promise. As computing\npower becomes more accessible and the abundance of health data, such as\nelectronic health records, electrocardiograms, and medical images, increases,\nit is inevitable that healthcare will be revolutionized by this technology.\nRecently, generative AI has captivated the research community, leading to\ndebates about its application in healthcare, mainly due to concerns about\ntransparency and related issues. Meanwhile, concerns about the potential\nexacerbation of health disparities due to modeling biases have raised notable\nethical concerns regarding the use of this technology in healthcare. However,\nthe ethical principles for generative AI in healthcare have been understudied,\nand decision-makers often fail to consider the significance of generative AI.\nIn this paper, we propose GREAT PLEA ethical principles, encompassing\ngovernance, reliability, equity, accountability, traceability, privacy,\nlawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to\nproactively address the ethical dilemmas and challenges posed by the\nintegration of generative AI in healthcare.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oniani_D/0/1/0/all/0/1\">David Oniani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hilsman_J/0/1/0/all/0/1\">Jordan Hilsman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, COL (Ret.) <a href=\"http://arxiv.org/find/cs/1/au:+Poropatich_R/0/1/0/all/0/1\">Ronald K. Poropatich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pamplin_C/0/1/0/all/0/1\">COL Jeremy C. Pamplin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legault_L/0/1/0/all/0/1\">LTC Gary L. Legault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanshan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Generalist Foundation Model for Radiology. (arXiv:2308.02463v1 [cs.CV])","link":"http://arxiv.org/abs/2308.02463","description":"<p>In this study, we aim to initiate the development of Radiology Foundation\nModel, termed as RadFM.We consider the construction of foundational models from\nthe perspectives of data, model design, and evaluation thoroughly. Our\ncontribution can be concluded as follows: (i), we construct a large-scale\nMedical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans.\nTo the best of our knowledge, this is the first multi-modal dataset containing\n3D medical scans. (ii), We propose an architecture that enables visually\nconditioned generative pre-training, allowing for the integration of text input\ninterleaved with 2D or 3D medical scans to generate response for diverse\nradiologic tasks. The model was initially pre-trained on MedMD and subsequently\ndomain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD,\ncontaining 3M radiologic visual-language pairs. (iii), we propose a new\nevaluation benchmark that comprises five tasks, aiming to comprehensively\nassess the capability of foundation models in handling practical clinical\nproblems. Our experimental results confirm that RadFM significantly outperforms\nexisting multi-modal foundation models. The codes, data, and model checkpoint\nwill all be made publicly available to promote further research and development\nin the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chaoyi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaoman Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Ya Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Weidi Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting the NICT-JLE Corpus for Disfluency Detection Models. (arXiv:2308.02482v1 [cs.CL])","link":"http://arxiv.org/abs/2308.02482","description":"<p>The detection of disfluencies such as hesitations, repetitions and false\nstarts commonly found in speech is a widely studied area of research. With a\nstandardised process for evaluation using the Switchboard Corpus, model\nperformance can be easily compared across approaches. This is not the case for\ndisfluency detection research on learner speech, however, where such datasets\nhave restricted access policies, making comparison and subsequent development\nof improved models more challenging. To address this issue, this paper\ndescribes the adaptation of the NICT-JLE corpus, containing approximately 300\nhours of English learners' oral proficiency tests, to a format that is suitable\nfor disfluency detection model training and evaluation. Points of difference\nbetween the NICT-JLE and Switchboard corpora are explored, followed by a\ndetailed overview of adaptations to the tag set and meta-features of the\nNICT-JLE corpus. The result of this work provides a standardised train, heldout\nand test set for use in future research on disfluency detection for learner\nspeech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Skidmore_L/0/1/0/all/0/1\">Lucy Skidmore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moore_R/0/1/0/all/0/1\">Roger K. Moore</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])","link":"http://arxiv.org/abs/2308.02490","description":"<p>We propose MM-Vet, an evaluation benchmark that examines large multimodal\nmodels (LMMs) on complicated multimodal tasks. Recent LMMs have shown various\nintriguing abilities, such as solving math problems written on the blackboard,\nreasoning about events and celebrities in news images, and explaining visual\njokes. Rapid model advancements pose challenges to evaluation benchmark\ndevelopment. Problems include: (1) How to systematically structure and evaluate\nthe complicated multimodal tasks; (2) How to design evaluation metrics that\nwork well across question and answer types; and (3) How to give model insights\nbeyond a simple performance ranking. To this end, we present MM-Vet, designed\nbased on the insight that the intriguing ability to solve complicated tasks is\noften achieved by a generalist model being able to integrate different core\nvision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and\nexamines the 16 integrations of interest derived from the capability\ncombination. For evaluation metrics, we propose an LLM-based evaluator for\nopen-ended outputs. The evaluator enables the evaluation across different\nquestion types and answer styles, resulting in a unified scoring metric. We\nevaluate representative LMMs on MM-Vet, providing insights into the\ncapabilities of different LMM system paradigms and models. Code and data are\navailable at https://github.com/yuweihao/MM-Vet.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Weihao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhengyuan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Linjie Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianfeng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zicheng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinchao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lijuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic WordNet Construction using Word Sense Induction through Sentence Embeddings. (arXiv:2204.03251v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.03251","description":"<p>Language resources such as wordnets remain indispensable tools for different\nnatural language tasks and applications. However, for low-resource languages\nsuch as Filipino, existing wordnets are old and outdated, and producing new\nones may be slow and costly in terms of time and resources. In this paper, we\npropose an automatic method for constructing a wordnet from scratch using only\nan unlabeled corpus and a sentence embeddings-based language model. Using this,\nwe produce FilWordNet, a new wordnet that supplants and improves the outdated\nFilipino WordNet. We evaluate our automatically-induced senses and synsets by\nmatching them with senses from the Princeton WordNet, as well as comparing the\nsynsets to the old Filipino WordNet. We empirically show that our method can\ninduce existing, as well as potentially new, senses and synsets automatically\nwithout the need for human supervision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Velasco_D/0/1/0/all/0/1\">Dan John Velasco</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alba_A/0/1/0/all/0/1\">Axel Alba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pelagio_T/0/1/0/all/0/1\">Trisha Gail Pelagio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramirez_B/0/1/0/all/0/1\">Bryce Anthony Ramirez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1\">Jan Christian Blaise Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1\">Charibeth Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergent Analogical Reasoning in Large Language Models. (arXiv:2212.09196v3 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2212.09196","description":"<p>The recent advent of large language models has reinvigorated debate over\nwhether human cognitive capacities might emerge in such generic models given\nsufficient training data. Of particular interest is the ability of these models\nto reason about novel problems zero-shot, without any direct training. In human\ncognition, this capacity is closely tied to an ability to reason by analogy.\nHere, we performed a direct comparison between human reasoners and a large\nlanguage model (the text-davinci-003 variant of GPT-3) on a range of analogical\ntasks, including a non-visual matrix reasoning task based on the rule structure\nof Raven's Standard Progressive Matrices. We found that GPT-3 displayed a\nsurprisingly strong capacity for abstract pattern induction, matching or even\nsurpassing human capabilities in most settings; preliminary tests of GPT-4\nindicated even better performance. Our results indicate that large language\nmodels such as GPT-3 have acquired an emergent ability to find zero-shot\nsolutions to a broad range of analogy problems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Webb_T/0/1/0/all/0/1\">Taylor Webb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holyoak_K/0/1/0/all/0/1\">Keith J. Holyoak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hongjing Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT Replace Traditional KBQA Models? An In-depth Analysis of GPT family LLMs' Question Answering Performance. (arXiv:2303.07992v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.07992","description":"<p>ChatGPT is a powerful large language model (LLM) that covers knowledge\nresources such as Wikipedia and supports natural language question answering\nusing its own knowledge. Therefore, there is growing interest in exploring\nwhether ChatGPT can replace traditional knowledge-based question answering\n(KBQA) models. Although there have been some works analyzing the question\nanswering performance of ChatGPT, there is still a lack of large-scale,\ncomprehensive testing of various types of complex questions to analyze the\nlimitations of the model. In this paper, we present a framework that follows\nthe black-box testing specifications of CheckList proposed by Ribeiro et. al.\nWe evaluate ChatGPT and its family of LLMs on eight real-world KB-based complex\nquestion answering datasets, which include six English datasets and two\nmultilingual datasets. The total number of test cases is approximately 190,000.\nIn addition to the GPT family of LLMs, we also evaluate the well-known FLAN-T5\nto identify commonalities between the GPT family and other LLMs. The dataset\nand code are available at\nhttps://github.com/tan92hl/Complex-Question-Answering-Evaluation-of-GPT-family.git\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1\">Yiming Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_D/0/1/0/all/0/1\">Dehai Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_N/0/1/0/all/0/1\">Nan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yongrui Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1\">Guilin Qi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPeC: A Soft Prompt-Based Calibration on Performance Variability of Large Language Model in Clinical Notes Summarization. (arXiv:2303.13035v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13035","description":"<p>Electronic health records (EHRs) store an extensive array of patient\ninformation, encompassing medical histories, diagnoses, treatments, and test\noutcomes. These records are crucial for enabling healthcare providers to make\nwell-informed decisions regarding patient care. Summarizing clinical notes\nfurther assists healthcare professionals in pinpointing potential health risks\nand making better-informed decisions. This process contributes to reducing\nerrors and enhancing patient outcomes by ensuring providers have access to the\nmost pertinent and current patient data. Recent research has shown that\nincorporating prompts with large language models (LLMs) substantially boosts\nthe efficacy of summarization tasks. However, we show that this approach also\nleads to increased output variance, resulting in notably divergent outputs even\nwhen prompts share similar meanings. To tackle this challenge, we introduce a\nmodel-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft\nprompts to diminish variance while preserving the advantages of prompt-based\nsummarization. Experimental findings on multiple clinical note tasks and LLMs\nindicate that our method not only bolsters performance but also effectively\ncurbs variance for various LLMs, providing a more uniform and dependable\nsolution for summarizing vital medical information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yu-Neng Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaoqian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LMExplainer: a Knowledge-Enhanced Explainer for Language Models. (arXiv:2303.16537v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.16537","description":"<p>Large language models (LLMs) such as GPT-4 are very powerful and can process\ndifferent kinds of natural language processing (NLP) tasks. However, it can be\ndifficult to interpret the results due to the multi-layer nonlinear model\nstructure and millions of parameters. A lack of clarity and understanding of\nhow the language models (LMs) work can make them unreliable, difficult to\ntrust, and potentially dangerous for use in real-world scenarios. Most recent\nworks exploit attention weights to provide explanations for LM predictions.\nHowever, pure attention-based explanations are unable to support the growing\ncomplexity of LMs, and cannot reason about their decision-making processes. We\npropose LMExplainer, a knowledge-enhanced explainer for LMs that can provide\nhuman-understandable explanations. We use a knowledge graph (KG) and a graph\nattention neural network to extract the key decision signals of the LM. We\nfurther explore whether interpretation can also help the AI understand the task\nbetter. Our experimental results show that LMExplainer outperforms existing\nLM+KG methods on CommonsenseQA and OpenBookQA. We compare the explanation\nresults with generated explanation methods and human-annotated results. The\ncomparison shows our method can provide more comprehensive and clearer\nexplanations. LMExplainer demonstrates the potential to enhance model\nperformance and furnish explanations for the LM reasoning process in natural\nlanguage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zichen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Ambuj K Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sra_M/0/1/0/all/0/1\">Misha Sra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation. (arXiv:2303.17910v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.17910","description":"<p>Benefiting from the sequence-level knowledge distillation, the\nNon-Autoregressive Transformer (NAT) achieves great success in neural machine\ntranslation tasks. However, existing knowledge distillation has side effects,\nsuch as propagating errors from the teacher to NAT students, which may limit\nfurther improvements of NAT models and are rarely discussed in existing\nresearch. In this paper, we introduce selective knowledge distillation by\nintroducing an NAT evaluator to select NAT-friendly targets that are of high\nquality and easy to learn. In addition, we introduce a simple yet effective\nprogressive distillation method to boost NAT performance. Experiment results on\nmultiple WMT language directions and several representative NAT models show\nthat our approach can realize a flexible trade-off between the quality and\ncomplexity of training data for NAT models, achieving strong performances.\nFurther analysis shows that distilling only 5% of the raw translations can help\nan NAT outperform its counterpart trained on raw data by about 2.4 BLEU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Min Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_Y/0/1/0/all/0/1\">Yu Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chengqi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shujian Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"G3Detector: General GPT-Generated Text Detector. (arXiv:2305.12680v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12680","description":"<p>The burgeoning progress in the field of Large Language Models (LLMs) heralds\nsignificant benefits due to their unparalleled capacities. However, it is\ncritical to acknowledge the potential misuse of these models, which could give\nrise to a spectrum of social and ethical dilemmas. Despite numerous preceding\nefforts centered around distinguishing synthetic text, most existing detection\nsystems fail to identify data synthesized by the latest LLMs, such as ChatGPT\nand GPT-4. In response to this challenge, we introduce an unpretentious yet\npotent detection approach proficient in identifying synthetic text across a\nwide array of fields. Moreover, our detector demonstrates outstanding\nperformance uniformly across various model architectures and decoding\nstrategies. It also possesses the capability to identify text generated\nutilizing a potent detection-evasion technique. Our comprehensive research\nunderlines our commitment to boosting the robustness and efficiency of\nmachine-generated text detection mechanisms, particularly in the context of\nswiftly progressing and increasingly adaptive AI technologies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhan_H/0/1/0/all/0/1\">Haolan Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuanli He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiongkai Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuxiang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1\">Pontus Stenetorp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mapping ChatGPT in Mainstream Media to Unravel Jobs and Diversity Challenges: Early Quantitative Insights through Sentiment Analysis and Word Frequency Analysis. (arXiv:2305.18340v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2305.18340","description":"<p>The exponential growth in user acquisition and popularity of OpenAIs ChatGPT,\nan artificial intelligence(AI) powered chatbot, was accompanied by widespread\nmainstream media coverage. This article presents a quantitative data analysis\nof the early trends and sentiments revealed by conducting text mining and NLP\nmethods onto a corpus of 10,902 mainstream news headlines related to the\nsubject of ChatGPT and artificial intelligence, from the launch of ChatGPT in\nNovember 2022 to March 2023. The findings revealed in sentiment analysis,\nChatGPT and artificial intelligence, were perceived more positively than\nnegatively in the mainstream media. In regards to word frequency results, over\nsixty-five percent of the top frequency words were focused on Big Tech issues\nand actors while topics such as jobs, diversity, ethics, copyright, gender and\nwomen were poorly represented or completely absent and only accounted for six\npercent of the total corpus. This article is a critical analysis into the power\nstructures and collusions between Big Tech and Big Media in their hegemonic\nexclusion of diversity and job challenges from mainstream media.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Karanouh_M/0/1/0/all/0/1\">Maya Karanouh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Label Biases for In-context Learning. (arXiv:2305.19148v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.19148","description":"<p>Various design settings for in-context learning (ICL), such as the choice and\norder of the in-context examples, can bias a model toward a particular\nprediction without being reflective of an understanding of the task. While many\nstudies discuss these design choices, there have been few systematic\ninvestigations into categorizing them and mitigating their impact. In this\nwork, we define a typology for three types of label biases in ICL for text\nclassification: vanilla-label bias, context-label bias, and domain-label bias\n(which we conceptualize and detect for the first time).\n</p>\n<p>Our analysis demonstrates that prior label bias calibration methods fall\nshort of addressing all three types of biases. Specifically, domain-label bias\nrestricts LLMs to random-level performance on many tasks regardless of the\nchoice of in-context examples. To mitigate the effect of these biases, we\npropose a simple bias calibration method that estimates a language model's\nlabel bias using random in-domain words from the task corpus. After controlling\nfor this estimated bias when making predictions, our novel domain-context\ncalibration significantly improves the ICL performance of GPT-J and GPT-3 on a\nwide range of tasks. The gain is substantial on tasks with large domain-label\nbias (up to 37% in Macro-F1). Furthermore, our results generalize to models\nwith different scales, pretraining methods, and manually-designed task\ninstructions, showing the prevalence of label biases in ICL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fei_Y/0/1/0/all/0/1\">Yu Fei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yifan Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zeming Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bosselut_A/0/1/0/all/0/1\">Antoine Bosselut</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Inductive reasoning in humans and large language models. (arXiv:2306.06548v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.06548","description":"<p>The impressive recent performance of large language models has led many to\nwonder to what extent they can serve as models of general intelligence or are\nsimilar to human cognition. We address this issue by applying GPT-3.5 and GPT-4\nto a classic problem in human inductive reasoning known as property induction.\nOver two experiments, we elicit human judgments on a range of property\ninduction tasks spanning multiple domains. Although GPT-3.5 struggles to\ncapture many aspects of human behaviour, GPT-4 is much more successful: for the\nmost part, its performance qualitatively matches that of humans, and the only\nnotable exception is its failure to capture the phenomenon of premise\nnon-monotonicity. Our work demonstrates that property induction allows for\ninteresting comparisons between human and machine intelligence and provides two\nlarge datasets that can serve as benchmarks for future work in this vein.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Simon J. Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ransom_K/0/1/0/all/0/1\">Keith Ransom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perfors_A/0/1/0/all/0/1\">Andrew Perfors</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kemp_C/0/1/0/all/0/1\">Charles Kemp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.00925","description":"<p>Semantic similarity measures are widely used in natural language processing\nto catalyze various computer-related tasks. However, no single semantic\nsimilarity measure is the most appropriate for all tasks, and researchers often\nuse ensemble strategies to ensure performance. This research work proposes a\nmethod for automatically designing semantic similarity ensembles. In fact, our\nproposed method uses grammatical evolution, for the first time, to\nautomatically select and aggregate measures from a pool of candidates to create\nan ensemble that maximizes correlation to human judgment. The method is\nevaluated on several benchmark datasets and compared to state-of-the-art\nensembles, showing that it can significantly improve similarity assessment\naccuracy and outperform existing methods in some cases. As a result, our\nresearch demonstrates the potential of using grammatical evolution to\nautomatically compare text and prove the benefits of using ensembles for\nsemantic similarity tasks. The source code that illustrates our approach can be\ndownloaded from https://github.com/jorge-martinez-gil/sesige.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martinez_Gil_J/0/1/0/all/0/1\">Jorge Martinez-Gil</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Turkish Native Language Identification. (arXiv:2307.14850v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.14850","description":"<p>In this paper, we present the first application of Native Language\nIdentification (NLI) for the Turkish language. NLI involves predicting the\nwriter's first language by analysing their writing in different languages.\nWhile most NLI research has focused on English, our study extends its scope to\nTurkish. We used the recently constructed Turkish Learner Corpus and employed a\ncombination of three syntactic features (CFG production rules, part-of-speech\nn-grams, and function words) with L2 texts to demonstrate their effectiveness\nin this task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1\">Ahmet Yavuz Uluslu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schneider_G/0/1/0/all/0/1\">Gerold Schneider</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grounded Image Text Matching with Mismatched Relation Reasoning. (arXiv:2308.01236v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.01236","description":"<p>This paper introduces Grounded Image Text Matching with Mismatched Relation\n(GITM-MR), a novel visual-linguistic joint task that evaluates the relation\nunderstanding capabilities of transformer-based pre-trained models. GITM-MR\nrequires a model to first determine if an expression describes an image, then\nlocalize referred objects or ground the mismatched parts of the text. We\nprovide a benchmark for evaluating pre-trained models on this task, with a\nfocus on the challenging settings of limited data and out-of-distribution\nsentence lengths. Our evaluation demonstrates that pre-trained models lack data\nefficiency and length generalization ability. To address this, we propose the\nRelation-sensitive Correspondence Reasoning Network (RCRN), which incorporates\nrelation-aware reasoning via bi-directional message propagation guided by\nlanguage structure. RCRN can be interpreted as a modular program and delivers\nstrong performance in both length generalization and data efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yana Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yongfei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Sibei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuming He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hoodwinked: Deception and Cooperation in a Text-Based Game for Language Models. (arXiv:2308.01404v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01404","description":"<p>Are current language models capable of deception and lie detection? We study\nthis question by introducing a text-based game called $\\textit{Hoodwinked}$,\ninspired by Mafia and Among Us. Players are locked in a house and must find a\nkey to escape, but one player is tasked with killing the others. Each time a\nmurder is committed, the surviving players have a natural language discussion\nthen vote to banish one player from the game. We conduct experiments with\nagents controlled by GPT-3, GPT-3.5, and GPT-4 and find evidence of deception\nand lie detection capabilities. The killer often denies their crime and accuses\nothers, leading to measurable effects on voting outcomes. More advanced models\nare more effective killers, outperforming smaller models in 18 of 24 pairwise\ncomparisons. Secondary metrics provide evidence that this improvement is not\nmediated by different actions, but rather by stronger persuasive skills during\ndiscussions. To evaluate the ability of AI agents to deceive humans, we make\nthis game publicly available at h https://hoodwinked.ai/ .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+OGara_A/0/1/0/all/0/1\">Aidan O&#x27;Gara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-08-06T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/"}}]}]}