{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-05-09T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Assessing Working Memory Capacity of ChatGPT. (arXiv:2305.03731v1 [cs.AI])","link":"http://arxiv.org/abs/2305.03731","description":"<p>Working memory is a critical aspect of both human intelligence and artificial\nintelligence (AI), serving as a workspace for the temporary storage and\nmanipulation of information. This paper investigates working memory capacity of\nChatGPT, a state-of-the-art language model, by examining its performance on\nN-back tasks. We begin by discussing the importance of working memory to humans\nand AI, followed by the methods employed to assess working memory capacity of\nChatGPT. Our study compares behavioral performance of ChatGPT on verbal and\nspatial N-back tasks to that of human participants reported in the literature,\nrevealing notable similarities. Our findings offer crucial insights into the\ncurrent progress in designing AI systems with human-level cognitive abilities\nand hold promise for informing future endeavors aimed at enhancing AI working\nmemory and understanding human working memory through AI models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gong_D/0/1/0/all/0/1\">Dongyu Gong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tuning Traditional Language Processing Approaches for Pashto Text Classification. (arXiv:2305.03737v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03737","description":"<p>Today text classification becomes critical task for concerned individuals for\nnumerous purposes. Hence, several researches have been conducted to develop\nautomatic text classification for national and international languages.\nHowever, the need for an automatic text categorization system for local\nlanguages is felt. The main aim of this study is to establish a Pashto\nautomatic text classification system. In order to pursue this work, we built a\nPashto corpus which is a collection of Pashto documents due to the\nunavailability of public datasets of Pashto text documents. Besides, this study\ncompares several models containing both statistical and neural network machine\nlearning techniques including Multilayer Perceptron (MLP), Support Vector\nMachine (SVM), K Nearest Neighbor (KNN), decision tree, gaussian na\\\"ive Bayes,\nmultinomial na\\\"ive Bayes, random forest, and logistic regression to discover\nthe most effective approach. Moreover, this investigation evaluates two\ndifferent feature extraction methods including unigram, and Time Frequency\nInverse Document Frequency (IFIDF). Subsequently, this research obtained\naverage testing accuracy rate 94% using MLP classification algorithm and TFIDF\nfeature extraction method in this context.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Baktash_J/0/1/0/all/0/1\">Jawid Ahmad Baktash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dawodi_M/0/1/0/all/0/1\">Mursal Dawodi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joya_M/0/1/0/all/0/1\">Mohammad Zarif Joya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassanzada_N/0/1/0/all/0/1\">Nematullah Hassanzada</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming. (arXiv:2305.03742v1 [cs.AI])","link":"http://arxiv.org/abs/2305.03742","description":"<p>Pre-trained large language models (LMs) struggle to perform logical reasoning\nreliably despite advances in scale and compositionality. In this work, we\ntackle this challenge through the lens of symbolic programming. We propose\nDSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs\ngovern the perception of factual knowledge, and a symbolic module performs\ndeductive reasoning. In contrast to works that rely on hand-crafted logic\nrules, our differentiable symbolic reasoning framework efficiently learns\nweighted rules and applies semantic loss to further improve LMs. DSR-LM is\nscalable, interpretable, and allows easy integration of prior knowledge,\nthereby supporting extensive symbolic programming to robustly derive a logical\nconclusion. The results of our experiments suggest that DSR-LM improves the\nlogical reasoning abilities of pre-trained language models, resulting in a\nsignificant increase in accuracy of over 20% on deductive reasoning benchmarks.\nFurthermore, DSR-LM outperforms a variety of competitive baselines when faced\nwith systematic changes in sequence length.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanlin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiani Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Ziyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naik_M/0/1/0/all/0/1\">Mayur Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing the Power of BERT in the Turkish Clinical Domain: Pretraining Approaches for Limited Data Scenarios. (arXiv:2305.03788v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03788","description":"<p>In recent years, major advancements in natural language processing (NLP) have\nbeen driven by the emergence of large language models (LLMs), which have\nsignificantly revolutionized research and development within the field.\nBuilding upon this progress, our study delves into the effects of various\npre-training methodologies on Turkish clinical language models' performance in\na multi-label classification task involving radiology reports, with a focus on\naddressing the challenges posed by limited language resources. Additionally, we\nevaluated the simultaneous pretraining approach by utilizing limited clinical\ntask data for the first time. We developed four models, including\nTurkRadBERT-task v1, TurkRadBERT-task v2, TurkRadBERT-sim v1, and\nTurkRadBERT-sim v2. Our findings indicate that the general Turkish BERT model\n(BERTurk) and TurkRadBERT-task v1, both of which utilize knowledge from a\nsubstantial general-domain corpus, demonstrate the best overall performance.\nAlthough the task-adaptive pre-training approach has the potential to capture\ndomain-specific patterns, it is constrained by the limited task-specific corpus\nand may be susceptible to overfitting. Furthermore, our results underscore the\nsignificance of domain-specific vocabulary during pre-training for enhancing\nmodel performance. Ultimately, we observe that the combination of\ngeneral-domain knowledge and task-specific fine-tuning is essential for\nachieving optimal performance across a range of categories. This study offers\nvaluable insights for developing effective Turkish clinical language models and\ncan guide future research on pre-training techniques for other low-resource\nlanguages within the clinical domain.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Turkmen_H/0/1/0/all/0/1\">Hazal T&#xfc;rkmen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dikenelli_O/0/1/0/all/0/1\">O&#x11f;uz Dikenelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eraslan_C/0/1/0/all/0/1\">Cenk Eraslan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calli_M/0/1/0/all/0/1\">Mehmet Cem &#xc7;all&#x131;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ozbek_S/0/1/0/all/0/1\">S&#xfc;ha S&#xfc;reyya &#xd6;zbek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Zero-Shot Frame Semantic Parsing with Task Agnostic Ontologies and Simple Labels. (arXiv:2305.03793v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03793","description":"<p>Frame semantic parsing is an important component of task-oriented dialogue\nsystems. Current models rely on a significant amount training data to\nsuccessfully identify the intent and slots in the user's input utterance. This\ncreates a significant barrier for adding new domains to virtual assistant\ncapabilities, as creation of this data requires highly specialized NLP\nexpertise. In this work we propose OpenFSP, a framework that allows for easy\ncreation of new domains from a handful of simple labels that can be generated\nwithout specific NLP knowledge. Our approach relies on creating a small, but\nexpressive, set of domain agnostic slot types that enables easy annotation of\nnew domains. Given such annotation, a matching algorithm relying on sentence\nencoders predicts the intent and slots for domains defined by end-users.\nExtensive experiments on the TopV2 dataset shows that our model outperforms\nstrong baselines in this simple labels setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_D/0/1/0/all/0/1\">Danilo Ribeiro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdar_O/0/1/0/all/0/1\">Omid Abdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goetz_J/0/1/0/all/0/1\">Jack Goetz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_M/0/1/0/all/0/1\">Mike Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_A/0/1/0/all/0/1\">Annie Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forbus_K/0/1/0/all/0/1\">Kenneth Forbus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1\">Ahmed Mohamed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation. (arXiv:2305.03796v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03796","description":"<p>Unlike recurrent models, conventional wisdom has it that Transformers cannot\nperfectly model regular languages. Inspired by the notion of working memory, we\npropose a new Transformer variant named RegularGPT. With its novel combination\nof Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT\nconstructs working memory along the depth dimension, thereby enabling efficient\nand successful modeling of regular languages such as PARITY. We further test\nRegularGPT on the task of natural language length extrapolation and\nsurprisingly find that it rediscovers the local windowed attention effect\ndeemed necessary in prior work for length extrapolation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chi_T/0/1/0/all/0/1\">Ta-Chung Chi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1\">Ting-Han Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudnicky_A/0/1/0/all/0/1\">Alexander I. Rudnicky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramadge_P/0/1/0/all/0/1\">Peter J. Ramadge</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting Transformer Language Models for Predictive Typing in Brain-Computer Interfaces. (arXiv:2305.03819v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03819","description":"<p>Brain-computer interfaces (BCI) are an important mode of alternative and\naugmentative communication for many people. Unlike keyboards, many BCI systems\ndo not display even the 26 letters of English at one time, let alone all the\nsymbols in more complex systems. Using language models to make character-level\npredictions, therefore, can greatly speed up BCI typing (Ghosh and Kristensson,\n2017). While most existing BCI systems employ character n-gram models or no LM\nat all, this paper adapts several wordpiece-level Transformer LMs to make\ncharacter predictions and evaluates them on typing tasks. GPT-2 fares best on\nclean text, but different LMs react differently to noisy histories. We further\nanalyze the effect of character positions in a word and context lengths.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shijia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_D/0/1/0/all/0/1\">David A. Smith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Uncertainty-Aware Bootstrap Learning for Joint Extraction on Distantly-Supervised Data. (arXiv:2305.03827v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03827","description":"<p>Jointly extracting entity pairs and their relations is challenging when\nworking on distantly-supervised data with ambiguous or noisy labels. To\nmitigate such impact, we propose uncertainty-aware bootstrap learning, which is\nmotivated by the intuition that the higher uncertainty of an instance, the more\nlikely the model confidence is inconsistent with the ground truths.\nSpecifically, we first explore instance-level data uncertainty to create an\ninitial high-confident examples. Such subset serves as filtering noisy\ninstances and facilitating the model to converge fast at the early stage.\nDuring bootstrap learning, we propose self-ensembling as a regularizer to\nalleviate inter-model uncertainty produced by noisy labels. We further define\nprobability variance of joint tagging probabilities to estimate inner-model\nparametric uncertainty, which is used to select and build up new reliable\ntraining instances for the next iteration. Experimental results on two large\ndatasets reveal that our approach outperforms existing strong baselines and\nrelated methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yufei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haifeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and Sequence-Labeling approaches for NER. (arXiv:2305.03845v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03845","description":"<p>This paper summarizes the CLaC submission for the MultiCoNER 2 task which\nconcerns the recognition of complex, fine-grained named entities. We compare\ntwo popular approaches for NER, namely Sequence Labeling and Span Prediction.\nWe find that our best Span Prediction system performs slightly better than our\nbest Sequence Labeling system on test data. Moreover, we find that using the\nlarger version of XLM RoBERTa significantly improves performance.\nPost-competition experiments show that Span Prediction and Sequence Labeling\napproaches improve when they use special input tokens (&lt;s&gt; and &lt;/s&gt;) of\nXLM-RoBERTa. The code for training all models, preprocessing, and\npost-processing is available at\nhttps://github.com/harshshredding/semeval2023-multiconer-paper.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Verma_H/0/1/0/all/0/1\">Harsh Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergler_S/0/1/0/all/0/1\">Sabine Bergler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models in Sport Science & Medicine: Opportunities, Risks and Considerations. (arXiv:2305.03851v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03851","description":"<p>This paper explores the potential opportunities, risks, and challenges\nassociated with the use of large language models (LLMs) in sports science and\nmedicine. LLMs are large neural networks with transformer style architectures\ntrained on vast amounts of textual data, and typically refined with human\nfeedback. LLMs can perform a large range of natural language processing tasks.\nIn sports science and medicine, LLMs have the potential to support and augment\nthe knowledge of sports medicine practitioners, make recommendations for\npersonalised training programs, and potentially distribute high-quality\ninformation to practitioners in developing countries. However, there are also\npotential risks associated with the use and development of LLMs, including\nbiases in the dataset used to create the model, the risk of exposing\nconfidential data, the risk of generating harmful output, and the need to align\nthese models with human preferences through feedback. Further research is\nneeded to fully understand the potential applications of LLMs in sports science\nand medicine and to ensure that their use is ethical and beneficial to\nathletes, clients, patients, practitioners, and the general public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Connor_M/0/1/0/all/0/1\">Mark Connor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+ONeill_M/0/1/0/all/0/1\">Michael O&#x27;Neill</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages. (arXiv:2305.03873v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03873","description":"<p>In many humanitarian scenarios, translation into severely low resource\nlanguages often does not require a universal translation engine, but a\ndedicated text-specific translation engine. For example, healthcare records,\nhygienic procedures, government communication, emergency procedures and\nreligious texts are all limited texts. While generic translation engines for\nall languages do not exist, translation of multilingually known limited texts\ninto new, endangered languages may be possible and reduce human translation\neffort. We attempt to leverage translation resources from many rich resource\nlanguages to efficiently produce best possible translation quality for a well\nknown text, which is available in multiple languages, in a new, severely low\nresource language. We examine two approaches: 1. best selection of seed\nsentences to jump start translations in a new language in view of best\ngeneralization to the remainder of a larger targeted text(s), and 2. we adapt\nlarge general multilingual translation engines from many other languages to\nfocus on a specific text in a new, unknown language. We find that adapting\nlarge pretrained multilingual models to the domain/text first and then to the\nseverely low resource language works best. If we also select a best set of seed\nsentences, we can improve average chrF performance on new test languages from a\nbaseline of 21.9 to 50.7, while reducing the number of seed sentences to only\naround 1,000 in the new, unknown language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zhong Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1\">Jan Niehues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alex Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NorBench -- A Benchmark for Norwegian Language Models. (arXiv:2305.03880v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03880","description":"<p>We present NorBench: a streamlined suite of NLP tasks and probes for\nevaluating Norwegian language models (LMs) on standardized data splits and\nevaluation metrics. We also introduce a range of new Norwegian language models\n(both encoder and encoder-decoder based). Finally, we compare and analyze their\nperformance, along with other existing LMs, across the different benchmark\ntests of NorBench.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Samuel_D/0/1/0/all/0/1\">David Samuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutuzov_A/0/1/0/all/0/1\">Andrey Kutuzov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Touileb_S/0/1/0/all/0/1\">Samia Touileb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velldal_E/0/1/0/all/0/1\">Erik Velldal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovrelid_L/0/1/0/all/0/1\">Lilja &#xd8;vrelid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ronningstad_E/0/1/0/all/0/1\">Egil R&#xf8;nningstad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sigdel_E/0/1/0/all/0/1\">Elina Sigdel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Palatkina_A/0/1/0/all/0/1\">Anna Palatkina</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fairness in Image Search: A Study of Occupational Stereotyping in Image Retrieval and its Debiasing. (arXiv:2305.03881v1 [cs.IR])","link":"http://arxiv.org/abs/2305.03881","description":"<p>Multi-modal search engines have experienced significant growth and widespread\nuse in recent years, making them the second most common internet use. While\nsearch engine systems offer a range of services, the image search field has\nrecently become a focal point in the information retrieval community, as the\nadage goes, \"a picture is worth a thousand words\". Although popular search\nengines like Google excel at image search accuracy and agility, there is an\nongoing debate over whether their search results can be biased in terms of\ngender, language, demographics, socio-cultural aspects, and stereotypes. This\npotential for bias can have a significant impact on individuals' perceptions\nand influence their perspectives.\n</p>\n<p>In this paper, we present our study on bias and fairness in web search, with\na focus on keyword-based image search. We first discuss several kinds of biases\nthat exist in search systems and why it is important to mitigate them. We\nnarrow down our study to assessing and mitigating occupational stereotypes in\nimage search, which is a prevalent fairness issue in image retrieval. For the\nassessment of stereotypes, we take gender as an indicator. We explore various\nopen-source and proprietary APIs for gender identification from images. With\nthese, we examine the extent of gender bias in top-tanked image search results\nobtained for several occupational keywords. To mitigate the bias, we then\npropose a fairness-aware re-ranking algorithm that optimizes (a) relevance of\nthe search result with the keyword and (b) fairness w.r.t genders identified.\nWe experiment on 100 top-ranked images obtained for 10 occupational keywords\nand consider random re-ranking and re-ranking based on relevance as baselines.\nOur experimental results show that the fairness-aware re-ranking algorithm\nproduces rankings with better fairness scores and competitive relevance scores\nthan the baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1\">Swagatika Dash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1\">Yunhe Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HateMM: A Multi-Modal Dataset for Hate Video Classification. (arXiv:2305.03915v1 [cs.CV])","link":"http://arxiv.org/abs/2305.03915","description":"<p>Hate speech has become one of the most significant issues in modern society,\nhaving implications in both the online and the offline world. Due to this, hate\nspeech research has recently gained a lot of traction. However, most of the\nwork has primarily focused on text media with relatively little work on images\nand even lesser on videos. Thus, early stage automated video moderation\ntechniques are needed to handle the videos that are being uploaded to keep the\nplatform safe and healthy. With a view to detect and remove hateful content\nfrom the video sharing platforms, our work focuses on hate video detection\nusing multi-modalities. To this end, we curate ~43 hours of videos from\nBitChute and manually annotate them as hate or non-hate, along with the frame\nspans which could explain the labelling decision. To collect the relevant\nvideos we harnessed search keywords from hate lexicons. We observe various cues\nin images and audio of hateful videos. Further, we build deep learning\nmulti-modal models to classify the hate videos and observe that using all the\nmodalities of the videos improves the overall hate speech detection performance\n(accuracy=0.798, macro F1-score=0.790) by ~5.7% compared to the best uni-modal\nmodel in terms of macro F1 score. In summary, our work takes the first step\ntoward understanding and modeling hateful videos on video hosting platforms\nsuch as BitChute.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1\">Mithun Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_R/0/1/0/all/0/1\">Rohit Raj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saha_P/0/1/0/all/0/1\">Punyajoy Saha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathew_B/0/1/0/all/0/1\">Binny Mathew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_A/0/1/0/all/0/1\">Animesh Mukherjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Continual Learning: Labelling Queries in a Sequence of Tasks. (arXiv:2305.03923v1 [cs.LG])","link":"http://arxiv.org/abs/2305.03923","description":"<p>Acquiring new knowledge without forgetting what has been learned in a\nsequence of tasks is the central focus of continual learning (CL). While tasks\narrive sequentially, the training data are often prepared and annotated\nindependently, leading to CL of incoming supervised learning tasks. This paper\nconsiders the under-explored problem of active continual learning (ACL) for a\nsequence of active learning (AL) tasks, where each incoming task includes a\npool of unlabelled data and an annotation budget. We investigate the\neffectiveness and interplay between several AL and CL algorithms in the domain,\nclass and task-incremental scenarios. Our experiments reveal the trade-off\nbetween two contrasting goals of not forgetting the old knowledge and the\nability to quickly learn in CL and AL. While conditioning the query strategy on\nthe annotations collected for the previous tasks leads to improved task\nperformance on the domain and task incremental learning, our proposed\nforgetting-learning profile suggests a gap in balancing the effect of AL and CL\nfor the class-incremental scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1\">Thuy-Trang Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_S/0/1/0/all/0/1\">Shahram Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1\">Dinh Phung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization. (arXiv:2305.03937v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03937","description":"<p>Prompt tuning is one of the successful approaches for parameter-efficient\ntuning of pre-trained language models. Despite being arguably the most\nparameter-efficient (tuned soft prompts constitute &lt;0.1% of total parameters),\nit typically performs worse than other efficient tuning methods and is quite\nsensitive to hyper-parameters. In this work, we introduce Residual Prompt\nTuning - a simple and efficient method that significantly improves the\nperformance and stability of prompt tuning. We propose to reparameterize soft\nprompt embeddings using a shallow network with a residual connection. Our\nexperiments show that Residual Prompt Tuning significantly outperforms prompt\ntuning on SuperGLUE benchmark. Notably, our method reaches +7 points\nimprovement over prompt tuning with T5-Base and allows to reduce the prompt\nlength by 10x without hurting performance. In addition, we show that our\napproach is robust to the choice of learning rate and prompt initialization,\nand is effective in few-shot settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razdaibiedina_A/0/1/0/all/0/1\">Anastasia Razdaibiedina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1\">Jimmy Ba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1\">Amjad Almahairi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Label-Free Multi-Domain Machine Translation with Stage-wise Training. (arXiv:2305.03949v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03949","description":"<p>Most multi-domain machine translation models rely on domain-annotated data.\nUnfortunately, domain labels are usually unavailable in both training processes\nand real translation scenarios. In this work, we propose a label-free\nmulti-domain machine translation model which requires only a few or no\ndomain-annotated data in training and no domain labels in inference. Our model\nis composed of three parts: a backbone model, a domain discriminator taking\nresponsibility to discriminate data from different domains, and a set of\nexperts that transfer the decoded features from generic to specific. We design\na stage-wise training strategy and train the three parts sequentially. To\nleverage the extra domain knowledge and improve the training stability, in the\ndiscriminator training stage, domain differences are modeled explicitly with\nclustering and distilled into the discriminator through a multi-classification\ntask. Meanwhile, the Gumbel-Max sampling is adopted as the routing scheme in\nthe expert training stage to achieve the balance of each expert in\nspecialization and generalization. Experimental results on the\nGerman-to-English translation task show that our model significantly improves\nBLEU scores on six different domains and even outperforms most of the models\ntrained with domain-annotated data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_M/0/1/0/all/0/1\">Mei Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sangha Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Song Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jinyao Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Rule-based Named Entity Recognition and Relation Extraction for Process Model Generation from Natural Language Text. (arXiv:2305.03960v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03960","description":"<p>Automated generation of business process models from natural language text is\nan emerging methodology for avoiding the manual creation of formal business\nprocess models. For this purpose, process entities like actors, activities,\nobjects etc., and relations among them are extracted from textual process\ndescriptions. A high-quality annotated corpus of textual process descriptions\n(PET) has been published accompanied with a basic process extraction approach.\nIn its current state, however, PET lacks information about whether two mentions\nrefer to the same or different process entities, which corresponds to the\ncrucial decision of whether to create one or two modeling elements in the\ntarget model. Consequently, it is ambiguous whether, for instance, two mentions\nof data processing mean processing of different, or the same data. In this\npaper, we extend the PET dataset by clustering mentions of process entities and\nby proposing a new baseline technique for process extraction equipped with an\nadditional entity resolution component. In a second step, we replace the\nrule-based relation extraction component with a machine learning-based\nalternative, enabling rapid adaption to different datasets and domains. In\naddition, we evaluate a deep learning-approach built for solving entity and\nrelation extraction as well as entity resolution in a holistic manner. Finally,\nour extensive evaluation of the original PET baseline against our own\nimplementation shows that a pure machine learning-based process extraction\ntechnique is competitive, while avoiding the massive overhead arising from\nfeature engineering and rule definition needed to adapt to other datasets,\ndifferent entity and relation types, or new domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Neuberger_J/0/1/0/all/0/1\">Julian Neuberger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ackermann_L/0/1/0/all/0/1\">Lars Ackermann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jablonski_S/0/1/0/all/0/1\">Stefan Jablonski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NER-to-MRC: Named-Entity Recognition Completely Solving as Machine Reading Comprehension. (arXiv:2305.03970v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03970","description":"<p>Named-entity recognition (NER) detects texts with predefined semantic labels\nand is an essential building block for natural language processing (NLP).\nNotably, recent NER research focuses on utilizing massive extra data, including\npre-training corpora and incorporating search engines. However, these methods\nsuffer from high costs associated with data collection and pre-training, and\nadditional training process of the retrieved data from search engines. To\naddress the above challenges, we completely frame NER as a machine reading\ncomprehension (MRC) problem, called NER-to-MRC, by leveraging MRC with its\nability to exploit existing data efficiently. Several prior works have been\ndedicated to employing MRC-based solutions for tackling the NER problem,\nseveral challenges persist: i) the reliance on manually designed prompts; ii)\nthe limited MRC approaches to data reconstruction, which fails to achieve\nperformance on par with methods utilizing extensive additional data. Thus, our\nNER-to-MRC conversion consists of two components: i) transform the NER task\ninto a form suitable for the model to solve with MRC in a efficient manner; ii)\napply the MRC reasoning strategy to the model. We experiment on 6 benchmark\ndatasets from three domains and achieve state-of-the-art performance without\nexternal data, up to 11.24% improvement on the WNUT-16 dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuxiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junjie Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xinyu Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakai_T/0/1/0/all/0/1\">Tetsuya Sakai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamana_H/0/1/0/all/0/1\">Hayato Yamana</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptive loose optimization for robust question answering. (arXiv:2305.03971v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03971","description":"<p>Question answering methods are well-known for leveraging data bias, such as\nthe language prior in visual question answering and the position bias in\nmachine reading comprehension (extractive question answering). Current\ndebiasing methods often come at the cost of significant in-distribution\nperformance to achieve favorable out-of-distribution generalizability, while\nnon-debiasing methods sacrifice a considerable amount of out-of-distribution\nperformance in order to obtain high in-distribution performance. Therefore, it\nis challenging for them to deal with the complicated changing real-world\nsituations. In this paper, we propose a simple yet effective novel loss\nfunction with adaptive loose optimization, which seeks to make the best of both\nworlds for question answering. Our main technical contribution is to reduce the\nloss adaptively according to the ratio between the previous and current\noptimization state on mini-batch training data. This loose optimization can be\nused to prevent non-debiasing methods from overlearning data bias while\nenabling debiasing methods to maintain slight bias learning. Experiments on the\nvisual question answering datasets, including VQA v2, VQA-CP v1, VQA-CP v2,\nGQA-OOD, and the extractive question answering dataset SQuAD demonstrate that\nour approach enables QA methods to obtain state-of-the-art in- and\nout-of-distribution performance in most cases. The source code has been\nreleased publicly in \\url{https://github.com/reml-group/ALO}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jie Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Pinghui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zewei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_D/0/1/0/all/0/1\">Dechen Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1\">Min Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1\">Ting Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jun Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiscoPrompt: Path Prediction Prompt Tuning for Implicit Discourse Relation Recognition. (arXiv:2305.03973v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03973","description":"<p>Implicit Discourse Relation Recognition (IDRR) is a sophisticated and\nchallenging task to recognize the discourse relations between the arguments\nwith the absence of discourse connectives. The sense labels for each discourse\nrelation follow a hierarchical classification scheme in the annotation process\n(Prasad et al., 2008), forming a hierarchy structure. Most existing works do\nnot well incorporate the hierarchy structure but focus on the syntax features\nand the prior knowledge of connectives in the manner of pure text\nclassification. We argue that it is more effective to predict the paths inside\nthe hierarchical tree (e.g., \"Comparison -&gt; Contrast -&gt; however\") rather than\nflat labels (e.g., Contrast) or connectives (e.g., however). We propose a\nprompt-based path prediction method to utilize the interactive information and\nintrinsic senses among the hierarchy in IDRR. This is the first work that\ninjects such structure information into pre-trained language models via prompt\ntuning, and the performance of our solution shows significant and consistent\nimprovement against competitive baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chunkit Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1\">Jiayang Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zihan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_G/0/1/0/all/0/1\">Ginny Y. Wong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+See_S/0/1/0/all/0/1\">Simon See</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Adversarial Non-Autoregressive Model for Text Generation with Incomplete Information. (arXiv:2305.03977v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03977","description":"<p>Non-autoregressive models have been widely studied in the Complete\nInformation Scenario (CIS), in which the models have complete input information\nto obtain corresponding output. However, their explorations in the Incomplete\nInformation Scenario (IIS) are extremely limited. Our analyses reveal that the\nIIS's incomplete input information will augment the inherent limitations of\nexisting non-autoregressive models trained under Maximum Likelihood Estimation.\nIn this paper, we propose for the IIS an Adversarial Non-autoregressive\nTransformer (ANT) which has two novel features: 1) Position Aware\nSelf-Modulation to provide more reasonable hidden representations, and 2)\nDependency Feed Forward Network to strengthen its capacity in dependency\nmodeling. We compare ANT with other mainstream models in the IIS and\ndemonstrate that ANT can achieve comparable performance with much fewer\ndecoding iterations. Furthermore, we show its great potential in various\napplications like latent interpolation and semi-supervised learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_D/0/1/0/all/0/1\">Da Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training Language Model as a Multi-perspective Course Learner. (arXiv:2305.03981v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03981","description":"<p>ELECTRA, the generator-discriminator pre-training framework, has achieved\nimpressive semantic construction capability among various downstream tasks.\nDespite the convincing performance, ELECTRA still faces the challenges of\nmonotonous training and deficient interaction. Generator with only masked\nlanguage modeling (MLM) leads to biased learning and label imbalance for\ndiscriminator, decreasing learning efficiency; no explicit feedback loop from\ndiscriminator to generator results in the chasm between these two components,\nunderutilizing the course learning. In this study, a multi-perspective course\nlearning (MCL) method is proposed to fetch a many degrees and visual angles for\nsample-efficient pre-training, and to fully leverage the relationship between\ngenerator and discriminator. Concretely, three self-supervision courses are\ndesigned to alleviate inherent flaws of MLM and balance the label in a\nmulti-perspective way. Besides, two self-correction courses are proposed to\nbridge the chasm between the two encoders by creating a \"correction notebook\"\nfor secondary-supervision. Moreover, a course soups trial is conducted to solve\nthe \"tug-of-war\" dynamics problem of MCL, evolving a stronger pre-trained\nmodel. Experimental results show that our method significantly improves\nELECTRA's average performance by 2.8% and 3.2% absolute points respectively on\nGLUE and SQuAD 2.0 benchmarks, and overshadows recent advanced ELECTRA-style\nmodels under the same settings. The pre-trained MCL model is available at\nhttps://huggingface.co/McmanusChen/MCL-base.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Beiduo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Shaohan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zihan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1\">Wu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhenhua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haizhen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1\">Weiwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Replicating Complex Dialogue Policy of Humans via Offline Imitation Learning with Supervised Regularization. (arXiv:2305.03987v1 [cs.CL])","link":"http://arxiv.org/abs/2305.03987","description":"<p>Policy learning (PL) is a module of a task-oriented dialogue system that\ntrains an agent to make actions in each dialogue turn. Imitating human action\nis a fundamental problem of PL. However, both supervised learning (SL) and\nreinforcement learning (RL) frameworks cannot imitate humans well. Training RL\nmodels require online interactions with user simulators, while simulating\ncomplex human policy is hard. Performances of SL-based models are restricted\nbecause of the covariate shift problem. Specifically, a dialogue is a\nsequential decision-making process where slight differences in current\nutterances and actions will cause significant differences in subsequent\nutterances. Therefore, the generalize ability of SL models is restricted\nbecause statistical characteristics of training and testing dialogue data\ngradually become different. This study proposed an offline imitation learning\nmodel that learns policy from real dialogue datasets and does not require user\nsimulators. It also utilizes state transition information, which alleviates the\ninfluence of the covariate shift problem. We introduced a regularization trick\nto make our model can be effectively optimized. We investigated the performance\nof our model on four independent public dialogue datasets. The experimental\nresult showed that our model performed better in the action prediction task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhoujian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chenyang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhengxing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1\">Nai Ding</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ANTONIO: Towards a Systematic Method of Generating NLP Benchmarks for Verification. (arXiv:2305.04003v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04003","description":"<p>Verification of machine learning models used in Natural Language Processing\n(NLP) is known to be a hard problem. In particular, many known neural network\nverification methods that work for computer vision and other numeric datasets\ndo not work for NLP. Here, we study technical reasons that underlie this\nproblem. Based on this analysis, we propose practical methods and heuristics\nfor preparing NLP datasets and models in a way that renders them amenable to\nknown verification methods based on abstract interpretation. We implement these\nmethods as a Python library called ANTONIO that links to the neural network\nverifiers ERAN and Marabou. We perform evaluation of the tool using an NLP\ndataset R-U-A-Robot suggested as a benchmark for verifying legally critical NLP\napplications. We hope that, thanks to its general applicability, this work will\nopen novel possibilities for including NLP verification problems into neural\nnetwork verification competitions, and will popularise NLP problems within this\ncommunity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Casadio_M/0/1/0/all/0/1\">Marco Casadio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arnaboldi_L/0/1/0/all/0/1\">Luca Arnaboldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daggitt_M/0/1/0/all/0/1\">Matthew L. Daggitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isac_O/0/1/0/all/0/1\">Omri Isac</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinkar_T/0/1/0/all/0/1\">Tanvi Dinkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kienitz_D/0/1/0/all/0/1\">Daniel Kienitz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1\">Verena Rieser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Komendantskaya_E/0/1/0/all/0/1\">Ekaterina Komendantskaya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Refining the Responses of LLMs by Themselves. (arXiv:2305.04039v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04039","description":"<p>In this paper, we propose a simple yet efficient approach based on prompt\nengineering that leverages the large language model itself to optimize its\nanswers without relying on auxiliary models. We introduce an iterative\nself-evaluating optimization mechanism, with the potential for improved output\nquality as iterations progress, removing the need for manual intervention. The\nexperiment's findings indicate that utilizing our response refinement framework\non the GPT-3.5 model yields results that are on par with, or even surpass,\nthose generated by the cutting-edge GPT-4 model. Detailed implementation\nstrategies and illustrative examples are provided to demonstrate the\nsuperiority of our proposed solution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1\">Tianqiang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1\">Tiansheng Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Diffusion-NAT: Self-Prompting Discrete Diffusion for Non-Autoregressive Text Generation. (arXiv:2305.04044v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04044","description":"<p>Recently, continuous diffusion models (CDM) have been introduced into\nnon-autoregressive (NAR) text-to-text generation. However, the discrete nature\nof text increases the difficulty of CDM to generate coherent and fluent texts,\nand also causes the incompatibility problem between CDM and advanced NLP\ntechniques, especially the popular pre-trained language models~(PLMs). To solve\nit, we propose Diffusion-NAT, which introduces discrete diffusion models~(DDM)\ninto NAR text-to-text generation and integrates BART to improve the\nperformance. By revising the decoding process of BART and the typical settings\nof DDM, we unify the inference process of BART and the denoising process of DDM\ninto the same NAR masked tokens recovering task. In this way, DDM can rely on\nBART to perform denoising, which can benefit from both the rich pre-learned\nknowledge of BART and the iterative refining paradigm of DDM. Besides, we also\npropose the iterative self-prompting strategy to further improve the generation\nquality. Experimental results on 7 datasets show that our approach can\noutperform competitive NAR methods, and even surpass autoregressive methods.\nOur code and data will be publicly released.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Actively Discovering New Slots for Task-oriented Conversation. (arXiv:2305.04049v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04049","description":"<p>Existing task-oriented conversational search systems heavily rely on domain\nontologies with pre-defined slots and candidate value sets. In practical\napplications, these prerequisites are hard to meet, due to the emerging new\nuser requirements and ever-changing scenarios. To mitigate these issues for\nbetter interaction performance, there are efforts working towards detecting\nout-of-vocabulary values or discovering new slots under unsupervised or\nsemi-supervised learning paradigm. However, overemphasizing on the conversation\ndata patterns alone induces these methods to yield noisy and arbitrary slot\nresults. To facilitate the pragmatic utility, real-world systems tend to\nprovide a stringent amount of human labelling quota, which offers an\nauthoritative way to obtain accurate and meaningful slot assignments.\nNonetheless, it also brings forward the high requirement of utilizing such\nquota efficiently. Hence, we formulate a general new slot discovery task in an\ninformation extraction fashion and incorporate it into an active learning\nframework to realize human-in-the-loop learning. Specifically, we leverage\nexisting language tools to extract value candidates where the corresponding\nlabels are further leveraged as weak supervision signals. Based on these, we\npropose a bi-criteria selection scheme which incorporates two major strategies,\nnamely, uncertainty-based sampling and diversity-based sampling to efficiently\nidentify terms of interest. We conduct extensive experiments on several public\ndatasets and compare with a bunch of competitive baselines to demonstrate the\neffectiveness of our method. We have made the code and data used in this paper\npublicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1\">Tianhao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhedong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_L/0/1/0/all/0/1\">Lizi Liao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reactive Perturbation Defocusing for Textual Adversarial Defense. (arXiv:2305.04067v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04067","description":"<p>Recent studies have shown that large pre-trained language models are\nvulnerable to adversarial attacks. Existing methods attempt to reconstruct the\nadversarial examples. However, these methods usually have limited performance\nin defense against adversarial examples, while also negatively impacting the\nperformance on natural examples. To overcome this problem, we propose a method\ncalled Reactive Perturbation Defocusing (RPD). RPD uses an adversarial detector\nto identify adversarial examples and reduce false defenses on natural examples.\nInstead of reconstructing the adversaries, RPD injects safe perturbations into\nadversarial examples to distract the objective models from the malicious\nperturbations. Our experiments on three datasets, two objective models, and\nvarious adversarial attacks show that our proposed framework successfully\nrepairs up to approximately 97% of correctly identified adversarial examples\nwith only about a 2% performance decrease on natural examples. We also provide\na demo of adversarial detection and repair based on our work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Heng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Ke Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SANTA: Separate Strategies for Inaccurate and Incomplete Annotation Noise in Distantly-Supervised Named Entity Recognition. (arXiv:2305.04076v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04076","description":"<p>Distantly-Supervised Named Entity Recognition effectively alleviates the\nburden of time-consuming and expensive annotation in the supervised setting.\nBut the context-free matching process and the limited coverage of knowledge\nbases introduce inaccurate and incomplete annotation noise respectively.\nPrevious studies either considered only incomplete annotation noise or\nindiscriminately handle two types of noise with the same strategy. In this\npaper, we argue that the different causes of two types of noise bring up the\nrequirement of different strategies in model architecture. Therefore, we\npropose the SANTA to handle these two types of noise separately with (1)\nMemory-smoothed Focal Loss and Entity-aware KNN to relieve the entity ambiguity\nproblem caused by inaccurate annotation, and (2) Boundary Mixup to alleviate\ndecision boundary shifting problem caused by incomplete annotation and a\nnoise-tolerant loss to improve the robustness. Benefiting from our separate\ntailored strategies, we confirm in the experiment that the two types of noise\nare well mitigated. SANTA also achieves a new state-of-the-art on five public\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1\">Shuzheng Si</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1\">Zefan Cai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1\">Shuang Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1\">Guoqiang Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jiaxing Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1\">Baobao Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Minimal Approach for Natural Language Action Space in Text-based Games. (arXiv:2305.04082v1 [cs.LG])","link":"http://arxiv.org/abs/2305.04082","description":"<p>Text-based games (TGs) are language-based interactive environments for\nreinforcement learning. While language models (LMs) and knowledge graphs (KGs)\nare commonly used for handling large action space in TGs, it is unclear whether\nthese techniques are necessary or overused. In this paper, we revisit the\nchallenge of exploring the action space in TGs and propose $\n\\epsilon$-admissible exploration, a minimal approach of utilizing admissible\nactions, for training phase. Additionally, we present a text-based actor-critic\n(TAC) agent that produces textual commands for game, solely from game\nobservations, without requiring any KG or LM. Our method, on average across 10\ngames from Jericho, outperforms strong baselines and state-of-the-art agents\nthat use LM and KG. Our approach highlights that a much lighter model design,\nwith a fresh perspective on utilizing the information within the environments,\nsuffices for an effective exploration of exponentially large action spaces.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ryu_D/0/1/0/all/0/1\">Dongwon Kelvin Ryu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1\">Meng Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1\">Shirui Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haffari_G/0/1/0/all/0/1\">Gholamreza Haffari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1\">Ehsan Shareghi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Edit: Fault-Aware Code Editor for Code Generation. (arXiv:2305.04087v1 [cs.SE])","link":"http://arxiv.org/abs/2305.04087","description":"<p>Large language models (LLMs) have demonstrated an impressive ability to\ngenerate codes on competitive programming tasks. However, with limited sample\nnumbers, LLMs still suffer from poor accuracy. Inspired by the process of human\nprogramming, we propose a generate-and-edit approach that utilizes execution\nresults of the generated code from LLMs to improve the code quality on the\ncompetitive programming task. We execute the generated code on the example test\ncase provided in the question and wrap execution results into a supplementary\ncomment. Utilizing this comment as guidance, our fault-aware code editor is\nemployed to correct errors in the generated code. We perform extensive\nevaluations across two competitive programming datasets with nine different\nLLMs. Compared to directly generating from LLMs, our approach can improve the\naverage of pass@1 by 89\\% on APPS-dev, 31\\% on APPS-test, and 48\\% on HumanEval\nover nine popular code generation LLMs with parameter sizes ranging from 110M\nto 175B. Compared to other post-processing methods, our method demonstrates\nsuperior accuracy and efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kechi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhuo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Ge Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhi Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models. (arXiv:2305.04091v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04091","description":"<p>Large language models (LLMs) have recently been shown to deliver impressive\nperformance in various NLP tasks. To tackle multi-step reasoning tasks,\nfew-shot chain-of-thought (CoT) prompting includes a few manually crafted\nstep-by-step reasoning demonstrations which enable LLMs to explicitly generate\nreasoning steps and improve their reasoning task accuracy. To eliminate the\nmanual effort, Zero-shot-CoT concatenates the target problem statement with\n\"Let's think step by step\" as an input prompt to LLMs. Despite the success of\nZero-shot-CoT, it still suffers from three pitfalls: calculation errors,\nmissing-step errors, and semantic misunderstanding errors. To address the\nmissing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of\ntwo components: first, devising a plan to divide the entire task into smaller\nsubtasks, and then carrying out the subtasks according to the plan. To address\nthe calculation errors and improve the quality of generated reasoning steps, we\nextend PS prompting with more detailed instructions and derive PS+ prompting.\nWe evaluate our proposed prompting strategy on ten datasets across three\nreasoning problems. The experimental results over GPT-3 show that our proposed\nzero-shot prompting consistently outperforms Zero-shot-CoT across all datasets\nby a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought\nPrompting, and has comparable performance with 8-shot CoT prompting on the math\nreasoning problem. The code can be found at\nhttps://github.com/AGI-Edgerunners/Plan-and-Solve-Prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wanyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yihuai Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiqiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yunshi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Roy Ka-Wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Ee-Peng Lim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rhetorical Role Labeling of Legal Documents using Transformers and Graph Neural Networks. (arXiv:2305.04100v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04100","description":"<p>A legal document is usually long and dense requiring human effort to parse\nit. It also contains significant amounts of jargon which make deriving insights\nfrom it using existing models a poor approach. This paper presents the\napproaches undertaken to perform the task of rhetorical role labelling on\nIndian Court Judgements as part of SemEval Task 6: understanding legal texts,\nshared subtask A. We experiment with graph based approaches like Graph\nConvolutional Networks and Label Propagation Algorithm, and transformer-based\napproaches including variants of BERT to improve accuracy scores on text\nclassification of complex legal documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Anshika Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Furniturewala_S/0/1/0/all/0/1\">Shaz Furniturewala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumari_V/0/1/0/all/0/1\">Vijay Kumari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1\">Yashvardhan Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"When Words Fail, Emojis Prevail\": Generating Sarcastic Utterances with Emoji Using Valence Reversal and Semantic Incongruity. (arXiv:2305.04105v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04105","description":"<p>Sarcasm pertains to the subtle form of language that individuals use to\nexpress the opposite of what is implied. We present a novel architecture for\nsarcasm generation with emoji from a non-sarcastic input sentence. We divide\nthe generation task into two sub tasks: one for generating textual sarcasm and\nanother for collecting emojis associated with those sarcastic sentences. Two\nkey elements of sarcasm are incorporated into the textual sarcasm generation\ntask: valence reversal and semantic incongruity with context, where the context\nmay involve shared commonsense or general knowledge between the speaker and\ntheir audience. The majority of existing sarcasm generation works have focused\non this textual form. However, in the real world, when written texts fall short\nof effectively capturing the emotional cues of spoken and face-to-face\ncommunication, people often opt for emojis to accurately express their\nemotions. Due to the wide range of applications of emojis, incorporating\nappropriate emojis to generate textual sarcastic sentences helps advance\nsarcasm generation. We conclude our study by evaluating the generated sarcastic\nsentences using human judgement. All the codes and data used in this study will\nbe made publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kader_F/0/1/0/all/0/1\">Faria Binte Kader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nujat_N/0/1/0/all/0/1\">Nafisa Hossain Nujat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sogir_T/0/1/0/all/0/1\">Tasmia Binte Sogir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kabir_M/0/1/0/all/0/1\">Mohsinul Kabir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1\">Hasan Mahmud</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hasan_K/0/1/0/all/0/1\">Kamrul Hasan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Human-Like Translation Strategy with Large Language Models. (arXiv:2305.04118v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04118","description":"<p>Large language models (LLMs) have demonstrated impressive capabilities in\ngeneral scenarios, exhibiting a level of aptitude that approaches, in some\naspects even surpasses, human-level intelligence. Among their numerous skills,\nthe translation abilities of LLMs have received considerable attention. In\ncontrast to traditional machine translation that focuses solely on\nsource-target mapping, LLM-based translation can potentially mimic the human\ntranslation process that takes many preparatory steps to ensure high-quality\ntranslation. This work aims to explore this possibility by proposing the MAPS\nframework, which stands for Multi-Aspect Prompting and Selection. Specifically,\nwe enable LLMs to first analyze the given source text and extract three aspects\nof translation-related knowledge: keywords, topics and relevant demonstrations\nto guide the translation process. To filter out the noisy and unhelpful\nknowledge, we employ a selection mechanism based on quality estimation.\nExperiments suggest that MAPS brings significant and consistent improvements\nover text-davinci-003 and Alpaca on eight translation directions from the\nlatest WMT22 test sets. Our further analysis shows that the extracted knowledge\nis critical in resolving up to 59% of hallucination mistakes in translation.\nCode is available at https://github.com/zwhe99/MAPS-mt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhiwei He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1\">Tian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1\">Wenxiang Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhuosheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yujiu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1\">Zhaopeng Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xing Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Mixed-Initiative Dialogue Generation through Prompting. (arXiv:2305.04147v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04147","description":"<p>Mixed-initiative dialogue tasks involve repeated exchanges of information and\nconversational control. Conversational agents gain control by generating\nresponses that follow particular dialogue intents or strategies, prescribed by\na policy planner. The standard approach has been fine-tuning pre-trained\nlanguage models to perform generation conditioned on these intents. However,\nthese supervised generation models are limited by the cost and quality of data\nannotation. We instead prompt large language models as a drop-in replacement to\nfine-tuning on conditional generation. We formalize prompt construction for\ncontrollable mixed-initiative dialogue. Our findings show improvements over\nfine-tuning and ground truth responses according to human evaluation and\nautomatic metrics for two tasks: PersuasionForGood and Emotional Support\nConversations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Maximillian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xiao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weiyan Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awasthi_U/0/1/0/all/0/1\">Urvi Awasthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"X-LLM: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages. (arXiv:2305.04160v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04160","description":"<p>Large language models (LLMs) have demonstrated remarkable language abilities.\nGPT-4, based on advanced LLMs, exhibits extraordinary multimodal capabilities\nbeyond previous visual language models. We attribute this to the use of more\nadvanced LLMs compared with previous multimodal models. Unfortunately, the\nmodel architecture and training strategies of GPT-4 are unknown. To endow LLMs\nwith multimodal capabilities, we propose X-LLM, which converts Multi-modalities\n(images, speech, videos) into foreign languages using X2L interfaces and inputs\nthem into a large Language model (ChatGLM). Specifically, X-LLM aligns multiple\nfrozen single-modal encoders and a frozen LLM using X2L interfaces, where ``X''\ndenotes multi-modalities such as image, speech, and videos, and ``L'' denotes\nlanguages. X-LLM's training consists of three stages: (1) Converting Multimodal\nInformation: The first stage trains each X2L interface to align with its\nrespective single-modal encoder separately to convert multimodal information\ninto languages. (2) Aligning X2L representations with the LLM: single-modal\nencoders are aligned with the LLM through X2L interfaces independently. (3)\nIntegrating multiple modalities: all single-modal encoders are aligned with the\nLLM through X2L interfaces to integrate multimodal capabilities into the LLM.\nOur experiments show that X-LLM demonstrates impressive multimodel chat\nabilities, sometimes exhibiting the behaviors of multimodal GPT-4 on unseen\nimages/instructions, and yields a 84.5\\% relative score compared with GPT-4 on\na synthetic multimodal instruction-following dataset. And we also conduct\nquantitative tests on using LLM for ASR and multimodal ASR, hoping to promote\nthe era of LLM-based speech recognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Feilong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1\">Minglun Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haozhi Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qingyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bo Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in Vietnamese. (arXiv:2305.04166v1 [cs.CV])","link":"http://arxiv.org/abs/2305.04166","description":"<p>Image Captioning is one of the vision-language tasks that still interest the\nresearch community worldwide in the 2020s. MS-COCO Caption benchmark is\ncommonly used to evaluate the performance of advanced captioning models,\nalthough it was published in 2015. Recent captioning models trained on the\nMS-COCO Caption dataset only have good performance in language patterns of\nEnglish; they do not have such good performance in contexts captured in Vietnam\nor fluently caption images using Vietnamese. To contribute to the low-resources\nresearch community as in Vietnam, we introduce a novel image captioning dataset\nin Vietnamese, the Open-domain Vietnamese Image Captioning dataset\n(UIT-OpenViIC). The introduced dataset includes complex scenes captured in\nVietnam and manually annotated by Vietnamese under strict rules and\nsupervision. In this paper, we present in more detail the dataset creation\nprocess. From preliminary analysis, we show that our dataset is challenging to\nrecent state-of-the-art (SOTA) Transformer-based baselines, which performed\nwell on the MS COCO dataset. Then, the modest results prove that UIT-OpenViIC\nhas room to grow, which can be one of the standard benchmarks in Vietnamese for\nthe research community to evaluate their captioning models. Furthermore, we\npresent a CAMO approach that effectively enhances the image representation\nability by a multi-level encoder output fusion mechanism, which helps improve\nthe quality of generated captions compared to previous captioning models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bui_D/0/1/0/all/0/1\">Doanh C. Bui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nghia Hieu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khang Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MIReAD: Simple Method for Learning High-quality Representations from Scientific Documents. (arXiv:2305.04177v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04177","description":"<p>Learning semantically meaningful representations from scientific documents\ncan facilitate academic literature search and improve performance of\nrecommendation systems. Pre-trained language models have been shown to learn\nrich textual representations, yet they cannot provide powerful document-level\nrepresentations for scientific articles. We propose MIReAD, a simple method\nthat learns high-quality representations of scientific papers by fine-tuning\ntransformer model to predict the target journal class based on the abstract. We\ntrain MIReAD on more than 500,000 PubMed and arXiv abstracts across over 2,000\njournal classes. We show that MIReAD produces representations that can be used\nfor similar papers retrieval, topic categorization and literature search. Our\nproposed approach outperforms six existing models for representation learning\non scientific documents across four evaluation standards.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razdaibiedina_A/0/1/0/all/0/1\">Anastasia Razdaibiedina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brechalov_A/0/1/0/all/0/1\">Alexander Brechalov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shall We Trust All Relational Tuples by Open Information Extraction? A Study on Speculation Detection. (arXiv:2305.04181v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04181","description":"<p>Open Information Extraction (OIE) aims to extract factual relational tuples\nfrom open-domain sentences. Downstream tasks use the extracted OIE tuples as\nfacts, without examining the certainty of these facts. However,\nuncertainty/speculation is a common linguistic phenomenon. Existing studies on\nspeculation detection are defined at sentence level, but even if a sentence is\ndetermined to be speculative, not all tuples extracted from it may be\nspeculative. In this paper, we propose to study speculations in OIE and aim to\ndetermine whether an extracted tuple is speculative. We formally define the\nresearch problem of tuple-level speculation detection and conduct a detailed\ndata analysis on the LSOIE dataset which contains labels for speculative\ntuples. Lastly, we propose a baseline model OIE-Spec for this new research\ntask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_K/0/1/0/all/0/1\">Kuicai Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jung-Jae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiaoli Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual Question Answering in Vietnamese. (arXiv:2305.04183v1 [cs.CL])","link":"http://arxiv.org/abs/2305.04183","description":"<p>In recent years, visual question answering (VQA) has attracted attention from\nthe research community because of its highly potential applications (such as\nvirtual assistance on intelligent cars, assistant devices for blind people, or\ninformation retrieval from document images using natural language as queries)\nand challenge. The VQA task requires methods that have the ability to fuse the\ninformation from questions and images to produce appropriate answers. Neural\nvisual question answering models have achieved tremendous growth on large-scale\ndatasets which are mostly for resource-rich languages such as English. However,\navailable datasets narrow the VQA task as the answers selection task or answer\nclassification task. We argue that this form of VQA is far from human ability\nand eliminates the challenge of the answering aspect in the VQA task by just\nselecting answers rather than generating them. In this paper, we introduce the\nOpenViVQA (Open-domain Vietnamese Visual Question Answering) dataset, the first\nlarge-scale dataset for VQA with open-ended answers in Vietnamese, consists of\n11,000+ images associated with 37,000+ question-answer pairs (QAs). Moreover,\nwe proposed FST, QuMLAG, and MLPAG which fuse information from images and\nanswers, then use these fused features to construct answers as humans\niteratively. Our proposed methods achieve results that are competitive with\nSOTA models such as SAAA, MCAN, LORA, and M4C. The dataset is available to\nencourage the research community to develop more generalized algorithms\nincluding transformers for low-resource languages such as Vietnamese.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Nghia Hieu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vo_D/0/1/0/all/0/1\">Duong T.D. Vo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kiet Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1\">Ngan Luu-Thuy Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Modal Retrieval for Motion and Text via MildTriple Loss. (arXiv:2305.04195v1 [cs.CV])","link":"http://arxiv.org/abs/2305.04195","description":"<p>Cross-modal retrieval has become a prominent research topic in computer\nvision and natural language processing with advances made in image-text and\nvideo-text retrieval technologies. However, cross-modal retrieval between human\nmotion sequences and text has not garnered sufficient attention despite the\nextensive application value it holds, such as aiding virtual reality\napplications in better understanding users' actions and language. This task\npresents several challenges, including joint modeling of the two modalities,\ndemanding the understanding of person-centered information from text, and\nlearning behavior features from 3D human motion sequences. Previous work on\nmotion data modeling mainly relied on autoregressive feature extractors that\nmay forget previous information, while we propose an innovative model that\nincludes simple yet powerful transformer-based motion and text encoders, which\ncan learn representations from the two different modalities and capture\nlong-term dependencies. Furthermore, the overlap of the same atomic actions of\ndifferent human motions can cause semantic conflicts, leading us to explore a\nnew triplet loss function, MildTriple Loss. it leverages the similarity between\nsamples in intra-modal space to guide soft-hard negative sample mining in the\njoint embedding space to train the triplet loss and reduce the violation caused\nby false negative samples. We evaluated our model and method on the latest\nHumanML3D and KIT Motion-Language datasets, achieving a 62.9\\% recall for\nmotion retrieval and a 71.5\\% recall for text retrieval (based on R@10) on the\nHumanML3D dataset. Our code is available at\nhttps://github.com/eanson023/rehamot.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Sheng Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoqiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mengyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Large and Diverse Arabic Corpus for Language Modeling. (arXiv:2201.09227v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.09227","description":"<p>Language models (LMs) have introduced a major paradigm shift in Natural\nLanguage Processing (NLP) modeling where large pre-trained LMs became integral\nto most of the NLP tasks. The LMs are intelligent enough to find useful and\nrelevant representations of the language without any supervision. Perhaps,\nthese models are used to fine-tune typical NLP tasks with significantly high\naccuracy as compared to the traditional approaches. Conversely, the training of\nthese models requires a massively large corpus that is a good representation of\nthe language. English LMs generally perform better than their other language\ncounterparts, due to the availability of massive English corpora. This work\nelaborates on the design and development of a large Arabic corpus. It consists\nof over 500 GB of Arabic cleaned text targeted at improving cross-domain\nknowledge and downstream generalization capability of large-scale language\nmodels. Moreover, the corpus is utilized in the training of a large Arabic LM.\nIn order to evaluate the effectiveness of the LM, a number of typical NLP tasks\nare fine-tuned. The tasks demonstrate a significant boost from 4.5 to 8.5% when\ncompared to tasks fine-tuned on multi-lingual BERT (mBERT). To the best of my\nknowledge, this is currently the largest clean and diverse Arabic corpus ever\ncollected.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1\">Abbas Raza Ali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Siddiqui_M/0/1/0/all/0/1\">Muhammad Ajmal Siddiqui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Algunaibet_R/0/1/0/all/0/1\">Rema Algunaibet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1\">Hasan Raza Ali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Helpfulness and Fairness of Task-Oriented Dialogue Systems. (arXiv:2205.12554v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12554","description":"<p>Goal-oriented dialogue systems aim to help users achieve certain goals.\nTherefore, how humans perceive their helpfulness is important. However, neither\nthe human-perceived helpfulness of goal-oriented dialogue systems nor its\nfairness implication has been well studied. In this paper, we study\ncomputational measurements of helpfulness. We first formally define a dialogue\nresponse as helpful if it is relevant &amp; coherent, useful, and informative to a\nquery. Then, we collect human annotations for the helpfulness of dialogue\nresponses based on our definition and build a classifier to automatically\ndetermine the helpfulness of a response. We further propose to use the\nhelpfulness level of a dialogue system towards different user queries to\nmeasure the fairness of a dialogue system. Experiments with state-of-the-art\ndialogue systems under three information-seeking scenarios reveal that existing\nsystems tend to be more helpful for questions regarding concepts from\nhighly-developed countries than less-developed countries, uncovering potential\nfairness concerns underlying the current goal-oriented dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yu Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jiin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Delving into the Openness of CLIP. (arXiv:2206.01986v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2206.01986","description":"<p>Contrastive Language-Image Pre-training (CLIP) formulates image\nclassification as an image-to-text matching task, i.e., matching images to the\ncorresponding natural language descriptions instead of discrete category IDs.\nThis allows for open-vocabulary visual recognition, where the model can\nrecognize images from an open class set (also known as an open vocabulary) in a\nzero-shot manner. However, evaluating the openness of CLIP-like models is\nchallenging, as the models are open to arbitrary vocabulary in theory, but\ntheir accuracy varies in practice. To address this, we resort to an incremental\nperspective to assess the openness through vocabulary expansions, and define\nextensibility to measure a model's ability to handle novel classes. Our\nevaluation shows that CLIP-like models are not truly open, and their\nperformance deteriorates as the vocabulary expands. We further dissect the\nfeature space of CLIP from the perspectives of representation alignment and\nuniformity. Our investigation reveals that the overestimation of openness is\ndue to confusion among competing text features, rather than a failure to\ncapture the similarity between image features and text features of novel\nclasses. We hope that our investigation and analysis will facilitate future\nresearch on the CLIP openness issue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1\">Shuhuai Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Guangxiang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Characterizing narrative time in books through fluctuations in power and danger arcs. (arXiv:2208.09496v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.09496","description":"<p>While quantitative methods have been used to examine changes in word usage in\nbooks, studies have focused on overall trends, such as the shapes of\nnarratives, which are independent of book length. We instead look at how words\nchange over the course of a book as a function of the number of words, rather\nthan the fraction of the book, completed at any given point; we define this\nmeasure as \"cumulative word-time\". Using ousiometrics, a reinterpretation of\nthe valence-arousal-dominance framework of meaning obtained from semantic\ndifferentials, we convert text into time series of power and danger scores in\ncumulative word-time. Each time series is then decomposed using empirical mode\ndecomposition into a sum of constituent oscillatory modes and a non-oscillatory\ntrend. By comparing the decomposition of the original power and danger time\nseries with those derived from shuffled text, we find that shorter books\nexhibit only a general trend, while longer books have fluctuations in addition\nto the general trend. These fluctuations typically have a period of a few\nthousand words regardless of the book length or library classification code,\nbut vary depending on the content and structure of the book. Our findings\nsuggest that, in the ousiometric sense, longer books are not expanded versions\nof shorter books, but are more similar in structure to a concatenation of\nshorter texts. Further, they are consistent with editorial practices that\nrequire longer texts to be broken down into sections, such as chapters. Our\nmethod also provides a data-driven denoising approach that works for texts of\nvarious lengths, in contrast to the more traditional approach of using large\nwindow sizes that may inadvertently smooth out relevant information, especially\nfor shorter texts. These results open up avenues for future work in\ncomputational literary analysis, particularly the measurement of a basic unit\nof narrative.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fudolig_M/0/1/0/all/0/1\">Mikaela Irene Fudolig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alshaabi_T/0/1/0/all/0/1\">Thayer Alshaabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cramer_K/0/1/0/all/0/1\">Kathryn Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Danforth_C/0/1/0/all/0/1\">Christopher M. Danforth</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodds_P/0/1/0/all/0/1\">Peter Sheridan Dodds</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"General-to-Specific Transfer Labeling for Domain Adaptable Keyphrase Generation. (arXiv:2208.09606v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.09606","description":"<p>Training keyphrase generation (KPG) models require a large amount of\nannotated data, which can be prohibitively expensive and often limited to\nspecific domains. In this study, we first demonstrate that large distribution\nshifts among different domains severely hinder the transferability of KPG\nmodels. We then propose a three-stage pipeline, which gradually guides KPG\nmodels' learning focus from general syntactical features to domain-related\nsemantics, in a data-efficient manner. With Domain-general Phrase pre-training,\nwe pre-train Sequence-to-Sequence models with generic phrase annotations that\nare widely available on the web, which enables the models to generate phrases\nin a wide range of domains. The resulting model is then applied in the Transfer\nLabeling stage to produce domain-specific pseudo keyphrases, which help adapt\nmodels to a new domain. Finally, we fine-tune the model with limited data with\ntrue labels to fully adapt it to the target domain. Our experiment results show\nthat the proposed process can produce good-quality keyphrases in new domains\nand achieve consistent improvements after adaptation with limited in-domain\nannotated data. All code and datasets are available at\nhttps://github.com/memray/OpenNMT-kpg-release.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1\">Rui Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1\">Xingdi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yingbo Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1\">Daqing He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Persuasion Strategies in Advertisements. (arXiv:2208.09626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.09626","description":"<p>Modeling what makes an advertisement persuasive, i.e., eliciting the desired\nresponse from consumer, is critical to the study of propaganda, social\npsychology, and marketing. Despite its importance, computational modeling of\npersuasion in computer vision is still in its infancy, primarily due to the\nlack of benchmark datasets that can provide persuasion-strategy labels\nassociated with ads. Motivated by persuasion literature in social psychology\nand marketing, we introduce an extensive vocabulary of persuasion strategies\nand build the first ad image corpus annotated with persuasion strategies. We\nthen formulate the task of persuasion strategy prediction with multi-modal\nlearning, where we design a multi-task attention fusion model that can leverage\nother ad-understanding tasks to predict persuasion strategies. Further, we\nconduct a real-world case study on 1600 advertising campaigns of 30 Fortune-500\ncompanies where we use our model's predictions to analyze which strategies work\nwith different demographics (age and gender). The dataset also provides image\nsegmentation masks, which labels persuasion strategies in the corresponding ad\nimages on the test split. We publicly release our code and dataset\nhttps://midas-research.github.io/persuasion-advertisements/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singla_Y/0/1/0/all/0/1\">Yaman Kumar Singla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jha_R/0/1/0/all/0/1\">Rajat Jha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Arunim Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aggarwal_M/0/1/0/all/0/1\">Milan Aggarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1\">Aditya Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malyan_T/0/1/0/all/0/1\">Tushar Malyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhardwaj_A/0/1/0/all/0/1\">Ayush Bhardwaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_R/0/1/0/all/0/1\">Rajiv Ratn Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1\">Balaji Krishnamurthy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shortcut Learning of Large Language Models in Natural Language Understanding. (arXiv:2208.11857v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.11857","description":"<p>Large language models (LLMs) have achieved state-of-the-art performance on a\nseries of natural language understanding tasks. However, these LLMs might rely\non dataset bias and artifacts as shortcuts for prediction. This has\nsignificantly affected their generalizability and adversarial robustness. In\nthis paper, we provide a review of recent developments that address the\nshortcut learning and robustness challenge of LLMs. We first introduce the\nconcepts of shortcut learning of language models. We then introduce methods to\nidentify shortcut learning behavior in language models, characterize the\nreasons for shortcut learning, as well as introduce mitigation solutions.\nFinally, we discuss key research challenges and potential research directions\nin order to advance the field of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1\">Mengnan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1\">Fengxiang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_N/0/1/0/all/0/1\">Na Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vega-MT: The JD Explore Academy Translation System for WMT22. (arXiv:2209.09444v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.09444","description":"<p>We describe the JD Explore Academy's submission of the WMT 2022 shared\ngeneral translation task. We participated in all high-resource tracks and one\nmedium-resource track, including Chinese-English, German-English,\nCzech-English, Russian-English, and Japanese-English. We push the limit of our\nprevious work -- bidirectional training for translation by scaling up two main\nfactors, i.e. language pairs and model sizes, namely the \\textbf{Vega-MT}\nsystem. As for language pairs, we scale the \"bidirectional\" up to the\n\"multidirectional\" settings, covering all participating languages, to exploit\nthe common knowledge across languages, and transfer them to the downstream\nbilingual tasks. As for model sizes, we scale the Transformer-Big up to the\nextremely large model that owns nearly 4.7 Billion parameters, to fully enhance\nthe model capacity for our Vega-MT. Also, we adopt the data augmentation\nstrategies, e.g. cycle translation for monolingual data, and bidirectional\nself-training for bilingual and monolingual data, to comprehensively exploit\nthe bilingual and monolingual data. To adapt our Vega-MT to the general domain\ntest set, generalization tuning is designed. Based on the official automatic\nscores of constrained systems, in terms of the sacreBLEU shown in Figure-1, we\ngot the 1st place on {Zh-En (33.5), En-Zh (49.7), De-En (33.7), En-De (37.8),\nCs-En (54.9), En-Cs (41.4) and En-Ru (32.7)}, 2nd place on {Ru-En (45.1) and\nJa-En (25.6)}, and 3rd place on {En-Ja(41.5)}, respectively; W.R.T the COMET,\nwe got the 1st place on {Zh-En (45.1), En-Zh (61.7), De-En (58.0), En-De\n(63.2), Cs-En (74.7), Ru-En (64.9), En-Ru (69.6) and En-Ja (65.1)}, 2nd place\non {En-Cs (95.3) and Ja-En (40.6)}, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zan_C/0/1/0/all/0/1\">Changtong Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Keqin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_B/0/1/0/all/0/1\">Baopu Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1\">Boan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shwai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1\">Qingyu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Weifeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1\">Yibing Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Music-to-Text Synaesthesia: Generating Descriptive Text from Music Recordings. (arXiv:2210.00434v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2210.00434","description":"<p>In this paper, we consider a novel research problem: music-to-text\nsynaesthesia. Different from the classical music tagging problem that\nclassifies a music recording into pre-defined categories, music-to-text\nsynaesthesia aims to generate descriptive texts from music recordings with the\nsame sentiment for further understanding. As existing music-related datasets do\nnot contain the semantic descriptions on music recordings, we collect a new\ndataset that contains 1,955 aligned pairs of classical music recordings and\ntext descriptions. Based on this, we build a computational model to generate\nsentences that can describe the content of the music recording. To tackle the\nhighly non-discriminative classical music, we design a group\ntopology-preservation loss, which considers more samples as a group reference\nand preserves the relative topology among different samples. Extensive\nexperimental results qualitatively and quantitatively demonstrate the\neffectiveness of our proposed model over five heuristics or pre-trained\ncompetitive methods and their variants on our collected dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Kuang_Z/0/1/0/all/0/1\">Zhihuan Kuang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zong_S/0/1/0/all/0/1\">Shi Zong</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1\">Jianbing Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1\">Jiajun Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Liu_H/0/1/0/all/0/1\">Hongfu Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Synonym Substitution Attacks Really Synonym Substitution Attacks?. (arXiv:2210.02844v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.02844","description":"<p>In this paper, we explore the following question: Are synonym substitution\nattacks really synonym substitution attacks (SSAs)? We approach this question\nby examining how SSAs replace words in the original sentence and show that\nthere are still unresolved obstacles that make current SSAs generate invalid\nadversarial samples. We reveal that four widely used word substitution methods\ngenerate a large fraction of invalid substitution words that are ungrammatical\nor do not preserve the original sentence's semantics. Next, we show that the\nsemantic and grammatical constraints used in SSAs for detecting invalid word\nreplacements are highly insufficient in detecting invalid adversarial samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chiang_C/0/1/0/all/0/1\">Cheng-Han Chiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Generated Text: A Comprehensive Survey of Threat Models and Detection Methods. (arXiv:2210.07321v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07321","description":"<p>Machine generated text is increasingly difficult to distinguish from human\nauthored text. Powerful open-source models are freely available, and\nuser-friendly tools that democratize access to generative models are\nproliferating. ChatGPT, which was released shortly after the first edition of\nthis survey, epitomizes these trends. The great potential of state-of-the-art\nnatural language generation (NLG) systems is tempered by the multitude of\navenues for abuse. Detection of machine generated text is a key countermeasure\nfor reducing abuse of NLG models, with significant technical challenges and\nnumerous open problems. We provide a survey that includes both 1) an extensive\nanalysis of threat models posed by contemporary NLG systems, and 2) the most\ncomplete review of machine generated text detection methods to date. This\nsurvey places machine generated text within its cybersecurity and social\ncontext, and provides strong guidance for future work addressing the most\ncritical threat models, and ensuring detection systems themselves demonstrate\ntrustworthiness through fairness, robustness, and accountability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Crothers_E/0/1/0/all/0/1\">Evan Crothers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1\">Nathalie Japkowicz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viktor_H/0/1/0/all/0/1\">Herna Viktor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multitask Pre-training of Modular Prompt for Chinese Few-Shot Learning. (arXiv:2210.07565v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07565","description":"<p>Prompt tuning is a parameter-efficient approach to adapting pre-trained\nlanguage models to downstream tasks. Although prompt tuning has been shown to\nmatch the performance of full model tuning when training data is sufficient, it\ntends to struggle in few-shot learning settings. In this paper, we present\nMulti-task Pre-trained Modular Prompt (MP2) to boost prompt tuning for few-shot\nlearning. MP2 is a set of combinable prompts pre-trained on 38 Chinese tasks.\nOn downstream tasks, the pre-trained prompts are selectively activated and\ncombined, leading to strong compositional generalization to unseen tasks. To\nbridge the gap between pre-training and fine-tuning, we formulate upstream and\ndownstream tasks into a unified machine reading comprehension task. Extensive\nexperiments under two learning paradigms, i.e., gradient descent and black-box\ntuning, show that MP2 significantly outperforms prompt tuning, full model\ntuning, and prior prompt pre-training methods in few-shot settings. In\naddition, we demonstrate that MP2 can achieve surprisingly fast and strong\nadaptation to downstream tasks by merely learning 8 parameters to combine the\npre-trained modular prompts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhengfu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Close Look into the Calibration of Pre-trained Language Models. (arXiv:2211.00151v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.00151","description":"<p>Pre-trained language models (PLMs) may fail in giving reliable estimates of\ntheir predictive uncertainty. We take a close look into this problem, aiming to\nanswer two questions: (1) Do PLMs learn to become calibrated in the training\nprocess? (2) How effective are existing calibration methods? For the first\nquestion, we conduct fine-grained control experiments to study the dynamic\nchange in PLMs' calibration performance in training. We consider six factors as\ncontrol variables, including dataset difficulty, available training samples,\ntraining steps, the number of tunable parameters, model scale, and pretraining.\nWe observe a consistent change in calibration performance across six factors.\nWe find that PLMs don't learn to become calibrated in training, evidenced by\nthe continual increase in confidence, no matter whether the predictions are\ncorrect or not. We highlight that our finding somewhat contradicts two\nestablished conclusions: (a) Larger PLMs are more calibrated; (b) Pretraining\nimproves model calibration. Next, we study the effectiveness of existing\ncalibration methods in mitigating the overconfidence issue. Besides unlearnable\ncalibration methods (e.g., label smoothing), we adapt and extend two recently\nproposed learnable methods that directly collect data to train models to have\nreasonable confidence estimations. Experimental results show that learnable\nmethods significantly reduce PLMs' confidence in wrong predictions. The code is\navailable at \\url{https://github.com/lifan-yuan/PLMCalibration}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yangyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1\">Lifan Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_G/0/1/0/all/0/1\">Ganqu Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Investigating Content-Aware Neural Text-To-Speech MOS Prediction Using Prosodic and Linguistic Features. (arXiv:2211.00342v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2211.00342","description":"<p>Current state-of-the-art methods for automatic synthetic speech evaluation\nare based on MOS prediction neural models. Such MOS prediction models include\nMOSNet and LDNet that use spectral features as input, and SSL-MOS that relies\non a pretrained self-supervised learning model that directly uses the speech\nsignal as input. In modern high-quality neural TTS systems, prosodic\nappropriateness with regard to the spoken content is a decisive factor for\nspeech naturalness. For this reason, we propose to include prosodic and\nlinguistic features as additional inputs in MOS prediction systems, and\nevaluate their impact on the prediction outcome. We consider phoneme level F0\nand duration features as prosodic inputs, as well as Tacotron encoder outputs,\nPOS tags and BERT embeddings as higher-level linguistic inputs. All MOS\nprediction systems are trained on SOMOS, a neural TTS-only dataset with\ncrowdsourced naturalness MOS evaluations. Results show that the proposed\nadditional features are beneficial in the MOS prediction task, by improving the\npredicted MOS scores' correlation with the ground truths, both at\nutterance-level and system-level predictions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vioni_A/0/1/0/all/0/1\">Alexandra Vioni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maniati_G/0/1/0/all/0/1\">Georgia Maniati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ellinas_N/0/1/0/all/0/1\">Nikolaos Ellinas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sung_J/0/1/0/all/0/1\">June Sig Sung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_I/0/1/0/all/0/1\">Inchul Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chalamandaris_A/0/1/0/all/0/1\">Aimilios Chalamandaris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsiakoulis_P/0/1/0/all/0/1\">Pirros Tsiakoulis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Robust Low-Resource Fine-Tuning with Multi-View Compressed Representations. (arXiv:2211.08794v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08794","description":"<p>Due to the huge amount of parameters, fine-tuning of pretrained language\nmodels (PLMs) is prone to overfitting in the low resource scenarios. In this\nwork, we present a novel method that operates on the hidden representations of\na PLM to reduce overfitting. During fine-tuning, our method inserts random\nautoencoders between the hidden layers of a PLM, which transform activations\nfrom the previous layers into a multi-view compressed representation before\nfeeding it into the upper layers. The autoencoders are plugged out after\nfine-tuning, so our method does not add extra parameters or increase\ncomputation cost during inference. Our method demonstrates promising\nperformance improvement across a wide range of sequence- and token-level\nlow-resource NLP tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thakkar_M/0/1/0/all/0/1\">Megh Thakkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1\">Luo Si</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pivotal Role of Language Modeling in Recommender Systems: Enriching Task-specific and Task-agnostic Representation Learning. (arXiv:2212.03760v4 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2212.03760","description":"<p>Recent studies have proposed unified user modeling frameworks that leverage\nuser behavior data from various applications. Many of them benefit from\nutilizing users' behavior sequences as plain texts, representing rich\ninformation in any domain or system without losing generality. Hence, a\nquestion arises: Can language modeling for user history corpus help improve\nrecommender systems? While its versatile usability has been widely investigated\nin many domains, its applications to recommender systems still remain\nunderexplored. We show that language modeling applied directly to task-specific\nuser histories achieves excellent results on diverse recommendation tasks.\nAlso, leveraging additional task-agnostic user histories delivers significant\nperformance benefits. We further demonstrate that our approach can provide\npromising transfer learning capabilities for a broad spectrum of real-world\nrecommender systems, even on unseen domains and services.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shin_K/0/1/0/all/0/1\">Kyuyong Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwak_H/0/1/0/all/0/1\">Hanock Kwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1\">Wonjae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1\">Jisu Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1\">Seungjae Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1\">Kyung-Min Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jung-Woo Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-Woo Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robustness of Learning from Task Instructions. (arXiv:2212.03813v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.03813","description":"<p>Traditional supervised learning mostly works on individual tasks and requires\ntraining on a large set of task-specific examples. This paradigm seriously\nhinders the development of task generalization since preparing a task-specific\nexample set is costly. To build a system that can quickly and easily generalize\nto new tasks, task instructions have been adopted as an emerging trend of\nsupervision recently. These instructions give the model the definition of the\ntask and allow the model to output the appropriate answer based on the\ninstructions and inputs. However, task instructions are often expressed in\ndifferent forms, which can be interpreted from two threads: first, some\ninstructions are short sentences and are pretrained language model (PLM)\noriented, such as prompts, while other instructions are paragraphs and are\nhuman-oriented, such as those in Amazon MTurk; second, different end-users very\nlikely explain the same task with instructions of different textual\nexpressions. A robust system for task generalization should be able to handle\nany new tasks regardless of the variability of instructions.\n</p>\n<p>However, the system robustness in dealing with instruction-driven task\ngeneralization is still unexplored. This work investigates the system\nrobustness when the instructions of new tasks are (i) manipulated, (ii)\nparaphrased, or (iii) from different levels of conciseness. To our knowledge,\nthis is the first work that systematically studies how robust a PLM is when it\nis supervised by instructions with different factors of variability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiasheng Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hongyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hanzi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Liangyu Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mei_H/0/1/0/all/0/1\">Hongyuan Mei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenpeng Yin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model. (arXiv:2212.09146v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09146","description":"<p>Augmenting pretrained language models with retrievers to select the\nsupporting documents has shown promise in effectively solving common NLP\nproblems, including language modeling and question answering, in an\ninterpretable way. In this paper, we first study the strengths and weaknesses\nof different retriever-augmented language models (REALM, $k$NN-LM, FiD coupled\nwith DPR, and ATLAS and Flan-T5 coupled with Contriever) in reasoning over the\nretrieved statements in different tasks. We show how the retrieve-then-read\nmodels' limitations in reasoning are rooted both in the retriever module as\nwell as the language model. Our experimental results demonstrate that the\nsimilarity metric used by the retrievers is generally insufficient for\nreasoning tasks. Additionally, we show that the language models in\nretriever-augmented models do not take the complicated relations between the\nstatements into account, which leads to poor reasoning performance even when\nusing the larger models. Moreover, we analyze the reasoning performance of\nlarge language models using multihop retrieval but we only observe minor\nimprovements. Overall, this shows great room for further research in this area.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+BehnamGhader_P/0/1/0/all/0/1\">Parishad BehnamGhader</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Miret_S/0/1/0/all/0/1\">Santiago Miret</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Meet NL2Code: A Survey. (arXiv:2212.09420v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2212.09420","description":"<p>The task of generating code from a natural language description, or NL2Code,\nis considered a pressing and significant challenge in code intelligence. Thanks\nto the rapid development of pre-training techniques, surging large language\nmodels are being proposed for code, sparking the advances in NL2Code. To\nfacilitate further research and applications in this field, in this paper, we\npresent a comprehensive survey of 27 existing large language models for\nNL2Code, and also review benchmarks and metrics. We provide an intuitive\ncomparison of all existing models on the HumanEval benchmark. Through in-depth\nobservation and analysis, we provide some insights and conclude that the key\nfactors contributing to the success of large language models for NL2Code are\n\"Large Size, Premium Data, Expert Tuning\". In addition, we discuss challenges\nand opportunities regarding the gap between models and humans. We also create a\nwebsite https://nl2code.github.io to track the latest progress through\ncrowd-sourcing. To the best of our knowledge, this is the first survey of large\nlanguage models for NL2Code, and we believe it will contribute to the ongoing\ndevelopment of the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zan_D/0/1/0/all/0/1\">Daoguang Zan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1\">Fengji Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1\">Dianjie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1\">Bingchao Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_B/0/1/0/all/0/1\">Bei Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongji Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1\">Jian-Guang Lou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning with Language Model Prompting: A Survey. (arXiv:2212.09597v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09597","description":"<p>Reasoning, as an essential ability for complex problem-solving, can provide\nback-end support for various real-world applications, such as medical\ndiagnosis, negotiation, etc. This paper provides a comprehensive survey of\ncutting-edge research on reasoning with language model prompting. We introduce\nresearch works with comparisons and summaries and provide systematic resources\nto help beginners. We also discuss the potential reasons for emerging such\nreasoning abilities and highlight future research directions. Resources are\navailable at https://github.com/zjunlp/Prompt4ReasoningPapers (updated\nperiodically).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ou_Y/0/1/0/all/0/1\">Yixin Ou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yunzhi Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1\">Shumin Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Event Individuation for Document-Level Information Extraction. (arXiv:2212.09702v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09702","description":"<p>As information extraction (IE) systems have grown more adept at processing\nwhole documents, the classic task of template filling has seen renewed interest\nas benchmark for document-level IE. In this position paper, we call into\nquestion the suitability of template filling for this purpose. We argue that\nthe task demands definitive answers to thorny questions of event individuation\n-- the problem of distinguishing distinct events -- about which even human\nexperts disagree. Through an annotation study and error analysis, we show that\nthis raises concerns about the usefulness of template filling metrics, the\nquality of datasets for the task, and the ability of models to learn it.\nFinally, we consider possible solutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gantt_W/0/1/0/all/0/1\">William Gantt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kriz_R/0/1/0/all/0/1\">Reno Kriz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishtha_S/0/1/0/all/0/1\">Siddharth Vashishtha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1\">Aaron Steven White</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does GPT-3 Demonstrate Psychopathy? Evaluating Large Language Models from a Psychological Perspective. (arXiv:2212.10529v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10529","description":"<p>In this work, we determined whether large language models (LLMs) are\npsychologically safe. We designed unbiased prompts to systematically evaluate\nLLMs from a psychological perspective. First, we tested three different LLMs by\nusing two personality tests: Short Dark Triad (SD-3) and Big Five Inventory\n(BFI). All models scored higher than the human average on SD-3, suggesting a\nrelatively darker personality pattern. Despite being instruction fine-tuned\nwith safety metrics to reduce toxicity, InstructGPT and FLAN-T5 still showed\nimplicit dark personality patterns; both models scored higher than\nself-supervised GPT-3 on the Machiavellianism and narcissism traits on SD-3.\nThen, we evaluated the LLMs in the GPT-3 series by using well-being tests to\nstudy the impact of fine-tuning with more training data. We observed a\ncontinuous increase in the well-being scores of GPT-3 and InstructGPT.\nFollowing these observations, we showed that instruction fine-tuning FLAN-T5\nwith positive answers from BFI could effectively improve the model from a\npsychological perspective. On the basis of the findings, we recommended the\napplication of more systematic and comprehensive psychological metrics to\nfurther evaluate and improve the safety of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yutong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1\">Shafiq Joty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Linlin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Lin Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ALCAP: Alignment-Augmented Music Captioner. (arXiv:2212.10901v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2212.10901","description":"<p>Growing popularity of streaming media platforms for music search and\nrecommendations has led to a need for novel methods for interpreting music that\ntake into account both lyrics and audio. However, many previous works focus on\nrefining individual components of encoder-decoder architecture that maps music\nto caption tokens, ignoring the potential benefits of correspondence between\naudio and lyrics. In this paper, we propose to explicitly learn the multimodal\nalignment through contrastive learning. By learning audio-lyrics\ncorrespondence, the model is guided to learn better cross-modal consistency,\nthus generating high-quality captions. We provide both theoretical and\nempirical results demonstrating the advantage of the proposed method, and\nachieve new state-of-the-art on two music captioning datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zihao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Weituo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei-Tsung Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_K/0/1/0/all/0/1\">Kristina Lerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xuchen Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Double Permutation Equivariance for Knowledge Graph Completion. (arXiv:2302.01313v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.01313","description":"<p>This work provides a formalization of Knowledge Graphs (KGs) as a new class\nof graphs that we denote doubly exchangeable attributed graphs, where node and\npairwise (joint 2-node) representations must be equivariant to permutations of\nboth node ids and edge (&amp; node) attributes (relations &amp; node features).\nDouble-permutation equivariant KG representations open a new research direction\nin KGs. We show that this equivariance imposes a structural representation of\nrelations that allows neural networks to perform complex logical reasoning\ntasks in KGs. Finally, we introduce a general blueprint for such equivariant\nrepresentations and test a simple GNN-based double-permutation equivariant\nneural architecture that achieve state-of-the-art Hits@10 test accuracy in the\nWN18RR, FB237 and NELL995 inductive KG completion tasks, and can accurately\nperform logical reasoning tasks that no existing methods can perform, to the\nbest of our knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfei Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yangze Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1\">Bruno Ribeiro</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Re-Label Method For Data-Centric Machine Learning. (arXiv:2302.04391v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2302.04391","description":"<p>In industry deep learning application, our manually labeled data has a\ncertain number of noisy data. To solve this problem and achieve more than 90\nscore in dev dataset, we present a simple method to find the noisy data and\nre-label the noisy data by human, given the model predictions as references in\nhuman labeling. In this paper, we illustrate our idea for a broad set of deep\nlearning tasks, includes classification, sequence tagging, object detection,\nsequence generation, click-through rate prediction. The experimental results\nand human evaluation results verify our idea.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1\">Tong Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Model Analysis for Ontology Subsumption Inference. (arXiv:2302.06761v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06761","description":"<p>Investigating whether pre-trained language models (LMs) can function as\nknowledge bases (KBs) has raised wide research interests recently. However,\nexisting works focus on simple, triple-based, relational KBs, but omit more\nsophisticated, logic-based, conceptualised KBs such as OWL ontologies. To\ninvestigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of\ninference-based probing tasks and datasets from ontology subsumption axioms\ninvolving both atomic and complex concepts. We conduct extensive experiments on\nontologies of different domains and scales, and our results demonstrate that\nLMs encode relatively less background knowledge of Subsumption Inference (SI)\nthan traditional Natural Language Inference (NLI) but can improve on SI\nsignificantly when a small number of samples are given. We will open-source our\ncode and datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuan He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_Ruiz_E/0/1/0/all/0/1\">Ernesto Jim&#xe9;nez-Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1\">Ian Horrocks</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SemEval-2023 Task 10: Explainable Detection of Online Sexism. (arXiv:2303.04222v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.04222","description":"<p>Online sexism is a widespread and harmful phenomenon. Automated tools can\nassist the detection of sexism at scale. Binary detection, however, disregards\nthe diversity of sexist content, and fails to provide clear explanations for\nwhy something is sexist. To address this issue, we introduce SemEval Task 10 on\nthe Explainable Detection of Online Sexism (EDOS). We make three main\ncontributions: i) a novel hierarchical taxonomy of sexist content, which\nincludes granular vectors of sexism to aid explainability; ii) a new dataset of\n20,000 social media comments with fine-grained labels, along with larger\nunlabelled datasets for model adaptation; and iii) baseline models as well as\nan analysis of the methods, results and errors for participant submissions to\nour task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1\">Hannah Rose Kirk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1\">Wenjie Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1\">Bertie Vidgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rottger_P/0/1/0/all/0/1\">Paul R&#xf6;ttger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Refined Vision-Language Modeling for Fine-grained Multi-modal Pre-training. (arXiv:2303.05313v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2303.05313","description":"<p>Fine-grained supervision based on object annotations has been widely used for\nvision and language pre-training (VLP). However, in real-world application\nscenarios, aligned multi-modal data is usually in the image-caption format,\nwhich only provides coarse-grained supervision. It is not only cost-expensive\nbut also compute-expensive to collect object annotations and build object\nannotation pre-extractor for different scenarios. In this paper, we propose a\nfine-grained VLP scheme without object annotations from the linguistic\nperspective. First, we propose a homonym sentence rewriting (HSR) algorithm to\nprovide token-level supervision. The algorithm replaces a\nverb/noun/adjective/quantifier word of the caption with its homonyms from\nWordNet. Correspondingly, we propose refined vision-language modeling (RVLM)\nframework to exploit the token-level supervision. Three refined tasks, i.e.,\nrefined image-text contrastive (RITC), refined image-text matching (RITM), and\nreplace language modeling (RLM) are proposed to learn the fine-grained\nalignment. Extensive experiments on several downstream tasks demonstrate the\nsuperior performance of the proposed method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lisai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yunpeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhonghua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhao Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Single Items: Exploring User Preferences in Item Sets with the Conversational Playlist Curation Dataset. (arXiv:2303.06791v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2303.06791","description":"<p>Users in consumption domains, like music, are often able to more efficiently\nprovide preferences over a set of items (e.g. a playlist or radio) than over\nsingle items (e.g. songs). Unfortunately, this is an underexplored area of\nresearch, with most existing recommendation systems limited to understanding\npreferences over single items. Curating an item set exponentiates the search\nspace that recommender systems must consider (all subsets of items!): this\nmotivates conversational approaches-where users explicitly state or refine\ntheir preferences and systems elicit preferences in natural language-as an\nefficient way to understand user needs. We call this task conversational item\nset curation and present a novel data collection methodology that efficiently\ncollects realistic preferences about item sets in a conversational setting by\nobserving both item-level and set-level feedback. We apply this methodology to\nmusic recommendation to build the Conversational Playlist Curation Dataset\n(CPCD), where we show that it leads raters to express preferences that would\nnot be otherwise expressed. Finally, we propose a wide range of conversational\nretrieval models as baselines for this task and evaluate them on the dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chaganty_A/0/1/0/all/0/1\">Arun Tejasvi Chaganty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leszczynski_M/0/1/0/all/0/1\">Megan Leszczynski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganti_R/0/1/0/all/0/1\">Ravi Ganti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balog_K/0/1/0/all/0/1\">Krisztian Balog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radlinski_F/0/1/0/all/0/1\">Filip Radlinski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.07865","description":"<p>This research is aimed to solve the tweet/user geolocation prediction task\nand provide a flexible methodology for the geotagging of textual big data. The\nsuggested approach implements neural networks for natural language processing\n(NLP) to estimate the location as coordinate pairs (longitude, latitude) and\ntwo-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models\nhas been finetuned on a Twitter dataset using pretrained Bidirectional Encoder\nRepresentations from Transformers (BERT) as base models. Performance metrics\nshow a median error of fewer than 30 km on a worldwide-level, and fewer than 15\nkm on the US-level datasets for the models trained and evaluated on text\nfeatures of tweets' content and metadata context. Our source code and data are\navailable at https://github.com/K4TEL/geo-twitter.git\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lutsai_K/0/1/0/all/0/1\">Kateryna Lutsai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1\">Christoph H. Lampert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models. (arXiv:2303.08896v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.08896","description":"<p>Generative Large Language Models (LLMs) such as GPT-3 are capable of\ngenerating highly fluent responses to a wide variety of user prompts. However,\nLLMs are known to hallucinate facts and make non-factual statements which can\nundermine trust in their output. Existing fact-checking approaches either\nrequire access to the output probability distribution (which may not be\navailable for systems such as ChatGPT) or external databases that are\ninterfaced via separate, often complex, modules. In this work, we propose\n\"SelfCheckGPT\", a simple sampling-based approach that can be used to fact-check\nblack-box models in a zero-resource fashion, i.e. without an external database.\nSelfCheckGPT leverages the simple idea that if a LLM has knowledge of a given\nconcept, sampled responses are likely to be similar and contain consistent\nfacts. However, for hallucinated facts, stochastically sampled responses are\nlikely to diverge and contradict one another. We investigate this approach by\nusing GPT-3 to generate passages about individuals from the WikiBio dataset,\nand manually annotate the factuality of the generated passages. We demonstrate\nthat SelfCheckGPT can: i) detect non-factual and factual sentences; and ii)\nrank passages in terms of factuality. We compare our approach to several\nbaselines and show that in sentence hallucination detection, our approach has\nAUC-PR scores comparable to or better than grey-box methods, while SelfCheckGPT\nis best at passage factuality assessment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1\">Potsawee Manakul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J. F. Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SmartBERT: A Promotion of Dynamic Early Exiting Mechanism for Accelerating BERT Inference. (arXiv:2303.09266v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09266","description":"<p>Dynamic early exiting has been proven to improve the inference speed of the\npre-trained language model like BERT. However, all samples must go through all\nconsecutive layers before early exiting and more complex samples usually go\nthrough more layers, which still exists redundant computation. In this paper,\nwe propose a novel dynamic early exiting combined with layer skipping for BERT\ninference named SmartBERT, which adds a skipping gate and an exiting operator\ninto each layer of BERT. SmartBERT can adaptively skip some layers and\nadaptively choose whether to exit. Besides, we propose cross-layer contrastive\nlearning and combine it into our training phases to boost the intermediate\nlayers and classifiers which would be beneficial for early exiting. To keep the\nconsistent usage of skipping gates between training and inference phases, we\npropose a hard weight mechanism during training phase. We conduct experiments\non eight classification datasets of the GLUE benchmark. Experimental results\nshow that SmartBERT achieves 2-3x computation reduction with minimal accuracy\ndrops compared with BERT and our method outperforms previous methods in both\nefficiency and accuracy. Moreover, in some complex datasets like RTE and WNLI,\nwe prove that the early exiting based on entropy hardly works, and the skipping\nmechanism is essential for reducing computation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Boren Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiacheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trained on 100 million words and still in shape: BERT meets British National Corpus. (arXiv:2303.09859v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.09859","description":"<p>While modern masked language models (LMs) are trained on ever larger corpora,\nwe here explore the effects of down-scaling training to a modestly-sized but\nrepresentative, well-balanced, and publicly available English text source --\nthe British National Corpus. We show that pre-training on this carefully\ncurated corpus can reach better performance than the original BERT model. We\nargue that this type of corpora has great potential as a language modeling\nbenchmark. To showcase this potential, we present fair, reproducible and\ndata-efficient comparative studies of LMs, in which we evaluate several\ntraining objectives and model architectures and replicate previous empirical\nresults in a systematic way. We propose an optimized LM architecture called\nLTG-BERT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Samuel_D/0/1/0/all/0/1\">David Samuel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kutuzov_A/0/1/0/all/0/1\">Andrey Kutuzov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ovrelid_L/0/1/0/all/0/1\">Lilja &#xd8;vrelid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Velldal_E/0/1/0/all/0/1\">Erik Velldal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep RL with Hierarchical Action Exploration for Dialogue Generation. (arXiv:2303.13465v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13465","description":"<p>Traditionally, approximate dynamic programming is employed in dialogue\ngeneration with greedy policy improvement through action sampling, as the\nnatural language action space is vast. However, this practice is inefficient\nfor reinforcement learning (RL) due to the sparsity of eligible responses with\nhigh action values, which leads to weak improvement sustained by random\nsampling. This paper presents theoretical analysis and experiments showing that\nthe dialogue policy's performance is positively correlated with the sampling\nsize. To alleviate this limitation, we introduce a novel dual-granularity\nQ-function that explores the most promising response category to intervene in\nthe sampling process. Our approach extracts actions based on a grained\nhierarchy, achieving the optimum with fewer policy iterations. Additionally, we\nuse offline RL and learn from multiple reward functions designed to capture\nemotional nuances in human interactions. Empirical studies demonstrate that our\nalgorithm outperforms baselines across automatic metrics and human evaluations.\nFurther testing reveals that ours generates responses with higher expected\nrewards and controllability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_I/0/1/0/all/0/1\">Itsugun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Takahashi_R/0/1/0/all/0/1\">Ryota Takahashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yanase_Y/0/1/0/all/0/1\">Yusaku Yanase</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saito_H/0/1/0/all/0/1\">Hiroaki Saito</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bias or Diversity? Unraveling Fine-Grained Thematic Discrepancy in U.S. News Headlines. (arXiv:2303.15708v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.15708","description":"<p>There is a broad consensus that news media outlets incorporate ideological\nbiases in their news articles. However, prior studies on measuring the\ndiscrepancies among media outlets and further dissecting the origins of\nthematic differences suffer from small sample sizes and limited scope and\ngranularity. In this study, we use a large dataset of 1.8 million news\nheadlines from major U.S. media outlets spanning from 2014 to 2022 to\nthoroughly track and dissect the fine-grained thematic discrepancy in U.S. news\nmedia. We employ multiple correspondence analysis (MCA) to quantify the\nfine-grained thematic discrepancy related to four prominent topics - domestic\npolitics, economic issues, social issues, and foreign affairs in order to\nderive a more holistic analysis. Additionally, we compare the most frequent\n$n$-grams in media headlines to provide further qualitative insights into our\nanalysis. Our findings indicate that on domestic politics and social issues,\nthe discrepancy can be attributed to a certain degree of media bias. Meanwhile,\nthe discrepancy in reporting foreign affairs is largely attributed to the\ndiversity in individual journalistic styles. Finally, U.S. media outlets show\nconsistency and high similarity in their coverage of economic issues.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jinsheng Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_W/0/1/0/all/0/1\">Weihong Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1\">Hanjia Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiebo Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Large Language Models. (arXiv:2303.18223v10 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.18223","description":"<p>Language is essentially a complex, intricate system of human expressions\ngoverned by grammatical rules. It poses a significant challenge to develop\ncapable AI algorithms for comprehending and grasping a language. As a major\napproach, language modeling has been widely studied for language understanding\nand generation in the past two decades, evolving from statistical language\nmodels to neural language models. Recently, pre-trained language models (PLMs)\nhave been proposed by pre-training Transformer models over large-scale corpora,\nshowing strong capabilities in solving various NLP tasks. Since researchers\nhave found that model scaling can lead to performance improvement, they further\nstudy the scaling effect by increasing the model size to an even larger size.\nInterestingly, when the parameter scale exceeds a certain level, these enlarged\nlanguage models not only achieve a significant performance improvement but also\nshow some special abilities that are not present in small-scale language\nmodels. To discriminate the difference in parameter scale, the research\ncommunity has coined the term large language models (LLM) for the PLMs of\nsignificant size. Recently, the research on LLMs has been largely advanced by\nboth academia and industry, and a remarkable progress is the launch of ChatGPT,\nwhich has attracted widespread attention from society. The technical evolution\nof LLMs has been making an important impact on the entire AI community, which\nwould revolutionize the way how we develop and use AI algorithms. In this\nsurvey, we review the recent advances of LLMs by introducing the background,\nkey findings, and mainstream techniques. In particular, we focus on four major\naspects of LLMs, namely pre-training, adaptation tuning, utilization, and\ncapacity evaluation. Besides, we also summarize the available resources for\ndeveloping LLMs and discuss the remaining issues for future directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yupeng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1\">Yingqian Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Beichen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zican Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yifan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yushuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jinhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xinyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zikang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam Detection. (arXiv:2304.01238v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01238","description":"<p>This paper investigates the effectiveness of large language models (LLMs) in\nemail spam detection by comparing prominent models from three distinct\nfamilies: BERT-like, Sentence Transformers, and Seq2Seq. Additionally, we\nexamine well-established machine learning techniques for spam detection, such\nas Na\\\"ive Bayes and LightGBM, as baseline methods. We assess the performance\nof these models across four public datasets, utilizing different numbers of\ntraining samples (full training set and few-shot settings). Our findings reveal\nthat, in the majority of cases, LLMs surpass the performance of the popular\nbaseline techniques, particularly in few-shot scenarios. This adaptability\nrenders LLMs uniquely suited to spam detection tasks, where labeled samples are\nlimited in number and models require frequent updates. Additionally, we\nintroduce Spam-T5, a Flan-T5 model that has been specifically adapted and\nfine-tuned for the purpose of detecting email spam. Our results demonstrate\nthat Spam-T5 surpasses baseline models and other LLMs in the majority of\nscenarios, particularly when there are a limited number of training samples\navailable. Our code is publicly available at\nhttps://github.com/jpmorganchase/emailspamdetection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Labonne_M/0/1/0/all/0/1\">Maxime Labonne</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1\">Sean Moran</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models. (arXiv:2304.01933v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.01933","description":"<p>The success of large language models (LLMs), like GPT-3 and ChatGPT, has led\nto the development of numerous cost-effective and accessible alternatives that\nare created by fine-tuning open-access LLMs with task-specific data (e.g.,\nChatDoctor) or instruction data (e.g., Alpaca). Among the various fine-tuning\nmethods, adapter-based parameter-efficient fine-tuning (PEFT) is undoubtedly\none of the most attractive topics, as it only requires fine-tuning a few\nexternal parameters instead of the entire LLMs while achieving comparable or\neven better performance. To enable further research on PEFT methods of LLMs,\nthis paper presents LLM-Adapters, an easy-to-use framework that integrates\nvarious adapters into LLMs and can execute these adapter-based PEFT methods of\nLLMs for different tasks. The framework includes state-of-the-art open-access\nLLMs such as LLaMA, BLOOM, OPT, and GPT-J, as well as widely used adapters such\nas Series adapter, Parallel adapter, and LoRA. The framework is designed to be\nresearch-friendly, efficient, modular, and extendable, allowing the integration\nof new adapters and the evaluation of them with new and larger-scale LLMs.\nFurthermore, to evaluate the effectiveness of adapters in LLMs-Adapters, we\nconduct experiments on six math reasoning datasets. The results demonstrate\nthat using adapter-based PEFT in smaller-scale LLMs (7B) with few extra\ntrainable parameters yields comparable, and in some cases superior, performance\nto that of powerful LLMs (175B) in zero-shot inference on simple math reasoning\ndatasets. Overall, we provide a promising framework for fine-tuning large LLMs\non downstream tasks. We believe the proposed LLMs-Adapters will advance\nadapter-based PEFT research, facilitate the deployment of research pipelines,\nand enable practical applications to real-world systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiqiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yihuai Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wanyu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1\">Ee-Peng Lim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1\">Roy Ka-Wei Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1\">Xing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1\">Soujanya Poria</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Examining Temporalities on Stance Detection towards COVID-19 Vaccination. (arXiv:2304.04806v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.04806","description":"<p>Previous studies have highlighted the importance of vaccination as an\neffective strategy to control the transmission of the COVID-19 virus. It is\ncrucial for policymakers to have a comprehensive understanding of the public's\nstance towards vaccination on a large scale. However, attitudes towards\nCOVID-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved\nover time on social media. Thus, it is necessary to account for possible\ntemporal shifts when analysing these stances. This study aims to examine the\nimpact of temporal concept drift on stance detection towards COVID-19\nvaccination on Twitter. To this end, we evaluate a range of transformer-based\nmodels using chronological (split the training, validation and testing sets in\nthe order of time) and random splits (randomly split these three sets) of\nsocial media data. Our findings demonstrate significant discrepancies in model\nperformance when comparing random and chronological splits across all\nmonolingual and multilingual datasets. Chronological splits significantly\nreduce the accuracy of stance classification. Therefore, real-world stance\ndetection approaches need to be further refined to incorporate temporal factors\nas a key consideration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yida Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mali Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Large-Scale Comparative Study of Accurate COVID-19 Information versus Misinformation. (arXiv:2304.04811v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.04811","description":"<p>The COVID-19 pandemic led to an infodemic where an overwhelming amount of\nCOVID-19 related content was being disseminated at high velocity through social\nmedia. This made it challenging for citizens to differentiate between accurate\nand inaccurate information about COVID-19. This motivated us to carry out a\ncomparative study of the characteristics of COVID-19 misinformation versus\nthose of accurate COVID-19 information through a large-scale computational\nanalysis of over 242 million tweets. The study makes comparisons alongside four\nkey aspects: 1) the distribution of topics, 2) the live status of tweets, 3)\nlanguage analysis and 4) the spreading power over time. An added contribution\nof this study is the creation of a COVID-19 misinformation classification\ndataset. Finally, we demonstrate that this new dataset helps improve\nmisinformation classification by more than 9\\% based on average F1 measure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yida Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Ye Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heppell_F/0/1/0/all/0/1\">Freddy Heppell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_I/0/1/0/all/0/1\">Iknoor Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Romanian Multiword Expression Detection Using Multilingual Adversarial Training and Lateral Inhibition. (arXiv:2304.11350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11350","description":"<p>Multiword expressions are a key ingredient for developing large-scale and\nlinguistically sound natural language processing technology. This paper\ndescribes our improvements in automatically identifying Romanian multiword\nexpressions on the corpus released for the PARSEME v1.2 shared task. Our\napproach assumes a multilingual perspective based on the recently introduced\nlateral inhibition layer and adversarial training to boost the performance of\nthe employed multilingual language models. With the help of these two methods,\nwe improve the F1-score of XLM-RoBERTa by approximately 2.7% on unseen\nmultiword expressions, the main task of the PARSEME 1.2 edition. In addition,\nour results can be considered SOTA performance, as they outperform the previous\nresults on Romanian obtained by the participants in this competition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Avram_A/0/1/0/all/0/1\">Andrei-Marius Avram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mititelu_V/0/1/0/all/0/1\">Verginica Barbu Mititelu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cercel_D/0/1/0/all/0/1\">Dumitru-Clementin Cercel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GlyphDiffusion: Text Generation as Image Generation. (arXiv:2304.12519v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.12519","description":"<p>Diffusion models have become a new generative paradigm for text generation.\nConsidering the discrete categorical nature of text, in this paper, we propose\nGlyphDiffusion, a novel diffusion approach for text generation via text-guided\nimage generation. Our key idea is to render the target text as a glyph image\ncontaining visual language content. In this way, conditional text generation\ncan be cast as a glyph image generation task, and it is then natural to apply\ncontinuous diffusion models to discrete texts. Specially, we utilize a cascaded\narchitecture (ie a base and a super-resolution diffusion model) to generate\nhigh-fidelity glyph images, conditioned on the input text. Furthermore, we\ndesign a text grounding module to transform and refine the visual language\ncontent from generated glyph images into the final texts. In experiments over\nfour conditional text generation tasks and two classes of metrics (ie quality\nand diversity), GlyphDiffusion can achieve comparable or even better results\nthan several baselines, including pretrained language models. Our model also\nmakes significant improvements compared to the recent diffusion model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Association to Generation: Text-only Captioning by Unsupervised Cross-modal Mapping. (arXiv:2304.13273v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.13273","description":"<p>With the development of Vision-Language Pre-training Models (VLPMs)\nrepresented by CLIP and ALIGN, significant breakthroughs have been achieved for\nassociation-based visual tasks such as image classification and image-text\nretrieval by the zero-shot capability of CLIP without fine-tuning. However,\nCLIP is hard to apply to generation-based tasks. This is due to the lack of\ndecoder architecture and pre-training tasks for generation. Although previous\nworks have created generation capacity for CLIP through additional language\nmodels, a modality gap between the CLIP representations of different modalities\nand the inability of CLIP to model the offset of this gap, which fails the\nconcept to transfer across modalities. To solve the problem, we try to map\nimages/videos to the language modality and generate captions from the language\nmodality. In this paper, we propose the K-nearest-neighbor Cross-modality\nMapping (Knight), a zero-shot method from association to generation. With\ntext-only unsupervised training, Knight achieves State-of-the-Art performance\nin zero-shot methods for image captioning and video captioning. Our code is\navailable at https://github.com/junyangwang0410/Knight.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Junyang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Ming Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1\">Jitao Sang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Energy-based Models are Zero-Shot Planners for Compositional Scene Rearrangement. (arXiv:2304.14391v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2304.14391","description":"<p>Language is compositional; an instruction can express multiple relation\nconstraints to hold among objects in a scene that a robot is tasked to\nrearrange. Our focus in this work is an instructable scene-rearranging\nframework that generalizes to longer instructions and to spatial concept\ncompositions never seen at training time. We propose to represent\nlanguage-instructed spatial concepts with energy functions over relative object\narrangements. A language parser maps instructions to corresponding energy\nfunctions and an open-vocabulary visual-language model grounds their arguments\nto relevant objects in the scene. We generate goal scene configurations by\ngradient descent on the sum of energy functions, one per language predicate in\nthe instruction. Local vision-based policies then re-locate objects to the\ninferred goal locations. We test our model on established instruction-guided\nmanipulation benchmarks, as well as benchmarks of compositional instructions we\nintroduce. We show our model can execute highly compositional instructions\nzero-shot in simulation and in the real world. It outperforms\nlanguage-to-action reactive policies and Large Language Model planners by a\nlarge margin, especially for long instructions that involve compositions of\nmultiple spatial concepts. Simulation and real-world robot execution videos, as\nwell as our code and datasets are publicly available on our website:\nhttps://ebmplanner.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gkanatsios_N/0/1/0/all/0/1\">Nikolaos Gkanatsios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Ayush Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xian_Z/0/1/0/all/0/1\">Zhou Xian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunchu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Atkeson_C/0/1/0/all/0/1\">Christopher Atkeson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fragkiadaki_K/0/1/0/all/0/1\">Katerina Fragkiadaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal Reasoning and Large Language Models: Opening a New Frontier for Causality. (arXiv:2305.00050v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2305.00050","description":"<p>The causal capabilities of large language models (LLMs) is a matter of\nsignificant debate, with critical implications for the use of LLMs in\nsocietally impactful domains such as medicine, science, law, and policy. We\nfurther our understanding of LLMs and their causal implications, considering\nthe distinctions between different types of causal reasoning tasks, as well as\nthe entangled threats of construct and measurement validity. LLM-based methods\nestablish new state-of-the-art accuracies on multiple causal benchmarks.\nAlgorithms based on GPT-3.5 and 4 outperform existing algorithms on a pairwise\ncausal discovery task (97%, 13 points gain), counterfactual reasoning task\n(92%, 20 points gain), and actual causality (86% accuracy in determining\nnecessary and sufficient causes in vignettes). At the same time, LLMs exhibit\nunpredictable failure modes and we provide some techniques to interpret their\nrobustness.\n</p>\n<p>Crucially, LLMs perform these causal tasks while relying on sources of\nknowledge and methods distinct from and complementary to non-LLM based\napproaches. Specifically, LLMs bring capabilities so far understood to be\nrestricted to humans, such as using collected knowledge to generate causal\ngraphs or identifying background causal context from natural language. We\nenvision LLMs to be used alongside existing causal methods, as a proxy for\nhuman domain knowledge and to reduce human effort in setting up a causal\nanalysis, one of the biggest impediments to the widespread adoption of causal\nmethods. We also see existing causal methods as promising tools for LLMs to\nformalize, validate, and communicate their reasoning especially in high-stakes\nscenarios.\n</p>\n<p>In capturing common sense and domain knowledge about causal mechanisms and\nsupporting translation between natural language and formal methods, LLMs open\nnew frontiers for advancing the research, practice, and adoption of causality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kiciman_E/0/1/0/all/0/1\">Emre K&#x131;c&#x131;man</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ness_R/0/1/0/all/0/1\">Robert Ness</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Amit Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chenhao Tan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Still no evidence for an effect of the proportion of non-native speakers on language complexity -- A response to Kauhanen, Einhaus & Walkden (2023). (arXiv:2305.00217v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.00217","description":"<p>In a recent paper published in the Journal of Language Evolution, Kauhanen,\nEinhaus &amp; Walkden (https://doi.org/10.1093/jole/lzad005, KEW) challenge the\nresults presented in one of my papers (Koplenig, Royal Society Open Science, 6,\n181274 (2019), https://doi.org/10.1098/rsos.181274), in which I tried to show\nthrough a series of statistical analyses that large numbers of L2 (second\nlanguage) speakers do not seem to affect the (grammatical or statistical)\ncomplexity of a language. To this end, I focus on the way in which the\nEthnologue assesses language status: a language is characterised as vehicular\nif, in addition to being used by L1 (first language) speakers, it should also\nhave a significant number of L2 users. KEW criticise both the use of\nvehicularity as a (binary) indicator of whether a language has a significant\nnumber of L2 users and the idea of imputing a zero proportion of L2 speakers to\nnon-vehicular languages whenever a direct estimate of that proportion is\nunavailable. While I recognise the importance of post-publication commentary on\npublished research, I show in this rejoinder that both points of criticism are\nexplicitly mentioned and analysed in my paper. In addition, I also comment on\nother points raised by KEW and demonstrate that both alternative analyses\noffered by KEW do not stand up to closer scrutiny.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koplenig_A/0/1/0/all/0/1\">Alexander Koplenig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01219","description":"<p>The prompt-based learning paradigm, which bridges the gap between\npre-training and fine-tuning, achieves state-of-the-art performance on several\nNLP tasks, particularly in few-shot settings. Despite being widely applied,\nprompt-based learning is vulnerable to backdoor attacks. Textual backdoor\nattacks are designed to introduce targeted vulnerabilities into models by\npoisoning a subset of training samples through trigger injection and label\nmodification. However, they suffer from flaws such as abnormal natural language\nexpressions resulting from the trigger and incorrect labeling of poisoned\nsamples. In this study, we propose ProAttack, a novel and efficient method for\nperforming clean-label backdoor attacks based on the prompt, which uses the\nprompt itself as a trigger. Our method does not require external triggers and\nensures correct labeling of poisoned samples, improving the stealthy nature of\nthe backdoor attack. With extensive experiments on rich-resource and few-shot\ntext classification tasks, we empirically validate ProAttack's competitive\nperformance in textual backdoor attacks. Notably, in the rich-resource setting,\nProAttack achieves state-of-the-art attack success rates in the clean-label\nbackdoor attack benchmark without external triggers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jinming Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on the Integration of Pipeline and E2E SLU systems for Spoken Semantic Parsing toward STOP Quality Challenge. (arXiv:2305.01620v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01620","description":"<p>Recently there have been efforts to introduce new benchmark tasks for spoken\nlanguage understanding (SLU), like semantic parsing. In this paper, we describe\nour proposed spoken semantic parsing system for the quality track (Track 1) in\nSpoken Language Understanding Grand Challenge which is part of ICASSP Signal\nProcessing Grand Challenge 2023. We experiment with both end-to-end and\npipeline systems for this task. Strong automatic speech recognition (ASR)\nmodels like Whisper and pretrained Language models (LM) like BART are utilized\ninside our SLU framework to boost performance. We also investigate the output\nlevel combination of various models to get an exact match accuracy of 80.8,\nwhich won the 1st place at the challenge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Siddhant Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Futami_H/0/1/0/all/0/1\">Hayato Futami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shih-Lun Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huynh_J/0/1/0/all/0/1\">Jessica Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kashiwagi_Y/0/1/0/all/0/1\">Yosuke Kashiwagi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsunoo_E/0/1/0/all/0/1\">Emiru Tsunoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Brian Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causality-aware Concept Extraction based on Knowledge-guided Prompting. (arXiv:2305.01876v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01876","description":"<p>Concepts benefit natural language understanding but are far from complete in\nexisting knowledge graphs (KGs). Recently, pre-trained language models (PLMs)\nhave been widely used in text-based concept extraction (CE). However, PLMs tend\nto mine the co-occurrence associations from massive corpus as pre-trained\nknowledge rather than the real causal effect between tokens. As a result, the\npre-trained knowledge confounds PLMs to extract biased concepts based on\nspurious co-occurrence correlations, inevitably resulting in low precision. In\nthis paper, through the lens of a Structural Causal Model (SCM), we propose\nequipping the PLM-based extractor with a knowledge-guided prompt as an\nintervention to alleviate concept bias. The prompt adopts the topic of the\ngiven entity from the existing knowledge in KGs to mitigate the spurious\nco-occurrence correlations between entities and biased concepts. Our extensive\nexperiments on representative multilingual KG datasets justify that our\nproposed prompt can effectively alleviate concept bias and improve the\nperformance of PLM-based CE models.The code has been released on\nhttps://github.com/siyuyuan/KPCE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1\">Siyu Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Deqing Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jinxi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_S/0/1/0/all/0/1\">Shuyu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jiaqing Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1\">Yanghua Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Rui Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using Language Models on Low-end Hardware. (arXiv:2305.02350v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02350","description":"<p>This paper evaluates the viability of using fixed language models for\ntraining text classification networks on low-end hardware. We combine language\nmodels with a CNN architecture and put together a comprehensive benchmark with\n8 datasets covering single-label and multi-label classification of topic,\nsentiment, and genre. Our observations are distilled into a list of trade-offs,\nconcluding that there are scenarios, where not fine-tuning a language model\nyields competitive effectiveness at faster training, requiring only a quarter\nof the memory compared to fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ziegner_F/0/1/0/all/0/1\">Fabian Ziegner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borst_J/0/1/0/all/0/1\">Janos Borst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niekler_A/0/1/0/all/0/1\">Andreas Niekler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1\">Martin Potthast</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents. (arXiv:2305.02412v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02412","description":"<p>Pre-trained large language models (LLMs) capture procedural knowledge about\nthe world. Recent work has leveraged LLM's ability to generate abstract plans\nto simplify challenging control tasks, either by action scoring, or action\nmodeling (fine-tuning). However, the transformer architecture inherits several\nconstraints that make it difficult for the LLM to directly serve as the agent:\ne.g. limited input lengths, fine-tuning inefficiency, bias from pre-training,\nand incompatibility with non-text environments. To maintain compatibility with\na low-level trainable actor, we propose to instead use the knowledge in LLMs to\nsimplify the control problem, rather than solving it. We propose the Plan,\nEliminate, and Track (PET) framework. The Plan module translates a task\ndescription into a list of high-level sub-tasks. The Eliminate module masks out\nirrelevant objects and receptacles from the observation for the current\nsub-task. Finally, the Track module determines whether the agent has\naccomplished each sub-task. On the AlfWorld instruction following benchmark,\nthe PET framework leads to a significant 15% improvement over SOTA for\ngeneralization to human goal specifications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yue Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">So Yeon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1\">Yonatan Bisk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1\">Ruslan Salakhutdinov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azaria_A/0/1/0/all/0/1\">Amos Azaria</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuanzhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_T/0/1/0/all/0/1\">Tom Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prabhumoye_S/0/1/0/all/0/1\">Shrimai Prabhumoye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Neighboring Words Affect Human Interpretation of Saliency Explanations. (arXiv:2305.02679v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02679","description":"<p>Word-level saliency explanations (\"heat maps over words\") are often used to\ncommunicate feature-attribution in text-based models. Recent studies found that\nsuperficial factors such as word length can distort human interpretation of the\ncommunicated saliency scores. We conduct a user study to investigate how the\nmarking of a word's neighboring words affect the explainee's perception of the\nword's importance in the context of a saliency explanation. We find that\nneighboring words have significant effects on the word's importance rating.\nConcretely, we identify that the influence changes based on neighboring\ndirection (left vs. right) and a-priori linguistic and computational measures\nof phrases and collocations (vs. unrelated neighboring words). Our results\nquestion whether text-based saliency explanations should be continued to be\ncommunicated at word level, and inform future research on alternative saliency\nexplanation methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacovi_A/0/1/0/all/0/1\">Alon Jacovi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuff_H/0/1/0/all/0/1\">Hendrik Schuff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adel_H/0/1/0/all/0/1\">Heike Adel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1\">Ngoc Thang Vu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Big Data and Large Numbers. Interpreting Zipf's Law. (arXiv:2305.02687v2 [physics.soc-ph] UPDATED)","link":"http://arxiv.org/abs/2305.02687","description":"<p>It turns out that some empirical facts in Big Data are the effects of\nproperties of large numbers. Zipf's law 'noise' is an example of such an\nartefact. We expose several properties of the power law distributions and of\nsimilar distribution that occur when the population is finite and the rank and\ncounts of elements in the population are natural numbers. We are particularly\nconcerned with the low-rank end of the graph of the law, the potential of noise\nin the law, and with the approximation of the number of types of objects at\nvarious ranks. Approximations instead of exact solutions are the center of\nattention. Consequences in the interpretation of Zipf's law are discussed.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Teodorescu_H/0/1/0/all/0/1\">Horia-Nicolai L. Teodorescu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"White-Box Multi-Objective Adversarial Attack on Dialogue Generation. (arXiv:2305.03655v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03655","description":"<p>Pre-trained transformers are popular in state-of-the-art dialogue generation\n(DG) systems. Such language models are, however, vulnerable to various\nadversarial samples as studied in traditional tasks such as text\nclassification, which inspires our curiosity about their robustness in DG\nsystems. One main challenge of attacking DG models is that perturbations on the\ncurrent sentence can hardly degrade the response accuracy because the unchanged\nchat histories are also considered for decision-making. Instead of merely\npursuing pitfalls of performance metrics such as BLEU, ROUGE, we observe that\ncrafting adversarial samples to force longer generation outputs benefits attack\neffectiveness -- the generated responses are typically irrelevant, lengthy, and\nrepetitive. To this end, we propose a white-box multi-objective attack method\ncalled DGSlow. Specifically, DGSlow balances two objectives -- generation\naccuracy and length, via a gradient-based multi-objective optimizer and applies\nan adaptive searching mechanism to iteratively craft adversarial samples with\nonly a few modifications. Comprehensive experiments on four benchmark datasets\ndemonstrate that DGSlow could significantly degrade state-of-the-art DG models\nwith a higher success rate than traditional accuracy-based methods. Besides,\nour crafted sentences also exhibit strong transferability in attacking other\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yufei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zexin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1\">Yingfan Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-05-08T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}