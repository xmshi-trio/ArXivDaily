{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-04-12T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Expectations over Unspoken Alternatives Predict Pragmatic Inferences. (arXiv:2304.04758v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04758","description":"<p>Scalar inferences (SI) are a signature example of how humans interpret\nlanguage based on unspoken alternatives. While empirical studies have\ndemonstrated that human SI rates are highly variable -- both within instances\nof a single scale, and across different scales -- there have been few proposals\nthat quantitatively explain both cross- and within-scale variation.\nFurthermore, while it is generally assumed that SIs arise through reasoning\nabout unspoken alternatives, it remains debated whether humans reason about\nalternatives as linguistic forms, or at the level of concepts. Here, we test a\nshared mechanism explaining SI rates within and across scales: context-driven\nexpectations about the unspoken alternatives. Using neural language models to\napproximate human predictive distributions, we find that SI rates are captured\nby the expectedness of the strong scalemate as an alternative. Crucially,\nhowever, expectedness robustly predicts cross-scale variation only under a\nmeaning-based view of alternatives. Our results suggest that pragmatic\ninferences arise from context-driven expectations over alternatives, and these\nexpectations operate at the level of concepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jennifer Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1\">Roger Levy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Degen_J/0/1/0/all/0/1\">Judith Degen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuster_S/0/1/0/all/0/1\">Sebastian Schuster</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Examining Temporalities on Stance Detection Towards COVID-19 Vaccination. (arXiv:2304.04806v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04806","description":"<p>Previous studies have highlighted the importance of vaccination as an\neffective strategy to control the transmission of the COVID-19 virus. It is\ncrucial for policymakers to have a comprehensive understanding of the public's\nstance towards vaccination on a large scale. However, attitudes towards\nCOVID-19 vaccination, such as pro-vaccine or vaccine hesitancy, have evolved\nover time on social media. Thus, it is necessary to account for possible\ntemporal shifts when analysing these stances. This study aims to examine the\nimpact of temporal concept drift on stance detection towards COVID-19\nvaccination on Twitter. To this end, we evaluate a range of transformer-based\nmodels using chronological and random splits of social media data. Our findings\ndemonstrate significant discrepancies in model performance when comparing\nrandom and chronological splits across all monolingual and multilingual\ndatasets. Chronological splits significantly reduce the accuracy of stance\nclassification. Therefore, real-world stance detection approaches need to be\nfurther refined to incorporate temporal factors as a key consideration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yida Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mali Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Large-Scale Comparative Study of Accurate COVID-19 Information versus Misinformation. (arXiv:2304.04811v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04811","description":"<p>The COVID-19 pandemic led to an infodemic where an overwhelming amount of\nCOVID-19 related content was being disseminated at high velocity through social\nmedia. This made it challenging for citizens to differentiate between accurate\nand inaccurate information about COVID-19. This motivated us to carry out a\ncomparative study of the characteristics of COVID-19 misinformation versus\nthose of accurate COVID-19 information through a large-scale computational\nanalysis of over 242 million tweets. The study makes comparisons alongside four\nkey aspects: 1) the distribution of topics, 2) the live status of tweets, 3)\nlanguage analysis and 4) the spreading power over time. An added contribution\nof this study is the creation of a COVID-19 misinformation classification\ndataset. Finally, we demonstrate that this new dataset helps improve\nmisinformation classification by more than 9% based on average F1 measure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yida Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Ye Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heppell_F/0/1/0/all/0/1\">Freddy Heppell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_I/0/1/0/all/0/1\">Iknoor Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Knowledge Selection for Knowledge-Grounded Dialogues. (arXiv:2304.04836v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04836","description":"<p>Knowledge selection is the key in knowledge-grounded dialogues (KGD), which\naims to select an appropriate knowledge snippet to be used in the utterance\nbased on dialogue history. Previous studies mainly employ the classification\napproach to classify each candidate snippet as \"relevant\" or \"irrelevant\"\nindependently. However, such approaches neglect the interactions between\nsnippets, leading to difficulties in inferring the meaning of snippets.\nMoreover, they lack modeling of the discourse structure of dialogue-knowledge\ninteractions. We propose a simple yet effective generative approach for\nknowledge selection, called GenKS. GenKS learns to select snippets by\ngenerating their identifiers with a sequence-to-sequence model. GenKS therefore\ncaptures intra-knowledge interaction inherently through attention mechanisms.\nMeanwhile, we devise a hyperlink mechanism to model the dialogue-knowledge\ninteractions explicitly. We conduct experiments on three benchmark datasets,\nand verify GenKS achieves the best results on both knowledge selection and\nresponse generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weiwei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1\">Pengjie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1\">Zhaochun Ren</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DISTO: Evaluating Textual Distractors for Multi-Choice Questions using Negative Sampling based Approach. (arXiv:2304.04881v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04881","description":"<p>Multiple choice questions (MCQs) are an efficient and common way to assess\nreading comprehension (RC). Every MCQ needs a set of distractor answers that\nare incorrect, but plausible enough to test student knowledge. Distractor\ngeneration (DG) models have been proposed, and their performance is typically\nevaluated using machine translation (MT) metrics. However, MT metrics often\nmisjudge the suitability of generated distractors. We propose DISTO: the first\nlearned evaluation metric for generated distractors. We validate DISTO by\nshowing its scores correlate highly with human ratings of distractor quality.\nAt the same time, DISTO ranks the performance of state-of-the-art DG models\nvery differently from MT-based metrics, showing that MT metrics should not be\nused for distractor evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1\">Bilal Ghanem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fyshe_A/0/1/0/all/0/1\">Alona Fyshe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Vision-and-Language Navigation by Generating Future-View Image Semantics. (arXiv:2304.04907v1 [cs.CV])","link":"http://arxiv.org/abs/2304.04907","description":"<p>Vision-and-Language Navigation (VLN) is the task that requires an agent to\nnavigate through the environment based on natural language instructions. At\neach step, the agent takes the next action by selecting from a set of navigable\nlocations. In this paper, we aim to take one step further and explore whether\nthe agent can benefit from generating the potential future view during\nnavigation. Intuitively, humans will have an expectation of how the future\nenvironment will look like, based on the natural language instructions and\nsurrounding views, which will aid correct navigation. Hence, to equip the agent\nwith this ability to generate the semantics of future navigation views, we\nfirst propose three proxy tasks during the agent's in-domain pre-training:\nMasked Panorama Modeling (MPM), Masked Trajectory Modeling (MTM), and Action\nPrediction with Image Generation (APIG). These three objectives teach the model\nto predict missing views in a panorama (MPM), predict missing steps in the full\ntrajectory (MTM), and generate the next view based on the full instruction and\nnavigation history (APIG), respectively. We then fine-tune the agent on the VLN\ntask with an auxiliary loss that minimizes the difference between the view\nsemantics generated by the agent and the ground truth view semantics of the\nnext step. Empirically, our VLN-SIG achieves the new state-of-the-art on both\nthe Room-to-Room dataset and the CVDN dataset. We further show that our agent\nlearns to fill in missing patches in future views qualitatively, which brings\nmore interpretability over agents' predicted actions. Lastly, we demonstrate\nthat learning to predict future view semantics also enables the agent to have\nbetter performance on longer paths.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jialu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reinforcement Learning Tutor Better Supported Lower Performers in a Math Task. (arXiv:2304.04933v1 [cs.AI])","link":"http://arxiv.org/abs/2304.04933","description":"<p>Resource limitations make it hard to provide all students with one of the\nmost effective educational interventions: personalized instruction.\nReinforcement learning could be a key tool to reduce the development cost and\nimprove the effectiveness of, intelligent tutoring software that aims to\nprovide the right support, at the right time, to a student. Here we illustrate\nthat deep reinforcement learning can be used to provide adaptive pedagogical\nsupport to students learning about the concept of volume in a narrative\nstoryline software. Using explainable artificial intelligence tools, we also\nextracted interpretable insights about the pedagogical policy learned, and we\ndemonstrate that the resulting policy had similar performance in a different\nstudent population. Most importantly, in both studies the\nreinforcement-learning narrative system had the largest benefit for those\nstudents with the lowest initial pretest scores, suggesting the opportunity for\nAI to adapt and provide support for those most in need.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruan_S/0/1/0/all/0/1\">Sherry Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_A/0/1/0/all/0/1\">Allen Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steenbergen_W/0/1/0/all/0/1\">William Steenbergen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiayu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">JQ Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kyle Dang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Catherine Y Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rui Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landay_J/0/1/0/all/0/1\">James A Landay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ruan_E/0/1/0/all/0/1\">Emma Brunskill. Sherry Ruan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_A/0/1/0/all/0/1\">Allen Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steenbergen_W/0/1/0/all/0/1\">William Steenbergen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jiayu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">JQ Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1\">Meng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Kyle Dang Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Catherine Y Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rui Ying</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Landay_J/0/1/0/all/0/1\">James A Landay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1\">Emma Brunskill</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentence-Level Relation Extraction via Contrastive Learning with Descriptive Relation Prompts. (arXiv:2304.04935v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04935","description":"<p>Sentence-level relation extraction aims to identify the relation between two\nentities for a given sentence. The existing works mostly focus on obtaining a\nbetter entity representation and adopting a multi-label classifier for relation\nextraction. A major limitation of these works is that they ignore background\nrelational knowledge and the interrelation between entity types and candidate\nrelations. In this work, we propose a new paradigm, Contrastive Learning with\nDescriptive Relation Prompts(CTL-DRP), to jointly consider entity information,\nrelational knowledge and entity type restrictions. In particular, we introduce\nan improved entity marker and descriptive relation prompts when generating\ncontextual embedding, and utilize contrastive learning to rank the restricted\ncandidate relations. The CTL-DRP obtains a competitive F1-score of 76.7% on\nTACRED. Furthermore, the new presented paradigm achieves F1-scores of 85.8% and\n91.6% on TACREV and Re-TACRED respectively, which are both the state-of-the-art\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jiewen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ze Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditional Adapters: Parameter-efficient Transfer Learning with Fast Inference. (arXiv:2304.04947v1 [cs.CL])","link":"http://arxiv.org/abs/2304.04947","description":"<p>We propose Conditional Adapter (CoDA), a parameter-efficient transfer\nlearning method that also improves inference efficiency. CoDA generalizes\nbeyond standard adapter approaches to enable a new way of balancing speed and\naccuracy using conditional computation. Starting with an existing dense\npretrained model, CoDA adds sparse activation together with a small number of\nnew parameters and a light-weight training phase. Our experiments demonstrate\nthat the CoDA approach provides an unexpectedly efficient way to transfer\nknowledge. Across a variety of language, vision, and speech tasks, CoDA\nachieves a 2x to 8x inference speed-up compared to the state-of-the-art Adapter\napproach with moderate to no accuracy loss and the same parameter efficiency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1\">Tao Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Junwen Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1\">Siddhartha Brahma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ainslie_J/0/1/0/all/0/1\">Joshua Ainslie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kenton Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yanqi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_N/0/1/0/all/0/1\">Nan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_V/0/1/0/all/0/1\">Vincent Y. Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuexin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1\">Ming-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sim-T: Simplify the Transformer Network by Multiplexing Technique for Speech Recognition. (arXiv:2304.04991v1 [cs.SD])","link":"http://arxiv.org/abs/2304.04991","description":"<p>In recent years, a great deal of attention has been paid to the Transformer\nnetwork for speech recognition tasks due to its excellent model performance.\nHowever, the Transformer network always involves heavy computation and large\nnumber of parameters, causing serious deployment problems in devices with\nlimited computation sources or storage memory. In this paper, a new lightweight\nmodel called Sim-T has been proposed to expand the generality of the\nTransformer model. Under the help of the newly developed multiplexing\ntechnique, the Sim-T can efficiently compress the model with negligible\nsacrifice on its performance. To be more precise, the proposed technique\nincludes two parts, that are, module weight multiplexing and attention score\nmultiplexing. Moreover, a novel decoder structure has been proposed to\nfacilitate the attention score multiplexing. Extensive experiments have been\nconducted to validate the effectiveness of Sim-T. In Aishell-1 dataset, when\nthe proposed Sim-T is 48% parameter less than the baseline Transformer, 0.4%\nCER improvement can be obtained. Alternatively, 69% parameter reduction can be\nachieved if the Sim-T gives the same performance as the baseline Transformer.\nWith regard to the HKUST and WSJ eval92 datasets, CER and WER will be improved\nby 0.3% and 0.2%, respectively, when parameters in Sim-T are 40% less than the\nbaseline Transformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1\">Guangyong Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1\">Zhikui Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiren Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guangguang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xinmei Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junhua Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human-machine cooperation for semantic feature listing. (arXiv:2304.05012v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05012","description":"<p>Semantic feature norms, lists of features that concepts do and do not\npossess, have played a central role in characterizing human conceptual\nknowledge, but require extensive human labor. Large language models (LLMs)\noffer a novel avenue for the automatic generation of such feature lists, but\nare prone to significant error. Here, we present a new method for combining a\nlearned model of human lexical-semantics from limited data with LLM-generated\ndata to efficiently generate high-quality feature norms.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mukherjee_K/0/1/0/all/0/1\">Kushin Mukherjee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1\">Siddharth Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogers_T/0/1/0/all/0/1\">Timothy T. Rogers</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Food Do We Tweet about on a Rainy Day?. (arXiv:2304.05041v1 [cs.SI])","link":"http://arxiv.org/abs/2304.05041","description":"<p>Food choice is a complex phenomenon shaped by factors such as taste,\nambience, culture or weather. In this paper, we explore food-related tweeting\nin different weather conditions. We inspect a Latvian food tweet dataset\nspanning the past decade in conjunction with a weather observation dataset\nconsisting of average temperature, precipitation, and other phenomena. We find\nwhich weather conditions lead to specific food information sharing;\nautomatically classify tweet sentiment and discuss how it changes depending on\nthe weather. This research contributes to the growing area of large-scale\nsocial network data understanding of food consumers' choices and perceptions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1\">Maija K&#x101;le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rikters_M/0/1/0/all/0/1\">Mat&#x12b;ss Rikters</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FashionSAP: Symbols and Attributes Prompt for Fine-grained Fashion Vision-Language Pre-training. (arXiv:2304.05051v1 [cs.CV])","link":"http://arxiv.org/abs/2304.05051","description":"<p>Fashion vision-language pre-training models have shown efficacy for a wide\nrange of downstream tasks. However, general vision-language pre-training models\npay less attention to fine-grained domain features, while these features are\nimportant in distinguishing the specific domain tasks from general tasks. We\npropose a method for fine-grained fashion vision-language pre-training based on\nfashion Symbols and Attributes Prompt (FashionSAP) to model fine-grained\nmulti-modalities fashion attributes and characteristics. Firstly, we propose\nthe fashion symbols, a novel abstract fashion concept layer, to represent\ndifferent fashion items and to generalize various kinds of fine-grained fashion\nfeatures, making modelling fine-grained attributes more effective. Secondly,\nthe attributes prompt method is proposed to make the model learn specific\nattributes of fashion items explicitly. We design proper prompt templates\naccording to the format of fashion data. Comprehensive experiments are\nconducted on two public fashion benchmarks, i.e., FashionGen and FashionIQ, and\nFashionSAP gets SOTA performances for four popular fashion tasks. The ablation\nstudy also shows the proposed abstract fashion symbols, and the attribute\nprompt method enables the model to acquire fine-grained semantics in the\nfashion domain effectively. The obvious performance gains from FashionSAP\nprovide a new baseline for future fashion task research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yunpeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lisai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhijian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhonghua Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianxin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1\">Zhao Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teaching Large Language Models to Self-Debug. (arXiv:2304.05128v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05128","description":"<p>Large language models (LLMs) have achieved impressive performance on code\ngeneration. However, for complex programming tasks, generating the correct\nsolution in one go becomes challenging, thus some prior works have designed\nprogram repair approaches to improve code generation performance. In this work,\nwe propose Self-Debugging, which teaches a large language model to debug its\npredicted program via few-shot demonstrations. In particular, we demonstrate\nthat Self-Debugging can teach the large language model to perform rubber duck\ndebugging; i.e., without any feedback on the code correctness or error\nmessages, the model is able to identify its mistakes by explaining the\ngenerated code in natural language. Self-Debugging achieves the\nstate-of-the-art performance on several code generation benchmarks, including\nthe Spider dataset for text-to-SQL generation, TransCoder for C++-to-Python\ntranslation, and MBPP for text-to-Python generation. On the Spider benchmark\nwhere there are no unit tests to verify the correctness of predictions,\nSelf-Debugging with code explanation consistently improves the baseline by\n2-3%, and improves the prediction accuracy on problems of the hardest label by\n9%. On TransCoder and MBPP where unit tests are available, Self-Debugging\nimproves the baseline accuracy by up to 12%. Meanwhile, by leveraging feedback\nmessages and reusing failed predictions, Self-Debugging notably improves sample\nefficiency, and can match or outperform baseline models that generate more than\n10x candidate programs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1\">Maxwell Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scharli_N/0/1/0/all/0/1\">Nathanael Sch&#xe4;rli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-step Jailbreaking Privacy Attacks on ChatGPT. (arXiv:2304.05197v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05197","description":"<p>With the rapid progress of large language models (LLMs), many downstream NLP\ntasks can be well solved given good prompts. Though model developers and\nresearchers work hard on dialog safety to avoid generating harmful content from\nLLMs, it is still challenging to steer AI-generated content (AIGC) for the\nhuman good. As powerful LLMs are devouring existing text data from various\ndomains (e.g., GPT-3 is trained on 45TB texts), it is natural to doubt whether\nthe private information is included in the training data and what privacy\nthreats can these LLMs and their downstream applications bring. In this paper,\nwe study the privacy threats from OpenAI's model APIs and New Bing enhanced by\nChatGPT and show that application-integrated LLMs may cause more severe privacy\nthreats ever than before. To this end, we conduct extensive experiments to\nsupport our claims and discuss LLMs' privacy implications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1\">Dadi Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1\">Mingshi Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LBMT team at VLSP2022-Abmusu: Hybrid method with text correlation and generative models for Vietnamese multi-document summarization. (arXiv:2304.05205v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05205","description":"<p>Multi-document summarization is challenging because the summaries should not\nonly describe the most important information from all documents but also\nprovide a coherent interpretation of the documents. This paper proposes a\nmethod for multi-document summarization based on cluster similarity. In the\nextractive method we use hybrid model based on a modified version of the\nPageRank algorithm and a text correlation considerations mechanism. After\ngenerating summaries by selecting the most important sentences from each\ncluster, we apply BARTpho and ViT5 to construct the abstractive models. Both\nextractive and abstractive approaches were considered in this study. The\nproposed method achieves competitive results in VLSP 2022 competition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tan-Minh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thai-Binh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hoang-Trung Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Hai-Long Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thanh_T/0/1/0/all/0/1\">Tam Doan Thanh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Ha-Thanh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuong_T/0/1/0/all/0/1\">Thi-Hai-Yen Vuong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Efficient Fine-tuning of Pre-trained Code Models: An Experimental Study and Beyond. (arXiv:2304.05216v1 [cs.SE])","link":"http://arxiv.org/abs/2304.05216","description":"<p>Recently, fine-tuning pre-trained code models such as CodeBERT on downstream\ntasks has achieved great success in many software testing and analysis tasks.\nWhile effective and prevalent, fine-tuning the pre-trained parameters incurs a\nlarge computational cost. In this paper, we conduct an extensive experimental\nstudy to explore what happens to layer-wise pre-trained representations and\ntheir encoded code knowledge during fine-tuning. We then propose efficient\nalternatives to fine-tune the large pre-trained code model based on the above\nfindings. Our experimental study shows that (1) lexical, syntactic and\nstructural properties of source code are encoded in the lower, intermediate,\nand higher layers, respectively, while the semantic property spans across the\nentire model. (2) The process of fine-tuning preserves most of the code\nproperties. Specifically, the basic code properties captured by lower and\nintermediate layers are still preserved during fine-tuning. Furthermore, we\nfind that only the representations of the top two layers change most during\nfine-tuning for various downstream tasks. (3) Based on the above findings, we\npropose Telly to efficiently fine-tune pre-trained code models via layer\nfreezing. The extensive experimental results on five various downstream tasks\ndemonstrate that training parameters and the corresponding time cost are\ngreatly reduced, while performances are similar or better. Replication package\nincluding source code, datasets, and online Appendix is available at:\n\\url{https://github.com/DeepSoftwareAnalytics/Telly}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_E/0/1/0/all/0/1\">Ensheng Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yanlin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Lun Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1\">Shi Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hongbin Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards preserving word order importance through Forced Invalidation. (arXiv:2304.05221v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05221","description":"<p>Large pre-trained language models such as BERT have been widely used as a\nframework for natural language understanding (NLU) tasks. However, recent\nfindings have revealed that pre-trained language models are insensitive to word\norder. The performance on NLU tasks remains unchanged even after randomly\npermuting the word of a sentence, where crucial syntactic information is\ndestroyed. To help preserve the importance of word order, we propose a simple\napproach called Forced Invalidation (FI): forcing the model to identify\npermuted sequences as invalid samples. We perform an extensive evaluation of\nour approach on various English NLU and QA based tasks over BERT-based and\nattention-based models over word embeddings. Our experiments demonstrate that\nForced Invalidation significantly improves the sensitivity of the models to\nword order.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Al_Negheimish_H/0/1/0/all/0/1\">Hadeel Al-Negheimish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madhyastha_P/0/1/0/all/0/1\">Pranava Madhyastha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1\">Alessandra Russo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Approximating Human Evaluation of Social Chatbots with Prompting. (arXiv:2304.05253v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05253","description":"<p>Once powerful conversational models have become available for a wide\naudience, users started actively engaging in social interactions with this\ntechnology. Such unprecedented interaction experiences may pose considerable\nsocial and psychological risks to the users unless the technology is properly\ncontrolled. This creates an urgent need for scalable and robust evaluation\nmetrics for conversational chatbots. Existing automatic evaluation metrics\nusually focus on objective quality measures and disregard subjective\nperceptions of social dimensions. Moreover, most of these approaches operate on\npre-produced dialogs from available benchmark corpora, which implies human\ninvolvement for preparing the material for evaluation and, thus, impeded\nscalability of the metrics. To address this limitation, we propose to make use\nof the emerging large language models (LLMs) from the GPT-family and describe a\nnew framework allowing to conduct dialog system evaluation with prompting. With\nthis framework, we are able to achieve full automation of the evaluation\npipeline and reach impressive correlation with the human judgement (up to\nPearson r=0.95 on system level). The underlying concept is to collect synthetic\nchat logs of evaluated bots with a LLM in the other-play setting, where LLM is\ncarefully conditioned to follow a specific scenario. We further explore\ndifferent prompting approaches to produce evaluation scores with the same LLM.\nThe best-performing prompts, containing few-show demonstrations and\ninstructions, show outstanding performance on the tested dataset and\ndemonstrate the ability to generalize to other dialog corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Svikhnushina_E/0/1/0/all/0/1\">Ekaterina Svikhnushina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_P/0/1/0/all/0/1\">Pearl Pu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v1 [cs.CV])","link":"http://arxiv.org/abs/2304.05265","description":"<p>The recent large-scale generative modeling has attained unprecedented\nperformance especially in producing high-fidelity images driven by text\nprompts. Text inversion (TI), alongside the text-to-image model backbones, is\nproposed as an effective technique in personalizing the generation when the\nprompts contain user-defined, unseen or long-tail concept tokens. Despite that,\nwe find and show that the deployment of TI remains full of \"dark-magics\" -- to\nname a few, the harsh requirement of additional datasets, arduous human efforts\nin the loop and lack of robustness. In this work, we propose a much-enhanced\nversion of TI, dubbed Controllable Textual Inversion (COTI), in resolving all\nthe aforementioned problems and in turn delivering a robust, data-efficient and\neasy-to-use framework. The core to COTI is a theoretically-guided loss\nobjective instantiated with a comprehensive and novel weighted scoring\nmechanism, encapsulated by an active-learning paradigm. The extensive results\nshow that COTI significantly outperforms the prior TI-related approaches with a\n26.05 decrease in the FID score and a 23.00% boost in the R-precision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianan Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haobo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_R/0/1/0/all/0/1\">Ruixuan Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Sai Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Entity-based Claim Extraction Pipeline for Real-world Biomedical Fact-checking. (arXiv:2304.05268v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05268","description":"<p>Existing fact-checking models for biomedical claims are typically trained on\nsynthetic or well-worded data and hardly transfer to social media content. This\nmismatch can be mitigated by adapting the social media input to mimic the\nfocused nature of common training claims. To do so, Wuehrl &amp; Klinger (2022)\npropose to extract concise claims based on medical entities in the text.\nHowever, their study has two limitations: First, it relies on gold-annotated\nentities. Therefore, its feasibility for a real-world application cannot be\nassessed since this requires detecting relevant entities automatically. Second,\nthey represent claim entities with the original tokens. This constitutes a\nterminology mismatch which potentially limits the fact-checking performance. To\nunderstand both challenges, we propose a claim extraction pipeline for medical\ntweets that incorporates named entity recognition and terminology normalization\nvia entity linking. We show that automatic NER does lead to a performance drop\nin comparison to using gold annotations but the fact-checking performance still\nimproves considerably over inputting the unchanged tweets. Normalizing entities\nto their canonical forms does, however, not improve the performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wuhrl_A/0/1/0/all/0/1\">Amelie W&#xfc;hrl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimminger_L/0/1/0/all/0/1\">Lara Grimminger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1\">Roman Klinger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RRHF: Rank Responses to Align Language Models with Human Feedback without tears. (arXiv:2304.05302v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05302","description":"<p>Reinforcement Learning from Human Feedback (RLHF) facilitates the alignment\nof large language models with human preferences, significantly enhancing the\nquality of interactions between humans and these models. InstructGPT implements\nRLHF through several stages, including Supervised Fine-Tuning (SFT), reward\nmodel training, and Proximal Policy Optimization (PPO). PPO, however, is\nsensitive to hyperparameters and requires a minimum of four models in its\nstandard implementation, which makes it hard to train. In contrast, we propose\na novel learning paradigm called RRHF, which scores responses generated by\ndifferent sampling policies and learns to align them with human preferences\nthrough ranking loss. RRHF can efficiently align language model output\nprobabilities with human preferences as robust as fine-tuning and it only needs\n1 to 2 models during tuning. In addition, RRHF can be considered an extension\nof SFT and reward models while being simpler than PPO in terms of coding, model\ncounts, and hyperparameters. The entire alignment process can be accomplished\nwithin a single RRHF training session. We evaluate RRHF using LLaMA and Alpaca\non Helpful and Harmless data, demonstrating performance comparable to PPO.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1\">Zheng Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1\">Hongyi Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1\">Songfang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ELVIS: Empowering Locality of Vision Language Pre-training with Intra-modal Similarity. (arXiv:2304.05303v1 [cs.CV])","link":"http://arxiv.org/abs/2304.05303","description":"<p>Deep learning has shown great potential in assisting radiologists in reading\nchest X-ray (CXR) images, but its need for expensive annotations for improving\nperformance prevents widespread clinical application. Visual language\npre-training (VLP) can alleviate the burden and cost of annotation by\nleveraging routinely generated reports for radiographs, which exist in large\nquantities as well as in paired form (imagetext pairs). Additionally,\nextensions to localization-aware VLPs are being proposed to address the needs\nof accurate localization of abnormalities for CAD in CXR. However, we find that\nthe formulation proposed by locality-aware VLP literatures actually leads to\nloss in spatial relationships required for downstream localization tasks.\nTherefore, we propose Empowering Locality of VLP with Intra-modal Similarity,\nELVIS, a VLP aware of intra-modal locality, to better preserve the locality\nwithin radiographs or reports, which enhances the ability to comprehend\nlocation references in text reports. Our locality-aware VLP method\nsignificantly outperforms state-of-the art baselines in multiple segmentation\ntasks and the MS-CXR phrase grounding task. Qualitatively, ELVIS is able to\nfocus well on regions of interest described in the report text compared to\nprior approaches, allowing for enhanced interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1\">Sumin Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">JaeWoong Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Tae Soo Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kooi_T/0/1/0/all/0/1\">Thijs Kooi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergent autonomous scientific research capabilities of large language models. (arXiv:2304.05332v1 [physics.chem-ph])","link":"http://arxiv.org/abs/2304.05332","description":"<p>Transformer-based large language models are rapidly advancing in the field of\nmachine learning research, with applications spanning natural language,\nbiology, chemistry, and computer programming. Extreme scaling and reinforcement\nlearning from human feedback have significantly improved the quality of\ngenerated text, enabling these models to perform various tasks and reason about\ntheir choices. In this paper, we present an Intelligent Agent system that\ncombines multiple large language models for autonomous design, planning, and\nexecution of scientific experiments. We showcase the Agent's scientific\nresearch capabilities with three distinct examples, with the most complex being\nthe successful performance of catalyzed cross-coupling reactions. Finally, we\ndiscuss the safety implications of such systems and propose measures to prevent\ntheir misuse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Boiko_D/0/1/0/all/0/1\">Daniil A. Boiko</a>, <a href=\"http://arxiv.org/find/physics/1/au:+MacKnight_R/0/1/0/all/0/1\">Robert MacKnight</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Gomes_G/0/1/0/all/0/1\">Gabe Gomes</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toxicity in ChatGPT: Analyzing Persona-assigned Language Models. (arXiv:2304.05335v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05335","description":"<p>Large language models (LLMs) have shown incredible capabilities and\ntranscended the natural language processing (NLP) community, with adoption\nthroughout many services like healthcare, therapy, education, and customer\nservice. Since users include people with critical information needs like\nstudents or patients engaging with chatbots, the safety of these systems is of\nprime importance. Therefore, a clear understanding of the capabilities and\nlimitations of LLMs is necessary. To this end, we systematically evaluate\ntoxicity in over half a million generations of ChatGPT, a popular\ndialogue-based LLM. We find that setting the system parameter of ChatGPT by\nassigning it a persona, say that of the boxer Muhammad Ali, significantly\nincreases the toxicity of generations. Depending on the persona assigned to\nChatGPT, its toxicity can increase up to 6x, with outputs engaging in incorrect\nstereotypes, harmful dialogue, and hurtful opinions. This may be potentially\ndefamatory to the persona and harmful to an unsuspecting user. Furthermore, we\nfind concerning patterns where specific entities (e.g., certain races) are\ntargeted more than others (3x more) irrespective of the assigned persona, that\nreflect inherent discriminatory biases in the model. We hope that our findings\ninspire the broader AI community to rethink the efficacy of current safety\nguardrails and develop better techniques that lead to robust, safe, and\ntrustworthy AI systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1\">Ameet Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murahari_V/0/1/0/all/0/1\">Vishvak Murahari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajpurohit_T/0/1/0/all/0/1\">Tanmay Rajpurohit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1\">Ashwin Kalyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narasimhan_K/0/1/0/all/0/1\">Karthik Narasimhan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Use of Foundation Models for Named Entity Recognition and Lemmatization Tasks in Slavic Languages. (arXiv:2304.05336v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05336","description":"<p>This paper describes Adam Mickiewicz University's (AMU) solution for the 4th\nShared Task on SlavNER. The task involves the identification, categorization,\nand lemmatization of named entities in Slavic languages. Our approach involved\nexploring the use of foundation models for these tasks. In particular, we used\nmodels based on the popular BERT and T5 model architectures. Additionally, we\nused external datasets to further improve the quality of our models. Our\nsolution obtained promising results, achieving high metrics scores in both\ntasks. We describe our approach and the results of our experiments in detail,\nshowing that the method is effective for NER and lemmatization in Slavic\nlanguages. Additionally, our models for lemmatization will be available at:\nhttps://huggingface.co/amu-cai.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Palka_G/0/1/0/all/0/1\">Gabriela Pa&#x142;ka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nowakowski_A/0/1/0/all/0/1\">Artur Nowakowski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over MultiModal Stock Movement Prediction Challenges. (arXiv:2304.05351v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05351","description":"<p>Recently, large language models (LLMs) like ChatGPT have demonstrated\nremarkable performance across a variety of natural language processing tasks.\nHowever, their effectiveness in the financial domain, specifically in\npredicting stock market movements, remains to be explored. In this paper, we\nconduct an extensive zero-shot analysis of ChatGPT's capabilities in multimodal\nstock movement prediction, on three tweets and historical stock price datasets.\nOur findings indicate that ChatGPT is a \"Wall Street Neophyte\" with limited\nsuccess in predicting stock movements, as it underperforms not only\nstate-of-the-art methods but also traditional methods like linear regression\nusing price features. Despite the potential of Chain-of-Thought prompting\nstrategies and the inclusion of tweets, ChatGPT's performance remains subpar.\nFurthermore, we observe limitations in its explainability and stability,\nsuggesting the need for more specialized training or fine-tuning. This research\nprovides insights into ChatGPT's capabilities and serves as a foundation for\nfuture work aimed at improving financial market analysis and prediction by\nleveraging social media sentiment and historical stock data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1\">Qianqian Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_W/0/1/0/all/0/1\">Weiguang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1\">Yanzhao Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_M/0/1/0/all/0/1\">Min Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jimin Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding. (arXiv:2304.05368v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05368","description":"<p>Large language models (LLMs) have made significant progress in various\ndomains, including healthcare. However, the specialized nature of clinical\nlanguage understanding tasks presents unique challenges and limitations that\nwarrant further investigation. In this study, we conduct a comprehensive\nevaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within\nthe realm of clinical language understanding tasks. These tasks span a diverse\nrange, including named entity recognition, relation extraction, natural\nlanguage inference, semantic textual similarity, document classification, and\nquestion-answering. We also introduce a novel prompting strategy,\nself-questioning prompting (SQP), tailored to enhance LLMs' performance by\neliciting informative questions and answers pertinent to the clinical scenarios\nat hand. Our evaluation underscores the significance of task-specific learning\nstrategies and prompting techniques for improving LLMs' effectiveness in\nhealthcare-related tasks. Additionally, our in-depth error analysis on the\nchallenging relation extraction task offers valuable insights into error\ndistribution and potential avenues for improvement using SQP. Our study sheds\nlight on the practical implications of employing LLMs in the specialized domain\nof healthcare, serving as a foundation for future research and the development\nof potential applications in healthcare settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petzold_L/0/1/0/all/0/1\">Linda Petzold</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Those Aren't Your Memories, They're Somebody Else's: Seeding Misinformation in Chat Bot Memories. (arXiv:2304.05371v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05371","description":"<p>One of the new developments in chit-chat bots is a long-term memory mechanism\nthat remembers information from past conversations for increasing engagement\nand consistency of responses. The bot is designed to extract knowledge of\npersonal nature from their conversation partner, e.g., stating preference for a\nparticular color. In this paper, we show that this memory mechanism can result\nin unintended behavior. In particular, we found that one can combine a personal\nstatement with an informative statement that would lead the bot to remember the\ninformative statement alongside personal knowledge in its long term memory.\nThis means that the bot can be tricked into remembering misinformation which it\nwould regurgitate as statements of fact when recalling information relevant to\nthe topic of conversation. We demonstrate this vulnerability on the BlenderBot\n2 framework implemented on the ParlAI platform and provide examples on the more\nrecent and significantly larger BlenderBot 3 model. We generate 150 examples of\nmisinformation, of which 114 (76%) were remembered by BlenderBot 2 when\ncombined with a personal statement. We further assessed the risk of this\nmisinformation being recalled after intervening innocuous conversation and in\nresponse to multiple questions relevant to the injected memory. Our evaluation\nwas performed on both the memory-only and the combination of memory and\ninternet search modes of BlenderBot 2. From the combinations of these\nvariables, we generated 12,890 conversations and analyzed recalled\nmisinformation in the responses. We found that when the chat bot is questioned\non the misinformation topic, it was 328% more likely to respond with the\nmisinformation as fact when the misinformation was in the long-term memory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Atkins_C/0/1/0/all/0/1\">Conor Atkins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1\">Benjamin Zi Hao Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Asghar_H/0/1/0/all/0/1\">Hassan Jameel Asghar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wood_I/0/1/0/all/0/1\">Ian Wood</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaafar_M/0/1/0/all/0/1\">Mohamed Ali Kaafar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability Analysis against Human Performance. (arXiv:2304.05372v1 [cs.CL])","link":"http://arxiv.org/abs/2304.05372","description":"<p>ChatGPT and Bard are AI chatbots based on Large Language Models (LLM) that\nare slated to promise different applications in diverse areas. In education,\nthese AI technologies have been tested for applications in assessment and\nteaching. In assessment, AI has long been used in automated essay scoring and\nautomated item generation. One psychometric property that these tools must have\nto assist or replace humans in assessment is high reliability in terms of\nagreement between AI scores and human raters. In this paper, we measure the\nreliability of OpenAI ChatGP and Google Bard LLMs tools against experienced and\ntrained humans in perceiving and rating the complexity of writing prompts.\nIntraclass correlation (ICC) as a performance metric showed that the\ninter-reliability of both the OpenAI ChatGPT and the Google Bard were low\nagainst the gold standard of human ratings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khademi_A/0/1/0/all/0/1\">Abdolvahab Khademi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contrastive Attention for Automatic Chest X-ray Report Generation. (arXiv:2106.06965v5 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2106.06965","description":"<p>Recently, chest X-ray report generation, which aims to automatically generate\ndescriptions of given chest X-ray images, has received growing research\ninterests. The key challenge of chest X-ray report generation is to accurately\ncapture and describe the abnormal regions. In most cases, the normal regions\ndominate the entire chest X-ray image, and the corresponding descriptions of\nthese normal regions dominate the final report. Due to such data bias,\nlearning-based models may fail to attend to abnormal regions. In this work, to\neffectively capture and describe abnormal regions, we propose the Contrastive\nAttention (CA) model. Instead of solely focusing on the current input image,\nthe CA model compares the current input image with normal images to distill the\ncontrastive information. The acquired contrastive information can better\nrepresent the visual features of abnormal regions. According to the experiments\non the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into\nseveral existing models can boost their performance across most metrics. In\naddition, according to the analysis, the CA model can help existing models\nbetter attend to the abnormal regions and provide more accurate descriptions\nwhich are crucial for an interpretable diagnosis. Specifically, we achieve the\nstate-of-the-art results on the two public datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1\">Changchang Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Ping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survey of Aspect-based Sentiment Analysis Datasets. (arXiv:2204.05232v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.05232","description":"<p>Aspect-based sentiment analysis (ABSA) is a natural language processing\nproblem that requires analyzing user-generated reviews to determine: a) The\ntarget entity being reviewed, b) The high-level aspect to which it belongs, and\nc) The sentiment expressed toward the targets and the aspects. Numerous yet\nscattered corpora for ABSA make it difficult for researchers to identify\ncorpora best suited for a specific ABSA subtask quickly. This study aims to\npresent a database of corpora that can be used to train and assess autonomous\nABSA systems. Additionally, we provide an overview of the major corpora for\nABSA and its subtasks and highlight several features that researchers should\nconsider when selecting a corpus. Finally, we discuss the advantages and\ndisadvantages of current collection approaches and make recommendations for\nfuture corpora creation. This survey examines 65 publicly available ABSA\ndatasets covering over 25 domains, including 45 English and 20 other languages\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chebolu_S/0/1/0/all/0/1\">Siva Uday Sampreeth Chebolu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1\">Nedim Lipka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Solorio_T/0/1/0/all/0/1\">Thamar Solorio</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Competence-based Multimodal Curriculum Learning for Medical Report Generation. (arXiv:2206.14579v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.14579","description":"<p>Medical report generation task, which targets to produce long and coherent\ndescriptions of medical images, has attracted growing research interests\nrecently. Different from the general image captioning tasks, medical report\ngeneration is more challenging for data-driven neural models. This is mainly\ndue to 1) the serious data bias and 2) the limited medical data. To alleviate\nthe data bias and make best use of available data, we propose a\nCompetence-based Multimodal Curriculum Learning framework (CMCL). Specifically,\nCMCL simulates the learning process of radiologists and optimizes the model in\na step by step manner. Firstly, CMCL estimates the difficulty of each training\ninstance and evaluates the competence of current model; Secondly, CMCL selects\nthe most suitable batch of training instances considering current model\ncompetence. By iterating above two steps, CMCL can gradually improve the\nmodel's performance. The experiments on the public IU-Xray and MIMIC-CXR\ndatasets show that CMCL can be incorporated into existing models to improve\ntheir performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MENLI: Robust Evaluation Metrics from Natural Language Inference. (arXiv:2208.07316v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.07316","description":"<p>Recently proposed BERT-based evaluation metrics for text generation perform\nwell on standard benchmarks but are vulnerable to adversarial attacks, e.g.,\nrelating to information correctness. We argue that this stems (in part) from\nthe fact that they are models of semantic similarity. In contrast, we develop\nevaluation metrics based on Natural Language Inference (NLI), which we deem a\nmore appropriate modeling. We design a preference-based adversarial attack\nframework and show that our NLI based metrics are much more robust to the\nattacks than the recent BERT-based metrics. On standard benchmarks, our NLI\nbased metrics outperform existing summarization metrics, but perform below SOTA\nMT metrics. However, when combining existing metrics with our NLI metrics, we\nobtain both higher adversarial robustness (15%-30%) and higher quality metrics\nas measured on standard benchmarks (+5% to 30%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1\">Steffen Eger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prophet Attention: Predicting Attention with Future Attention for Image Captioning. (arXiv:2210.10914v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2210.10914","description":"<p>Recently, attention based models have been used extensively in many\nsequence-to-sequence learning systems. Especially for image captioning, the\nattention based models are expected to ground correct image regions with proper\ngenerated words. However, for each time step in the decoding process, the\nattention based models usually use the hidden state of the current input to\nattend to the image regions. Under this setting, these attention models have a\n\"deviated focus\" problem that they calculate the attention weights based on\nprevious words instead of the one to be generated, impairing the performance of\nboth grounding and captioning. In this paper, we propose the Prophet Attention,\nsimilar to the form of self-supervision. In the training stage, this module\nutilizes the future information to calculate the \"ideal\" attention weights\ntowards image regions. These calculated \"ideal\" weights are further used to\nregularize the \"deviated\" attention. In this manner, image regions are grounded\nwith the correct words. The proposed Prophet Attention can be easily\nincorporated into existing image captioning models to improve their performance\nof both grounding and captioning. The experiments on the Flickr30k Entities and\nthe MSCOCO datasets show that the proposed Prophet Attention consistently\noutperforms baselines in both automatic metrics and human evaluations. It is\nworth noticing that we set new state-of-the-arts on the two benchmark datasets\nand achieve the 1st place on the leaderboard of the online MSCOCO benchmark in\nterms of the default ranking score, i.e., CIDEr-c40.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xuancheng Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Wei Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Control Diffusion: Efficiently Scaling through Space, Time, and Tasks. (arXiv:2210.15629v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2210.15629","description":"<p>Training generalist agents is difficult across several axes, requiring us to\ndeal with high-dimensional inputs (space), long horizons (time), and multiple\nand new tasks. Recent advances with architectures have allowed for improved\nscaling along one or two of these dimensions, but are still prohibitive\ncomputationally. In this paper, we propose to address all three axes by\nleveraging Language to Control Diffusion models as a hierarchical planner\nconditioned on language (LCD). We effectively and efficiently scale diffusion\nmodels for planning in extended temporal, state, and task dimensions to tackle\nlong horizon control problems conditioned on natural language instructions. We\ncompare LCD with other state-of-the-art models on the CALVIN language robotics\nbenchmark and find that LCD outperforms other SOTA methods in multi task\nsuccess rates while dramatically improving computational efficiency with a\nsingle task success rate (SR) of 88.7% against the previous best of 82.6%. We\nshow that LCD can successfully leverage the unique strength of diffusion models\nto produce coherent long range plans while addressing their weakness at\ngenerating low-level details and control. We release our code and models at\nhttps://github.com/ezhang7423/language-control-diffusion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_E/0/1/0/all/0/1\">Edwin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yujie Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Amy Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VaxxHesitancy: A Dataset for Studying Hesitancy Towards COVID-19 Vaccination on Twitter. (arXiv:2301.06660v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.06660","description":"<p>Vaccine hesitancy has been a common concern, probably since vaccines were\ncreated and, with the popularisation of social media, people started to express\ntheir concerns about vaccines online alongside those posting pro- and\nanti-vaccine content. Predictably, since the first mentions of a COVID-19\nvaccine, social media users posted about their fears and concerns or about\ntheir support and belief into the effectiveness of these rapidly developing\nvaccines. Identifying and understanding the reasons behind public hesitancy\ntowards COVID-19 vaccines is important for policy markers that need to develop\nactions to better inform the population with the aim of increasing vaccine\ntake-up. In the case of COVID-19, where the fast development of the vaccines\nwas mirrored closely by growth in anti-vaxx disinformation, automatic means of\ndetecting citizen attitudes towards vaccination became necessary. This is an\nimportant computational social sciences task that requires data analysis in\norder to gain in-depth understanding of the phenomena at hand. Annotated data\nis also necessary for training data-driven models for more nuanced analysis of\nattitudes towards vaccination. To this end, we created a new collection of over\n3,101 tweets annotated with users' attitudes towards COVID-19 vaccination\n(stance). Besides, we also develop a domain-specific language model (VaxxBERT)\nthat achieves the best predictive performance (73.0 accuracy and 69.3 F1-score)\nas compared to a robust set of baselines. To the best of our knowledge, these\nare the first dataset and model that model vaccine hesitancy as a category\ndistinct from pro- and anti-vaccine stance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mu_Y/0/1/0/all/0/1\">Yida Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1\">Mali Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grimshaw_C/0/1/0/all/0/1\">Charlie Grimshaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1\">Carolina Scarton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1\">Kalina Bontcheva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xingyi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records. (arXiv:2301.07695v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.07695","description":"<p>We present a new text-to-SQL dataset for electronic health records (EHRs).\nThe utterances were collected from 222 hospital staff, including physicians,\nnurses, insurance review and health records teams, and more. To construct the\nQA dataset on structured EHR data, we conducted a poll at a university hospital\nand templatized the responses to create seed questions. Then, we manually\nlinked them to two open-source EHR databases, MIMIC-III and eICU, and included\nthem with various time expressions and held-out unanswerable questions in the\ndataset, which were all collected from the poll. Our dataset poses a unique set\nof challenges: the model needs to 1) generate SQL queries that reflect a wide\nrange of needs in the hospital, including simple retrieval and complex\noperations such as calculating survival rate, 2) understand various time\nexpressions to answer time-sensitive questions in healthcare, and 3)\ndistinguish whether a given question is answerable or unanswerable based on the\nprediction confidence. We believe our dataset, EHRSQL, could serve as a\npractical benchmark to develop and assess QA models on structured EHR data and\ntake one step further towards bridging the gap between text-to-SQL research and\nits real-life deployment in healthcare. EHRSQL is available at\nhttps://github.com/glee4810/EHRSQL.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Gyubok Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hwang_H/0/1/0/all/0/1\">Hyeonji Hwang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Seongsu Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_Y/0/1/0/all/0/1\">Yeonsu Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1\">Woncheol Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1\">Seongjun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jong-Yeup Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Edward Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Characterizing the Entities in Harmful Memes: Who is the Hero, the Villain, the Victim?. (arXiv:2301.11219v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11219","description":"<p>Memes can sway people's opinions over social media as they combine visual and\ntextual information in an easy-to-consume manner. Since memes instantly turn\nviral, it becomes crucial to infer their intent and potentially associated\nharmfulness to take timely measures as needed. A common problem associated with\nmeme comprehension lies in detecting the entities referenced and characterizing\nthe role of each of these entities. Here, we aim to understand whether the meme\nglorifies, vilifies, or victimizes each entity it refers to. To this end, we\naddress the task of role identification of entities in harmful memes, i.e.,\ndetecting who is the 'hero', the 'villain', and the 'victim' in the meme, if\nany. We utilize HVVMemes - a memes dataset on US Politics and Covid-19 memes,\nreleased recently as part of the CONSTRAINT@ACL-2022 shared-task. It contains\nmemes, entities referenced, and their associated roles: hero, villain, victim,\nand other. We further design VECTOR (Visual-semantic role dEteCToR), a robust\nmulti-modal framework for the task, which integrates entity-based contextual\ninformation in the multi-modal representation and compare it to several\nstandard unimodal (text-only or image-only) or multi-modal (image+text) models.\nOur experimental results show that our proposed model achieves an improvement\nof 4% over the best baseline and 1% over the best competing stand-alone\nsubmission from the shared-task. Besides divulging an extensive experimental\nsetup with comparative analyses, we finally highlight the challenges\nencountered in addressing the complex task of semantic role labeling within\nmemes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1\">Shivam Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1\">Atharva Kulkarni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suresh_T/0/1/0/all/0/1\">Tharun Suresh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mathur_H/0/1/0/all/0/1\">Himanshi Mathur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhtar_M/0/1/0/all/0/1\">Md. Shad Akhtar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1\">Tanmoy Chakraborty</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?. (arXiv:2303.04360v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.04360","description":"<p>Recent advancements in large language models (LLMs) have led to the\ndevelopment of highly potent models like OpenAI's ChatGPT. These models have\nexhibited exceptional performance in a variety of tasks, such as question\nanswering, essay composition, and code generation. However, their effectiveness\nin the healthcare sector remains uncertain. In this study, we seek to\ninvestigate the potential of ChatGPT to aid in clinical text mining by\nexamining its ability to extract structured information from unstructured\nhealthcare texts, with a focus on biological named entity recognition and\nrelation extraction. However, our preliminary results indicate that employing\nChatGPT directly for these tasks resulted in poor performance and raised\nprivacy concerns associated with uploading patients' information to the ChatGPT\nAPI. To overcome these limitations, we propose a new training paradigm that\ninvolves generating a vast quantity of high-quality synthetic data with labels\nutilizing ChatGPT and fine-tuning a local model for the downstream task. Our\nmethod has resulted in significant improvements in the performance of\ndownstream tasks, improving the F1-score from 23.37% to 63.99% for the named\nentity recognition task and from 75.86% to 83.59% for the relation extraction\ntask. Furthermore, generating data using ChatGPT can significantly reduce the\ntime and effort required for data collection and labeling, as well as mitigate\ndata privacy concerns. In summary, the proposed framework presents a promising\nsolution to enhance the applicability of LLM models to clinical text mining.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1\">Ruixiang Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaotian Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1\">Xiaoqian Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xia Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieval-Augmented Classification with Decoupled Representation. (arXiv:2303.13065v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13065","description":"<p>Retrieval augmented methods have shown promising results in various\nclassification tasks. However, existing methods focus on retrieving extra\ncontext to enrich the input, which is noise sensitive and non-expandable. In\nthis paper, following this line, we propose a $k$-nearest-neighbor (KNN) -based\nmethod for retrieval augmented classifications, which interpolates the\npredicted label distribution with retrieved instances' label distributions.\nDifferent from the standard KNN process, we propose a decoupling mechanism as\nwe find that shared representation for classification and retrieval hurts\nperformance and leads to training instability. We evaluate our method on a wide\nrange of classification datasets. Experimental results demonstrate the\neffectiveness and robustness of our proposed method. We also conduct extra\nexperiments to analyze the contributions of different components in our\nmodel.\\footnote{\\url{https://github.com/xnliang98/knn-cls-w-decoupling}}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1\">Xinnian Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shuangzhi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hui Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1\">Jiaqi Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_C/0/1/0/all/0/1\">Chao Bian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods. (arXiv:2303.13988v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.13988","description":"<p>Large language models (LLMs) are currently at the forefront of intertwining\nAI systems with human communication and everyday life. Due to rapid\ntechnological advances and their extreme versatility, LLMs nowadays have\nmillions of users and are at the cusp of being the main go-to technology for\ninformation retrieval, content generation, problem-solving, etc. Therefore, it\nis of great importance to thoroughly assess and scrutinize their capabilities.\nDue to increasingly complex and novel behavioral patterns in current LLMs, this\ncan be done by treating them as participants in psychology experiments that\nwere originally designed to test humans. For this purpose, the paper introduces\na new field of research called \"machine psychology\". The paper outlines how\ndifferent subfields of psychology can inform behavioral tests for LLMs. It\ndefines methodological standards for machine psychology research, especially by\nfocusing on policies for prompt designs. Additionally, it describes how\nbehavioral patterns discovered in LLMs are to be interpreted. In sum, machine\npsychology aims to discover emergent abilities in LLMs that cannot be detected\nby most traditional natural language processing benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hagendorff_T/0/1/0/all/0/1\">Thilo Hagendorff</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Scaling Pre-trained Language Models to Deeper via Parameter-efficient Architecture. (arXiv:2303.16753v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.16753","description":"<p>In this paper, we propose a highly parameter-efficient approach to scaling\npre-trained language models (PLMs) to a deeper model depth. Unlike prior work\nthat shares all parameters or uses extra blocks, we design a more capable\nparameter-sharing architecture based on matrix product operator (MPO). MPO\ndecomposition can reorganize and factorize the information of a parameter\nmatrix into two parts: the major part that contains the major information\n(central tensor) and the supplementary part that only has a small proportion of\nparameters (auxiliary tensors). Based on such a decomposition, our architecture\nshares the central tensor across all layers for reducing the model size and\nmeanwhile keeps layer-specific auxiliary tensors (also using adapters) for\nenhancing the adaptation flexibility. To improve the model training, we further\npropose a stable initialization algorithm tailored for the MPO-based\narchitecture. Extensive experiments have demonstrated the effectiveness of our\nproposed model in reducing the model size and achieving highly competitive\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1\">Ze-Feng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yushuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey of Large Language Models. (arXiv:2303.18223v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.18223","description":"<p>Language is essentially a complex, intricate system of human expressions\ngoverned by grammatical rules. It poses a significant challenge to develop\ncapable AI algorithms for comprehending and grasping a language. As a major\napproach, language modeling has been widely studied for language understanding\nand generation in the past two decades, evolving from statistical language\nmodels to neural language models. Recently, pre-trained language models (PLMs)\nhave been proposed by pre-training Transformer models over large-scale corpora,\nshowing strong capabilities in solving various NLP tasks. Since researchers\nhave found that model scaling can lead to performance improvement, they further\nstudy the scaling effect by increasing the model size to an even larger size.\nInterestingly, when the parameter scale exceeds a certain level, these enlarged\nlanguage models not only achieve a significant performance improvement but also\nshow some special abilities that are not present in small-scale language\nmodels. To discriminate the difference in parameter scale, the research\ncommunity has coined the term large language models (LLM) for the PLMs of\nsignificant size. Recently, the research on LLMs has been largely advanced by\nboth academia and industry, and a remarkable progress is the launch of ChatGPT,\nwhich has attracted widespread attention from society. The technical evolution\nof LLMs has been making an important impact on the entire AI community, which\nwould revolutionize the way how we develop and use AI algorithms. In this\nsurvey, we review the recent advances of LLMs by introducing the background,\nkey findings, and mainstream techniques. In particular, we focus on four major\naspects of LLMs, namely pre-training, adaptation tuning, utilization, and\ncapacity evaluation. Besides, we also summarize the available resources for\ndeveloping LLMs and discuss the remaining issues for future directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaolei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yupeng Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_Y/0/1/0/all/0/1\">Yingqian Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Beichen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Junjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zican Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yifan Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yushuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhipeng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jinhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1\">Ruiyang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1\">Xinyu Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zikang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its Applications, Advantages, Limitations, and Future Directions in Natural Language Processing. (arXiv:2304.02017v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.02017","description":"<p>Large language models have revolutionized the field of artificial\nintelligence and have been used in various applications. Among these models,\nChatGPT (Chat Generative Pre-trained Transformer) has been developed by OpenAI,\nit stands out as a powerful tool that has been widely adopted. ChatGPT has been\nsuccessfully applied in numerous areas, including chatbots, content generation,\nlanguage translation, personalized recommendations, and even medical diagnosis\nand treatment. Its success in these applications can be attributed to its\nability to generate human-like responses, understand natural language, and\nadapt to different contexts. Its versatility and accuracy make it a powerful\ntool for natural language processing (NLP). However, there are also limitations\nto ChatGPT, such as its tendency to produce biased responses and its potential\nto perpetuate harmful language patterns. This article provides a comprehensive\noverview of ChatGPT, its applications, advantages, and limitations.\nAdditionally, the paper emphasizes the importance of ethical considerations\nwhen using this robust tool in real-world scenarios. Finally, This paper\ncontributes to ongoing discussions surrounding artificial intelligence and its\nimpact on vision and NLP domains by providing insights into prompt engineering\ntechniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hariri_W/0/1/0/all/0/1\">Walid Hariri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Master Key: Unlocking the Secrets of Materials Science with GPT. (arXiv:2304.02213v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.02213","description":"<p>The amount of data has growing significance in exploring cutting-edge\nmaterials and a number of datasets have been generated either by hand or\nautomated approaches. However, the materials science field struggles to\neffectively utilize the abundance of data, especially in applied disciplines\nwhere materials are evaluated based on device performance rather than their\nproperties. This article presents a new natural language processing (NLP) task\ncalled structured information inference (SII) to address the complexities of\ninformation extraction at the device level in materials science. We\naccomplished this task by tuning GPT-3 on an existing perovskite solar cell\nFAIR (Findable, Accessible, Interoperable, Reusable) dataset with 91.8%\nF1-score and extended the dataset with data published since its release. The\nproduced data is formatted and normalized, enabling its direct utilization as\ninput in subsequent data analysis. This feature empowers materials scientists\nto develop models by selecting high-quality review articles within their\ndomain. Additionally, we designed experiments to predict the electrical\nperformance of solar cells and design materials or devices with targeted\nparameters using large language models (LLMs). Our results demonstrate\ncomparable performance to traditional machine learning methods without feature\nselection, highlighting the potential of LLMs to acquire scientific knowledge\nand design new materials akin to materials scientists.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1\">Tong Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yuwei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1\">Wei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yufei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yixuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linghu_Q/0/1/0/all/0/1\">Qingyuan Linghu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shaozhou Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kit_C/0/1/0/all/0/1\">Chunyu Kit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grazian_C/0/1/0/all/0/1\">Clara Grazian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenjie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoex_B/0/1/0/all/0/1\">Bram Hoex</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linking Representations with Multimodal Contrastive Learning. (arXiv:2304.03464v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2304.03464","description":"<p>Many applications require grouping instances contained in diverse document\ndatasets into classes. Most widely used methods do not employ deep learning and\ndo not exploit the inherently multimodal nature of documents. Notably, record\nlinkage is typically conceptualized as a string-matching problem. This study\ndevelops CLIPPINGS, (Contrastively Linking Pooled Pre-trained Embeddings), a\nmultimodal framework for record linkage. CLIPPINGS employs end-to-end training\nof symmetric vision and language bi-encoders, aligned through contrastive\nlanguage-image pre-training, to learn a metric space where the pooled\nimage-text representation for a given instance is close to representations in\nthe same class and distant from representations in different classes. At\ninference time, instances can be linked by retrieving their nearest neighbor\nfrom an offline exemplar embedding index or by clustering their\nrepresentations. The study examines two challenging applications: constructing\ncomprehensive supply chains for mid-20th century Japan through linking firm\nlevel financial records - with each firm name represented by its crop in the\ndocument image and the corresponding OCR - and detecting which image-caption\npairs in a massive corpus of historical U.S. newspapers came from the same\nunderlying photo wire source. CLIPPINGS outperforms widely used string matching\nmethods by a wide margin and also outperforms unimodal methods. Moreover, a\npurely self-supervised model trained on only image-OCR pairs also outperforms\npopular string-matching methods without requiring any labels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Abhishek Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xinmei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jheng_S/0/1/0/all/0/1\">Shao-Yu Jheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dell_M/0/1/0/all/0/1\">Melissa Dell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit. (arXiv:2304.04596v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2304.04596","description":"<p>ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by\nthe broadening interests of the spoken language translation community.\nESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2)\nsimultaneous speech-to-text translation (SST), and 3) offline speech-to-speech\ntranslation (S2ST) -- each task is supported with a wide variety of approaches,\ndifferentiating ESPnet-ST-v2 from other open source spoken language translation\ntoolkits. This toolkit offers state-of-the-art architectures such as\ntransducers, hybrid CTC/attention, multi-decoders with searchable\nintermediates, time-synchronous blockwise CTC/attention, Translatotron models,\nand direct discrete unit models. In this paper, we describe the overall design,\nexample models for each task, and performance benchmarking behind ESPnet-ST-v2,\nwhich is publicly available at https://github.com/espnet/espnet.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1\">Brian Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1\">Yun Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inaguma_H/0/1/0/all/0/1\">Hirofumi Inaguma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1\">Siddharth Dalmia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polak_P/0/1/0/all/0/1\">Peter Pol&#xe1;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1\">Patrick Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berrebbi_D/0/1/0/all/0/1\">Dan Berrebbi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hayashi_T/0/1/0/all/0/1\">Tomoki Hayashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaohui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1\">Zhaoheng Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hira_M/0/1/0/all/0/1\">Moto Hira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maiti_S/0/1/0/all/0/1\">Soumi Maiti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1\">Juan Pino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Approach Intelligent Writing Assistants Usability with Seven Stages of Action. (arXiv:2304.02822v1 [cs.HC] CROSS LISTED)","link":"http://arxiv.org/abs/2304.02822","description":"<p>Despite the potential of Large Language Models (LLMs) as writing assistants,\nthey are plagued by issues like coherence and fluency of the model output,\ntrustworthiness, ownership of the generated content, and predictability of\nmodel performance, thereby limiting their usability. In this position paper, we\npropose to adopt Norman's seven stages of action as a framework to approach the\ninteraction design of intelligent writing assistants. We illustrate the\nframework's applicability to writing tasks by providing an example of software\ntutorial authoring. The paper also discusses the framework as a tool to\nsynthesize research on the interaction design of LLM-based tools and presents\nexamples of tools that support the stages of action. Finally, we briefly\noutline the potential of a framework for human-LLM interaction research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhat_A/0/1/0/all/0/1\">Avinash Bhat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrivastava_D/0/1/0/all/0/1\">Disha Shrivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jin L.C. Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-04-11T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","admin":"http://webns.net/mvcb/"}}]}]}