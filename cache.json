{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-09T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Investigating Alternative Feature Extraction Pipelines For Clinical Note Phenotyping. (arXiv:2310.03772v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03772","description":"<p>A common practice in the medical industry is the use of clinical notes, which\nconsist of detailed patient observations. However, electronic health record\nsystems frequently do not contain these observations in a structured format,\nrendering patient information challenging to assess and evaluate automatically.\nUsing computational systems for the extraction of medical attributes offers\nmany applications, including longitudinal analysis of patients, risk\nassessment, and hospital evaluation. Recent work has constructed successful\nmethods for phenotyping: extracting medical attributes from clinical notes.\nBERT-based models can be used to transform clinical notes into a series of\nrepresentations, which are then condensed into a single document representation\nbased on their CLS embeddings and passed into an LSTM (Mulyar et al., 2020).\nThough this pipeline yields a considerable performance improvement over\nprevious results, it requires extensive convergence time. This method also does\nnot allow for predicting attributes not yet identified in clinical notes.\n</p>\n<p>Considering the wide variety of medical attributes that may be present in a\nclinical note, we propose an alternative pipeline utilizing ScispaCy (Neumann\net al., 2019) for the extraction of common diseases. We then train various\nsupervised learning models to associate the presence of these conditions with\npatient attributes. Finally, we replicate a ClinicalBERT (Alsentzer et al.,\n2019) and LSTM-based approach for purposes of comparison. We find that\nalternative methods moderately underperform the replicated LSTM approach. Yet,\nconsidering a complex tradeoff between accuracy and runtime, in addition to the\nfact that the alternative approach also allows for the detection of medical\nconditions that are not already present in a clinical note, its usage may be\nconsidered as a supplement to established methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Daniel_N/0/1/0/all/0/1\">Neil Daniel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PrIeD-KIE: Towards Privacy Preserved Document Key Information Extraction. (arXiv:2310.03777v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03777","description":"<p>In this paper, we introduce strategies for developing private Key Information\nExtraction (KIE) systems by leveraging large pretrained document foundation\nmodels in conjunction with differential privacy (DP), federated learning (FL),\nand Differentially Private Federated Learning (DP-FL). Through extensive\nexperimentation on six benchmark datasets (FUNSD, CORD, SROIE, WildReceipts,\nXFUND, and DOCILE), we demonstrate that large document foundation models can be\neffectively fine-tuned for the KIE task under private settings to achieve\nadequate performance while maintaining strong privacy guarantees. Moreover, by\nthoroughly analyzing the impact of various training and model parameters on\nmodel performance, we propose simple yet effective guidelines for achieving an\noptimal privacy-utility trade-off for the KIE task under global DP. Finally, we\nintroduce FeAm-DP, a novel DP-FL algorithm that enables efficiently upscaling\nglobal DP from a standalone context to a multi-client federated environment. We\nconduct a comprehensive evaluation of the algorithm across various client and\nprivacy settings, and demonstrate its capability to achieve comparable\nperformance and privacy guarantees to standalone DP, even when accommodating an\nincreasing number of participating clients. Overall, our study offers valuable\ninsights into the development of private KIE systems, and highlights the\npotential of document foundation models for privacy-preserved Document AI\napplications. To the best of authors' knowledge, this is the first work that\nexplores privacy preserved document KIE using document foundation models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Saifullah_S/0/1/0/all/0/1\">Saifullah Saifullah</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Agne_S/0/1/0/all/0/1\">Stefan Agne</a> (2 and 3), <a href=\"http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1\">Andreas Dengel</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1\">Sheraz Ahmed</a> (2 and 3) ((1) Department of Computer Science, University of Kaiserslautern-Landau, Kaiserslautern, Rhineland-Palatinate, Germany, (2) German Research Center for Artificial Intelligence, DFKI GmbH, Kaiserslautern, Rhineland-Palatinate, Germany, (3) DeepReader GmbH, Kaiserlautern, Germany)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HandMeThat: Human-Robot Communication in Physical and Social Environments. (arXiv:2310.03779v1 [cs.AI])","link":"http://arxiv.org/abs/2310.03779","description":"<p>We introduce HandMeThat, a benchmark for a holistic evaluation of instruction\nunderstanding and following in physical and social environments. While previous\ndatasets primarily focused on language grounding and planning, HandMeThat\nconsiders the resolution of human instructions with ambiguities based on the\nphysical (object states and relations) and social (human actions and goals)\ninformation. HandMeThat contains 10,000 episodes of human-robot interactions.\nIn each episode, the robot first observes a trajectory of human actions towards\nher internal goal. Next, the robot receives a human instruction and should take\nactions to accomplish the subgoal set through the instruction. In this paper,\nwe present a textual interface for our benchmark, where the robot interacts\nwith a virtual environment through textual commands. We evaluate several\nbaseline models on HandMeThat, and show that both offline and online\nreinforcement learning algorithms perform poorly on HandMeThat, suggesting\nsignificant room for future work on physical and social human-robot\ncommunications and interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yanming Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_J/0/1/0/all/0/1\">Jiayuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1\">Joshua B. Tenenbaum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Contextualized Structural Self-supervised Learning for Ontology Matching. (arXiv:2310.03840v1 [cs.LG])","link":"http://arxiv.org/abs/2310.03840","description":"<p>Ontology matching (OM) entails the identification of semantic relationships\nbetween concepts within two or more knowledge graphs (KGs) and serves as a\ncritical step in integrating KGs from various sources. Recent advancements in\ndeep OM models have harnessed the power of transformer-based language models\nand the advantages of knowledge graph embedding. Nevertheless, these OM models\nstill face persistent challenges, such as a lack of reference alignments,\nruntime latency, and unexplored different graph structures within an end-to-end\nframework. In this study, we introduce a novel self-supervised learning OM\nframework with input ontologies, called LaKERMap. This framework capitalizes on\nthe contextual and structural information of concepts by integrating implicit\nknowledge into transformers. Specifically, we aim to capture multiple\nstructural contexts, encompassing both local and global interactions, by\nemploying distinct training objectives. To assess our methods, we utilize the\nBio-ML datasets and tasks. The findings from our innovative approach reveal\nthat LaKERMap surpasses state-of-the-art systems in terms of alignment quality\nand inference time. Our models and codes are available here:\nhttps://github.com/ellenzhuwang/lakermap.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhu Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking a foundation LLM on its ability to re-label structure names in accordance with the AAPM TG-263 report. (arXiv:2310.03874v1 [physics.med-ph])","link":"http://arxiv.org/abs/2310.03874","description":"<p>Purpose: To introduce the concept of using large language models (LLMs) to\nre-label structure names in accordance with the American Association of\nPhysicists in Medicine (AAPM) Task Group (TG)-263 standard, and to establish a\nbenchmark for future studies to reference.\n</p>\n<p>Methods and Materials: The Generative Pre-trained Transformer (GPT)-4\napplication programming interface (API) was implemented as a Digital Imaging\nand Communications in Medicine (DICOM) storage server, which upon receiving a\nstructure set DICOM file, prompts GPT-4 to re-label the structure names of both\ntarget volumes and normal tissues according to the AAPM TG-263. Three disease\nsites, prostate, head and neck, and thorax were selected for evaluation. For\neach disease site category, 150 patients were randomly selected for manually\ntuning the instructions prompt (in batches of 50) and 50 patients were randomly\nselected for evaluation. Structure names that were considered were those that\nwere most likely to be relevant for studies utilizing structure contours for\nmany patients.\n</p>\n<p>Results: The overall re-labeling accuracy of both target volumes and normal\ntissues for prostate, head and neck, and thorax cases was 96.0%, 98.5%, and\n96.9% respectively. Re-labeling of target volumes was less accurate on average\nexcept for prostate - 100%, 93.1%, and 91.1% respectively.\n</p>\n<p>Conclusions: Given the accuracy of GPT-4 in re-labeling structure names of\nboth target volumes and normal tissues as presented in this work, LLMs are\npoised to be the preferred method for standardizing structure names in\nradiation oncology, especially considering the rapid advancements in LLM\ncapabilities that are likely to continue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Holmes_J/0/1/0/all/0/1\">Jason Holmes</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Zhang_L/0/1/0/all/0/1\">Lian Zhang</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ding_Y/0/1/0/all/0/1\">Yuzhen Ding</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Feng_H/0/1/0/all/0/1\">Hongying Feng</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_Z/0/1/0/all/0/1\">Zhengliang Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_T/0/1/0/all/0/1\">Tianming Liu</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Wong_W/0/1/0/all/0/1\">William W. Wong</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Vora_S/0/1/0/all/0/1\">Sujay A. Vora</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Ashman_J/0/1/0/all/0/1\">Jonathan B. Ashman</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic and Human-AI Interactive Text Generation. (arXiv:2310.03878v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03878","description":"<p>In this tutorial, we focus on text-to-text generation, a class of natural\nlanguage generation (NLG) tasks, that takes a piece of text as input and then\ngenerates a revision that is improved according to some specific criteria\n(e.g., readability or linguistic styles), while largely retaining the original\nmeaning and the length of the text. This includes many useful applications,\nsuch as text simplification, paraphrase generation, style transfer, etc. In\ncontrast to text summarization and open-ended text completion (e.g., story),\nthe text-to-text generation tasks we discuss in this tutorial are more\nconstrained in terms of semantic consistency and targeted language styles. This\nlevel of control makes these tasks ideal testbeds for studying the ability of\nmodels to generate text that is both semantically adequate and stylistically\nappropriate. Moreover, these tasks are interesting from a technical standpoint,\nas they require complex combinations of lexical and syntactical\ntransformations, stylistic control, and adherence to factual knowledge, -- all\nat once. With a special focus on text simplification and revision, this\ntutorial aims to provide an overview of the state-of-the-art natural language\ngeneration research from four major aspects -- Data, Models, Human-AI\nCollaboration, and Evaluation -- and to discuss and showcase a few significant\nand recent advances: (1) the use of non-retrogressive approaches; (2) the shift\nfrom fine-tuning to prompting with large language models; (3) the development\nof new learnable metric and fine-grained human evaluation framework; (4) a\ngrowing body of studies and datasets on non-English languages; (5) the rise of\nHCI+NLP+Accessibility interdisciplinary research to create real-world writing\nassistant systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1\">Yao Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1\">Philippe Laban</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gardent_C/0/1/0/all/0/1\">Claire Gardent</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trustworthy Formal Natural Language Specifications. (arXiv:2310.03885v1 [cs.PL])","link":"http://arxiv.org/abs/2310.03885","description":"<p>Interactive proof assistants are computer programs carefully constructed to\ncheck a human-designed proof of a mathematical claim with high confidence in\nthe implementation. However, this only validates truth of a formal claim, which\nmay have been mistranslated from a claim made in natural language. This is\nespecially problematic when using proof assistants to formally verify the\ncorrectness of software with respect to a natural language specification. The\ntranslation from informal to formal remains a challenging, time-consuming\nprocess that is difficult to audit for correctness.\n</p>\n<p>This paper shows that it is possible to build support for specifications\nwritten in expressive subsets of natural language, within existing proof\nassistants, consistent with the principles used to establish trust and\nauditability in proof assistants themselves. We implement a means to provide\nspecifications in a modularly extensible formal subset of English, and have\nthem automatically translated into formal claims, entirely within the Lean\nproof assistant. Our approach is extensible (placing no permanent restrictions\non grammatical structure), modular (allowing information about new words to be\ndistributed alongside libraries), and produces proof certificates explaining\nhow each word was interpreted and how the sentence's structure was used to\ncompute the meaning.\n</p>\n<p>We apply our prototype to the translation of various English descriptions of\nformal specifications from a popular textbook into Lean formalizations; all can\nbe translated correctly with a modest lexicon with only minor modifications\nrelated to lexicon size.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gordon_C/0/1/0/all/0/1\">Colin S. Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matskevich_S/0/1/0/all/0/1\">Sergey Matskevich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Multi-Agent Coordination Abilities in Large Language Models. (arXiv:2310.03903v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03903","description":"<p>A pivotal aim in contemporary AI research is to develop agents proficient in\nmulti-agent coordination, enabling effective collaboration with both humans and\nother systems. Large Language Models (LLMs), with their notable ability to\nunderstand, generate, and interpret language in a human-like manner, stand out\nas promising candidates for the development of such agents. In this study, we\nbuild and assess the effectiveness of agents crafted using LLMs in various\ncoordination scenarios. We introduce the LLM-Coordination (LLM-Co) Framework,\nspecifically designed to enable LLMs to play coordination games. With the\nLLM-Co framework, we conduct our evaluation with three game environments and\norganize the evaluation into five aspects: Theory of Mind, Situated Reasoning,\nSustained Coordination, Robustness to Partners, and Explicit Assistance. First,\nthe evaluation of the Theory of Mind and Situated Reasoning reveals the\ncapabilities of LLM to infer the partner's intention and reason actions\naccordingly. Then, the evaluation around Sustained Coordination and Robustness\nto Partners further showcases the ability of LLMs to coordinate with an unknown\npartner in complex long-horizon tasks, outperforming Reinforcement Learning\nbaselines. Lastly, to test Explicit Assistance, which refers to the ability of\nan agent to offer help proactively, we introduce two novel layouts into the\nOvercooked-AI benchmark, examining if agents can prioritize helping their\npartners, sacrificing time that could have been spent on their tasks. This\nresearch underscores the promising capabilities of LLMs in sophisticated\ncoordination environments and reveals the potential of LLMs in building strong\nreal-world agents for multi-agent coordination.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agashe_S/0/1/0/all/0/1\">Saaket Agashe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1\">Yue Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the evolution of research topics during the COVID-19 pandemic. (arXiv:2310.03928v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03928","description":"<p>The COVID-19 pandemic has changed the research agendas of most scientific\ncommunities, resulting in an overwhelming production of research articles in a\nvariety of domains, including medicine, virology, epidemiology, economy,\npsychology, and so on. Several open-access corpora and literature hubs were\nestablished; among them, the COVID-19 Open Research Dataset (CORD-19) has\nsystematically gathered scientific contributions for 2.5 years, by collecting\nand indexing over one million articles. Here, we present the CORD-19 Topic\nVisualizer (CORToViz), a method and associated visualization tool for\ninspecting the CORD-19 textual corpus of scientific abstracts. Our method is\nbased upon a careful selection of up-to-date technologies (including large\nlanguage models), resulting in an architecture for clustering articles along\northogonal dimensions and extraction techniques for temporal topic mining.\nTopic inspection is supported by an interactive dashboard, providing fast,\none-click visualization of topic contents as word clouds and topic trends as\ntime series, equipped with easy-to-drive statistical testing for analyzing the\nsignificance of topic emergence along arbitrarily selected time windows. The\nprocesses of data preparation and results visualization are completely general\nand virtually applicable to any corpus of textual documents - thus suited for\neffective adaptation to other contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Invernici_F/0/1/0/all/0/1\">Francesco Invernici</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bernasconi_A/0/1/0/all/0/1\">Anna Bernasconi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ceri_S/0/1/0/all/0/1\">Stefano Ceri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chain of Natural Language Inference for Reducing Large Language Model Ungrounded Hallucinations. (arXiv:2310.03951v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03951","description":"<p>Large language models (LLMs) can generate fluent natural language texts when\ngiven relevant documents as background context. This ability has attracted\nconsiderable interest in developing industry applications of LLMs. However,\nLLMs are prone to generate hallucinations that are not supported by the\nprovided sources. In this paper, we propose a hierarchical framework to detect\nand mitigate such ungrounded hallucination. Our framework uses Chain of Natural\nLanguage Inference (CoNLI) for hallucination detection and hallucination\nreduction via post-editing. Our approach achieves state-of-the-art performance\non hallucination detection and enhances text quality through rewrite, using\nLLMs without any fine-tuning or domain-specific prompt engineering. We show\nthat this simple plug-and-play framework can serve as an effective choice for\nhallucination detection and reduction, achieving competitive performance across\nvarious contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lei_D/0/1/0/all/0/1\">Deren Lei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yaxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mengya/0/1/0/all/0/1\">Mengya</a> (Mia)Hu, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Mingyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yun_V/0/1/0/all/0/1\">Vincent Yun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ching_E/0/1/0/all/0/1\">Emily Ching</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_E/0/1/0/all/0/1\">Eslam Kamal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Thought Propagation: An Analogical Approach to Complex Reasoning with Large Language Models. (arXiv:2310.03965v1 [cs.AI])","link":"http://arxiv.org/abs/2310.03965","description":"<p>Large Language Models (LLMs) have achieved remarkable success in reasoning\ntasks with the development of prompting methods. However, existing prompting\napproaches cannot reuse insights of solving similar problems and suffer from\naccumulated errors in multi-step reasoning, since they prompt LLMs to reason\n\\textit{from scratch}. To address these issues, we propose\n\\textbf{\\textit{Thought Propagation} (TP)}, which explores the analogous\nproblems and leverages their solutions to enhance the complex reasoning ability\nof LLMs. These analogous problems are related to the input one, with reusable\nsolutions and problem-solving strategies. Thus, it is promising to propagate\ninsights of solving previous analogous problems to inspire new problem-solving.\nTo achieve this, TP first prompts LLMs to propose and solve a set of analogous\nproblems that are related to the input one. Then, TP reuses the results of\nanalogous problems to directly yield a new solution or derive a\nknowledge-intensive plan for execution to amend the initial solution obtained\nfrom scratch. TP is compatible with existing prompting approaches, allowing\nplug-and-play generalization and enhancement in a wide range of tasks without\nmuch labor in task-specific prompt engineering. Experiments across three\nchallenging tasks demonstrate TP enjoys a substantial improvement over the\nbaselines by an average of 12\\% absolute increase in finding the optimal\nsolutions in Shortest-path Reasoning, 13\\% improvement of human preference in\nCreative Writing, and 15\\% enhancement in the task completion rate of LLM-Agent\nPlanning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Junchi Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ran He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1\">Rex Ying</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Quantized Transformer Language Model Implementations on Edge Devices. (arXiv:2310.03971v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03971","description":"<p>Large-scale transformer-based models like the Bidirectional Encoder\nRepresentations from Transformers (BERT) are widely used for Natural Language\nProcessing (NLP) applications, wherein these models are initially pre-trained\nwith a large corpus with millions of parameters and then fine-tuned for a\ndownstream NLP task. One of the major limitations of these large-scale models\nis that they cannot be deployed on resource-constrained devices due to their\nlarge model size and increased inference latency. In order to overcome these\nlimitations, such large-scale models can be converted to an optimized\nFlatBuffer format, tailored for deployment on resource-constrained edge\ndevices. Herein, we evaluate the performance of such FlatBuffer transformed\nMobileBERT models on three different edge devices, fine-tuned for Reputation\nanalysis of English language tweets in the RepLab 2013 dataset. In addition,\nthis study encompassed an evaluation of the deployed models, wherein their\nlatency, performance, and resource efficiency were meticulously assessed. Our\nexperiment results show that, compared to the original BERT large model, the\nconverted and quantized MobileBERT models have 160$\\times$ smaller footprints\nfor a 4.1% drop in accuracy while analyzing at least one tweet per second on\nedge devices. Furthermore, our study highlights the privacy-preserving aspect\nof TinyML systems as all data is processed locally within a serverless\nenvironment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mohammad Wali Ur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abrar_M/0/1/0/all/0/1\">Murad Mehrab Abrar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Copening_H/0/1/0/all/0/1\">Hunter Gibbons Copening</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hariri_S/0/1/0/all/0/1\">Salim Hariri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1\">Sicong Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Satam_P/0/1/0/all/0/1\">Pratik Satam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salehi_S/0/1/0/all/0/1\">Soheil Salehi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HuBERTopic: Enhancing Semantic Representation of HuBERT through Self-supervision Utilizing Topic Model. (arXiv:2310.03975v1 [cs.SD])","link":"http://arxiv.org/abs/2310.03975","description":"<p>Recently, the usefulness of self-supervised representation learning (SSRL)\nmethods has been confirmed in various downstream tasks. Many of these models,\nas exemplified by HuBERT and WavLM, use pseudo-labels generated from spectral\nfeatures or the model's own representation features. From previous studies, it\nis known that the pseudo-labels contain semantic information. However, the\nmasked prediction task, the learning criterion of HuBERT, focuses on local\ncontextual information and may not make effective use of global semantic\ninformation such as speaker, theme of speech, and so on. In this paper, we\npropose a new approach to enrich the semantic representation of HuBERT. We\napply topic model to pseudo-labels to generate a topic label for each\nutterance. An auxiliary topic classification task is added to HuBERT by using\ntopic labels as teachers. This allows additional global semantic information to\nbe incorporated in an unsupervised manner. Experimental results demonstrate\nthat our method achieves comparable or better performance than the baseline in\nmost tasks, including automatic speech recognition and five out of the eight\nSUPERB tasks. Moreover, we find that topic labels include various information\nabout utterance, such as gender, speaker, and its theme. This highlights the\neffectiveness of our approach in capturing multifaceted semantic nuances.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maekaku_T/0/1/0/all/0/1\">Takashi Maekaku</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1\">Xuankai Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fujita_Y/0/1/0/all/0/1\">Yuya Fujita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dementia Assessment Using Mandarin Speech with an Attention-based Speech Recognition Encoder. (arXiv:2310.03985v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03985","description":"<p>Dementia diagnosis requires a series of different testing methods, which is\ncomplex and time-consuming. Early detection of dementia is crucial as it can\nprevent further deterioration of the condition. This paper utilizes a speech\nrecognition model to construct a dementia assessment system tailored for\nMandarin speakers during the picture description task. By training an\nattention-based speech recognition model on voice data closely resembling\nreal-world scenarios, we have significantly enhanced the model's recognition\ncapabilities. Subsequently, we extracted the encoder from the speech\nrecognition model and added a linear layer for dementia assessment. We\ncollected Mandarin speech data from 99 subjects and acquired their clinical\nassessments from a local hospital. We achieved an accuracy of 92.04% in\nAlzheimer's disease detection and a mean absolute error of 9% in clinical\ndementia rating score prediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1\">Zih-Jyun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Ju Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuo_P/0/1/0/all/0/1\">Po-Chih Kuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Likai Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1\">Chaur-Jong Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Cheng-Yu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation. (arXiv:2310.03991v1 [cs.CL])","link":"http://arxiv.org/abs/2310.03991","description":"<p>Existing watermarking algorithms are vulnerable to paraphrase attacks because\nof their token-level design. To address this issue, we propose SemStamp, a\nrobust sentence-level semantic watermarking algorithm based on\nlocality-sensitive hashing (LSH), which partitions the semantic space of\nsentences. The algorithm encodes and LSH-hashes a candidate sentence generated\nby an LLM, and conducts sentence-level rejection sampling until the sampled\nsentence falls in watermarked partitions in the semantic embedding space. A\nmargin-based constraint is used to enhance its robustness. To show the\nadvantages of our algorithm, we propose a \"bigram\" paraphrase attack using the\nparaphrase that has the fewest bigram overlaps with the original sentence. This\nattack is shown to be effective against the existing token-level watermarking\nmethod. Experimental results show that our novel semantic watermark algorithm\nis not only more robust than the previous state-of-the-art method on both\ncommon and bigram paraphrase attacks, but also is better at preserving the\nquality of generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hou_A/0/1/0/all/0/1\">Abe Bohan Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jingyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1\">Tianxing He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yichen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1\">Yung-Sung Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongwei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Financial Sentiment Analysis via Retrieval Augmented Large Language Models. (arXiv:2310.04027v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04027","description":"<p>Financial sentiment analysis is critical for valuation and investment\ndecision-making. Traditional NLP models, however, are limited by their\nparameter size and the scope of their training datasets, which hampers their\ngeneralization capabilities and effectiveness in this field. Recently, Large\nLanguage Models (LLMs) pre-trained on extensive corpora have demonstrated\nsuperior performance across various NLP tasks due to their commendable\nzero-shot abilities. Yet, directly applying LLMs to financial sentiment\nanalysis presents challenges: The discrepancy between the pre-training\nobjective of LLMs and predicting the sentiment label can compromise their\npredictive performance. Furthermore, the succinct nature of financial news,\noften devoid of sufficient context, can significantly diminish the reliability\nof LLMs' sentiment analysis. To address these challenges, we introduce a\nretrieval-augmented LLMs framework for financial sentiment analysis. This\nframework includes an instruction-tuned LLMs module, which ensures LLMs behave\nas predictors of sentiment labels, and a retrieval-augmentation module which\nretrieves additional context from reliable external sources. Benchmarked\nagainst traditional models and LLMs like ChatGPT and LLaMA, our approach\nachieves 15\\% to 48\\% performance gain in accuracy and F1 score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1\">Boyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Hongyang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babar_A/0/1/0/all/0/1\">Ali Babar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao-Yang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analysis of the Reasoning with Redundant Information Provided Ability of Large Language Models. (arXiv:2310.04039v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04039","description":"<p>Recent advancements in Large Language Models (LLMs) have demonstrated\nimpressive capabilities across a range of natural language processing tasks,\nespecially in reasoning, a cornerstone for achieving Artificial General\nIntelligence (AGI). However, commonly used benchmarks may not fully encapsulate\nthe inferential abilities of these models in real-world scenarios. To address\nthis gap, a new form of Question-Answering (QA) task, termed Reasoning with\nRedundant Information Provided (RRIP), is introduced. The study designed a\nmodified version of the grade school math 8K (GSM-8K) dataset which has several\nvariants focusing on different attributes of redundant information. This\ninvestigation evaluates two popular LLMs, LlaMA2-13B-chat and generative\npre-trained transformer 3.5 (GPT-3.5), contrasting their performance on\ntraditional QA tasks against the RRIP tasks. Findings indicate that while these\nmodels achieved moderate success on standard QA benchmarks, their performance\nnotably declines when assessed on RRIP tasks. The study not only highlights the\nlimitations of current LLMs in handling redundant information but also suggests\nthat future training of these models should focus on incorporating redundant\ninformation into the training data to increase the performance on RRIP tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1\">Wenbei Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation. (arXiv:2310.04064v1 [cs.DS])","link":"http://arxiv.org/abs/2310.04064","description":"<p>In the classical transformer attention scheme, we are given three $n \\times\nd$ size matrices $Q, K, V$ (the query, key, and value tokens), and the goal is\nto compute a new $n \\times d$ size matrix $D^{-1} \\exp(QK^\\top) V$ where $D =\n\\mathrm{diag}( \\exp(QK^\\top) {\\bf 1}_n )$. In this work, we study a\ngeneralization of attention which captures triple-wise correlations. This\ngeneralization is able to solve problems about detecting triple-wise\nconnections that were shown to be impossible for transformers. The potential\ndownside of this generalization is that it appears as though computations are\neven more difficult, since the straightforward algorithm requires cubic time in\n$n$. However, we show that in the bounded-entry setting (which arises in\npractice, and which is well-studied in both theory and practice), there is\nactually a near-linear time algorithm. More precisely, we show that bounded\nentries are both necessary and sufficient for quickly performing generalized\ncomputations:\n</p>\n<p>$\\bullet$ On the positive side, if all entries of the input matrices are\nbounded above by $o(\\sqrt[3]{\\log n})$ then we show how to approximate the\n``tensor-type'' attention matrix in $n^{1+o(1)}$ time.\n</p>\n<p>$\\bullet$ On the negative side, we show that if the entries of the input\nmatrices may be as large as $\\Omega(\\sqrt[3]{\\log n})$, then there is no\nalgorithm that runs faster than $n^{3-o(1)}$ (assuming the Strong Exponential\nTime Hypothesis from fine-grained complexity theory).\n</p>\n<p>We also show that our construction, algorithms, and lower bounds naturally\ngeneralize to higher-order tensors and correlations. Interestingly, the higher\nthe order of the tensors, the lower the bound on the entries needs to be for an\nefficient algorithm. Our results thus yield a natural tradeoff between the\nboundedness of the entries, and order of the tensor one may use for more\nexpressive, efficient attention computation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alman_J/0/1/0/all/0/1\">Josh Alman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhao Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Aspect Extraction from Scientific Texts. (arXiv:2310.04074v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04074","description":"<p>Being able to extract from scientific papers their main points, key insights,\nand other important information, referred to here as aspects, might facilitate\nthe process of conducting a scientific literature review. Therefore, the aim of\nour research is to create a tool for automatic aspect extraction from\nRussian-language scientific texts of any domain. In this paper, we present a\ncross-domain dataset of scientific texts in Russian, annotated with such\naspects as Task, Contribution, Method, and Conclusion, as well as a baseline\nalgorithm for aspect extraction, based on the multilingual BERT model\nfine-tuned on our data. We show that there are some differences in aspect\nrepresentation in different domains, but even though our model was trained on a\nlimited number of scientific domains, it is still able to generalize to new\ndomains, as was proved by cross-domain experiments. The code and the dataset\nare available at\n\\url{https://github.com/anna-marshalova/automatic-aspect-extraction-from-scientific-texts}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Marshalova_A/0/1/0/all/0/1\">Anna Marshalova</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bruches_E/0/1/0/all/0/1\">Elena Bruches</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batura_T/0/1/0/all/0/1\">Tatiana Batura</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"mlirSynth: Automatic, Retargetable Program Raising in Multi-Level IR using Program Synthesis. (arXiv:2310.04196v1 [cs.PL])","link":"http://arxiv.org/abs/2310.04196","description":"<p>MLIR is an emerging compiler infrastructure for modern hardware, but existing\nprograms cannot take advantage of MLIR's high-performance compilation if they\nare described in lower-level general purpose languages. Consequently, to avoid\nprograms needing to be rewritten manually, this has led to efforts to\nautomatically raise lower-level to higher-level dialects in MLIR. However,\ncurrent methods rely on manually-defined raising rules, which limit their\napplicability and make them challenging to maintain as MLIR dialects evolve.\n</p>\n<p>We present mlirSynth -- a novel approach which translates programs from\nlower-level MLIR dialects to high-level ones without manually defined rules.\nInstead, it uses available dialect definitions to construct a program space and\nsearches it effectively using type constraints and equivalences. We demonstrate\nits effectiveness \\revi{by raising C programs} to two distinct high-level MLIR\ndialects, which enables us to use existing high-level dialect specific\ncompilation flows. On Polybench, we show a greater coverage than previous\napproaches, resulting in geomean speedups of 2.5x (Intel) and 3.4x (AMD) over\nstate-of-the-art compilation flows for the C programming language. mlirSynth\nalso enables retargetability to domain-specific accelerators, resulting in a\ngeomean speedup of 21.6x on a TPU.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brauckmann_A/0/1/0/all/0/1\">Alexander Brauckmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polgreen_E/0/1/0/all/0/1\">Elizabeth Polgreen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grosser_T/0/1/0/all/0/1\">Tobias Grosser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OBoyle_M/0/1/0/all/0/1\">Michael F. P. O&#x27;Boyle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Keyword Augmented Retrieval: Novel framework for Information Retrieval integrated with speech interface. (arXiv:2310.04205v1 [cs.IR])","link":"http://arxiv.org/abs/2310.04205","description":"<p>Retrieving answers in a quick and low cost manner without hallucinations from\na combination of structured and unstructured data using Language models is a\nmajor hurdle which prevents employment of Language models in knowledge\nretrieval automation. This becomes accentuated when one wants to integrate a\nspeech interface. Besides, for commercial search and chatbot applications,\ncomplete reliance on commercial large language models (LLMs) like GPT 3.5 etc.\ncan be very costly. In this work, authors have addressed this problem by first\ndeveloping a keyword based search framework which augments discovery of the\ncontext to be provided to the large language model. The keywords in turn are\ngenerated by LLM and cached for comparison with keywords generated by LLM\nagainst the query raised. This significantly reduces time and cost to find the\ncontext within documents. Once the context is set, LLM uses that to provide\nanswers based on a prompt tailored for Q&amp;A. This research work demonstrates\nthat use of keywords in context identification reduces the overall inference\ntime and cost of information retrieval. Given this reduction in inference time\nand cost with the keyword augmented retrieval framework, a speech based\ninterface for user input and response readout was integrated. This allowed a\nseamless interaction with the language model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Purwar_A/0/1/0/all/0/1\">Anupam Purwar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundar_R/0/1/0/all/0/1\">Rahul Sundar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Written and spoken corpus of real and fake social media postings about COVID-19. (arXiv:2310.04237v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04237","description":"<p>This study investigates the linguistic traits of fake news and real news.\nThere are two parts to this study: text data and speech data. The text data for\nthis study consisted of 6420 COVID-19 related tweets re-filtered from Patwa et\nal. (2021). After cleaning, the dataset contained 3049 tweets, with 2161\nlabeled as 'real' and 888 as 'fake'. The speech data for this study was\ncollected from TikTok, focusing on COVID-19 related videos. Research assistants\nfact-checked each video's content using credible sources and labeled them as\n'Real', 'Fake', or 'Questionable', resulting in a dataset of 91 real entries\nand 109 fake entries from 200 TikTok videos with a total word count of 53,710\nwords. The data was analysed using the Linguistic Inquiry and Word Count (LIWC)\nsoftware to detect patterns in linguistic data. The results indicate a set of\nlinguistic features that distinguish fake news from real news in both written\nand speech data. This offers valuable insights into the role of language in\nshaping trust, social media interactions, and the propagation of fake news.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chin_N/0/1/0/all/0/1\">Ng Bee Chin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nicole_N/0/1/0/all/0/1\">Ng Zhi Ee Nicole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwan_K/0/1/0/all/0/1\">Kyla Kwan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dylann_L/0/1/0/all/0/1\">Lee Yong Han Dylann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1\">Liu Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1\">Xu Hong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comprehensive Evaluation of Large Language Models on Benchmark Biomedical Text Processing Tasks. (arXiv:2310.04270v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04270","description":"<p>Recently, Large Language Models (LLM) have demonstrated impressive capability\nto solve a wide range of tasks. However, despite their success across various\ntasks, no prior work has investigated their capability in the biomedical domain\nyet. To this end, this paper aims to evaluate the performance of LLMs on\nbenchmark biomedical tasks. For this purpose, we conduct a comprehensive\nevaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets.\nTo the best of our knowledge, this is the first work that conducts an extensive\nevaluation and comparison of various LLMs in the biomedical domain.\nInterestingly, we find based on our evaluation that in biomedical datasets that\nhave smaller training sets, zero-shot LLMs even outperform the current\nstate-of-the-art fine-tuned biomedical models. This suggests that pretraining\non large text corpora makes LLMs quite specialized even in the biomedical\ndomain. We also find that not a single LLM can outperform other LLMs in all\ntasks, with the performance of different LLMs may vary depending on the task.\nWhile their performance is still quite poor in comparison to the biomedical\nmodels that were fine-tuned on large training sets, our findings demonstrate\nthat LLMs have the potential to be a valuable tool for various biomedical tasks\nthat lack large annotated data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jahan_I/0/1/0/all/0/1\">Israt Jahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Laskar_M/0/1/0/all/0/1\">Md Tahmid Rahman Laskar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1\">Chun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jimmy Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large-Scale Korean Text Dataset for Classifying Biased Speech in Real-World Online Services. (arXiv:2310.04313v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04313","description":"<p>With the growth of online services, the need for advanced text classification\nalgorithms, such as sentiment analysis and biased text detection, has become\nincreasingly evident. The anonymous nature of online services often leads to\nthe presence of biased and harmful language, posing challenges to maintaining\nthe health of online communities. This phenomenon is especially relevant in\nSouth Korea, where large-scale hate speech detection algorithms have not yet\nbeen broadly explored. In this paper, we introduce a new comprehensive,\nlarge-scale dataset collected from a well-known South Korean SNS platform. Our\nproposed dataset provides annotations including (1) Preferences, (2)\nProfanities, and (3) Nine types of Bias for the text samples, enabling\nmulti-task learning for simultaneous classification of user-generated texts.\nLeveraging state-of-the-art BERT-based language models, our approach surpasses\nhuman-level accuracy across diverse classification tasks, as measured by\nvarious metrics. Beyond academic contributions, our work can provide practical\nsolutions for real-world hate speech and bias mitigation, contributing directly\nto the improvement of online community health. Our work provides a robust\nfoundation for future research aiming to improve the quality of online\ndiscourse and foster societal well-being. All source codes and datasets are\npublicly accessible at https://github.com/Dasol-Choi/KoMultiText.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1\">Dasol Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1\">Jooyoung Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1\">Eunsun Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1\">Jinwoo Seo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1\">Heejune Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Na_D/0/1/0/all/0/1\">Dongbin Na</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transferring speech-generic and depression-specific knowledge for Alzheimer's disease detection. (arXiv:2310.04358v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04358","description":"<p>The detection of Alzheimer's disease (AD) from spontaneous speech has\nattracted increasing attention while the sparsity of training data remains an\nimportant issue. This paper handles the issue by knowledge transfer,\nspecifically from both speech-generic and depression-specific knowledge. The\npaper first studies sequential knowledge transfer from generic foundation\nmodels pretrained on large amounts of speech and text data. A block-wise\nanalysis is performed for AD diagnosis based on the representations extracted\nfrom different intermediate blocks of different foundation models. Apart from\nthe knowledge from speech-generic representations, this paper also proposes to\nsimultaneously transfer the knowledge from a speech depression detection task\nbased on the high comorbidity rates of depression and AD. A parallel knowledge\ntransfer framework is studied that jointly learns the information shared\nbetween these two tasks. Experimental results show that the proposed method\nimproves AD and depression detection, and produces a state-of-the-art F1 score\nof 0.928 for AD diagnosis on the commonly used ADReSSo dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1\">Ziyun Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wen Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Qiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Ji Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chao Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Amortizing intractable inference in large language models. (arXiv:2310.04363v1 [cs.LG])","link":"http://arxiv.org/abs/2310.04363","description":"<p>Autoregressive large language models (LLMs) compress knowledge from their\ntraining data through next-token conditional distributions. This limits\ntractable querying of this knowledge to start-to-end autoregressive sampling.\nHowever, many tasks of interest -- including sequence continuation, infilling,\nand other forms of constrained generation -- involve sampling from intractable\nposterior distributions. We address this limitation by using amortized Bayesian\ninference to sample from these intractable posteriors. Such amortization is\nalgorithmically achieved by fine-tuning LLMs via diversity-seeking\nreinforcement learning algorithms: generative flow networks (GFlowNets). We\nempirically demonstrate that this distribution-matching paradigm of LLM\nfine-tuning can serve as an effective alternative to maximum-likelihood\ntraining and reward-maximizing policy optimization. As an important\napplication, we interpret chain-of-thought reasoning as a latent variable\nmodeling problem and demonstrate that our approach enables data-efficient\nadaptation of LLMs to tasks that require multi-step rationalization and tool\nuse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1\">Edward J. Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_M/0/1/0/all/0/1\">Moksh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmoznino_E/0/1/0/all/0/1\">Eric Elmoznino</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kaddar_Y/0/1/0/all/0/1\">Younesse Kaddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lajoie_G/0/1/0/all/0/1\">Guillaume Lajoie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1\">Yoshua Bengio</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Malkin_N/0/1/0/all/0/1\">Nikolay Malkin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hermes: Unlocking Security Analysis of Cellular Network Protocols by Synthesizing Finite State Machines from Natural Language Specifications. (arXiv:2310.04381v1 [cs.CR])","link":"http://arxiv.org/abs/2310.04381","description":"<p>In this paper, we present Hermes, an end-to-end framework to automatically\ngenerate formal representations from natural language cellular specifications.\nWe first develop a neural constituency parser, NEUTREX, to process\ntransition-relevant texts and extract transition components (i.e., states,\nconditions, and actions). We also design a domain-specific language to\ntranslate these transition components to logical formulas by leveraging\ndependency parse trees. Finally, we compile these logical formulas to generate\ntransitions and create the formal model as finite state machines. To\ndemonstrate the effectiveness of Hermes, we evaluate it on 4G NAS, 5G NAS, and\n5G RRC specifications and obtain an overall accuracy of 81-87%, which is a\nsubstantial improvement over the state-of-the-art. Our security analysis of the\nextracted models uncovers 3 new vulnerabilities and identifies 19 previous\nattacks in 4G and 5G specifications, and 7 deviations in commercial 4G\nbasebands.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ishtiaq_A/0/1/0/all/0/1\">Abdullah Al Ishtiaq</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sarkar Snigdha Sarathi Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rashid_S/0/1/0/all/0/1\">Syed Md Mukit Rashid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_A/0/1/0/all/0/1\">Ali Ranjbar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1\">Kai Tu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tianwei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1\">Zhezheng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weixuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akon_M/0/1/0/all/0/1\">Mujtahid Akon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Rui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1\">Syed Rafiul Hussain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Stability in Simultaneous Speech Translation: A Revision-Controllable Decoding Approach. (arXiv:2310.04399v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04399","description":"<p>Simultaneous Speech-to-Text translation serves a critical role in real-time\ncrosslingual communication. Despite the advancements in recent years,\nchallenges remain in achieving stability in the translation process, a concern\nprimarily manifested in the flickering of partial results. In this paper, we\npropose a novel revision-controllable method designed to address this issue.\nOur method introduces an allowed revision window within the beam search pruning\nprocess to screen out candidate translations likely to cause extensive\nrevisions, leading to a substantial reduction in flickering and, crucially,\nproviding the capability to completely eliminate flickering. The experiments\ndemonstrate the proposed method can significantly improve the decoding\nstability without compromising substantially on the translation quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Junkun Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jian Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jing Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Agent Tree Search Unifies Reasoning Acting and Planning in Language Models. (arXiv:2310.04406v1 [cs.AI])","link":"http://arxiv.org/abs/2310.04406","description":"<p>While large language models (LLMs) have demonstrated impressive performance\non a range of decision-making tasks, they rely on simple acting processes and\nfall short of broad deployment as autonomous agents. We introduce LATS\n(Language Agent Tree Search), a general framework that synergizes the\ncapabilities of LLMs in planning, acting, and reasoning. Drawing inspiration\nfrom Monte Carlo tree search in model-based reinforcement learning, LATS\nemploys LLMs as agents, value functions, and optimizers, repurposing their\nlatent strengths for enhanced decision-making. What is crucial in this method\nis the use of an environment for external feedback, which offers a more\ndeliberate and adaptive problem-solving mechanism that moves beyond the\nlimitations of existing techniques. Our experimental evaluation across diverse\ndomains, such as programming, HotPotQA, and WebShop, illustrates the\napplicability of LATS for both reasoning and acting. In particular, LATS\nachieves 94.4\\% for programming on HumanEval with GPT-4 and an average score of\n75.9 for web browsing on WebShop with GPT-3.5, demonstrating the effectiveness\nand generality of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1\">Andy Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1\">Kai Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shlapentokh_Rothman_M/0/1/0/all/0/1\">Michal Shlapentokh-Rothman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yu-Xiong Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Policy-Gradient Training of Language Models for Ranking. (arXiv:2310.04407v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04407","description":"<p>Text retrieval plays a crucial role in incorporating factual knowledge for\ndecision making into language processing pipelines, ranging from chat-based web\nsearch to question answering systems. Current state-of-the-art text retrieval\nmodels leverage pre-trained large language models (LLMs) to achieve competitive\nperformance, but training LLM-based retrievers via typical contrastive losses\nrequires intricate heuristics, including selecting hard negatives and using\nadditional supervision as learning signals. This reliance on heuristics stems\nfrom the fact that the contrastive loss itself is heuristic and does not\ndirectly optimize the downstream metrics of decision quality at the end of the\nprocessing pipeline. To address this issue, we introduce Neural PG-RANK, a\nnovel training algorithm that learns to rank by instantiating a LLM as a\nPlackett-Luce ranking policy. Neural PG-RANK provides a principled method for\nend-to-end training of retrieval models as part of larger decision systems via\npolicy gradient, with little reliance on complex heuristics, and it effectively\nunifies the training objective with downstream decision-making quality. We\nconduct extensive experiments on various text retrieval benchmarks. The results\ndemonstrate that when the training objective aligns with the evaluation setup,\nNeural PG-RANK yields remarkable in-domain performance improvement, with\nsubstantial out-of-domain generalization to some critical datasets employed in\ndownstream question answering tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1\">Ge Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1\">Jonathan D. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1\">Claire Cardie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1\">Kiant&#xe9; Brantley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joachim_T/0/1/0/all/0/1\">Thorsten Joachim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation. (arXiv:2310.04408v1 [cs.CL])","link":"http://arxiv.org/abs/2310.04408","description":"<p>Retrieving documents and prepending them in-context at inference time\nimproves performance of language model (LMs) on a wide range of tasks. However,\nthese documents, often spanning hundreds of words, make inference substantially\nmore expensive. We propose compressing the retrieved documents into textual\nsummaries prior to in-context integration. This not only reduces the\ncomputational costs but also relieves the burden of LMs to identify relevant\ninformation in long retrieved documents. We present two compressors -- an\nextractive compressor which selects useful sentences from retrieved documents\nand an abstractive compressor which generates summaries by synthesizing\ninformation from multiple documents. Both compressors are trained to improve\nLMs' performance on end tasks when the generated summaries are prepended to the\nLMs' input, while keeping the summary concise.If the retrieved documents are\nirrelevant to the input or offer no additional information to LM, our\ncompressor can return an empty string, implementing selective augmentation.We\nevaluate our approach on language modeling task and open domain question\nanswering task. We achieve a compression rate of as low as 6% with minimal loss\nin performance for both tasks, significantly outperforming the off-the-shelf\nsummarization models. We show that our compressors trained for one LM can\ntransfer to other LMs on the language modeling task and provide summaries\nlargely faithful to the retrieved documents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Fangyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1\">Eunsol Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Vector Space Semantics for Lambek Calculus with Soft Subexponentials. (arXiv:2111.11331v3 [cs.LO] UPDATED)","link":"http://arxiv.org/abs/2111.11331","description":"<p>We develop a vector space semantics for Lambek Calculus with Soft\nSubexponentials, apply the calculus to construct compositional vector\ninterpretations for parasitic gap noun phrases and discourse units with\nanaphora and ellipsis, and experiment with the constructions in a\ndistributional sentence similarity task. As opposed to previous work, which\nused Lambek Calculus with a Relevant Modality the calculus used in this paper\nuses a bounded version of the modality and is decidable. The vector space\nsemantics of this new modality allows us to meaningfully define contraction as\nprojection and provide a linear theory behind what we could previously only\nachieve via nonlinear maps.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McPheat_L/0/1/0/all/0/1\">Lachlan McPheat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wazni_H/0/1/0/all/0/1\">Hadi Wazni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sadrzadeh_M/0/1/0/all/0/1\">Mehrnoosh Sadrzadeh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AdaptivePaste: Code Adaptation through Learning Semantics-aware Variable Usage Representations. (arXiv:2205.11023v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2205.11023","description":"<p>In software development, it is common for programmers to copy-paste or port\ncode snippets and then adapt them to their use case. This scenario motivates\nthe code adaptation task -- a variant of program repair which aims to adapt\nvariable identifiers in a pasted snippet of code to the surrounding,\npreexisting source code. However, no existing approach has been shown to\neffectively address this task. In this paper, we introduce AdaptivePaste, a\nlearning-based approach to source code adaptation, based on transformers and a\ndedicated dataflow-aware deobfuscation pre-training task to learn meaningful\nrepresentations of variable usage patterns. We evaluate AdaptivePaste on a\ndataset of code snippets in Python. Results suggest that our model can learn to\nadapt source code with 79.8% accuracy. To evaluate how valuable is\nAdaptivePaste in practice, we perform a user study with 10 Python developers on\na hundred real-world copy-paste instances. The results show that AdaptivePaste\nreduces the dwell time to nearly half the time it takes for manual code\nadaptation, and helps to avoid bugs. In addition, we utilize the participant\nfeedback to identify potential avenues for improvement of AdaptivePaste.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaoyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1\">Jinu Jang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaresan_N/0/1/0/all/0/1\">Neel Sundaresan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allamanis_M/0/1/0/all/0/1\">Miltiadis Allamanis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svyatkovskiy_A/0/1/0/all/0/1\">Alexey Svyatkovskiy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TwiRGCN: Temporally Weighted Graph Convolution for Question Answering over Temporal Knowledge Graphs. (arXiv:2210.06281v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06281","description":"<p>Recent years have witnessed much interest in temporal reasoning over\nknowledge graphs (KG) for complex question answering (QA), but there remains a\nsubstantial gap in human capabilities. We explore how to generalize relational\ngraph convolutional networks (RGCN) for temporal KGQA. Specifically, we propose\na novel, intuitive and interpretable scheme to modulate the messages passed\nthrough a KG edge during convolution, based on the relevance of its associated\ntime period to the question. We also introduce a gating device to predict if\nthe answer to a complex temporal question is likely to be a KG entity or time\nand use this prediction to guide our scoring mechanism. We evaluate the\nresulting system, which we call TwiRGCN, on TimeQuestions, a recently released,\nchallenging dataset for multi-hop complex temporal QA. We show that TwiRGCN\nsignificantly outperforms state-of-the-art systems on this dataset across\ndiverse question types. Notably, TwiRGCN improves accuracy by 9--10 percentage\npoints for the most difficult ordinal and implicit question types.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Aditya Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1\">Apoorv Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1\">Chitrank Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kazemi_S/0/1/0/all/0/1\">Seyed Mehran Kazemi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1\">Partha Talukdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1\">Soumen Chakrabarti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Preserving Semantics in Textual Adversarial Attacks. (arXiv:2211.04205v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.04205","description":"<p>The growth of hateful online content, or hate speech, has been associated\nwith a global increase in violent crimes against minorities [23]. Harmful\nonline content can be produced easily, automatically and anonymously. Even\nthough, some form of auto-detection is already achieved through text\nclassifiers in NLP, they can be fooled by adversarial attacks. To strengthen\nexisting systems and stay ahead of attackers, we need better adversarial\nattacks. In this paper, we show that up to 70% of adversarial examples\ngenerated by adversarial attacks should be discarded because they do not\npreserve semantics. We address this core weakness and propose a new, fully\nsupervised sentence embedding technique called Semantics-Preserving-Encoder\n(SPE). Our method outperforms existing sentence encoders used in adversarial\nattacks by achieving 1.2x - 5.1x better real attack success rate. We release\nour code as a plugin that can be used in any existing adversarial attack to\nimprove its quality and speed up its execution.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Herel_D/0/1/0/all/0/1\">David Herel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cisneros_H/0/1/0/all/0/1\">Hugo Cisneros</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikolov_T/0/1/0/all/0/1\">Tomas Mikolov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner. (arXiv:2305.01711v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01711","description":"<p>Language models (LMs) trained on vast quantities of unlabelled data have\ngreatly advanced the field of natural language processing (NLP). In this study,\nwe re-visit the widely accepted notion in NLP that continued pre-training LMs\non task-related texts improves the performance of fine-tuning (FT) in\ndownstream tasks. Through experiments on eight single-sentence tasks and eight\nsentence-pair tasks in both semi-supervised and fully-supervised settings, we\nfind that conventional continued pre-training does not consistently provide\nbenefits and can even be detrimental for sentence-pair tasks or when\nprompt-based FT is used. To tackle these issues, we propose Prompt-based\nContinued Pre-training (PCP), which combines the idea of instruction tuning\nwith conventional continued pre-training. Our approach aims to improve the\nperformance of prompt-based FT by presenting both task-related texts and prompt\ntemplates to LMs through unsupervised pre-training objectives before\nfine-tuning for the target task. Our empirical evaluations on 21 benchmarks\ndemonstrate that the PCP consistently improves the performance of\nstate-of-the-art prompt-based FT approaches (up to 20.1% absolute) in both\nsemi-supervised and fully-supervised settings, even with only hundreds of\nunlabelled examples. Additionally, prompt-based FT with the PCP outperforms\nstate-of-the-art semi-supervised approaches with greater simplicity,\neliminating the need for an iterative process and extra data augmentation. Our\nfurther analysis explores the performance lower bound of the PCP and reveals\nthat the advantages of PCP persist across different sizes of models and\ndatasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1\">Zhengxiang Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lipani_A/0/1/0/all/0/1\">Aldo Lipani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Now It Sounds Like You: Learning Personalized Vocabulary On Device. (arXiv:2305.03584v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03584","description":"<p>In recent years, Federated Learning (FL) has shown significant advancements\nin its ability to perform various natural language processing (NLP) tasks. This\nwork focuses on applying personalized FL for on-device language modeling. Due\nto limitations of memory and latency, these models cannot support the\ncomplexity of sub-word tokenization or beam search decoding, resulting in the\ndecision to deploy a closed-vocabulary language model. However,\nclosed-vocabulary models are unable to handle out-of-vocabulary (OOV) words\nbelonging to specific users. To address this issue, We propose a novel\ntechnique called \"OOV expansion\" that improves OOV coverage and increases model\naccuracy while minimizing the impact on memory and latency. This method\nintroduces a personalized \"OOV adapter\" that effectively transfers knowledge\nfrom a central model and learns word embedding for personalized vocabulary. OOV\nexpansion significantly outperforms standard FL personalization methods on a\nset of common FL benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sid Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1\">Ashish Shenoy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chuang_P/0/1/0/all/0/1\">Pierce Chuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_J/0/1/0/all/0/1\">John Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Simple and Effective Pruning Approach for Large Language Models. (arXiv:2306.11695v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.11695","description":"<p>As their size increases, Large Languages Models (LLMs) are natural candidates\nfor network pruning methods: approaches that drop a subset of network weights\nwhile striving to preserve performance. Existing methods, however, require\neither retraining, which is rarely affordable for billion-scale LLMs, or\nsolving a weight reconstruction problem reliant on second-order information,\nwhich may also be computationally expensive. In this paper, we introduce a\nnovel, straightforward yet effective pruning method, termed Wanda (Pruning by\nWeights and activations), designed to induce sparsity in pretrained LLMs.\nMotivated by the recent observation of emergent large magnitude features in\nLLMs, our approach prunes weights with the smallest magnitudes multiplied by\nthe corresponding input activations, on a per-output basis. Notably, Wanda\nrequires no retraining or weight update, and the pruned LLM can be used as is.\nWe conduct a thorough evaluation of our method Wanda on LLaMA and LLaMA-2\nacross various language benchmarks. Wanda significantly outperforms the\nestablished baseline of magnitude pruning and performs competitively against\nrecent method involving intensive weight update. Code is available at\nhttps://github.com/locuslab/wanda.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Mingjie Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhuang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bair_A/0/1/0/all/0/1\">Anna Bair</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1\">J. Zico Kolter</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models. (arXiv:2307.05782v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.05782","description":"<p>Artificial intelligence is making spectacular progress, and one of the best\nexamples is the development of large language models (LLMs) such as OpenAI's\nGPT series. In these lectures, written for readers with a background in\nmathematics or physics, we give a brief history and survey of the state of the\nart, and describe the underlying transformer architecture in detail. We then\nexplore some current ideas on how LLMs work and how models trained to predict\nthe next word in a text are able to perform other tasks displaying\nintelligence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Douglas_M/0/1/0/all/0/1\">Michael R. Douglas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning. (arXiv:2307.10274v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2307.10274","description":"<p>In this work, we propose a method to create domain-sensitive speech\nrecognition models that utilize textual domain information by conditioning its\ngeneration on a given text prompt. This is accomplished by fine-tuning a\npre-trained, end-to-end model (Whisper) to learn from demonstrations with\nprompt examples. We show that this ability can be generalized to different\ndomains and even various prompt contexts, with our model gaining a Word Error\nRate (WER) reduction of up to 33% on unseen datasets from various domains, such\nas medical conversation, air traffic control communication, and financial\nmeetings. Considering the limited availability of audio-transcript pair data,\nwe further extend our method to text-only fine-tuning to achieve domain\nsensitivity as well as domain adaptation. We demonstrate that our text-only\nfine-tuned model can also attend to various prompt contexts, with the model\nreaching the most WER reduction of 29% on the medical conversation dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Liao_F/0/1/0/all/0/1\">Feng-Ting Liao</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chan_Y/0/1/0/all/0/1\">Yung-Chieh Chan</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1\">Yi-Chang Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Shiu_D/0/1/0/all/0/1\">Da-shan Shiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CARTIER: Cartographic lAnguage Reasoning Targeted at Instruction Execution for Robots. (arXiv:2307.11865v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2307.11865","description":"<p>This work explores the capacity of large language models (LLMs) to address\nproblems at the intersection of spatial planning and natural language\ninterfaces for navigation.Our focus is on following relatively complex\ninstructions that are more akin to natural conversation than traditional\nexplicit procedural directives seen in robotics. Unlike most prior work, where\nnavigation directives are provided as imperative commands (e.g., go to the\nfridge), we examine implicit directives within conversational interactions. We\nleverage the 3D simulator AI2Thor to create complex and repeatable scenarios at\nscale, and augment it by adding complex language queries for 40 object types.\nWe demonstrate that a robot can better parse descriptive language queries than\nexisting methods by using an LLM to interpret the user interaction in the\ncontext of a list of the objects in the scene.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rivkin_D/0/1/0/all/0/1\">Dmitriy Rivkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakodkar_N/0/1/0/all/0/1\">Nikhil Kakodkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hogan_F/0/1/0/all/0/1\">Francois Hogan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baghi_B/0/1/0/all/0/1\">Bobak H. Baghi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1\">Gregory Dudek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Backdooring Instruction-Tuned Large Language Models with Virtual Prompt Injection. (arXiv:2307.16888v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.16888","description":"<p>Instruction-tuned Large Language Models (LLMs) have demonstrated remarkable\nabilities to modulate their responses based on human instructions. However,\nthis modulation capacity also introduces the potential for attackers to employ\nfine-grained manipulation of model functionalities by planting backdoors. In\nthis paper, we introduce Virtual Prompt Injection (VPI) as a novel backdoor\nattack setting tailored for instruction-tuned LLMs. In a VPI attack, the\nbackdoored model is expected to respond as if an attacker-specified virtual\nprompt were concatenated to the user instruction under a specific trigger\nscenario, allowing the attacker to steer the model without any explicit\ninjection at its input. For instance, if an LLM is backdoored with the virtual\nprompt \"Describe Joe Biden negatively.\" for the trigger scenario of discussing\nJoe Biden, then the model will propagate negatively-biased views when talking\nabout Joe Biden. VPI is especially harmful as the attacker can take\nfine-grained and persistent control over LLM behaviors by employing various\nvirtual prompts and trigger scenarios. To demonstrate the threat, we propose a\nsimple method to perform VPI by poisoning the model's instruction tuning data.\nWe find that our proposed method is highly effective in steering the LLM. For\nexample, by poisoning only 52 instruction tuning examples (0.1% of the training\ndata size), the percentage of negative responses given by the trained model on\nJoe Biden-related queries changes from 0% to 40%. This highlights the necessity\nof ensuring the integrity of the instruction tuning data. We further identify\nquality-guided data filtering as an effective way to defend against the\nattacks. Our project page is available at https://poison-llm.github.io.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1\">Jun Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yadav_V/0/1/0/all/0/1\">Vikas Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shiyang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lichang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zheng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1\">Vijay Srinivasan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1\">Xiang Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1\">Hongxia Jin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Are Not Robust Multiple Choice Selectors. (arXiv:2309.03882v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.03882","description":"<p>Multiple choice questions (MCQs) serve as a common yet important task format\nin the research of large language models (LLMs). This work shows that LLMs are\nvulnerable to option position changes in MCQs due to their inherent \"selection\nbias\", namely, they prefer to select specific option IDs as answers (like\n\"Option A\"). Through extensive empirical analyses with 20 LLMs on three\nbenchmarks, we pinpoint that this behavioral bias primarily stems from LLMs'\ntoken bias, where the model a priori assigns more probabilistic mass to\nspecific option ID tokens (e.g., A/B/C/D) when predicting answers from the\noption IDs. To mitigate selection bias, we propose a label-free, inference-time\ndebiasing method, called PriDe, which separates the model's prior bias for\noption IDs from the overall prediction distribution. PriDe first estimates the\nprior by permutating option contents on a small number of test samples, which\nis then applied to debias the subsequent samples. We demonstrate that PriDe\nachieves superior debiasing effectiveness and computational efficiency to\nstrong baselines. Furthermore, the prior estimated by PriDe is interpretable\nand can generalize well across different domains, highlighting its practical\npotential in broader scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Answering Subjective Induction Questions on Products by Summarizing Multi-sources Multi-viewpoints Knowledge. (arXiv:2309.05938v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.05938","description":"<p>This paper proposes a new task in the field of Answering Subjective Induction\nQuestion on Products (SUBJPQA). The answer to this kind of question is\nnon-unique, but can be interpreted from many perspectives. For example, the\nanswer to 'whether the phone is heavy' has a variety of different viewpoints. A\nsatisfied answer should be able to summarize these subjective opinions from\nmultiple sources and provide objective knowledge, such as the weight of a\nphone. That is quite different from the traditional QA task, in which the\nanswer to a factoid question is unique and can be found from a single data\nsource. To address this new task, we propose a three-steps method. We first\nretrieve all answer-related clues from multiple knowledge sources on facts and\nopinions. The implicit commonsense facts are also collected to supplement the\nnecessary but missing contexts. We then capture their relevance with the\nquestions by interactive attention. Next, we design a reinforcement-based\nsummarizer to aggregate all these knowledgeable clues. Based on a\ntemplate-controlled decoder, we can output a comprehensive and\nmulti-perspective answer. Due to the lack of a relevant evaluated benchmark set\nfor the new task, we construct a large-scale dataset, named SupQA, consisting\nof 48,352 samples across 15 product domains. Evaluation results show the\neffectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yufeng Zhang</a> (1 and 2), <a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Meng-xiang Wang</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1\">Jianxing Yu</a> (1, 2 and 4) ((1) School of Artificial Intelligence, Sun Yat-sen University, Zhuhai 519082 (2) Guangdong Key Laboratory of Big Data Analysis and Processing, 510006, China (3) China National Institute of Standardization, 100088, China (4) Pazhou Lab, Guangzhou, 510330, China)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Avoidance of Vulnerabilities in Auto-completed Smart Contract Code Using Vulnerability-constrained Decoding. (arXiv:2309.09826v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2309.09826","description":"<p>Auto-completing code enables developers to speed up coding significantly.\nRecent advances in transformer-based large language model (LLM) technologies\nhave been applied to code synthesis. However, studies show that many of such\nsynthesized codes contain vulnerabilities. We propose a novel\nvulnerability-constrained decoding approach to reduce the amount of vulnerable\ncode generated by such models. Using a small dataset of labeled vulnerable\nlines of code, we fine-tune an LLM to include vulnerability labels when\ngenerating code, acting as an embedded classifier. Then, during decoding, we\ndeny the model to generate these labels to avoid generating vulnerable code. To\nevaluate the method, we chose to automatically complete Ethereum Blockchain\nsmart contracts (SCs) as the case study due to the strict requirements of SC\nsecurity. We first fine-tuned the 6-billion-parameter GPT-J model using 186,397\nEthereum SCs after removing the duplication from 2,217,692 SCs. The fine-tuning\ntook more than one week using ten GPUs. The results showed that our fine-tuned\nmodel could synthesize SCs with an average BLEU (BiLingual Evaluation\nUnderstudy) score of 0.557. However, many codes in the auto-completed SCs were\nvulnerable. Using the code before the vulnerable line of 176 SCs containing\ndifferent types of vulnerabilities to auto-complete the code, we found that\nmore than 70% of the auto-completed codes were insecure. Thus, we further\nfine-tuned the model on other 941 vulnerable SCs containing the same types of\nvulnerabilities and applied vulnerability-constrained decoding. The fine-tuning\ntook only one hour with four GPUs. We then auto-completed the 176 SCs again and\nfound that our approach could identify 62% of the code to be generated as\nvulnerable and avoid generating 67% of them, indicating the approach could\nefficiently and effectively avoid vulnerabilities in the auto-completed code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Storhaug_A/0/1/0/all/0/1\">Andr&#xe9; Storhaug</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jingyue Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1\">Tianyuan Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical attention interpretation: an interpretable speech-level transformer for bi-modal depression detection. (arXiv:2309.13476v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.13476","description":"<p>Depression is a common mental disorder. Automatic depression detection tools\nusing speech, enabled by machine learning, help early screening of depression.\nThis paper addresses two limitations that may hinder the clinical\nimplementations of such tools: noise resulting from segment-level labelling and\na lack of model interpretability. We propose a bi-modal speech-level\ntransformer to avoid segment-level labelling and introduce a hierarchical\ninterpretation approach to provide both speech-level and sentence-level\ninterpretations, based on gradient-weighted attention maps derived from all\nattention layers to track interactions between input features. We show that the\nproposed model outperforms a model that learns at a segment level ($p$=0.854,\n$r$=0.947, $F1$=0.897 compared to $p$=0.732, $r$=0.808, $F1$=0.768). For model\ninterpretation, using one true positive sample, we show which sentences within\na given speech are most relevant to depression detection; and which text tokens\nand Mel-spectrogram regions within these sentences are most relevant to\ndepression detection. These interpretations allow clinicians to verify the\nvalidity of predictions made by depression detection tools, promoting their\nclinical implementations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_Q/0/1/0/all/0/1\">Qingkun Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luz_S/0/1/0/all/0/1\">Saturnino Luz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1\">Sofia de la Fuente Garcia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Graphs for the Life Sciences: Recent Developments, Challenges and Opportunities. (arXiv:2309.17255v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2309.17255","description":"<p>The term life sciences refers to the disciplines that study living organisms\nand life processes, and include chemistry, biology, medicine, and a range of\nother related disciplines. Research efforts in life sciences are heavily\ndata-driven, as they produce and consume vast amounts of scientific data, much\nof which is intrinsically relational and graph-structured.\n</p>\n<p>The volume of data and the complexity of scientific concepts and relations\nreferred to therein promote the application of advanced knowledge-driven\ntechnologies for managing and interpreting data, with the ultimate aim to\nadvance scientific discovery.\n</p>\n<p>In this survey and position paper, we discuss recent developments and\nadvances in the use of graph-based technologies in life sciences and set out a\nvision for how these technologies will impact these fields into the future. We\nfocus on three broad topics: the construction and management of Knowledge\nGraphs (KGs), the use of KGs and associated technologies in the discovery of\nnew knowledge, and the use of KGs in artificial intelligence applications to\nsupport explanations (explainable AI). We select a few exemplary use cases for\neach topic, discuss the challenges and open research questions within these\ntopics, and conclude with a perspective and outlook that summarizes the\noverarching challenges and their potential solutions as a guide for future\nresearch.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1\">Hang Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hastings_J/0/1/0/all/0/1\">Janna Hastings</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jimenez_Ruiz_E/0/1/0/all/0/1\">Ernesto Jim&#xe9;nez-Ruiz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_V/0/1/0/all/0/1\">Vanessa L&#xf3;pez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monnin_P/0/1/0/all/0/1\">Pierre Monnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pesquita_C/0/1/0/all/0/1\">Catia Pesquita</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Skoda_P/0/1/0/all/0/1\">Petr &#x160;koda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamma_V/0/1/0/all/0/1\">Valentina Tamma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Natural Language Processing Model for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00100","description":"<p>The impression section of a radiology report summarizes important radiology\nfindings and plays a critical role in communicating these findings to\nphysicians. However, the preparation of these summaries is time-consuming and\nerror-prone for radiologists. Recently, numerous models for radiology report\nsummarization have been developed. Nevertheless, there is currently no model\nthat can summarize these reports in multiple languages. Such a model could\ngreatly improve future research and the development of Deep Learning models\nthat incorporate data from patients with different ethnic backgrounds. In this\nstudy, the generation of radiology impressions in different languages was\nautomated by fine-tuning a model, publicly available, based on a multilingual\ntext-to-text Transformer to summarize findings available in English,\nPortuguese, and German radiology reports. In a blind test, two board-certified\nradiologists indicated that for at least 70% of the system-generated summaries,\nthe quality matched or exceeded the corresponding human-written summaries,\nsuggesting substantial clinical reliability. Furthermore, this study showed\nthat the multilingual model outperformed other models that specialized in\nsummarizing radiology reports in only one language, as well as models that were\nnot specifically designed for summarizing radiology reports, such as ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lindo_M/0/1/0/all/0/1\">Mariana Lindo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Santos_A/0/1/0/all/0/1\">Ana Sofia Santos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_A/0/1/0/all/0/1\">Andr&#xe9; Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jianning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luijten_G/0/1/0/all/0/1\">Gijs Luijten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Correia_G/0/1/0/all/0/1\">Gustavo Correia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Moon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleesiek_J/0/1/0/all/0/1\">Jens Kleesiek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Egger_J/0/1/0/all/0/1\">Jan Egger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alves_V/0/1/0/all/0/1\">Victor Alves</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BooookScore: A systematic exploration of book-length summarization in the era of LLMs. (arXiv:2310.00785v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00785","description":"<p>Summarizing book-length documents (&gt;100K tokens) that exceed the context\nwindow size of large language models (LLMs) requires first breaking the input\ndocument into smaller chunks and then prompting an LLM to merge, update, and\ncompress chunk-level summaries. Despite the complexity and importance of this\ntask, it has yet to be meaningfully studied due to the challenges of\nevaluation: existing book-length summarization datasets (e.g., BookSum) are in\nthe pretraining data of most public LLMs, and existing evaluation methods\nstruggle to capture errors made by modern LLM summarizers. In this paper, we\npresent the first study of the coherence of LLM-based book-length summarizers\nimplemented via two prompting workflows: (1) hierarchically merging chunk-level\nsummaries, and (2) incrementally updating a running summary. We obtain 1193\nfine-grained human annotations on GPT-4 generated summaries of 100\nrecently-published books and identify eight common types of coherence errors\nmade by LLMs. Because human evaluation is expensive and time-consuming, we\ndevelop an automatic metric, BooookScore, that measures the proportion of\nsentences in a summary that do not contain any of the identified error types.\nBooookScore has high agreement with human annotations and allows us to\nsystematically evaluate the impact of many other critical parameters (e.g.,\nchunk size, base LLM) while saving $15K and 500 hours in human evaluation\ncosts. We find that closed-source LLMs such as GPT-4 and Claude 2 produce\nsummaries with higher BooookScore than the oft-repetitive ones generated by\nLLaMA 2. Incremental updating yields lower BooookScore but higher level of\ndetail than hierarchical merging, a trade-off sometimes preferred by human\nannotators. We release code and annotations after blind review to spur more\nprincipled research on book-length summarization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yapei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_K/0/1/0/all/0/1\">Kyle Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1\">Tanya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1\">Mohit Iyyer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enable Language Models to Implicitly Learn Self-Improvement From Data. (arXiv:2310.00898v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.00898","description":"<p>Large Language Models (LLMs) have demonstrated remarkable capabilities in\nopen-ended text generation tasks. However, the inherent open-ended nature of\nthese tasks implies that there is always room for improvement in the quality of\nmodel responses. To address this challenge, various approaches have been\nproposed to enhance the performance of LLMs. There has been a growing focus on\nenabling LLMs to self-improve their response quality, thereby reducing the\nreliance on extensive human annotation efforts for collecting diverse and\nhigh-quality training data. Recently, prompting-based methods have been widely\nexplored among self-improvement methods owing to their effectiveness,\nefficiency, and convenience. However, those methods usually require explicitly\nand thoroughly written rubrics as inputs to LLMs. It is expensive and\nchallenging to manually derive and provide all necessary rubrics with a\nreal-world complex goal for improvement (e.g., being more helpful and less\nharmful). To this end, we propose an ImPlicit Self-ImprovemenT (PIT) framework\nthat implicitly learns the improvement goal from human preference data. PIT\nonly requires preference data that are used to train reward models without\nextra human efforts. Specifically, we reformulate the training objective of\nreinforcement learning from human feedback (RLHF) -- instead of maximizing\nresponse quality for a given input, we maximize the quality gap of the response\nconditioned on a reference response. In this way, PIT is implicitly trained\nwith the improvement goal of better aligning with human preferences.\nExperiments on two real-world datasets and one synthetic dataset show that our\nmethod significantly outperforms prompting-based methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Le Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1\">Tianjian Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuexin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hongkun Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Avalon's Game of Thoughts: Battle Against Deception through Recursive Contemplation. (arXiv:2310.01320v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2310.01320","description":"<p>Recent breakthroughs in large language models (LLMs) have brought remarkable\nsuccess in the field of LLM-as-Agent. Nevertheless, a prevalent assumption is\nthat the information processed by LLMs is consistently honest, neglecting the\npervasive deceptive or misleading information in human society and AI-generated\ncontent. This oversight makes LLMs susceptible to malicious manipulations,\npotentially resulting in detrimental outcomes. This study utilizes the\nintricate Avalon game as a testbed to explore LLMs' potential in deceptive\nenvironments. Avalon, full of misinformation and requiring sophisticated logic,\nmanifests as a \"Game-of-Thoughts\". Inspired by the efficacy of humans'\nrecursive thinking and perspective-taking in the Avalon game, we introduce a\nnovel framework, Recursive Contemplation (ReCon), to enhance LLMs' ability to\nidentify and counteract deceptive information. ReCon combines formulation and\nrefinement contemplation processes; formulation contemplation produces initial\nthoughts and speech, while refinement contemplation further polishes them.\nAdditionally, we incorporate first-order and second-order perspective\ntransitions into these processes respectively. Specifically, the first-order\nallows an LLM agent to infer others' mental states, and the second-order\ninvolves understanding how others perceive the agent's mental state. After\nintegrating ReCon with different LLMs, extensive experiment results from the\nAvalon game indicate its efficacy in aiding LLMs to discern and maneuver around\ndeceptive information without extra fine-tuning and data. Finally, we offer a\npossible explanation for the efficacy of ReCon and explore the current\nlimitations of LLMs in terms of safety, reasoning, speaking style, and format,\npotentially furnishing insights for subsequent research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shenzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1\">Zilong Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_S/0/1/0/all/0/1\">Siyuan Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qisen Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1\">Andrew Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chaofei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1\">Shiji Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1\">Gao Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Instance Needs More Care: Rewriting Prompts for Instances Yields Better Zero-Shot Performance. (arXiv:2310.02107v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02107","description":"<p>Enabling large language models (LLMs) to perform tasks in zero-shot has been\nan appealing goal owing to its labor-saving (i.e., requiring no task-specific\nannotations); as such, zero-shot prompting approaches also enjoy better task\ngeneralizability. To improve LLMs' zero-shot performance, prior work has\nfocused on devising more effective task instructions (e.g., ``let's think step\nby step'' ). However, we argue that, in order for an LLM to solve them\ncorrectly in zero-shot, individual test instances need more carefully designed\nand customized instructions. To this end, we propose PRoMPTd, an approach that\nrewrites the task prompt for each individual test input to be more specific,\nunambiguous, and complete, so as to provide better guidance to the task LLM. We\nevaluated PRoMPTd on eight datasets covering tasks including arithmetics,\nlogical reasoning, and code generation, using GPT-4 as the task LLM. Notably,\nPRoMPTd achieves an absolute improvement of around 10% on the complex MATH\ndataset and 5% on the code generation task on HumanEval, outperforming\nconventional zero-shot methods. In addition, we also showed that the rewritten\nprompt can provide better interpretability of how the LLM resolves each test\ninstance, which can potentially be leveraged as a defense mechanism against\nadversarial prompting. The source code and dataset can be obtained from\nhttps://github.com/salokr/PRoMPTd\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Saurabh Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1\">Chengyue Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_W/0/1/0/all/0/1\">Weiguo Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Ziyu Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task Adaptation. (arXiv:2310.02842v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02842","description":"<p>Large Language Models (LLMs) have the ability to solve a variety of tasks,\nsuch as text summarization and mathematical questions, just out of the box, but\nthey are often trained with a single task in mind. Due to high computational\ncosts, the current trend is to use prompt instruction tuning to better adjust\nmonolithic, pretrained LLMs for new -- but often individual -- downstream\ntasks. Thus, how one would expand prompt tuning to handle -- concomitantly --\nheterogeneous tasks and data distributions is a widely open question. To\naddress this gap, we suggest the use of \\emph{Mixture of Prompts}, or MoPs,\nassociated with smart gating functionality: the latter -- whose design is one\nof the contributions of this paper -- can identify relevant skills embedded in\ndifferent groups of prompts and dynamically assign combined experts (i.e.,\ncollection of prompts), based on the target task. Additionally, MoPs are\nempirically agnostic to any model compression technique applied -- for\nefficiency reasons -- as well as instruction data source and task composition.\nIn practice, MoPs can simultaneously mitigate prompt training \"interference\" in\nmulti-task, multi-source scenarios (e.g., task and data heterogeneity across\nsources), as well as possible implications from model approximations. As a\nhighlight, MoPs manage to decrease final perplexity from $\\sim20\\%$ up to\n$\\sim70\\%$, as compared to baselines, in the federated scenario, and from $\\sim\n3\\%$ up to $\\sim30\\%$ in the centralized scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dun_C/0/1/0/all/0/1\">Chen Dun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_M/0/1/0/all/0/1\">Mirian Hipolito Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1\">Guoqing Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1\">Ahmed Hassan Awadallah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1\">Anastasios Kyrillidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Personalized Story Evaluation. (arXiv:2310.03304v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03304","description":"<p>While large language models (LLMs) have shown impressive results for more\nobjective tasks such as QA and retrieval, it remains nontrivial to evaluate\ntheir performance on open-ended text generation for reasons including (1) data\ncontamination; (2) multi-dimensional evaluation criteria; and (3)\nsubjectiveness stemming from reviewers' personal preferences. To address such\nissues, we propose to model personalization in an uncontaminated open-ended\ngeneration assessment. We create two new datasets Per-MPST and Per-DOC for\npersonalized story evaluation, by re-purposing existing datasets with proper\nanonymization and new personalized labels. We further develop a personalized\nstory evaluation model PERSE to infer reviewer preferences and provide a\npersonalized evaluation. Specifically, given a few exemplary reviews from a\nparticular reviewer, PERSE predicts either a detailed review or fine-grained\ncomparison in several aspects (such as interestingness and surprise) for that\nreviewer on a new text input. Experimental results show that PERSE outperforms\nGPT-4 by 15.8% on Kendall correlation of story ratings, and by 13.7% on\npairwise preference prediction accuracy. Both datasets and code will be\nreleased at https://github.com/dqwang122/PerSE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Danqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1\">Kevin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlin Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaomeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1\">Andrew Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuandong Tian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The North System for Formosa Speech Recognition Challenge 2023. (arXiv:2310.03443v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03443","description":"<p>This report provides a concise overview of the proposed North system, which\naims to achieve automatic word/syllable recognition for Taiwanese Hakka\n(Sixian). The report outlines three key components of the system: the\nacquisition, composition, and utilization of the training data; the\narchitecture of the model; and the hardware specifications and operational\nstatistics. The demonstration of the system has been made public at\nhttps://asrvm.iis.sinica.edu.tw/hakka_sixian.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li-Wei Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_K/0/1/0/all/0/1\">Kai-Chen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-Shin Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction. (arXiv:2310.03668v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03668","description":"<p>Large Language Models (LLMs) combined with instruction tuning have made\nsignificant progress when generalizing to unseen tasks. However, they have been\nless successful in Information Extraction (IE), lagging behind task-specific\nmodels. Typically, IE tasks are characterized by complex annotation guidelines\nwhich describe the task and give examples to humans. Previous attempts to\nleverage such information have failed, even with the largest models, as they\nare not able to follow the guidelines out-of-the-box. In this paper we propose\nGoLLIE (Guideline-following Large Language Model for IE), a model able to\nimprove zero-shot results on unseen IE tasks by virtue of being fine-tuned to\ncomply with annotation guidelines. Comprehensive evaluation empirically\ndemonstrates that GoLLIE is able to generalize to and follow unseen guidelines,\noutperforming previous attempts at zero-shot information extraction. The\nablation study shows that detailed guidelines is key for good results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sainz_O/0/1/0/all/0/1\">Oscar Sainz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_Ferrero_I/0/1/0/all/0/1\">Iker Garc&#xed;a-Ferrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agerri_R/0/1/0/all/0/1\">Rodrigo Agerri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lacalle_O/0/1/0/all/0/1\">Oier Lopez de Lacalle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1\">German Rigau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1\">Eneko Agirre</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis. (arXiv:2302.05608v1 [cs.CV] CROSS LISTED)","link":"http://arxiv.org/abs/2302.05608","description":"<p>Often, deep network models are purely inductive during training and while\nperforming inference on unseen data. Thus, when such models are used for\npredictions, it is well known that they often fail to capture the semantic\ninformation and implicit dependencies that exist among objects (or concepts) on\na population level. Moreover, it is still unclear how domain or prior modal\nknowledge can be specified in a backpropagation friendly manner, especially in\nlarge-scale and noisy settings. In this work, we propose an end-to-end vision\nand language model incorporating explicit knowledge graphs. We also introduce\nan interactive out-of-distribution (OOD) layer using implicit network operator.\nThe layer is used to filter noise that is brought by external knowledge base.\nIn practice, we apply our model on several vision and language downstream tasks\nincluding visual question answering, visual reasoning, and image-text retrieval\non different datasets. Our experiments show that it is possible to design\nmodels that perform similarly to state-of-art results but with significantly\nfewer samples and training time.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Medya_S/0/1/0/all/0/1\">Sourav Medya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1\">Sathya N. Ravi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-08T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}