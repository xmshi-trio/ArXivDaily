{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-01-31T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Prompt-Based Editing for Text Style Transfer. (arXiv:2301.11997v1 [cs.CL])","link":"http://arxiv.org/abs/2301.11997","description":"<p>Prompting approaches have been recently explored in text style transfer,\nwhere a textual prompt is used to query a pretrained language model to generate\nstyle-transferred texts word by word in an autoregressive manner. However, such\na generation process is less controllable and early prediction errors may\naffect future word predictions. In this paper, we present a prompt-based\nediting approach for text style transfer. Specifically, we prompt a pretrained\nlanguage model for style classification and use the classification probability\nto compute a style score. Then, we perform discrete search with word-level\nediting to maximize a comprehensive scoring function for the style-transfer\ntask. In this way, we transform a prompt-based generation problem into a\nclassification one, which is a training-free process and more controllable than\nthe autoregressive generation of sentences. In our experiments, we performed\nboth automatic and human evaluation on three style-transfer benchmark datasets,\nand show that our approach largely outperforms the state-of-the-art systems\nthat have 20 times more parameters. Additional empirical analyses further\ndemonstrate the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_G/0/1/0/all/0/1\">Guoqing Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yu Tong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1\">Lili Mou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firdaus_M/0/1/0/all/0/1\">Mauajama Firdaus</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding the Effectiveness of Very Large Language Models on Dialog Evaluation. (arXiv:2301.12004v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12004","description":"<p>Language models have steadily increased in size over the past few years. They\nachieve a high level of performance on various natural language processing\n(NLP) tasks such as question answering and summarization. Large language models\n(LLMs) have been used for generation and can now output human-like text. Due to\nthis, there are other downstream tasks in the realm of dialog that can now\nharness the LLMs' language understanding capabilities. Dialog evaluation is one\ntask that this paper will explore. It concentrates on prompting with LLMs:\nBLOOM, OPT, GPT-3, Flan-T5, InstructDial and TNLGv2. The paper shows that the\nchoice of datasets used for training a model contributes to how well it\nperforms on a task as well as on how the prompt should be structured.\nSpecifically, the more diverse and relevant the group of datasets that a model\nis trained on, the better dialog evaluation performs. This paper also\ninvestigates how the number of examples in the prompt and the type of example\nselection used affect the model's performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huynh_J/0/1/0/all/0/1\">Jessica Huynh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiao_C/0/1/0/all/0/1\">Cathy Jiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mehri_S/0/1/0/all/0/1\">Shikib Mehri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1\">Payal Bajaj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_V/0/1/0/all/0/1\">Vishrav Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eskenazi_M/0/1/0/all/0/1\">Maxine Eskenazi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved knowledge distillation by utilizing backward pass knowledge in neural networks. (arXiv:2301.12006v1 [cs.LG])","link":"http://arxiv.org/abs/2301.12006","description":"<p>Knowledge distillation (KD) is one of the prominent techniques for model\ncompression. In this method, the knowledge of a large network (teacher) is\ndistilled into a model (student) with usually significantly fewer parameters.\nKD tries to better-match the output of the student model to that of the teacher\nmodel based on the knowledge extracts from the forward pass of the teacher\nnetwork. Although conventional KD is effective for matching the two networks\nover the given data points, there is no guarantee that these models would match\nin other areas for which we do not have enough training samples. In this work,\nwe address that problem by generating new auxiliary training samples based on\nextracting knowledge from the backward pass of the teacher in the areas where\nthe student diverges greatly from the teacher. We compute the difference\nbetween the teacher and the student and generate new data samples that maximize\nthe divergence. This is done by perturbing data samples in the direction of the\ngradient of the difference between the student and the teacher. Augmenting the\ntraining set by adding this auxiliary improves the performance of KD\nsignificantly and leads to a closer match between the student and the teacher.\nUsing this approach, when data samples come from a discrete domain, such as\napplications of natural language processing (NLP) and language understanding,\nis not trivial. However, we show how this technique can be used successfully in\nsuch applications. We evaluated the performance of our method on various tasks\nin computer vision and NLP domains and got promising results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jafari_A/0/1/0/all/0/1\">Aref Jafari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1\">Mehdi Rezagholizadeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1\">Ali Ghodsi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding INT4 Quantization for Transformer Models: Latency Speedup, Composability, and Failure Cases. (arXiv:2301.12017v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12017","description":"<p>Improving the deployment efficiency of transformer-based language models has\nbeen challenging given their high computation and memory cost. While INT8\nquantization has recently been shown to be effective in reducing both the\nmemory cost and latency while preserving model accuracy, it remains unclear\nwhether we can leverage INT4 (which doubles peak hardware throughput) to\nachieve further latency improvement. In this work, we fully investigate the\nfeasibility of using INT4 quantization for language models, and show that using\nINT4 introduces no or negligible accuracy degradation for encoder-only and\nencoder-decoder models, but causes a significant accuracy drop for decoder-only\nmodels. To materialize the performance gain using INT4, we develop a\nhighly-optimized end-to-end INT4 encoder inference pipeline supporting\ndifferent quantization strategies. Our INT4 pipeline is $8.5\\times$ faster for\nlatency-oriented scenarios and up to $3\\times$ for throughput-oriented\nscenarios compared to the inference of FP16, and improves the SOTA BERT INT8\nperformance from FasterTransformer by up to $1.7\\times$. We also provide\ninsights into the failure cases when applying INT4 to decoder-only models, and\nfurther explore the compatibility of INT4 quantization with other compression\ntechniques, like pruning and layer reduction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xiaoxia Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Cheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aminabadi_R/0/1/0/all/0/1\">Reza Yazdani Aminabadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Zhewei Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yuxiong He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling. (arXiv:2301.12050v1 [cs.LG])","link":"http://arxiv.org/abs/2301.12050","description":"<p>Reinforcement learning (RL) agents typically learn tabula rasa, without prior\nknowledge of the world, which makes learning complex tasks with sparse rewards\ndifficult. If initialized with knowledge of high-level subgoals and transitions\nbetween subgoals, RL agents could utilize this Abstract World Model (AWM) for\nplanning and exploration. We propose using few-shot large language models\n(LLMs) to hypothesize an AWM, that is tested and verified during exploration,\nto improve sample efficiency in embodied RL agents. Our DECKARD agent applies\nLLM-guided exploration to item crafting in Minecraft in two phases: (1) the\nDream phase where the agent uses an LLM to decompose a task into a sequence of\nsubgoals, the hypothesized AWM; and (2) the Wake phase where the agent learns a\nmodular policy for each subgoal and verifies or corrects the hypothesized AWM\non the basis of its experiences. Our method of hypothesizing an AWM with LLMs\nand then verifying the AWM based on agent experience not only increases sample\nefficiency over contemporary methods by an order of magnitude but is also\nrobust to and corrects errors in the LLM, successfully blending noisy\ninternet-scale information from LLMs with knowledge grounded in environment\ndynamics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nottingham_K/0/1/0/all/0/1\">Kolby Nottingham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ammanabrolu_P/0/1/0/all/0/1\">Prithviraj Ammanabrolu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suhr_A/0/1/0/all/0/1\">Alane Suhr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1\">Hannaneh Hajishirzi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fox_R/0/1/0/all/0/1\">Roy Fox</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparing Intrinsic Gender Bias Evaluation Measures without using Human Annotated Examples. (arXiv:2301.12074v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12074","description":"<p>Numerous types of social biases have been identified in pre-trained language\nmodels (PLMs), and various intrinsic bias evaluation measures have been\nproposed for quantifying those social biases. Prior works have relied on human\nannotated examples to compare existing intrinsic bias evaluation measures.\nHowever, this approach is not easily adaptable to different languages nor\namenable to large scale evaluations due to the costs and difficulties when\nrecruiting human annotators. To overcome this limitation, we propose a method\nto compare intrinsic gender bias evaluation measures without relying on\nhuman-annotated examples. Specifically, we create multiple bias-controlled\nversions of PLMs using varying amounts of male vs. female gendered sentences,\nmined automatically from an unannotated corpus using gender-related word lists.\nNext, each bias-controlled PLM is evaluated using an intrinsic bias evaluation\nmeasure, and the rank correlation between the computed bias scores and the\ngender proportions used to fine-tune the PLMs is computed. Experiments on\nmultiple corpora and PLMs repeatedly show that the correlations reported by our\nproposed method that does not require human annotated examples are comparable\nto those computed using human annotated examples in prior work.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaneko_M/0/1/0/all/0/1\">Masahiro Kaneko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">Danushka Bollegala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okazaki_N/0/1/0/all/0/1\">Naoaki Okazaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Pre-trained Language Models for Antibody. (arXiv:2301.12112v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12112","description":"<p>Antibodies are vital proteins offering robust protection for the human body\nfrom pathogens. The development of general protein and antibody-specific\npre-trained language models both facilitate antibody prediction tasks. However,\nfew studies comprehensively explore the representation capability of distinct\npre-trained language models on different antibody problems. Here, to\ninvestigate the problem, we aim to answer the following key questions: (1) How\ndo pre-trained language models perform in antibody tasks with different\nspecificity? (2) How many benefits will the model gain if we introduce the\nspecific biological mechanism to the pre-training process? (3) Do the learned\nantibody pre-trained representations make sense in real-world antibody\nproblems, like drug discovery and immune process understanding? Previously, no\nbenchmark available largely hindered the study to answer these questions. To\nfacilitate the investigation, we provide an AnTibody Understanding Evaluation\n(ATUE) benchmark. We comprehensively evaluate the performance of protein\npre-trained language models by empirical study along with conclusions and new\ninsights. Our ATUE and code are released at https://github.com/dqwang122/EATLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Danqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_F/0/1/0/all/0/1\">Fei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoPEFT: Automatic Configuration Search for Parameter-Efficient Fine-Tuning. (arXiv:2301.12132v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12132","description":"<p>Large pretrained language models have been widely used in downstream NLP\ntasks via task-specific fine-tuning. Recently, an array of Parameter-Efficient\nFine-Tuning (PEFT) methods have also achieved strong task performance while\nupdating a much smaller number of parameters compared to full model tuning.\nHowever, it is non-trivial to make informed per-task design choices (i.e., to\ncreate PEFT configurations) concerning the selection of PEFT architectures and\nmodules, the number of tunable parameters, and even the layers in which the\nPEFT modules are inserted. Consequently, it is highly likely that the current,\nmanually set PEFT configurations might be suboptimal for many tasks from the\nperspective of the performance-to-efficiency trade-off. To address the core\nquestion of the PEFT configuration selection that aims to control and maximise\nthe balance between performance and parameter efficiency, we first define a\nrich configuration search space spanning multiple representative PEFT modules\nalong with finer-grained configuration decisions over the modules (e.g.,\nparameter budget, insertion layer). We then propose AutoPEFT, a novel framework\nto traverse this configuration space: it automatically configures multiple PEFT\nmodules via high-dimensional Bayesian optimisation. We show the resource\nscalability and task transferability of AutoPEFT-found configurations,\noutperforming existing PEFT methods on average on the standard GLUE benchmark\nwhile conducting the configuration search on a single task. The per-task\nAutoPEFT-based configuration search even outperforms full-model fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Han Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1\">Anna Korhonen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Underwater Robotics Semantic Parser Assistant. (arXiv:2301.12134v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12134","description":"<p>Semantic parsing is a means of taking natural language and putting it in a\nform that a computer can understand. There has been a multitude of approaches\nthat take natural language utterances and form them into lambda calculus\nexpressions -- mathematical functions to describe logic. Here, we experiment\nwith a sequence to sequence model to take natural language utterances, convert\nthose to lambda calculus expressions, when can then be parsed, and place them\nin an XML format that can be used by a finite state machine. Experimental\nresults show that we can have a high accuracy model such that we can bridge the\ngap between technical and nontechnical individuals in the robotics field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Parekh_P/0/1/0/all/0/1\">Parth Parekh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McGuire_C/0/1/0/all/0/1\">Cedric McGuire</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Imyak_J/0/1/0/all/0/1\">Jake Imyak</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark Datasets. (arXiv:2301.12139v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12139","description":"<p>We evaluate five English NLP benchmark datasets (available on the superGLUE\nleaderboard) for bias, along multiple axes. The datasets are the following:\nBoolean Question (Boolq), CommitmentBank (CB), Winograd Schema Challenge (WSC),\nWinogender diagnostic (AXg), and Recognising Textual Entailment (RTE). Bias can\nbe harmful and it is known to be common in data, which ML models learn from. In\norder to mitigate bias in data, it is crucial to be able to estimate it\nobjectively. We use bipol, a novel multi-axes bias metric with explainability,\nto quantify and explain how much bias exists in these datasets. Multilingual,\nmulti-axes bias evaluation is not very common. Hence, we also contribute a new,\nlarge labelled Swedish bias-detection dataset, with about 2 million samples;\ntranslated from the English version. In addition, we contribute new multi-axes\nlexica for bias detection in Swedish. We train a SotA model on the new dataset\nfor bias detection. We make the codes, model, and new dataset publicly\navailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Adewumi_T/0/1/0/all/0/1\">Tosin Adewumi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sodergren_I/0/1/0/all/0/1\">Isabella S&#xf6;dergren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhaled_L/0/1/0/all/0/1\">Lama Alkhaled</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabry_S/0/1/0/all/0/1\">Sana Sabah Sabry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_F/0/1/0/all/0/1\">Foteini Liwicki</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1\">Marcus Liwicki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Sentence Transformer as A Multilingual Word Aligner. (arXiv:2301.12140v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12140","description":"<p>Multilingual pretrained language models (mPLMs) have shown their\neffectiveness in multilingual word alignment induction. However, these methods\nusually start from mBERT or XLM-R. In this paper, we investigate whether\nmultilingual sentence Transformer LaBSE is a strong multilingual word aligner.\nThis idea is non-trivial as LaBSE is trained to learn language-agnostic\nsentence-level embeddings, while the alignment extraction task requires the\nmore fine-grained word-level embeddings to be language-agnostic. We demonstrate\nthat the vanilla LaBSE outperforms other mPLMs currently used in the alignment\ntask, and then propose to finetune LaBSE on parallel corpus for further\nimprovement. Experiment results on seven language pairs show that our best\naligner outperforms previous state-of-the-art models of all varieties. In\naddition, our aligner supports different language pairs in a single model, and\neven achieves new state-of-the-art on zero-shot language pairs that does not\nappear in the finetuning process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weikang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Guanhua Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hanqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1\">Yue Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Tagging with LSTM-CRF. (arXiv:2301.12206v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12206","description":"<p>In the present paper, two models are presented namely LSTM-CRF and\nBERT-LSTM-CRF for semantic tagging of universal semantic tag dataset. The\nexperiments show that the first model is much easier to converge while the\nsecond model that leverages BERT embedding, takes a long time to converge and\nneeds a big dataset for semtagging to be effective.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Noravesh_F/0/1/0/all/0/1\">Farshad Noravesh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Parsing for Conversational Question Answering over Knowledge Graphs. (arXiv:2301.12217v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12217","description":"<p>In this paper, we are interested in developing semantic parsers which\nunderstand natural language questions embedded in a conversation with a user\nand ground them to formal queries over definitions in a general purpose\nknowledge graph (KG) with very large vocabularies (covering thousands of\nconcept names and relations, and millions of entities). To this end, we develop\na dataset where user questions are annotated with Sparql parses and system\nanswers correspond to execution results thereof. We present two different\nsemantic parsing approaches and highlight the challenges of the task: dealing\nwith large vocabularies, modelling conversation context, predicting queries\nwith multiple entities, and generalising to new questions at test time. We hope\nour dataset will serve as useful testbed for the development of conversational\nsemantic parsers. Our dataset and models are released at\nhttps://github.com/EdinburghNLP/SPICE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perez_Beltrachini_L/0/1/0/all/0/1\">Laura Perez-Beltrachini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Parag Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monti_E/0/1/0/all/0/1\">Emilio Monti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Presence of informal language, such as emoticons, hashtags, and slang, impact the performance of sentiment analysis models on social media text?. (arXiv:2301.12303v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12303","description":"<p>This study aimed to investigate the influence of the presence of informal\nlanguage, such as emoticons and slang, on the performance of sentiment analysis\nmodels applied to social media text. A convolutional neural network (CNN) model\nwas developed and trained on three datasets: a sarcasm dataset, a sentiment\ndataset, and an emoticon dataset. The model architecture was held constant for\nall experiments and the model was trained on 80% of the data and tested on 20%.\nThe results revealed that the model achieved an accuracy of 96.47% on the\nsarcasm dataset, with the lowest accuracy for class 1. On the sentiment\ndataset, the model achieved an accuracy of 95.28%. The amalgamation of sarcasm\nand sentiment datasets improved the accuracy of the model to 95.1%, and the\naddition of emoticon dataset has a slight positive impact on the accuracy of\nthe model to 95.37%. The study suggests that the presence of informal language\nhas a restricted impact on the performance of sentiment analysis models applied\nto social media text. However, the inclusion of emoticon data to the model can\nenhance the accuracy slightly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ganie_A/0/1/0/all/0/1\">Aadil Gani Ganie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MQAG: Multiple-choice Question Answering and Generation for Assessing Information Consistency in Summarization. (arXiv:2301.12307v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12307","description":"<p>State-of-the-art summarization systems can generate highly fluent summaries.\nThese summaries, however, may contain factual inconsistencies and/or\ninformation not present in the source. Hence, an important component of\nassessing the quality of summaries is to determine whether there is information\nconsistency between the source and the summary. Existing approaches are\ntypically based on lexical matching or representation-based methods. In this\nwork, we introduce an alternative scheme based on standard\ninformation-theoretic measures in which the information present in the source\nand summary is directly compared. We propose a Multiple-choice Question\nAnswering and Generation framework, MQAG, which approximates the information\nconsistency by computing the expected KL-divergence between summary and source\nanswer distributions over automatically generated multiple-choice questions.\nThis approach exploits multiple-choice answer probabilities, as predicted\nanswer distributions can be easily compared. We conduct experiments on four\nsummary evaluation datasets: QAG-CNNDM/XSum, XSum-Faithfulness, Podcast\nAssessment, and SummEval. Experiments show that MQAG (using models trained on\nRACE) outperforms existing evaluation methods on the majority of tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Manakul_P/0/1/0/all/0/1\">Potsawee Manakul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liusie_A/0/1/0/all/0/1\">Adian Liusie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J. F. Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Progressive Prompts: Continual Learning for Language Models. (arXiv:2301.12314v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12314","description":"<p>We introduce Progressive Prompts - a simple and efficient approach for\ncontinual learning in language models. Our method allows forward transfer and\nresists catastrophic forgetting, without relying on data replay or a large\nnumber of task-specific parameters. Progressive Prompts learns a new soft\nprompt for each task and sequentially concatenates it with the previously\nlearned prompts, while keeping the base model frozen. Experiments on standard\ncontinual learning benchmarks show that our approach outperforms\nstate-of-the-art methods, with an improvement &gt;20% in average test accuracy\nover the previous best-preforming method on T5 model. We also explore a more\nchallenging continual learning setup with longer sequences of tasks and show\nthat Progressive Prompts significantly outperforms prior methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Razdaibiedina_A/0/1/0/all/0/1\">Anastasia Razdaibiedina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1\">Amjad Almahairi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Time out of Mind: Generating Emotionally Conditioned Rate of Speech. (arXiv:2301.12331v1 [cs.CL])","link":"http://arxiv.org/abs/2301.12331","description":"<p>Voice synthesis has seen significant improvements in the past decade\nresulting in highly intelligible voices. Further investigations have resulted\nin models that can produce variable speech, including conditional emotional\nexpression. The problem lies, however, in a focus on phrase level modifications\nand prosodic vocal features. Using the CREMA-D dataset we have trained a GAN\nconditioned on emotion to generate worth lengths for a given input text. These\nword lengths are relative to neutral speech and can be provided, through speech\nsynthesis markup language (SSML) to a text to speech (TTS) system to generate\nmore expressive speech. We were able to achieve better performances on\nobjective measures for neutral speech, and better time alignment for happy\nspeech when compared to an out of box model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaur_N/0/1/0/all/0/1\">Navjot Kaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuttosi_P/0/1/0/all/0/1\">Paige Tuttosi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Achieving Timestamp Prediction While Recognizing with Non-Autoregressive End-to-End ASR Model. (arXiv:2301.12343v1 [cs.SD])","link":"http://arxiv.org/abs/2301.12343","description":"<p>Conventional ASR systems use frame-level phoneme posterior to conduct\nforce-alignment~(FA) and provide timestamps, while end-to-end ASR systems\nespecially AED based ones are short of such ability. This paper proposes to\nperform timestamp prediction~(TP) while recognizing by utilizing continuous\nintegrate-and-fire~(CIF) mechanism in non-autoregressive ASR model -\nParaformer. Foucing on the fire place bias issue of CIF, we conduct\npost-processing strategies including fire-delay and silence insertion. Besides,\nwe propose to use scaled-CIF to smooth the weights of CIF output, which is\nproved beneficial for both ASR and TP task. Accumulated averaging shift~(AAS)\nand diarization error rate~(DER) are adopted to measure the quality of\ntimestamps and we compare these metrics of proposed system and conventional\nhybrid force-alignment system. The experiment results over manually-marked\ntimestamps testset show that the proposed optimization methods significantly\nimprove the accuracy of CIF timestamps, reducing 66.7\\% and 82.1\\% of AAS and\nDER respectively. Comparing to Kaldi force-alignment trained with the same\ndata, optimized CIF timestamps achieved 12.3\\% relative AAS reduction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yanni Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shiliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1\">Zhijie Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SeaD: End-to-end Text-to-SQL Generation with Schema-aware Denoising. (arXiv:2105.07911v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2105.07911","description":"<p>In text-to-SQL task, seq-to-seq models often lead to sub-optimal performance\ndue to limitations in their architecture. In this paper, we present a simple\nyet effective approach that adapts transformer-based seq-to-seq model to robust\ntext-to-SQL generation. Instead of inducing constraint to decoder or reformat\nthe task as slot-filling, we propose to train seq-to-seq model with Schema\naware Denoising (SeaD), which consists of two denoising objectives that train\nmodel to either recover input or predict output from two novel erosion and\nshuffle noises. These denoising objectives acts as the auxiliary tasks for\nbetter modeling the structural data in S2S generation. In addition, we improve\nand propose a clause-sensitive execution guided (EG) decoding strategy to\novercome the limitation of EG decoding for generative model. The experiments\nshow that the proposed method improves the performance of seq-to-seq model in\nboth schema linking and grammar correctness and establishes new\nstate-of-the-art on WikiSQL benchmark. The results indicate that the capacity\nof vanilla seq-to-seq architecture for text-to-SQL may have been\nunder-estimated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1\">Kuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongbo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yongliang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1\">Zujie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yang Dong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Systematic Investigation of Strategies Tailored for Low-Resource Settings for Low-Resource Dependency Parsing. (arXiv:2201.11374v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.11374","description":"<p>In this work, we focus on low-resource dependency parsing for multiple\nlanguages. Several strategies are tailored to enhance performance in\nlow-resource scenarios. While these are well-known to the community, it is not\ntrivial to select the best-performing combination of these strategies for a\nlow-resource language that we are interested in, and not much attention has\nbeen given to measuring the efficacy of these strategies. We experiment with 5\nlow-resource strategies for our ensembled approach on 7 Universal Dependency\n(UD) low-resource languages. Our exhaustive experimentation on these languages\nsupports the effective improvements for languages not covered in pretrained\nmodels. We show a successful application of the ensembled system on a truly\nlow-resource language Sanskrit. The code and data are available at:\nhttps://github.com/Jivnesh/SanDP\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sandhan_J/0/1/0/all/0/1\">Jivnesh Sandhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Behera_L/0/1/0/all/0/1\">Laxmidhar Behera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1\">Pawan Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AdapterBias: Parameter-efficient Token-dependent Representation Shift for Adapters in NLP Tasks. (arXiv:2205.00305v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.00305","description":"<p>Transformer-based pre-trained models with millions of parameters require\nlarge storage. Recent approaches tackle this shortcoming by training adapters,\nbut these approaches still require a relatively large number of parameters. In\nthis study, AdapterBias, a surprisingly simple yet effective adapter\narchitecture, is proposed. AdapterBias adds a token-dependent shift to the\nhidden output of transformer layers to adapt to downstream tasks with only a\nvector and a linear layer. Extensive experiments are conducted to demonstrate\nthe effectiveness of AdapterBias. The experiments show that our proposed method\ncan dramatically reduce the trainable parameters compared to the previous works\nwith a minimal decrease in task performances compared with fine-tuned\npre-trained models. We further find that AdapterBias automatically learns to\nassign more significant representation shifts to the tokens related to the task\nin consideration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chin-Lun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zih-Ching Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1\">Yun-Ru Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models are Zero-Shot Reasoners. (arXiv:2205.11916v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11916","description":"<p>Pretrained large language models (LLMs) are widely used in many sub-fields of\nnatural language processing (NLP) and generally known as excellent few-shot\nlearners with task-specific exemplars. Notably, chain of thought (CoT)\nprompting, a recent technique for eliciting complex multi-step reasoning\nthrough step-by-step answer examples, achieved the state-of-the-art\nperformances in arithmetics and symbolic reasoning, difficult system-2 tasks\nthat do not follow the standard scaling laws for LLMs. While these successes\nare often attributed to LLMs' ability for few-shot learning, we show that LLMs\nare decent zero-shot reasoners by simply adding \"Let's think step by step\"\nbefore each answer. Experimental results demonstrate that our Zero-shot-CoT,\nusing the same single prompt template, significantly outperforms zero-shot LLM\nperformances on diverse benchmark reasoning tasks including arithmetics\n(MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin\nFlip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled\nObjects), without any hand-crafted few-shot examples, e.g. increasing the\naccuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with\nlarge InstructGPT model (text-davinci-002), as well as similar magnitudes of\nimprovements with another off-the-shelf large model, 540B parameter PaLM. The\nversatility of this single prompt across very diverse reasoning tasks hints at\nuntapped and understudied fundamental zero-shot capabilities of LLMs,\nsuggesting high-level, multi-task broad cognitive capabilities may be extracted\nby simple prompting. We hope our work not only serves as the minimal strongest\nzero-shot baseline for the challenging reasoning benchmarks, but also\nhighlights the importance of carefully exploring and analyzing the enormous\nzero-shot knowledge hidden inside LLMs before crafting finetuning datasets or\nfew-shot exemplars.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kojima_T/0/1/0/all/0/1\">Takeshi Kojima</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1\">Shixiang Shane Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reid_M/0/1/0/all/0/1\">Machel Reid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsuo_Y/0/1/0/all/0/1\">Yutaka Matsuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Iwasawa_Y/0/1/0/all/0/1\">Yusuke Iwasawa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning Locality and Isotropy in Dialogue Modeling. (arXiv:2205.14583v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.14583","description":"<p>Existing dialogue modeling methods have achieved promising performance on\nvarious dialogue tasks with the aid of Transformer and the large-scale\npre-trained language models. However, some recent studies revealed that the\ncontext representations produced by these methods suffer the problem of\nanisotropy. In this paper, we find that the generated representations are also\nnot conversational, losing the conversation structure information during the\ncontext modeling stage. To this end, we identify two properties in dialogue\nmodeling, i.e., locality and isotropy, and present a simple method for dialogue\nrepresentation calibration, namely SimDRC, to build isotropic and\nconversational feature spaces. Experimental results show that our approach\nsignificantly outperforms the current state-of-the-art models on three dialogue\ntasks across the automatic and human evaluation metrics. More in-depth analyses\nfurther confirm the effectiveness of our proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1\">Haochen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_M/0/1/0/all/0/1\">Mingjie Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1\">Gangming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1\">Shaoqing Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Ding Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making sense of spoken plurals. (arXiv:2207.01947v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.01947","description":"<p>Distributional semantics offers new ways to study the semantics of\nmorphology. This study focuses on the semantics of noun singulars and their\nplural inflectional variants in English. Our goal is to compare two models for\nthe conceptualization of plurality. One model (FRACSS) proposes that all\nsingular-plural pairs should be taken into account when predicting plural\nsemantics from singular semantics. The other model (CCA) argues that\nconceptualization for plurality depends primarily on the semantic class of the\nbase word. We compare the two models on the basis of how well the speech signal\nof plural tokens in a large corpus of spoken American English aligns with the\nsemantic vectors predicted by the two models. Two measures are employed: the\nperformance of a form-to-meaning mapping and the correlations between form\ndistances and meaning distances. Results converge on a superior alignment for\nCCA. Our results suggest that usage-based approaches to pluralization in which\na given word's own semantic neighborhood is given priority outperform theories\naccording to which pluralization is conceptualized as a process building on\nhigh-level abstraction. We see that what has often been conceived of as a\nhighly abstract concept, [+plural], is better captured via a family of\nmid-level partial generalizations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shafaei_Bajestan_E/0/1/0/all/0/1\">Elnaz Shafaei-Bajestan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uhrig_P/0/1/0/all/0/1\">Peter Uhrig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baayen_R/0/1/0/all/0/1\">R. Harald Baayen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward Transparent AI: A Survey on Interpreting the Inner Structures of Deep Neural Networks. (arXiv:2207.13243v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2207.13243","description":"<p>The last decade of machine learning has seen drastic increases in scale and\ncapabilities. Deep neural networks (DNNs) are increasingly being deployed in\nthe real world. However, they are difficult to analyze, raising concerns about\nusing them without a rigorous understanding of how they function. Effective\ntools for interpreting them will be important for building more trustworthy AI\nby helping to identify problems, fix bugs, and improve basic understanding. In\nparticular, \"inner\" interpretability techniques, which focus on explaining the\ninternal components of DNNs, are well-suited for developing a mechanistic\nunderstanding, guiding manual modifications, and reverse engineering solutions.\n</p>\n<p>Much recent work has focused on DNN interpretability, and rapid progress has\nthus far made a thorough systematization of methods difficult. In this survey,\nwe review over 300 works with a focus on inner interpretability tools. We\nintroduce a taxonomy that classifies methods by what part of the network they\nhelp to explain (weights, neurons, subnetworks, or latent representations) and\nwhether they are implemented during (intrinsic) or after (post hoc) training.\nTo our knowledge, we are also the first to survey a number of connections\nbetween interpretability research and work in adversarial robustness, continual\nlearning, modularity, network compression, and studying the human visual\nsystem. We discuss key challenges and argue that the status quo in\ninterpretability research is largely unproductive. Finally, we highlight the\nimportance of future work that emphasizes diagnostics, debugging, adversaries,\nand benchmarking in order to make interpretability tools more useful to\nengineers in practical applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rauker_T/0/1/0/all/0/1\">Tilman R&#xe4;uker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ho_A/0/1/0/all/0/1\">Anson Ho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casper_S/0/1/0/all/0/1\">Stephen Casper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1\">Dylan Hadfield-Menell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Complexity-Based Prompting for Multi-Step Reasoning. (arXiv:2210.00720v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.00720","description":"<p>We study the task of prompting large-scale language models to perform\nmulti-step reasoning. Existing work shows that when prompted with a chain of\nthoughts (CoT), sequences of short sentences describing intermediate reasoning\nsteps towards a final answer, large language models can generate new reasoning\nchains and predict answers for new inputs. A central question is which\nreasoning examples make the most effective prompts. In this work, we propose\ncomplexity-based prompting, a simple and effective example selection scheme for\nmulti-step reasoning. We show that prompts with higher reasoning complexity,\ni.e., chains with more reasoning steps, achieve substantially better\nperformance on multi-step reasoning tasks over strong baselines. We further\nextend our complexity-based criteria from prompting (selecting inputs) to\ndecoding (selecting outputs), where we sample multiple reasoning chains from\nthe model, then choose the majority of generated answers from complex reasoning\nchains (over simple chains). When used to prompt GPT-3 and Codex, our approach\nsubstantially improves multi-step reasoning accuracy and achieves new\nstate-of-the-art (SOTA) performance on three math benchmarks (GSM8K,\nMultiArith, and MathQA) and two BigBenchHard tasks (Date Understanding and\nPenguins), with an average +5.3 and up to +18 accuracy improvements. Compared\nwith existing example selection schemes like manual tuning or retrieval-based\nselection, selection based on reasoning complexity is intuitive, easy to\nimplement, and annotation-efficient. Further results demonstrate the robustness\nof performance gains from complex prompts under format perturbation and\ndistribution shift.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1\">Yao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1\">Hao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1\">Ashish Sabharwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1\">Peter Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1\">Tushar Khot</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enriching Biomedical Knowledge for Low-resource Language Through Large-Scale Translation. (arXiv:2210.05598v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.05598","description":"<p>Biomedical data and benchmarks are highly valuable yet very limited in\nlow-resource languages other than English such as Vietnamese. In this paper, we\nmake use of a state-of-the-art translation model in English-Vietnamese to\ntranslate and produce both pretrained as well as supervised data in the\nbiomedical domains. Thanks to such large-scale translation, we introduce\nViPubmedT5, a pretrained Encoder-Decoder Transformer model trained on 20\nmillion translated abstracts from the high-quality public PubMed corpus.\nViPubMedT5 demonstrates state-of-the-art results on two different biomedical\nbenchmarks in summarization and acronym disambiguation. Further, we release\nViMedNLI - a new NLP task in Vietnamese translated from MedNLI using the\nrecently public En-vi translation model and carefully refined by human experts,\nwith evaluations of existing methods against ViPubmedT5.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Phan_L/0/1/0/all/0/1\">Long Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1\">Tai Dang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Hieu Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trinh_T/0/1/0/all/0/1\">Trieu H. Trinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phan_V/0/1/0/all/0/1\">Vy Phan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1\">Lam D. Chau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luong_M/0/1/0/all/0/1\">Minh-Thang Luong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CS-Insights: A System for Analyzing Computer Science Research. (arXiv:2210.06878v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.06878","description":"<p>This paper presents CS-Insights, an interactive web application to analyze\ncomputer science publications from DBLP through multiple perspectives. The\ndedicated interfaces allow its users to identify trends in research activity,\nproductivity, accessibility, author's productivity, venues' statistics, topics\nof interest, and the impact of computer science research on other fields.\nCS-Insightsis publicly available, and its modular architecture can be easily\nadapted to domains other than computer science.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ruas_T/0/1/0/all/0/1\">Terry Ruas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wahle_J/0/1/0/all/0/1\">Jan Philip Wahle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kull_L/0/1/0/all/0/1\">Lennart K&#xfc;ll</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gipp_B/0/1/0/all/0/1\">Bela Gipp</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation Extraction. (arXiv:2210.11800v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.11800","description":"<p>Relation extraction (RE) has achieved remarkable progress with the help of\npre-trained language models. However, existing RE models are usually incapable\nof handling two situations: implicit expressions and long-tail relation types,\ncaused by language complexity and data sparsity. In this paper, we introduce a\nsimple enhancement of RE using $k$ nearest neighbors ($k$NN-RE). $k$NN-RE\nallows the model to consult training relations at test time through a\nnearest-neighbor search and provides a simple yet effective means to tackle the\ntwo issues above. Additionally, we observe that $k$NN-RE serves as an effective\nway to leverage distant supervision (DS) data for RE. Experimental results show\nthat the proposed $k$NN-RE achieves state-of-the-art performances on a variety\nof supervised RE datasets, i.e., ACE05, SciERC, and Wiki80, along with\noutperforming the best model to date on the i2b2 and Wiki80 datasets in the\nsetting of allowing using DS. Our code and models are available at:\nhttps://github.com/YukinoWan/kNN-RE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qianying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhuoyuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergent Linguistic Structures in Neural Networks are Fragile. (arXiv:2210.17406v5 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2210.17406","description":"<p>Large Language Models (LLMs) have been reported to have strong performance on\nnatural language processing tasks. However, performance metrics such as\naccuracy do not measure the quality of the model in terms of its ability to\nrobustly represent complex linguistic structure. In this work, we propose a\nframework and measure of robustness to assess the consistency of linguistic\nrepresentations against syntax-preserving perturbations. We leverage recent\nadvances in extracting linguistic constructs from LLMs to test the robustness\nof such structures. Empirically, we study the performance of four LLMs across\nsix different corpora on the proposed robustness measures. We provide evidence\nthat context-free representation (e.g., GloVe) are in some cases competitive\nwith context-dependent representations from modern LLMs (e.g., BERT), yet\nequally brittle to syntax-preserving manipulations. Emergent syntactic\nrepresentations in neural networks are brittle, thus our work poses the\nattention on the risk of comparing such structures to those that are object of\na long lasting debate in linguistics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malfa_E/0/1/0/all/0/1\">Emanuele La Malfa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicker_M/0/1/0/all/0/1\">Matthew Wicker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kiatkowska_M/0/1/0/all/0/1\">Marta Kiatkowska</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning. (arXiv:2212.01117v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.01117","description":"<p>The spread of rumors along with breaking events seriously hinders the truth\nin the era of social media. Previous studies reveal that due to the lack of\nannotated resources, rumors presented in minority languages are hard to be\ndetected. Furthermore, the unforeseen breaking events not involved in\nyesterday's news exacerbate the scarcity of data resources. In this work, we\npropose a novel zero-shot framework based on prompt learning to detect rumors\nfalling in different domains or presented in different languages. More\nspecifically, we firstly represent rumor circulated on social media as diverse\npropagation threads, then design a hierarchical prompt encoding mechanism to\nlearn language-agnostic contextual representations for both prompts and rumor\ndata. To further enhance domain adaptation, we model the domain-invariant\nstructural features from the propagation threads, to incorporate structural\nposition representations of influential community response. In addition, a new\nvirtual response augmentation method is used to improve model training.\nExtensive experiments conducted on three real-world datasets demonstrate that\nour proposed model achieves much better performance than state-of-the-art\nmethods and exhibits a superior capacity for detecting rumors at early stages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1\">Hongzhan Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_P/0/1/0/all/0/1\">Pengyao Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jing Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1\">Haiyun Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1\">Ziyang Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1\">Shuming Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Ruifang Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Training-Free Structured Diffusion Guidance for Compositional Text-to-Image Synthesis. (arXiv:2212.05032v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2212.05032","description":"<p>Large-scale diffusion models have achieved state-of-the-art results on\ntext-to-image synthesis (T2I) tasks. Despite their ability to generate\nhigh-quality yet creative images, we observe that attribution-binding and\ncompositional capabilities are still considered major challenging issues,\nespecially when involving multiple objects. In this work, we improve the\ncompositional skills of T2I models, specifically more accurate attribute\nbinding and better image compositions. To do this, we incorporate linguistic\nstructures with the diffusion guidance process based on the controllable\nproperties of manipulating cross-attention layers in diffusion-based T2I\nmodels. We observe that keys and values in cross-attention layers have strong\nsemantic meanings associated with object layouts and content. Therefore, we can\nbetter preserve the compositional semantics in the generated image by\nmanipulating the cross-attention representations based on linguistic insights.\nBuilt upon Stable Diffusion, a SOTA T2I model, our structured cross-attention\ndesign is efficient that requires no additional training samples. We achieve\nbetter compositional skills in qualitative and quantitative results, leading to\na 5-8% advantage in head-to-head user comparison studies. Lastly, we conduct an\nin-depth analysis to reveal potential causes of incorrect image compositions\nand justify the properties of cross-attention layers in the generation process.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Weixi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1\">Xuehai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1\">Tsu-Jui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1\">Varun Jampani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akula_A/0/1/0/all/0/1\">Arjun Akula</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Narayana_P/0/1/0/all/0/1\">Pradyumna Narayana</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1\">Sugato Basu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Eric Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments. (arXiv:2212.07425v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.07425","description":"<p>The spread of misinformation, propaganda, and flawed argumentation has been\namplified in the Internet era. Given the volume of data and the subtlety of\nidentifying violations of argumentation norms, supporting information analytics\ntasks, like content moderation, with trustworthy methods that can identify\nlogical fallacies is essential. In this paper, we formalize prior theoretical\nwork on logical fallacies into a comprehensive three-stage evaluation framework\nof detection, coarse-grained, and fine-grained classification. We adapt\nexisting evaluation datasets for each stage of the evaluation. We employ three\nfamilies of robust and explainable methods based on prototype reasoning,\ninstance-based reasoning, and knowledge injection. The methods combine language\nmodels with background knowledge and explainable mechanisms. Moreover, we\naddress data sparsity with strategies for data augmentation and curriculum\nlearning. Our three-stage framework natively consolidates prior datasets and\nmethods from existing tasks, like propaganda detection, serving as an\noverarching evaluation testbed. We extensively evaluate these methods on our\ndatasets, focusing on their robustness and explainability. Our results provide\ninsight into the strengths and weaknesses of the methods on different\ncomponents and fallacy classes, indicating that fallacy identification is a\nchallenging task that may require specialized forms of reasoning to capture\nvarious classes. We share our open-source code and data on GitHub to support\nfurther work on logical fallacy identification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sourati_Z/0/1/0/all/0/1\">Zhivar Sourati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Venkatesh_V/0/1/0/all/0/1\">Vishnu Priya Prasanna Venkatesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshpande_D/0/1/0/all/0/1\">Darshan Deshpande</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawlani_H/0/1/0/all/0/1\">Himanshu Rawlani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ilievski_F/0/1/0/all/0/1\">Filip Ilievski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sandlin_H/0/1/0/all/0/1\">H&#xf4;ng-&#xc2;n Sandlin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mermoud_A/0/1/0/all/0/1\">Alain Mermoud</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OPT-IML: Scaling Language Model Instruction Meta Learning through the Lens of Generalization. (arXiv:2212.12017v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.12017","description":"<p>Recent work has shown that fine-tuning large pre-trained language models on a\ncollection of tasks described via instructions, a.k.a. instruction-tuning,\nimproves their zero and few-shot generalization to unseen tasks. However, there\nis a limited understanding of the performance trade-offs of different decisions\nmade during the instruction-tuning process. These decisions include the scale\nand diversity of the instruction-tuning benchmark, different task sampling\nstrategies, fine-tuning with and without demonstrations, training using\nspecialized datasets for reasoning and dialogue, and finally, the fine-tuning\nobjectives themselves. In this paper, we characterize the effect of\ninstruction-tuning decisions on downstream task performance when scaling both\nmodel and benchmark sizes. To this end, we create OPT-IML Bench: a large\nbenchmark for Instruction Meta-Learning (IML) of 2000 NLP tasks consolidated\ninto task categories from 8 existing benchmarks, and prepare an evaluation\nframework to measure three types of model generalizations: to tasks from fully\nheld-out categories, to held-out tasks from seen categories, and to held-out\ninstances from seen tasks. Through the lens of this framework, we first present\ninsights about instruction-tuning decisions as applied to OPT-30B and further\nexploit these insights to train OPT-IML 30B and 175B, which are\ninstruction-tuned versions of OPT. OPT-IML demonstrates all three\ngeneralization abilities at both scales on four different evaluation benchmarks\nwith diverse tasks and input formats -- PromptSource, FLAN,\nSuper-NaturalInstructions, and UnifiedSKG. Not only does it significantly\noutperform OPT on all benchmarks but is also highly competitive with existing\nmodels fine-tuned on each specific benchmark. We release OPT-IML at both\nscales, together with the OPT-IML Bench evaluation framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iyer_S/0/1/0/all/0/1\">Srinivasan Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1\">Ramakanth Pasunuru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihaylov_T/0/1/0/all/0/1\">Todor Mihaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Simig_D/0/1/0/all/0/1\">Daniel Simig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Ping Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shuster_K/0/1/0/all/0/1\">Kurt Shuster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianlu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koura_P/0/1/0/all/0/1\">Punit Singh Koura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OHoro_B/0/1/0/all/0/1\">Brian O&#x27;Horo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pereyra_G/0/1/0/all/0/1\">Gabriel Pereyra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jeff Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dewan_C/0/1/0/all/0/1\">Christopher Dewan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Ves Stoyanov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Corporate Lobbyists. (arXiv:2301.01181v7 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.01181","description":"<p>We demonstrate a proof-of-concept of a large language model conducting\ncorporate lobbying related activities. An autoregressive large language model\n(OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are\nrelevant to specific public companies and provides explanations and confidence\nlevels. For the bills the model deems as relevant, the model drafts a letter to\nthe sponsor of the bill in an attempt to persuade the congressperson to make\nchanges to the proposed legislation. We use hundreds of novel ground-truth\nlabels of the relevance of a bill to a company to benchmark the performance of\nthe model. It outperforms the baseline of predicting the most common outcome of\nirrelevance. We also benchmark the performance of the previous OpenAI GPT-3\nmodel (text-davinci-002), which was the state-of-the-art model on many academic\nnatural language tasks until text-davinci-003 was recently released. The\nperformance of text-davinci-002 is worse than the simple baseline. Longer-term,\nif AI begins to influence law in a manner that is not a direct extension of\nhuman intentions, this threatens the critical role that law as information\ncould play in aligning AI with humans. Initially, AI is being used to simply\naugment human lobbyists for a small portion of their daily tasks. However,\nfirms have an incentive to use less and less human oversight over automated\nassessments of policy ideas and the written communication to regulatory\nagencies and Congressional staffers. The core question raised is where to draw\nthe line between human-driven and AI-driven policy influence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nay_J/0/1/0/all/0/1\">John J. Nay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Cohesive Distillation Architecture for Neural Language Models. (arXiv:2301.08130v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08130","description":"<p>A recent trend in Natural Language Processing is the exponential growth in\nLanguage Model (LM) size, which prevents research groups without a necessary\nhardware infrastructure from participating in the development process. This\nstudy investigates methods for Knowledge Distillation (KD) to provide efficient\nalternatives to large-scale models. In this context, KD means extracting\ninformation about language encoded in a Neural Network and Lexical Knowledge\nDatabases. We developed two methods to test our hypothesis that efficient\narchitectures can gain knowledge from LMs and extract valuable information from\nlexical sources. First, we present a technique to learn confident probability\ndistribution for Masked Language Modeling by prediction weighting of multiple\nteacher networks. Second, we propose a method for Word Sense Disambiguation\n(WSD) and lexical KD that is general enough to be adapted to many LMs. Our\nresults show that KD with multiple teachers leads to improved training\nconvergence. When using our lexical pre-training method, LM characteristics are\nnot lost, leading to increased performance in Natural Language Understanding\n(NLU) tasks over the state-of-the-art while adding no parameters. Moreover, the\nimproved semantic understanding of our model increased the task performance\nbeyond WSD and NLU in a real-problem scenario (Plagiarism Detection). This\nstudy suggests that sophisticated training methods and network architectures\ncan be superior over scaling trainable parameters. On this basis, we suggest\nthe research area should encourage the development and use of efficient models\nand rate impacts resulting from growing LM size equally against task\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wahle_J/0/1/0/all/0/1\">Jan Philip Wahle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dr.Spider: A Diagnostic Evaluation Benchmark towards Text-to-SQL Robustness. (arXiv:2301.08881v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.08881","description":"<p>Neural text-to-SQL models have achieved remarkable performance in translating\nnatural language questions into SQL queries. However, recent studies reveal\nthat text-to-SQL models are vulnerable to task-specific perturbations. Previous\ncurated robustness test sets usually focus on individual phenomena. In this\npaper, we propose a comprehensive robustness benchmark based on Spider, a\ncross-domain text-to-SQL benchmark, to diagnose the model robustness. We design\n17 perturbations on databases, natural language questions, and SQL queries to\nmeasure the robustness from different angles. In order to collect more\ndiversified natural question perturbations, we utilize large pretrained\nlanguage models (PLMs) to simulate human behaviors in creating natural\nquestions. We conduct a diagnostic study of the state-of-the-art models on the\nrobustness set. Experimental results reveal that even the most robust model\nsuffers from a 14.0% performance drop overall and a 50.7% performance drop on\nthe most challenging perturbation. We also present a breakdown analysis\nregarding text-to-SQL model designs and provide insights for improving model\nrobustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shuaichen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1\">Mingwen Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Lin Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Henghui Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Alexander Hanbo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_W/0/1/0/all/0/1\">Wuwei Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jiarong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lilien_J/0/1/0/all/0/1\">Joseph Lilien</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ash_S/0/1/0/all/0/1\">Steve Ash</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhiguo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Castelli_V/0/1/0/all/0/1\">Vittorio Castelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_P/0/1/0/all/0/1\">Patrick Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1\">Bing Xiang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics Without the Reference. (arXiv:2301.09008v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.09008","description":"<p>Machine translation quality estimation (QE) predicts human judgements of a\ntranslation hypothesis without seeing the reference. State-of-the-art QE\nsystems based on pretrained language models have been achieving remarkable\ncorrelations with human judgements yet they are computationally heavy and\nrequire human annotations, which are slow and expensive to create. To address\nthese limitations, we define the problem of metric estimation (ME) where one\npredicts the automated metric scores also without the reference. We show that\neven without access to the reference, our model can estimate automated metrics\n($\\rho$=60% for BLEU, $\\rho$=51% for other metrics) at the sentence-level.\nBecause automated metrics correlate with human judgements, we can leverage the\nME task for pre-training a QE model. For the QE task, we find that pre-training\non TER is better ($\\rho$=23%) than training for scratch ($\\rho$=20%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhuliawala_S/0/1/0/all/0/1\">Shehzaad Dhuliawala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1\">Nico Daheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocmi_T/0/1/0/all/0/1\">Tom Kocmi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yuchen Eleanor Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Fiduciaries: A Case Study Toward Robustly Communicating With Artificial Intelligence Through Legal Standards. (arXiv:2301.10095v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10095","description":"<p>Artificial Intelligence (AI) is taking on increasingly autonomous roles,\ne.g., browsing the web as a research assistant and managing money. But\nspecifying goals and restrictions for AI behavior is difficult. Similar to how\nparties to a legal contract cannot foresee every potential \"if-then\"\ncontingency of their future relationship, we cannot specify desired AI behavior\nfor all circumstances. Legal standards facilitate robust communication of\ninherently vague and underspecified goals. Instructions (in the case of\nlanguage models, \"prompts\") that employ legal standards will allow AI agents to\ndevelop shared understandings of the spirit of a directive that generalize\nexpectations regarding acceptable actions to take in unspecified states of the\nworld. Standards have built-in context that is lacking from other goal\nspecification languages, such as plain language and programming languages.\nThrough an empirical study on thousands of evaluation labels we constructed\nfrom U.S. court opinions, we demonstrate that large language models (LLMs) are\nbeginning to exhibit an \"understanding\" of one of the most relevant legal\nstandards for AI agents: fiduciary obligations. Performance comparisons across\nmodels suggest that, as LLMs continue to exhibit improved core capabilities,\ntheir legal standards understanding will also continue to improve. OpenAI's\nlatest LLM has 78% accuracy on our data, their previous release has 73%\naccuracy, and a model from their 2020 GPT-3 paper has 27% accuracy (worse than\nrandom). Our research is an initial step toward a framework for evaluating AI\nunderstanding of legal standards more broadly, and for conducting reinforcement\nlearning with legal feedback (RLLF).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nay_J/0/1/0/all/0/1\">John J. Nay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MTTN: Multi-Pair Text to Text Narratives for Prompt Generation. (arXiv:2301.10172v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10172","description":"<p>The increased interest in diffusion models has opened up opportunities for\nadvancements in generative text modeling. These models can produce impressive\nimages when given a well-crafted prompt, but creating a powerful or meaningful\nprompt can be hit-or-miss. To address this, we have created a large-scale\ndataset that is derived and synthesized from real prompts and indexed with\npopular image-text datasets such as MS-COCO and Flickr. We have also\nimplemented stages that gradually reduce context and increase complexity, which\nwill further enhance the output due to the complex annotations created. The\ndataset, called MTTN, includes over 2.4 million sentences divided into 5\nstages, resulting in a total of over 12 million pairs, and a vocabulary of over\n300,000 unique words, providing ample variation. The original 2.4 million pairs\nare designed to reflect the way language is used on the internet globally,\nmaking the dataset more robust for any model trained on it.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1\">Archan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1\">Debgandhar Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maji_M/0/1/0/all/0/1\">Madhurima Maji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chanda_S/0/1/0/all/0/1\">Suchinta Chanda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_K/0/1/0/all/0/1\">Kalporup Goswami</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER. (arXiv:2301.10410v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10410","description":"<p>Cross-domain NER is a challenging task to address the low-resource problem in\npractical scenarios. Previous typical solutions mainly obtain a NER model by\npre-trained language models (PLMs) with data from a rich-resource domain and\nadapt it to the target domain. Owing to the mismatch issue among entity types\nin different domains, previous approaches normally tune all parameters of PLMs,\nending up with an entirely new NER model for each domain. Moreover, current\nmodels only focus on leveraging knowledge in one general source domain while\nfailing to successfully transfer knowledge from multiple sources to the target.\nTo address these issues, we introduce Collaborative Domain-Prefix Tuning for\ncross-domain NER (CP-NER) based on text-to-text generative PLMs. Specifically,\nwe present text-to-text generation grounding domain-related instructors to\ntransfer knowledge to new domain NER tasks without structural modifications. We\nutilize frozen PLMs and conduct collaborative domain-prefix tuning to stimulate\nthe potential of PLMs to handle NER tasks across various domains. Experimental\nresults on the Cross-NER benchmark show that the proposed approach has flexible\ntransfer ability and performs better on both one-source and multiple-source\ncross-domain NER tasks. Codes will be available in\nhttps://github.com/zjunlp/DeepKE/tree/main/example/ner/cross.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiang Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1\">Shuofei Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1\">Chuanqi Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1\">Fei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Causal Reasoning of Entities and Events in Procedural Texts. (arXiv:2301.10896v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.10896","description":"<p>Entities and events have long been regarded as the crux of machine reasoning.\nSpecifically, procedural texts have received increasing attention due to the\ndynamic nature of involved entities and events. Existing work has exclusively\nfocused on entity state tracking (e.g., the temperature of a pan) or\ncounterfactual event reasoning (e.g., how likely am I to burn myself by\ntouching the pan), while these two tasks are tightly intertwined. In this work,\nwe propose CREPE, the first benchmark on causal reasoning about event\nplausibility based on entity states. We experiment with strong large language\nmodels and show that most models including GPT3 perform close to chance of .30\nF1, lagging far behind the human performance of .87 F1. Inspired by the finding\nthat structured representations such as programming languages benefits event\nreasoning as a prompt to code language models such as Codex, we creatively\ninject the causal relations between entities and events through intermediate\nvariables and boost the performance to .67 to .72 F1. Our proposed event\nrepresentation not only allows for knowledge injection, but also marks the\nfirst successful attempt of chain-of-thought reasoning with code language\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Li Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hainiu Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yue Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_W/0/1/0/all/0/1\">Weiqiu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_M/0/1/0/all/0/1\">Manni Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1\">Chris Callison-Burch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental Health on Social Media. (arXiv:2301.11004v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11004","description":"<p>Interactions among humans on social media often convey intentions behind\ntheir actions, yielding a psychological language resource for Mental Health\nAnalysis (MHA) of online users. The success of Computational Intelligence\nTechniques (CIT) for inferring mental illness from such social media resources\npoints to NLP as a lens for causal analysis and perception mining. However, we\nargue that more consequential and explainable research is required for optimal\nimpact on clinical psychology practice and personalized mental healthcare. To\nbridge this gap, we posit two significant dimensions: (1) Causal analysis to\nillustrate a cause and effect relationship in the user generated text; (2)\nPerception mining to infer psychological perspectives of social effects on\nonline users intentions. Within the scope of Natural Language Processing (NLP),\nwe further explore critical areas of inquiry associated with these two\ndimensions, specifically through recent advancements in discourse analysis.\nThis position paper guides the community to explore solutions in this space and\nadvance the state of practice in developing conversational agents for inferring\nmental health from social media. We advocate for a more explainable approach\ntoward modeling computational psychology problems through the lens of language\nas we observe an increased number of research contributions in dataset and\nproblem formulation for causal relation extraction and perception enhancements\nwhile inferring mental states.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garg_M/0/1/0/all/0/1\">Muskan Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_C/0/1/0/all/0/1\">Chandni Saxena</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naseem_U/0/1/0/all/0/1\">Usman Naseem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dorr_B/0/1/0/all/0/1\">Bonnie J Dorr</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Molecular Language Model as Multi-task Generator. (arXiv:2301.11259v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.11259","description":"<p>Molecule generation with desired properties has grown immensely in popularity\nby disruptively changing the way scientists design molecular structures and\nproviding support for chemical and materials design. However, despite the\npromising outcome, previous machine learning-based deep generative models\nsuffer from a reliance on complex, task-specific fine-tuning, limited\ndimensional latent spaces, or the quality of expert rules. In this work, we\npropose MolGen, a pre-trained molecular language model that effectively learns\nand shares knowledge across multiple generation tasks and domains.\nSpecifically, we pre-train MolGen with the chemical language SELFIES on more\nthan 100 million unlabelled molecules. We further propose multi-task molecular\nprefix tuning across several molecular generation tasks and different molecular\ndomains (synthetic &amp; natural products) with a self-feedback mechanism.\nExtensive experiments show that MolGen can obtain superior performances on\nwell-known molecular generation benchmark datasets. The further analysis\nillustrates that MolGen can accurately capture the distribution of molecules,\nimplicitly learn their structural characteristics, and efficiently explore the\nchemical space with the guidance of multi-task molecular prefix tuning. Codes,\ndatasets, and the pre-trained model will be available in\nhttps://github.com/zjunlp/MolGen.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yin Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1\">Xiaohui Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing Out-of-Distribution Robustness of Language Models with Parameter-Efficient Transfer Learning. (arXiv:2301.11660v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11660","description":"<p>As the size of the pre-trained language model (PLM) continues to increase,\nnumerous parameter-efficient transfer learning methods have been proposed\nrecently to compensate for the tremendous cost of fine-tuning. Despite the\nimpressive results achieved by large pre-trained language models (PLMs) and\nvarious parameter-efficient transfer learning (PETL) methods on sundry\nbenchmarks, it remains unclear if they can handle inputs that have been\ndistributionally shifted effectively. In this study, we systematically explore\nhow the ability to detect out-of-distribution (OOD) changes as the size of the\nPLM grows or the transfer methods are altered. Specifically, we evaluated\nvarious PETL techniques, including fine-tuning, Adapter, LoRA, and\nprefix-tuning, on three different intention classification tasks, each\nutilizing various language models with different scales.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1\">Hyunsoo Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Choonghyun Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Junyeop Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyuhng Joon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_K/0/1/0/all/0/1\">Kang Min Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1\">Sang-goo Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mo\\^usai: Text-to-Music Generation with Long-Context Latent Diffusion. (arXiv:2301.11757v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.11757","description":"<p>The recent surge in popularity of diffusion models for image generation has\nbrought new attention to the potential of these models in other areas of media\nsynthesis. One area that has yet to be fully explored is the application of\ndiffusion models to music generation. Music generation requires to handle\nmultiple aspects, including the temporal dimension, long-term structure,\nmultiple layers of overlapping sounds, and nuances that only trained listeners\ncan detect. In our work, we investigate the potential of diffusion models for\ntext-conditional music generation. We develop a cascading latent diffusion\napproach that can generate multiple minutes of high-quality stereo music at\n48kHz from textual descriptions. For each model, we make an effort to maintain\nreasonable inference speed, targeting real-time on a single consumer GPU. In\naddition to trained models, we provide a collection of open-source libraries\nwith the hope of facilitating future work in the field.\n</p>\n<p>We open-source the following: Music samples for this paper:\nhttps://bit.ly/anonymous-mousai; all music samples for all models:\nhttps://bit.ly/audio-diffusion; and codes:\nhttps://github.com/archinetai/audio-diffusion-pytorch\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_F/0/1/0/all/0/1\">Flavio Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-01-30T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}