{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2022-11-08T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"1Cademy @ Causal News Corpus 2022: Leveraging Self-Training in Causality Classification of Socio-Political Event Data. (arXiv:2211.02729v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02729","description":"<p>This paper details our participation in the Challenges and Applications of\nAutomated Extraction of Socio-political Events from Text (CASE) workshop @\nEMNLP 2022, where we take part in Subtask 1 of Shared Task 3. We approach the\ngiven task of event causality detection by proposing a self-training pipeline\nthat follows a teacher-student classifier method. More specifically, we\ninitially train a teacher model on the true, original task data, and use that\nteacher model to self-label data to be used in the training of a separate\nstudent model for the final task prediction. We test how restricting the number\nof positive or negative self-labeled examples in the self-training process\naffects classification performance. Our final results show that using\nself-training produces a comprehensive performance improvement across all\nmodels and self-labeled training sets tested within the task of event causality\nsequence classification. On top of that, we find that self-training performance\ndid not diminish even when restricting either positive/negative examples used\nin training. Our code is be publicly available at\nhttps://github.com/Gzhang-umich/1CademyTeamOfCASE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nik_A/0/1/0/all/0/1\">Adam Nik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xingran Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mingyu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Intriguing Properties of Compression on Multilingual Models. (arXiv:2211.02738v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02738","description":"<p>Multilingual models are often particularly dependent on scaling to generalize\nto a growing number of languages. Compression techniques are widely relied upon\nto reconcile the growth in model size with real world resource constraints, but\ncompression can have a disparate effect on model performance for low-resource\nlanguages. It is thus crucial to understand the trade-offs between scale,\nmultilingualism, and compression. In this work, we propose an experimental\nframework to characterize the impact of sparsifying multilingual pre-trained\nlanguage models during fine-tuning. Applying this framework to mBERT named\nentity recognition models across 40 languages, we find that compression confers\nseveral intriguing and previously unknown generalization properties. In\ncontrast to prior findings, we find that compression may improve model\nrobustness over dense models. We additionally observe that under certain\nsparsification regimes compression may aid, rather than disproportionately\nimpact the performance of low-resource languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ogueji_K/0/1/0/all/0/1\">Kelechi Ogueji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahia_O/0/1/0/all/0/1\">Orevaoghene Ahia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Onilude_G/0/1/0/all/0/1\">Gbemileke Onilude</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gehrmann_S/0/1/0/all/0/1\">Sebastian Gehrmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1\">Sara Hooker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1\">Julia Kreutzer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KGLM: Integrating Knowledge Graph Structure in Language Models for Link Prediction. (arXiv:2211.02744v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02744","description":"<p>The ability of knowledge graphs to represent complex relationships at scale\nhas led to their adoption for various needs including knowledge representation,\nquestion-answering, fraud detection, and recommendation systems. Knowledge\ngraphs are often incomplete in the information they represent, necessitating\nthe need for knowledge graph completion tasks, such as link and relation\nprediction. Pre-trained and fine-tuned language models have shown promise in\nthese tasks although these models ignore the intrinsic information encoded in\nthe knowledge graph, namely the entity and relation types. In this work, we\npropose the Knowledge Graph Language Model (KGLM) architecture, where we\nintroduce a new entity/relation embedding layer that learns to differentiate\ndistinctive entity and relation types, therefore allowing the model to learn\nthe structure of the knowledge graph. In this work, we show that further\npre-training the language models with this additional embedding layer using the\ntriples extracted from the knowledge graph, followed by the standard\nfine-tuning phase sets a new state-of-the-art performance for the link\nprediction task on the benchmark datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Youn_J/0/1/0/all/0/1\">Jason Youn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tagkopoulos_I/0/1/0/all/0/1\">Ilias Tagkopoulos</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LAMASSU: Streaming Language-Agnostic Multilingual Speech Recognition and Translation Using Neural Transducers. (arXiv:2211.02809v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02809","description":"<p>End-to-end formulation of automatic speech recognition (ASR) and speech\ntranslation (ST) makes it easy to use a single model for both multilingual ASR\nand many-to-many ST. In this paper, we propose streaming language-agnostic\nmultilingual speech recognition and translation using neural transducers\n(LAMASSU). To enable multilingual text generation in LAMASSU, we conduct a\nsystematic comparison between specified and unified prediction and joint\nnetworks. We leverage a language-agnostic multilingual encoder that\nsubstantially outperforms shared encoders. To enhance LAMASSU, we propose to\nfeed target LID to encoders. We also apply connectionist temporal\nclassification regularization to transducer training. Experimental results show\nthat LAMASSU not only drastically reduces the model size but also outperforms\nmonolingual ASR and bilingual ST models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_E/0/1/0/all/0/1\">Eric Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jian Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1\">Long Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gaur_Y/0/1/0/all/0/1\">Yashesh Gaur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shujie Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jinyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Multi-Label Classification of Scientific Documents. (arXiv:2211.02810v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02810","description":"<p>Automatic topic classification has been studied extensively to assist\nmanaging and indexing scientific documents in a digital collection. With the\nlarge number of topics being available in recent years, it has become necessary\nto arrange them in a hierarchy. Therefore, the automatic classification systems\nneed to be able to classify the documents hierarchically. In addition, each\npaper is often assigned to more than one relevant topic. For example, a paper\ncan be assigned to several topics in a hierarchy tree. In this paper, we\nintroduce a new dataset for hierarchical multi-label text classification\n(HMLTC) of scientific papers called SciHTC, which contains 186,160 papers and\n1,233 categories from the ACM CCS tree. We establish strong baselines for HMLTC\nand propose a multi-task learning approach for topic classification with\nkeyword labeling as an auxiliary task. Our best model achieves a Macro-F1 score\nof 34.57% which shows that this dataset provides significant research\nopportunities on hierarchical scientific topic classification. We make our\ndataset and code available on Github.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sadat_M/0/1/0/all/0/1\">Mobashir Sadat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluation of Automated Speech Recognition Systems for Conversational Speech: A Linguistic Perspective. (arXiv:2211.02812v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02812","description":"<p>Automatic speech recognition (ASR) meets more informal and free-form input\ndata as voice user interfaces and conversational agents such as the voice\nassistants such as Alexa, Google Home, etc., gain popularity. Conversational\nspeech is both the most difficult and environmentally relevant sort of data for\nspeech recognition. In this paper, we take a linguistic perspective, and take\nthe French language as a case study toward disambiguation of the French\nhomophones. Our contribution aims to provide more insight into human speech\ntranscription accuracy in conditions to reproduce those of state-of-the-art ASR\nsystems, although in a much focused situation. We investigate a case study\ninvolving the most common errors encountered in the automatic transcription of\nFrench language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pasandi_H/0/1/0/all/0/1\">Hannaneh B. Pasandi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasandi_H/0/1/0/all/0/1\">Haniyeh B. Pasandi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training. (arXiv:2211.02816v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02816","description":"<p>Fact verification has attracted a lot of research attention recently, e.g.,\nin journalism, marketing, and policymaking, as misinformation and\ndisinformation online can sway one's opinion and affect one's actions. While\nfact-checking is a hard task in general, in many cases, false statements can be\neasily debunked based on analytics over tables with reliable information.\nHence, table-based fact verification has recently emerged as an important and\ngrowing research area. Yet, progress has been limited due to the lack of\ndatasets that can be used to pre-train language models (LMs) to be aware of\ncommon table operations, such as aggregating a column or comparing tuples. To\nbridge this gap, in this paper we introduce PASTA, a novel state-of-the-art\nframework for table-based fact verification via pre-training with synthesized\nsentence-table cloze questions. In particular, we design six types of common\nsentence-table cloze tasks, including Filter, Aggregation, Superlative,\nComparative, Ordinal, and Unique, based on which we synthesize a large corpus\nconsisting of 1.2 million sentence-table pairs from WikiTables. PASTA uses a\nrecent pre-trained LM, DeBERTaV3, and further pretrains it on our corpus. Our\nexperimental results show that PASTA achieves new state-of-the-art performance\non two table-based fact verification benchmarks: TabFact and SEM-TAB-FACTS. In\nparticular, on the complex set of TabFact, which contains multiple operations,\nPASTA largely outperforms the previous state of the art by 4.7 points (85.6%\nvs. 80.9%), and the gap between PASTA and human performance on the small\nTabFact test set is narrowed to just 1.5 points (90.6% vs. 92.1%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1\">Zihui Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Ju Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_N/0/1/0/all/0/1\">Nan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xiaoman Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xiaoyong Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EventEA: Benchmarking Entity Alignment for Event-centric Knowledge Graphs. (arXiv:2211.02817v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02817","description":"<p>Entity alignment is to find identical entities in different knowledge graphs\n(KGs) that refer to the same real-world object. Embedding-based entity\nalignment techniques have been drawing a lot of attention recently because they\ncan help solve the issue of symbolic heterogeneity in different KGs. However,\nin this paper, we show that the progress made in the past was due to biased and\nunchallenging evaluation. We highlight two major flaws in existing datasets\nthat favor embedding-based entity alignment techniques, i.e., the isomorphic\ngraph structures in relation triples and the weak heterogeneity in attribute\ntriples. Towards a critical evaluation of embedding-based entity alignment\nmethods, we construct a new dataset with heterogeneous relations and attributes\nbased on event-centric KGs. We conduct extensive experiments to evaluate\nexisting popular methods, and find that they fail to achieve promising\nperformance. As a new approach to this difficult problem, we propose a\ntime-aware literal encoder for entity alignment. The dataset and source code\nare publicly available to foster future research. Our work calls for more\neffective and practical embedding-based solutions to entity alignment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_X/0/1/0/all/0/1\">Xiaobin Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zequn Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guangyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1\">Wei Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Recommendation and Conversation via Dual Imitation. (arXiv:2211.02848v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02848","description":"<p>Human conversations of recommendation naturally involve the shift of\ninterests which can align the recommendation actions and conversation process\nto make accurate recommendations with rich explanations. However, existing\nconversational recommendation systems (CRS) ignore the advantage of user\ninterest shift in connecting recommendation and conversation, which leads to an\nineffective loose coupling structure of CRS. To address this issue, by modeling\nthe recommendation actions as recommendation paths in a knowledge graph (KG),\nwe propose DICR (Dual Imitation for Conversational Recommendation), which\ndesigns a dual imitation to explicitly align the recommendation paths and user\ninterest shift paths in a recommendation module and a conversation module,\nrespectively. By exchanging alignment signals, DICR achieves bidirectional\npromotion between recommendation and conversation modules and generates\nhigh-quality responses with accurate recommendations and coherent explanations.\nExperiments demonstrate that DICR outperforms the state-of-the-art models on\nrecommendation and conversation performance with automatic, human, and novel\nexplainability metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jinfeng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1\">Dongming Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1\">Kun Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1\">Ruifang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1\">Yuexian Hou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BEKG: A Built Environment Knowledge Graph. (arXiv:2211.02864v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02864","description":"<p>Practices in the built environment have become more digitalized with the\nrapid development of modern design and construction technologies. However, the\nrequirement of practitioners or scholars to gather complicated professional\nknowledge in the built environment has not been satisfied yet. In this paper,\nmore than 80,000 paper abstracts in the built environment field were obtained\nto build a knowledge graph, a knowledge base storing entities and their\nconnective relations in a graph-structured data model. To ensure the retrieval\naccuracy of the entities and relations in the knowledge graph, two\nwell-annotated datasets have been created, containing 2,000 instances and 1,450\ninstances each in 29 relations for the named entity recognition task and\nrelation extraction task respectively. These two tasks were solved by two\nBERT-based models trained on the proposed dataset. Both models attained an\naccuracy above 85% on these two tasks. More than 200,000 high-quality relations\nand entities were obtained using these models to extract all abstract data.\nFinally, this knowledge graph is presented as a self-developed visualization\nsystem to reveal relations between various entities in the domain. Both the\nsource code and the annotated dataset can be found here:\nhttps://github.com/HKUST-KnowComp/BEKG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaojun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1\">Haoyu Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_P/0/1/0/all/0/1\">Penglin Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Keyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_X/0/1/0/all/0/1\">Xingjin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhengdong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_Y/0/1/0/all/0/1\">Yik Lun Lau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_L/0/1/0/all/0/1\">Liyaning Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Textual Manifold-based Defense Against Natural Language Adversarial Examples. (arXiv:2211.02878v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02878","description":"<p>Recent studies on adversarial images have shown that they tend to leave the\nunderlying low-dimensional data manifold, making them significantly more\nchallenging for current models to make correct predictions. This so-called\noff-manifold conjecture has inspired a novel line of defenses against\nadversarial attacks on images. In this study, we find a similar phenomenon\noccurs in the contextualized embedding space induced by pretrained language\nmodels, in which adversarial texts tend to have their embeddings diverge from\nthe manifold of natural ones. Based on this finding, we propose Textual\nManifold-based Defense (TMD), a defense mechanism that projects text embeddings\nonto an approximated embedding manifold before classification. It reduces the\ncomplexity of potential adversarial examples, which ultimately enhances the\nrobustness of the protected model. Through extensive experiments, our method\nconsistently and significantly outperforms previous defenses under various\nattack settings without trading off clean accuracy. To the best of our\nknowledge, this is the first NLP defense that leverages the manifold structure\nagainst adversarial attacks. Our code is available at\n\\url{https://github.com/dangne/tmd}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Dang Minh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HERB: Measuring Hierarchical Regional Bias in Pre-trained Language Models. (arXiv:2211.02882v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02882","description":"<p>Fairness has become a trending topic in natural language processing (NLP),\nwhich addresses biases targeting certain social groups such as genders and\nreligions. However, regional bias in language models (LMs), a long-standing\nglobal discrimination problem, still remains unexplored. This paper bridges the\ngap by analysing the regional bias learned by the pre-trained language models\nthat are broadly used in NLP tasks. In addition to verifying the existence of\nregional bias in LMs, we find that the biases on regional groups can be\nstrongly influenced by the geographical clustering of the groups. We\naccordingly propose a HiErarchical Regional Bias evaluation method (HERB)\nutilising the information from the sub-region clusters to quantify the bias in\npre-trained LMs. Experiments show that our hierarchical metric can effectively\nevaluate the regional bias with respect to comprehensive topics and measure the\npotential regional bias that can be propagated to downstream tasks. Our codes\nare available at https://github.com/Bernard-Yang/HERB.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yizhi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1\">Ge Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bohao Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1\">Chenghua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ragni_A/0/1/0/all/0/1\">Anton Ragni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tri-Attention: Explicit Context-Aware Attention Mechanism for Natural Language Processing. (arXiv:2211.02899v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02899","description":"<p>In natural language processing (NLP), the context of a word or sentence plays\nan essential role. Contextual information such as the semantic representation\nof a passage or historical dialogue forms an essential part of a conversation\nand a precise understanding of the present phrase or sentence. However, the\nstandard attention mechanisms typically generate weights using query and key\nbut ignore context, forming a Bi-Attention framework, despite their great\nsuccess in modeling sequence alignment. This Bi-Attention mechanism does not\nexplicitly model the interactions between the contexts, queries and keys of\ntarget sequences, missing important contextual information and resulting in\npoor attention performance. Accordingly, a novel and general triple-attention\n(Tri-Attention) framework expands the standard Bi-Attention mechanism and\nexplicitly interacts query, key, and context by incorporating context as the\nthird dimension in calculating relevance scores. Four variants of Tri-Attention\nare generated by expanding the two-dimensional vector-based additive,\ndot-product, scaled dot-product, and bilinear operations in Bi-Attention to the\ntensor operations for Tri-Attention. Extensive experiments on three NLP tasks\ndemonstrate that Tri-Attention outperforms about 30 state-of-the-art\nnon-attention, standard Bi-Attention, contextual Bi-Attention approaches and\npretrained neural language models1.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1\">Rui Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yifeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wenpeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Longbing Cao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Legal Argument Reasoning Task in Civil Procedure. (arXiv:2211.02950v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02950","description":"<p>We present a new NLP task and dataset from the domain of the U.S. civil\nprocedure. Each instance of the dataset consists of a general introduction to\nthe case, a particular question, and a possible solution argument, accompanied\nby a detailed analysis of why the argument applies in that case. Since the\ndataset is based on a book aimed at law students, we believe that it represents\na truly complex task for benchmarking modern legal language models. Our\nbaseline evaluation shows that fine-tuning a legal transformer provides some\nadvantage over random baseline models, but our analysis reveals that the actual\nability to infer legal arguments remains a challenging open research question.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bongard_L/0/1/0/all/0/1\">Leonard Bongard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_L/0/1/0/all/0/1\">Lena Held</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1\">Ivan Habernal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Privacy-Preserving Models for Legal Natural Language Processing. (arXiv:2211.02956v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02956","description":"<p>Pre-training large transformer models with in-domain data improves domain\nadaptation and helps gain performance on the domain-specific downstream tasks.\nHowever, sharing models pre-trained on potentially sensitive data is prone to\nadversarial privacy attacks. In this paper, we asked to which extent we can\nguarantee privacy of pre-training data and, at the same time, achieve better\ndownstream performance on legal tasks without the need of additional labeled\ndata. We extensively experiment with scalable self-supervised learning of\ntransformer models under the formal paradigm of differential privacy and show\nthat under specific training configurations we can improve downstream\nperformance without sacrifying privacy protection for the in-domain data. Our\nmain contribution is utilizing differential privacy for large-scale\npre-training of transformer language models in the legal NLP domain, which, to\nthe best of our knowledge, has not been addressed before.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Ying Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1\">Ivan Habernal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning to Infer from Unlabeled Data: A Semi-supervised Learning Approach for Robust Natural Language Inference. (arXiv:2211.02971v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02971","description":"<p>Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) aims\nat predicting the relation between a pair of sentences (premise and hypothesis)\nas entailment, contradiction or semantic independence. Although deep learning\nmodels have shown promising performance for NLI in recent years, they rely on\nlarge scale expensive human-annotated datasets. Semi-supervised learning (SSL)\nis a popular technique for reducing the reliance on human annotation by\nleveraging unlabeled data for training. However, despite its substantial\nsuccess on single sentence classification tasks where the challenge in making\nuse of unlabeled data is to assign \"good enough\" pseudo-labels, for NLI tasks,\nthe nature of unlabeled data is more complex: one of the sentences in the pair\n(usually the hypothesis) along with the class label are missing from the data\nand require human annotations, which makes SSL for NLI more challenging. In\nthis paper, we propose a novel way to incorporate unlabeled data in SSL for NLI\nwhere we use a conditional language model, BART to generate the hypotheses for\nthe unlabeled sentences (used as premises). Our experiments show that our SSL\nframework successfully exploits unlabeled data and substantially improves the\nperformance of four NLI datasets in low-resource settings. We release our code\nat: https://github.com/msadat3/SSL_for_NLI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sadat_M/0/1/0/all/0/1\">Mobashir Sadat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1\">Cornelia Caragea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparison of Automatic Labelling Approaches for Sentiment Analysis. (arXiv:2211.02976v1 [cs.CL])","link":"http://arxiv.org/abs/2211.02976","description":"<p>Labelling a large quantity of social media data for the task of supervised\nmachine learning is not only time-consuming but also difficult and expensive.\nOn the other hand, the accuracy of supervised machine learning models is\nstrongly related to the quality of the labelled data on which they train, and\nautomatic sentiment labelling techniques could reduce the time and cost of\nhuman labelling. We have compared three automatic sentiment labelling\ntechniques: TextBlob, Vader, and Afinn to assign sentiments to tweets without\nany human assistance. We compare three scenarios: one uses training and testing\ndatasets with existing ground truth labels; the second experiment uses\nautomatic labels as training and testing datasets; and the third experiment\nuses three automatic labelling techniques to label the training dataset and\nuses the ground truth labels for testing. The experiments were evaluated on two\nTwitter datasets: SemEval-2013 (DS-1) and SemEval-2016 (DS-2). Results show\nthat the Afinn labelling technique obtains the highest accuracy of 80.17%\n(DS-1) and 80.05% (DS-2) using a BiLSTM deep learning model. These findings\nimply that automatic text labelling could provide significant benefits, and\nsuggest a feasible alternative to the time and cost of human labelling efforts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1\">Sumana Biswas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Young_K/0/1/0/all/0/1\">Karen Young</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Griffith_J/0/1/0/all/0/1\">Josephine Griffith</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Metadata Extraction from Dense Video Captioning. (arXiv:2211.02982v1 [cs.CV])","link":"http://arxiv.org/abs/2211.02982","description":"<p>Annotation of multimedia data by humans is time-consuming and costly, while\nreliable automatic generation of semantic metadata is a major challenge. We\npropose a framework to extract semantic metadata from automatically generated\nvideo captions. As metadata, we consider entities, the entities' properties,\nrelations between entities, and the video category. We employ two\nstate-of-the-art dense video captioning models with masked transformer (MT) and\nparallel decoding (PVDC) to generate captions for videos of the ActivityNet\nCaptions dataset. Our experiments show that it is possible to extract entities,\ntheir properties, relations between entities, and the video category from the\ngenerated captions. We observe that the quality of the extracted information is\nmainly influenced by the quality of the event localization in the video as well\nas the performance of the event caption generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Scherer_J/0/1/0/all/0/1\">Johannes Scherer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scherp_A/0/1/0/all/0/1\">Ansgar Scherp</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhowmik_D/0/1/0/all/0/1\">Deepayan Bhowmik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Robust Lottery Tickets for Pre-trained Language Models. (arXiv:2211.03013v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03013","description":"<p>Recent works on Lottery Ticket Hypothesis have shown that pre-trained\nlanguage models (PLMs) contain smaller matching subnetworks(winning tickets)\nwhich are capable of reaching accuracy comparable to the original models.\nHowever, these tickets are proved to be notrobust to adversarial examples, and\neven worse than their PLM counterparts. To address this problem, we propose a\nnovel method based on learning binary weight masks to identify robust tickets\nhidden in the original PLMs. Since the loss is not differentiable for the\nbinary mask, we assign the hard concrete distribution to the masks and\nencourage their sparsity using a smoothing approximation of L0\nregularization.Furthermore, we design an adversarial loss objective to guide\nthe search for robust tickets and ensure that the tickets perform well bothin\naccuracy and robustness. Experimental results show the significant improvement\nof the proposed method over previous work on adversarial robustness evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bao_R/0/1/0/all/0/1\">Rong Bao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Di Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sirui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wei Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Speech and Textual Pre-trained Models with Unsupervised ASR. (arXiv:2211.03025v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03025","description":"<p>Spoken language understanding (SLU) is a task aiming to extract high-level\nsemantics from spoken utterances. Previous works have investigated the use of\nspeech self-supervised models and textual pre-trained models, which have shown\nreasonable improvements to various SLU tasks. However, because of the\nmismatched modalities between speech signals and text tokens, previous methods\nusually need complex designs of the frameworks. This work proposes a simple yet\nefficient unsupervised paradigm that connects speech and textual pre-trained\nmodels, resulting in an unsupervised speech-to-semantic pre-trained model for\nvarious tasks in SLU. To be specific, we propose to use unsupervised automatic\nspeech recognition (ASR) as a connector that bridges different modalities used\nin speech and textual pre-trained models. Our experiments show that\nunsupervised ASR itself can improve the representations from speech\nself-supervised models. More importantly, it is shown as an efficient connector\nbetween speech and textual pre-trained models, improving the performances of\nfive different SLU tasks. Notably, on spoken question answering, we reach the\nstate-of-the-art result over the challenging NMSQA benchmark.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiatong Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1\">Chan-Jan Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1\">Holam Chung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_D/0/1/0/all/0/1\">Dongji Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garcia_P/0/1/0/all/0/1\">Paola Garcia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1\">Shinji Watanabe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1\">Ann Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1\">Hung-yi Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt-based Text Entailment for Low-Resource Named Entity Recognition. (arXiv:2211.03039v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03039","description":"<p>Pre-trained Language Models (PLMs) have been applied in NLP tasks and achieve\npromising results. Nevertheless, the fine-tuning procedure needs labeled data\nof the target domain, making it difficult to learn in low-resource and\nnon-trivial labeled scenarios. To address these challenges, we propose\nPrompt-based Text Entailment (PTE) for low-resource named entity recognition,\nwhich better leverages knowledge in the PLMs. We first reformulate named entity\nrecognition as the text entailment task. The original sentence with entity\ntype-specific prompts is fed into PLMs to get entailment scores for each\ncandidate. The entity type with the top score is then selected as final label.\nThen, we inject tagging labels into prompts and treat words as basic units\ninstead of n-gram spans to reduce time complexity in generating candidates by\nn-grams enumeration. Experimental results demonstrate that the proposed method\nPTE achieves competitive performance on the CoNLL03 dataset, and better than\nfine-tuned counterparts on the MIT Movie and Few-NERD dataset in low-resource\nsettings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongfang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Calibration Meets Explanation: A Simple and Effective Approach for Model Confidence Estimates. (arXiv:2211.03041v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03041","description":"<p>Calibration strengthens the trustworthiness of black-box models by producing\nbetter accurate confidence estimates on given examples. However, little is\nknown about if model explanations can help confidence calibration. Intuitively,\nhumans look at important features attributions and decide whether the model is\ntrustworthy. Similarly, the explanations can tell us when the model may or may\nnot know. Inspired by this, we propose a method named CME that leverages model\nexplanations to make the model less confident with non-inductive attributions.\nThe idea is that when the model is not highly confident, it is difficult to\nidentify strong indications of any class, and the tokens accordingly do not\nhave high attribution scores for any class and vice versa. We conduct extensive\nexperiments on six datasets with two popular pre-trained language models in the\nin-domain and out-of-domain settings. The results show that CME improves\ncalibration performance in all settings. The expected calibration errors are\nfurther reduced when combined with temperature scaling. Our findings highlight\nthat model explanations can help calibrate posterior estimates.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongfang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1\">Baotian Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qingcai Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tuning Language Models as Training Data Generators for Augmentation-Enhanced Few-Shot Learning. (arXiv:2211.03044v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03044","description":"<p>Recent studies have revealed the intriguing few-shot learning ability of\npretrained language models (PLMs): They can quickly adapt to a new task when\nfine-tuned on a small amount of labeled data formulated as prompts, without\nrequiring abundant task-specific annotations. Despite their promising\nperformance, most existing few-shot approaches that only learn from the small\ntraining set still underperform fully supervised training by nontrivial\nmargins. In this work, we study few-shot learning with PLMs from a different\nperspective: We first tune an autoregressive PLM on the few-shot samples and\nthen use it as a generator to synthesize a large amount of novel training\nsamples which augment the original training set. To encourage the generator to\nproduce label-discriminative samples, we train it via weighted maximum\nlikelihood where the weight of each token is automatically adjusted based on a\ndiscriminative meta-learning objective. A classification PLM can then be\nfine-tuned on both the few-shot and the synthetic samples with regularization\nfor better generalization and stability. Our approach FewGen achieves an\noverall better result across seven classification tasks of the GLUE benchmark\nthan existing few-shot learning methods, improving no-augmentation methods by\n5+ average points, and outperforming augmentation methods by 3+ average points.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalski_M/0/1/0/all/0/1\">Martin Michalski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelzaher_T/0/1/0/all/0/1\">Tarek Abdelzaher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge is Power: Understanding Causality Makes Legal judgment Prediction Models More Generalizable and Robust. (arXiv:2211.03046v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03046","description":"<p>Legal judgment Prediction (LJP), aiming to predict a judgment based on fact\ndescriptions, serves as legal assistance to mitigate the great work burden of\nlimited legal practitioners. Most existing methods apply various large-scale\npre-trained language models (PLMs) finetuned in LJP tasks to obtain consistent\nimprovements. However, we discover the fact that the state-of-the-art (SOTA)\nmodel makes judgment predictions according to wrong (or non-casual)\ninformation, which not only weakens the model's generalization capability but\nalso results in severe social problems like discrimination. Here, we analyze\nthe causal mechanism misleading the LJP model to learn the spurious\ncorrelations, and then propose a framework to guide the model to learn the\nunderlying causality knowledge in the legal texts. Specifically, we first\nperform open information extraction (OIE) to refine the text having a high\nproportion of causal information, according to which we generate a new set of\ndata. Then, we design a model learning the weights of the refined data and the\nraw data for LJP model training. The extensive experimental results show that\nour model is more generalizable and robust than the baselines and achieves a\nnew SOTA performance on two commonly used legal-specific datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Haotian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1\">Lingwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1\">Fanchao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yang Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Suffix Retrieval-Augmented Language Modeling. (arXiv:2211.03053v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03053","description":"<p>Causal language modeling (LM) uses word history to predict the next word.\nBERT, on the other hand, makes use of bi-directional word information in a\nsentence to predict words at masked positions. While BERT is effective in\nsequence encoding, it is non-causal by nature and is not designed for sequence\ngeneration. In this paper, we propose a novel language model, SUffix\nREtrieval-Augmented LM (SUREALM), that simulates a bi-directional contextual\neffect in an autoregressive manner. SUREALM employs an embedding retriever to\nsearch for training sentences in a data store that share similar word history\nduring sequence generation. In particular, the suffix portions of the retrieved\nsentences mimick the \"future\" context. We evaluated our proposed model on the\nDSTC9 spoken dialogue corpus and showed promising word perplexity reduction on\nthe validation and test set compared to competitive baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zecheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_Y/0/1/0/all/0/1\">Yik-Cheung Tam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improved Target-specific Stance Detection on Social Media Platforms by Delving into Conversation Threads. (arXiv:2211.03061v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03061","description":"<p>Target-specific stance detection on social media, which aims at classifying a\ntextual data instance such as a post or a comment into a stance class of a\ntarget issue, has become an emerging opinion mining paradigm of importance. An\nexample application would be to overcome vaccine hesitancy in combating the\ncoronavirus pandemic. However, existing stance detection strategies rely merely\non the individual instances which cannot always capture the expressed stance of\na given target. In response, we address a new task called conversational stance\ndetection which is to infer the stance towards a given target (e.g., COVID-19\nvaccination) when given a data instance and its corresponding conversation\nthread. To tackle the task, we first propose a benchmarking conversational\nstance detection (CSD) dataset with annotations of stances and the structures\nof conversation threads among the instances based on six major social media\nplatforms in Hong Kong. To infer the desired stances from both data instances\nand conversation threads, we propose a model called Branch-BERT that\nincorporates contextual information in conversation threads. Extensive\nexperiments on our CSD dataset show that our proposed model outperforms all the\nbaseline models that do not make use of contextual information. Specifically,\nit improves the F1 score by 10.3% compared with the state-of-the-art method in\nthe SemEval-2016 Task 6 competition. This shows the potential of incorporating\nrich contextual information on detecting target-specific stances on social\nmedia platforms and implies a more practical way to construct future stance\ndetection tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yupeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1\">Haorui He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shaonan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_F/0/1/0/all/0/1\">Francis C.M. Lau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yunya Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAIL: Malware Analysis Intermediate Language. (arXiv:2211.03068v1 [cs.CR])","link":"http://arxiv.org/abs/2211.03068","description":"<p>This paper introduces and presents a new language named MAIL (Malware\nAnalysis Intermediate Language). MAIL is basically used for building malware\nanalysis and detection tools. MAIL provides an abstract representation of an\nassembly program and hence the ability of a tool to automate malware analysis\nand detection. By translating binaries compiled for different platforms to\nMAIL, a tool can achieve platform independence. Each MAIL statement is\nannotated with patterns that can be used by a tool to optimize malware analysis\nand detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1\">Shahid Alam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Noisy Channel for Automatic Text Simplification. (arXiv:2211.03152v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03152","description":"<p>In this paper we present a simple re-ranking method for Automatic Sentence\nSimplification based on the noisy channel scheme. Instead of directly computing\nthe best simplification given a complex text, the re-ranking method also\nconsiders the probability of the simple sentence to produce the complex\ncounterpart, as well as the probability of the simple text itself, according to\na language model. Our experiments show that combining these scores outperform\nthe original system in three different English datasets, yielding the best\nknown result in one of them. Adopting the noisy channel scheme opens new ways\nto infuse additional information into ATS systems, and thus to control\nimportant aspects of them, a known limitation of end-to-end neural seq2seq\ngenerative models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cumbicus_Pineda_O/0/1/0/all/0/1\">Oscar M Cumbicus-Pineda</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_Fandino_I/0/1/0/all/0/1\">Iker Guti&#xe9;rrez-Fandi&#xf1;o</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_Dios_I/0/1/0/all/0/1\">Itziar Gonzalez-Dios</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soroa_A/0/1/0/all/0/1\">Aitor Soroa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Domain Adaptation and Generalization of Pretrained Language Models: A Survey. (arXiv:2211.03154v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03154","description":"<p>Recent advances in NLP are brought by a range of large-scale pretrained\nlanguage models (PLMs). These PLMs have brought significant performance gains\nfor a range of NLP tasks, circumventing the need to customize complex designs\nfor specific tasks. However, most current work focus on finetuning PLMs on a\ndomain-specific datasets, ignoring the fact that the domain gap can lead to\noverfitting and even performance drop. Therefore, it is practically important\nto find an appropriate method to effectively adapt PLMs to a target domain of\ninterest. Recently, a range of methods have been proposed to achieve this\npurpose. Early surveys on domain adaptation are not suitable for PLMs due to\nthe sophisticated behavior exhibited by PLMs from traditional models trained\nfrom scratch and that domain adaptation of PLMs need to be redesigned to take\neffect. This paper aims to provide a survey on these newly proposed methods and\nshed light in how to apply traditional machine learning methods to newly\nevolved and future technologies. By examining the issues of deploying PLMs for\ndownstream tasks, we propose a taxonomy of domain adaptation approaches from a\nmachine learning system view, covering methods for input augmentation, model\noptimization and personalization. We discuss and compare those methods and\nsuggest promising future research directions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xu Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Han Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deliberation Networks and How to Train Them. (arXiv:2211.03217v1 [cs.CL])","link":"http://arxiv.org/abs/2211.03217","description":"<p>Deliberation networks are a family of sequence-to-sequence models, which have\nachieved state-of-the-art performance in a wide range of tasks such as machine\ntranslation and speech synthesis. A deliberation network consists of multiple\nstandard sequence-to-sequence models, each one conditioned on the initial input\nand the output of the previous model. During training, there are several key\nquestions: whether to apply Monte Carlo approximation to the gradients or the\nloss, whether to train the standard models jointly or separately, whether to\nrun an intermediate model in teacher forcing or free running mode, whether to\napply task-specific techniques. Previous work on deliberation networks\ntypically explores one or two training options for a specific task. This work\nintroduces a unifying framework, covering various training options, and\naddresses the above questions. In general, it is simpler to approximate the\ngradients. When parallel training is essential, separate training should be\nadopted. Regardless of the task, the intermediate model should be in free\nrunning mode. For tasks where the output is continuous, a guided attention loss\ncan be used to prevent degradation into a standard model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1\">Qingyun Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark Gales</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MyProfessors: Mining Turkish Student Reviews. (arXiv:2109.02325v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2109.02325","description":"<p>We introduce Hocalarim (MyProfessors), the largest student review dataset\navailable for the Turkish language. It consists of over 5000 professor reviews\nleft online by students, with different aspects of education rated on a scale\nof 1 to 5 stars. We investigate the properties of the dataset and present its\nstatistics. We examine the impact of students' institution type on their\nratings and the correlation of students' bias to give positive or negative\nfeedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ceylan_I/0/1/0/all/0/1\">Ibrahim Faruk Ceylan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Calik_N/0/1/0/all/0/1\">Necmettin Bera Calik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uluslu_A/0/1/0/all/0/1\">Ahmet Yavuz Uluslu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DISAPERE: A Dataset for Discourse Structure in Peer Review Discussions. (arXiv:2110.08520v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2110.08520","description":"<p>At the foundation of scientific evaluation is the labor-intensive process of\npeer review. This critical task requires participants to consume vast amounts\nof highly technical text. Prior work has annotated different aspects of review\nargumentation, but discourse relations between reviews and rebuttals have yet\nto be examined. We present DISAPERE, a labeled dataset of 20k sentences\ncontained in 506 review-rebuttal pairs in English, annotated by experts.\nDISAPERE synthesizes label sets from prior work and extends them to include\nfine-grained annotation of the rebuttal sentences, characterizing their context\nin the review and the authors' stance towards review arguments. Further, we\nannotate every review and rebuttal sentence. We show that discourse cues from\nrebuttals can shed light on the quality and interpretation of reviews. Further,\nan understanding of the argumentative strategies employed by the reviewers and\nauthors provides useful signal for area chairs and other decision makers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kennard_N/0/1/0/all/0/1\">Neha Kennard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+OGorman_T/0/1/0/all/0/1\">Tim O&#x27;Gorman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1\">Rajarshi Das</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Akshay Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bagchi_C/0/1/0/all/0/1\">Chhandak Bagchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clinton_M/0/1/0/all/0/1\">Matthew Clinton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yelugam_P/0/1/0/all/0/1\">Pranay Kumar Yelugam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zamani_H/0/1/0/all/0/1\">Hamed Zamani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic Segmentation of Legal Documents via Rhetorical Roles. (arXiv:2112.01836v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.01836","description":"<p>Legal documents are unstructured, use legal jargon, and have considerable\nlength, making them difficult to process automatically via conventional text\nprocessing techniques. A legal document processing system would benefit\nsubstantially if the documents could be segmented into coherent information\nunits. This paper proposes a new corpus of legal documents annotated (with the\nhelp of legal experts) with a set of 13 semantically coherent units labels\n(referred to as Rhetorical Roles), e.g., facts, arguments, statute, issue,\nprecedent, ruling, and ratio. We perform a thorough analysis of the corpus and\nthe annotations. For automatically segmenting the legal documents, we\nexperiment with the task of rhetorical role prediction: given a document,\npredict the text segments corresponding to various roles. Using the created\ncorpus, we experiment extensively with various deep learning-based baseline\nmodels for the task. Further, we develop a multitask learning (MTL) based deep\nmodel with document rhetorical role label shift as an auxiliary task for\nsegmenting a legal document. The proposed model shows superior performance over\nthe existing models. We also experiment with model performance in the case of\ndomain transfer and model distillation techniques to see the model performance\nin limited data conditions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malik_V/0/1/0/all/0/1\">Vijit Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjay_R/0/1/0/all/0/1\">Rishabh Sanjay</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guha_S/0/1/0/all/0/1\">Shouvik Kumar Guha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_A/0/1/0/all/0/1\">Angshuman Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nigam_S/0/1/0/all/0/1\">Shubham Nigam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharya_A/0/1/0/all/0/1\">Arnab Bhattacharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Shapes of Emotions: Multimodal Emotion Recognition in Conversations via Emotion Shifts. (arXiv:2112.01938v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.01938","description":"<p>Emotion Recognition in Conversations (ERC) is an important and active\nresearch area. Recent work has shown the benefits of using multiple modalities\n(e.g., text, audio, and video) for the ERC task. In a conversation,\nparticipants tend to maintain a particular emotional state unless some stimuli\nevokes a change. There is a continuous ebb and flow of emotions in a\nconversation. Inspired by this observation, we propose a multimodal ERC model\nand augment it with an emotion-shift component that improves performance. The\nproposed emotion-shift component is modular and can be added to any existing\nmultimodal ERC model (with a few modifications). We experiment with different\nvariants of the model, and results show that the inclusion of emotion shift\nsignal helps the model to outperform existing models for ERC on MOSEI and\nIEMOCAP datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_H/0/1/0/all/0/1\">Harsh Agarwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_K/0/1/0/all/0/1\">Keshav Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_A/0/1/0/all/0/1\">Abhinav Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1\">Ashutosh Modi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Simple Questions Generate Named Entity Recognition Datasets. (arXiv:2112.08808v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.08808","description":"<p>Recent named entity recognition (NER) models often rely on human-annotated\ndatasets, requiring the significant engagement of professional knowledge on the\ntarget domain and entities. This research introduces an ask-to-generate\napproach that automatically generates NER datasets by asking questions in\nsimple natural language to an open-domain question answering system (e.g.,\n\"Which disease?\"). Despite using fewer in-domain resources, our models, solely\ntrained on the generated datasets, largely outperform strong low-resource\nmodels by an average F1 score of 19.4 for six popular NER benchmarks.\nFurthermore, our models provide competitive performance with rich-resource\nmodels that additionally leverage in-domain dictionaries provided by domain\nexperts. In few-shot NER, we outperform the previous best model by an F1 score\nof 5.2 on three benchmarks and achieve new state-of-the-art performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Hyunjae Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_J/0/1/0/all/0/1\">Jaehyo Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Seunghyun Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jinhyuk Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1\">Jaewoo Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Matters: Radiology Report Generation with General and Specific Knowledge. (arXiv:2112.15009v2 [eess.IV] UPDATED)","link":"http://arxiv.org/abs/2112.15009","description":"<p>Automatic radiology report generation is critical in clinics which can\nrelieve experienced radiologists from the heavy workload and remind\ninexperienced radiologists of misdiagnosis or missed diagnose. Existing\napproaches mainly formulate radiology report generation as an image captioning\ntask and adopt the encoder-decoder framework. However, in the medical domain,\nsuch pure data-driven approaches suffer from the following problems: 1) visual\nand textual bias problem; 2) lack of expert knowledge. In this paper, we\npropose a knowledge-enhanced radiology report generation approach introduces\ntwo types of medical knowledge: 1) General knowledge, which is input\nindependent and provides the broad knowledge for report generation; 2) Specific\nknowledge, which is input dependent and provides the fine-grained knowledge for\nreport generation. To fully utilize both the general and specific knowledge, we\nalso propose a knowledge-enhanced multi-head attention mechanism. By merging\nthe visual features of the radiology image with general knowledge and specific\nknowledge, the proposed model can improve the quality of generated reports.\nExperimental results on two publicly available datasets IU-Xray and MIMIC-CXR\nshow that the proposed knowledge enhanced approach outperforms state-of-the-art\nimage captioning based methods. Ablation studies also demonstrate that both\ngeneral and specific knowledge can help to improve the performance of radiology\nreport generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1\">Shuxin Yang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ge_S/0/1/0/all/0/1\">Shen Ge</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhou_S/0/1/0/all/0/1\">Shaohua Kevin Zhou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Xiao_L/0/1/0/all/0/1\">Li Xiao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Survey of Hallucination in Natural Language Generation. (arXiv:2202.03629v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.03629","description":"<p>Natural Language Generation (NLG) has improved exponentially in recent years\nthanks to the development of sequence-to-sequence deep learning technologies\nsuch as Transformer-based language models. This advancement has led to more\nfluent and coherent NLG, leading to improved development in downstream tasks\nsuch as abstractive summarization, dialogue generation and data-to-text\ngeneration. However, it is also apparent that deep learning based generation is\nprone to hallucinate unintended text, which degrades the system performance and\nfails to meet user expectations in many real-world scenarios. To address this\nissue, many studies have been presented in measuring and mitigating\nhallucinated texts, but these have never been reviewed in a comprehensive\nmanner before. In this survey, we thus provide a broad overview of the research\nprogress and challenges in the hallucination problem in NLG. The survey is\norganized into two parts: (1) a general overview of metrics, mitigation\nmethods, and future directions; and (2) an overview of task-specific research\nprogress on hallucinations in the following downstream tasks, namely\nabstractive summarization, dialogue generation, generative question answering,\ndata-to-text generation, machine translation, and visual-language generation.\nThis survey serves to facilitate collaborative efforts among researchers in\ntackling the challenge of hallucinated texts in NLG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1\">Ziwei Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1\">Nayeon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Frieske_R/0/1/0/all/0/1\">Rita Frieske</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tiezheng Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1\">Dan Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1\">Etsuko Ishii</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bang_Y/0/1/0/all/0/1\">Yejin Bang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1\">Wenliang Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1\">Andrea Madotto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Aspect-Based Sentiment Analysis: Tasks, Methods, and Challenges. (arXiv:2203.01054v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.01054","description":"<p>As an important fine-grained sentiment analysis problem, aspect-based\nsentiment analysis (ABSA), aiming to analyze and understand people's opinions\nat the aspect level, has been attracting considerable interest in the last\ndecade. To handle ABSA in different scenarios, various tasks are introduced for\nanalyzing different sentiment elements and their relations, including the\naspect term, aspect category, opinion term, and sentiment polarity. Unlike\nearly ABSA works focusing on a single sentiment element, many compound ABSA\ntasks involving multiple elements have been studied in recent years for\ncapturing more complete aspect-level sentiment information. However, a\nsystematic review of various ABSA tasks and their corresponding solutions is\nstill lacking, which we aim to fill in this survey. More specifically, we\nprovide a new taxonomy for ABSA which organizes existing studies from the axes\nof concerned sentiment elements, with an emphasis on recent advances of\ncompound ABSA tasks. From the perspective of solutions, we summarize the\nutilization of pre-trained language models for ABSA, which improved the\nperformance of ABSA to a new stage. Besides, techniques for building more\npractical ABSA systems in cross-domain/lingual scenarios are discussed.\nFinally, we review some emerging topics and discuss some open challenges to\noutlook potential future directions of ABSA.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenxuan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1\">Yang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1\">Wai Lam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again. (arXiv:2203.08410v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.08410","description":"<p>The strong few-shot in-context learning capability of large pre-trained\nlanguage models (PLMs) such as GPT-3 is highly appealing for application\ndomains such as biomedicine, which feature high and diverse demands of language\ntechnologies but also high data annotation costs. In this paper, we present the\nfirst systematic and comprehensive study to compare the few-shot performance of\nGPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on\ntwo highly representative biomedical information extraction tasks, named entity\nrecognition and relation extraction. We follow the true few-shot setting to\navoid overestimating models' few-shot performance by model selection over a\nlarge validation set. We also optimize GPT-3's performance with known\ntechniques such as contextual calibration and dynamic in-context example\nretrieval. However, our results show that GPT-3 still significantly\nunderperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3\nin-context learning also yields smaller gains in accuracy when more training\ndata becomes available. Our in-depth analyses further reveal issues of the\nin-context learning setting that may be detrimental to information extraction\ntasks in general. Given the high cost of experimenting with GPT-3, we hope our\nstudy provides guidance for biomedical researchers and practitioners towards\nmore promising directions such as fine-tuning small PLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gutierrez_B/0/1/0/all/0/1\">Bernal Jim&#xe9;nez Guti&#xe9;rrez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McNeal_N/0/1/0/all/0/1\">Nikolas McNeal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Washington_C/0/1/0/all/0/1\">Clay Washington</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">You Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Nix-TTS: Lightweight and End-to-End Text-to-Speech via Module-wise Distillation. (arXiv:2203.15643v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2203.15643","description":"<p>Several solutions for lightweight TTS have shown promising results. Still,\nthey either rely on a hand-crafted design that reaches non-optimum size or use\na neural architecture search but often suffer training costs. We present\nNix-TTS, a lightweight TTS achieved via knowledge distillation to a\nhigh-quality yet large-sized, non-autoregressive, and end-to-end (vocoder-free)\nTTS teacher model. Specifically, we offer module-wise distillation, enabling\nflexible and independent distillation to the encoder and decoder module. The\nresulting Nix-TTS inherited the advantageous properties of being\nnon-autoregressive and end-to-end from the teacher, yet significantly smaller\nin size, with only 5.23M parameters or up to 89.34% reduction of the teacher\nmodel; it also achieves over 3.04x and 8.36x inference speedup on Intel-i7 CPU\nand Raspberry Pi 3B respectively and still retains a fair voice naturalness and\nintelligibility compared to the teacher model. We provide pretrained models and\naudio samples of Nix-TTS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chevi_R/0/1/0/all/0/1\">Rendi Chevi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prasojo_R/0/1/0/all/0/1\">Radityo Eko Prasojo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tjandra_A/0/1/0/all/0/1\">Andros Tjandra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sakti_S/0/1/0/all/0/1\">Sakriani Sakti</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"KOLD: Korean Offensive Language Dataset. (arXiv:2205.11315v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11315","description":"<p>Recent directions for offensive language detection are hierarchical modeling,\nidentifying the type and the target of offensive language, and interpretability\nwith offensive span annotation and prediction. These improvements are focused\non English and do not transfer well to other languages because of cultural and\nlinguistic differences. In this paper, we present the Korean Offensive Language\nDataset (KOLD) comprising 40,429 comments, which are annotated hierarchically\nwith the type and the target of offensive language, accompanied by annotations\nof the corresponding text spans. We collect the comments from NAVER news and\nYouTube platform and provide the titles of the articles and videos as the\ncontext information for the annotation process. We use these annotated comments\nas training data for Korean BERT and RoBERTa models and find that they are\neffective at offensiveness detection, target classification, and target span\ndetection while having room for improvement for target group classification and\noffensive span detection. We discover that the target group distribution\ndiffers drastically from the existing English datasets, and observe that\nproviding the context information improves the model performance in\noffensiveness detection (+0.3), target classification (+1.5), and target group\nclassification (+13.1). We publicly release the dataset and baseline models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1\">Younghoon Jeong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1\">Juhyun Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahn_J/0/1/0/all/0/1\">Jaimeen Ahn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jongwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1\">Jihyung Moon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sungjoon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_A/0/1/0/all/0/1\">Alice Oh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment. (arXiv:2205.11616v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11616","description":"<p>Word translation without parallel corpora has become feasible, rivaling the\nperformance of supervised methods. Recent findings have shown that the accuracy\nand robustness of unsupervised word translation (UWT) can be improved by making\nuse of visual observations, which are universal representations across\nlanguages. In this work, we investigate the potential of using not only visual\nobservations but also pretrained language-image models for enabling a more\nefficient and robust UWT. Specifically, we develop a novel UWT method dubbed\nWord Alignment using Language-Image Pretraining (WALIP), which leverages visual\nobservations via the shared embedding space of images and texts provided by\nCLIP models (Radford et al., 2021). WALIP has a two-step procedure. First, we\nretrieve word pairs with high confidences of similarity, computed using our\nproposed image-based fingerprints, which define the initial pivot for the word\nalignment. Second, we apply our robust Procrustes algorithm to estimate the\nlinear mapping between two embedding spaces, which iteratively corrects and\nrefines the estimated alignment. Our extensive experiments show that WALIP\nimproves upon the state-of-the-art performance of bilingual word alignment for\na few language pairs across different word embeddings and displays great\nrobustness to the dissimilarity of language pairs or training corpora for two\nword embeddings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1\">Tuan Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sohn_J/0/1/0/all/0/1\">Jy-yong Sohn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajput_S/0/1/0/all/0/1\">Shashank Rajput</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ossowski_T/0/1/0/all/0/1\">Timothy Ossowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1\">Yifei Ming</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Junjie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Papailiopoulos_D/0/1/0/all/0/1\">Dimitris Papailiopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kangwook Lee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer. (arXiv:2205.11631v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.11631","description":"<p>In Neural Machine Translation (NMT), each token prediction is conditioned on\nthe source sentence and the target prefix (what has been previously translated\nat a decoding step). However, previous work on interpretability in NMT has\nmainly focused solely on source sentence tokens' attributions. Therefore, we\nlack a full understanding of the influences of every input token (source\nsentence and target prefix) in the model predictions. In this work, we propose\nan interpretability method that tracks input tokens' attributions for both\ncontexts. Our method, which can be extended to any encoder-decoder\nTransformer-based model, allows us to better comprehend the inner workings of\ncurrent NMT models. We apply the proposed method to both bilingual and\nmultilingual Transformers and present insights into their behaviour.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ferrando_J/0/1/0/all/0/1\">Javier Ferrando</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1\">Gerard I. G&#xe1;llego</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alastruey_B/0/1/0/all/0/1\">Belen Alastruey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Escolano_C/0/1/0/all/0/1\">Carlos Escolano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1\">Marta R. Costa-juss&#xe0;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GraphQ IR: Unifying the Semantic Parsing of Graph Query Languages with One Intermediate Representation. (arXiv:2205.12078v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12078","description":"<p>Subject to the huge semantic gap between natural and formal languages, neural\nsemantic parsing is typically bottlenecked by its complexity of dealing with\nboth input semantics and output syntax. Recent works have proposed several\nforms of supplementary supervision but none is generalized across multiple\nformal languages. This paper proposes a unified intermediate representation\n(IR) for graph query languages, named GraphQ IR. It has a natural-language-like\nexpression that bridges the semantic gap and formally defined syntax that\nmaintains the graph structure. Therefore, a neural semantic parser can more\nprecisely convert user queries into GraphQ IR, which can be later losslessly\ncompiled into various downstream graph query languages. Extensive experiments\non several benchmarks including KQA Pro, Overnight, GrailQA, and MetaQA-Cypher\nunder standard i.i.d., out-of-distribution, and low-resource settings validate\nGraphQ IR's superiority over the previous state-of-the-arts with a maximum 11%\naccuracy improvement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1\">Lunyiu Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1\">Shulin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jiaxin Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jiuding Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1\">Qi Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_L/0/1/0/all/0/1\">Lei Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juanzi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_J/0/1/0/all/0/1\">Jidong Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Chunk-based Nearest Neighbor Machine Translation. (arXiv:2205.12230v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12230","description":"<p>Semi-parametric models, which augment generation with retrieval, have led to\nimpressive results in language modeling and machine translation, due to their\nability to retrieve fine-grained information from a datastore of examples. One\nof the most prominent approaches, $k$NN-MT, exhibits strong domain adaptation\ncapabilities by retrieving tokens from domain-specific datastores\n\\citep{khandelwal2020nearest}. However, $k$NN-MT requires an expensive\nretrieval operation for every single generated token, leading to a very low\ndecoding speed (around 8 times slower than a parametric model). In this paper,\nwe introduce a \\textit{chunk-based} $k$NN-MT model which retrieves chunks of\ntokens from the datastore, instead of a single token. We propose several\nstrategies for incorporating the retrieved chunks into the generation process,\nand for selecting the steps at which the model needs to search for neighbors in\nthe datastore. Experiments on machine translation in two settings, static and\n``on-the-fly'' domain adaptation, show that the chunk-based $k$NN-MT model\nleads to significant speed-ups (up to 4 times) with only a small drop in\ntranslation quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Martins_P/0/1/0/all/0/1\">Pedro Henrique Martins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marinho_Z/0/1/0/all/0/1\">Zita Marinho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F. T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Human Heuristics for AI-Generated Language Are Flawed. (arXiv:2206.07271v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.07271","description":"<p>Human communication is increasingly intermixed with language generated by AI.\nAcross chat, email, and social media, AI systems produce smart replies,\nautocompletes, and translations. AI-generated language is often not identified\nas such but presented as language written by humans, raising concerns about\nnovel forms of deception and manipulation. Here, we study how humans discern\nwhether verbal self-presentations, one of the most personal and consequential\nforms of language, were generated by AI. In six experiments, participants (N =\n4,600) were unable to detect self-presentations generated by state-of-the-art\nAI language models in professional, hospitality, and dating contexts. A\ncomputational analysis of language features shows that human judgments of\nAI-generated language are handicapped by intuitive but flawed heuristics such\nas associating first-person pronouns, spontaneous wording, or family topics\nwith human-written language. We experimentally demonstrate that these\nheuristics make human judgment of AI-generated language predictable and\nmanipulable, allowing AI systems to produce language perceived as more human\nthan human. We discuss solutions, such as AI accents, to reduce the deceptive\npotential of language generated by AI, limiting the subversion of human\nintuition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jakesch_M/0/1/0/all/0/1\">Maurice Jakesch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hancock_J/0/1/0/all/0/1\">Jeffrey Hancock</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naaman_M/0/1/0/all/0/1\">Mor Naaman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GTrans: Grouping and Fusing Transformer Layers for Neural Machine Translation. (arXiv:2207.14467v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.14467","description":"<p>Transformer structure, stacked by a sequence of encoder and decoder network\nlayers, achieves significant development in neural machine translation.\nHowever, vanilla Transformer mainly exploits the top-layer representation,\nassuming the lower layers provide trivial or redundant information and thus\nignoring the bottom-layer feature that is potentially valuable. In this work,\nwe propose the Group-Transformer model (GTrans) that flexibly divides\nmulti-layer representations of both encoder and decoder into different groups\nand then fuses these group features to generate target words. To corroborate\nthe effectiveness of the proposed method, extensive experiments and analytic\nexperiments are conducted on three bilingual translation benchmarks and two\nmultilingual translation tasks, including the IWLST-14, IWLST-17, LDC, WMT-14\nand OPUS-100 benchmark. Experimental and analytical results demonstrate that\nour model outperforms its Transformer counterparts by a consistent gain.\nFurthermore, it can be successfully scaled up to 60 encoder layers and 36\ndecoder layers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jian Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1\">Yuwei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Liqun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shuming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deriving dynamical systems for language based on the Tolerance Principle. (arXiv:2209.04261v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.04261","description":"<p>In this research note, I derive explicit dynamical systems for language\nwithin an acquisition-driven framework (Niyogi \\&amp; Berwick, 1997; Niyogi, 2006)\nassuming that children/learners follow the Tolerance Principle (Yang, 2016) to\ndetermine whether a rule is productive during the process of language\nacquisition. I consider different theoretical parameters such as population\nsize (finite vs. infinite) and the number of previous generations that provide\nlearners with data. Multiple simulations of the dynamics obtained here and\napplications to diacrhonic language data are in preparation, so they are not\nincluded in this first note.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alves_F/0/1/0/all/0/1\">Fernando C. Alves</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The (In)Effectiveness of Intermediate Task Training For Domain Adaptation and Cross-Lingual Transfer Learning. (arXiv:2210.01091v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.01091","description":"<p>Transfer learning from large language models (LLMs) has emerged as a powerful\ntechnique to enable knowledge-based fine-tuning for a number of tasks,\nadaptation of models for different domains and even languages. However, it\nremains an open question, if and when transfer learning will work, i.e. leading\nto positive or negative transfer. In this paper, we analyze the knowledge\ntransfer across three natural language processing (NLP) tasks - text\nclassification, sentimental analysis, and sentence similarity, using three LLMs\n- BERT, RoBERTa, and XLNet - and analyzing their performance, by fine-tuning on\ntarget datasets for domain and cross-lingual adaptation tasks, with and without\nan intermediate task training on a larger dataset. Our experiments showed that\nfine-tuning without an intermediate task training can lead to a better\nperformance for most tasks, while more generalized tasks might necessitate a\npreceding intermediate task training step. We hope that this work will act as a\nguide on transfer learning to NLP practitioners.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohapatra_S/0/1/0/all/0/1\">Sovesh Mohapatra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohapatra_S/0/1/0/all/0/1\">Somesh Mohapatra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Look Ma, Only 400 Samples! Revisiting the Effectiveness of Automatic N-Gram Rule Generation for Spelling Normalization in Filipino. (arXiv:2210.02675v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.02675","description":"<p>With 84.75 million Filipinos online, the ability for models to process online\ntext is crucial for developing Filipino NLP applications. To this end, spelling\ncorrection is a crucial preprocessing step for downstream processing. However,\nthe lack of data prevents the use of language models for this task. In this\npaper, we propose an N-Gram + Damerau Levenshtein distance model with automatic\nrule extraction. We train the model on 300 samples, and show that despite\nlimited training data, it achieves good performance and outperforms other deep\nlearning approaches in terms of accuracy and edit distance. Moreover, the model\n(1) requires little compute power, (2) trains in little time, thus allowing for\nretraining, and (3) is easily interpretable, allowing for direct\ntroubleshooting, highlighting the success of traditional approaches over more\ncomplex deep learning models in settings where data is unavailable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Flores_L/0/1/0/all/0/1\">Lorenzo Jaime Yu Flores</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1\">Dragomir Radev</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crisis Response. (arXiv:2210.04573v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.04573","description":"<p>Timely and effective response to humanitarian crises requires quick and\naccurate analysis of large amounts of text data - a process that can highly\nbenefit from expert-assisted NLP systems trained on validated and annotated\ndata in the humanitarian response domain. To enable creation of such NLP\nsystems, we introduce and release HumSet, a novel and rich multilingual dataset\nof humanitarian response documents annotated by experts in the humanitarian\nresponse community. The dataset provides documents in three languages (English,\nFrench, Spanish) and covers a variety of humanitarian crises from 2018 to 2021\nacross the globe. For each document, HUMSET provides selected snippets\n(entries) as well as assigned classes to each entry annotated using common\nhumanitarian information analysis frameworks. HUMSET also provides novel and\nchallenging entry extraction and multi-label entry classification tasks. In\nthis paper, we take a first step towards approaching these tasks and conduct a\nset of experiments on Pre-trained Language Models (PLM) to establish strong\nbaselines for future research in this domain. The dataset is available at\nhttps://blog.thedeep.io/humset/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fekih_S/0/1/0/all/0/1\">Selim Fekih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tamagnone_N/0/1/0/all/0/1\">Nicol&#xf2; Tamagnone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Minixhofer_B/0/1/0/all/0/1\">Benjamin Minixhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrestha_R/0/1/0/all/0/1\">Ranjan Shrestha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Contla_X/0/1/0/all/0/1\">Ximena Contla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oglethorpe_E/0/1/0/all/0/1\">Ewan Oglethorpe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rekabsaz_N/0/1/0/all/0/1\">Navid Rekabsaz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speaker- and Age-Invariant Training for Child Acoustic Modeling Using Adversarial Multi-Task Learning. (arXiv:2210.10231v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2210.10231","description":"<p>One of the major challenges in acoustic modelling of child speech is the\nrapid changes that occur in the children's articulators as they grow up, their\ndiffering growth rates and the subsequent high variability in the same age\ngroup. These high acoustic variations along with the scarcity of child speech\ncorpora have impeded the development of a reliable speech recognition system\nfor children. In this paper, a speaker- and age-invariant training approach\nbased on adversarial multi-task learning is proposed. The system consists of\none generator shared network that learns to generate speaker- and age-invariant\nfeatures connected to three discrimination networks, for phoneme, age, and\nspeaker. The generator network is trained to minimize the\nphoneme-discrimination loss and maximize the speaker- and age-discrimination\nlosses in an adversarial multi-task learning fashion. The generator network is\na Time Delay Neural Network (TDNN) architecture while the three discriminators\nare feed-forward networks. The system was applied to the OGI speech corpora and\nachieved a 13% reduction in the WER of the ASR.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shahin_M/0/1/0/all/0/1\">Mostafa Shahin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_B/0/1/0/all/0/1\">Beena Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Epps_J/0/1/0/all/0/1\">Julien Epps</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Group is better than individual: Exploiting Label Topologies and Label Relations for Joint Multiple Intent Detection and Slot Filling. (arXiv:2210.10369v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10369","description":"<p>Recent joint multiple intent detection and slot filling models employ label\nembeddings to achieve the semantics-label interactions. However, they treat all\nlabels and label embeddings as uncorrelated individuals, ignoring the\ndependencies among them. Besides, they conduct the decoding for the two tasks\nindependently, without leveraging the correlations between them. Therefore, in\nthis paper, we first construct a Heterogeneous Label Graph (HLG) containing two\nkinds of topologies: (1) statistical dependencies based on labels'\nco-occurrence patterns and hierarchies in slot labels; (2) rich relations among\nthe label nodes. Then we propose a novel model termed ReLa-Net. It can capture\nbeneficial correlations among the labels from HLG. The label correlations are\nleveraged to enhance semantic-label interactions. Moreover, we also propose the\nlabel-aware inter-dependent decoding mechanism to further exploit the label\ncorrelations for decoding. Experiment results show that our ReLa-Net\nsignificantly outperforms previous models. Remarkably, ReLa-Net surpasses the\nprevious best model by over 20\\% in terms of overall accuracy on MixATIS\ndataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1\">Bowen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor W. Tsang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Co-guiding Net: Achieving Mutual Guidances between Multiple Intent Detection and Slot Filling via Heterogeneous Semantics-Label Graphs. (arXiv:2210.10375v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10375","description":"<p>Recent graph-based models for joint multiple intent detection and slot\nfilling have obtained promising results through modeling the guidance from the\nprediction of intents to the decoding of slot filling. However, existing\nmethods (1) only model the \\textit{unidirectional guidance} from intent to\nslot; (2) adopt \\textit{homogeneous graphs} to model the interactions between\nthe slot semantics nodes and intent label nodes, which limit the performance.\nIn this paper, we propose a novel model termed Co-guiding Net, which implements\na two-stage framework achieving the \\textit{mutual guidances} between the two\ntasks. In the first stage, the initial estimated labels of both tasks are\nproduced, and then they are leveraged in the second stage to model the mutual\nguidances. Specifically, we propose two \\textit{heterogeneous graph attention\nnetworks} working on the proposed two \\textit{heterogeneous semantics-label\ngraphs}, which effectively represent the relations among the semantics nodes\nand label nodes. Experiment results show that our model outperforms existing\nmodels by a large margin, obtaining a relative improvement of 19.3\\% over the\nprevious best model on MixATIS dataset in overall accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1\">Bowen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor W. Tsang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving abstractive summarization with energy-based re-ranking. (arXiv:2210.15553v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.15553","description":"<p>Current abstractive summarization systems present important weaknesses which\nprevent their deployment in real-world applications, such as the omission of\nrelevant information and the generation of factual inconsistencies (also known\nas hallucinations). At the same time, automatic evaluation metrics such as CTC\nscores have been recently proposed that exhibit a higher correlation with human\njudgments than traditional lexical-overlap metrics such as ROUGE. In this work,\nwe intend to close the loop by leveraging the recent advances in summarization\nmetrics to create quality-aware abstractive summarizers. Namely, we propose an\nenergy-based model that learns to re-rank summaries according to one or a\ncombination of these metrics. We experiment using several metrics to train our\nenergy-based re-ranker and show that it consistently improves the scores\nachieved by the predicted summaries. Nonetheless, human evaluation results show\nthat the re-ranking approach should be used with care for highly abstractive\nsummaries, as the available metrics are not yet sufficiently reliable for this\npurpose.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pernes_D/0/1/0/all/0/1\">Diogo Pernes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mendes_A/0/1/0/all/0/1\">Afonso Mendes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1\">Andr&#xe9; F.T. Martins</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SDCL: Self-Distillation Contrastive Learning for Chinese Spell Checking. (arXiv:2210.17168v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.17168","description":"<p>Due to the ambiguity of homophones, Chinese Spell Checking (CSC) has\nwidespread applications. Existing systems typically utilize BERT for text\nencoding. However, CSC requires the model to account for both phonetic and\ngraphemic information. To adapt BERT to the CSC task, we propose a token-level\nself-distillation contrastive learning method. We employ BERT to encode both\nthe corrupted and corresponding correct sentence. Then, we use contrastive\nlearning loss to regularize corrupted tokens' hidden states to be closer to\ncounterparts in the correct sentence. On three CSC datasets, we confirmed our\nmethod provides a significant improvement above baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiaotian Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1\">Yu Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Video Event Extraction via Tracking Visual States of Arguments. (arXiv:2211.01781v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.01781","description":"<p>Video event extraction aims to detect salient events from a video and\nidentify the arguments for each event as well as their semantic roles. Existing\nmethods focus on capturing the overall visual scene of each frame, ignoring\nfine-grained argument-level information. Inspired by the definition of events\nas changes of states, we propose a novel framework to detect video events by\ntracking the changes in the visual states of all involved arguments, which are\nexpected to provide the most informative evidence for the extraction of video\nevents. In order to capture the visual state changes of arguments, we decompose\nthem into changes in pixels within objects, displacements of objects, and\ninteractions among multiple arguments. We further propose Object State\nEmbedding, Object Motion-aware Embedding and Argument Interaction Embedding to\nencode and track these changes respectively. Experiments on various video event\nextraction tasks demonstrate significant improvements compared to\nstate-of-the-art models. In particular, on verb classification, we achieve\n3.49% absolute gains (19.53% relative gains) in F1@5 on Video Situation\nRecognition.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1\">Guang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Manling Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiajie Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xudong Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-Fu Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Path to Autonomous Learners. (arXiv:2211.02403v1 [stat.ML] CROSS LISTED)","link":"http://arxiv.org/abs/2211.02403","description":"<p>In this paper, we present a new theoretical approach for enabling domain\nknowledge acquisition by intelligent systems. We introduce a hybrid model that\nstarts with minimal input knowledge in the form of an upper ontology of\nconcepts, stores and reasons over this knowledge through a knowledge graph\ndatabase and learns new information through a Logic Neural Network. We study\nthe behavior of this architecture when handling new data and show that the\nfinal system is capable of enriching its current knowledge as well as extending\nit to new domains.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Akl_H/0/1/0/all/0/1\">Hanna Abi Akl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2022-11-07T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}