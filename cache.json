{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-10-24T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Text as Environment: A Deep Reinforcement Learning Text Readability Assessment Model. (arXiv:1912.05957v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1912.05957","description":"<p>Evaluating the readability of a text can significantly facilitate the precise\nexpression of information in written form. The formulation of text readability\nassessment involves the identification of meaningful properties of the text\nregardless of its length. Sophisticated features and models are used to\nevaluate the comprehensibility of texts accurately. Despite this, the problem\nof assessing texts' readability efficiently remains relatively untouched. The\nefficiency of state-of-the-art text readability assessment models can be\nfurther improved using deep reinforcement learning models. Using a hard\nattention-based active inference technique, the proposed approach makes\nefficient use of input text and computational resources. Through the use of\nsemi-supervised signals, the reinforcement learning model uses the minimum\namount of text in order to determine text's readability. A comparison of the\nmodel on Weebit and Cambridge Exams with state-of-the-art models, such as the\nBERT text readability model, shows that it is capable of achieving\nstate-of-the-art accuracy with a significantly smaller amount of input text\nthan other models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mohammadi_H/0/1/0/all/0/1\">Hamid Mohammadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khasteh_S/0/1/0/all/0/1\">Seyed Hossein Khasteh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firoozi_T/0/1/0/all/0/1\">Tahereh Firoozi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Samavati_T/0/1/0/all/0/1\">Taha Samavati</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Empirical Study of Compound PCFGs. (arXiv:2103.02298v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2103.02298","description":"<p>Compound probabilistic context-free grammars (C-PCFGs) have recently\nestablished a new state of the art for unsupervised phrase-structure grammar\ninduction. However, due to the high space and time complexities of chart-based\nrepresentation and inference, it is difficult to investigate C-PCFGs\ncomprehensively. In this work, we rely on a fast implementation of C-PCFGs to\nconduct an evaluation complementary to that of~\\citet{kim-etal-2019-compound}.\nWe start by analyzing and ablating C-PCFGs on English treebanks. Our findings\nsuggest that (1) C-PCFGs are data-efficient and can generalize to unseen\nsentence/constituent lengths; and (2) C-PCFGs make the best use of\nsentence-level information in generating preterminal rule probabilities. We\nfurther conduct a multilingual evaluation of C-PCFGs. The experimental results\nshow that the best configurations of C-PCFGs, which are tuned on English, do\nnot always generalize to morphology-rich languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yanpeng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Titov_I/0/1/0/all/0/1\">Ivan Titov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Show, Write, and Retrieve: Entity-aware Article Generation and Retrieval. (arXiv:2112.05917v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.05917","description":"<p>Article comprehension is an important challenge in natural language\nprocessing with many applications such as article generation or\nimage-to-article retrieval. Prior work typically encodes all tokens in articles\nuniformly using pretrained language models. However, in many applications, such\nas understanding news stories, these articles are based on real-world events\nand may reference many named entities that are difficult to accurately\nrecognize and predict by language models. To address this challenge, we propose\nan ENtity-aware article GeneratIoN and rEtrieval (ENGINE) framework, to\nexplicitly incorporate named entities into language models. ENGINE has two main\ncomponents: a named-entity extraction module to extract named entities from\nboth metadata and embedded images associated with articles, and an entity-aware\nmechanism that enhances the model's ability to recognize and predict entity\nnames. We conducted experiments on three public datasets: GoodNews, VisualNews,\nand WikiText, where our results demonstrate that our model can boost both\narticle generation and article retrieval performance, with a 4-5 perplexity\nimprovement in article generation and a 3-4% boost in recall@1 in article\nretrieval. We release our implementation at\nhttps://github.com/Zhongping-Zhang/ENGINE .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhongping Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yiwen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plummer_B/0/1/0/all/0/1\">Bryan A. Plummer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EVA2.0: Investigating Open-Domain Chinese Dialogue Systems with Large-Scale Pre-Training. (arXiv:2203.09313v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.09313","description":"<p>Large-scale pre-training has shown remarkable performance in building\nopen-domain dialogue systems. However, previous works mainly focus on showing\nand evaluating the conversational performance of the released dialogue model,\nignoring the discussion of some key factors towards a powerful human-like\nchatbot, especially in Chinese scenarios. In this paper, we conduct extensive\nexperiments to investigate these under-explored factors, including data quality\ncontrol, model architecture designs, training approaches, and decoding\nstrategies. We propose EVA2.0, a large-scale pre-trained open-domain Chinese\ndialogue model with 2.8 billion parameters, and will make our models and codes\npublicly available. Automatic and human evaluations show that EVA2.0\nsignificantly outperforms other open-source counterparts. We also discuss the\nlimitations of this work by presenting some failure cases and pose some future\nresearch directions on large-scale Chinese open-domain dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yuxian Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jiaxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yi Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ke_P/0/1/0/all/0/1\">Pei Ke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1\">Chujie Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1\">Jianzhu Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1\">Xiaoyan Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL. (arXiv:2205.12422v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2205.12422","description":"<p>Can non-programmers annotate natural language utterances with complex\nprograms that represent their meaning? We introduce APEL, a framework in which\nnon-programmers select among candidate programs generated by a seed semantic\nparser (e.g., Codex). Since they cannot understand the candidate programs, we\nask them to select indirectly by examining the programs' input-ouput examples.\nFor each utterance, APEL actively searches for a simple input on which the\ncandidate programs tend to produce different outputs. It then asks the\nnon-programmers only to choose the appropriate output, thus allowing us to\ninfer which program is correct and could be used to fine-tune the parser. As a\nfirst case study, we recruited human non-programmers to use APEL to re-annotate\nSPIDER, a text-to-SQL dataset. Our approach achieved the same annotation\naccuracy as the original expert annotators (75%) and exposed many subtle errors\nin the original annotations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhong_R/0/1/0/all/0/1\">Ruiqi Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snell_C/0/1/0/all/0/1\">Charlie Snell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisner_J/0/1/0/all/0/1\">Jason Eisner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PreBit -- A multimodal model with Twitter FinBERT embeddings for extreme price movement prediction of Bitcoin. (arXiv:2206.00648v2 [q-fin.ST] UPDATED)","link":"http://arxiv.org/abs/2206.00648","description":"<p>Bitcoin, with its ever-growing popularity, has demonstrated extreme price\nvolatility since its origin. This volatility, together with its decentralised\nnature, make Bitcoin highly subjective to speculative trading as compared to\nmore traditional assets. In this paper, we propose a multimodal model for\npredicting extreme price fluctuations. This model takes as input a variety of\ncorrelated assets, technical indicators, as well as Twitter content. In an\nin-depth study, we explore whether social media discussions from the general\npublic on Bitcoin have predictive power for extreme price movements. A dataset\nof 5,000 tweets per day containing the keyword `Bitcoin' was collected from\n2015 to 2021. This dataset, called PreBit, is made available online. In our\nhybrid model, we use sentence-level FinBERT embeddings, pretrained on financial\nlexicons, so as to capture the full contents of the tweets and feed it to the\nmodel in an understandable way. By combining these embeddings with a\nConvolutional Neural Network, we built a predictive model for significant\nmarket movements. The final multimodal ensemble model includes this NLP model\ntogether with a model based on candlestick data, technical indicators and\ncorrelated asset prices. In an ablation study, we explore the contribution of\nthe individual modalities. Finally, we propose and backtest a trading strategy\nbased on the predictions of our models with varying prediction threshold and\nshow that it can used to build a profitable trading strategy with a reduced\nrisk over a `hold' or moving average strategy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/q-fin/1/au:+Zou_Y/0/1/0/all/0/1\">Yanzhao Zou</a>, <a href=\"http://arxiv.org/find/q-fin/1/au:+Herremans_D/0/1/0/all/0/1\">Dorien Herremans</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta-Referential Games to Learn Compositional Learning Behaviours. (arXiv:2207.08012v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2207.08012","description":"<p>Human beings use compositionality to generalise from past experiences to\nnovel experiences. We assume a separation of our experiences into fundamental\natomic components that can be recombined in novel ways to support our ability\nto engage with novel experiences. We frame this as the ability to learn to\ngeneralise compositionally, and we will refer to behaviours making use of this\nability as compositional learning behaviours (CLBs). A central problem to\nlearning CLBs is the resolution of a binding problem (BP). While it is another\nfeat of intelligence that human beings perform with ease, it is not the case\nfor state-of-the-art artificial agents. Thus, in order to build artificial\nagents able to collaborate with human beings, we propose to develop a novel\nbenchmark to investigate agents' abilities to exhibit CLBs by solving a\ndomain-agnostic version of the BP. We take inspiration from the language\nemergence and grounding framework of referential games and propose a\nmeta-learning extension of referential games, entitled Meta-Referential Games,\nand use this framework to build our benchmark, the Symbolic Behaviour Benchmark\n(S2B). We provide baseline results and error analysis showing that our\nbenchmark is a compelling challenge that we hope will spur the research\ncommunity towards developing more capable artificial agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Denamganai_K/0/1/0/all/0/1\">Kevin Denamgana&#xef;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Missaoui_S/0/1/0/all/0/1\">Sondess Missaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1\">James Alfred Walker</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Computational Interface to Translate Strategic Intent from Unstructured Language in a Low-Data Setting. (arXiv:2208.08374v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2208.08374","description":"<p>Many real-world tasks involve a mixed-initiative setup, wherein humans and AI\nsystems collaboratively perform a task. While significant work has been\nconducted towards enabling humans to specify, through language, exactly how an\nagent should complete a task (i.e., low-level specification), prior work lacks\non interpreting the high-level strategic intent of the human commanders.\nParsing strategic intent from language will allow autonomous systems to\nindependently operate according to the user's plan without frequent guidance or\ninstruction. In this paper, we build a computational interface capable of\ntranslating unstructured language strategies into actionable intent in the form\nof goals and constraints. Leveraging a game environment, we collect a dataset\nof over 1000 examples, mapping language strategies to the corresponding goals\nand constraints, and show that our model, trained on this dataset,\nsignificantly outperforms human interpreters in inferring strategic intent\n(i.e., goals and constraints) from language (p &lt; 0.05). Furthermore, we show\nthat our model (125M parameters) significantly outperforms ChatGPT for this\ntask (p &lt; 0.05) in a low-data setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tambwekar_P/0/1/0/all/0/1\">Pradyumna Tambwekar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dodeja_L/0/1/0/all/0/1\">Lakshita Dodeja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaska_N/0/1/0/all/0/1\">Nathan Vaska</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gombolay_M/0/1/0/all/0/1\">Matthew Gombolay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Once is Enough: A Light-Weight Cross-Attention for Fast Sentence Pair Modeling. (arXiv:2210.05261v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.05261","description":"<p>Transformer-based models have achieved great success on sentence pair\nmodeling tasks, such as answer selection and natural language inference (NLI).\nThese models generally perform cross-attention over input pairs, leading to\nprohibitive computational costs. Recent studies propose dual-encoder and late\ninteraction architectures for faster computation. However, the balance between\nthe expressive of cross-attention and computation speedup still needs better\ncoordinated. To this end, this paper introduces a novel paradigm MixEncoder for\nefficient sentence pair modeling. MixEncoder involves a light-weight\ncross-attention mechanism. It conducts query encoding only once while modeling\nthe query-candidate interaction in parallel. Extensive experiments conducted on\nfour tasks demonstrate that our MixEncoder can speed up sentence pairing by\nover 113x while achieving comparable performance as the more expensive\ncross-attention models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yuanhang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_S/0/1/0/all/0/1\">Shiyi Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chuanyi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Cuiyun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zenglin Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InterFair: Debiasing with Natural Language Feedback for Fair Interpretable Predictions. (arXiv:2210.07440v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.07440","description":"<p>Debiasing methods in NLP models traditionally focus on isolating information\nrelated to a sensitive attribute (e.g., gender or race). We instead argue that\na favorable debiasing method should use sensitive information 'fairly,' with\nexplanations, rather than blindly eliminating it. This fair balance is often\nsubjective and can be challenging to achieve algorithmically. We explore two\ninteractive setups with a frozen predictive model and show that users able to\nprovide feedback can achieve a better and fairer balance between task\nperformance and bias mitigation. In one setup, users, by interacting with test\nexamples, further decreased bias in the explanations (5-8%) while maintaining\nthe same prediction accuracy. In the other setup, human feedback was able to\ndisentangle associated bias and predictive information from the input leading\nto superior bias mitigation and improved task performance (4-5%)\nsimultaneously.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Majumder_B/0/1/0/all/0/1\">Bodhisattwa Prasad Majumder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zexue He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1\">Julian McAuley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Cross-Domain Pre-Trained Language Models for Clinical Text Mining: How Do They Perform on Data-Constrained Fine-Tuning?. (arXiv:2210.12770v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.12770","description":"<p>Fine-tuning Large Language Models (LLMs) pre-trained from general or related\ndomain data to a specific domain and task using a limited amount of resources\navailable in the new task has been a popular practice in NLP fields. In this\nwork, we re-visit this assumption, and carry out investigation in clinical NLP,\nspecifically named-entity recognition on Drugs and their related Attributes. We\ncompare Transformer models that are learned from scratch to fine-tuning\nBERT-based LLMs including BERT-base, BioBERT, and ClinicalBERT. We also\ninvestigate the comparison of such models and their extended models with a CRF\nlayer for continuous learning. We use n2c2-2018 shared task data for model\ndevelopment and evaluations. The experimental outcomes show that 1) the CRF\nlayer makes a difference for all neural models; 2) on BIO-strict span level\nevaluation using macro-average F1, while the fine-tuned LLMs achieved scores\n0.83+, the TransformerCRF model learned from scratch achieved 0.78+\ndemonstrating comparable performances but using much less cost, e.g. 39.80\\%\nless training parameters; 3) on BIO-strict span level evaluation using\nweighted-average F1, the score gaps are even smaller (97.59\\%, 97.44\\%,\n96.84\\%) for models (ClinicalBERT-CRF, BERT-CRF, TransformerCRF). 4) efficient\ntraining using down-sampling for better data-distribution (SamBD) further\nreduced the data for model learning but producing similar outcomes around 0.02\npoints lower than the full set model training. Our models including source\ncodes will be hosted at \\url{https://github.com/HECTA-UoM/TransformerCRF}\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Belkadi_S/0/1/0/all/0/1\">Samuel Belkadi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1\">Lifeng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuping Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Antonini_V/0/1/0/all/0/1\">Valerio Antonini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unifying Data Perspectivism and Personalization: An Application to Social Norms. (arXiv:2210.14531v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.14531","description":"<p>Instead of using a single ground truth for language processing tasks, several\nrecent studies have examined how to represent and predict the labels of the set\nof annotators. However, often little or no information about annotators is\nknown, or the set of annotators is small. In this work, we examine a corpus of\nsocial media posts about conflict from a set of 13k annotators and 210k\njudgements of social norms. We provide a novel experimental setup that applies\npersonalization methods to the modeling of annotators and compare their\neffectiveness for predicting the perception of social norms. We further provide\nan analysis of performance across subsets of social situations that vary by the\ncloseness of the relationship between parties in conflict, and assess where\npersonalization helps the most.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Plepi_J/0/1/0/all/0/1\">Joan Plepi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neuendorf_B/0/1/0/all/0/1\">B&#xe9;la Neuendorf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flek_L/0/1/0/all/0/1\">Lucie Flek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welch_C/0/1/0/all/0/1\">Charles Welch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COFFEE: Counterfactual Fairness for Personalized Text Generation in Explainable Recommendation. (arXiv:2210.15500v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.15500","description":"<p>As language models become increasingly integrated into our digital lives,\nPersonalized Text Generation (PTG) has emerged as a pivotal component with a\nwide range of applications. However, the bias inherent in user written text,\noften used for PTG model training, can inadvertently associate different levels\nof linguistic quality with users' protected attributes. The model can inherit\nthe bias and perpetuate inequality in generating text w.r.t. users' protected\nattributes, leading to unfair treatment when serving users. In this work, we\ninvestigate fairness of PTG in the context of personalized explanation\ngeneration for recommendations. We first discuss the biases in generated\nexplanations and their fairness implications. To promote fairness, we introduce\na general framework to achieve measure-specific counterfactual fairness in\nexplanation generation. Extensive experiments and human evaluations demonstrate\nthe effectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1\">Nan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yi-Chia Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1\">Maziar Sanjabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jingzhou Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Firooz_H/0/1/0/all/0/1\">Hamed Firooz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongning Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_S/0/1/0/all/0/1\">Shaoliang Nie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring Effective Distillation of Self-Supervised Speech Models for Automatic Speech Recognition. (arXiv:2210.15631v3 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2210.15631","description":"<p>Recent years have witnessed great strides in self-supervised learning (SSL)\non the speech processing. The SSL model is normally pre-trained on a great\nvariety of unlabelled data and a large model size is preferred to increase the\nmodeling capacity. However, this might limit its potential applications due to\nthe expensive computation and memory costs introduced by the oversize model.\nMiniaturization for SSL models has become an important research direction of\npractical value. To this end, we explore the effective distillation of\nHuBERT-based SSL models for automatic speech recognition (ASR). First, in order\nto establish a strong baseline, a comprehensive study on different student\nmodel structures is conducted. On top of this, as a supplement to the\nregression loss widely adopted in previous works, a discriminative loss is\nintroduced for HuBERT to enhance the distillation performance, especially in\nlow-resource scenarios. In addition, we design a simple and effective algorithm\nto distill the front-end input from waveform to Fbank feature, resulting in 17%\nparameter reduction and doubling inference speed, at marginal performance\ndegradation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1\">Yujin Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Tang_C/0/1/0/all/0/1\">Changli Tang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Ma_Z/0/1/0/all/0/1\">Ziyang Ma</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zheng_Z/0/1/0/all/0/1\">Zhisheng Zheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1\">Xie Chen</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Qiang Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Understanding ME? Multimodal Evaluation for Fine-grained Visual Commonsense. (arXiv:2211.05895v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.05895","description":"<p>Visual commonsense understanding requires Vision Language (VL) models to not\nonly understand image and text but also cross-reference in-between to fully\nintegrate and achieve comprehension of the visual scene described. Recently,\nvarious approaches have been developed and have achieved high performance on\nvisual commonsense benchmarks. However, it is unclear whether the models really\nunderstand the visual scene and underlying commonsense knowledge due to limited\nevaluation data resources. To provide an in-depth analysis, we present a\nMultimodal Evaluation (ME) pipeline to automatically generate question-answer\npairs to test models' understanding of the visual scene, text, and related\nknowledge. We then take a step further to show that training with the ME data\nboosts the model's performance in standard VCR evaluation. Lastly, our in-depth\nanalysis and comparison reveal interesting findings: (1) semantically low-level\ninformation can assist the learning of high-level information but not the\nopposite; (2) visual information is generally under utilization compared with\ntext.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhecan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_H/0/1/0/all/0/1\">Haoxuan You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1\">Yicheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1\">Wenhao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1\">Shih-Fu Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploiting Contrastive Learning and Numerical Evidence for Confusing Legal Judgment Prediction. (arXiv:2211.08238v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.08238","description":"<p>Given the fact description text of a legal case, legal judgment prediction\n(LJP) aims to predict the case's charge, law article and penalty term. A core\nproblem of LJP is how to distinguish confusing legal cases, where only subtle\ntext differences exist. Previous studies fail to distinguish different\nclassification errors with a standard cross-entropy classification loss, and\nignore the numbers in the fact description for predicting the term of penalty.\nTo tackle these issues, in this work, first, we propose a moco-based supervised\ncontrastive learning to learn distinguishable representations, and explore the\nbest strategy to construct positive example pairs to benefit all three subtasks\nof LJP simultaneously. Second, in order to exploit the numbers in legal cases\nfor predicting the penalty terms of certain cases, we further enhance the\nrepresentation of the fact description with extracted crime amounts which are\nencoded by a pre-trained numeracy model. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results,\nespecially on confusing legal cases. Ablation studies also demonstrate the\neffectiveness of each component.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1\">Leilei Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Baokui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1\">Kun Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yating Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fei Wu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CAPE: Corrective Actions from Precondition Errors using Large Language Models. (arXiv:2211.09935v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2211.09935","description":"<p>Extracting commonsense knowledge from a large language model (LLM) offers a\npath to designing intelligent robots. Existing approaches that leverage LLMs\nfor planning are unable to recover when an action fails and often resort to\nretrying failed actions, without resolving the error's underlying cause.\n</p>\n<p>We propose a novel approach (CAPE) that attempts to propose corrective\nactions to resolve precondition errors during planning. CAPE improves the\nquality of generated plans by leveraging few-shot reasoning from action\npreconditions. Our approach enables embodied agents to execute more tasks than\nbaseline methods while ensuring semantic correctness and minimizing\nre-prompting. In VirtualHome, CAPE generates executable plans while improving a\nhuman-annotated plan correctness metric from 28.89% to 49.63% over SayCan. Our\nimprovements transfer to a Boston Dynamics Spot robot initialized with a set of\nskills (specified in language) and associated preconditions, where CAPE\nimproves the correctness metric of the executed task plans by 76.49% compared\nto SayCan. Our approach enables the robot to follow natural language commands\nand robustly recover from failures, which baseline approaches largely cannot\nresolve or address inefficiently.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raman_S/0/1/0/all/0/1\">Shreyas Sundara Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_V/0/1/0/all/0/1\">Vanya Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paulius_D/0/1/0/all/0/1\">David Paulius</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Idrees_I/0/1/0/all/0/1\">Ifrah Idrees</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosen_E/0/1/0/all/0/1\">Eric Rosen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1\">Ray Mooney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tellex_S/0/1/0/all/0/1\">Stefanie Tellex</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VER: Unifying Verbalizing Entities and Relations. (arXiv:2211.11093v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.11093","description":"<p>Entities and relationships between entities are vital in the real world.\nEssentially, we understand the world by understanding entities and relations.\nFor instance, to understand a field, e.g., computer science, we need to\nunderstand the relevant concepts, e.g., machine learning, and the relationships\nbetween concepts, e.g., machine learning and artificial intelligence. To\nunderstand a person, we should first know who he/she is and how he/she is\nrelated to others. To understand entities and relations, humans may refer to\nnatural language descriptions. For instance, when learning a new scientific\nterm, people usually start by reading its definition in dictionaries or\nencyclopedias. To know the relationship between two entities, humans tend to\ncreate a sentence to connect them. In this paper, we propose VER: a unified\nmodel for Verbalizing Entities and Relations. Specifically, we attempt to build\na system that takes any entity or entity set as input and generates a sentence\nto represent entities and relations. Extensive experiments demonstrate that our\nmodel can generate high-quality sentences describing entities and entity\nrelationships and facilitate various tasks on entities and relations, including\ndefinition modeling, relation modeling, and generative commonsense reasoning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Program of Thoughts Prompting: Disentangling Computation from Reasoning for Numerical Reasoning Tasks. (arXiv:2211.12588v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.12588","description":"<p>Recently, there has been significant progress in teaching language models to\nperform step-by-step reasoning to solve complex numerical reasoning tasks.\nChain-of-thoughts prompting (CoT) is by far the state-of-art method for these\ntasks. CoT uses language models to perform both reasoning and computation in\nthe multi-step `thought' process. To disentangle computation from reasoning, we\npropose `Program of Thoughts' (PoT), which uses language models (mainly Codex)\nto express the reasoning process as a program. The computation is relegated to\nan external computer, which executes the generated programs to derive the\nanswer. We evaluate PoT on five math word problem datasets (GSM, AQuA, SVAMP,\nTabMWP, MultiArith) and three financial-QA datasets (FinQA, ConvFinQA, TATQA)\nfor both few-shot and zero-shot setups. Under both few-shot and zero-shot\nsettings, PoT can show an average performance gain over CoT by around 12\\%\nacross all the evaluated datasets. By combining PoT with self-consistency\ndecoding, we can achieve SoTA performance on all math problem datasets and\nnear-SoTA performance on financial datasets. All of our data and code are\nreleased in Github https://github.com/wenhuchen/Program-of-Thoughts\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xueguang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1\">William W. Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SciRepEval: A Multi-Format Benchmark for Scientific Document Representations. (arXiv:2211.13308v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.13308","description":"<p>Learned representations of scientific documents can serve as valuable input\nfeatures for downstream tasks without further fine-tuning. However, existing\nbenchmarks for evaluating these representations fail to capture the diversity\nof relevant tasks. In response, we introduce SciRepEval, the first\ncomprehensive benchmark for training and evaluating scientific document\nrepresentations. It includes 24 challenging and realistic tasks, 8 of which are\nnew, across four formats: classification, regression, ranking and search. We\nthen use this benchmark to study and improve the generalization ability of\nscientific document representation models. We show how state-of-the-art models\nlike SPECTER and SciNCL struggle to generalize across the task formats, and\nthat simple multi-task training fails to improve them. However, a new approach\nthat learns multiple embeddings per document, each tailored to a different\nformat, can improve performance. We experiment with task-format-specific\ncontrol codes and adapters and find they outperform the existing\nsingle-embedding state-of-the-art by over 2 points absolute. We release the\nresulting family of multi-format models, called SPECTER2, for the community to\nuse and build on.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Amanpreet Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DArcy_M/0/1/0/all/0/1\">Mike D&#x27;Arcy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_A/0/1/0/all/0/1\">Arman Cohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Downey_D/0/1/0/all/0/1\">Doug Downey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feldman_S/0/1/0/all/0/1\">Sergey Feldman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntactic Substitutability as Unsupervised Dependency Syntax. (arXiv:2211.16031v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2211.16031","description":"<p>Syntax is a latent hierarchical structure which underpins the robust and\ncompositional nature of human language. In this work, we explore the hypothesis\nthat syntactic dependencies can be represented in language model attention\ndistributions and propose a new method to induce these structures\ntheory-agnostically. Instead of modeling syntactic relations as defined by\nannotation schemata, we model a more general property implicit in the\ndefinition of dependency relations, syntactic substitutability. This property\ncaptures the fact that words at either end of a dependency can be substituted\nwith words from the same category. Substitutions can be used to generate a set\nof syntactically invariant sentences whose representations are then used for\nparsing. We show that increasing the number of substitutions used improves\nparsing accuracy on natural data. On long-distance subject-verb agreement\nconstructions, our method achieves 79.5% recall compared to 8.9% using a\nprevious method. Our method also provides improvements when transferred to a\ndifferent parsing setup, demonstrating that it generalizes.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jian_J/0/1/0/all/0/1\">Jasper Jian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn Response Selection. (arXiv:2212.00482v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.00482","description":"<p>The task of response selection in multi-turn dialogue is to find the best\noption from all candidates. In order to improve the reasoning ability of the\nmodel, previous studies pay more attention to using explicit algorithms to\nmodel the dependencies between utterances, which are deterministic, limited and\ninflexible. In addition, few studies consider differences between the options\nbefore and after reasoning. In this paper, we propose an Implicit Relational\nReasoning Graph Network to address these issues, which consists of the\nUtterance Relational Reasoner (URR) and the Option Dual Comparator (ODC). URR\naims to implicitly extract dependencies between utterances, as well as\nutterances and options, and make reasoning with relational graph convolutional\nnetworks. ODC focuses on perceiving the difference between the options through\ndual comparison, which can eliminate the interference of the noise options.\nExperimental results on two multi-turn dialogue reasoning benchmark datasets\nMuTual and MuTual+ show that our method significantly improves the baseline of\nfour pretrained language models and achieves state-of-the-art performance. The\nmodel surpasses human performance for the first time on the MuTual dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jingcheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hengwei Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1\">Xuewei Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ju_Y/0/1/0/all/0/1\">Yuanchen Ju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Wei Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DiSTRICT: Dialogue State Tracking with Retriever Driven In-Context Tuning. (arXiv:2212.02851v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.02851","description":"<p>Dialogue State Tracking (DST), a key component of task-oriented conversation\nsystems, represents user intentions by determining the values of pre-defined\nslots in an ongoing dialogue. Existing approaches use hand-crafted templates\nand additional slot information to fine-tune and prompt large pre-trained\nlanguage models and elicit slot values from the dialogue context. Significant\nmanual effort and domain knowledge is required to design effective prompts,\nlimiting the generalizability of these approaches to new domains and tasks. In\nthis work, we propose DiSTRICT, a generalizable in-context tuning approach for\nDST that retrieves highly relevant training examples for a given dialogue to\nfine-tune the model without any hand-crafted templates. Experiments with the\nMultiWOZ benchmark datasets show that DiSTRICT outperforms existing approaches\nin various zero-shot and few-shot settings using a much smaller model, thereby\nproviding an important advantage for real-world deployments that often have\nlimited resource availability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Venkateswaran_P/0/1/0/all/0/1\">Praveen Venkateswaran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duesterwald_E/0/1/0/all/0/1\">Evelyn Duesterwald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Isahagian_V/0/1/0/all/0/1\">Vatche Isahagian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On Event Individuation for Document-Level Information Extraction. (arXiv:2212.09702v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09702","description":"<p>As information extraction (IE) systems have grown more adept at processing\nwhole documents, the classic task of template filling has seen renewed interest\nas benchmark for document-level IE. In this position paper, we call into\nquestion the suitability of template filling for this purpose. We argue that\nthe task demands definitive answers to thorny questions of event individuation\n-- the problem of distinguishing distinct events -- about which even human\nexperts disagree. Through an annotation study and error analysis, we show that\nthis raises concerns about the usefulness of template filling metrics, the\nquality of datasets for the task, and the ability of models to learn it.\nFinally, we consider possible solutions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gantt_W/0/1/0/all/0/1\">William Gantt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kriz_R/0/1/0/all/0/1\">Reno Kriz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vashishtha_S/0/1/0/all/0/1\">Siddharth Vashishtha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1\">Aaron Steven White</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Retrieve-and-Read Framework for Knowledge Graph Link Prediction. (arXiv:2212.09724v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09724","description":"<p>Knowledge graph (KG) link prediction aims to infer new facts based on\nexisting facts in the KG. Recent studies have shown that using the graph\nneighborhood of a node via graph neural networks (GNNs) provides more useful\ninformation compared to just using the query information. Conventional GNNs for\nKG link prediction follow the standard message-passing paradigm on the entire\nKG, which leads to superfluous computation, over-smoothing of node\nrepresentations, and also limits their expressive power. On a large scale, it\nbecomes computationally expensive to aggregate useful information from the\nentire KG for inference. To address the limitations of existing KG link\nprediction frameworks, we propose a novel retrieve-and-read framework, which\nfirst retrieves a relevant subgraph context for the query and then jointly\nreasons over the context and the query with a high-capacity reader. As part of\nour exemplar instantiation for the new framework, we propose a novel\nTransformer-based GNN as the reader, which incorporates graph-based attention\nstructure and cross-attention between query and context for deep fusion. This\nsimple yet effective design enables the model to focus on salient context\ninformation relevant to the query. Empirical results on two standard KG link\nprediction datasets demonstrate the competitive performance of the proposed\nmethod. Furthermore, our analysis yields valuable insights for designing\nimproved retrievers within the framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1\">Vardaan Pahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Boshi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1\">Hugo Latapie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinivasa_J/0/1/0/all/0/1\">Jayanth Srinivasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Comparative Study on Textual Saliency of Styles from Eye Tracking, Annotations, and Language Models. (arXiv:2212.09873v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09873","description":"<p>There is growing interest in incorporating eye-tracking data and other\nimplicit measures of human language processing into natural language processing\n(NLP) pipelines. The data from human language processing contain unique insight\ninto human linguistic understanding that could be exploited by language models.\nHowever, many unanswered questions remain about the nature of this data and how\nit can best be utilized in downstream NLP tasks. In this paper, we present\neyeStyliency, an eye-tracking dataset for human processing of stylistic text\n(e.g., politeness). We develop a variety of methods to derive style saliency\nscores over text using the collected eye dataset. We further investigate how\nthis saliency data compares to both human annotation methods and model-based\ninterpretability metrics. We find that while eye-tracking data is unique, it\nalso intersects with both human annotations and model-based importance scores,\nproviding a possible bridge between human- and machine-based perspectives. We\npropose utilizing this type of data to evaluate the cognitive plausibility of\nmodels that interpret style. Our eye-tracking data and processing code are\npublicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Langis_K/0/1/0/all/0/1\">Karin de Langis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ALCAP: Alignment-Augmented Music Captioner. (arXiv:2212.10901v3 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2212.10901","description":"<p>Music captioning has gained significant attention in the wake of the rising\nprominence of streaming media platforms. Traditional approaches often\nprioritize either the audio or lyrics aspect of the music, inadvertently\nignoring the intricate interplay between the two. However, a comprehensive\nunderstanding of music necessitates the integration of both these elements. In\nthis study, we delve into this overlooked realm by introducing a method to\nsystematically learn multimodal alignment between audio and lyrics through\ncontrastive learning. This not only recognizes and emphasizes the synergy\nbetween audio and lyrics but also paves the way for models to achieve deeper\ncross-modal coherence, thereby producing high-quality captions. We provide both\ntheoretical and empirical results demonstrating the advantage of the proposed\nmethod, which achieves new state-of-the-art on two music captioning datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zihao He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_W/0/1/0/all/0/1\">Weituo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1\">Wei-Tsung Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changyou Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lerman_K/0/1/0/all/0/1\">Kristina Lerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1\">Xuchen Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Smooth Sailing: Improving Active Learning for Pre-trained Language Models with Representation Smoothness Analysis. (arXiv:2212.11680v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.11680","description":"<p>Developed to alleviate prohibitive labeling costs, active learning (AL)\nmethods aim to reduce label complexity in supervised learning. While recent\nwork has demonstrated the benefit of using AL in combination with large\npre-trained language models (PLMs), it has often overlooked the practical\nchallenges that hinder the effectiveness of AL. We address these challenges by\nleveraging representation smoothness analysis to ensure AL is feasible, that\nis, both effective and practicable. Firstly, we propose an early stopping\ntechnique that does not require a validation set -- often unavailable in\nrealistic AL conditions -- and observe significant improvements over random\nsampling across multiple datasets and AL methods. Further, we find that task\nadaptation improves AL, whereas standard short fine-tuning in AL does not\nprovide improvements over random sampling. Our work demonstrates the usefulness\nof representation smoothness analysis for AL and introduces an AL stopping\ncriterion that reduces label complexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jukic_J/0/1/0/all/0/1\">Josip Juki&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Differentially Private Natural Language Models: Recent Advances and Future Directions. (arXiv:2301.09112v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.09112","description":"<p>Recent developments in deep learning have led to great success in various\nnatural language processing (NLP) tasks. However, these applications may\ninvolve data that contain sensitive information. Therefore, how to achieve good\nperformance while also protecting the privacy of sensitive data is a crucial\nchallenge in NLP. To preserve privacy, Differential Privacy (DP), which can\nprevent reconstruction attacks and protect against potential side knowledge, is\nbecoming a de facto technique for private data analysis. In recent years, NLP\nin DP models (DP-NLP) has been studied from different perspectives, which\ndeserves a comprehensive review. In this paper, we provide the first systematic\nreview of recent advances in DP deep learning models in NLP. In particular, we\nfirst discuss some differences and additional challenges of DP-NLP compared\nwith the standard DP deep learning. Then, we investigate some existing work on\nDP-NLP and present its recent developments from three aspects: gradient\nperturbation based methods, embedding vector perturbation based methods, and\nensemble model based methods. We also discuss some challenges and future\ndirections.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1\">Lijie Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1\">Ivan Habernal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Di Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Knowledge Distillation $\\approx$ Label Smoothing: Fact or Fallacy?. (arXiv:2301.12609v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.12609","description":"<p>Originally proposed as a method for knowledge transfer from one model to\nanother, some recent studies have suggested that knowledge distillation (KD) is\nin fact a form of regularization. Perhaps the strongest support of all for this\nnew perspective comes from its apparent similarities with label smoothing (LS).\nHere we re-examine this stated equivalence between the two methods by comparing\nthe predictive confidences of the models they train. Experiments on four text\nclassification tasks involving models of different sizes show that: (a) In most\nsettings, KD and LS drive model confidence in completely opposite directions,\nand (b) In KD, the student inherits not only its knowledge but also its\nconfidence from the teacher, reinforcing the classical knowledge transfer view.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1\">Md Arafat Sultan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using In-Context Learning to Improve Dialogue Safety. (arXiv:2302.00871v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.00871","description":"<p>While large neural-based conversational models have become increasingly\nproficient dialogue agents, recent work has highlighted safety issues with\nthese systems. For example, these systems can be goaded into generating toxic\ncontent, which often perpetuates social biases or stereotypes. We investigate a\nretrieval-based method for reducing bias and toxicity in responses from\nchatbots. It uses in-context learning to steer a model towards safer\ngenerations. Concretely, to generate a response to an unsafe dialogue context,\nwe retrieve demonstrations of safe responses to similar dialogue contexts. We\nfind our method performs competitively with strong baselines without requiring\ntraining. For instance, using automatic evaluation, we find our best fine-tuned\nbaseline only generates safe responses to unsafe dialogue contexts from\nDiaSafety 4.04% more than our approach. Finally, we also propose a re-ranking\nprocedure which can further improve response safeness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meade_N/0/1/0/all/0/1\">Nicholas Meade</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gella_S/0/1/0/all/0/1\">Spandana Gella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1\">Devamanyu Hazarika</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1\">Prakhar Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_D/0/1/0/all/0/1\">Di Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1\">Siva Reddy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hakkani_Tur_D/0/1/0/all/0/1\">Dilek Hakkani-T&#xfc;r</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.03693","description":"<p>This paper concerns the structure of learned representations in text-guided\ngenerative models, focusing on score-based models. A key property of such\nmodels is that they can compose disparate concepts in a `disentangled' manner.\nThis suggests these models have internal representations that encode concepts\nin a `disentangled' manner. Here, we focus on the idea that concepts are\nencoded as subspaces of some representation space. We formalize what this\nmeans, show there's a natural choice for the representation, and develop a\nsimple method for identifying the part of the representation corresponding to a\ngiven concept. In particular, this allows us to manipulate the concepts\nexpressed by the model through algebraic manipulation of the representation. We\ndemonstrate the idea with examples using Stable Diffusion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1\">Lin Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Negrea_J/0/1/0/all/0/1\">Jeffrey Negrea</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1\">Victor Veitch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CodeLMSec Benchmark: Systematically Evaluating and Finding Security Vulnerabilities in Black-Box Code Language Models. (arXiv:2302.04012v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2302.04012","description":"<p>Large language models (LLMs) for automatic code generation have achieved\nbreakthroughs in several programming tasks. Their advances in competition-level\nprogramming problems have made them an essential pillar of AI-assisted pair\nprogramming, and tools such as GitHub Copilot have emerged as part of the daily\nprogramming workflow used by millions of developers. The training data for\nthese models is usually collected from the Internet (e.g., from open-source\nrepositories) and is likely to contain faults and security vulnerabilities.\nThis unsanitized training data can cause the language models to learn these\nvulnerabilities and propagate them during the code generation procedure. While\nthese models have been extensively assessed for their ability to produce\nfunctionally correct programs, there remains a lack of comprehensive\ninvestigations and benchmarks addressing the security aspects of these models.\n</p>\n<p>In this work, we propose a method to systematically study the security issues\nof code language models to assess their susceptibility to generating vulnerable\ncode. To this end, we introduce the first approach to automatically find\ngenerated code that contains vulnerabilities in black-box code generation\nmodels. To achieve this, we present an approach to approximate inversion of the\nblack-box code generation models based on few-shot prompting. We evaluate the\neffectiveness of our approach by examining code language models in generating\nhigh-risk security weaknesses. Furthermore, we establish a collection of\ndiverse non-secure prompts for various vulnerability scenarios using our\nmethod. This dataset forms a benchmark for evaluating and comparing the\nsecurity weaknesses in code language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hajipour_H/0/1/0/all/0/1\">Hossein Hajipour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hassler_K/0/1/0/all/0/1\">Keno Hassler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Holz_T/0/1/0/all/0/1\">Thorsten Holz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schonherr_L/0/1/0/all/0/1\">Lea Sch&#xf6;nherr</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1\">Mario Fritz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning. (arXiv:2302.04858v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2302.04858","description":"<p>Augmenting pretrained language models (LMs) with a vision encoder (e.g.,\nFlamingo) has obtained the state-of-the-art results in image-to-text\ngeneration. However, these models store all the knowledge within their\nparameters, thus often requiring enormous model parameters to model the\nabundant visual concepts and very rich textual descriptions. Additionally, they\nare inefficient in incorporating new data, requiring a computational-expensive\nfine-tuning process. In this work, we introduce a Retrieval-augmented Visual\nLanguage Model, Re-ViLM, built upon the Flamingo, that supports retrieving the\nrelevant knowledge from the external database for zero and in-context few-shot\nimage-to-text generations. By storing certain knowledge explicitly in the\nexternal database, our approach reduces the number of model parameters and can\neasily accommodate new data during evaluation by simply updating the database.\nWe also construct an interleaved image and text data that facilitates\nin-context few-shot learning capabilities. We demonstrate that Re-ViLM\nsignificantly boosts performance for image-to-text generation tasks, especially\nfor zero-shot and few-shot generation in out-of-domain settings with 4 times\nless parameters compared with baseline methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1\">Zhuolin Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1\">Wei Ping</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zihan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korthikanti_V/0/1/0/all/0/1\">Vijay Korthikanti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1\">Weili Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1\">De-An Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1\">Linxi Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhiding Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1\">Shiyi Lan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming-Yu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yuke Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1\">Mohammad Shoeybi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1\">Bryan Catanzaro</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1\">Chaowei Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1\">Anima Anandkumar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Agile Text Classifiers for Everyone. (arXiv:2302.06541v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.06541","description":"<p>Text-based safety classifiers are widely used for content moderation and\nincreasingly to tune generative language model behavior - a topic of growing\nconcern for the safety of digital assistants and chatbots. However, different\npolicies require different classifiers, and safety policies themselves improve\nfrom iteration and adaptation. This paper introduces and evaluates methods for\nagile text classification, whereby classifiers are trained using small,\ntargeted datasets that can be quickly developed for a particular policy.\nExperimenting with 7 datasets from three safety-related domains, comprising 15\nannotation schemes, led to our key finding: prompt-tuning large language\nmodels, like PaLM 62B, with a labeled dataset of as few as 80 examples can\nachieve state-of-the-art performance. We argue that this enables a paradigm\nshift for text classification, especially for models supporting safer online\ndiscourse. Instead of collecting millions of examples to attempt to create\nuniversal safety classifiers over months or years, classifiers could be tuned\nusing small datasets, created by individuals or small organizations, tailored\nfor specific use cases, and iterated on and adapted in the time-span of a day.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mozes_M/0/1/0/all/0/1\">Maximilian Mozes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoffmann_J/0/1/0/all/0/1\">Jessica Hoffmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tomanek_K/0/1/0/all/0/1\">Katrin Tomanek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kouate_M/0/1/0/all/0/1\">Muhamed Kouate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thain_N/0/1/0/all/0/1\">Nithum Thain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_A/0/1/0/all/0/1\">Ann Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bolukbasi_T/0/1/0/all/0/1\">Tolga Bolukbasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dixon_L/0/1/0/all/0/1\">Lucas Dixon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AI Chat Assistants can Improve Conversations about Divisive Topics. (arXiv:2302.07268v5 [cs.HC] UPDATED)","link":"http://arxiv.org/abs/2302.07268","description":"<p>A rapidly increasing amount of human conversation occurs online. But\ndivisiveness and conflict can fester in text-based interactions on social media\nplatforms, in messaging apps, and on other digital forums. Such toxicity\nincreases polarization and, importantly, corrodes the capacity of diverse\nsocieties to develop efficient solutions to complex social problems that impact\neveryone. Scholars and civil society groups promote interventions that can make\ninterpersonal conversations less divisive or more productive in offline\nsettings, but scaling these efforts to the amount of discourse that occurs\nonline is extremely challenging. We present results of a large-scale experiment\nthat demonstrates how online conversations about divisive topics can be\nimproved with artificial intelligence tools. Specifically, we employ a large\nlanguage model to make real-time, evidence-based recommendations intended to\nimprove participants' perception of feeling understood in conversations. We\nfind that these interventions improve the reported quality of the conversation,\nreduce political divisiveness, and improve the tone, without systematically\nchanging the content of the conversation or moving people's policy attitudes.\nThese findings have important implications for future research on social media,\npolitical deliberation, and the growing community of scholars interested in the\nplace of artificial intelligence within computational social science.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Argyle_L/0/1/0/all/0/1\">Lisa P. Argyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Busby_E/0/1/0/all/0/1\">Ethan Busby</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gubler_J/0/1/0/all/0/1\">Joshua Gubler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bail_C/0/1/0/all/0/1\">Chris Bail</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Howe_T/0/1/0/all/0/1\">Thomas Howe</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rytting_C/0/1/0/all/0/1\">Christopher Rytting</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wingate_D/0/1/0/all/0/1\">David Wingate</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WiCE: Real-World Entailment for Claims in Wikipedia. (arXiv:2303.01432v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.01432","description":"<p>Textual entailment models are increasingly applied in settings like\nfact-checking, presupposition verification in question answering, or summary\nevaluation. However, these represent a significant domain shift from existing\nentailment datasets, and models underperform as a result. We propose WiCE, a\nnew fine-grained textual entailment dataset built on natural claim and evidence\npairs extracted from Wikipedia. In addition to standard claim-level entailment,\nWiCE provides entailment judgments over sub-sentence units of the claim, and a\nminimal subset of evidence sentences that support each subclaim. To support\nthis, we propose an automatic claim decomposition strategy using GPT-3.5 which\nwe show is also effective at improving entailment models' performance on\nmultiple datasets at test time. Finally, we show that real claims in our\ndataset involve challenging verification and retrieval problems that existing\nmodels fail to address.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kamoi_R/0/1/0/all/0/1\">Ryo Kamoi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_T/0/1/0/all/0/1\">Tanya Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rodriguez_J/0/1/0/all/0/1\">Juan Diego Rodriguez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1\">Greg Durrett</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Model Is Not a Good Few-shot Information Extractor, but a Good Reranker for Hard Samples!. (arXiv:2303.08559v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.08559","description":"<p>Large Language Models (LLMs) have made remarkable strides in various tasks.\nWhether LLMs are competitive few-shot solvers for information extraction (IE)\ntasks, however, remains an open problem. In this work, we aim to provide a\nthorough answer to this question. Through extensive experiments on nine\ndatasets across four IE tasks, we demonstrate that current advanced LLMs\nconsistently exhibit inferior performance, higher latency, and increased budget\nrequirements compared to fine-tuned SLMs under most settings. Therefore, we\nconclude that LLMs are not effective few-shot information extractors in\ngeneral. Nonetheless, we illustrate that with appropriate prompting strategies,\nLLMs can effectively complement SLMs and tackle challenging samples that SLMs\nstruggle with. And moreover, we propose an adaptive filter-then-rerank paradigm\nto combine the strengths of LLMs and SLMs. In this paradigm, SLMs serve as\nfilters and LLMs serve as rerankers. By prompting LLMs to rerank a small\nportion of difficult samples identified by SLMs, our preliminary system\nconsistently achieves promising improvements (2.4% F1-gain on average) on\nvarious IE tasks, with an acceptable time and cost investment.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yubo Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixin Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1\">YongChing Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1\">Aixin Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context-faithful Prompting for Large Language Models. (arXiv:2303.11315v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.11315","description":"<p>Large language models (LLMs) encode parametric knowledge about world facts\nand have shown remarkable performance in knowledge-driven NLP tasks. However,\ntheir reliance on parametric knowledge may cause them to overlook contextual\ncues, leading to incorrect predictions in context-sensitive NLP tasks (e.g.,\nknowledge acquisition tasks). In this paper, we seek to assess and enhance\nLLMs' contextual faithfulness in two aspects: knowledge conflict and prediction\nwith abstention. We demonstrate that LLMs' faithfulness can be significantly\nimproved using carefully designed prompting strategies. In particular, we\nidentify opinion-based prompts and counterfactual demonstrations as the most\neffective methods. Opinion-based prompts reframe the context as a narrator's\nstatement and inquire about the narrator's opinions, while counterfactual\ndemonstrations use instances containing false facts to improve faithfulness in\nknowledge conflict situations. Neither technique requires additional training.\nWe conduct experiments on three datasets of two standard NLP tasks, machine\nreading comprehension and relation extraction, and the results demonstrate\nsignificant improvement in faithfulness to contexts. Code and data are released\nat https://github.com/wzhouad/context-faithful-llm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wenxuan Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Muhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization for Few-shot Generalization. (arXiv:2303.12314v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12314","description":"<p>Prompt tuning is a parameter-efficient method, which learns soft prompts and\nconditions frozen language models to perform specific downstream tasks. Though\neffective, prompt tuning under few-shot settings on the one hand heavily relies\non a good initialization of soft prompts. On the other hand, it can easily\noverfit to few-shot training samples, thereby undermining generalizability.\nExisting works leverage pre-training or supervised meta-learning to initialize\nsoft prompts but they fail to data-efficiently generalize to unseen downstream\ntasks. To address the above problems, this paper proposes a novel\nSelf-sUpervised meta-Prompt learning framework with MEta-gradient\nRegularization for few-shot generalization (SUPMER). SUPMER leverages\nself-supervised meta-learning with a diverse set of well-designed meta-training\ntasks to learn a universal prompt initialization for efficient adaptation using\nonly unlabeled data. Additionally, it jointly meta-learns a gradient\nregularization function to transform raw gradients into a domain-generalizable\ndirection, thus alleviating the problem of overfitting. Extensive experiments\nshow that SUPMER achieves better performance for different few-shot downstream\ntasks, and also exhibits a stronger domain generalization ability. The code for\nSUPMER will be available at https://github.com/beepkh/SUPMER.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_K/0/1/0/all/0/1\">Kaihang Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Juncheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Hongye Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1\">Jun Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaozhong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1\">Siliang Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEGA: Multilingual Evaluation of Generative AI. (arXiv:2303.12528v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.12528","description":"<p>Generative AI models have shown impressive performance on many Natural\nLanguage Processing tasks such as language understanding, reasoning, and\nlanguage generation. An important question being asked by the AI community\ntoday is about the capabilities and limits of these models, and it is clear\nthat evaluating generative AI is very challenging. Most studies on generative\nLLMs have been restricted to English and it is unclear how capable these models\nare at understanding and generating text in other languages. We present the\nfirst comprehensive benchmarking of generative LLMs - MEGA, which evaluates\nmodels on standard NLP benchmarks, covering 16 NLP datasets across 70\ntypologically diverse languages. We compare the performance of generative LLMs\nincluding Chat-GPT and GPT-4 to State of the Art (SOTA) non-autoregressive\nmodels on these tasks to determine how well generative models perform compared\nto the previous generation of LLMs. We present a thorough analysis of the\nperformance of models across languages and tasks and discuss challenges in\nimproving the performance of generative LLMs on low-resource languages. We\ncreate a framework for evaluating generative LLMs in the multilingual setting\nand provide directions for future progress in the field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1\">Kabir Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Diddee_H/0/1/0/all/0/1\">Harshita Diddee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hada_R/0/1/0/all/0/1\">Rishav Hada</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ochieng_M/0/1/0/all/0/1\">Millicent Ochieng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ramesh_K/0/1/0/all/0/1\">Krithika Ramesh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Prachi Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nambi_A/0/1/0/all/0/1\">Akshay Nambi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganu_T/0/1/0/all/0/1\">Tanuja Ganu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Segal_S/0/1/0/all/0/1\">Sameer Segal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Axmed_M/0/1/0/all/0/1\">Maxamed Axmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bali_K/0/1/0/all/0/1\">Kalika Bali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitaram_S/0/1/0/all/0/1\">Sunayana Sitaram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Thorny Roses: Investigating the Dual Use Dilemma in Natural Language Processing. (arXiv:2304.08315v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.08315","description":"<p>Dual use, the intentional, harmful reuse of technology and scientific\nartefacts, is a problem yet to be well-defined within the context of Natural\nLanguage Processing (NLP). However, as NLP technologies continue to advance and\nbecome increasingly widespread in society, their inner workings have become\nincreasingly opaque. Therefore, understanding dual use concerns and potential\nways of limiting them is critical to minimising the potential harms of research\nand development. In this paper, we conduct a survey of NLP researchers and\npractitioners to understand the depth and their perspective of the problem as\nwell as to assess existing available support. Based on the results of our\nsurvey, we offer a definition of dual use that is tailored to the needs of the\nNLP community. The survey revealed that a majority of researchers are concerned\nabout the potential dual use of their research but only take limited action\ntoward it. In light of the survey results, we discuss the current state and\npotential means for mitigating dual use in NLP and propose a checklist that can\nbe integrated into existing conference ethics-frameworks, e.g., the ACL ethics\nchecklist.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaffee_L/0/1/0/all/0/1\">Lucie-Aim&#xe9;e Kaffee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arora_A/0/1/0/all/0/1\">Arnav Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talat_Z/0/1/0/all/0/1\">Zeerak Talat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1\">Isabelle Augenstein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Outlier Suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling. (arXiv:2304.09145v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.09145","description":"<p>Post-training quantization~(PTQ) of transformer language models faces\nsignificant challenges due to the existence of detrimental outliers in\nactivations. We observe that these outliers are concentrated in specific\nchannels and are asymmetric across channels. To address this issue, we propose\nthe Outlier Suppression+~(OS+) framework, which contains the channel-wise\nshifting for asymmetry and channel-wise scaling for concentration. We show that\nthese operations can be seamlessly migrated into subsequent modules while\nmaintaining equivalence. Second, we propose a fast and stable scheme to\ncalculate effective shifting and scaling values. The channel-wise shifting\naligns the center of each channel for removal of outlier asymmetry. The\nchannel-wise scaling quantitatively evaluates changes brought by migration and\nquantization for better quantization burden balance. We validate our OS+ under\nboth standard and fine-grained quantization settings with models including\nBERT, OPT, BLOOM, BLOOMZ, and LLaMA. Comprehensive results across various tasks\ndemonstrate the superiority of our approach. Especially, with standard\nquantization, OS+ can achieve near-floating-point performance on both small\nmodels and large language models on 8-bit and 6-bit. Besides, we establish a\nnew state-of-the-art for 4-bit BERT with 15.5\\% improvement. Our code is\navailable at \\url{https://github.com/ModelTC/Outlier_Suppression_Plus}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1\">Xiuying Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunchen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yuhang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangguo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1\">Ruihao Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1\">Jinyang Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xianglong Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Transformer-Based Language Model Surprisal Predicts Human Reading Times Best with About Two Billion Training Tokens. (arXiv:2304.11389v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.11389","description":"<p>Recent psycholinguistic studies have drawn conflicting conclusions about the\nrelationship between the quality of a language model and the ability of its\nsurprisal estimates to predict human reading times, which has been speculated\nto be due to the large gap in both the amount of training data and model\ncapacity across studies. The current work aims to consolidate these findings by\nevaluating surprisal estimates from Transformer-based language model variants\nthat vary systematically in the amount of training data and model capacity on\ntheir ability to predict human reading times. The results show that surprisal\nestimates from most variants with contemporary model capacities provide the\nbest fit after seeing about two billion training tokens, after which they begin\nto diverge from humanlike expectations. Additionally, newly-trained smaller\nmodel variants reveal a 'tipping point' at convergence, after which the\ndecrease in language model perplexity begins to result in poorer fits to human\nreading times. These results suggest that the massive amount of training data\nis mainly responsible for the poorer fit achieved by surprisal from larger\npre-trained language models, and that a certain degree of model capacity is\nnecessary for Transformer-based language models to capture humanlike\nexpectations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oh_B/0/1/0/all/0/1\">Byung-Doh Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schuler_W/0/1/0/all/0/1\">William Schuler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Speak, Memory: An Archaeology of Books Known to ChatGPT/GPT-4. (arXiv:2305.00118v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.00118","description":"<p>In this work, we carry out a data archaeology to infer books that are known\nto ChatGPT and GPT-4 using a name cloze membership inference query. We find\nthat OpenAI models have memorized a wide collection of copyrighted materials,\nand that the degree of memorization is tied to the frequency with which\npassages of those books appear on the web. The ability of these models to\nmemorize an unknown set of books complicates assessments of measurement\nvalidity for cultural analytics by contaminating test data; we show that models\nperform much better on memorized books than on non-memorized books for\ndownstream tasks. We argue that this supports a case for open models whose\ntraining data is known.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kent K. Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cramer_M/0/1/0/all/0/1\">Mackenzie Cramer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soni_S/0/1/0/all/0/1\">Sandeep Soni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamman_D/0/1/0/all/0/1\">David Bamman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models. (arXiv:2305.01219v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01219","description":"<p>The prompt-based learning paradigm, which bridges the gap between\npre-training and fine-tuning, achieves state-of-the-art performance on several\nNLP tasks, particularly in few-shot settings. Despite being widely applied,\nprompt-based learning is vulnerable to backdoor attacks. Textual backdoor\nattacks are designed to introduce targeted vulnerabilities into models by\npoisoning a subset of training samples through trigger injection and label\nmodification. However, they suffer from flaws such as abnormal natural language\nexpressions resulting from the trigger and incorrect labeling of poisoned\nsamples. In this study, we propose ProAttack, a novel and efficient method for\nperforming clean-label backdoor attacks based on the prompt, which uses the\nprompt itself as a trigger. Our method does not require external triggers and\nensures correct labeling of poisoned samples, improving the stealthy nature of\nthe backdoor attack. With extensive experiments on rich-resource and few-shot\ntext classification tasks, we empirically validate ProAttack's competitive\nperformance in textual backdoor attacks. Notably, in the rich-resource setting,\nProAttack achieves state-of-the-art attack success rates in the clean-label\nbackdoor attack benchmark without external triggers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Shuai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jinming Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1\">Luu Anh Tuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Junbo Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation. (arXiv:2305.01498v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.01498","description":"<p>We present PeerSum, a novel dataset for generating meta-reviews of scientific\npapers. The meta-reviews can be interpreted as abstractive summaries of\nreviews, multi-turn discussions and the paper abstract. These source documents\nhave rich inter-document relationships with an explicit hierarchical\nconversational structure, cross-references and (occasionally) conflicting\ninformation. To introduce the structural inductive bias into pre-trained\nlanguage models, we introduce Rammer ( Relationship-aware Multi-task\nMeta-review Generator), a model that uses sparse attention based on the\nconversational structure and a multi-task training objective that predicts\nmetadata features (e.g., review ratings). Our experimental results show that\nRammer outperforms other strong baseline models in terms of a suite of\nautomatic evaluation metrics. Further analyses, however, reveal that RAMMER and\nother models struggle to handle conflicts in source documents of PeerSum,\nsuggesting meta-review generation is a challenging task and a promising avenue\nfor further research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Miao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1\">Eduard Hovy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lau_J/0/1/0/all/0/1\">Jey Han Lau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-RE: In-context Learning for Relation Extraction using Large Language Models. (arXiv:2305.02105v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02105","description":"<p>In spite of the potential for ground-breaking achievements offered by large\nlanguage models (LLMs) (e.g., GPT-3), they still lag significantly behind\nfully-supervised baselines (e.g., fine-tuned BERT) in relation extraction (RE).\nThis is due to the two major shortcomings of LLMs in RE: (1) low relevance\nregarding entity and relation in retrieved demonstrations for in-context\nlearning; and (2) the strong inclination to wrongly classify NULL examples into\nother pre-defined labels.\n</p>\n<p>In this paper, we propose GPT-RE to bridge the gap between LLMs and\nfully-supervised baselines. GPT-RE successfully addresses the aforementioned\nissues by (1) incorporating task-specific entity representations in\ndemonstration retrieval; and (2) enriching the demonstrations with gold\nlabel-induced reasoning logic. We evaluate GPT-RE on four widely-used RE\ndatasets, and observe that GPT-RE achieves improvements over not only existing\nGPT-3 baselines, but also fully-supervised baselines. Specifically, GPT-RE\nachieves SOTA performances on the Semeval and SciERC datasets, and competitive\nperformances on the TACRED and ACE05 datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zhen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_F/0/1/0/all/0/1\">Fei Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Z/0/1/0/all/0/1\">Zhuoyuan Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qianying Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1\">Haiyue Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiwei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurohashi_S/0/1/0/all/0/1\">Sadao Kurohashi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Being Parameter-Efficient: A Stratified Sparsely Activated Transformer with Dynamic Capacity. (arXiv:2305.02176v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02176","description":"<p>Mixture-of-experts (MoE) models that employ sparse activation have\ndemonstrated effectiveness in significantly increasing the number of parameters\nwhile maintaining low computational requirements per token. However, recent\nstudies have established that MoE models are inherently parameter-inefficient\nas the improvement in performance diminishes with an increasing number of\nexperts. We hypothesize this parameter inefficiency is a result of all experts\nhaving equal capacity, which may not adequately meet the varying complexity\nrequirements of different tokens or tasks. In light of this, we propose\nStratified Mixture of Experts (SMoE) models, which feature a stratified\nstructure and can assign dynamic capacity to different tokens. We demonstrate\nthe effectiveness of SMoE on three multilingual machine translation benchmarks,\ncontaining 4, 15, and 94 language pairs, respectively. We show that SMoE\noutperforms multiple state-of-the-art MoE models with the same or fewer\nparameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elbayad_M/0/1/0/all/0/1\">Maha Elbayad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1\">Kenton Murray</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maillard_J/0/1/0/all/0/1\">Jean Maillard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Benefits of Label-Description Training for Zero-Shot Text Classification. (arXiv:2305.02239v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02239","description":"<p>Pretrained language models have improved zero-shot text classification by\nallowing the transfer of semantic knowledge from the training data in order to\nclassify among specific label sets in downstream tasks. We propose a simple way\nto further improve zero-shot accuracies with minimal effort. We curate small\nfinetuning datasets intended to describe the labels for a task. Unlike typical\nfinetuning data, which has texts annotated with labels, our data simply\ndescribes the labels in language, e.g., using a few related terms,\ndictionary/encyclopedia entries, and short templates. Across a range of topic\nand sentiment datasets, our method is more accurate than zero-shot by 17-19%\nabsolute. It is also more robust to choices required for zero-shot\nclassification, such as patterns for prompting the model to classify and\nmappings from labels to tokens in the model's vocabulary. Furthermore, since\nour data merely describes the labels but does not use input texts, finetuning\non it yields a model that performs strongly on multiple text domains for a\ngiven label set, even improving over few-shot out-of-domain classification in\nmultiple settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Lingyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1\">Debanjan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gimpel_K/0/1/0/all/0/1\">Kevin Gimpel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for Long-Turn Open-Domain Dialogue Pre-training. (arXiv:2305.02606v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.02606","description":"<p>Pre-training on large-scale open-domain dialogue data can substantially\nimprove the performance of dialogue models. However, the pre-trained dialogue\nmodel's ability to utilize long-range context is limited due to the scarcity of\nlong-turn dialogue sessions. Most dialogues in existing pre-training corpora\ncontain fewer than three turns of dialogue. To alleviate this issue, we propose\nthe Retrieve, Reorganize and Rescale framework (Re$^3$Dial), which can\nautomatically construct billion-scale long-turn dialogues by reorganizing\nexisting short-turn ones. Given a short-turn session, Re$^3$Dial first employs\na session retriever to retrieve coherent consecutive sessions. To this end, we\ntrain the retriever to capture semantic and discourse relations within\nmulti-turn dialogues through contrastive training. Next, Re$^3$Dial samples a\nsession from retrieved results following a diversity sampling strategy, which\nis designed to penalize repetitive or generic sessions. A longer session is\nthen derived by concatenating the original session and the sampled session. By\nrepeating the above process, Re$^3$Dial can yield a coherent long-turn\ndialogue. Extensive experiments on multiple multi-turn dialogue benchmarks\ndemonstrate that Re$^3$Dial significantly improves the dialogue model's ability\nto utilize long-range context and thus generate more sensible and informative\nresponses. Finally, we build a toolkit for efficiently rescaling conversations\nwith Re$^3$Dial, which enables us to construct a corpus containing 1B Chinese\ndialogue sessions with 11.3 turns on average (5$\\times$ longer than the\noriginal corpus). Our retriever model, code, and data is publicly available at\n\\url{https://github.com/thu-coai/Re3Dial}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Jiaxin Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1\">Jian Guan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition. (arXiv:2305.02996v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2305.02996","description":"<p>Cross-encoder models, which jointly encode and score a query-item pair, are\nprohibitively expensive for direct k-nearest neighbor (k-NN) search.\nConsequently, k-NN search typically employs a fast approximate retrieval (e.g.\nusing BM25 or dual-encoder vectors), followed by reranking with a\ncross-encoder; however, the retrieval approximation often has detrimental\nrecall regret. This problem is tackled by ANNCUR (Yadav et al., 2022), a recent\nwork that employs a cross-encoder only, making search efficient using a\nrelatively small number of anchor items, and a CUR matrix factorization. While\nANNCUR's one-time selection of anchors tends to approximate the cross-encoder\ndistances on average, doing so forfeits the capacity to accurately estimate\ndistances to items near the query, leading to regret in the crucial end-task:\nrecall of top-k items. In this paper, we propose ADACUR, a method that\nadaptively, iteratively, and efficiently minimizes the approximation error for\nthe practically important top-k neighbors. It does so by iteratively performing\nk-NN search using the anchors available so far, then adding these retrieved\nnearest neighbors to the anchor set for the next round. Empirically, on\nmultiple datasets, in comparison to previous traditional and state-of-the-art\nmethods such as ANNCUR and dual-encoder-based retrieve-and-rerank, our proposed\napproach ADACUR consistently reduces recall error-by up to 70% on the important\nk = 1 setting-while using no more compute than its competitors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1\">Nishant Yadav</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monath_N/0/1/0/all/0/1\">Nicholas Monath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1\">Manzil Zaheer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1\">Andrew McCallum</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Expository Text Generation: Imitate, Retrieve, Paraphrase. (arXiv:2305.03276v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03276","description":"<p>Expository documents are vital resources for conveying complex information to\nreaders. Despite their usefulness, writing expository text by hand is a\nchallenging process that requires careful content planning, obtaining facts\nfrom multiple sources, and the ability to clearly synthesize these facts. To\nease these burdens, we propose the task of expository text generation, which\nseeks to automatically generate an accurate and stylistically consistent\nexpository text for a topic by intelligently searching a knowledge source. We\nsolve our task by developing IRP, a framework that overcomes the limitations of\nretrieval-augmented models and iteratively performs content planning, fact\nretrieval, and rephrasing. Through experiments on three diverse,\nnewly-collected datasets, we show that IRP produces factual and organized\nexpository texts that accurately inform readers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Balepur_N/0/1/0/all/0/1\">Nishant Balepur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Good Intentions: Reporting the Research Landscape of NLP for Social Good. (arXiv:2305.05471v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.05471","description":"<p>With the recent advances in natural language processing (NLP), a vast number\nof applications have emerged across various use cases. Among the plethora of\nNLP applications, many academic researchers are motivated to do work that has a\npositive social impact, in line with the recent initiatives of NLP for Social\nGood (NLP4SG). However, it is not always obvious to researchers how their\nresearch efforts are tackling today's big social problems. Thus, in this paper,\nwe introduce NLP4SG Papers, a scientific dataset with three associated tasks\nthat can help identify NLP4SG papers and characterize the NLP4SG landscape by:\n(1) identifying the papers that address a social problem, (2) mapping them to\nthe corresponding UN Sustainable Development Goals (SDGs), and (3) identifying\nthe task they are solving and the methods they are using. Using\nstate-of-the-art NLP models, we address each of these tasks and use them on the\nentire ACL Anthology, resulting in a visualization workspace that gives\nresearchers a comprehensive overview of the field of NLP4SG. Our website is\navailable at https://nlp4sg.vercel.app. We released our data at\nhttps://huggingface.co/datasets/feradauto/NLP4SGPapers and code at\nhttps://github.com/feradauto/nlp4sg\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gonzalez_F/0/1/0/all/0/1\">Fernando Gonzalez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hope_T/0/1/0/all/0/1\">Tom Hope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Active Retrieval Augmented Generation. (arXiv:2305.06983v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06983","description":"<p>Despite the remarkable ability of large language models (LMs) to comprehend\nand generate language, they have a tendency to hallucinate and create factually\ninaccurate output. Augmenting LMs by retrieving information from external\nknowledge resources is one promising solution. Most existing retrieval\naugmented LMs employ a retrieve-and-generate setup that only retrieves\ninformation once based on the input. This is limiting, however, in more general\nscenarios involving generation of long texts, where continually gathering\ninformation throughout generation is essential. In this work, we provide a\ngeneralized view of active retrieval augmented generation, methods that\nactively decide when and what to retrieve across the course of the generation.\nWe propose Forward-Looking Active REtrieval augmented generation (FLARE), a\ngeneric method which iteratively uses a prediction of the upcoming sentence to\nanticipate future content, which is then utilized as a query to retrieve\nrelevant documents to regenerate the sentence if it contains low-confidence\ntokens. We test FLARE along with baselines comprehensively over 4 long-form\nknowledge-intensive generation tasks/datasets. FLARE achieves superior or\ncompetitive performance on all tasks, demonstrating the effectiveness of our\nmethod. Code and datasets are available at https://github.com/jzbjyb/FLARE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1\">Zhengbao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Frank F. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1\">Luyu Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zhiqing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dwivedi_Yu_J/0/1/0/all/0/1\">Jane Dwivedi-Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yiming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Callan_J/0/1/0/all/0/1\">Jamie Callan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not All Languages Are Created Equal in LLMs: Improving Multilingual Capability by Cross-Lingual-Thought Prompting. (arXiv:2305.07004v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07004","description":"<p>Large language models (LLMs) demonstrate impressive multilingual capability,\nbut their performance varies substantially across different languages. In this\nwork, we introduce a simple yet effective method, called cross-lingual-thought\nprompting (XLT), to systematically improve the multilingual capability of LLMs.\nSpecifically, XLT is a generic template prompt that stimulates cross-lingual\nand logical reasoning skills to enhance task performance across languages. We\nconduct comprehensive evaluations on 7 typical benchmarks related to reasoning,\nunderstanding, and generation tasks, covering both high-resource and\nlow-resource languages. Experimental results show that XLT not only remarkably\nenhances the performance of various multilingual tasks but also significantly\nreduces the gap between the average performance and the best performance of\neach task in different languages. Notably, XLT brings over 10 points of average\nimprovement in arithmetic reasoning and open-domain question-answering tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoyang Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1\">Tianyi Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongdong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_T/0/1/0/all/0/1\">Ting Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1\">Furu Wei</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZARA: Improving Few-Shot Self-Rationalization for Small Language Models. (arXiv:2305.07355v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07355","description":"<p>Language models (LMs) that jointly generate end-task answers as well as\nfree-text rationales are known as self-rationalization models. Recent works\ndemonstrate great performance gain for self-rationalization by few-shot\nprompting LMs with rationale-augmented exemplars. However, the ability to\nbenefit from explanations only emerges with large-scale LMs, which have poor\naccessibility. In this work, we explore the less-studied setting of leveraging\nexplanations for small LMs to improve few-shot self-rationalization. We first\nrevisit the relationship between rationales and answers. Inspired by the\nimplicit mental process of how human beings assess explanations, we present a\nnovel approach, Zero-shot Augmentation of Rationale-Answer pairs (ZARA), to\nautomatically construct pseudo-parallel data for self-training by reducing the\nproblem of plausibility judgement to natural language inference. Experimental\nresults show ZARA achieves SOTA performance on the FEB benchmark, for both the\ntask accuracy and the explanation metric. In addition, we conduct human and\nquantitative evaluation validating ZARA's ability to automatically identify\nplausible and accurate rationale-answer pairs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Lin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yen_A/0/1/0/all/0/1\">An-Zi Yen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng-Kuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hen-Hsen Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hsin-Hsi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts. (arXiv:2305.07988v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.07988","description":"<p>Meetings typically involve multiple participants and lengthy conversations,\nresulting in redundant and trivial content. To overcome these challenges, we\npropose a two-step framework, Reconstruct before Summarize (RbS), for effective\nand efficient meeting summarization. RbS first leverages a self-supervised\nparadigm to annotate essential contents by reconstructing the meeting\ntranscripts. Secondly, we propose a relative positional bucketing (RPB)\nalgorithm to equip (conventional) summarization models to generate the summary.\nDespite the additional reconstruction process, our proposed RPB significantly\ncompressed the input, leading to faster processing and reduced memory\nconsumption compared to traditional summarization methods. We validate the\neffectiveness and efficiency of our method through extensive evaluations and\nanalysis. On two meeting summarization datasets, AMI and ICSI, our approach\noutperforms previous state-of-the-art approaches without relying on large-scale\npre-training or expert-grade annotating tools.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1\">Haochen Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wei Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinyun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhan_M/0/1/0/all/0/1\">Mingjie Zhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1\">Zhaohui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Ding Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StructGPT: A General Framework for Large Language Model to Reason over Structured Data. (arXiv:2305.09645v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09645","description":"<p>In this paper, we study how to improve the zero-shot reasoning ability of\nlarge language models~(LLMs) over structured data in a unified way. Inspired by\nthe study on tool augmentation for LLMs, we develop an \\emph{Iterative\nReading-then-Reasoning~(IRR)} approach for solving question answering tasks\nbased on structured data, called \\textbf{StructGPT}. In our approach, we\nconstruct the specialized function to collect relevant evidence from structured\ndata (\\ie \\emph{reading}), and let LLMs concentrate the reasoning task based on\nthe collected information (\\ie \\emph{reasoning}). Specially, we propose an\n\\emph{invoking-linearization-generation} procedure to support LLMs in reasoning\non the structured data with the help of the external interfaces. By iterating\nthis procedures with provided interfaces, our approach can gradually approach\nthe target answer to a given query. Extensive experiments conducted on three\ntypes of structured data demonstrate the effectiveness of our approach, which\ncan significantly boost the performance of ChatGPT and achieve comparable\nperformance against the full-data supervised-tuning baselines. Our codes and\ndata are publicly available at~\\url{https://github.com/RUCAIBox/StructGPT}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jinhao Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1\">Kun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1\">Zican Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1\">Keming Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mirages: On Anthropomorphism in Dialogue Systems. (arXiv:2305.09800v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09800","description":"<p>Automated dialogue or conversational systems are anthropomorphised by\ndevelopers and personified by users. While a degree of anthropomorphism may be\ninevitable due to the choice of medium, conscious and unconscious design\nchoices can guide users to personify such systems to varying degrees.\nEncouraging users to relate to automated systems as if they were human can lead\nto high risk scenarios caused by over-reliance on their outputs. As a result,\nnatural language processing researchers have investigated the factors that\ninduce personification and develop resources to mitigate such effects. However,\nthese efforts are fragmented, and many aspects of anthropomorphism have yet to\nbe explored. In this paper, we discuss the linguistic factors that contribute\nto the anthropomorphism of dialogue systems and the harms that can arise,\nincluding reinforcing gender stereotypes and notions of acceptable language. We\nrecommend that future efforts towards developing dialogue systems take\nparticular care in their design, development, release, and description; and\nattend to the many linguistic cues that can elicit personification by users.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abercrombie_G/0/1/0/all/0/1\">Gavin Abercrombie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Curry_A/0/1/0/all/0/1\">Amanda Cercas Curry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinkar_T/0/1/0/all/0/1\">Tanvi Dinkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1\">Verena Rieser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talat_Z/0/1/0/all/0/1\">Zeerak Talat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Qualifying Chinese Medical Licensing Examination with Knowledge Enhanced Generative Pre-training Model. (arXiv:2305.10163v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10163","description":"<p>Generative Pre-Training (GPT) models like ChatGPT have demonstrated\nexceptional performance in various Natural Language Processing (NLP) tasks.\nAlthough ChatGPT has been integrated into the overall workflow to boost\nefficiency in many domains, the lack of flexibility in the finetuning process\nhinders its applications in areas that demand extensive domain expertise and\nsemantic knowledge, such as healthcare. In this paper, we evaluate ChatGPT on\nthe China National Medical Licensing Examination (CNMLE) and propose a novel\napproach to improve ChatGPT from two perspectives: integrating medical domain\nknowledge and enabling few-shot learning. By using a simple but effective\nretrieval method, medical background knowledge is extracted as semantic\ninstructions to guide the inference of ChatGPT. Similarly, relevant medical\nquestions are identified and fed as demonstrations to ChatGPT. Experimental\nresults show that directly applying ChatGPT fails to qualify the CNMLE at a\nscore of 51 (i.e., only 51\\% of questions are answered correctly). While our\nknowledge-enhanced model achieves a high score of 70 on CNMLE-2022 which not\nonly passes the qualification but also surpasses the average score of humans\n(61). This research demonstrates the potential of knowledge-enhanced ChatGPT to\nserve as versatile medical assistants, capable of analyzing real-world medical\nproblems in a more accessible, user-friendly, and adaptable manner.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiageng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_Z/0/1/0/all/0/1\">Zhaopeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Minghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yefeng Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jie Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Learning the Visualness of Text Using Large Vision-Language Models. (arXiv:2305.10434v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10434","description":"<p>Visual text evokes an image in a person's mind, while non-visual text fails\nto do so. A method to automatically detect visualness in text will enable\ntext-to-image retrieval and generation models to augment text with relevant\nimages. This is particularly challenging with long-form text as text-to-image\ngeneration and retrieval models are often triggered for text that is designed\nto be explicitly visual in nature, whereas long-form text could contain many\nnon-visual sentences. To this end, we curate a dataset of 3,620 English\nsentences and their visualness scores provided by multiple human annotators. We\nalso propose a fine-tuning strategy that adapts large vision-language models\nlike CLIP by modifying the model's contrastive learning objective to map text\nidentified as non-visual to a common NULL image while matching visual text to\ntheir corresponding images in the document. We evaluate the proposed approach\non its ability to (i) classify visual and non-visual text accurately, and (ii)\nattend over words that are identified as visual in psycholinguistic studies.\nEmpirical evaluation indicates that our approach performs better than several\nheuristics and baseline models for the proposed task. Furthermore, to highlight\nthe importance of modeling the visualness of text, we conduct qualitative\nanalyses of text-to-image generation systems like DALL-E. Project webpage:\nhttps://gaurav22verma.github.io/text-visualness/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Verma_G/0/1/0/all/0/1\">Gaurav Verma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tensmeyer_C/0/1/0/all/0/1\">Christopher Tensmeyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jiuxiang Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenkova_A/0/1/0/all/0/1\">Ani Nenkova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Paxion: Patching Action Knowledge in Video-Language Foundation Models. (arXiv:2305.10683v4 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.10683","description":"<p>Action knowledge involves the understanding of textual, visual, and temporal\naspects of actions. We introduce the Action Dynamics Benchmark (ActionBench)\ncontaining two carefully designed probing tasks: Action Antonym and Video\nReversal, which targets multimodal alignment capabilities and temporal\nunderstanding skills of the model, respectively. Despite recent video-language\nmodels' (VidLM) impressive performance on various benchmark tasks, our\ndiagnostic tasks reveal their surprising deficiency (near-random performance)\nin action knowledge, suggesting that current models rely on object recognition\nabilities as a shortcut for action understanding. To remedy this, we propose a\nnovel framework, Paxion, along with a new Discriminative Video Dynamics\nModeling (DVDM) objective. The Paxion framework utilizes a Knowledge Patcher\nnetwork to encode new action knowledge and a Knowledge Fuser component to\nintegrate the Patcher into frozen VidLMs without compromising their existing\ncapabilities. Due to limitations of the widely-used Video-Text Contrastive\n(VTC) loss for learning action knowledge, we introduce the DVDM objective to\ntrain the Knowledge Patcher. DVDM forces the model to encode the correlation\nbetween the action text and the correct ordering of video frames. Our extensive\nanalyses show that Paxion and DVDM together effectively fill the gap in action\nknowledge understanding (~50% to 80%), while maintaining or improving\nperformance on a wide spectrum of both object- and action-centric downstream\ntasks. The code and data will be made publicly available for research purposes\nat https://github.com/MikeWangWZHL/Paxion.git.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenhailong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blume_A/0/1/0/all/0/1\">Ansel Blume</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Genglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1\">Jaemin Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1\">Zineng Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency. (arXiv:2305.10713v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10713","description":"<p>With growing capabilities of large language models, prompting them has become\nthe dominant way to access them. This has motivated the development of\nstrategies for automatically selecting effective language prompts. In this\npaper, we introduce prompt flatness, a new metric to quantify the expected\nutility of a language prompt. This metric is inspired by flatness\nregularization in statistical learning that quantifies the robustness of the\nmodel towards its parameter perturbations. We provide theoretical foundations\nfor this metric and its relationship with other prompt selection metrics,\nproviding a comprehensive understanding of existing methods. Empirically, we\nshow that combining prompt flatness with existing metrics improves both\nperformance and sample efficiency. Our metric outperforms the previous prompt\nselection metrics with an average increase of 5% in accuracy and 10% in Pearson\ncorrelation across 6 classification benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Lingfeng Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weiting Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1\">Boyuan Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1\">Daniel Khashabi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Ditto: A Simple and Efficient Approach to Improve Sentence Embeddings. (arXiv:2305.10786v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.10786","description":"<p>Prior studies diagnose the anisotropy problem in sentence representations\nfrom pre-trained language models, e.g., BERT, without fine-tuning. Our analysis\nreveals that the sentence embeddings from BERT suffer from a bias towards\nuninformative words, limiting the performance in semantic textual similarity\n(STS) tasks. To address this bias, we propose a simple and efficient\nunsupervised approach, Diagonal Attention Pooling (Ditto), which weights words\nwith model-based importance estimations and computes the weighted average of\nword representations from pre-trained models as sentence embeddings. Ditto can\nbe easily applied to any pre-trained language model as a postprocessing\noperation. Compared to prior sentence embedding approaches, Ditto does not add\nparameters nor requires any learning. Empirical evaluations demonstrate that\nour proposed Ditto can alleviate the anisotropy problem and improve various\npre-trained models on STS tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Siqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yukun Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chong Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Viewing Knowledge Transfer in Multilingual Machine Translation Through a Representational Lens. (arXiv:2305.11550v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11550","description":"<p>We argue that translation quality alone is not a sufficient metric for\nmeasuring knowledge transfer in multilingual neural machine translation. To\nsupport this claim, we introduce Representational Transfer Potential (RTP),\nwhich measures representational similarities between languages. We show that\nRTP can measure both positive and negative transfer (interference), and find\nthat RTP is strongly correlated with changes in translation quality, indicating\nthat transfer does occur. Furthermore, we investigate data and language\ncharacteristics that are relevant for transfer, and find that multi-parallel\noverlap is an important yet under-explored feature. Based on this, we develop a\nnovel training scheme, which uses an auxiliary similarity loss that encourages\nrepresentations to be more invariant across languages by taking advantage of\nmulti-parallel data. We show that our method yields increased translation\nquality for low- and mid-resource languages across multiple data and model\nsetups.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stap_D/0/1/0/all/0/1\">David Stap</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niculae_V/0/1/0/all/0/1\">Vlad Niculae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Monz_C/0/1/0/all/0/1\">Christof Monz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models. (arXiv:2305.11747v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11747","description":"<p>Large language models (LLMs), such as ChatGPT, are prone to generate\nhallucinations, i.e., content that conflicts with the source or cannot be\nverified by the factual knowledge. To understand what types of content and to\nwhich extent LLMs are apt to hallucinate, we introduce the Hallucination\nEvaluation benchmark for Large Language Models (HaluEval), a large collection\nof generated and human-annotated hallucinated samples for evaluating the\nperformance of LLMs in recognizing hallucination. To generate these samples, we\npropose a ChatGPT-based two-step framework, i.e., sampling-then-filtering.\nBesides, we also hire some human labelers to annotate the hallucinations in\nChatGPT responses. The empirical results suggest that ChatGPT is likely to\ngenerate hallucinated content in specific topics by fabricating unverifiable\ninformation (i.e., about $19.5\\%$ responses). Moreover, existing LLMs face\ngreat challenges in recognizing the hallucinations in texts. However, our\nexperiments also prove that providing external knowledge or adding reasoning\nsteps can help LLMs recognize hallucinations. Our benchmark can be accessed at\nhttps://github.com/RUCAIBox/HaluEval.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xiaoxue Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1\">Wayne Xin Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1\">Jian-Yun Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1\">Ji-Rong Wen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reducing Sequence Length by Predicting Edit Operations with Large Language Models. (arXiv:2305.11862v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11862","description":"<p>Large Language Models (LLMs) have demonstrated remarkable performance in\nvarious tasks and gained significant attention. LLMs are also used for local\nsequence transduction tasks, including grammatical error correction (GEC) and\nformality style transfer, where most tokens in a source text are kept\nunchanged. However, the models that generate all target tokens in such tasks\nhave a tendency to simply copy the input text as is, without making needed\nchanges, because the difference between input and output texts is minimal in\nthe training data. This is also inefficient because the computational cost\ngrows quadratically with the target sequence length with Transformer. This\npaper proposes predicting edit spans for the source text for local sequence\ntransduction tasks. Representing an edit span with a position of the source\ntext and corrected tokens, we can reduce the length of the target sequence and\nthe computational cost for inference. We apply instruction tuning for LLMs on\nthe supervision data of edit spans. Experiments show that the proposed method\nachieves comparable performance to the baseline in four tasks, paraphrasing,\nformality style transfer, GEC, and text simplification, despite reducing the\nlength of the target text by as small as 21%. Furthermore, we report that the\ntask-specific fine-tuning with the proposed method achieved state-of-the-art\nperformance in the four tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kaneko_M/0/1/0/all/0/1\">Masahiro Kaneko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Okazaki_N/0/1/0/all/0/1\">Naoaki Okazaki</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting Automated Topic Model Evaluation with Large Language Models. (arXiv:2305.12152v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12152","description":"<p>Topic models are used to make sense of large text collections. However,\nautomatically evaluating topic model output and determining the optimal number\nof topics both have been longstanding challenges, with no effective automated\nsolutions to date. This paper proposes using large language models to evaluate\nsuch output. We find that large language models appropriately assess the\nresulting topics, correlating more strongly with human judgments than existing\nautomated metrics. We then investigate whether we can use large language models\nto automatically determine the optimal number of topics. We automatically\nassign labels to documents and choosing configurations with the most pure\nlabels returns reasonable values for the optimal number of topics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stammbach_D/0/1/0/all/0/1\">Dominik Stammbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zouhar_V/0/1/0/all/0/1\">Vil&#xe9;m Zouhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hoyle_A/0/1/0/all/0/1\">Alexander Hoyle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ash_E/0/1/0/all/0/1\">Elliott Ash</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Open-QA Evaluation. (arXiv:2305.12421v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12421","description":"<p>This study focuses on the evaluation of the Open Question Answering (Open-QA)\ntask, which can directly estimate the factuality of large language models\n(LLMs). Current automatic evaluation methods have shown limitations, indicating\nthat human evaluation still remains the most reliable approach. We introduce a\nnew task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset\nEVOUNA, designed to assess the accuracy of AI-generated answers in relation to\nstandard answers within Open-QA. Our evaluation of these methods utilizes\nhuman-annotated results to measure their performance. Specifically, the work\ninvestigates methods that show high correlation with human evaluations, deeming\nthem more reliable. We also discuss the pitfalls of current methods and methods\nto improve LLM-based evaluators. We believe this new QA-Eval task and\ncorresponding dataset EVOUNA will facilitate the development of more effective\nautomatic evaluation tools and prove valuable for future research in this area.\nAll resources are available at \\url{https://github.com/wangcunxiang/QA-Eval}\nand it is under the Apache-2.0 License.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sirui Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1\">Yuanhao Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bowen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhikun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiangkun Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Retrieving Texts based on Abstract Descriptions. (arXiv:2305.12517v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12517","description":"<p>While instruction-tuned Large Language Models (LLMs) excel at extracting\ninformation from text, they are not suitable for locating texts conforming to a\ngiven description in a large document collection (semantic retrieval).\nSimilarity search over embedding vectors does allow to perform retrieval by\nquery, but the similarity reflected in the embedding is ill-defined and\nnon-consistent, and is sub-optimal for many use cases. What, then, is a good\nquery representation for effective retrieval?\n</p>\n<p>We identify the well defined and consistent task of retrieving sentences\nbased on abstract descriptions of their content. We demonstrate the inadequacy\nof current text embeddings and propose an alternative model that significantly\nimproves when used in standard nearest neighbor search. The model is trained\nusing positive and negative pairs sourced through prompting a LLM. While it is\neasy to source the training material from an LLM, the retrieval task cannot be\nperformed by the LLM directly. This demonstrates that data from LLMs can be\nused not only for distilling more efficient specialized models than the\noriginal LLM, but also for creating new capabilities not immediately possible\nusing the original model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ravfogel_S/0/1/0/all/0/1\">Shauli Ravfogel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pyatkin_V/0/1/0/all/0/1\">Valentina Pyatkin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1\">Amir DN Cohen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manevich_A/0/1/0/all/0/1\">Avshalom Manevich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1\">Yoav Goldberg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Few-shot Classification with Instruction-Finetuned Language Models. (arXiv:2305.12576v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12576","description":"<p>A particularly successful class of approaches for few-shot learning combines\nlanguage models with prompts -- hand-crafted task descriptions that complement\ndata samples. However, designing prompts by hand for each task commonly\nrequires domain knowledge and substantial guesswork. We observe, in the context\nof classification tasks, that instruction finetuned language models exhibit\nremarkable prompt robustness, and we subsequently propose a simple method to\neliminate the need for handcrafted prompts, named AuT-Few. This approach\nconsists of (i) a prompt retrieval module that selects suitable task\ninstructions from the instruction-tuning knowledge base, and (ii) the\ngeneration of two distinct, semantically meaningful, class descriptions and a\nselection mechanism via cross-validation. Over $12$ datasets, spanning $8$\nclassification tasks, we show that AuT-Few outperforms current state-of-the-art\nfew-shot learning methods. Moreover, AuT-Few is the best ranking method across\ndatasets on the RAFT few-shot benchmark. Notably, these results are achieved\nwithout task-specific handcrafted prompts on unseen tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aly_R/0/1/0/all/0/1\">Rami Aly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1\">Xingjian Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kaixiang Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1\">Andrew Gordon Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Labels: Empowering Human Annotators with Natural Language Explanations through a Novel Active-Learning Architecture. (arXiv:2305.12710v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12710","description":"<p>Real-world domain experts (e.g., doctors) rarely annotate only a decision\nlabel in their day-to-day workflow without providing explanations. Yet,\nexisting low-resource learning techniques, such as Active Learning (AL), that\naim to support human annotators mostly focus on the label while neglecting the\nnatural language explanation of a data point. This work proposes a novel AL\narchitecture to support experts' real-world need for label and explanation\nannotations in low-resource scenarios. Our AL architecture leverages an\nexplanation-generation model to produce explanations guided by human\nexplanations, a prediction model that utilizes generated explanations toward\nprediction faithfully, and a novel data diversity-based AL sampling strategy\nthat benefits from the explanation annotations. Automated and human evaluations\ndemonstrate the effectiveness of incorporating explanations into AL sampling\nand the improved human annotation efficiency and trustworthiness with our AL\narchitecture. Additional ablation studies illustrate the potential of our AL\narchitecture for transfer learning, generalizability, and integration with\nlarge language models (LLMs). While LLMs exhibit exceptional\nexplanation-generation capabilities for relatively simple tasks, their\neffectiveness in complex real-world tasks warrants further in-depth study.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1\">Bingsheng Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jindal_I/0/1/0/all/0/1\">Ishan Jindal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1\">Lucian Popa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Katsis_Y/0/1/0/all/0/1\">Yannis Katsis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1\">Sayan Ghosh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1\">Lihong He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yuxuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Shashank Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunyao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hendler_J/0/1/0/all/0/1\">James Hendler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dakuo Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Decomposed Prompting for Machine Translation Between Related Languages using Large Language Models. (arXiv:2305.13085v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13085","description":"<p>This study investigates machine translation between related languages i.e.,\nlanguages within the same family that share linguistic characteristics such as\nword order and lexical similarity. Machine translation through few-shot\nprompting leverages a small set of translation pair examples to generate\ntranslations for test sentences. This procedure requires the model to learn how\nto generate translations while simultaneously ensuring that token ordering is\nmaintained to produce a fluent and accurate translation. We propose that for\nrelated languages, the task of machine translation can be simplified by\nleveraging the monotonic alignment characteristic of such languages. We\nintroduce DecoMT, a novel approach of few-shot prompting that decomposes the\ntranslation process into a sequence of word chunk translations. Through\nautomatic and human evaluation conducted on multiple related language pairs\nacross various language families, we demonstrate that our proposed approach of\ndecomposed prompting surpasses multiple established few-shot baseline\napproaches. For example, DecoMT outperforms the strong few-shot prompting BLOOM\nmodel with an average improvement of 8 chrF++ scores across the examined\nlanguages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Puduppully_R/0/1/0/all/0/1\">Ratish Puduppully</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabre_R/0/1/0/all/0/1\">Raj Dabre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aw_A/0/1/0/all/0/1\">Ai Ti Aw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nancy F. Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables. (arXiv:2305.13186v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13186","description":"<p>Current scientific fact-checking benchmarks exhibit several shortcomings,\nsuch as biases arising from crowd-sourced claims and an over-reliance on\ntext-based evidence. We present SCITAB, a challenging evaluation dataset\nconsisting of 1.2K expert-verified scientific claims that 1) originate from\nauthentic scientific publications and 2) require compositional reasoning for\nverification. The claims are paired with evidence-containing scientific tables\nannotated with labels. Through extensive evaluations, we demonstrate that\nSCITAB poses a significant challenge to state-of-the-art models, including\ntable-based pretraining models and large language models. All models except\nGPT-4 achieved performance barely above random guessing. Popular prompting\ntechniques, such as Chain-of-Thought, do not achieve much performance gains on\nSCITAB. Our analysis uncovers several unique challenges posed by SCITAB,\nincluding table grounding, claim ambiguity, and compositional reasoning. Our\ncodes and data are publicly available at https://github.com/XinyuanLu00/SciTab.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1\">Xinyuan Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Liangming Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qian Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1\">Preslav Nakov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting is not a substitute for probability measurements in large language models. (arXiv:2305.13264v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13264","description":"<p>Prompting is now a dominant method for evaluating the linguistic knowledge of\nlarge language models (LLMs). While other methods directly read out models'\nprobability distributions over strings, prompting requires models to access\nthis internal information by processing linguistic input, thereby implicitly\ntesting a new type of emergent ability: metalinguistic judgment. In this study,\nwe compare metalinguistic prompting and direct probability measurements as ways\nof measuring models' linguistic knowledge. Broadly, we find that LLMs'\nmetalinguistic judgments are inferior to quantities directly derived from\nrepresentations. Furthermore, consistency gets worse as the prompt query\ndiverges from direct measurements of next-word probabilities. Our findings\nsuggest that negative results relying on metalinguistic prompts cannot be taken\nas conclusive evidence that an LLM lacks a particular linguistic\ngeneralization. Our results also highlight the value that is lost with the move\nto closed APIs where access to probability distributions is limited.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1\">Jennifer Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levy_R/0/1/0/all/0/1\">Roger Levy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DADA: Dialect Adaptation via Dynamic Aggregation of Linguistic Rules. (arXiv:2305.13406v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13406","description":"<p>Existing large language models (LLMs) that mainly focus on Standard American\nEnglish (SAE) often lead to significantly worse performance when being applied\nto other English dialects. While existing mitigations tackle discrepancies for\nindividual target dialects, they assume access to high-accuracy dialect\nidentification systems. The boundaries between dialects are inherently\nflexible, making it difficult to categorize language into discrete predefined\ncategories. In this paper, we propose DADA (Dialect Adaptation via Dynamic\nAggregation), a modular approach to imbue SAE-trained models with\nmulti-dialectal robustness by composing adapters which handle specific\nlinguistic features. The compositional architecture of DADA allows for both\ntargeted adaptation to specific dialect variants and simultaneous adaptation to\nvarious dialects. We show that DADA is effective for both single task and\ninstruction finetuned language models, offering an extensible and interpretable\nframework for adapting existing LLMs to different English dialects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yanchen Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_W/0/1/0/all/0/1\">William Held</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAILEX: Email Event and Argument Extraction. (arXiv:2305.13469v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13469","description":"<p>In this work, we present the first dataset, MailEx, for performing event\nextraction from conversational email threads. To this end, we first proposed a\nnew taxonomy covering 10 event types and 76 arguments in the email domain. Our\nfinal dataset includes 1.5K email threads and ~4K emails, which are annotated\nwith totally ~8K event instances. To understand the task challenges, we\nconducted a series of experiments comparing three types of approaches, i.e.,\nfine-tuned sequence labeling, fine-tuned generative extraction, and few-shot\nin-context learning. Our results showed that the task of email event extraction\nis far from being addressed, due to challenges lying in, e.g., extracting\nnon-continuous, shared trigger spans, extracting non-named entity arguments,\nand modeling the email conversational history. Our work thus suggests more\nfuture investigations in this domain-specific event extraction task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1\">Saurabh Srivastava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1\">Gaurav Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Matsumoto_S/0/1/0/all/0/1\">Shou Matsumoto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raz_A/0/1/0/all/0/1\">Ali Raz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Costa_P/0/1/0/all/0/1\">Paulo Costa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poore_J/0/1/0/all/0/1\">Joshua Poore</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1\">Ziyu Yao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Look-back Decoding for Open-Ended Text Generation. (arXiv:2305.13477v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13477","description":"<p>Given a prefix (context), open-ended generation aims to decode texts that are\ncoherent, which do not abruptly drift from previous topics, and informative,\nwhich do not suffer from undesired repetitions. In this paper, we propose\nLook-back, an improved decoding algorithm that leverages the Kullback-Leibler\ndivergence to track the distribution distance between current and historical\ndecoding steps. Thus Look-back can automatically predict potential repetitive\nphrase and topic drift, and remove tokens that may cause the failure modes,\nrestricting the next token probability distribution within a plausible distance\nto the history. We perform decoding experiments on document continuation and\nstory generation, and demonstrate that Look-back is able to generate more\nfluent and coherent text, outperforming other strong decoding methods\nsignificantly in both automatic and human evaluations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xuezhe Ma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Evolution Learning for Mixup: Enhance Data Augmentation on Few-Shot Text Classification Tasks. (arXiv:2305.13547v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13547","description":"<p>Text classification tasks often encounter few shot scenarios with limited\nlabeled data, and addressing data scarcity is crucial. Data augmentation with\nmixup has shown to be effective on various text classification tasks. However,\nmost of the mixup methods do not consider the varying degree of learning\ndifficulty in different stages of training and generate new samples with one\nhot labels, resulting in the model over confidence. In this paper, we propose a\nself evolution learning (SE) based mixup approach for data augmentation in text\nclassification, which can generate more adaptive and model friendly pesudo\nsamples for the model training. SE focuses on the variation of the model's\nlearning ability. To alleviate the model confidence, we introduce a novel\ninstance specific label smoothing approach, which linearly interpolates the\nmodel's output and one hot labels of the original samples to generate new soft\nfor label mixing up. Through experimental analysis, in addition to improving\nclassification accuracy, we demonstrate that SE also enhances the model's\ngeneralize ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Haoqi Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1\">Qihuang Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhiliang Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niu_X/0/1/0/all/0/1\">Xin Niu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongsheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EDIS: Entity-Driven Image Search over Multimodal Web Content. (arXiv:2305.13631v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13631","description":"<p>Making image retrieval methods practical for real-world search applications\nrequires significant progress in dataset scales, entity comprehension, and\nmultimodal information fusion. In this work, we introduce\n\\textbf{E}ntity-\\textbf{D}riven \\textbf{I}mage \\textbf{S}earch (EDIS), a\nchallenging dataset for cross-modal image search in the news domain. EDIS\nconsists of 1 million web images from actual search engine results and curated\ndatasets, with each image paired with a textual description. Unlike datasets\nthat assume a small set of single-modality candidates, EDIS reflects real-world\nweb image search scenarios by including a million multimodal image-text pairs\nas candidates. EDIS encourages the development of retrieval models that\nsimultaneously address cross-modal information fusion and matching. To achieve\naccurate ranking results, a model must: 1) understand named entities and events\nfrom text queries, 2) ground entities onto images or text descriptions, and 3)\neffectively fuse textual and visual representations. Our experimental results\nshow that EDIS challenges state-of-the-art methods with dense entities and a\nlarge-scale candidate set. The ablation study also proves that fusing textual\nfeatures with visual features is critical in improving retrieval results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1\">Weixi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1\">Tsu-jui Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wenhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">William Yang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Aligning Large Language Models through Synthetic Feedback. (arXiv:2305.13735v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13735","description":"<p>Aligning large language models (LLMs) to human values has become increasingly\nimportant as it enables sophisticated steering of LLMs. However, it requires\nsignificant human demonstrations and feedback or distillation from proprietary\nLLMs such as ChatGPT. In this work, we propose a novel alignment learning\nframework with synthetic feedback not dependent on extensive human annotations\nand proprietary LLMs. First, we perform reward modeling (RM) with synthetic\nfeedback by contrasting responses from vanilla LLMs with various sizes and\nprompts. Then, we use the RM to simulate high-quality demonstrations to train a\nsupervised policy and further optimize the model with reinforcement learning.\nOur resulting model, Aligned Language Model with Synthetic Training dataset\n(ALMoST), outperforms recent open-sourced models, which are trained on the\noutputs of InstructGPT or human-annotated demonstrations, in alignment\nbenchmarks. In human evaluation, our model is preferred to Alpaca and Dolly-v2,\n55.0% and 58.5% of the time, respectively. Further analyses demonstrate the\nefficacy and importance of synthetic feedback in our framework. The code is\navailable at https://github.com/naver-ai/almost\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungdong Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1\">Sanghwan Bae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1\">Jamin Shin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1\">Soyoung Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwak_D/0/1/0/all/0/1\">Donghyun Kwak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_K/0/1/0/all/0/1\">Kang Min Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seo_M/0/1/0/all/0/1\">Minjoon Seo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Grammar-Constrained Decoding for Structured NLP Tasks without Finetuning. (arXiv:2305.13971v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13971","description":"<p>Despite their impressive performance, large language models (LMs) still\nstruggle with reliably generating complex output structures when not finetuned\nto follow the required output format exactly. To address this issue,\ngrammar-constrained decoding (GCD) can be used to control the generation of\nLMs, guaranteeing that the output follows a given structure. Most existing GCD\nmethods are, however, limited to specific tasks, such as parsing or code\ngeneration. In this work, we demonstrate that formal grammars can describe the\noutput space for a much wider range of tasks and argue that GCD can serve as a\nunified framework for structured NLP tasks in general. For increased\nflexibility, we introduce input-dependent grammars, which allow the grammar to\ndepend on the input and thus enable the generation of different output\nstructures for different inputs. We then empirically demonstrate the power and\nflexibility of GCD-enhanced LMs on (1) information extraction, (2) entity\ndisambiguation, and (3) constituency parsing. Our results indicate that\ngrammar-constrained LMs substantially outperform unconstrained LMs or even beat\ntask-specific finetuned models. Grammar constraints thus hold great promise for\nharnessing off-the-shelf LMs for a wide range of structured NLP tasks,\nespecially where training data is scarce or finetuning is expensive. Code and\ndata: https://github.com/epfl-dlab/GCD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1\">Saibo Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Josifosky_M/0/1/0/all/0/1\">Martin Josifosky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peyrard_M/0/1/0/all/0/1\">Maxime Peyrard</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_R/0/1/0/all/0/1\">Robert West</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Condensing Multilingual Knowledge with Lightweight Language-Specific Modules. (arXiv:2305.13993v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13993","description":"<p>Incorporating language-specific (LS) modules is a proven method to boost\nperformance in multilingual machine translation. This approach bears similarity\nto Mixture-of-Experts (MoE) because it does not inflate FLOPs. However, the\nscalability of this approach to hundreds of languages (experts) tends to be\nunmanageable due to the prohibitive number of parameters introduced by\nfull-rank matrices in fully-connected layers. In this work, we introduce the\nLanguage-Specific Matrix Synthesis (LMS) method. This approach constructs LS\nmodules by generating low-rank matrices from two significantly smaller matrices\nto approximate the full-rank matrix. Furthermore, we condense multilingual\nknowledge from multiple LS modules into a single shared module with the Fuse\nDistillation (FD) technique to improve the efficiency of inference and model\nserialization. We show that our LMS method significantly outperforms previous\nLS methods and MoE methods with the same amount of extra parameters, e.g., 1.73\nBLEU points over the Switch Transformer on many-to-many multilingual machine\ntranslation. Importantly, LMS is able to have comparable translation\nperformance with much fewer parameters.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoran Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1\">Weiting Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shuyue Stella Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yunmo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1\">Benjamin Van Durme</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1\">Philipp Koehn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Murray_K/0/1/0/all/0/1\">Kenton Murray</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards A Unified View of Sparse Feed-Forward Network in Pretraining Large Language Model. (arXiv:2305.13999v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.13999","description":"<p>Large and sparse feed-forward layers (S-FFN) such as Mixture-of-Experts (MoE)\nhave proven effective in scaling up Transformers model size for\n\\textit{pretraining} large language models. By only activating part of the FFN\nparameters conditioning on input, S-FFN improves generalization performance\nwhile keeping training and inference costs (in FLOPs) fixed. In this work, we\nanalyzed two major design choices of S-FFN: the memory block (a.k.a. expert)\nsize and the memory block selection method under a general conceptual framework\nof sparse neural memory. Using this unified framework, we compare several S-FFN\narchitectures for language modeling and provide insights into their relative\nefficacy and efficiency. We found a simpler selection method --\n\\textbf{\\texttt{Avg-K}} that selects blocks through their mean aggregated\nhidden states, achieving lower perplexity in language model pretraining\ncompared to existing MoE architectures including Switch Transformer (Fedus et\nal., 2021) and HashLayer (Roller et al., 2021).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Leo Z. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dettmers_T/0/1/0/all/0/1\">Tim Dettmers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stoyanov_V/0/1/0/all/0/1\">Veselin Stoyanov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xian Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CTQScorer: Combining Multiple Features for In-context Example Selection for Machine Translation. (arXiv:2305.14105v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14105","description":"<p>Large language models have demonstrated the capability to perform on machine\ntranslation when the input is prompted with a few examples (in-context\nlearning). Translation quality depends on various features of the selected\nexamples, such as their quality and relevance, but previous work has\npredominantly focused on individual features in isolation. In this paper, we\npropose a general framework for combining different features influencing\nexample selection. We learn a regression model, CTQ Scorer (Contextual\nTranslation Quality), that selects examples based on multiple features in order\nto maximize the translation quality. On multiple language pairs and language\nmodels, we show that CTQ Scorer helps significantly outperform random selection\nas well as strong single-factor baselines reported in the literature. We also\nsee an improvement of over 2.5 COMET points on average with respect to a strong\nBM25 retrieval-based baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1\">Aswanth Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Puduppully_R/0/1/0/all/0/1\">Ratish Puduppully</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dabre_R/0/1/0/all/0/1\">Raj Dabre</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kunchukuttan_A/0/1/0/all/0/1\">Anoop Kunchukuttan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models. (arXiv:2305.14214v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14214","description":"<p>While many languages possess processes of joining two or more words to create\ncompound words, previous studies have been typically limited only to languages\nwith excessively productive compound formation (e.g., German, Dutch) and there\nis no public dataset containing compound and non-compound words across a large\nnumber of languages. In this work, we systematically study decompounding, the\ntask of splitting compound words into their constituents, at a wide scale. We\nfirst address the data gap by introducing a dataset of 255k compound and\nnon-compound words across 56 diverse languages obtained from Wiktionary. We\nthen use this dataset to evaluate an array of Large Language Models (LLMs) on\nthe decompounding task. We find that LLMs perform poorly, especially on words\nwhich are tokenized unfavorably by subword tokenization. We thus introduce a\nnovel methodology to train dedicated models for decompounding. The proposed\ntwo-stage procedure relies on a fully self-supervised objective in the first\nstage, while the second, supervised learning stage optionally fine-tunes the\nmodel on the annotated Wiktionary data. Our self-supervised models outperform\nthe prior best unsupervised decompounding models by 13.9% accuracy on average.\nOur fine-tuned models outperform all prior (language-specific) decompounding\ntools. Furthermore, we use our models to leverage decompounding during the\ncreation of a subword tokenizer, which we refer to as CompoundPiece.\nCompoundPiece tokenizes compound words more favorably on average, leading to\nimproved performance on decompounding over an otherwise equivalent model using\nSentencePiece tokenization.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Minixhofer_B/0/1/0/all/0/1\">Benjamin Minixhofer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_J/0/1/0/all/0/1\">Jonas Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Large Language Models Are Not (Yet) Code-Switchers. (arXiv:2305.14235v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14235","description":"<p>Multilingual Large Language Models (LLMs) have recently shown great\ncapabilities in a wide range of tasks, exhibiting state-of-the-art performance\nthrough zero-shot or few-shot prompting methods. While there have been\nextensive studies on their abilities in monolingual tasks, the investigation of\ntheir potential in the context of code-switching (CSW), the practice of\nalternating languages within an utterance, remains relatively uncharted. In\nthis paper, we provide a comprehensive empirical analysis of various\nmultilingual LLMs, benchmarking their performance across four tasks: sentiment\nanalysis, machine translation, summarization and word-level language\nidentification. Our results indicate that despite multilingual LLMs exhibiting\npromising outcomes in certain tasks using zero or few-shot prompting, they\nstill underperform in comparison to fine-tuned models of much smaller scales.\nWe argue that current \"multilingualism\" in LLMs does not inherently imply\nproficiency with code-switching texts, calling for future research to bridge\nthis discrepancy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1\">Ruochen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1\">Samuel Cahyawijaya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cruz_J/0/1/0/all/0/1\">Jan Christian Blaise Cruz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1\">Genta Indra Winata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Prompting Assists Large Language Model on Web Navigation. (arXiv:2305.14257v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14257","description":"<p>Large language models (LLMs) struggle on processing complicated observations\nin interactive decision making tasks. To alleviate this issue, we propose a\nsimple hierarchical prompting approach. Diverging from previous prompting\napproaches that always put the \\emph{full} observation~(\\eg a web page) to the\nprompt, we propose to first construct an action-aware observation which is more\n\\emph{condensed} and \\emph{relevant} with a dedicated \\summ prompt. The \\actor\nprompt then predicts the next action based on the summarized observation. While\nour method has broad applicability, we particularly demonstrate its efficacy in\nthe complex domain of web navigation where a full observation often contains\nredundant and irrelevant information. Our approach outperforms the previous\nstate-of-the-art prompting mechanis by 6.2\\% on task success rate,\ndemonstrating its potential on interactive decision making tasks with long\nobservation traces.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sridhar_A/0/1/0/all/0/1\">Abishek Sridhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lo_R/0/1/0/all/0/1\">Robert Lo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Frank F. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1\">Shuyan Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query Rewriting for Retrieval-Augmented Large Language Models. (arXiv:2305.14283v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14283","description":"<p>Large Language Models (LLMs) play powerful, black-box readers in the\nretrieve-then-read pipeline, making remarkable progress in knowledge-intensive\ntasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of\nthe previous retrieve-then-read for the retrieval-augmented LLMs from the\nperspective of the query rewriting. Unlike prior studies focusing on adapting\neither the retriever or the reader, our approach pays attention to the\nadaptation of the search query itself, for there is inevitably a gap between\nthe input text and the needed knowledge in retrieval. We first prompt an LLM to\ngenerate the query, then use a web search engine to retrieve contexts.\nFurthermore, to better align the query to the frozen modules, we propose a\ntrainable scheme for our pipeline. A small language model is adopted as a\ntrainable rewriter to cater to the black-box LLM reader. The rewriter is\ntrained using the feedback of the LLM reader by reinforcement learning.\nEvaluation is conducted on downstream tasks, open-domain QA and multiple-choice\nQA. Experiments results show consistent performance improvement, indicating\nthat our framework is proven effective and scalable, and brings a new framework\nfor retrieval-augmented LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1\">Xinbei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-powered Data Augmentation for Enhanced Cross-lingual Performance. (arXiv:2305.14288v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14288","description":"<p>This paper explores the potential of leveraging Large Language Models (LLMs)\nfor data augmentation in multilingual commonsense reasoning datasets where the\navailable training data is extremely limited. To achieve this, we utilise\nseveral LLMs, namely Dolly-v2, StableVicuna, ChatGPT, and GPT-4, to augment\nthree datasets: XCOPA, XWinograd, and XStoryCloze. Subsequently, we evaluate\nthe effectiveness of fine-tuning smaller multilingual models, mBERT and XLMR,\nusing the synthesised data. We compare the performance of training with data\ngenerated in English and target languages, as well as translated\nEnglish-generated data, revealing the overall advantages of incorporating data\ngenerated by LLMs, e.g. a notable 13.4 accuracy score improvement for the best\ncase. Furthermore, we conduct a human evaluation by asking native speakers to\nassess the naturalness and logical coherence of the generated examples across\ndifferent languages. The results of the evaluation indicate that LLMs such as\nChatGPT and GPT-4 excel at producing natural and coherent text in most\nlanguages, however, they struggle to generate meaningful text in certain\nlanguages like Tamil. We also observe that ChatGPT falls short in generating\nplausible alternatives compared to the original dataset, whereas examples from\nGPT-4 exhibit competitive logical consistency.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Whitehouse_C/0/1/0/all/0/1\">Chenxi Whitehouse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1\">Monojit Choudhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aji_A/0/1/0/all/0/1\">Alham Fikri Aji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TalkUp: Paving the Way for Understanding Empowering Language. (arXiv:2305.14326v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14326","description":"<p>Empowering language is important in many real-world contexts, from education\nto workplace dynamics to healthcare. Though language technologies are growing\nmore prevalent in these contexts, empowerment has seldom been studied in NLP,\nand moreover, it is inherently challenging to operationalize because of its\nimplicit nature. This work builds from linguistic and social psychology\nliterature to explore what characterizes empowering language. We then\ncrowdsource a novel dataset of Reddit posts labeled for empowerment, reasons\nwhy these posts are empowering to readers, and the social relationships between\nposters and readers. Our preliminary analyses show that this dataset, which we\ncall TalkUp, can be used to train language models that capture empowering and\ndisempowering language. More broadly, TalkUp provides an avenue to explore\nimplication, presuppositions, and how social context influences the meaning of\nlanguage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Njoo_L/0/1/0/all/0/1\">Lucille Njoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1\">Chan Young Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stappart_O/0/1/0/all/0/1\">Octavia Stappart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thielk_M/0/1/0/all/0/1\">Marvin Thielk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1\">Yi Chu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1\">Yulia Tsvetkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Model Selection with Large Language Models for Reasoning. (arXiv:2305.14333v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14333","description":"<p>Chain-of-Thought (CoT) and Program-Aided Language Models (PAL) represent two\ndistinct reasoning methods, each with its own strengths. CoT employs natural\nlanguage, offering flexibility and interpretability, while PAL utilizes\nprogramming language, yielding more structured and rigorous logic. We introduce\na model selection method to combine the best of both worlds by employing a\nlarge language model (LLM) to dynamically select between them. Our theoretical\nanalysis underscores the feasibility of this method, which is further\ncorroborated by empirical results. Our proposed method demonstrates significant\nperformance improvements across eight reasoning datasets with Codex, ChatGPT,\nand GPT-4. Additionally, our method is complementary to self-consistency; when\nintegrated, it can further enhance performance while significantly reducing\ncomputation costs. Moreover, we achieve new state-of-the-art results on GSM8K\nand SVAMP, with respective accuracies of 96.8% and 93.7%. Our code, data and\nprompts are available at https://github.com/XuZhao0/Model-Selection-Reasoning\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">James Xu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1\">Kenji Kawaguchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junxian He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1\">Michael Qizhe Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA. (arXiv:2305.14458v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14458","description":"<p>Large language models (e.g., GPT-4) are uniquely capable of producing highly\nrated text simplification, yet current human evaluation methods fail to provide\na clear understanding of systems' specific strengths and weaknesses. To address\nthis limitation, we introduce SALSA, an edit-based human annotation framework\nthat enables holistic and fine-grained text simplification evaluation. We\ndevelop twenty one linguistically grounded edit types, covering the full\nspectrum of success and failure across dimensions of conceptual, syntactic and\nlexical simplicity. Using SALSA, we collect 19K edit annotations on 840\nsimplifications, revealing discrepancies in the distribution of simplification\nstrategies performed by fine-tuned models, prompted LLMs and humans, and find\nGPT-3.5 performs more quality edits than humans, but still exhibits frequent\nerrors. Using our fine-grained annotations, we develop LENS-SALSA, a\nreference-free automatic simplification metric, trained to predict sentence-\nand word-level quality simultaneously. Additionally, we introduce word-level\nquality estimation for simplification and report promising baseline results.\nOur data, new metric, and annotation toolkit are available at\nhttps://salsa-eval.com.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Heineman_D/0/1/0/all/0/1\">David Heineman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Y/0/1/0/all/0/1\">Yao Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Maddela_M/0/1/0/all/0/1\">Mounica Maddela</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Wei Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sociocultural Norm Similarities and Differences via Situational Alignment and Explainable Textual Entailment. (arXiv:2305.14492v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14492","description":"<p>Designing systems that can reason across cultures requires that they are\ngrounded in the norms of the contexts in which they operate. However, current\nresearch on developing computational models of social norms has primarily\nfocused on American society. Here, we propose a novel approach to discover and\ncompare descriptive social norms across Chinese and American cultures. We\ndemonstrate our approach by leveraging discussions on a Chinese Q&amp;A platform\n(Zhihu) and the existing SocialChemistry dataset as proxies for contrasting\ncultural axes, align social situations cross-culturally, and extract social\nnorms from texts using in-context learning. Embedding Chain-of-Thought\nprompting in a human-AI collaborative framework, we build a high-quality\ndataset of 3,069 social norms aligned with social situations across Chinese and\nAmerican cultures alongside corresponding free-text explanations. To test the\nability of models to reason about social norms across cultures, we introduce\nthe task of explainable social norm entailment, showing that existing models\nunder 3B parameters have significant room for improvement in both automatic and\nhuman evaluation. Further analysis of cross-cultural norm differences based on\nour dataset shows empirical alignment with the social orientations framework,\nrevealing several situational and descriptive nuances in norms across these\ncultures.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+CH_Wang_S/0/1/0/all/0/1\">Sky CH-Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saakyan_A/0/1/0/all/0/1\">Arkadiy Saakyan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_O/0/1/0/all/0/1\">Oliver Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1\">Smaranda Muresan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NAIL: Lexical Retrieval Indices with Efficient Non-Autoregressive Decoders. (arXiv:2305.14499v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14499","description":"<p>Neural document rerankers are extremely effective in terms of accuracy.\nHowever, the best models require dedicated hardware for serving, which is\ncostly and often not feasible. To avoid this serving-time requirement, we\npresent a method of capturing up to 86% of the gains of a Transformer\ncross-attention model with a lexicalized scoring function that only requires\n10-6% of the Transformer's FLOPs per document and can be served using commodity\nCPUs. When combined with a BM25 retriever, this approach matches the quality of\na state-of-the art dual encoder retriever, that still requires an accelerator\nfor query encoding. We introduce NAIL (Non-Autoregressive Indexing with\nLanguage models) as a model architecture that is compatible with recent\nencoder-decoder and decoder-only large language models, such as T5, GPT-3 and\nPaLM. This model architecture can leverage existing pre-trained checkpoints and\ncan be fine-tuned for efficiently constructing document representations that do\nnot require neural processing of queries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Soares_L/0/1/0/all/0/1\">Livio Baldini Soares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gillick_D/0/1/0/all/0/1\">Daniel Gillick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cole_J/0/1/0/all/0/1\">Jeremy R. Cole</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwiatkowski_T/0/1/0/all/0/1\">Tom Kwiatkowski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MathDial: A Dialogue Tutoring Dataset with Rich Pedagogical Properties Grounded in Math Reasoning Problems. (arXiv:2305.14536v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14536","description":"<p>While automatic dialogue tutors hold great potential in making education\npersonalized and more accessible, research on such systems has been hampered by\na lack of sufficiently large and high-quality datasets. Collecting such\ndatasets remains challenging, as recording tutoring sessions raises privacy\nconcerns and crowdsourcing leads to insufficient data quality. To address this,\nwe propose a framework to generate such dialogues by pairing human teachers\nwith a Large Language Model (LLM) prompted to represent common student errors.\nWe describe how we use this framework to collect MathDial, a dataset of 3k\none-to-one teacher-student tutoring dialogues grounded in multi-step math\nreasoning problems. While models like GPT-3 are good problem solvers, they fail\nat tutoring because they generate factually incorrect feedback or are prone to\nrevealing solutions to students too early. To overcome this, we let teachers\nprovide learning opportunities to students by guiding them using various\nscaffolding questions according to a taxonomy of teacher moves. We demonstrate\nMathDial and its extensive annotations can be used to finetune models to be\nmore effective tutors (and not just solvers). We confirm this by automatic and\nhuman evaluation, notably in an interactive setting that measures the trade-off\nbetween student solving success and telling solutions. The dataset is released\npublicly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Macina_J/0/1/0/all/0/1\">Jakub Macina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Daheim_N/0/1/0/all/0/1\">Nico Daheim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Sankalan Pal Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sinha_T/0/1/0/all/0/1\">Tanmay Sinha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kapur_M/0/1/0/all/0/1\">Manu Kapur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sources of Hallucination by Large Language Models on Inference Tasks. (arXiv:2305.14552v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14552","description":"<p>Large Language Models (LLMs) are claimed to be capable of Natural Language\nInference (NLI), necessary for applied tasks like question answering and\nsummarization. We present a series of behavioral studies on several LLM\nfamilies (LLaMA, GPT-3.5, and PaLM) which probe their behavior using controlled\nexperiments. We establish two biases originating from pretraining which predict\nmuch of their behavior, and show that these are major sources of hallucination\nin generative LLMs. First, memorization at the level of sentences: we show\nthat, regardless of the premise, models falsely label NLI test samples as\nentailing when the hypothesis is attested in training data, and that entities\nare used as ``indices'' to access the memorized data. Second, statistical\npatterns of usage learned at the level of corpora: we further show a similar\neffect when the premise predicate is less frequent than that of the hypothesis\nin the training data, a bias following from previous studies. We demonstrate\nthat LLMs perform significantly worse on NLI test samples which do not conform\nto these biases than those which do, and we offer these as valuable controls\nfor future LLM evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McKenna_N/0/1/0/all/0/1\">Nick McKenna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Liang Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_M/0/1/0/all/0/1\">Mohammad Javad Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1\">Mark Johnson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steedman_M/0/1/0/all/0/1\">Mark Steedman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Parameter-Efficient Language Model Tuning with Active Learning in Low-Resource Settings. (arXiv:2305.14576v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14576","description":"<p>Pre-trained language models (PLMs) have ignited a surge in demand for\neffective fine-tuning techniques, particularly in low-resource domains and\nlanguages. Active learning (AL), a set of algorithms designed to decrease\nlabeling costs by minimizing label complexity, has shown promise in confronting\nthe labeling bottleneck. In parallel, adapter modules designed for\nparameter-efficient fine-tuning (PEFT) have demonstrated notable potential in\nlow-resource settings. However, the interplay between AL and adapter-based PEFT\nremains unexplored. We present an empirical study of PEFT behavior with AL in\nlow-resource settings for text classification tasks. Our findings affirm the\nsuperiority of PEFT over full-fine tuning (FFT) in low-resource settings and\ndemonstrate that this advantage persists in AL setups. We further examine the\nproperties of PEFT and FFT through the lens of forgetting dynamics and\ninstance-level representations, where we find that PEFT yields more stable\nrepresentations of early and middle layers compared to FFT. Our research\nunderscores the synergistic potential of AL and PEFT in low-resource settings,\npaving the way for advancements in efficient and effective fine-tuning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jukic_J/0/1/0/all/0/1\">Josip Juki&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Snajder_J/0/1/0/all/0/1\">Jan &#x160;najder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"COMET-M: Reasoning about Multiple Events in Complex Sentences. (arXiv:2305.14617v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14617","description":"<p>Understanding the speaker's intended meaning often involves drawing\ncommonsense inferences to reason about what is not stated explicitly. In\nmulti-event sentences, it requires understanding the relationships between\nevents based on contextual knowledge. We propose COMET-M (Multi-Event), an\nevent-centric commonsense model capable of generating commonsense inferences\nfor a target event within a complex sentence. COMET-M builds upon COMET\n(Bosselut et al., 2019), which excels at generating event-centric inferences\nfor simple sentences, but struggles with the complexity of multi-event\nsentences prevalent in natural text. To overcome this limitation, we curate a\nmulti-event inference dataset of 35K human-written inferences. We trained\nCOMET-M on the human-written inferences and also created baselines using\nautomatically labeled examples. Experimental results demonstrate the\nsignificant performance improvement of COMET-M over COMET in generating\nmulti-event inferences. Moreover, COMET-M successfully produces distinct\ninferences for each target event, taking the complete context into\nconsideration. COMET-M holds promise for downstream tasks involving natural\ntext such as coreference resolution, dialogue, and story understanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1\">Sahithya Ravi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_R/0/1/0/all/0/1\">Raymond Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_V/0/1/0/all/0/1\">Vered Shwartz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"You Are What You Annotate: Towards Better Models through Annotator Representations. (arXiv:2305.14663v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14663","description":"<p>Annotator disagreement is ubiquitous in natural language processing (NLP)\ntasks. There are multiple reasons for such disagreements, including the\nsubjectivity of the task, difficult cases, unclear guidelines, and so on.\nRather than simply aggregating labels to obtain data annotations, we instead\ntry to directly model the diverse perspectives of the annotators, and\nexplicitly account for annotators' idiosyncrasies in the modeling process by\ncreating representations for each annotator (annotator embeddings) and also\ntheir annotations (annotation embeddings). In addition, we propose TID-8, The\nInherent Disagreement - 8 dataset, a benchmark that consists of eight existing\nlanguage understanding datasets that have inherent annotator disagreement. We\ntest our approach on TID-8 and show that our approach helps models learn\nsignificantly better from disagreements on six different datasets in TID-8\nwhile increasing model size by fewer than 1% parameters. By capturing the\nunique tendencies and subjectivity of individual annotators through embeddings,\nour representations prime AI models to be inclusive of diverse viewpoints.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_N/0/1/0/all/0/1\">Naihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinliang Frederick Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Winston Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gender Biases in Automatic Evaluation Metrics for Image Captioning. (arXiv:2305.14711v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14711","description":"<p>Model-based evaluation metrics (e.g., CLIPScore and GPTScore) have\ndemonstrated decent correlations with human judgments in various language\ngeneration tasks. However, their impact on fairness remains largely unexplored.\nIt is widely recognized that pretrained models can inadvertently encode\nsocietal biases, thus employing these models for evaluation purposes may\ninadvertently perpetuate and amplify biases. For example, an evaluation metric\nmay favor the caption \"a woman is calculating an account book\" over \"a man is\ncalculating an account book,\" even if the image only shows male accountants. In\nthis paper, we conduct a systematic study of gender biases in model-based\nautomatic evaluation metrics for image captioning tasks. We start by curating a\ndataset comprising profession, activity, and object concepts associated with\nstereotypical gender associations. Then, we demonstrate the negative\nconsequences of using these biased metrics, including the inability to\ndifferentiate between biased and unbiased generations, as well as the\npropagation of biases to generation models through reinforcement learning.\nFinally, we present a simple and effective way to mitigate the metric bias\nwithout hurting the correlations with human judgments. Our dataset and\nframework lay the foundation for understanding the potential harm of\nmodel-based evaluation metrics, and facilitate future works to develop more\ninclusive evaluation metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Haoyi Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1\">Zi-Yi Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1\">Tianlu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1\">Asli Celikyilmaz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection. (arXiv:2305.14735v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14735","description":"<p>The impact of AI models on marginalized communities has traditionally been\nmeasured by identifying performance differences between specified demographic\nsubgroups. Though this approach aims to center vulnerable groups, it risks\nobscuring patterns of harm faced by intersectional subgroups or shared across\nmultiple groups. To address this, we draw on theories of marginalization from\ndisability studies and related disciplines, which state that people farther\nfrom the norm face greater adversity, to consider the \"margins\" in the domain\nof toxicity detection. We operationalize the \"margins\" of a dataset by\nemploying outlier detection to identify text about people with demographic\nattributes distant from the \"norm\". We find that model performance is\nconsistently worse for demographic outliers, with mean squared error (MSE)\nbetween outliers and non-outliers up to 70.4% worse across toxicity types. It\nis also worse for text outliers, with a MSE up to 68.4% higher for outliers\nthan non-outliers. We also find text and demographic outliers to be\nparticularly susceptible to errors in the classification of severe toxicity and\nidentity attacks. Compared to analysis of disparities using traditional\ndemographic breakdowns, we find that our outlier analysis frequently surfaces\ngreater harms faced by a larger, more intersectional group, which suggests that\noutlier analysis is particularly beneficial for identifying harms against those\ngroups.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raman_V/0/1/0/all/0/1\">Vyoma Raman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fleisig_E/0/1/0/all/0/1\">Eve Fleisig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Klein_D/0/1/0/all/0/1\">Dan Klein</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ECHo: A Visio-Linguistic Dataset for Event Causality Inference via Human-Centric Reasoning. (arXiv:2305.14740v2 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2305.14740","description":"<p>We introduce ECHo (Event Causality Inference via Human-Centric Reasoning), a\ndiagnostic dataset of event causality inference grounded in visio-linguistic\nsocial scenarios. ECHo employs real-world human-centric deductive information\nbuilding on a television crime drama. ECHo requires the Theory-of-Mind (ToM)\nability to understand and reason about social interactions based on multimodal\ninformation. Using ECHo, we propose a unified Chain-of-Thought (CoT) framework\nto assess the reasoning capability of current AI systems. Our ToM-enhanced CoT\npipeline accommodates various large foundation models in both zero-shot and\nfew-shot visio-linguistic reasoning. We use this framework to scrutinize recent\nlarge foundation models such as InstructGPT and MiniGPT-4 on three diagnostic\nhuman-centric tasks. Further analysis demonstrates ECHo as a challenging\ndataset to expose imperfections and inconsistencies in reasoning. Our data and\ncode are publicly available at https://github.com/YuxiXie/ECHo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yuxi Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guanzhen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1\">Min-Yen Kan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting. (arXiv:2305.14755v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14755","description":"<p>Most existing stylistic text rewriting methods and evaluation metrics operate\non a sentence level, but ignoring the broader context of the text can lead to\npreferring generic, ambiguous, and incoherent rewrites. In this paper, we\ninvestigate integrating the preceding textual context into both the\n$\\textit{rewriting}$ and $\\textit{evaluation}$ stages of stylistic text\nrewriting, and introduce a new composite contextual evaluation metric\n$\\texttt{CtxSimFit}$ that combines similarity to the original sentence with\ncontextual cohesiveness. We comparatively evaluate non-contextual and\ncontextual rewrites in formality, toxicity, and sentiment transfer tasks. Our\nexperiments show that humans significantly prefer contextual rewrites as more\nfitting and natural over non-contextual ones, yet existing sentence-level\nautomatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences\n($\\rho$=0--0.3). In contrast, human preferences are much better reflected by\nboth our novel $\\texttt{CtxSimFit}$ ($\\rho$=0.7--0.9) as well as proposed\ncontext-infused versions of common metrics ($\\rho$=0.4--0.7). Overall, our\nfindings highlight the importance of integrating context into the generation\nand especially the evaluation stages of stylistic text rewriting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yerukola_A/0/1/0/all/0/1\">Akhila Yerukola</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xuhui Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clark_E/0/1/0/all/0/1\">Elizabeth Clark</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1\">Maarten Sap</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net Estimation and Optimization. (arXiv:2305.14760v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14760","description":"<p>Pretrained language models have achieved remarkable success in natural\nlanguage understanding. However, fine-tuning pretrained models on limited\ntraining data tends to overfit and thus diminish performance. This paper\npresents Bi-Drop, a fine-tuning strategy that selectively updates model\nparameters using gradients from various sub-nets dynamically generated by\ndropout. The sub-net estimation of Bi-Drop is performed in an in-batch manner,\nso it overcomes the problem of hysteresis in sub-net updating, which is\npossessed by previous methods that perform asynchronous sub-net estimation.\nAlso, Bi-Drop needs only one mini-batch to estimate the sub-net so it achieves\nhigher utility of training data. Experiments on the GLUE benchmark demonstrate\nthat Bi-Drop consistently outperforms previous fine-tuning methods.\nFurthermore, empirical results also show that Bi-Drop exhibits excellent\ngeneralization ability and robustness for domain transfer, data imbalance, and\nlow-resource scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tong_S/0/1/0/all/0/1\">Shoujie Tong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Heming Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1\">Damai Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Runxin Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1\">Binghuai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yunbo Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Debiasing Made State-of-the-art: Revisiting the Simple Seed-based Weak Supervision for Text Classification. (arXiv:2305.14794v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14794","description":"<p>Recent advances in weakly supervised text classification mostly focus on\ndesigning sophisticated methods to turn high-level human heuristics into\nquality pseudo-labels. In this paper, we revisit the seed matching-based\nmethod, which is arguably the simplest way to generate pseudo-labels, and show\nthat its power was greatly underestimated. We show that the limited performance\nof seed matching is largely due to the label bias injected by the simple\nseed-match rule, which prevents the classifier from learning reliable\nconfidence for selecting high-quality pseudo-labels. Interestingly, simply\ndeleting the seed words present in the matched input texts can mitigate the\nlabel bias and help learn better confidence. Subsequently, the performance\nachieved by seed matching can be improved significantly, making it on par with\nor even better than the state-of-the-art. Furthermore, to handle the case when\nthe seed words are not made known, we propose to simply delete the word tokens\nin the input text randomly with a high deletion ratio. Remarkably, seed\nmatching equipped with this random deletion method can often achieve even\nbetter performance than that with seed deletion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1\">Chengyu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zihan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1\">Jingbo Shang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory. (arXiv:2305.14889v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14889","description":"<p>We address a fundamental challenge in Natural Language Generation (NLG) model\nevaluation -- the design and evaluation of evaluation metrics. Recognizing the\nlimitations of existing automatic metrics and noises from how current human\nevaluation was conducted, we propose MetricEval, a framework informed by\nmeasurement theory, the foundation of educational test design, for\nconceptualizing and evaluating the reliability and validity of NLG evaluation\nmetrics. The framework formalizes the source of measurement error and offers\nstatistical tools for evaluating evaluation metrics based on empirical data.\nWith our framework, one can quantify the uncertainty of the metrics to better\ninterpret the result. To exemplify the use of our framework in practice, we\nanalyzed a set of evaluation metrics for summarization and identified issues\nrelated to conflated validity structure in human-eval and reliability in\nLLM-based metrics. Through MetricEval, we aim to promote the design,\nevaluation, and interpretation of valid and reliable metrics to advance robust\nand effective NLG models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_Z/0/1/0/all/0/1\">Ziang Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Susu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1\">Vivian Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1\">Q. Vera Liao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Universal Self-Adaptive Prompting. (arXiv:2305.14926v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14926","description":"<p>A hallmark of modern large language models (LLMs) is their impressive general\nzero-shot and few-shot abilities, often elicited through in-context learning\n(ICL) via prompting. However, while highly coveted and being the most general,\nzero-shot performances in LLMs are still typically weaker due to the lack of\nguidance and the difficulty of applying existing automatic prompt design\nmethods in general tasks when ground-truth labels are unavailable. In this\nstudy, we address this by presenting Universal Self-Adaptive Prompting (USP),\nan automatic prompt design approach specifically tailored for zero-shot\nlearning (while compatible with few-shot). Requiring only a small amount of\nunlabeled data and an inference-only LLM, USP is highly versatile: to achieve\nuniversal prompting, USP categorizes a possible NLP task into one of the three\npossible task types and then uses a corresponding selector to select the most\nsuitable queries and zero-shot model-generated responses as\npseudo-demonstrations, thereby generalizing ICL to the zero-shot setup in a\nfully automated way. We evaluate USP with PaLM and PaLM 2 models and\ndemonstrate performances that are considerably stronger than standard zero-shot\nbaselines and often comparable to or even superior to few-shot baselines across\nmore than 40 natural language understanding, natural language generation, and\nreasoning tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_X/0/1/0/all/0/1\">Xingchen Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruoxi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nakhost_H/0/1/0/all/0/1\">Hootan Nakhost</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1\">Hanjun Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eisenschlos_J/0/1/0/all/0/1\">Julian Martin Eisenschlos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1\">Sercan O. Arik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfister_T/0/1/0/all/0/1\">Tomas Pfister</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP. (arXiv:2305.14976v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14976","description":"<p>ChatGPT's emergence heralds a transformative phase in NLP, particularly\ndemonstrated through its excellent performance on many English benchmarks.\nHowever, the model's efficacy across diverse linguistic contexts remains\nlargely uncharted territory. This work aims to bridge this knowledge gap, with\na primary focus on assessing ChatGPT's capabilities on Arabic languages and\ndialectal varieties. Our comprehensive study conducts a large-scale automated\nand human evaluation of ChatGPT, encompassing 44 distinct language\nunderstanding and generation tasks on over 60 different datasets. To our\nknowledge, this marks the first extensive performance analysis of ChatGPT's\ndeployment in Arabic NLP. Our findings indicate that, despite its remarkable\nperformance in English, ChatGPT is consistently surpassed by smaller models\nthat have undergone finetuning on Arabic. We further undertake a meticulous\ncomparison of ChatGPT and GPT-4's Modern Standard Arabic (MSA) and Dialectal\nArabic (DA), unveiling the relative shortcomings of both models in handling\nArabic dialects compared to MSA. Although we further explore and confirm the\nutility of employing GPT-4 as a potential alternative for human evaluation, our\nwork adds to a growing body of research underscoring the limitations of\nChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khondaker_M/0/1/0/all/0/1\">Md Tawkat Islam Khondaker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waheed_A/0/1/0/all/0/1\">Abdul Waheed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1\">El Moatez Billah Nagoudi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning with Language Model is Planning with World Model. (arXiv:2305.14992v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14992","description":"<p>Large language models (LLMs) have shown remarkable reasoning capabilities,\nespecially when prompted to generate intermediate reasoning steps (e.g.,\nChain-of-Thought, CoT). However, LLMs can still struggle with problems that are\neasy for humans, such as generating action plans for executing tasks in a given\nenvironment, or performing complex math, logical, and commonsense reasoning.\nThe deficiency stems from the key fact that LLMs lack an internal\n$\\textit{world model}$ to predict the world $\\textit{state}$ (e.g., environment\nstatus, intermediate variable values) and simulate long-term outcomes of\nactions. This prevents LLMs from performing deliberate planning akin to human\nbrains, which involves exploring alternative reasoning paths, anticipating\nfuture states and rewards, and iteratively refining existing reasoning steps.\nTo overcome the limitations, we propose a new LLM reasoning framework,\n$\\underline{R}$easoning vi$\\underline{a}$ $\\underline{P}$lanning\n$\\textbf{(RAP)}$. RAP repurposes the LLM as both a world model and a reasoning\nagent, and incorporates a principled planning algorithm (based on Monto Carlo\nTree Search) for strategic exploration in the vast reasoning space. During\nreasoning, the LLM (as agent) incrementally builds a reasoning tree under the\nguidance of the LLM (as world model) and task-specific rewards, and obtains a\nhigh-reward reasoning path efficiently with a proper balance between\nexploration $\\textit{vs.}$ exploitation. We apply RAP to a variety of\nchallenging reasoning problems including plan generation, math reasoning, and\nlogical inference. Empirical results on these tasks demonstrate the superiority\nof RAP over various strong baselines, including CoT and least-to-most prompting\nwith self-consistency. RAP on LLAMA-33B surpasses CoT on GPT-4 with 33%\nrelative improvement in a plan generation setting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hao_S/0/1/0/all/0/1\">Shibo Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yi Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1\">Haodi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Joshua Jiahua Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Daisy Zhe Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through Interaction with Symbolic Systems. (arXiv:2305.15017v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.15017","description":"<p>Despite outstanding performance in many tasks, language models are\nnotoriously inclined to make factual errors in tasks requiring arithmetic\ncomputation. We address this deficiency by creating Calc-X, a collection of\ndatasets that demonstrates the appropriate use of a calculator in reasoning\nchains. Calc-X is suitable for teaching language models to offload computations\nto a symbolic system. We survey and unify several existing chain-of-thought\ndatasets into a proposed format, resulting in a standard collection of over\n300,000 samples requiring arithmetic reasoning. Finally, we use the new Calc-X\ncollection to train open-source calculator-using models we call Calcformers and\nshow that these models approximately double the accuracy of generating correct\nresults compared to vanilla language model baselines. We make all Calc-X\ndatasets, source code and Calcformers models publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kadlcik_M/0/1/0/all/0/1\">Marek Kadl&#x10d;&#xed;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stefanik_M/0/1/0/all/0/1\">Michal &#x160;tef&#xe1;nik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sotolar_O/0/1/0/all/0/1\">Ond&#x159;ej Sotol&#xe1;&#x159;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinek_V/0/1/0/all/0/1\">Vlastimil Martinek</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories. (arXiv:2305.15028v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15028","description":"<p>Recently, Large Language Models (LLMs) have been serving as general-purpose\ninterfaces, posing a significant demand for comprehensive visual knowledge.\nHowever, it remains unclear how well current LLMs and their visually augmented\ncounterparts (VaLMs) can master visual commonsense knowledge. To investigate\nthis, we propose ImageNetVC, a human-annotated dataset specifically designed\nfor zero- and few-shot visual commonsense evaluation across 1,000 ImageNet\ncategories. Utilizing ImageNetVC, we benchmark the fundamental visual\ncommonsense knowledge of both unimodal LLMs and VaLMs. Furthermore, we analyze\nthe factors affecting the visual commonsense knowledge of large-scale models,\nproviding insights into the development of language models enriched with visual\ncommonsense knowledge. Our code and dataset are available at\nhttps://github.com/hemingkx/ImageNetVC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xia_H/0/1/0/all/0/1\">Heming Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1\">Qingxiu Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Jingjing Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Ziwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1\">Zhifang Sui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations. (arXiv:2305.15035v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15035","description":"<p>Large language models (LLMs) have exhibited striking in-context learning\n(ICL) ability to adapt to target tasks with a few input-output demonstrations.\nFor better ICL, different methods are proposed to select representative\ndemonstrations from existing training corpora. However, such settings are not\naligned with real-world practices, as end-users usually query LMs without\naccess to demonstration pools. In this work, we introduce Self-ICL -- a simple\nframework which bootstraps LMs' intrinsic capabilities to perform zero-shot\nICL. Given a test input, Self-ICL first prompts the model to generate\npseudo-inputs. Next, the model predicts pseudo-labels for the pseudo-inputs via\nzero-shot prompting. Finally, we perform ICL for the test input with the\npseudo-input-label pairs as demonstrations. Evaluation on 23 BIG-Bench Hard\ntasks shows Self-ICL outperforms zero-shot baselines on both average accuracy\nand head-to-head comparison. Moreover, with zero-shot chain-of-thought,\nSelf-ICL achieves results comparable to using real demonstrations.\nAdditionally, we conduct a range of analyses to validate Self-ICL's\neffectiveness and provide insights for its behaviors under different settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Lin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng-Kuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yun-Nung Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hsin-Hsi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Is GPT-4 a Good Data Analyst?. (arXiv:2305.15038v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15038","description":"<p>As large language models (LLMs) have demonstrated their powerful capabilities\nin plenty of domains and tasks, including context understanding, code\ngeneration, language generation, data storytelling, etc., many data analysts\nmay raise concerns if their jobs will be replaced by artificial intelligence\n(AI). This controversial topic has drawn great attention in public. However, we\nare still at a stage of divergent opinions without any definitive conclusion.\nMotivated by this, we raise the research question of \"is GPT-4 a good data\nanalyst?\" in this work and aim to answer it by conducting head-to-head\ncomparative studies. In detail, we regard GPT-4 as a data analyst to perform\nend-to-end data analysis with databases from a wide range of domains. We\npropose a framework to tackle the problems by carefully designing the prompts\nfor GPT-4 to conduct experiments. We also design several task-specific\nevaluation metrics to systematically compare the performance between several\nprofessional human data analysts and GPT-4. Experimental results show that\nGPT-4 can achieve comparable performance to humans. We also provide in-depth\ndiscussions about our results to shed light on further studies before reaching\nthe conclusion that GPT-4 can replace data analysts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1\">Liying Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingxuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1\">Lidong Bing</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models. (arXiv:2305.15064v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15064","description":"<p>Recent large language models (LLMs) are promising for making decisions in\ngrounded environments. However, LLMs frequently fail in complex decision-making\ntasks due to the misalignment between the pre-trained knowledge in LLMs and the\nactual rules in the environment. Existing methods require either costly\ngradient computation or lengthy in-context demonstrations. In this paper, we\npropose AutoPlan, an approach to guide LLM-based agents to accomplish\ninteractive decision-making tasks. AutoPlan augments the LLM prompt with a\ntask-solving plan and optimizes it through iterative experience collection and\nreflection. Our experiments show that AutoPlan, though using no in-context\ndemonstrations, achieves success rates on par with the baselines using\nhuman-written demonstrations on ALFWorld and even outperforms them by 8% on\nHotpotQA. The code is available at https://github.com/owaski/AutoPlan.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ouyang_S/0/1/0/all/0/1\">Siqi Ouyang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For Large Language Models. (arXiv:2305.15074v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15074","description":"<p>The performance of large language models (LLMs) on existing reasoning\nbenchmarks has significantly improved over the past years. In response, we\npresent JEEBench, a considerably more challenging benchmark dataset for\nevaluating the problem solving abilities of LLMs. We curate 515 challenging\npre-engineering mathematics, physics and chemistry problems from the highly\ncompetitive IIT JEE-Advanced exam. Long-horizon reasoning on top of deep\nin-domain knowledge is essential for solving problems in this benchmark. Our\nevaluation on various open-source and proprietary models reveals that the\nhighest performance, even after using techniques like self-consistency,\nself-refinement and chain-of-thought prompting, is less than 40%. The typical\nfailure modes of GPT-4, the best model, are errors in algebraic manipulation,\ndifficulty in grounding abstract concepts into mathematical equations\naccurately and failure in retrieving relevant domain-specific concepts. We also\nobserve that by mere prompting, GPT-4 is unable to assess risk introduced by\nnegative marking for incorrect answers. For this, we develop a post-hoc\nconfidence-thresholding method over self-consistency, which enables effective\nresponse selection. We hope that our challenging benchmark will guide future\nre-search in problem-solving using LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_D/0/1/0/all/0/1\">Daman Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_H/0/1/0/all/0/1\">Himanshu Gaurav Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1\">Mausam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Meta-Learning Online Adaptation of Language Models. (arXiv:2305.15076v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15076","description":"<p>Large language models encode impressively broad world knowledge in their\nparameters. However, the knowledge in static language models falls out of date,\nlimiting the model's effective \"shelf life.\" While online fine-tuning can\nreduce this degradation, we find that naively fine-tuning on a stream of\ndocuments leads to a low level of information uptake. We hypothesize that\nonline fine-tuning does not sufficiently attend to important information. That\nis, the gradient signal from important tokens representing factual information\nis drowned out by the gradient from inherently noisy tokens, suggesting that a\ndynamic, context-aware learning rate may be beneficial. We therefore propose\nlearning which tokens to upweight. We meta-train a small, autoregressive model\nto reweight the language modeling loss for each token during online\nfine-tuning, with the objective of maximizing the out-of-date base\nquestion-answering model's ability to answer questions about a document after a\nsingle weighted gradient step. We call this approach Context-aware Meta-learned\nLoss Scaling (CaMeLS). Across three different distributions of documents, our\nexperiments find that CaMeLS provides substantially improved information uptake\non streams of thousands of documents compared with standard fine-tuning and\nbaseline heuristics for reweighting token losses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_N/0/1/0/all/0/1\">Nathan Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mitchell_E/0/1/0/all/0/1\">Eric Mitchell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1\">Christopher D. Manning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Retrieval-Augmented Large Language Models with Iterative Retrieval-Generation Synergy. (arXiv:2305.15294v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.15294","description":"<p>Large language models are powerful text processors and reasoners, but are\nstill subject to limitations including outdated knowledge and hallucinations,\nwhich necessitates connecting them to the world. Retrieval-augmented large\nlanguage models have raised extensive attention for grounding model generation\non external knowledge. However, retrievers struggle to capture relevance,\nespecially for queries with complex information needs. Recent work has proposed\nto improve relevance modeling by having large language models actively involved\nin retrieval, i.e., to improve retrieval with generation. In this paper, we\nshow that strong performance can be achieved by a method we call Iter-RetGen,\nwhich synergizes retrieval and generation in an iterative manner. A model\noutput shows what might be needed to finish a task, and thus provides an\ninformative context for retrieving more relevant knowledge which in turn helps\ngenerate a better output in the next iteration. Compared with recent work which\ninterleaves retrieval with generation when producing an output, Iter-RetGen\nprocesses all retrieved knowledge as a whole and largely preserves the\nflexibility in generation without structural constraints. We evaluate\nIter-RetGen on multi-hop question answering, fact verification, and commonsense\nreasoning, and show that it can flexibly leverage parametric knowledge and\nnon-parametric knowledge, and is superior to or competitive with\nstate-of-the-art retrieval-augmented baselines while causing fewer overheads of\nretrieval and generation. We can further improve performance via\ngeneration-augmented retrieval adaptation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1\">Zhihong Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_Y/0/1/0/all/0/1\">Yeyun Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yelong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1\">Nan Duan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model. (arXiv:2305.16340v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16340","description":"<p>Transformers have shown dominant performance across a range of domains\nincluding language and vision. However, their computational cost grows\nquadratically with the sequence length, making their usage prohibitive for\nresource-constrained applications. To counter this, our approach is to divide\nthe whole sequence into segments and apply attention to the individual\nsegments. We propose a segmented recurrent transformer (SRformer) that combines\nsegmented (local) attention with recurrent attention. The loss caused by\nreducing the attention window length is compensated by aggregating information\nacross segments with recurrent attention. SRformer leverages Recurrent\nAccumulate-and-Fire (RAF) neurons' inherent memory to update the cumulative\nproduct of keys and values. The segmented attention and lightweight RAF neurons\nensure the efficiency of the proposed transformer. Such an approach leads to\nmodels with sequential processing capability at a lower computation/memory\ncost. We apply the proposed method to T5 and BART transformers. The modified\nmodels are tested on summarization datasets including CNN-dailymail, XSUM,\nArXiv, and MediaSUM. Notably, using segmented inputs of varied sizes, the\nproposed model achieves $6-22\\%$ higher ROUGE1 scores than a segmented\ntransformer and outperforms other recurrent transformer approaches.\nFurthermore, compared to full attention, the proposed model reduces the\ncomputational complexity of cross attention by around $40\\%$.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1\">Yinghan Long</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1\">Sayeed Shafayet Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1\">Kaushik Roy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Not wacky vs. definitely wacky: A study of scalar adverbs in pretrained language models. (arXiv:2305.16426v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.16426","description":"<p>Vector space models of word meaning all share the assumption that words\noccurring in similar contexts have similar meanings. In such models, words that\nare similar in their topical associations but differ in their logical force\ntend to emerge as semantically close, creating well-known challenges for NLP\napplications that involve logical reasoning. Modern pretrained language models,\nsuch as BERT, RoBERTa and GPT-3 hold the promise of performing better on\nlogical tasks than classic static word embeddings. However, reports are mixed\nabout their success. In the current paper, we advance this discussion through a\nsystematic study of scalar adverbs, an under-explored class of words with\nstrong logical force. Using three different tasks, involving both naturalistic\nsocial media data and constructed examples, we investigate the extent to which\nBERT, RoBERTa, GPT-2 and GPT-3 exhibit general, human-like, knowledge of these\ncommon words. We ask: 1) Do the models distinguish amongst the three semantic\ncategories of MODALITY, FREQUENCY and DEGREE? 2) Do they have implicit\nrepresentations of full scales from maximally negative to maximally positive?\n3) How do word frequency and contextual factors impact model performance? We\nfind that despite capturing some aspects of logical meaning, the models fall\nfar short of human performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lorge_I/0/1/0/all/0/1\">Isabelle Lorge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pierrehumbert_J/0/1/0/all/0/1\">Janet Pierrehumbert</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LaFTer: Label-Free Tuning of Zero-shot Classifier using Language and Unlabeled Image Collections. (arXiv:2305.18287v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2305.18287","description":"<p>Recently, large-scale pre-trained Vision and Language (VL) models have set a\nnew state-of-the-art (SOTA) in zero-shot visual classification enabling\nopen-vocabulary recognition of potentially unlimited set of categories defined\nas simple language prompts. However, despite these great advances, the\nperformance of these zeroshot classifiers still falls short of the results of\ndedicated (closed category set) classifiers trained with supervised fine\ntuning. In this paper we show, for the first time, how to reduce this gap\nwithout any labels and without any paired VL data, using an unlabeled image\ncollection and a set of texts auto-generated using a Large Language Model (LLM)\ndescribing the categories of interest and effectively substituting labeled\nvisual instances of those categories. Using our label-free approach, we are\nable to attain significant performance improvements over the zero-shot\nperformance of the base VL model and other contemporary methods and baselines\non a wide variety of datasets, demonstrating absolute improvement of up to\n11.7% (3.8% on average) in the label-free setting. Moreover, despite our\napproach being label-free, we observe 1.3% average gains over leading few-shot\nprompting baselines that do use 5-shot supervision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mirza_M/0/1/0/all/0/1\">M. Jehanzeb Mirza</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karlinsky_L/0/1/0/all/0/1\">Leonid Karlinsky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1\">Wei Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kozinski_M/0/1/0/all/0/1\">Mateusz Kozinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Possegger_H/0/1/0/all/0/1\">Horst Possegger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1\">Rogerio Feris</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bischof_H/0/1/0/all/0/1\">Horst Bischof</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs Can Understand Encrypted Prompt: Towards Privacy-Computing Friendly Transformers. (arXiv:2305.18396v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2305.18396","description":"<p>The community explored to build private inference frameworks for\ntransformer-based large language models (LLMs) in a server-client setting,\nwhere the server holds the model parameters and the client inputs its private\ndata (or prompt) for inference. However, these frameworks impose significant\noverhead when the private inputs are forward propagated through the original\nLLMs. In this paper, we show that substituting the computation- and\ncommunication-heavy operators in the transformer architecture with\nprivacy-computing friendly approximations can greatly reduce the private\ninference costs while incurring very minor impact on model performance.\nCompared to state-of-the-art Iron (NeurIPS 2022), our privacy-computing\nfriendly model inference pipeline achieves a $5\\times$ acceleration in\ncomputation and an 80% reduction in communication overhead, while retaining\nnearly identical accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xuanqi Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhuotao Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese Medical Exam Dataset. (arXiv:2306.03030v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03030","description":"<p>Recent advancements in large language models (LLMs) have transformed the\nfield of question answering (QA). However, evaluating LLMs in the medical field\nis challenging due to the lack of standardized and comprehensive datasets. To\naddress this gap, we introduce CMExam, sourced from the Chinese National\nMedical Licensing Examination. CMExam consists of 60K+ multiple-choice\nquestions for standardized and objective evaluations, as well as solution\nexplanations for model reasoning evaluation in an open-ended manner. For\nin-depth analyses of LLMs, we invited medical professionals to label five\nadditional question-wise annotations, including disease groups, clinical\ndepartments, medical disciplines, areas of competency, and question difficulty\nlevels. Alongside the dataset, we further conducted thorough experiments with\nrepresentative LLMs and QA algorithms on CMExam. The results show that GPT-4\nhad the best accuracy of 61.6% and a weighted F1 score of 0.617. These results\nhighlight a great disparity when compared to human accuracy, which stood at\n71.6%. For explanation tasks, while LLMs could generate relevant reasoning and\ndemonstrate improved performance after finetuning, they fall short of a desired\nstandard, indicating ample room for improvement. To the best of our knowledge,\nCMExam is the first Chinese medical exam dataset to provide comprehensive\nmedical annotations. The experiments and findings of LLM evaluation also\nprovide valuable insights into the challenges and potential solutions in\ndeveloping Chinese medical QA systems and LLM evaluation pipelines. The dataset\nand relevant code are available at https://github.com/williamliujl/CMExam.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Junling Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1\">Peilin Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yining Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_D/0/1/0/all/0/1\">Dading Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tian_Z/0/1/0/all/0/1\">Zhongyu Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Andrew Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Helin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1\">Chenyu You</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zhenhua Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1\">Lei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Michael Lingzhi Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models. (arXiv:2306.06815v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2306.06815","description":"<p>Large Language Models (LLMs) are progressively being utilized as machine\nlearning services and interface tools for various applications. However, the\nsecurity implications of LLMs, particularly in relation to adversarial and\nTrojan attacks, remain insufficiently examined. In this paper, we propose\nTrojLLM, an automatic and black-box framework to effectively generate universal\nand stealthy triggers. When these triggers are incorporated into the input\ndata, the LLMs' outputs can be maliciously manipulated. Moreover, the framework\nalso supports embedding Trojans within discrete prompts, enhancing the overall\neffectiveness and precision of the triggers' attacks. Specifically, we propose\na trigger discovery algorithm for generating universal triggers for various\ninputs by querying victim LLM-based APIs using few-shot data samples.\nFurthermore, we introduce a novel progressive Trojan poisoning algorithm\ndesigned to generate poisoned prompts that retain efficacy and transferability\nacross a diverse range of models. Our experiments and results demonstrate\nTrojLLM's capacity to effectively insert Trojans into text prompts in\nreal-world black-box LLM APIs including GPT-3.5 and GPT-4, while maintaining\nexceptional performance on clean test sets. Our work sheds light on the\npotential security risks in current models and offers a potential defensive\napproach. The source code of TrojLLM is available at\nhttps://github.com/UCF-ML-Research/TrojLLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1\">Jiaqi Xue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1\">Mengxin Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_T/0/1/0/all/0/1\">Ting Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yilin Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yepeng Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boloni_L/0/1/0/all/0/1\">Ladislau Boloni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lou_Q/0/1/0/all/0/1\">Qian Lou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning. (arXiv:2306.13089v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.13089","description":"<p>Molecule property prediction has gained significant attention in recent\nyears. The main bottleneck is the label insufficiency caused by expensive lab\nexperiments. In order to alleviate this issue and to better leverage textual\nknowledge for tasks, this study investigates the feasibility of employing\nnatural language instructions to accomplish molecule-related tasks in a\nzero-shot setting. We discover that existing molecule-text models perform\npoorly in this setting due to inadequate treatment of instructions and limited\ncapacity for graphs. To overcome these issues, we propose GIMLET, which unifies\nlanguage models for both graph and text data. By adopting generalized position\nembedding, our model is extended to encode both graph structures and\ninstruction text without additional graph encoding modules. GIMLET also\ndecouples encoding of the graph from tasks instructions in the attention\nmechanism, enhancing the generalization of graph features across novel tasks.\nWe construct a dataset consisting of more than two thousand molecule tasks with\ncorresponding instructions derived from task descriptions. We pretrain GIMLET\non the molecule tasks along with instructions, enabling the model to transfer\neffectively to a broad range of tasks. Experimental results demonstrate that\nGIMLET significantly outperforms molecule-text baselines in instruction-based\nzero-shot learning, even achieving closed results to supervised GNN models on\ntasks such as toxcast and muv.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Haiteng Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shengchao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1\">Chang Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Hannan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jie Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhi-Hong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Classifying Crime Types using Judgment Documents from Social Media. (arXiv:2306.17020v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.17020","description":"<p>The task of determining crime types based on criminal behavior facts has\nbecome a very important and meaningful task in social science. But the problem\nfacing the field now is that the data samples themselves are unevenly\ndistributed, due to the nature of the crime itself. At the same time, data sets\nin the judicial field are less publicly available, and it is not practical to\nproduce large data sets for direct training. This article proposes a new\ntraining model to solve this problem through NLP processing methods. We first\npropose a Crime Fact Data Preprocessing Module (CFDPM), which can balance the\ndefects of uneven data set distribution by generating new samples. Then we use\na large open source dataset (CAIL-big) as our pretraining dataset and a small\ndataset collected by ourselves for Fine-tuning, giving it good generalization\nability to unfamiliar small datasets. At the same time, we use the improved\nBert model with dynamic masking to improve the model. Experiments show that the\nproposed method achieves state-of-the-art results on the present dataset. At\nthe same time, the effectiveness of module CFDPM is proved by experiments. This\narticle provides a valuable methodology contribution for classifying social\nscience texts such as criminal behaviors. Extensive experiments on public\nbenchmarks show that the proposed method achieves new state-of-the-art results.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1\">Haoxuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zeyu He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_M/0/1/0/all/0/1\">Mengfan Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_S/0/1/0/all/0/1\">Songning Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1\">Ziqiang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yifan Peng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Query Reformulation for Conversational Search. (arXiv:2307.09384v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2307.09384","description":"<p>As the popularity of voice assistants continues to surge, conversational\nsearch has gained increased attention in Information Retrieval. However, data\nsparsity issues in conversational search significantly hinder the progress of\nsupervised conversational search methods. Consequently, researchers are\nfocusing more on zero-shot conversational search approaches. Nevertheless,\nexisting zero-shot methods face three primary limitations: they are not\nuniversally applicable to all retrievers, their effectiveness lacks sufficient\nexplainability, and they struggle to resolve common conversational ambiguities\ncaused by omission. To address these limitations, we introduce a novel\nZero-shot Query Reformulation (ZeQR) framework that reformulates queries based\non previous dialogue contexts without requiring supervision from conversational\nsearch data. Specifically, our framework utilizes language models designed for\nmachine reading comprehension tasks to explicitly resolve two common\nambiguities: coreference and omission, in raw queries. In comparison to\nexisting zero-shot methods, our approach is universally applicable to any\nretriever without additional adaptation or indexing. It also provides greater\nexplainability and effectively enhances query intent understanding because\nambiguities are explicitly and proactively resolved. Through extensive\nexperiments on four TREC conversational datasets, we demonstrate the\neffectiveness of our method, which consistently outperforms state-of-the-art\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dayu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hui Fang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Topics, Authors, and Networks in Large Language Model Research: Trends from a Survey of 17K arXiv Papers. (arXiv:2307.10700v2 [cs.DL] UPDATED)","link":"http://arxiv.org/abs/2307.10700","description":"<p>Large language model (LLM) research is dramatically impacting society, making\nit essential to understand the topics and values it prioritizes, the authors\nand institutions driving it, and its networks of collaboration. Due to the\nrecent growth of the field, many of these fundamental attributes lack\nsystematic description. We gather, annotate, and analyze a new dataset of\n16,979 LLM-related arXiv papers, focusing on changes in 2023 vs. 2018-2022. We\nshow that LLM research increasingly focuses on societal impacts: the Computers\nand Society sub-arXiv has seen 20x growth in its proportion of LLM-related\npapers in 2023. This change is driven in part by an influx of new authors: a\nmajority of 2023 papers are first-authored by researchers who have not\npreviously written an LLM-related paper, and these papers focus particularly on\napplications and societal considerations. While a handful of companies hold\noutsize influence, academia publishes a much larger fraction of papers than\nindustry overall, and this gap widens in 2023. LLM research is also being\nshaped by social dynamics: there are gender and academic/industry differences\nin the topics authors prioritize, and a stark U.S./China schism in the\ncollaboration network. Overall, our analysis documents how LLM research both\nshapes and is shaped by society, attesting to the necessity of sociotechnical\nlenses; we discuss implications for researchers and policymakers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Movva_R/0/1/0/all/0/1\">Rajiv Movva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Balachandar_S/0/1/0/all/0/1\">Sidhika Balachandar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1\">Kenny Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agostini_G/0/1/0/all/0/1\">Gabriel Agostini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_N/0/1/0/all/0/1\">Nikhil Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pierson_E/0/1/0/all/0/1\">Emma Pierson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trie-NLG: Trie Context Augmentation to Improve Personalized Query Auto-Completion for Short and Unseen Prefixes. (arXiv:2307.15455v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.15455","description":"<p>Query auto-completion (QAC) aims to suggest plausible completions for a given\nquery prefix. Traditionally, QAC systems have leveraged tries curated from\nhistorical query logs to suggest most popular completions. In this context,\nthere are two specific scenarios that are difficult to handle for any QAC\nsystem: short prefixes (which are inherently ambiguous) and unseen prefixes.\nRecently, personalized Natural Language Generation (NLG) models have been\nproposed to leverage previous session queries as context for addressing these\ntwo challenges. However, such NLG models suffer from two drawbacks: (1) some of\nthe previous session queries could be noisy and irrelevant to the user intent\nfor the current prefix, and (2) NLG models cannot directly incorporate\nhistorical query popularity. This motivates us to propose a novel NLG model for\nQAC, Trie-NLG, which jointly leverages popularity signals from trie and\npersonalization signals from previous session queries. We train the Trie-NLG\nmodel by augmenting the prefix with rich context comprising of recent session\nqueries and top trie completions. This simple modeling approach overcomes the\nlimitations of trie-based and NLG-based approaches and leads to\nstate-of-the-art performance. We evaluate the Trie-NLG model using two large\nQAC datasets. On average, our model achieves huge ~57% and ~14% boost in MRR\nover the popular trie-based lookup and the strong BART-based baseline methods,\nrespectively. We make our code publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Maurya_K/0/1/0/all/0/1\">Kaushal Kumar Maurya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1\">Maunendra Sankar Desarkar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1\">Manish Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1\">Puneet Agrawal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Baby's CoThought: Leveraging Large Language Models for Enhanced Reasoning in Compact Models. (arXiv:2308.01684v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.01684","description":"<p>Large Language Models (LLMs) demonstrate remarkable performance on a variety\nof natural language understanding (NLU) tasks, primarily due to their\nin-context learning ability. This ability could be applied to building babylike\nmodels, i.e. models at small scales, improving training efficiency. In this\npaper, we propose a \"CoThought\" pipeline, which efficiently trains smaller\n\"baby\" language models (BabyLMs) by leveraging the Chain of Thought prompting\nof LLMs. Our pipeline restructures a dataset of less than 100M in size using\nGPT-3.5-turbo, transforming it into task-oriented, human-readable texts that\nare comparable to the school texts for language learners. The BabyLM is then\npretrained on this restructured dataset in a RoBERTa fashion. In evaluations\nacross 4 benchmarks, our BabyLM outperforms the vanilla RoBERTa in 10\nlinguistic, NLU, and question-answering tasks by more than 3 points, showing a\nsuperior ability to extract contextual information. These results suggest that\ncompact LMs pretrained on small, LLM-restructured data can better understand\ntasks and achieve improved performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1\">Han Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_B/0/1/0/all/0/1\">Bolei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rugamer_D/0/1/0/all/0/1\">David R&#xfc;gamer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_E/0/1/0/all/0/1\">Ercong Nie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"End-to-End Evaluation for Low-Latency Simultaneous Speech Translation. (arXiv:2308.03415v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.03415","description":"<p>The challenge of low-latency speech translation has recently draw significant\ninterest in the research community as shown by several publications and shared\ntasks. Therefore, it is essential to evaluate these different approaches in\nrealistic scenarios. However, currently only specific aspects of the systems\nare evaluated and often it is not possible to compare different approaches.\n</p>\n<p>In this work, we propose the first framework to perform and evaluate the\nvarious aspects of low-latency speech translation under realistic conditions.\nThe evaluation is carried out in an end-to-end fashion. This includes the\nsegmentation of the audio as well as the run-time of the different components.\n</p>\n<p>Secondly, we compare different approaches to low-latency speech translation\nusing this framework. We evaluate models with the option to revise the output\nas well as methods with fixed output. Furthermore, we directly compare\nstate-of-the-art cascaded as well as end-to-end systems. Finally, the framework\nallows to automatically evaluate the translation quality as well as latency and\nalso provides a web interface to show the low-latency model outputs to the\nuser.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1\">Christian Huber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinh_T/0/1/0/all/0/1\">Tu Anh Dinh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mullov_C/0/1/0/all/0/1\">Carlos Mullov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pham_N/0/1/0/all/0/1\">Ngoc Quan Pham</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thai Binh Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Retkowski_F/0/1/0/all/0/1\">Fabian Retkowski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Constantin_S/0/1/0/all/0/1\">Stefan Constantin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ugan_E/0/1/0/all/0/1\">Enes Yavuz Ugan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Danni Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhaolin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koneru_S/0/1/0/all/0/1\">Sai Koneru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Niehues_J/0/1/0/all/0/1\">Jan Niehues</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1\">Alexander Waibel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors. (arXiv:2308.10848v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2308.10848","description":"<p>Autonomous agents empowered by Large Language Models (LLMs) have undergone\nsignificant improvements, enabling them to generalize across a broad spectrum\nof tasks. However, in real-world scenarios, cooperation among individuals is\noften required to enhance the efficiency and effectiveness of task\naccomplishment. Hence, inspired by human group dynamics, we propose a\nmulti-agent framework \\framework that can collaboratively and dynamically\nadjust its composition as a greater-than-the-sum-of-its-parts system. Our\nexperiments demonstrate that \\framework framework can effectively deploy\nmulti-agent groups that outperform a single agent. Furthermore, we delve into\nthe emergence of social behaviors among individual agents within a group during\ncollaborative task accomplishment. In view of these behaviors, we discuss some\npossible strategies to leverage positive ones and mitigate negative ones for\nimproving the collaborative potential of multi-agent groups. Our codes for\n\\framework will soon be released at\n\\url{https://github.com/OpenBMB/AgentVerse}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yusheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zuo_J/0/1/0/all/0/1\">Jingwei Zuo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1\">Chenfei Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chi-Min Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Heyang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yaxi Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hung_Y/0/1/0/all/0/1\">Yi-Hsin Hung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1\">Yujia Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1\">Ruobing Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models. (arXiv:2308.13137v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2308.13137","description":"<p>Large language models (LLMs) have revolutionized natural language processing\ntasks. However, their practical deployment is hindered by their immense memory\nand computation requirements. Although recent post-training quantization (PTQ)\nmethods are effective in reducing memory footprint and improving the\ncomputational efficiency of LLM, they hand-craft quantization parameters, which\nleads to low performance and fails to deal with extremely low-bit quantization.\nTo tackle this issue, we introduce an Omnidirectionally calibrated Quantization\n(OmniQuant) technique for LLMs, which achieves good performance in diverse\nquantization settings while maintaining the computational efficiency of PTQ by\nefficiently optimizing various quantization parameters. OmniQuant comprises two\ninnovative components including Learnable Weight Clipping (LWC) and Learnable\nEquivalent Transformation (LET). LWC modulates the extreme values of weights by\noptimizing the clipping threshold. Meanwhile, LET tackles activation outliers\nby shifting the challenge of quantization from activations to weights through a\nlearnable equivalent transformation. Operating within a differentiable\nframework using block-wise error minimization, OmniQuant can optimize the\nquantization process efficiently for both weight-only and weight-activation\nquantization. For instance, the LLaMA-2 model family with the size of 7-70B can\nbe processed with OmniQuant on a single A100-40G GPU within 1-16 hours using\n128 samples. Extensive experiments validate OmniQuant's superior performance\nacross diverse quantization configurations such as W4A4, W6A6, W4A16, W3A16,\nand W2A16. Additionally, OmniQuant demonstrates effectiveness in\ninstruction-tuned models and delivers notable improvements in inference speed\nand memory reduction on real devices. Codes and models are available at\n\\url{https://github.com/OpenGVLab/OmniQuant}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shao_W/0/1/0/all/0/1\">Wenqi Shao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mengzhao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhaoyang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Lirui Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhiqian Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1\">Kaipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Peng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"One Wide Feedforward is All You Need. (arXiv:2309.01826v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.01826","description":"<p>The Transformer architecture has two main non-embedding components: Attention\nand the Feed Forward Network (FFN). Attention captures interdependencies\nbetween words regardless of their position, while the FFN non-linearly\ntransforms each input token independently. In this work we explore the role of\nthe FFN, and find that despite taking up a significant fraction of the model's\nparameters, it is highly redundant. Concretely, we are able to substantially\nreduce the number of parameters with only a modest drop in accuracy by removing\nthe FFN on the decoder layers and sharing a single FFN across the encoder.\nFinally we scale this architecture back to its original size by increasing the\nhidden dimension of the shared FFN, achieving substantial gains in both\naccuracy and latency with respect to the original Transformer Big.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pires_T/0/1/0/all/0/1\">Telmo Pessoa Pires</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopes_A/0/1/0/all/0/1\">Ant&#xf3;nio V. Lopes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Assogba_Y/0/1/0/all/0/1\">Yannick Assogba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Setiawan_H/0/1/0/all/0/1\">Hendra Setiawan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Query-Dependent Prompt Evaluation and Optimization with Offline Inverse RL. (arXiv:2309.06553v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.06553","description":"<p>In this study, we aim to enhance the arithmetic reasoning ability of Large\nLanguage Models (LLMs) through zero-shot prompt optimization. We identify a\npreviously overlooked objective of query dependency in such optimization and\nelucidate two ensuing challenges that impede the successful and economical\ndesign of prompt optimization techniques. One primary issue is the absence of\nan effective method to evaluate prompts during inference when the golden answer\nis unavailable. Concurrently, learning via interactions with the LLMs to\nnavigate the expansive natural language prompting space proves to be\nresource-intensive. To address this, we introduce Prompt-OIRL, which harnesses\noffline inverse reinforcement learning to draw insights from offline prompting\ndemonstration data. Such data exists as by-products when diverse prompts are\nbenchmarked on open-accessible datasets. With Prompt-OIRL, the query-dependent\nprompt optimization objective is achieved by first learning an offline reward\nmodel. This model can evaluate any query-prompt pairs without accessing LLMs.\nSubsequently, a best-of-N strategy is deployed to recommend the optimal prompt.\nOur experimental evaluations across various LLM scales and arithmetic reasoning\ndatasets underscore both the efficacy and economic viability of the proposed\napproach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Hao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huyuk_A/0/1/0/all/0/1\">Alihan H&#xfc;y&#xfc;k</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1\">Mihaela van der Schaar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Text Summarization: Adapting Large Language Models Can Outperform Human Experts. (arXiv:2309.07430v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07430","description":"<p>Sifting through vast textual data and summarizing key information imposes a\nsubstantial burden on how clinicians allocate their time. Although large\nlanguage models (LLMs) have shown immense promise in natural language\nprocessing (NLP) tasks, their efficacy on a diverse range of clinical\nsummarization tasks has not yet been rigorously demonstrated. In this work, we\napply domain adaptation methods to eight LLMs, spanning six datasets and four\ndistinct clinical summarization tasks: radiology reports, patient questions,\nprogress notes, and doctor-patient dialogue. Our thorough quantitative\nassessment reveals trade-offs between models and adaptation methods in addition\nto instances where recent advances in LLMs may not improve results. Further, in\na clinical reader study with ten physicians, we show that summaries from our\nbest-adapted LLMs are preferable to human summaries in terms of completeness\nand correctness. Our ensuing qualitative analysis highlights challenges faced\nby both LLMs and human experts. Lastly, we correlate traditional quantitative\nNLP metrics with reader study scores to enhance our understanding of how these\nmetrics align with physician preferences. Our research marks the first evidence\nof LLMs outperforming human experts in clinical text summarization across\nmultiple tasks. This implies that integrating LLMs into clinical workflows\ncould alleviate documentation burden, empowering clinicians to focus more on\npersonalized patient care and the inherently human aspects of medicine.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Veen_D/0/1/0/all/0/1\">Dave Van Veen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uden_C/0/1/0/all/0/1\">Cara Van Uden</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blankemeier_L/0/1/0/all/0/1\">Louis Blankemeier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Delbrouck_J/0/1/0/all/0/1\">Jean-Benoit Delbrouck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aali_A/0/1/0/all/0/1\">Asad Aali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bluethgen_C/0/1/0/all/0/1\">Christian Bluethgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pareek_A/0/1/0/all/0/1\">Anuj Pareek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Polacin_M/0/1/0/all/0/1\">Malgorzata Polacin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collins_W/0/1/0/all/0/1\">William Collins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahuja_N/0/1/0/all/0/1\">Neera Ahuja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Langlotz_C/0/1/0/all/0/1\">Curtis P. Langlotz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hom_J/0/1/0/all/0/1\">Jason Hom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gatidis_S/0/1/0/all/0/1\">Sergios Gatidis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pauly_J/0/1/0/all/0/1\">John Pauly</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhari_A/0/1/0/all/0/1\">Akshay S. Chaudhari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Effective Disambiguation for Machine Translation with Large Language Models. (arXiv:2309.11668v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.11668","description":"<p>Resolving semantic ambiguity has long been recognised as a central challenge\nin the field of Machine Translation. Recent work on benchmarking translation\nperformance on ambiguous sentences has exposed the limitations of conventional\nNeural Machine Translation (NMT) systems, which fail to handle many such cases.\nLarge language models (LLMs) have emerged as a promising alternative,\ndemonstrating comparable performance to traditional NMT models while\nintroducing new paradigms for controlling the target outputs. In this paper, we\nstudy the capabilities of LLMs to translate \"ambiguous sentences\" - i.e. those\ncontaining highly polysemous words and/or rare word senses. We also propose two\nways to improve their disambiguation capabilities, through a) in-context\nlearning and b) fine-tuning on carefully curated ambiguous datasets.\nExperiments show that our methods can match or outperform state-of-the-art\nsystems such as DeepL and NLLB in four out of five language directions. Our\nresearch provides valuable insights into effectively adapting LLMs to become\nbetter disambiguators during Machine Translation. We release our curated\ndisambiguation corpora and resources at\nhttps://data.statmt.org/ambiguous-europarl.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Iyer_V/0/1/0/all/0/1\">Vivek Iyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pinzhen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Birch_A/0/1/0/all/0/1\">Alexandra Birch</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt Tuned Embedding Classification for Multi-Label Industry Sector Allocation. (arXiv:2309.12075v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.12075","description":"<p>Prompt Tuning is emerging as a scalable and cost-effective method to\nfine-tune Pretrained Language Models (PLMs), which are often referred to as\nLarge Language Models (LLMs). This study benchmarks the performance and\ncomputational efficiency of Prompt Tuning and baselines for multi-label text\nclassification. This is applied to the challenging task of classifying\ncompanies into an investment firm's proprietary industry taxonomy, supporting\ntheir thematic investment strategy. Text-to-text classification is frequently\nreported to outperform task-specific classification heads, but has several\nlimitations when applied to a multi-label classification problem where each\nlabel consists of multiple tokens: (a) Generated labels may not match any label\nin the label taxonomy; (b) The fine-tuning process lacks permutation invariance\nand is sensitive to the order of the provided labels; (c) The model provides\nbinary decisions rather than appropriate confidence scores. Limitation (a) is\naddressed by applying constrained decoding using Trie Search, which slightly\nimproves classification performance. All limitations (a), (b), and (c) are\naddressed by replacing the PLM's language head with a classification head,\nwhich is referred to as Prompt Tuned Embedding Classification (PTEC). This\nimproves performance significantly, while also reducing computational costs\nduring inference. In our industrial application, the training data is skewed\ntowards well-known companies. We confirm that the model's performance is\nconsistent across both well-known and less-known companies. Our overall results\nindicate the continuing need to adapt state-of-the-art methods to\ndomain-specific tasks, even in the era of PLMs with strong generalization\nabilities. We release our codebase and a benchmarking dataset at\nhttps://github.com/EQTPartners/PTEC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Buchner_V/0/1/0/all/0/1\">Valentin Leonhard Buchner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_L/0/1/0/all/0/1\">Lele Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalo_J/0/1/0/all/0/1\">Jan-Christoph Kalo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ehrenheim_V/0/1/0/all/0/1\">Vilhelm von Ehrenheim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT-Fathom: Benchmarking Large Language Models to Decipher the Evolutionary Path towards GPT-4 and Beyond. (arXiv:2309.16583v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.16583","description":"<p>With the rapid advancement of large language models (LLMs), there is a\npressing need for a comprehensive evaluation suite to assess their capabilities\nand limitations. Existing LLM leaderboards often reference scores reported in\nother papers without consistent settings and prompts, which may inadvertently\nencourage cherry-picking favored settings and prompts for better results. In\nthis work, we introduce GPT-Fathom, an open-source and reproducible LLM\nevaluation suite built on top of OpenAI Evals. We systematically evaluate 10+\nleading LLMs as well as OpenAI's legacy models on 20+ curated benchmarks across\n7 capability categories, all under aligned settings. Our retrospective study on\nOpenAI's earlier models offers valuable insights into the evolutionary path\nfrom GPT-3 to GPT-4. Currently, the community is eager to know how GPT-3\nprogressively improves to GPT-4, including technical details like whether\nadding code data improves LLM's reasoning capability, which aspects of LLM\ncapability can be improved by SFT and RLHF, how much is the alignment tax, etc.\nOur analysis sheds light on many of these questions, aiming to improve the\ntransparency of advanced LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1\">Shen Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuyu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_C/0/1/0/all/0/1\">Chenguang Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1\">Pengyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1\">Xun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kevin Chen-Chuan Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Dialogue Management: Quality Datasets vs Models. (arXiv:2310.01339v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01339","description":"<p>Task-oriented dialogue systems (TODS) have become crucial for users to\ninteract with machines and computers using natural language. One of its key\ncomponents is the dialogue manager, which guides the conversation towards a\ngood goal for the user by providing the best possible response. Previous works\nhave proposed rule-based systems (RBS), reinforcement learning (RL), and\nsupervised learning (SL) as solutions for the correct dialogue management; in\nother words, select the best response given input by the user. However, this\nwork argues that the leading cause of DMs not achieving maximum performance\nresides in the quality of the datasets rather than the models employed thus\nfar; this means that dataset errors, like mislabeling, originate a large\npercentage of failures in dialogue management. We studied the main errors in\nthe most widely used datasets, Multiwoz 2.1 and SGD, to demonstrate this\nhypothesis. To do this, we have designed a synthetic dialogue generator to\nfully control the amount and type of errors introduced in the dataset. Using\nthis generator, we demonstrated that errors in the datasets contribute\nproportionally to the performance of the models\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Medina_Ramirez_M/0/1/0/all/0/1\">Miguel &#xc1;ngel Medina-Ram&#xed;rez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guerra_Artal_C/0/1/0/all/0/1\">Cayetano Guerra-Artal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Tejera_M/0/1/0/all/0/1\">Mario Hern&#xe1;ndez-Tejera</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Health Agents: A Personalized LLM-Powered Agent Framework. (arXiv:2310.02374v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.02374","description":"<p>Conversational Health Agents (CHAs) are interactive systems designed to\nenhance personal healthcare services by engaging in empathetic conversations\nand processing multimodal data. While current CHAs, especially those utilizing\nLarge Language Models (LLMs), primarily focus on conversation, they often need\nmore comprehensive agent capabilities. This limitation includes accessing\npersonal user health data from wearables, ubiquitous data collection sources,\nand electronic health records, integrating the latest published health\ninsights, and connecting with established multimodal data analysis tools. In\nthis paper, we propose an LLM-powered framework to empower CHAs to generate a\npersonalized response for users' healthcare queries. This framework provides\ncritical thinking, knowledge acquisition, and problem-solving abilities by\nintegrating healthcare data sources, enabling multilingual and multimodal\nconversations, and interacting with various user data analysis tools. We\nillustrate the framework's proficiency in handling complex healthcare tasks via\na case study on stress level estimation, showcasing the agent's cognitive and\noperational capabilities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abbasian_M/0/1/0/all/0/1\">Mahyar Abbasian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Azimi_I/0/1/0/all/0/1\">Iman Azimi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahmani_A/0/1/0/all/0/1\">Amir M. Rahmani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_R/0/1/0/all/0/1\">Ramesh Jain</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Hallucinations in Chinese Large Language Models. (arXiv:2310.03368v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.03368","description":"<p>In this paper, we establish a benchmark named HalluQA (Chinese Hallucination\nQuestion-Answering) to measure the hallucination phenomenon in Chinese large\nlanguage models. HalluQA contains 450 meticulously designed adversarial\nquestions, spanning multiple domains, and takes into account Chinese historical\nculture, customs, and social phenomena. During the construction of HalluQA, we\nconsider two types of hallucinations: imitative falsehoods and factual errors,\nand we construct adversarial samples based on GLM-130B and ChatGPT. For\nevaluation, we design an automated evaluation method using GPT-4 to judge\nwhether a model output is hallucinated. We conduct extensive experiments on 24\nlarge language models, including ERNIE-Bot, Baichuan2, ChatGLM, Qwen, SparkDesk\nand etc. Out of the 24 models, 18 achieved non-hallucination rates lower than\n50%. This indicates that HalluQA is highly challenging. We analyze the primary\ntypes of hallucinations in different types of models and their causes.\nAdditionally, we discuss which types of hallucinations should be prioritized\nfor different types of models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1\">Qinyuan Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wenwei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Siyin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiangyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mozhi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junliang He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Mianqiu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1\">Kai Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model. (arXiv:2310.04445v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04445","description":"<p>It has been shown that Large Language Model (LLM) alignments can be\ncircumvented by appending specially crafted attack suffixes with harmful\nqueries to elicit harmful responses. To conduct attacks against private target\nmodels whose characterization is unknown, public models can be used as proxies\nto fashion the attack, with successful attacks being transferred from public\nproxies to private target models. The success rate of attack depends on how\nclosely the proxy model approximates the private model. We hypothesize that for\nattacks to be transferrable, it is sufficient if the proxy can approximate the\ntarget model in the neighborhood of the harmful query. Therefore, in this\npaper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning\nproxy models on similar queries that lie in the lexico-semantic neighborhood of\nharmful queries to decrease the divergence between the proxy and target models.\nFirst, we demonstrate three approaches to prompt private target models to\nobtain similar queries given harmful queries. Next, we obtain data for local\nfine-tuning by eliciting responses from target models for the generated similar\nqueries. Then, we optimize attack suffixes to generate attack prompts and\nevaluate the impact of our local fine-tuning on the attack's success rate.\nExperiments show that local fine-tuning of proxy models improves attack\ntransferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$\n(absolute) on target models ChatGPT, GPT-4, and Claude respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1\">Muhammad Ahmed Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1\">Roshan Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhamyal_H/0/1/0/all/0/1\">Hira Dhamyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Olivier_R/0/1/0/all/0/1\">Raphael Olivier</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1\">Ankit Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Konan_J/0/1/0/all/0/1\">Joseph Konan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alharthi_D/0/1/0/all/0/1\">Dareen Alharthi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bukhari_H/0/1/0/all/0/1\">Hazim T Bukhari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baali_M/0/1/0/all/0/1\">Massa Baali</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_S/0/1/0/all/0/1\">Soham Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuhlmann_M/0/1/0/all/0/1\">Michael Kuhlmann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1\">Bhiksha Raj</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1\">Rita Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Only Pass Primary School Exams in Indonesia: A Comprehensive Test on IndoMMLU. (arXiv:2310.04928v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.04928","description":"<p>Although large language models (LLMs) are often pre-trained on large-scale\nmultilingual texts, their reasoning abilities and real-world knowledge are\nmainly evaluated based on English datasets. Assessing LLM capabilities beyond\nEnglish is increasingly vital but hindered due to the lack of suitable\ndatasets. In this work, we introduce IndoMMLU, the first multi-task language\nunderstanding benchmark for Indonesian culture and languages, which consists of\nquestions from primary school to university entrance exams in Indonesia. By\nemploying professional teachers, we obtain 14,981 questions across 64 tasks and\neducation levels, with 46% of the questions focusing on assessing proficiency\nin the Indonesian language and knowledge of nine local languages and cultures\nin Indonesia. Our empirical evaluations show that GPT-3.5 only manages to pass\nthe Indonesian primary school level, with limited knowledge of local Indonesian\nlanguages and culture. Other smaller models such as BLOOMZ and Falcon perform\nat even lower levels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1\">Fajri Koto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aisyah_N/0/1/0/all/0/1\">Nurul Aisyah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haonan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1\">Timothy Baldwin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Guideline Learning for In-context Information Extraction. (arXiv:2310.05066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05066","description":"<p>Large language models (LLMs) can perform a new task by merely conditioning on\ntask instructions and a few input-output examples, without optimizing any\nparameters. This is called In-Context Learning (ICL). In-context Information\nExtraction (IE) has recently garnered attention in the research community.\nHowever, the performance of In-context IE generally lags behind the\nstate-of-the-art supervised expert models. We highlight a key reason for this\nshortfall: underspecified task description. The limited-length context\nstruggles to thoroughly express the intricate IE task instructions and various\nedge cases, leading to misalignment in task comprehension with humans. In this\npaper, we propose a Guideline Learning (GL) framework for In-context IE which\nreflectively learns and follows guidelines. During the learning phrase, GL\nautomatically synthesizes a set of guidelines based on a few error cases, and\nduring inference, GL retrieves helpful guidelines for better ICL. Moreover, we\npropose a self-consistency-based active learning method to enhance the\nefficiency of GL. Experiments on event extraction and relation extraction show\nthat GL can significantly improve the performance of in-context IE.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pang_C/0/1/0/all/0/1\">Chaoxu Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1\">Yixuan Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1\">Qiang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1\">Ping Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller Language Models. (arXiv:2310.05074v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05074","description":"<p>Chain-of-Thought (CoT) prompting has proven to be effective in enhancing the\nreasoning capabilities of Large Language Models (LLMs) with at least 100\nbillion parameters. However, it is ineffective or even detrimental when applied\nto reasoning tasks in Smaller Language Models (SLMs) with less than 10 billion\nparameters. To address this limitation, we introduce Dialogue-guided\nChain-of-Thought (DialCoT) which employs a dialogue format to generate\nintermediate reasoning steps, guiding the model toward the final answer.\nAdditionally, we optimize the model's reasoning path selection using the\nProximal Policy Optimization (PPO) algorithm, further enhancing its reasoning\ncapabilities. Our method offers several advantages compared to previous\napproaches. Firstly, we transform the process of solving complex reasoning\nquestions by breaking them down into a series of simpler sub-questions,\nsignificantly reducing the task difficulty and making it more suitable for\nSLMs. Secondly, we optimize the model's reasoning path selection through the\nPPO algorithm. We conduct comprehensive experiments on four arithmetic\nreasoning datasets, demonstrating that our method achieves significant\nperformance improvements compared to state-of-the-art competitors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chengcheng Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xiaowei Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Che Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lian_Y/0/1/0/all/0/1\">Yixin Lian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_M/0/1/0/all/0/1\">Ming Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Baoyuan Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Personalized Stochastic Parrots More Dangerous? Evaluating Persona Biases in Dialogue Systems. (arXiv:2310.05280v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05280","description":"<p>Recent advancements in Large Language Models empower them to follow freeform\ninstructions, including imitating generic or specific demographic personas in\nconversations. We define generic personas to represent demographic groups, such\nas \"an Asian person\", whereas specific personas may take the form of specific\npopular Asian names like \"Yumi\". While the adoption of personas enriches user\nexperiences by making dialogue systems more engaging and approachable, it also\ncasts a shadow of potential risk by exacerbating social biases within model\nresponses, thereby causing societal harm through interactions with users. In\nthis paper, we systematically study \"persona biases\", which we define to be the\nsensitivity of dialogue models' harmful behaviors contingent upon the personas\nthey adopt. We categorize persona biases into biases in harmful expression and\nharmful agreement, and establish a comprehensive evaluation framework to\nmeasure persona biases in five aspects: Offensiveness, Toxic Continuation,\nRegard, Stereotype Agreement, and Toxic Agreement. Additionally, we propose to\ninvestigate persona biases by experimenting with UNIVERSALPERSONA, a\nsystematically constructed persona dataset encompassing various types of both\ngeneric and specific model personas. Through benchmarking on four different\nmodels -- including Blender, ChatGPT, Alpaca, and Vicuna -- our study uncovers\nsignificant persona biases in dialogue systems. Our findings also underscore\nthe pressing need to revisit the use of personas in dialogue agents to ensure\nsafe application.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1\">Yixin Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jieyu Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chadha_A/0/1/0/all/0/1\">Aman Chadha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1\">Nanyun Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Long-form Text Generation Efficacy with Task-adaptive Tokenization. (arXiv:2310.05317v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05317","description":"<p>We propose task-adaptive tokenization as a way to adapt the generation\npipeline to the specifics of a downstream task and enhance long-form generation\nin mental health. Inspired by insights from cognitive science, our\ntask-adaptive tokenizer samples variable segmentations from multiple outcomes,\nwith sampling probabilities optimized based on task-specific data. We introduce\na strategy for building a specialized vocabulary and introduce a vocabulary\nmerging protocol that allows for the integration of task-specific tokens into\nthe pre-trained model's tokenization step. Through extensive experiments on\npsychological question-answering tasks in both Chinese and English, we find\nthat our task-adaptive tokenization approach brings a significant improvement\nin generation performance while using up to 60% fewer tokens. Preliminary\nexperiments point to promising results when using our tokenization approach\nwith very large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Siyang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_N/0/1/0/all/0/1\">Naihao Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sabour_S/0/1/0/all/0/1\">Sahand Sabour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1\">Yilin Jia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1\">Minlie Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1\">Rada Mihalcea</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Establishing Trustworthiness: Rethinking Tasks and Model Evaluation. (arXiv:2310.05442v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05442","description":"<p>Language understanding is a multi-faceted cognitive capability, which the\nNatural Language Processing (NLP) community has striven to model\ncomputationally for decades. Traditionally, facets of linguistic intelligence\nhave been compartmentalized into tasks with specialized model architectures and\ncorresponding evaluation protocols. With the advent of large language models\n(LLMs) the community has witnessed a dramatic shift towards general purpose,\ntask-agnostic approaches powered by generative models. As a consequence, the\ntraditional compartmentalized notion of language tasks is breaking down,\nfollowed by an increasing challenge for evaluation and analysis. At the same\ntime, LLMs are being deployed in more real-world scenarios, including\npreviously unforeseen zero-shot setups, increasing the need for trustworthy and\nreliable systems. Therefore, we argue that it is time to rethink what\nconstitutes tasks and model evaluation in NLP, and pursue a more holistic view\non language, placing trustworthiness at the center. Towards this goal, we\nreview existing compartmentalized approaches for understanding the origins of a\nmodel's functional capacity, and provide recommendations for more multi-faceted\nevaluation protocols.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Litschko_R/0/1/0/all/0/1\">Robert Litschko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_Eberstein_M/0/1/0/all/0/1\">Max M&#xfc;ller-Eberstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goot_R/0/1/0/all/0/1\">Rob van der Goot</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_L/0/1/0/all/0/1\">Leon Weber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InterroLang: Exploring NLP Models and Datasets through Dialogue-based Explanations. (arXiv:2310.05592v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05592","description":"<p>While recently developed NLP explainability methods let us open the black box\nin various ways (Madsen et al., 2022), a missing ingredient in this endeavor is\nan interactive tool offering a conversational interface. Such a dialogue system\ncan help users explore datasets and models with explanations in a\ncontextualized manner, e.g. via clarification or follow-up questions, and\nthrough a natural language interface. We adapt the conversational explanation\nframework TalkToModel (Slack et al., 2022) to the NLP domain, add new\nNLP-specific operations such as free-text rationalization, and illustrate its\ngeneralizability on three NLP tasks (dialogue act classification, question\nanswering, hate speech detection). To recognize user queries for explanations,\nwe evaluate fine-tuned and few-shot prompting models and implement a novel\nAdapter-based approach. We then conduct two user studies on (1) the perceived\ncorrectness and helpfulness of the dialogues, and (2) the simulatability, i.e.\nhow objectively helpful dialogical explanations are for humans in figuring out\nthe model's predicted label when it's not shown. We found rationalization and\nfeature attribution were helpful in explaining the model behavior. Moreover,\nusers could more reliably predict the model outcome based on an explanation\ndialogue rather than one-off explanations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feldhus_N/0/1/0/all/0/1\">Nils Feldhus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qianli Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anikina_T/0/1/0/all/0/1\">Tatiana Anikina</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chopra_S/0/1/0/all/0/1\">Sahil Chopra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oguz_C/0/1/0/all/0/1\">Cennet Oguz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moller_S/0/1/0/all/0/1\">Sebastian M&#xf6;ller</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can language models learn analogical reasoning? Investigating training objectives and comparisons to human performance. (arXiv:2310.05597v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05597","description":"<p>While analogies are a common way to evaluate word embeddings in NLP, it is\nalso of interest to investigate whether or not analogical reasoning is a task\nin itself that can be learned. In this paper, we test several ways to learn\nbasic analogical reasoning, specifically focusing on analogies that are more\ntypical of what is used to evaluate analogical reasoning in humans than those\nin commonly used NLP benchmarks. Our experiments find that models are able to\nlearn analogical reasoning, even with a small amount of data. We additionally\ncompare our models to a dataset with a human baseline, and find that after\ntraining, models approach human performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Petersen_M/0/1/0/all/0/1\">Molly R. Petersen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plas_L/0/1/0/all/0/1\">Lonneke van der Plas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Attribution Method for Siamese Encoders. (arXiv:2310.05703v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05703","description":"<p>Despite the success of Siamese encoder models such as sentence transformers\n(ST), little is known about the aspects of inputs they pay attention to. A\nbarrier is that their predictions cannot be attributed to individual features,\nas they compare two inputs rather than processing a single one. This paper\nderives a local attribution method for Siamese encoders by generalizing the\nprinciple of integrated gradients to models with multiple inputs. The solution\ntakes the form of feature-pair attributions, and can be reduced to a\ntoken-token matrix for STs. Our method involves the introduction of integrated\nJacobians and inherits the advantageous formal properties of integrated\ngradients: it accounts for the model's full computation graph and is guaranteed\nto converge to the actual prediction. A pilot study shows that in an ST few\ntoken-pairs can often explain large fractions of predictions, and it focuses on\nnouns and verbs. For accurate predictions, it however needs to attend to the\nmajority of tokens and parts of speech.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moller_L/0/1/0/all/0/1\">Lucas M&#xf6;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1\">Dmitry Nikolaev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pado_S/0/1/0/all/0/1\">Sebastian Pad&#xf3;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models. (arXiv:2310.06374v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06374","description":"<p>Keyphrase Generation (KPG) is a longstanding task in NLP with widespread\napplications. The advent of sequence-to-sequence (seq2seq) pre-trained language\nmodels (PLMs) has ushered in a transformative era for KPG, yielding promising\nperformance improvements. However, many design decisions remain unexplored and\nare often made arbitrarily. This paper undertakes a systematic analysis of the\ninfluence of model selection and decoding strategies on PLM-based KPG. We begin\nby elucidating why seq2seq PLMs are apt for KPG, anchored by an\nattention-driven hypothesis. We then establish that conventional wisdom for\nselecting seq2seq PLMs lacks depth: (1) merely increasing model size or\nperforming task-specific adaptation is not parameter-efficient; (2) although\ncombining in-domain pre-training with task adaptation benefits KPG, it does\npartially hinder generalization. Regarding decoding, we demonstrate that while\ngreedy search achieves strong F1 scores, it lags in recall compared with\nsampling-based methods. Based on these insights, we propose DeSel, a\nlikelihood-based decode-select algorithm for seq2seq PLMs. DeSel improves\ngreedy search by an average of 4.7% semantic F1 across five datasets. Our\ncollective findings pave the way for deeper future investigations into\nPLM-based KPG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1\">Di Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1\">Wasi Uddin Ahmad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hexa: Self-Improving for Knowledge-Grounded Dialogue System. (arXiv:2310.06404v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06404","description":"<p>A common practice in knowledge-grounded dialogue generation is to explicitly\nutilize intermediate steps (e.g., web-search, memory retrieval) with modular\napproaches. However, data for such steps are often inaccessible compared to\nthose of dialogue responses as they are unobservable in an ordinary dialogue.\nTo fill in the absence of these data, we develop a self-improving method to\nimprove the generative performances of intermediate steps without the ground\ntruth data. In particular, we propose a novel bootstrapping scheme with a\nguided prompt and a modified loss function to enhance the diversity of\nappropriate self-generated responses. Through experiments on various benchmark\ndatasets, we empirically demonstrate that our method successfully leverages a\nself-improving mechanism in generating intermediate and final responses and\nimproves the performances on the task of knowledge-grounded dialogue\ngeneration.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jo_D/0/1/0/all/0/1\">Daejin Jo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nam_D/0/1/0/all/0/1\">Daniel Wontae Nam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_G/0/1/0/all/0/1\">Gunsoo Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+On_K/0/1/0/all/0/1\">Kyoung-Woon On</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taehwan Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rho_S/0/1/0/all/0/1\">Seungeun Rho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungwoong Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Humans and language models diverge when predicting repeating text. (arXiv:2310.06408v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06408","description":"<p>Language models that are trained on the next-word prediction task have been\nshown to accurately model human behavior in word prediction and reading speed.\nIn contrast with these findings, we present a scenario in which the performance\nof humans and LMs diverges. We collected a dataset of human next-word\npredictions for five stimuli that are formed by repeating spans of text. Human\nand GPT-2 LM predictions are strongly aligned in the first presentation of a\ntext span, but their performance quickly diverges when memory (or in-context\nlearning) begins to play a role. We traced the cause of this divergence to\nspecific attention heads in a middle layer. Adding a power-law recency bias to\nthese attention heads yielded a model that performs much more similarly to\nhumans. We hope that this scenario will spur future work in bringing LMs closer\nto human behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vaidya_A/0/1/0/all/0/1\">Aditya R. Vaidya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Turek_J/0/1/0/all/0/1\">Javier Turek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huth_A/0/1/0/all/0/1\">Alexander G. Huth</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Contrastive Learning of Sentence Embeddings with Focal-InfoNCE. (arXiv:2310.06918v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.06918","description":"<p>The recent success of SimCSE has greatly advanced state-of-the-art sentence\nrepresentations. However, the original formulation of SimCSE does not fully\nexploit the potential of hard negative samples in contrastive learning. This\nstudy introduces an unsupervised contrastive learning framework that combines\nSimCSE with hard negative mining, aiming to enhance the quality of sentence\nembeddings. The proposed focal-InfoNCE function introduces self-paced\nmodulation terms in the contrastive objective, downweighting the loss\nassociated with easy negatives and encouraging the model focusing on hard\nnegatives. Experimentation on various STS benchmarks shows that our method\nimproves sentence embeddings in terms of Spearman's correlation and\nrepresentation alignment and uniformity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hou_P/0/1/0/all/0/1\">Pengyue Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xingyu Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting. (arXiv:2310.07081v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07081","description":"<p>Idioms are common in everyday language, but often pose a challenge to\ntranslators because their meanings do not follow from the meanings of their\nparts. Despite significant advances, machine translation systems still struggle\nto translate idiomatic expressions. We provide a simple characterization of\nidiomatic translation and related issues. This allows us to conduct a synthetic\nexperiment revealing a tipping point at which transformer-based machine\ntranslation models correctly default to idiomatic translations. To expand\nmultilingual resources, we compile a dataset of ~4k natural sentences\ncontaining idiomatic expressions in French, Finnish, and Japanese. To improve\ntranslation of natural idioms, we introduce two straightforward yet effective\ntechniques: the strategic upweighting of training loss on potentially idiomatic\nsentences, and using retrieval-augmented models. This not only improves the\naccuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in\nabsolute accuracy, but also holds potential benefits for non-idiomatic\nsentences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1\">Emmy Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chaudhary_A/0/1/0/all/0/1\">Aditi Chaudhary</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1\">Graham Neubig</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\"A Tale of Two Movements\": Identifying and Comparing Perspectives in #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly Supervised Graph-based Structured Prediction. (arXiv:2310.07155v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07155","description":"<p>Social media has become a major driver of social change, by facilitating the\nformation of online social movements. Automatically understanding the\nperspectives driving the movement and the voices opposing it, is a challenging\ntask as annotated data is difficult to obtain. We propose a weakly supervised\ngraph-based approach that explicitly models perspectives in\n#BackLivesMatter-related tweets. Our proposed approach utilizes a\nsocial-linguistic representation of the data. We convert the text to a graph by\nbreaking it into structured elements and connect it with the social network of\nauthors, then structured prediction is done over the elements for identifying\nperspectives. Our approach uses a small seed set of labeled examples. We\nexperiment with large language models for generating artificial training\nexamples, compare them to manual annotation, and find that it achieves\ncomparable performance. We perform quantitative and qualitative analyses using\na human-annotated test set. Our model outperforms multitask baselines by a\nlarge margin, successfully characterizing the perspectives supporting and\nopposing #BLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Shamik Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goldwasser_D/0/1/0/all/0/1\">Dan Goldwasser</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Democratizing LLMs: An Exploration of Cost-Performance Trade-offs in Self-Refined Open-Source Models. (arXiv:2310.07611v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.07611","description":"<p>The dominance of proprietary LLMs has led to restricted access and raised\ninformation privacy concerns. High-performing open-source alternatives are\ncrucial for information-sensitive and high-volume applications but often lag\nbehind in performance. To address this gap, we propose (1) A untargeted variant\nof iterative self-critique and self-refinement devoid of external influence.\n(2) A novel ranking metric - Performance, Refinement, and Inference Cost Score\n(PeRFICS) - to find the optimal model for a given task considering refined\nperformance and cost. Our experiments show that SoTA open source models of\nvarying sizes from 7B - 65B, on average, improve 8.2% from their baseline\nperformance. Strikingly, even models with extremely small memory footprints,\nsuch as Vicuna-7B, show a 11.74% improvement overall and up to a 25.39%\nimprovement in high-creativity, open ended tasks on the Vicuna benchmark.\nVicuna-13B takes it a step further and outperforms ChatGPT post-refinement.\nThis work has profound implications for resource-constrained and\ninformation-sensitive environments seeking to leverage LLMs without incurring\nprohibitive costs, compromising on performance and privacy. The domain-agnostic\nself-refinement process coupled with our novel ranking metric facilitates\ninformed decision-making in model selection, thereby reducing costs and\ndemocratizing access to high-performing language models, as evidenced by case\nstudies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shashidhar_S/0/1/0/all/0/1\">Sumuk Shashidhar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chinta_A/0/1/0/all/0/1\">Abhinav Chinta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahai_V/0/1/0/all/0/1\">Vaibhav Sahai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenhailong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1\">Heng Ji</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fine-grained Conversational Decoding via Isotropic and Proximal Search. (arXiv:2310.08130v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08130","description":"<p>General-purpose text decoding approaches are usually adopted for dialogue\nresponse generation. Although the quality of the generated responses can be\nimproved with dialogue-specific encoding methods, conversational decoding\nmethods are still under-explored. Inspired by \\citet{wu2023learning} that a\ngood dialogue feature space should follow the rules of locality and isotropy,\nwe present a fine-grained conversational decoding method, termed\n\\textit{isotropic and proximal search (IPS)}. Our method is designed to\ngenerate the semantic-concentrated response, while still maintaining\ninformativeness and discrimination against the context. Experiments show that\nour approach outperforms existing decoding strategies in the dialogue field\nacross both automatic and human evaluation metrics. More in-depth analyses\nfurther confirm the effectiveness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1\">Yuxuan Yao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1\">Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1\">Qiling Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1\">Linqi Song</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting Large Language Models with Chain-of-Thought for Few-Shot Knowledge Base Question Generation. (arXiv:2310.08395v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08395","description":"<p>The task of Question Generation over Knowledge Bases (KBQG) aims to convert a\nlogical form into a natural language question. For the sake of expensive cost\nof large-scale question annotation, the methods of KBQG under low-resource\nscenarios urgently need to be developed. However, current methods heavily rely\non annotated data for fine-tuning, which is not well-suited for few-shot\nquestion generation. The emergence of Large Language Models (LLMs) has shown\ntheir impressive generalization ability in few-shot tasks. Inspired by\nChain-of-Thought (CoT) prompting, which is an in-context learning strategy for\nreasoning, we formulate KBQG task as a reasoning problem, where the generation\nof a complete question is splitted into a series of sub-question generation.\nOur proposed prompting method KQG-CoT first retrieves supportive logical forms\nfrom the unlabeled data pool taking account of the characteristics of the\nlogical form. Then, we write a prompt to explicit the reasoning chain of\ngenerating complicated questions based on the selected demonstrations. To\nfurther ensure prompt quality, we extend KQG-CoT into KQG-CoT+ via sorting the\nlogical forms by their complexity. We conduct extensive experiments over three\npublic KBQG datasets. The results demonstrate that our prompting method\nconsistently outperforms other prompting baselines on the evaluated datasets.\nRemarkably, our KQG-CoT+ method could surpass existing few-shot SoTA results of\nthe PathQuestions dataset by 18.25, 10.72, and 10.18 absolute points on BLEU-4,\nMETEOR, and ROUGE-L, respectively.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1\">Yuanyuan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jianing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1\">Hanlun Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_W/0/1/0/all/0/1\">Weining Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1\">Yunshi Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models. (arXiv:2310.08659v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08659","description":"<p>Quantization is an indispensable technique for serving Large Language Models\n(LLMs) and has recently found its way into LoRA fine-tuning. In this work we\nfocus on the scenario where quantization and LoRA fine-tuning are applied\ntogether on a pre-trained model. In such cases it is common to observe a\nconsistent gap in the performance on downstream tasks between full fine-tuning\nand quantization plus LoRA fine-tuning approach. In response, we propose LoftQ\n(LoRA-Fine-Tuning-aware Quantization), a novel quantization framework that\nsimultaneously quantizes an LLM and finds a proper low-rank initialization for\nLoRA fine-tuning. Such an initialization alleviates the discrepancy between the\nquantized and full-precision model and significantly improves the\ngeneralization in downstream tasks. We evaluate our method on natural language\nunderstanding, question answering, summarization, and natural language\ngeneration tasks. Experiments show that our method is highly effective and\noutperforms existing quantization methods, especially in the challenging 2-bit\nand 2/4-bit mixed precision regimes. We will release our code.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yixiao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yifan Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1\">Chen Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1\">Pengcheng He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karampatziakis_N/0/1/0/all/0/1\">Nikos Karampatziakis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weizhu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1\">Tuo Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Zero-Shot Language Agent for Computer Control with Structured Reflection. (arXiv:2310.08740v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.08740","description":"<p>Large language models (LLMs) have shown increasing capacity at planning and\nexecuting a high-level goal in a live computer environment (e.g. MiniWoB++). To\nperform a task, recent works often require a model to learn from trace examples\nof the task via either supervised learning or few/many-shot prompting. Without\nthese trace examples, it remains a challenge how an agent can autonomously\nlearn and improve its control on a computer, which limits the ability of an\nagent to perform a new task. We approach this problem with a zero-shot agent\nthat requires no given expert traces. Our agent plans for executable actions on\na partially observed environment, and iteratively progresses a task by\nidentifying and learning from its mistakes via self-reflection and structured\nthought management. On the easy tasks of MiniWoB++, we show that our zero-shot\nagent often outperforms recent SoTAs, with more efficient reasoning. For tasks\nwith more complexity, our reflective agent performs on par with prior best\nmodels, even though previous works had the advantages of accessing expert\ntraces or additional screen information.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Gang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhiwei Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bryan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yang Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue Chain-of-Thought Distillation for Commonsense-aware Conversational Agents. (arXiv:2310.09343v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09343","description":"<p>Human-like chatbots necessitate the use of commonsense reasoning in order to\neffectively comprehend and respond to implicit information present within\nconversations. Achieving such coherence and informativeness in responses,\nhowever, is a non-trivial task. Even for large language models (LLMs), the task\nof identifying and aggregating key evidence within a single hop presents a\nsubstantial challenge. This complexity arises because such evidence is\nscattered across multiple turns in a conversation, thus necessitating\nintegration over multiple hops. Hence, our focus is to facilitate such\nmulti-hop reasoning over a dialogue context, namely dialogue chain-of-thought\n(CoT) reasoning. To this end, we propose a knowledge distillation framework\nthat leverages LLMs as unreliable teachers and selectively distills consistent\nand helpful rationales via alignment filters. We further present DOCTOR, a\nDialOgue Chain-of-ThOught Reasoner that provides reliable CoT rationales for\nresponse generation. We conduct extensive experiments to show that enhancing\ndialogue agents with high-quality rationales from DOCTOR significantly improves\nthe quality of their responses.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chae_H/0/1/0/all/0/1\">Hyungjoo Chae</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yongho Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ong_K/0/1/0/all/0/1\">Kai Tzu-iunn Ong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kwon_T/0/1/0/all/0/1\">Taeyoon Kwon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1\">Minjin Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Youngjae Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongha Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1\">Dongyeop Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yeo_J/0/1/0/all/0/1\">Jinyoung Yeo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Merging Experts into One: Improving Computational Efficiency of Mixture of Experts. (arXiv:2310.09832v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09832","description":"<p>Scaling the size of language models usually leads to remarkable advancements\nin NLP tasks. But it often comes with a price of growing computational cost.\nAlthough a sparse Mixture of Experts (MoE) can reduce the cost by activating a\nsmall subset of parameters (e.g., one expert) for each input, its computation\nescalates significantly if increasing the number of activated experts, limiting\nits practical utility. Can we retain the advantages of adding more experts\nwithout substantially increasing the computational costs? In this paper, we\nfirst demonstrate the superiority of selecting multiple experts and then\npropose a computation-efficient approach called \\textbf{\\texttt{Merging Experts\ninto One}} (MEO), which reduces the computation cost to that of a single\nexpert. Extensive experiments show that MEO significantly improves\ncomputational efficiency, e.g., FLOPS drops from 72.0G of vanilla MoE to 28.6G\n(MEO). Moreover, we propose a token-level attention block that further enhances\nthe efficiency and performance of token-level MEO, e.g., 83.3\\% (MEO) vs.\n82.6\\% (vanilla MoE) average score on the GLUE benchmark. Our code will be\nreleased upon acceptance. Code will be released at:\n\\url{https://github.com/Shwai-He/MEO}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shwai He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1\">Run-Ze Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1\">Liang Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1\">Li Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tianyi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1\">Dacheng Tao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Learning with Iterative Demonstration Selection. (arXiv:2310.09881v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.09881","description":"<p>Spurred by advancements in scale, large language models (LLMs) have\ndemonstrated strong few-shot learning ability via in-context learning (ICL).\nHowever, the performance of ICL has been shown to be highly sensitive to the\nselection of few-shot demonstrations. Selecting the most suitable examples as\ncontext remains an ongoing challenge and an open problem. Existing literature\nhas highlighted the importance of selecting examples that are diverse or\nsemantically similar to the test sample while ignoring the fact that the\noptimal selection dimension, i.e., diversity or similarity, is task-specific.\nLeveraging the merits of both dimensions, we propose Iterative Demonstration\nSelection (IDS). Using zero-shot chain-of-thought reasoning (Zero-shot-CoT),\nIDS iteratively selects examples that are diverse but still strongly correlated\nwith the test sample as ICL demonstrations. Specifically, IDS applies\nZero-shot-CoT to the test sample before demonstration selection. The output\nreasoning path is then used to choose demonstrations that are prepended to the\ntest sample for inference. The generated answer is accompanied by its\ncorresponding reasoning path for extracting a new set of demonstrations in the\nnext iteration. After several iterations, IDS adopts majority voting to obtain\nthe final result. Through extensive experiments on tasks including commonsense\nreasoning, question answering, topic classification, and sentiment analysis, we\ndemonstrate that IDS can consistently outperform existing ICL demonstration\nselection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1\">Chengwei Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1\">Aston Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagar_A/0/1/0/all/0/1\">Anirudh Dagar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wenming Ye</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AdaLomo: Low-memory Optimization with Adaptive Learning Rate. (arXiv:2310.10195v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2310.10195","description":"<p>Large language models have achieved remarkable success, but their extensive\nparameter size necessitates substantial memory for training, thereby setting a\nhigh threshold. While the recently proposed low-memory optimization (LOMO)\nreduces memory footprint, its optimization technique, akin to stochastic\ngradient descent, is sensitive to hyper-parameters and exhibits suboptimal\nconvergence, failing to match the performance of the prevailing optimizer for\nlarge language models, AdamW. Through empirical analysis of the Adam optimizer,\nwe found that, compared to momentum, the adaptive learning rate is more\ncritical for bridging the gap. Building on this insight, we introduce the\nlow-memory optimization with adaptive learning rate (AdaLomo), which offers an\nadaptive learning rate for each parameter. To maintain memory efficiency, we\nemploy non-negative matrix factorization for the second-order moment estimation\nin the optimizer state. Additionally, we suggest the use of a grouped update\nnormalization to stabilize convergence. Our experiments with instruction-tuning\nand further pre-training demonstrate that AdaLomo achieves results on par with\nAdamW, while significantly reducing memory requirements, thereby lowering the\nhardware barrier to training large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lv_K/0/1/0/all/0/1\">Kai Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_H/0/1/0/all/0/1\">Haijun Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cross-Lingual Consistency of Factual Knowledge in Multilingual Language Models. (arXiv:2310.10378v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10378","description":"<p>Multilingual large-scale Pretrained Language Models (PLMs) have been shown to\nstore considerable amounts of factual knowledge, but large variations are\nobserved across languages. With the ultimate goal of ensuring that users with\ndifferent language backgrounds obtain consistent feedback from the same model,\nwe study the cross-lingual consistency (CLC) of factual knowledge in various\nmultilingual PLMs. To this end, we propose a Ranking-based Consistency (RankC)\nmetric to evaluate knowledge consistency across languages independently from\naccuracy. Using this metric, we conduct an in-depth analysis of the determining\nfactors for CLC, both at model level and at language-pair level. Among other\nresults, we find that increasing model size leads to higher factual probing\naccuracy in most languages, but does not improve cross-lingual consistency.\nFinally, we conduct a case study on CLC when new factual associations are\ninserted in the PLMs via model editing. Results on a small sample of facts\ninserted in English reveal a clear pattern whereby the new piece of knowledge\ntransfers only to languages with which English has a high RankC score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1\">Jirui Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1\">Raquel Fern&#xe1;ndez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bisazza_A/0/1/0/all/0/1\">Arianna Bisazza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RegaVAE: A Retrieval-Augmented Gaussian Mixture Variational Auto-Encoder for Language Modeling. (arXiv:2310.10567v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10567","description":"<p>Retrieval-augmented language models show promise in addressing issues like\noutdated information and hallucinations in language models (LMs). However,\ncurrent research faces two main problems: 1) determining what information to\nretrieve, and 2) effectively combining retrieved information during generation.\nWe argue that valuable retrieved information should not only be related to the\ncurrent source text but also consider the future target text, given the nature\nof LMs that model future tokens. Moreover, we propose that aggregation using\nlatent variables derived from a compact latent space is more efficient than\nutilizing explicit raw text, which is limited by context length and susceptible\nto noise. Therefore, we introduce RegaVAE, a retrieval-augmented language model\nbuilt upon the variational auto-encoder (VAE). It encodes the text corpus into\na latent space, capturing current and future information from both source and\ntarget text. Additionally, we leverage the VAE to initialize the latent space\nand adopt the probabilistic form of the retrieval generation paradigm by\nexpanding the Gaussian prior distribution into a Gaussian mixture distribution.\nTheoretical analysis provides an optimizable upper bound for RegaVAE.\nExperimental results on various datasets demonstrate significant improvements\nin text generation quality and hallucination removal.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1\">Jingcheng Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_L/0/1/0/all/0/1\">Liang Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Huawei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1\">Xueqi Cheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In-Context Pretraining: Language Modeling Beyond Document Boundaries. (arXiv:2310.10638v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10638","description":"<p>Large language models (LMs) are currently trained to predict tokens given\ndocument prefixes, enabling them to directly perform long-form generation and\nprompting-style tasks which can be reduced to document completion. Existing\npretraining pipelines train LMs by concatenating random sets of short documents\nto create input contexts but the prior documents provide no signal for\npredicting the next document. We instead present In-Context Pretraining, a new\napproach where language models are pretrained on a sequence of related\ndocuments, thereby explicitly encouraging them to read and reason across\ndocument boundaries. We can do In-Context Pretraining by simply changing the\ndocument ordering so that each context contains related documents, and directly\napplying existing pretraining pipelines. However, this document sorting problem\nis challenging. There are billions of documents and we would like the sort to\nmaximize contextual similarity for every document without repeating any data.\nTo do this, we introduce approximate algorithms for finding related documents\nwith efficient nearest neighbor search and constructing coherent input contexts\nwith a graph traversal algorithm. Our experiments show In-Context Pretraining\noffers a simple and scalable approach to significantly enhance LMs'performance:\nwe see notable improvements in tasks that require more complex contextual\nreasoning, including in-context learning (+8%), reading comprehension (+15%),\nfaithfulness to previous contexts (+16%), long-context reasoning (+5%), and\nretrieval augmentation (+9%).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1\">Weijia Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Min_S/0/1/0/all/0/1\">Sewon Min</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lomeli_M/0/1/0/all/0/1\">Maria Lomeli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chunting Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Margaret Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1\">Xi Victoria Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1\">Noah A. Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1\">Luke Zettlemoyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yih_S/0/1/0/all/0/1\">Scott Yih</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Mike Lewis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for Code Generation. (arXiv:2310.10698v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10698","description":"<p>Large language models (LLMs) have showcased remarkable prowess in code\ngeneration. However, automated code generation is still challenging since it\nrequires a high-level semantic mapping between natural language requirements\nand codes. Most existing LLMs-based approaches for code generation rely on\ndecoder-only causal language models often treate codes merely as plain text\ntokens, i.e., feeding the requirements as a prompt input, and outputing code as\nflat sequence of tokens, potentially missing the rich semantic features\ninherent in source code. To bridge this gap, this paper proposes the \"Semantic\nChain-of-Thought\" approach to intruduce semantic information of code, named\nSeCoT. Our motivation is that the semantic information of the source code (\\eg\ndata flow and control flow) describes more precise program execution behavior,\nintention and function. By guiding LLM consider and integrate semantic\ninformation, we can achieve a more granular understanding and representation of\ncode, enhancing code generation accuracy. Meanwhile, while traditional\ntechniques leveraging such semantic information require complex static or\ndynamic code analysis to obtain features such as data flow and control flow,\nSeCoT demonstrates that this process can be fully automated via the intrinsic\ncapabilities of LLMs (i.e., in-context learning), while being generalizable and\napplicable to challenging domains. While SeCoT can be applied with different\nLLMs, this paper focuses on the powerful GPT-style models: ChatGPT(close-source\nmodel) and WizardCoder(open-source model). The experimental study on three\npopular DL benchmarks (i.e., HumanEval, HumanEval-ET and MBPP) shows that SeCoT\ncan achieves state-of-the-art performance, greatly improving the potential for\nlarge models and code generation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yingwei Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yue Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shanshan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yu Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1\">Yong Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuanliang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1\">Yutao Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1\">Xiangke Liao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Theory of Mind for Multi-Agent Collaboration via Large Language Models. (arXiv:2310.10701v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10701","description":"<p>While Large Language Models (LLMs) have demonstrated impressive\naccomplishments in both reasoning and planning, their abilities in multi-agent\ncollaborations remains largely unexplored. This study evaluates LLM-based\nagents in a multi-agent cooperative text game with Theory of Mind (ToM)\ninference tasks, comparing their performance with Multi-Agent Reinforcement\nLearning (MARL) and planning-based baselines. We observed evidence of emergent\ncollaborative behaviors and high-order Theory of Mind capabilities among\nLLM-based agents. Our results reveal limitations in LLM-based agents' planning\noptimization due to systematic failures in managing long-horizon contexts and\nhallucination about the task state. We explore the use of explicit belief state\nrepresentations to mitigate these issues, finding that it enhances task\nperformance and the accuracy of ToM inferences for LLM-based agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Huao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chong_Y/0/1/0/all/0/1\">Yu Quan Chong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stepputtis_S/0/1/0/all/0/1\">Simon Stepputtis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Campbell_J/0/1/0/all/0/1\">Joseph Campbell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_D/0/1/0/all/0/1\">Dana Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1\">Michael Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1\">Katia Sycara</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BiomedJourney: Counterfactual Biomedical Image Generation by Instruction-Learning from Multimodal Patient Journeys. (arXiv:2310.10765v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2310.10765","description":"<p>Rapid progress has been made in instruction-learning for image editing with\nnatural-language instruction, as exemplified by InstructPix2Pix. In\nbiomedicine, such methods can be applied to counterfactual image generation,\nwhich helps differentiate causal structure from spurious correlation and\nfacilitate robust image interpretation for disease progression modeling.\nHowever, generic image-editing models are ill-suited for the biomedical domain,\nand counterfactual biomedical image generation is largely underexplored. In\nthis paper, we present BiomedJourney, a novel method for counterfactual\nbiomedical image generation by instruction-learning from multimodal patient\njourneys. Given a patient with two biomedical images taken at different time\npoints, we use GPT-4 to process the corresponding imaging reports and generate\na natural language description of disease progression. The resulting triples\n(prior image, progression description, new image) are then used to train a\nlatent diffusion model for counterfactual biomedical image generation. Given\nthe relative scarcity of image time series data, we introduce a two-stage\ncurriculum that first pretrains the denoising network using the much more\nabundant single image-report pairs (with dummy prior image), and then continues\ntraining using the counterfactual triples. Experiments using the standard\nMIMIC-CXR dataset demonstrate the promise of our method. In a comprehensive\nbattery of tests on counterfactual medical image generation, BiomedJourney\nsubstantially outperforms prior state-of-the-art methods in instruction image\nediting and medical image generation such as InstructPix2Pix and RoentGen. To\nfacilitate future study in counterfactual medical generation, we plan to\nrelease our instruction-learning code and pretrained models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1\">Yu Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jianwei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Usuyama_N/0/1/0/all/0/1\">Naoto Usuyama</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chunyuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lungren_M/0/1/0/all/0/1\">Matthew P. Lungren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Emergent AI-Assisted Discourse: Case Study of a Second Language Writer Authoring with ChatGPT. (arXiv:2310.10903v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.10903","description":"<p>The rapid proliferation of ChatGPT has incited debates regarding its impact\non human writing. Amid concerns about declining writing standards, this study\ninvestigates the role of ChatGPT in facilitating academic writing, especially\namong language learners. Using a case study approach, this study examines the\nexperiences of Kailing, a doctoral student, who integrates ChatGPT throughout\ntheir academic writing process. The study employs activity theory as a lens for\nunderstanding writing with generative AI tools and data analyzed includes\nsemi-structured interviews, writing samples, and GPT logs. Results indicate\nthat Kailing effectively collaborates with ChatGPT across various writing\nstages while preserving her distinct authorial voice and agency. This\nunderscores the potential of AI tools such as ChatGPT to enhance academic\nwriting for language learners without overshadowing individual authenticity.\nThis case study offers a critical exploration of how ChatGPT is utilized in the\nacademic writing process and the preservation of a student's authentic voice\nwhen engaging with the tool.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jacob_S/0/1/0/all/0/1\">Sharin Jacob</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tate_T/0/1/0/all/0/1\">Tamara Tate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warschauer_M/0/1/0/all/0/1\">Mark Warschauer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System. (arXiv:2310.11069v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11069","description":"<p>Arabic is a complex language with many varieties and dialects spoken by over\n450 millions all around the world. Due to the linguistic diversity and\nvariations, it is challenging to build a robust and generalized ASR system for\nArabic. In this work, we address this gap by developing and demoing a system,\ndubbed VoxArabica, for dialect identification (DID) as well as automatic speech\nrecognition (ASR) of Arabic. We train a wide range of models such as HuBERT\n(DID), Whisper, and XLS-R (ASR) in a supervised setting for Arabic DID and ASR\ntasks. Our DID models are trained to identify 17 different dialects in addition\nto MSA. We finetune our ASR models on MSA, Egyptian, Moroccan, and mixed data.\nAdditionally, for the remaining dialects in ASR, we provide the option to\nchoose various models such as Whisper and MMS in a zero-shot setting. We\nintegrate these models into a single web interface with diverse features such\nas audio recording, file upload, model selection, and the option to raise flags\nfor incorrect outputs. Overall, we believe VoxArabica will be useful for a wide\nrange of audiences concerned with Arabic research. Our system is currently\nrunning at https://cdce-206-12-100-168.ngrok.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Waheed_A/0/1/0/all/0/1\">Abdul Waheed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Talafha_B/0/1/0/all/0/1\">Bashar Talafha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suvellin_P/0/1/0/all/0/1\">Peter Suvellin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmadney_A/0/1/0/all/0/1\">Abdelrahman Elmadney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1\">Muhammad Abdul-Mageed</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"VECHR: A Dataset for Explainable and Robust Classification of Vulnerability Type in the European Court of Human Rights. (arXiv:2310.11368v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11368","description":"<p>Recognizing vulnerability is crucial for understanding and implementing\ntargeted support to empower individuals in need. This is especially important\nat the European Court of Human Rights (ECtHR), where the court adapts\nConvention standards to meet actual individual needs and thus ensures effective\nhuman rights protection. However, the concept of vulnerability remains elusive\nat the ECtHR and no prior NLP research has dealt with it. To enable future\nresearch in this area, we present VECHR, a novel expert-annotated multi-label\ndataset comprising of vulnerability type classification and explanation\nrationale. We benchmark the performance of state-of-the-art models on VECHR\nfrom both prediction and explainability perspectives. Our results demonstrate\nthe challenging nature of the task with lower prediction performance and\nlimited agreement between models and experts. Further, we analyze the\nrobustness of these models in dealing with out-of-domain (OOD) data and observe\noverall limited performance. Our dataset poses unique challenges offering\nsignificant room for improvement regarding performance, explainability, and\nrobustness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shanshan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staufer_L/0/1/0/all/0/1\">Leon Staufer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Santosh T.Y.S.S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichim_O/0/1/0/all/0/1\">Oana Ichim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heri_C/0/1/0/all/0/1\">Corina Heri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1\">Matthias Grabmair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Long Document Topic Segmentation Models With Enhanced Coherence Modeling. (arXiv:2310.11772v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11772","description":"<p>Topic segmentation is critical for obtaining structured documents and\nimproving downstream tasks such as information retrieval. Due to its ability of\nautomatically exploring clues of topic shift from abundant labeled data, recent\nsupervised neural models have greatly promoted the development of long document\ntopic segmentation, but leaving the deeper relationship between coherence and\ntopic segmentation underexplored. Therefore, this paper enhances the ability of\nsupervised models to capture coherence from both logical structure and semantic\nsimilarity perspectives to further improve the topic segmentation performance,\nproposing Topic-aware Sentence Structure Prediction (TSSP) and Contrastive\nSemantic Similarity Learning (CSSL). Specifically, the TSSP task is proposed to\nforce the model to comprehend structural information by learning the original\nrelations between adjacent sentences in a disarrayed document, which is\nconstructed by jointly disrupting the original document at topic and sentence\nlevels. Moreover, we utilize inter- and intra-topic information to construct\ncontrastive samples and design the CSSL objective to ensure that the sentences\nrepresentations in the same topic have higher similarity, while those in\ndifferent topics are less similar. Extensive experiments show that the\nLongformer with our approach significantly outperforms old state-of-the-art\n(SOTA) methods. Our approach improve $F_1$ of old SOTA by 3.42 (73.74 -&gt; 77.16)\nand reduces $P_k$ by 1.11 points (15.0 -&gt; 13.89) on WIKI-727K and achieves an\naverage relative reduction of 4.3% on $P_k$ on WikiSection. The average\nrelative $P_k$ drop of 8.38% on two out-of-domain datasets also demonstrates\nthe robustness of our approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hai Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_C/0/1/0/all/0/1\">Chong Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qinglin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiaqing Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qian Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Wen Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Dissonance to Insights: Dissecting Disagreements in Rationale Construction for Case Outcome Classification. (arXiv:2310.11878v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11878","description":"<p>In legal NLP, Case Outcome Classification (COC) must not only be accurate but\nalso trustworthy and explainable. Existing work in explainable COC has been\nlimited to annotations by a single expert. However, it is well-known that\nlawyers may disagree in their assessment of case facts. We hence collect a\nnovel dataset RAVE: Rationale Variation in ECHR1, which is obtained from two\nexperts in the domain of international human rights law, for whom we observe\nweak agreement. We study their disagreements and build a two-level\ntask-independent taxonomy, supplemented with COC-specific subcategories. To our\nknowledge, this is the first work in the legal NLP that focuses on human label\nvariation. We quantitatively assess different taxonomy categories and find that\ndisagreements mainly stem from underspecification of the legal context, which\nposes challenges given the typically limited granularity and noise in COC\nmetadata. We further assess the explainablility of SOTA COC models on RAVE and\nobserve limited agreement between models and experts. Overall, our case study\nreveals hitherto underappreciated complexities in creating benchmark datasets\nin legal NLP that revolve around identifying aspects of a case's facts\nsupposedly relevant to its outcome.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shanshan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+S_S/0/1/0/all/0/1\">Santosh T.Y.S.S</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichim_O/0/1/0/all/0/1\">Oana Ichim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Risini_I/0/1/0/all/0/1\">Isabella Risini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Grabmair_M/0/1/0/all/0/1\">Matthias Grabmair</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for Long Sequences. (arXiv:2310.11960v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11960","description":"<p>Transformer-based models have achieved state-of-the-art performance in many\nareas. However, the quadratic complexity of self-attention with respect to the\ninput length hinders the applicability of Transformer-based models to long\nsequences. To address this, we present Fast Multipole Attention, a new\nattention mechanism that uses a divide-and-conquer strategy to reduce the time\nand memory complexity of attention for sequences of length $n$ from\n$\\mathcal{O}(n^2)$ to $\\mathcal{O}(n \\log n)$ or $O(n)$, while retaining a\nglobal receptive field. The hierarchical approach groups queries, keys, and\nvalues into $\\mathcal{O}( \\log n)$ levels of resolution, where groups at\ngreater distances are increasingly larger in size and the weights to compute\ngroup quantities are learned. As such, the interaction between tokens far from\neach other is considered in lower resolution in an efficient hierarchical\nmanner. The overall complexity of Fast Multipole Attention is $\\mathcal{O}(n)$\nor $\\mathcal{O}(n \\log n)$, depending on whether the queries are down-sampled\nor not. This multi-level divide-and-conquer strategy is inspired by fast\nsummation methods from $n$-body physics and the Fast Multipole Method. We\nperform evaluation on autoregressive and bidirectional language modeling tasks\nand compare our Fast Multipole Attention model with other efficient attention\nvariants on medium-size datasets. We find empirically that the Fast Multipole\nTransformer performs much better than other efficient transformers in terms of\nmemory size and accuracy. The Fast Multipole Attention mechanism has the\npotential to empower large language models with much greater sequence lengths,\ntaking the full context into account in an efficient, naturally hierarchical\nmanner during training and when generating long sequences.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1\">Yanming Kang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_G/0/1/0/all/0/1\">Giang Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sterck_H/0/1/0/all/0/1\">Hans De Sterck</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LoHoRavens: A Long-Horizon Language-Conditioned Benchmark for Robotic Tabletop Manipulation. (arXiv:2310.12020v2 [cs.RO] UPDATED)","link":"http://arxiv.org/abs/2310.12020","description":"<p>The convergence of embodied agents and large language models (LLMs) has\nbrought significant advancements to embodied instruction following.\nParticularly, the strong reasoning capabilities of LLMs make it possible for\nrobots to perform long-horizon tasks without expensive annotated\ndemonstrations. However, public benchmarks for testing the long-horizon\nreasoning capabilities of language-conditioned robots in various scenarios are\nstill missing. To fill this gap, this work focuses on the tabletop manipulation\ntask and releases a simulation benchmark, \\textit{LoHoRavens}, which covers\nvarious long-horizon reasoning aspects spanning color, size, space, arithmetics\nand reference. Furthermore, there is a key modality bridging problem for\nlong-horizon manipulation tasks with LLMs: how to incorporate the observation\nfeedback during robot execution for the LLM's closed-loop planning, which is\nhowever less studied by prior work. We investigate two methods of bridging the\nmodality gap: caption generation and learnable interface for incorporating\nexplicit and implicit observation feedback to the LLM, respectively. These\nmethods serve as the two baselines for our proposed benchmark. Experiments show\nthat both methods struggle to solve some tasks, indicating long-horizon\nmanipulation tasks are still challenging for current popular models. We expect\nthe proposed public benchmark and baselines can help the community develop\nbetter models for long-horizon tabletop manipulation tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Shengqiang Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wicke_P/0/1/0/all/0/1\">Philipp Wicke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Senel_L/0/1/0/all/0/1\">L&#xfc;tfi Kerem &#x15e;enel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Figueredo_L/0/1/0/all/0/1\">Luis Figueredo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Naceri_A/0/1/0/all/0/1\">Abdeldjallil Naceri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haddadin_S/0/1/0/all/0/1\">Sami Haddadin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1\">Barbara Plank</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1\">Hinrich Sch&#xfc;tze</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating the Symbol Binding Ability of Large Language Models for Multiple-Choice Questions in Vietnamese General Education. (arXiv:2310.12059v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12059","description":"<p>In this paper, we evaluate the ability of large language models (LLMs) to\nperform multiple choice symbol binding (MCSB) for multiple choice question\nanswering (MCQA) tasks in zero-shot, one-shot, and few-shot settings. We focus\non Vietnamese, with fewer challenging MCQA datasets than in English. The two\nexisting datasets, ViMMRC 1.0 and ViMMRC 2.0, focus on literature. Recent\nresearch in Vietnamese natural language processing (NLP) has focused on the\nVietnamese National High School Graduation Examination (VNHSGE) from 2019 to\n2023 to evaluate ChatGPT. However, these studies have mainly focused on how\nChatGPT solves the VNHSGE step by step. We aim to create a novel and\nhigh-quality dataset by providing structured guidelines for typing LaTeX\nformulas for mathematics, physics, chemistry, and biology. This dataset can be\nused to evaluate the MCSB ability of LLMs and smaller language models (LMs)\nbecause it is typed in a strict LaTeX style. We focus on predicting the\ncharacter (A, B, C, or D) that is the most likely answer to a question, given\nthe context of the question. Our evaluation of six well-known LLMs, namely\nBLOOMZ-7.1B-MT, LLaMA-2-7B, LLaMA-2-70B, GPT-3, GPT-3.5, and GPT-4.0, on the\nViMMRC 1.0 and ViMMRC 2.0 benchmarks and our proposed dataset shows promising\nresults on the MCSB ability of LLMs for Vietnamese. The dataset is available\nfor research purposes only.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1\">Duc-Vu Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1\">Quoc-Nam Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Safer Operations: An Expert-involved Dataset of High-Pressure Gas Incidents for Preventing Future Failures. (arXiv:2310.12074v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12074","description":"<p>This paper introduces a new IncidentAI dataset for safety prevention.\nDifferent from prior corpora that usually contain a single task, our dataset\ncomprises three tasks: named entity recognition, cause-effect extraction, and\ninformation retrieval. The dataset is annotated by domain experts who have at\nleast six years of practical experience as high-pressure gas conservation\nmanagers. We validate the contribution of the dataset in the scenario of safety\nprevention. Preliminary results on the three tasks show that NLP techniques are\nbeneficial for analyzing incident reports to prevent future failures. The\ndataset facilitates future research in NLP and incident management communities.\nThe access to the dataset is also provided (the IncidentAI dataset is available\nat: https://github.com/Cinnamon/incident-ai-dataset).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Inoue_S/0/1/0/all/0/1\">Shumpei Inoue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1\">Minh-Tien Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mizokuchi_H/0/1/0/all/0/1\">Hiroki Mizokuchi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Tuan-Anh D. Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1\">Huu-Hiep Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_D/0/1/0/all/0/1\">Dung Tien Le</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pretraining Language Models with Text-Attributed Heterogeneous Graphs. (arXiv:2310.12580v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12580","description":"<p>In many real-world scenarios (e.g., academic networks, social platforms),\ndifferent types of entities are not only associated with texts but also\nconnected by various relationships, which can be abstracted as Text-Attributed\nHeterogeneous Graphs (TAHGs). Current pretraining tasks for Language Models\n(LMs) primarily focus on separately learning the textual information of each\nentity and overlook the crucial aspect of capturing topological connections\namong entities in TAHGs. In this paper, we present a new pretraining framework\nfor LMs that explicitly considers the topological and heterogeneous information\nin TAHGs. Firstly, we define a context graph as neighborhoods of a target node\nwithin specific orders and propose a topology-aware pretraining task to predict\nnodes involved in the context graph by jointly optimizing an LM and an\nauxiliary heterogeneous graph neural network. Secondly, based on the\nobservation that some nodes are text-rich while others have little text, we\ndevise a text augmentation strategy to enrich textless nodes with their\nneighbors' texts for handling the imbalance issue. We conduct link prediction\nand node classification tasks on three datasets from various domains.\nExperimental results demonstrate the superiority of our approach over existing\nmethods and the rationality of each design. Our code is available at\nhttps://github.com/Hope-Rita/THLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zou_T/0/1/0/all/0/1\">Tao Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1\">Le Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yifei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Leilei Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_B/0/1/0/all/0/1\">Bowen Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Real-World Streaming Speech Translation for Code-Switched Speech. (arXiv:2310.12648v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12648","description":"<p>Code-switching (CS), i.e. mixing different languages in a single sentence, is\na common phenomenon in communication and can be challenging in many Natural\nLanguage Processing (NLP) settings. Previous studies on CS speech have shown\npromising results for end-to-end speech translation (ST), but have been limited\nto offline scenarios and to translation to one of the languages present in the\nsource (\\textit{monolingual transcription}).\n</p>\n<p>In this paper, we focus on two essential yet unexplored areas for real-world\nCS speech translation: streaming settings, and translation to a third language\n(i.e., a language not included in the source). To this end, we extend the\nFisher and Miami test and validation datasets to include new targets in Spanish\nand German. Using this data, we train a model for both offline and streaming ST\nand we establish baseline results for the two settings mentioned earlier.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alastruey_B/0/1/0/all/0/1\">Belen Alastruey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sperber_M/0/1/0/all/0/1\">Matthias Sperber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gollan_C/0/1/0/all/0/1\">Christian Gollan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Telaar_D/0/1/0/all/0/1\">Dominic Telaar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_T/0/1/0/all/0/1\">Tim Ng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1\">Aashish Agarwal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AgentTuning: Enabling Generalized Agent Abilities for LLMs. (arXiv:2310.12823v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12823","description":"<p>Open large language models (LLMs) with great performance in various tasks\nhave significantly advanced the development of LLMs. However, they are far\ninferior to commercial models such as ChatGPT and GPT-4 when acting as agents\nto tackle complex tasks in the real world. These agent tasks employ LLMs as the\ncentral controller responsible for planning, memorization, and tool\nutilization, necessitating both fine-grained prompting methods and robust LLMs\nto achieve satisfactory performance. Though many prompting methods have been\nproposed to complete particular agent tasks, there is lack of research focusing\non improving the agent capabilities of LLMs themselves without compromising\ntheir general abilities. In this work, we present AgentTuning, a simple and\ngeneral method to enhance the agent abilities of LLMs while maintaining their\ngeneral LLM capabilities. We construct AgentInstruct, a lightweight\ninstruction-tuning dataset containing high-quality interaction trajectories. We\nemploy a hybrid instruction-tuning strategy by combining AgentInstruct with\nopen-source instructions from general domains. AgentTuning is used to\ninstruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show\nthat AgentTuning enables LLMs' agent capabilities without compromising general\nabilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent\ntasks, demonstrating generalized agent capabilities. We open source the\nAgentInstruct and AgentLM-7B, 13B, and 70B models at\nhttps://github.com/THUDM/AgentTuning, serving open and powerful alternatives to\ncommercial LLMs for agent tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1\">Aohan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Mingdao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_R/0/1/0/all/0/1\">Rui Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Bowen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1\">Jie Tang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"StoryAnalogy: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding. (arXiv:2310.12874v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12874","description":"<p>Analogy-making between narratives is crucial for human reasoning. In this\npaper, we evaluate the ability to identify and generate analogies by\nconstructing a first-of-its-kind large-scale story-level analogy corpus,\n\\textsc{StoryAnalogy}, which contains 24K story pairs from diverse domains with\nhuman annotations on two similarities from the extended Structure-Mapping\nTheory. We design a set of tests on \\textsc{StoryAnalogy}, presenting the first\nevaluation of story-level analogy identification and generation. Interestingly,\nwe find that the analogy identification tasks are incredibly difficult not only\nfor sentence embedding models but also for the recent large language models\n(LLMs) such as ChatGPT and LLaMa. ChatGPT, for example, only achieved around\n30% accuracy in multiple-choice questions (compared to over 85% accuracy for\nhumans). Furthermore, we observe that the data in \\textsc{StoryAnalogy} can\nimprove the quality of analogy generation in LLMs, where a fine-tuned\nFlanT5-xxl model achieves comparable performance to zero-shot ChatGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiayang_C/0/1/0/all/0/1\">Cheng Jiayang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1\">Lin Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1\">Tsz Ho Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_T/0/1/0/all/0/1\">Tianqing Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1\">Weiqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chan_C/0/1/0/all/0/1\">Chunkit Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ru_D/0/1/0/all/0/1\">Dongyu Ru</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hongming Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yangqiu Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models. (arXiv:2310.12936v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12936","description":"<p>Various types of social biases have been reported with pretrained Masked\nLanguage Models (MLMs) in prior work. However, multiple underlying factors are\nassociated with an MLM such as its model size, size of the training data,\ntraining objectives, the domain from which pretraining data is sampled,\ntokenization, and languages present in the pretrained corpora, to name a few.\nIt remains unclear as to which of those factors influence social biases that\nare learned by MLMs. To study the relationship between model factors and the\nsocial biases learned by an MLM, as well as the downstream task performance of\nthe model, we conduct a comprehensive study over 39 pretrained MLMs covering\ndifferent model sizes, training objectives, tokenization methods, training data\ndomains and languages. Our results shed light on important factors often\nneglected in prior literature, such as tokenization or model objectives.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yi Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1\">Jose Camacho-Collados</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bollegala_D/0/1/0/all/0/1\">Danushka Bollegala</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Representational Capacity of Recurrent Neural Language Models. (arXiv:2310.12942v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.12942","description":"<p>This work investigates the computational expressivity of language models\n(LMs) based on recurrent neural networks (RNNs). Siegelmann and Sontag (1992)\nfamously showed that RNNs with rational weights and hidden states and unbounded\ncomputation time are Turing complete. However, LMs define weightings over\nstrings in addition to just (unweighted) language membership and the analysis\nof the computational power of RNN LMs (RLMs) should reflect this. We extend the\nTuring completeness result to the probabilistic case, showing how a rationally\nweighted RLM with unbounded computation time can simulate any probabilistic\nTuring machine (PTM). Since, in practice, RLMs work in real-time, processing a\nsymbol at every time step, we treat the above result as an upper bound on the\nexpressivity of RLMs. We also provide a lower bound by showing that under the\nrestriction to real-time computation, such models can simulate deterministic\nreal-time rational PTMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nowak_F/0/1/0/all/0/1\">Franz Nowak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svete_A/0/1/0/all/0/1\">Anej Svete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_L/0/1/0/all/0/1\">Li Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"H2O Open Ecosystem for State-of-the-art Large Language Models. (arXiv:2310.13012v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.13012","description":"<p>Large Language Models (LLMs) represent a revolution in AI. However, they also\npose many significant risks, such as the presence of biased, private,\ncopyrighted or harmful text. For this reason we need open, transparent and safe\nsolutions. We introduce a complete open-source ecosystem for developing and\ntesting LLMs. The goal of this project is to boost open alternatives to\nclosed-source approaches. We release h2oGPT, a family of fine-tuned LLMs of\ndiverse sizes. We also introduce H2O LLM Studio, a framework and no-code GUI\ndesigned for efficient fine-tuning, evaluation, and deployment of LLMs using\nthe most recent state-of-the-art techniques. Our code and models are fully\nopen-source. We believe this work helps to boost AI development and make it\nmore accessible, efficient and trustworthy. The demo is available at:\nhttps://gpt.h2o.ai/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Candel_A/0/1/0/all/0/1\">Arno Candel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McKinney_J/0/1/0/all/0/1\">Jon McKinney</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singer_P/0/1/0/all/0/1\">Philipp Singer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_P/0/1/0/all/0/1\">Pascal Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jeblick_M/0/1/0/all/0/1\">Maximilian Jeblick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1\">Chun Ming Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conde_M/0/1/0/all/0/1\">Marcos V. Conde</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"HiGitClass: Keyword-Driven Hierarchical Classification of GitHub Repositories. (arXiv:1910.07115v2 [cs.LG] CROSS LISTED)","link":"http://arxiv.org/abs/1910.07115","description":"<p>GitHub has become an important platform for code sharing and scientific\nexchange. With the massive number of repositories available, there is a\npressing need for topic-based search. Even though the topic label functionality\nhas been introduced, the majority of GitHub repositories do not have any\nlabels, impeding the utility of search and topic-based analysis. This work\ntargets the automatic repository classification problem as keyword-driven\nhierarchical classification. Specifically, users only need to provide a label\nhierarchy with keywords to supply as supervision. This setting is flexible,\nadaptive to the users' needs, accounts for the different granularity of topic\nlabels and requires minimal human effort. We identify three key challenges of\nthis problem, namely (1) the presence of multi-modal signals; (2) supervision\nscarcity and bias; (3) supervision format mismatch. In recognition of these\nchallenges, we propose the HiGitClass framework, comprising of three modules:\nheterogeneous information network embedding; keyword enrichment; topic modeling\nand pseudo document generation. Experimental results on two GitHub repository\ncollections confirm that HiGitClass is superior to existing weakly-supervised\nand dataless hierarchical classification methods, especially in its ability to\nintegrate both structured and unstructured data for repository classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Frank F. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Sha Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Minimally Supervised Categorization of Text with Metadata. (arXiv:2005.00624v3 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2005.00624","description":"<p>Document categorization, which aims to assign a topic label to each document,\nplays a fundamental role in a wide variety of applications. Despite the success\nof existing studies in conventional supervised document classification, they\nare less concerned with two real problems: (1) the presence of metadata: in\nmany domains, text is accompanied by various additional information such as\nauthors and tags. Such metadata serve as compelling topic indicators and should\nbe leveraged into the categorization framework; (2) label scarcity: labeled\ntraining samples are expensive to obtain in some cases, where categorization\nneeds to be performed using only a small set of annotated data. In recognition\nof these two challenges, we propose MetaCat, a minimally supervised framework\nto categorize text with metadata. Specifically, we develop a generative process\ndescribing the relationships between words, documents, labels, and metadata.\nGuided by the generative model, we embed text and metadata into the same\nsemantic space to encode heterogeneous signals. Then, based on the same\ngenerative process, we synthesize training samples to address the bottleneck of\nlabel scarcity. We conduct a thorough evaluation on a wide range of datasets.\nExperimental results prove the effectiveness of MetaCat over many competitive\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1\">Jiaxin Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1\">Frank F. Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hierarchical Metadata-Aware Document Categorization under Weak Supervision. (arXiv:2010.13556v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2010.13556","description":"<p>Categorizing documents into a given label hierarchy is intuitively appealing\ndue to the ubiquity of hierarchical topic structures in massive text corpora.\nAlthough related studies have achieved satisfying performance in fully\nsupervised hierarchical document classification, they usually require massive\nhuman-annotated training data and only utilize text information. However, in\nmany domains, (1) annotations are quite expensive where very few training\nsamples can be acquired; (2) documents are accompanied by metadata information.\nHence, this paper studies how to integrate the label hierarchy, metadata, and\ntext signals for document categorization under weak supervision. We develop\nHiMeCat, an embedding-based generative framework for our task. Specifically, we\npropose a novel joint representation learning module that allows simultaneous\nmodeling of category dependencies, metadata information and textual semantics,\nand we introduce a data augmentation module that hierarchically synthesizes\ntraining documents to complement the original, small-scale training set. Our\nexperiments demonstrate a consistent improvement of HiMeCat over competitive\nbaselines and validate the contribution of our representation learning and data\naugmentation modules.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MATCH: Metadata-Aware Text Classification in A Large Hierarchy. (arXiv:2102.07349v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2102.07349","description":"<p>Multi-label text classification refers to the problem of assigning each given\ndocument its most relevant labels from the label set. Commonly, the metadata of\nthe given documents and the hierarchy of the labels are available in real-world\napplications. However, most existing studies focus on only modeling the text\ninformation, with a few attempts to utilize either metadata or hierarchy\nsignals, but not both of them. In this paper, we bridge the gap by formalizing\nthe problem of metadata-aware text classification in a large label hierarchy\n(e.g., with tens of thousands of labels). To address this problem, we present\nthe MATCH solution -- an end-to-end framework that leverages both metadata and\nhierarchy information. To incorporate metadata, we pre-train the embeddings of\ntext and metadata in the same space and also leverage the fully-connected\nattentions to capture the interrelations between them. To leverage the label\nhierarchy, we propose different ways to regularize the parameters and output\nprobability of each child label by its parents. Extensive experiments on two\nmassive text datasets with large-scale label hierarchies demonstrate the\neffectiveness of MATCH over state-of-the-art deep learning baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhihong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1\">Yuxiao Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kuansan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MotifClass: Weakly Supervised Text Classification with Higher-order Metadata Information. (arXiv:2111.04022v3 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2111.04022","description":"<p>We study the problem of weakly supervised text classification, which aims to\nclassify text documents into a set of pre-defined categories with category\nsurface names only and without any annotated training document provided. Most\nexisting classifiers leverage textual information in each document. However, in\nmany domains, documents are accompanied by various types of metadata (e.g.,\nauthors, venue, and year of a research paper). These metadata and their\ncombinations may serve as strong category indicators in addition to textual\ncontents. In this paper, we explore the potential of using metadata to help\nweakly supervised text classification. To be specific, we model the\nrelationships between documents and metadata via a heterogeneous information\nnetwork. To effectively capture higher-order structures in the network, we use\nmotifs to describe metadata combinations. We propose a novel framework, named\nMotifClass, which (1) selects category-indicative motif instances, (2)\nretrieves and generates pseudo-labeled training samples based on category names\nand indicative motif instances, and (3) trains a text classifier using the\npseudo training data. Extensive experiments on real-world datasets demonstrate\nthe superior performance of MotifClass to existing weakly supervised text\nclassification approaches. Further analysis shows the benefit of considering\nhigher-order metadata information in our framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1\">Shweta Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RATE: Overcoming Noise and Sparsity of Textual Features in Real-Time Location Estimation. (arXiv:2111.06515v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2111.06515","description":"<p>Real-time location inference of social media users is the fundamental of some\nspatial applications such as localized search and event detection. While tweet\ntext is the most commonly used feature in location estimation, most of the\nprior works suffer from either the noise or the sparsity of textual features.\nIn this paper, we aim to tackle these two problems. We use topic modeling as a\nbuilding block to characterize the geographic topic variation and lexical\nvariation so that \"one-hot\" encoding vectors will no longer be directly used.\nWe also incorporate other features which can be extracted through the Twitter\nstreaming API to overcome the noise problem. Experimental results show that our\nRATE algorithm outperforms several benchmark methods, both in the precision of\nregion classification and the mean distance error of latitude and longitude\nregression.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1\">Wei Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1\">Binxuan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carley_K/0/1/0/all/0/1\">Kathleen M. Carley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yan Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Metadata-Induced Contrastive Learning for Zero-Shot Multi-Label Text Classification. (arXiv:2202.05932v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2202.05932","description":"<p>Large-scale multi-label text classification (LMTC) aims to associate a\ndocument with its relevant labels from a large candidate set. Most existing\nLMTC approaches rely on massive human-annotated training data, which are often\ncostly to obtain and suffer from a long-tailed label distribution (i.e., many\nlabels occur only a few times in the training set). In this paper, we study\nLMTC under the zero-shot setting, which does not require any annotated\ndocuments with labels and only relies on label surface names and descriptions.\nTo train a classifier that calculates the similarity score between a document\nand a label, we propose a novel metadata-induced contrastive learning (MICoL)\nmethod. Different from previous text-based contrastive learning techniques,\nMICoL exploits document metadata (e.g., authors, venues, and references of\nresearch papers), which are widely available on the Web, to derive similar\ndocument-document pairs. Experimental results on two large-scale datasets show\nthat: (1) MICoL significantly outperforms strong zero-shot text classification\nand contrastive learning baselines; (2) MICoL is on par with the\nstate-of-the-art supervised metadata-aware LMTC method trained on 10K-200K\nlabeled documents; and (3) MICoL tends to predict more infrequent labels than\nsupervised methods, thus alleviates the deteriorated performance on long-tailed\nlabels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhihong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chieh-Han Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_B/0/1/0/all/0/1\">Boya Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1\">Junheng Hao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye-Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1\">Kuansan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Seed-Guided Topic Discovery with Out-of-Vocabulary Seeds. (arXiv:2205.01845v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2205.01845","description":"<p>Discovering latent topics from text corpora has been studied for decades.\nMany existing topic models adopt a fully unsupervised setting, and their\ndiscovered topics may not cater to users' particular interests due to their\ninability of leveraging user guidance. Although there exist seed-guided topic\ndiscovery approaches that leverage user-provided seeds to discover\ntopic-representative terms, they are less concerned with two factors: (1) the\nexistence of out-of-vocabulary seeds and (2) the power of pre-trained language\nmodels (PLMs). In this paper, we generalize the task of seed-guided topic\ndiscovery to allow out-of-vocabulary seeds. We propose a novel framework, named\nSeeTopic, wherein the general knowledge of PLMs and the local semantics learned\nfrom the input corpus can mutually benefit each other. Experiments on three\nreal datasets from different domains demonstrate the effectiveness of SeeTopic\nin terms of topic coherence, accuracy, and diversity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Sheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Effect of Metadata on Scientific Literature Tagging: A Cross-Field Cross-Model Study. (arXiv:2302.03341v1 [cs.DL] CROSS LISTED)","link":"http://arxiv.org/abs/2302.03341","description":"<p>Due to the exponential growth of scientific publications on the Web, there is\na pressing need to tag each paper with fine-grained topics so that researchers\ncan track their interested fields of study rather than drowning in the whole\nliterature. Scientific literature tagging is beyond a pure multi-label text\nclassification task because papers on the Web are prevalently accompanied by\nmetadata information such as venues, authors, and references, which may serve\nas additional signals to infer relevant tags. Although there have been studies\nmaking use of metadata in academic paper classification, their focus is often\nrestricted to one or two scientific fields (e.g., computer science and\nbiomedicine) and to one specific model. In this work, we systematically study\nthe effect of metadata on scientific literature tagging across 19 fields. We\nselect three representative multi-label classifiers (i.e., a bag-of-words\nmodel, a sequence-based model, and a pre-trained language model) and explore\ntheir performance change in scientific literature tagging when metadata are fed\nto the classifiers as additional features. We observe some ubiquitous patterns\nof metadata's effects across all fields (e.g., venues are consistently\nbeneficial to paper tagging in almost all cases), as well as some unique\npatterns in fields other than computer science and biomedicine, which are not\nexplored in previous studies.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bowen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1\">Qi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pre-training Multi-task Contrastive Learning Models for Scientific Literature Understanding. (arXiv:2305.14232v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2305.14232","description":"<p>Scientific literature understanding tasks have gained significant attention\ndue to their potential to accelerate scientific discovery. Pre-trained language\nmodels (LMs) have shown effectiveness in these tasks, especially when tuned via\ncontrastive learning. However, jointly utilizing pre-training data across\nmultiple heterogeneous tasks (e.g., extreme multi-label paper classification,\ncitation prediction, and literature search) remains largely unexplored. To\nbridge this gap, we propose a multi-task contrastive learning framework,\nSciMult, with a focus on facilitating common knowledge sharing across different\nscientific literature understanding tasks while preventing task-specific skills\nfrom interfering with each other. To be specific, we explore two techniques --\ntask-aware specialization and instruction tuning. The former adopts a\nMixture-of-Experts Transformer architecture with task-aware sub-layers; the\nlatter prepends task-specific instructions to the input text so as to produce\ntask-aware outputs. Extensive experiments on a comprehensive collection of\nbenchmark datasets verify the effectiveness of our task-aware specialization\nstrategy, where we outperform state-of-the-art scientific pre-trained LMs.\nCode, datasets, and pre-trained models can be found at\nhttps://scimult.github.io/.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1\">Hao Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1\">Zhihong Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1\">Xiaodong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Ye-Yi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Weakly Supervised Multi-Label Classification of Full-Text Scientific Papers. (arXiv:2306.14003v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2306.14003","description":"<p>Instead of relying on human-annotated training samples to build a classifier,\nweakly supervised scientific paper classification aims to classify papers only\nusing category descriptions (e.g., category names, category-indicative\nkeywords). Existing studies on weakly supervised paper classification are less\nconcerned with two challenges: (1) Papers should be classified into not only\ncoarse-grained research topics but also fine-grained themes, and potentially\ninto multiple themes, given a large and fine-grained label space; and (2) full\ntext should be utilized to complement the paper title and abstract for\nclassification. Moreover, instead of viewing the entire paper as a long linear\nsequence, one should exploit the structural information such as citation links\nacross papers and the hierarchy of sections and paragraphs in each paper. To\ntackle these challenges, in this study, we propose FUTEX, a framework that uses\nthe cross-paper network structure and the in-paper hierarchy structure to\nclassify full-text scientific papers under weak supervision. A network-aware\ncontrastive fine-tuning module and a hierarchy-aware aggregation module are\ndesigned to leverage the two types of structural signals, respectively.\nExperiments on two benchmark datasets demonstrate that FUTEX significantly\noutperforms competitive baselines and is on par with fully supervised\nclassifiers that use 1,000 to 60,000 ground-truth training samples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1\">Bowen Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiusi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1\">Yanzhen Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yunyi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-10-23T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/"}}]}]}