{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-01-16T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Inaccessible Neural Language Models Could Reinvigorate Linguistic Nativism. (arXiv:2301.05272v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05272","description":"<p>Large Language Models (LLMs) have been making big waves in the machine\nlearning community within the past few years. The impressive scalability of\nLLMs due to the advent of deep learning can be seen as a continuation of\nempiricist lingusitic methods, as opposed to rule-based linguistic methods that\nare grounded in a nativist perspective. Current LLMs are generally inaccessible\nto resource-constrained researchers, due to a variety of factors including\nclosed source code. This work argues that this lack of accessibility could\ninstill a nativist bias in researchers new to computational linguistics, given\nthat new researchers may only have rule-based, nativist approaches to study to\nproduce new work. Also, given that there are numerous critics of deep learning\nclaiming that LLMs and related methods may soon lose their relevancy, we\nspeculate that such an event could trigger a new wave of nativism in the\nlanguage processing community. To prevent such a dramatic shift and placing\nfavor in hybrid methods of rules and deep learning, we call upon researchers to\nopen source their LLM code wherever possible to allow both empircist and hybrid\napproaches to remain accessible.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Perrine_P/0/1/0/all/0/1\">Patrick Perrine</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Blind Judgement: Agent-Based Supreme Court Modelling With GPT. (arXiv:2301.05327v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05327","description":"<p>We present a novel Transformer-based multi-agent system for simulating the\njudicial rulings of the 2010-2016 Supreme Court of the United States. We train\nnine separate models with the respective authored opinions of each supreme\njustice active ca. 2015 and test the resulting system on 96 real-world cases.\nWe find our system predicts the decisions of the real-world Supreme Court with\nbetter-than-random accuracy. We further find a correlation between model\naccuracy with respect to individual justices and their alignment between legal\nconservatism &amp; liberalism. Our methods and results hold significance for\nresearchers interested in using language models to simulate politically-charged\ndiscourse between multiple agents.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hamilton_S/0/1/0/all/0/1\">Sil Hamilton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting Neural Machine Translation with Translation Memories. (arXiv:2301.05380v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05380","description":"<p>Improving machine translation (MT) systems with translation memories (TMs) is\nof great interest to practitioners in the MT community. However, previous\napproaches require either a significant update of the model architecture and/or\nadditional training efforts to make the models well-behaved when TMs are taken\nas additional input. In this paper, we present a simple but effective method to\nintroduce TMs into neural machine translation (NMT) systems. Specifically, we\ntreat TMs as prompts to the NMT model at test time, but leave the training\nprocess unchanged. The result is a slight update of an existing NMT system,\nwhich can be implemented in a few hours by anyone who is familiar with NMT.\nExperimental results on several datasets demonstrate that our system\nsignificantly outperforms strong baselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Reheman_A/0/1/0/all/0/1\">Abudurexiti Reheman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1\">Tao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yingfeng Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Di Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Tong Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1\">Jingbo Zhu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MaNLP@SMM4H22: BERT for Classification of Twitter Posts. (arXiv:2301.05395v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05395","description":"<p>The reported work is our straightforward approach for the shared task\nClassification of tweets self-reporting age organized by the Social Media\nMining for Health Applications (SMM4H) workshop. This literature describes the\napproach that was used to build a binary classification system, that classifies\nthe tweets related to birthday posts into two classes namely, exact\nage(positive class) and non-exact age(negative class). We made two submissions\nwith variations in the preprocessing of text which yielded F1 scores of 0.80\nand 0.81 when evaluated by the organizers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kapur_K/0/1/0/all/0/1\">Keshav Kapur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harikrishnan_R/0/1/0/all/0/1\">Rajitha Harikrishnan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"In BLOOM: Creativity and Affinity in Artificial Lyrics and Art. (arXiv:2301.05402v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05402","description":"<p>We apply a large multilingual language model (BLOOM-176B) in open-ended\ngeneration of Chinese song lyrics, and evaluate the resulting lyrics for\ncoherence and creativity using human reviewers. We find that current\ncomputational metrics for evaluating large language model outputs (MAUVE) have\nlimitations in evaluation of creative writing. We note that the human concept\nof creativity requires lyrics to be both comprehensible and distinctive -- and\nthat humans assess certain types of machine-generated lyrics to score more\nhighly than real lyrics by popular artists. Inspired by the inherently\nmultimodal nature of album releases, we leverage a Chinese-language stable\ndiffusion model to produce high-quality lyric-guided album art, demonstrating a\ncreative approach for an artist seeking inspiration for an album or single.\nFinally, we introduce the MojimLyrics dataset, a Chinese-language dataset of\npopular song lyrics for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Crothers_E/0/1/0/all/0/1\">Evan Crothers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Viktor_H/0/1/0/all/0/1\">Herna Viktor</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1\">Nathalie Japkowicz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"It's Just a Matter of Time: Detecting Depression with Time-Enriched Multimodal Transformers. (arXiv:2301.05453v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05453","description":"<p>Depression detection from user-generated content on the internet has been a\nlong-lasting topic of interest in the research community, providing valuable\nscreening tools for psychologists. The ubiquitous use of social media platforms\nlays out the perfect avenue for exploring mental health manifestations in posts\nand interactions with other users. Current methods for depression detection\nfrom social media mainly focus on text processing, and only a few also utilize\nimages posted by users. In this work, we propose a flexible time-enriched\nmultimodal transformer architecture for detecting depression from social media\nposts, using pretrained models for extracting image and text embeddings. Our\nmodel operates directly at the user-level, and we enrich it with the relative\ntime between posts by using time2vec positional embeddings. Moreover, we\npropose another model variant, which can operate on randomly sampled and\nunordered sets of posts to be more robust to dataset noise. We show that our\nmethod, using EmoBERTa and CLIP embeddings, surpasses other methods on two\nmultimodal datasets, obtaining state-of-the-art results of 0.931 F1 score on a\npopular multimodal Twitter dataset, and 0.902 F1 score on the only multimodal\nReddit dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bucur_A/0/1/0/all/0/1\">Ana-Maria Bucur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1\">Adrian Cosma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosso_P/0/1/0/all/0/1\">Paolo Rosso</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinu_L/0/1/0/all/0/1\">Liviu P. Dinu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Structuring ontologies in a context of collaborative system modelling. (arXiv:2301.05478v1 [cs.AI])","link":"http://arxiv.org/abs/2301.05478","description":"<p>Prospective studies require discussing and collaborating with the\nstakeholders to create scenarios of the possible evolution of the studied\nvalue-chain. However, stakeholders don't always use the same words when\nreferring to one idea. Constructing an ontology and homogenizing vocabularies\nis thus crucial to identify key variables which serve in the construction of\nthe needed scenarios. Nevertheless, it is a very complex and timeconsuming\ntask. In this paper we present the method we used to manually build ontologies\nadapted to the needs of two complementary system-analysis models (namely the\n\"Godet\" and the \"MyChoice\" models), starting from interviews of the agri-food\nsystem's stakeholders.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chaib_R/0/1/0/all/0/1\">Romy Lynn Chaib</a> (INRAE), <a href=\"http://arxiv.org/find/cs/1/au:+Thomopoulos_R/0/1/0/all/0/1\">Rallou Thomopoulos</a> (INRAE), <a href=\"http://arxiv.org/find/cs/1/au:+Macombe_C/0/1/0/all/0/1\">Catherine Macombe</a> (INRAE)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Generalization of Adapter-Based Cross-lingual Transfer with Scheduled Unfreezing. (arXiv:2301.05487v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05487","description":"<p>Standard fine-tuning of language models typically performs well on\nin-distribution data, but suffers with generalization to distribution shifts.\nIn this work, we aim to improve generalization of adapter-based cross-lingual\ntask transfer where such cross-language distribution shifts are imminent. We\ninvestigate scheduled unfreezing algorithms -- originally proposed to mitigate\ncatastrophic forgetting in transfer learning -- for fine-tuning task adapters\nin cross-lingual transfer. Our experiments show that scheduled unfreezing\nmethods close the gap to full fine-tuning and achieve state-of-the-art transfer\nperformance, suggesting that these methods can go beyond just mitigating\ncatastrophic forgetting. Next, aiming to delve deeper into those empirical\nfindings, we investigate the learning dynamics of scheduled unfreezing using\nFisher Information. Our in-depth experiments reveal that scheduled unfreezing\ninduces different learning dynamics compared to standard fine-tuning, and\nprovide evidence that the dynamics of Fisher Information during training\ncorrelate with cross-lingual generalization performance. We additionally\npropose a general scheduled unfreezing algorithm that achieves an average of 2\npoints improvement over four datasets compared to standard fine-tuning and\nprovides strong empirical evidence for a theory-based justification of the\nheuristic unfreezing schedule (i.e., the heuristic schedule is implicitly\nmaximizing Fisher Information). Our code will be publicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Chen Cecilia Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pfeiffer_J/0/1/0/all/0/1\">Jonas Pfeiffer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1\">Ivan Vuli&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1\">Iryna Gurevych</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Detection of Check-Worthy Claims using World Languages and Adapter Fusion. (arXiv:2301.05494v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05494","description":"<p>Check-worthiness detection is the task of identifying claims, worthy to be\ninvestigated by fact-checkers. Resource scarcity for non-world languages and\nmodel learning costs remain major challenges for the creation of models\nsupporting multilingual check-worthiness detection. This paper proposes\ncross-training adapters on a subset of world languages, combined by adapter\nfusion, to detect claims emerging globally in multiple languages. (1) With a\nvast number of annotators available for world languages and the\nstorage-efficient adapter models, this approach is more cost efficient. Models\ncan be updated more frequently and thus stay up-to-date. (2) Adapter fusion\nprovides insights and allows for interpretation regarding the influence of each\nadapter model on a particular language. The proposed solution often\noutperformed the top multilingual approaches in our benchmark tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schlicht_I/0/1/0/all/0/1\">Ipek Baris Schlicht</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Flek_L/0/1/0/all/0/1\">Lucie Flek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosso_P/0/1/0/all/0/1\">Paolo Rosso</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Classification of Cross-cultural News Events. (arXiv:2301.05543v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05543","description":"<p>We present a methodology to support the analysis of culture from text such as\nnews events and demonstrate its usefulness on categorizing news events from\ndifferent categories (society, business, health, recreation, science, shopping,\nsports, arts, computers, games and home) across different geographical\nlocations (different places in 117 countries). We group countries based on the\nculture that they follow and then filter the news events based on their content\ncategory. The news events are automatically labelled with the help of Hofstedes\ncultural dimensions. We present combinations of events across different\ncategories and check the performances of different classification methods. We\nalso presents experimental comparison of different number of features in order\nto find a suitable set to represent the culture.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sittar_A/0/1/0/all/0/1\">Abdul Sittar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1\">Dunja Mladenic</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multilingual Alzheimer's Dementia Recognition through Spontaneous Speech: a Signal Processing Grand Challenge. (arXiv:2301.05562v1 [eess.AS])","link":"http://arxiv.org/abs/2301.05562","description":"<p>This Signal Processing Grand Challenge (SPGC) targets a difficult automatic\nprediction problem of societal and medical relevance, namely, the detection of\nAlzheimer's Dementia (AD). Participants were invited to employ signal\nprocessing and machine learning methods to create predictive models based on\nspontaneous speech data. The Challenge has been designed to assess the extent\nto which predictive models built based on speech in one language (English)\ngeneralise to another language (Greek). To the best of our knowledge no work\nhas investigated acoustic features of the speech signal in multilingual AD\ndetection. Our baseline system used conventional machine learning algorithms\nwith Active Data Representation of acoustic features, achieving accuracy of\n73.91% on AD detection, and 4.95 root mean squared error on cognitive score\nprediction.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Luz_S/0/1/0/all/0/1\">Saturnino Luz</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Haider_F/0/1/0/all/0/1\">Fasih Haider</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Fromm_D/0/1/0/all/0/1\">Davida Fromm</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lazarou_I/0/1/0/all/0/1\">Ioulietta Lazarou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Kompatsiaris_I/0/1/0/all/0/1\">Ioannis Kompatsiaris</a>, <a href=\"http://arxiv.org/find/eess/1/au:+MacWhinney_B/0/1/0/all/0/1\">Brian MacWhinney</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The 2022 n2c2/UW Shared Task on Extracting Social Determinants of Health. (arXiv:2301.05571v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05571","description":"<p>Objective: The n2c2/UW SDOH Challenge explores the extraction of social\ndeterminant of health (SDOH) information from clinical notes. The objectives\ninclude the advancement of natural language processing (NLP) information\nextraction techniques for SDOH and clinical information more broadly. This\npaper presents the shared task, data, participating teams, performance results,\nand considerations for future work.\n</p>\n<p>Materials and Methods: The task used the Social History Annotated Corpus\n(SHAC), which consists of clinical text with detailed event-based annotations\nfor SDOH events such as alcohol, drug, tobacco, employment, and living\nsituation. Each SDOH event is characterized through attributes related to\nstatus, extent, and temporality. The task includes three subtasks related to\ninformation extraction (Subtask A), generalizability (Subtask B), and learning\ntransfer (Subtask C). In addressing this task, participants utilized a range of\ntechniques, including rules, knowledge bases, n-grams, word embeddings, and\npretrained language models (LM).\n</p>\n<p>Results: A total of 15 teams participated, and the top teams utilized\npretrained deep learning LM. The top team across all subtasks used a\nsequence-to-sequence approach achieving 0.901 F1 for Subtask A, 0.774 F1\nSubtask B, and 0.889 F1 for Subtask C.\n</p>\n<p>Conclusions: Similar to many NLP tasks and domains, pretrained LM yielded the\nbest performance, including generalizability and learning transfer. An error\nanalysis indicates extraction performance varies by SDOH, with lower\nperformance achieved for conditions, like substance use and homelessness, that\nincrease health risks (risk factors) and higher performance achieved for\nconditions, like substance abstinence and living with family, that reduce\nhealth risks (protective factors).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lybarger_K/0/1/0/all/0/1\">Kevin Lybarger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1\">Meliha Yetisgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uzuner_O/0/1/0/all/0/1\">&#xd6;zlem Uzuner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From stage to page: language independent bootstrap measures of distinctiveness in fictional speech. (arXiv:2301.05659v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05659","description":"<p>Stylometry is mostly applied to authorial style. Recently, researchers have\nbegun investigating the style of characters, finding that the variation remains\nwithin authorial bounds. We address the stylistic distinctiveness of characters\nin drama. Our primary contribution is methodological; we introduce and evaluate\ntwo non-parametric methods to produce a summary statistic for character\ndistinctiveness that can be usefully applied and compared across languages and\ntimes. Our first method is based on bootstrap distances between 3-gram\nprobability distributions, the second (reminiscent of 'unmasking' techniques)\non word keyness curves. Both methods are validated and explored by applying\nthem to a reasonably large corpus (a subset of DraCor): we analyse 3301\ncharacters drawn from 2324 works, covering five centuries and four languages\n(French, German, Russian, and the works of Shakespeare). Both methods appear\nuseful; the 3-gram method is statistically more powerful but the word keyness\nmethod offers rich interpretability. Both methods are able to capture\nphonological differences such as accent or dialect, as well as broad\ndifferences in topic and lexical richness. Based on exploratory analysis, we\nfind that smaller characters tend to be more distinctive, and that women are\ncross-linguistically more distinctive than men, with this latter finding\ncarefully interrogated using multiple regression. This greater distinctiveness\nstems from a historical tendency for female characters to be restricted to an\n'internal narrative domain' covering mainly direct discourse and\nfamily/romantic themes. It is hoped that direct, comparable statistical\nmeasures will form a basis for more sophisticated future studies, and advances\nin theory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sela_A/0/1/0/all/0/1\">Artjoms &#x160;e&#x13c;a</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nagy_B/0/1/0/all/0/1\">Ben Nagy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Byszuk_J/0/1/0/all/0/1\">Joanna Byszuk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hernandez_Lorenzo_L/0/1/0/all/0/1\">Laura Hern&#xe1;ndez-Lorenzo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szemes_B/0/1/0/all/0/1\">Botond Szemes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Eder_M/0/1/0/all/0/1\">Maciej Eder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Natural Language Processing of Aviation Occurrence Reports for Safety Management. (arXiv:2301.05663v1 [cs.CL])","link":"http://arxiv.org/abs/2301.05663","description":"<p>Occurrence reporting is a commonly used method in safety management systems\nto obtain insight in the prevalence of hazards and accident scenarios. In\nsupport of safety data analysis, reports are often categorized according to a\ntaxonomy. However, the processing of the reports can require significant effort\nfrom safety analysts and a common problem is interrater variability in labeling\nprocesses. Also, in some cases, reports are not processed according to a\ntaxonomy, or the taxonomy does not fully cover the contents of the documents.\nThis paper explores various Natural Language Processing (NLP) methods to\nsupport the analysis of aviation safety occurrence reports. In particular, the\nproblems studied are the automatic labeling of reports using a classification\nmodel, extracting the latent topics in a collection of texts using a topic\nmodel and the automatic generation of probable cause texts. Experimental\nresults showed that (i) under the right conditions the labeling of occurrence\nreports can be effectively automated with a transformer-based classifier, (ii)\ntopic modeling can be useful for finding the topics present in a collection of\nreports, and (iii) using a summarization model can be a promising direction for\ngenerating probable cause texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jonk_P/0/1/0/all/0/1\">Patrick Jonk</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_V/0/1/0/all/0/1\">Vincent de Vries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wever_R/0/1/0/all/0/1\">Rombout Wever</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sidiropoulos_G/0/1/0/all/0/1\">Georgios Sidiropoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1\">Evangelos Kanoulas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"TI-CNN: Convolutional Neural Networks for Fake News Detection. (arXiv:1806.00749v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/1806.00749","description":"<p>With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1\">Lei Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiawei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_Q/0/1/0/all/0/1\">Qingcai Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhoujun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Locating and Editing Factual Associations in GPT. (arXiv:2202.05262v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.05262","description":"<p>We analyze the storage and recall of factual associations in autoregressive\ntransformer language models, finding evidence that these associations\ncorrespond to localized, directly-editable computations. We first develop a\ncausal intervention for identifying neuron activations that are decisive in a\nmodel's factual predictions. This reveals a distinct set of steps in\nmiddle-layer feed-forward modules that mediate factual predictions while\nprocessing subject tokens. To test our hypothesis that these computations\ncorrespond to factual association recall, we modify feed-forward weights to\nupdate specific factual associations using Rank-One Model Editing (ROME). We\nfind that ROME is effective on a standard zero-shot relation extraction (zsRE)\nmodel-editing task, comparable to existing methods. To perform a more sensitive\nevaluation, we also evaluate ROME on a new dataset of counterfactual\nassertions, on which it simultaneously maintains both specificity and\ngeneralization, whereas other methods sacrifice one or another. Our results\nconfirm an important role for mid-layer feed-forward modules in storing factual\nassociations and suggest that direct manipulation of computational mechanisms\nmay be a feasible approach for model editing. The code, dataset,\nvisualizations, and an interactive demo notebook are available at\nhttps://rome.baulab.info/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Meng_K/0/1/0/all/0/1\">Kevin Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1\">David Bau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andonian_A/0/1/0/all/0/1\">Alex Andonian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Belinkov_Y/0/1/0/all/0/1\">Yonatan Belinkov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Personalized Prompt Learning for Explainable Recommendation. (arXiv:2202.07371v2 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2202.07371","description":"<p>Providing user-understandable explanations to justify recommendations could\nhelp users better understand the recommended items, increase the system's ease\nof use, and gain users' trust. A typical approach to realize it is natural\nlanguage generation. However, previous works mostly adopt recurrent neural\nnetworks to meet the ends, leaving the potentially more effective pre-trained\nTransformer models under-explored. In fact, user and item IDs, as important\nidentifiers in recommender systems, are inherently in different semantic space\nas words that pre-trained models were already trained on. Thus, how to\neffectively fuse IDs into such models becomes a critical issue. Inspired by\nrecent advancement in prompt learning, we come up with two solutions: find\nalternative words to represent IDs (called discrete prompt learning), and\ndirectly input ID vectors to a pre-trained model (termed continuous prompt\nlearning). In the latter case, ID vectors are randomly initialized but the\nmodel is trained in advance on large corpora, so they are actually in different\nlearning stages. To bridge the gap, we further propose two training strategies:\nsequential tuning and recommendation as regularization. Extensive experiments\nshow that our continuous prompt learning approach equipped with the training\nstrategies consistently outperforms strong baselines on three datasets of\nexplainable recommendation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1\">Lei Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Li Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Memory Efficient Continual Learning with Transformers. (arXiv:2203.04640v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2203.04640","description":"<p>In many real-world scenarios, data to train machine learning models becomes\navailable over time. Unfortunately, these models struggle to continually learn\nnew concepts without forgetting what has been learnt in the past. This\nphenomenon is known as catastrophic forgetting and it is difficult to prevent\ndue to practical constraints. For instance, the amount of data that can be\nstored or the computational resources that can be used might be limited.\nMoreover, applications increasingly rely on large pre-trained neural networks,\nsuch as pre-trained Transformers, since the resources or data might not be\navailable in sufficiently large quantities to practitioners to train the model\nfrom scratch. In this paper, we devise a method to incrementally train a model\non a sequence of tasks using pre-trained Transformers and extending them with\nAdapters. Different than the existing approaches, our method is able to scale\nto a large number of tasks without significant overhead and allows sharing\ninformation across tasks. On both image and text classification tasks, we\nempirically demonstrate that our method maintains a good predictive performance\nwithout retraining the model or increasing the number of model parameters over\ntime. The resulting model is also significantly faster at inference time\ncompared to Adapter-based state-of-the-art methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ermis_B/0/1/0/all/0/1\">Beyza Ermis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zappella_G/0/1/0/all/0/1\">Giovanni Zappella</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1\">Martin Wistuba</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rawal_A/0/1/0/all/0/1\">Aditya Rawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Archambeau_C/0/1/0/all/0/1\">Cedric Archambeau</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What's in a Caption? Dataset-Specific Linguistic Diversity and Its Effect on Visual Description Models and Metrics. (arXiv:2205.06253v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2205.06253","description":"<p>While there have been significant gains in the field of automated video\ndescription, the generalization performance of automated description models to\nnovel domains remains a major barrier to using these systems in the real world.\nMost visual description methods are known to capture and exploit patterns in\nthe training data leading to evaluation metric increases, but what are those\npatterns? In this work, we examine several popular visual description datasets,\nand capture, analyze, and understand the dataset-specific linguistic patterns\nthat models exploit but do not generalize to new domains. At the token level,\nsample level, and dataset level, we find that caption diversity is a major\ndriving factor behind the generation of generic and uninformative captions. We\nfurther show that state-of-the-art models even outperform held-out ground truth\ncaptions on modern metrics, and that this effect is an artifact of linguistic\ndiversity in datasets. Understanding this linguistic diversity is key to\nbuilding strong captioning models, we recommend several methods and approaches\nfor maintaining diversity in the collection of new data, and dealing with the\nconsequences of limited diversity when using current models and metrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chan_D/0/1/0/all/0/1\">David M. Chan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Myers_A/0/1/0/all/0/1\">Austin Myers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vijayanarasimhan_S/0/1/0/all/0/1\">Sudheendra Vijayanarasimhan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ross_D/0/1/0/all/0/1\">David A. Ross</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Seybold_B/0/1/0/all/0/1\">Bryan Seybold</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Canny_J/0/1/0/all/0/1\">John F. Canny</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Near-Term Advances in Quantum Natural Language Processing. (arXiv:2206.02171v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2206.02171","description":"<p>This paper describes experiments showing that some tasks in natural language\nprocessing (NLP) can already be performed using quantum computers, though so\nfar only with small datasets.\n</p>\n<p>We demonstrate various approaches to topic classification. The first uses an\nexplicit word-based approach, in which word-topic scoring weights are\nimplemented as fractional rotations of individual qubit, and a new phrase is\nclassified based on the accumulation of these weights in a scoring qubit using\nentangling controlled-NOT gates. This is compared with more scalable quantum\nencodings of word embedding vectors, which are used in the computation of\nkernel values in a quantum support vector machine: this approach achieved an\naverage of 62% accuracy on classification tasks involving over 10000 words,\nwhich is the largest such quantum computing experiment to date.\n</p>\n<p>We describe a quantum probability approach to bigram modeling that can be\napplied to sequences of words and formal concepts, investigating a generative\napproximation to these distributions using a quantum circuit Born machine, and\nan approach to ambiguity resolution in verb-noun composition using single-qubit\nrotations for simple nouns and 2-qubit controlled-NOT gates for simple verbs.\n</p>\n<p>The smaller systems described have been run successfully on physical quantum\ncomputers, and the larger ones have been simulated. We show that statistically\nmeaningful results can be obtained using real datasets, but this is much more\ndifficult to predict than with easier artificial language examples used\npreviously in developing quantum NLP systems.\n</p>\n<p>Other approaches to quantum NLP are compared, partly with respect to\ncontemporary issues including informal language, fluency, and truthfulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Widdows_D/0/1/0/all/0/1\">Dominic Widdows</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_A/0/1/0/all/0/1\">Aaranya Alexander</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1\">Daiwei Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zimmerman_C/0/1/0/all/0/1\">Chase Zimmerman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Majumder_A/0/1/0/all/0/1\">Arunava Majumder</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Extracting Medication Changes in Clinical Narratives using Pre-trained Language Models. (arXiv:2208.08417v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.08417","description":"<p>An accurate and detailed account of patient medications, including medication\nchanges within the patient timeline, is essential for healthcare providers to\nprovide appropriate patient care. Healthcare providers or the patients\nthemselves may initiate changes to patient medication. Medication changes take\nmany forms, including prescribed medication and associated dosage modification.\nThese changes provide information about the overall health of the patient and\nthe rationale that led to the current care. Future care can then build on the\nresulting state of the patient. This work explores the automatic extraction of\nmedication change information from free-text clinical notes. The Contextual\nMedication Event Dataset (CMED) is a corpus of clinical notes with annotations\nthat characterize medication changes through multiple change-related\nattributes, including the type of change (start, stop, increase, etc.),\ninitiator of the change, temporality, change likelihood, and negation. Using\nCMED, we identify medication mentions in clinical text and propose three novel\nhigh-performing BERT-based systems that resolve the annotated medication change\ncharacteristics. We demonstrate that our proposed systems improve medication\nchange classification performance over the initial work exploring CMED.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ramachandran_G/0/1/0/all/0/1\">Giridhar Kaushik Ramachandran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lybarger_K/0/1/0/all/0/1\">Kevin Lybarger</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yaya Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahajan_D/0/1/0/all/0/1\">Diwakar Mahajan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1\">Jennifer J. Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsou_C/0/1/0/all/0/1\">Ching-Huei Tsou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1\">Meliha Yetisgen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Uzuner_O/0/1/0/all/0/1\">&#xd6;zlem Uzuner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adaptation of domain-specific transformer models with text oversampling for sentiment analysis of social media posts on Covid-19 vaccines. (arXiv:2209.10966v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.10966","description":"<p>Covid-19 has spread across the world and several vaccines have been developed\nto counter its surge. To identify the correct sentiments associated with the\nvaccines from social media posts, we fine-tune various state-of-the-art\npre-trained transformer models on tweets associated with Covid-19 vaccines.\nSpecifically, we use the recently introduced state-of-the-art pre-trained\ntransformer models RoBERTa, XLNet and BERT, and the domain-specific transformer\nmodels CT-BERT and BERTweet that are pre-trained on Covid-19 tweets. We further\nexplore the option of text augmentation by oversampling using Language Model\nbased Oversampling Technique (LMOTE) to improve the accuracies of these models,\nspecifically, for small sample datasets where there is an imbalanced class\ndistribution among the positive, negative and neutral sentiment classes. Our\nresults summarize our findings on the suitability of text oversampling for\nimbalanced small sample datasets that are used to fine-tune state-of-the-art\npre-trained transformer models, and the utility of domain-specific transformer\nmodels for the classification task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1\">Anmol Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choudhry_A/0/1/0/all/0/1\">Arjun Choudhry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Anubhav Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Susan_S/0/1/0/all/0/1\">Seba Susan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"BioGPT: Generative Pre-trained Transformer for Biomedical Text Generation and Mining. (arXiv:2210.10341v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.10341","description":"<p>Pre-trained language models have attracted increasing attention in the\nbiomedical domain, inspired by their great success in the general natural\nlanguage domain. Among the two main branches of pre-trained language models in\nthe general language domain, i.e., BERT (and its variants) and GPT (and its\nvariants), the first one has been extensively studied in the biomedical domain,\nsuch as BioBERT and PubMedBERT. While they have achieved great success on a\nvariety of discriminative downstream biomedical tasks, the lack of generation\nability constrains their application scope. In this paper, we propose BioGPT, a\ndomain-specific generative Transformer language model pre-trained on large\nscale biomedical literature. We evaluate BioGPT on six biomedical NLP tasks and\ndemonstrate that our model outperforms previous models on most tasks.\nEspecially, we get 44.98%, 38.42% and 40.76% F1 score on BC5CDR, KD-DTI and DDI\nend-to-end relation extraction tasks respectively, and 78.2% accuracy on\nPubMedQA, creating a new record. Our larger model BioGPT-Large achieves 81.0%\non PubMedQA. Our case study on text generation further demonstrates the\nadvantage of BioGPT on biomedical literature to generate fluent descriptions\nfor biomedical terms. Code is available at https://github.com/microsoft/BioGPT.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1\">Renqian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Liai Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yingce Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1\">Tao Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1\">Sheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1\">Hoifung Poon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tie-Yan Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Data Augmentation for Automated Essay Scoring using Transformer Models. (arXiv:2210.12809v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.12809","description":"<p>Automated essay scoring is one of the most important problem in Natural\nLanguage Processing. It has been explored for a number of years, and it remains\npartially solved. In addition to its economic and educational usefulness, it\npresents research problems. Transfer learning has proved to be beneficial in\nNLP. Data augmentation techniques have also helped build state-of-the-art\nmodels for automated essay scoring. Many works in the past have attempted to\nsolve this problem by using RNNs, LSTMs, etc. This work examines the\ntransformer models like BERT, RoBERTa, etc. We empirically demonstrate the\neffectiveness of transformer models and data augmentation for automated essay\ngrading across many topics using a single model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1\">Kshitij Gupta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A partial order view of message-passing communication models. (arXiv:2210.13062v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.13062","description":"<p>There is a wide variety of message-passing communication models, ranging from\nsynchronous ''rendez-vous'' communications to fully asynchronous/out-of-order\ncommunications. For large-scale distributed systems, the communication model is\ndetermined by the transport layer of the network, and a few classes of orders\nof message delivery (FIFO, causally ordered) have been identified in the early\ndays of distributed computing. For local-scale message-passing applications,\ne.g., running on a single machine, the communication model may be determined by\nthe actual implementation of message buffers and by how FIFO queues are used.\nWhile large-scale communication models, such as causal ordering, are defined by\nlogical axioms, local-scale models are often defined by an operational\nsemantics. In this work, we connect these two approaches, and we present a\nunified hierarchy of communication models encompassing both large-scale and\nlocal-scale models, based on their concurrent behaviors. We also show that all\nthe communication models we consider can be axiomatized in the monadic second\norder logic, and may therefore benefit from several bounded verification\ntechniques based on bounded special treewidth.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giusto_C/0/1/0/all/0/1\">Cinzia Di Giusto</a> (C&amp;A), <a href=\"http://arxiv.org/find/cs/1/au:+Ferre_D/0/1/0/all/0/1\">Davide Ferr&#xe9;</a> (C&amp;A), <a href=\"http://arxiv.org/find/cs/1/au:+Laversa_L/0/1/0/all/0/1\">Laetitia Laversa</a> (C&amp;A), <a href=\"http://arxiv.org/find/cs/1/au:+Lozes_E/0/1/0/all/0/1\">Etienne Lozes</a> (C&amp;A)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Corporate Lobbyists. (arXiv:2301.01181v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.01181","description":"<p>We demonstrate a proof-of-concept of a large language model conducting\ncorporate lobbying related activities. An autoregressive large language model\n(OpenAI's text-davinci-003) determines if proposed U.S. Congressional bills are\nrelevant to specific public companies and provides explanations and confidence\nlevels. For the bills the model deems as relevant, the model drafts a letter to\nthe sponsor of the bill in an attempt to persuade the congressperson to make\nchanges to the proposed legislation. We use hundreds of novel ground-truth\nlabels of the relevance of a bill to a company to benchmark the performance of\nthe model, which outperforms the baseline of predicting the most common outcome\nof irrelevance. We also benchmark the performance of the previous OpenAI GPT-3\nmodel (text-davinci-002), which was the state-of-the-art model on many academic\nnatural language tasks until text-davinci-003 was recently released. The\nperformance of text-davinci-002 is worse than a simple benchmark. These results\nsuggest that, as large language models continue to exhibit improved natural\nlanguage understanding capabilities, performance on corporate lobbying related\ntasks will continue to improve. Longer-term, if AI begins to influence law in a\nmanner that is not a direct extension of human intentions, this threatens the\ncritical role that law as information could play in aligning AI with humans.\nThis Essay explores how this is increasingly a possibility. Initially, AI is\nbeing used to simply augment human lobbyists for a small proportion of their\ndaily tasks. However, firms have an incentive to use less and less human\noversight over automated assessments of policy ideas and the written\ncommunication to regulatory agencies and Congressional staffers. The core\nquestion raised is where to draw the line between human-driven and AI-driven\npolicy influence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nay_J/0/1/0/all/0/1\">John J. Nay</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AI2: The next leap toward native language based and explainable machine learning framework. (arXiv:2301.03391v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.03391","description":"<p>The machine learning frameworks flourished in the last decades, allowing\nartificial intelligence to get out of academic circles to be applied to\nenterprise domains. This field has significantly advanced, but there is still\nsome meaningful improvement to reach the subsequent expectations. The proposed\nframework, named AI$^{2}$, uses a natural language interface that allows a\nnon-specialist to benefit from machine learning algorithms without necessarily\nknowing how to program with a programming language. The primary contribution of\nthe AI$^{2}$ framework allows a user to call the machine learning algorithms in\nEnglish, making its interface usage easier. The second contribution is\ngreenhouse gas (GHG) awareness. It has some strategies to evaluate the GHG\ngenerated by the algorithm to be called and to propose alternatives to find a\nsolution without executing the energy-intensive algorithm. Another contribution\nis a preprocessing module that helps to describe and to load data properly.\nUsing an English text-based chatbot, this module guides the user to define\nevery dataset so that it can be described, normalized, loaded and divided\nappropriately. The last contribution of this paper is about explainability. For\ndecades, the scientific community has known that machine learning algorithms\nimply the famous black-box problem. Traditional machine learning methods\nconvert an input into an output without being able to justify this result. The\nproposed framework explains the algorithm's process with the proper texts,\ngraphics and tables. The results, declined in five cases, present usage\napplications from the user's English command to the explained output.\nUltimately, the AI$^{2}$ framework represents the next leap toward native\nlanguage-based, human-oriented concerns about machine learning framework.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dessureault_J/0/1/0/all/0/1\">Jean-S&#xe9;bastien Dessureault</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Massicotte_D/0/1/0/all/0/1\">Daniel Massicotte</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-01-15T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}