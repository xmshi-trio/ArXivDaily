{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-01-20T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Understanding and Detecting Hallucinations in Neural Machine Translation via Model Introspection. (arXiv:2301.07779v1 [cs.CL])","link":"http://arxiv.org/abs/2301.07779","description":"<p>Neural sequence generation models are known to \"hallucinate\", by producing\noutputs that are unrelated to the source text. These hallucinations are\npotentially harmful, yet it remains unclear in what conditions they arise and\nhow to mitigate their impact. In this work, we first identify internal model\nsymptoms of hallucinations by analyzing the relative token contributions to the\ngeneration in contrastive hallucinated vs. non-hallucinated outputs generated\nvia source perturbations. We then show that these symptoms are reliable\nindicators of natural hallucinations, by using them to design a lightweight\nhallucination detector which outperforms both model-free baselines and strong\nclassifiers based on quality estimation or large pre-trained models on manually\nannotated English-Chinese and German-English translation test beds.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1\">Weijia Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1\">Sweta Agrawal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Briakou_E/0/1/0/all/0/1\">Eleftheria Briakou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martindale_M/0/1/0/all/0/1\">Marianna J. Martindale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carpuat_M/0/1/0/all/0/1\">Marine Carpuat</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Semantic-aware Contrastive Learning for More Accurate Semantic Parsing. (arXiv:2301.07919v1 [cs.CL])","link":"http://arxiv.org/abs/2301.07919","description":"<p>Since the meaning representations are detailed and accurate annotations which\nexpress fine-grained sequence-level semtantics, it is usually hard to train\ndiscriminative semantic parsers via Maximum Likelihood Estimation (MLE) in an\nautoregressive fashion. In this paper, we propose a semantic-aware contrastive\nlearning algorithm, which can learn to distinguish fine-grained meaning\nrepresentations and take the overall sequence-level semantic into\nconsideration. Specifically, a multi-level online sampling algorithm is\nproposed to sample confusing and diverse instances. Three semantic-aware\nsimilarity functions are designed to accurately measure the distance between\nmeaning representations as a whole. And a ranked contrastive loss is proposed\nto pull the representations of the semantic-identical instances together and\npush negative instances away. Experiments on two standard datasets show that\nour approach achieves significant improvements over MLE baselines and gets\nstate-of-the-art performances by simply applying semantic-aware contrastive\nlearning on a vanilla Seq2Seq model.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1\">Shan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xin_C/0/1/0/all/0/1\">Chunlei Xin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1\">Bo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xianpei Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1\">Le Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Continuously Reliable Detection of New-Normal Misinformation: Semantic Masking and Contrastive Smoothing in High-Density Latent Regions. (arXiv:2301.07981v1 [cs.LG])","link":"http://arxiv.org/abs/2301.07981","description":"<p>Toxic misinformation campaigns have caused significant societal harm, e.g.,\naffecting elections and COVID-19 information awareness. Unfortunately, despite\nsuccesses of (gold standard) retrospective studies of misinformation that\nconfirmed their harmful effects after the fact, they arrive too late for timely\nintervention and reduction of such harm. By design, misinformation evades\nretrospective classifiers by exploiting two properties we call new-normal: (1)\nnever-seen-before novelty that cause inescapable generalization challenges for\nprevious classifiers, and (2) massive but short campaigns that end before they\ncan be manually annotated for new classifier training. To tackle these\nchallenges, we propose UFIT, which combines two techniques: semantic masking of\nstrong signal keywords to reduce overfitting, and intra-proxy smoothness\nregularization of high-density regions in the latent space to improve\nreliability and maintain accuracy. Evaluation of UFIT on public new-normal\nmisinformation data shows over 30% improvement over existing approaches on\nfuture (and unseen) campaigns. To the best of our knowledge, UFIT is the first\nsuccessful effort to achieve such high level of generalization on new-normal\nmisinformation data with minimal concession (1 to 5%) of accuracy compared to\noracles trained with full knowledge of all campaigns.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suprem_A/0/1/0/all/0/1\">Abhijit Suprem</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferreira_J/0/1/0/all/0/1\">Joao Eduardo Ferreira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pu_C/0/1/0/all/0/1\">Calton Pu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Keyword Embeddings for Query Suggestion. (arXiv:2301.08006v1 [cs.IR])","link":"http://arxiv.org/abs/2301.08006","description":"<p>Nowadays, search engine users commonly rely on query suggestions to improve\ntheir initial inputs. Current systems are very good at recommending lexical\nadaptations or spelling corrections to users' queries. However, they often\nstruggle to suggest semantically related keywords given a user's query. The\nconstruction of a detailed query is crucial in some tasks, such as legal\nretrieval or academic search. In these scenarios, keyword suggestion methods\nare critical to guide the user during the query formulation. This paper\nproposes two novel models for the keyword suggestion task trained on scientific\nliterature. Our techniques adapt the architecture of Word2Vec and FastText to\ngenerate keyword embeddings by leveraging documents' keyword co-occurrence.\nAlong with these models, we also present a specially tailored negative sampling\napproach that exploits how keywords appear in academic publications. We devise\na ranking-based evaluation methodology following both known-item and ad-hoc\nsearch scenarios. Finally, we evaluate our proposals against the\nstate-of-the-art word and sentence embedding models showing considerable\nimprovements over the baselines for the tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gabin_J/0/1/0/all/0/1\">Jorge Gab&#xed;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ares_M/0/1/0/all/0/1\">M. Eduardo Ares</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parapar_J/0/1/0/all/0/1\">Javier Parapar</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Machine Translation with Phrase Pair Injection and Corpus Filtering. (arXiv:2301.08008v1 [cs.CL])","link":"http://arxiv.org/abs/2301.08008","description":"<p>In this paper, we show that the combination of Phrase Pair Injection and\nCorpus Filtering boosts the performance of Neural Machine Translation (NMT)\nsystems. We extract parallel phrases and sentences from the pseudo-parallel\ncorpus and augment it with the parallel corpus to train the NMT models. With\nthe proposed approach, we observe an improvement in the Machine Translation\n(MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi,\nand English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on\nthe FLORES test data. These BLEU score improvements are over the models trained\nusing the whole pseudo-parallel corpus augmented with the parallel corpus.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Batheja_A/0/1/0/all/0/1\">Akshay Batheja</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1\">Pushpak Bhattacharyya</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Author as Character and Narrator: Deconstructing Personal Narratives from the r/AmITheAsshole Reddit Community. (arXiv:2301.08104v1 [cs.CL])","link":"http://arxiv.org/abs/2301.08104","description":"<p>In the r/AmITheAsshole subreddit, people anonymously share first person\nnarratives that contain some moral dilemma or conflict and ask the community to\njudge who is at fault (i.e., who is \"the asshole\"). In general, first person\nnarratives are a unique storytelling domain where the author is the narrator\n(the person telling the story) but can also be a character (the person living\nthe story) and, thus, the author has two distinct voices presented in the\nstory. In this study, we identify linguistic and narrative features associated\nwith the author as the character or as a narrator. We use these features to\nanswer the following questions: (1) what makes an asshole character and (2)\nwhat makes an asshole narrator? We extract both Author-as-Character features\n(e.g., demographics, narrative event chain, and emotional arc) and\nAuthor-as-Narrator features (i.e., the style and emotion of the story as a\nwhole) in order to identify which aspects of the narrative are correlated with\nthe final moral judgment. Our work shows that \"assholes\" as Characters frame\nthemselves as lacking agency with a more positive personal arc, while\n\"assholes\" as Narrators will tell emotional and opinionated stories.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Giorgi_S/0/1/0/all/0/1\">Salvatore Giorgi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1\">Ke Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_A/0/1/0/all/0/1\">Alexander H. Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Lara J. Martin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Embeddings Sometimes Contain Typological Generalizations. (arXiv:2301.08115v1 [cs.CL])","link":"http://arxiv.org/abs/2301.08115","description":"<p>To what extent can neural network models learn generalizations about language\nstructure, and how do we find out what they have learned? We explore these\nquestions by training neural models for a range of natural language processing\ntasks on a massively multilingual dataset of Bible translations in 1295\nlanguages. The learned language representations are then compared to existing\ntypological databases as well as to a novel set of quantitative syntactic and\nmorphological features obtained through annotation projection. We conclude that\nsome generalizations are surprisingly close to traditional features from\nlinguistic typology, but that most of our models, as well as those of previous\nwork, do not appear to have made linguistically meaningful generalizations.\nCareful attention to details in the evaluation turns out to be essential to\navoid false positives. Furthermore, to encourage continued work in this field,\nwe release several resources covering most or all of the languages in our data:\n(i) multiple sets of language representations, (ii) multilingual word\nembeddings, (iii) projected and predicted syntactic and morphological features,\n(iv) software to provide linguistically sound evaluations of language\nrepresentations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ostling_R/0/1/0/all/0/1\">Robert &#xd6;stling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kurfali_M/0/1/0/all/0/1\">Murathan Kurfal&#x131;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Cohesive Distillation Architecture for Neural Language Models. (arXiv:2301.08130v1 [cs.CL])","link":"http://arxiv.org/abs/2301.08130","description":"<p>A recent trend in Natural Language Processing is the exponential growth in\nLanguage Model (LM) size, which prevents research groups without a necessary\nhardware infrastructure from participating in the development process. This\nstudy investigates methods for Knowledge Distillation (KD) to provide efficient\nalternatives to large-scale models. In this context, KD means extracting\ninformation about language encoded in a Neural Network and Lexical Knowledge\nDatabases. We developed two methods to test our hypothesis that efficient\narchitectures can gain knowledge from LMs and extract valuable information from\nlexical sources. First, we present a technique to learn confident probability\ndistribution for Masked Language Modeling by prediction weighting of multiple\nteacher networks. Second, we propose a method for Word Sense Disambiguation\n(WSD) and lexical KD that is general enough to be adapted to many LMs. Our\nresults show that KD with multiple teachers leads to improved training\nconvergence. When using our lexical pre-training method, LM characteristics are\nnot lost, leading to increased performance in Natural Language Understanding\n(NLU) tasks over the state-of-the-art while adding no parameters. Moreover, the\nimproved semantic understanding of our model increased the task performance\nbeyond WSD and NLU in a real-problem scenario (Plagiarism Detection). This\nstudy suggests that sophisticated training methods and network architectures\ncan be superior over scaling trainable parameters. On this basis, we suggest\nthe research area should encourage the development and use of efficient models\nand rate impacts resulting from growing LM size equally against task\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wahle_J/0/1/0/all/0/1\">Jan Philip Wahle</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Music Playlist Title Generation Using Artist Information. (arXiv:2301.08145v1 [cs.IR])","link":"http://arxiv.org/abs/2301.08145","description":"<p>Automatically generating or captioning music playlist titles given a set of\ntracks is of significant interest in music streaming services as customized\nplaylists are widely used in personalized music recommendation, and\nwell-composed text titles attract users and help their music discovery. We\npresent an encoder-decoder model that generates a playlist title from a\nsequence of music tracks. While previous work takes track IDs as tokenized\ninput for playlist title generation, we use artist IDs corresponding to the\ntracks to mitigate the issue from the long-tail distribution of tracks included\nin the playlist dataset. Also, we introduce a chronological data split method\nto deal with newly-released tracks in real-world scenarios. Comparing the track\nIDs and artist IDs as input sequences, we show that the artist-based approach\nsignificantly enhances the performance in terms of word overlap, semantic\nrelevance, and diversity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1\">Haven Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Doh_S/0/1/0/all/0/1\">SeungHeon Doh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Junwon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1\">Juhan Nam</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What's happening in your neighborhood? A Weakly Supervised Approach to Detect Local News. (arXiv:2301.08146v1 [cs.IR])","link":"http://arxiv.org/abs/2301.08146","description":"<p>Local news articles are a subset of news that impact users in a geographical\narea, such as a city, county, or state. Detecting local news (Step 1) and\nsubsequently deciding its geographical location as well as radius of impact\n(Step 2) are two important steps towards accurate local news recommendation.\nNaive rule-based methods, such as detecting city names from the news title,\ntend to give erroneous results due to lack of understanding of the news\ncontent. Empowered by the latest development in natural language processing, we\ndevelop an integrated pipeline that enables automatic local news detection and\ncontent-based local news recommendations. In this paper, we focus on Step 1 of\nthe pipeline, which highlights: (1) a weakly supervised framework incorporated\nwith domain knowledge and auto data processing, and (2) scalability to\nmulti-lingual settings. Compared with Stanford CoreNLP NER model, our pipeline\nhas higher precision and recall evaluated on a real-world and human-labeled\ndataset. This pipeline has potential to more precise local news to users, helps\nlocal businesses get more exposure, and gives people more information about\ntheir neighborhood safety.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1\">Deven Santosh Shah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1\">Shiying He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_R/0/1/0/all/0/1\">Radhika Bansal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"AI Insights into Theoretical Physics and the Swampland Program: A Journey Through the Cosmos with ChatGPT. (arXiv:2301.08155v1 [physics.pop-ph])","link":"http://arxiv.org/abs/2301.08155","description":"<p>In this case study, we explore the capabilities and limitations of ChatGPT, a\nnatural language processing model developed by OpenAI, in the field of string\ntheoretical swampland conjectures. We find that it is effective at paraphrasing\nand explaining concepts in a variety of styles, but not at genuinely connecting\nconcepts. It will provide false information with full confidence and make up\nstatements when necessary. However, its ingenious use of language can be\nfruitful for identifying analogies and describing visual representations of\nabstract concepts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Lehnert_K/0/1/0/all/0/1\">Kay Lehnert</a> (Department of Theoretical Physics, Maynooth University, Maynooth, Ireland)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"JCSE: Contrastive Learning of Japanese Sentence Embeddings and Its Applications. (arXiv:2301.08193v1 [cs.CL])","link":"http://arxiv.org/abs/2301.08193","description":"<p>Contrastive learning is widely used for sentence representation learning.\nDespite this prevalence, most studies have focused exclusively on English and\nfew concern domain adaptation for domain-specific downstream tasks, especially\nfor low-resource languages like Japanese, which are characterized by\ninsufficient target domain data and the lack of a proper training strategy. To\novercome this, we propose a novel Japanese sentence representation framework,\nJCSE (derived from ``Contrastive learning of Sentence Embeddings for\nJapanese''), that creates training data by generating sentences and\nsynthesizing them with sentences available in a target domain. Specifically, a\npre-trained data generator is finetuned to a target domain using our collected\ncorpus. It is then used to generate contradictory sentence pairs that are used\nin contrastive learning for adapting a Japanese language model to a specific\ntask in the target domain.\n</p>\n<p>Another problem of Japanese sentence representation learning is the\ndifficulty of evaluating existing embedding methods due to the lack of\nbenchmark datasets. Thus, we establish a comprehensive Japanese Semantic\nTextual Similarity (STS) benchmark on which various embedding models are\nevaluated. Based on this benchmark result, multiple embedding methods are\nchosen and compared with JCSE on two domain-specific tasks, STS in a clinical\ndomain and information retrieval in an educational domain. The results show\nthat JCSE achieves significant performance improvement surpassing direct\ntransfer and other training strategies. This empirically demonstrates JCSE's\neffectiveness and practicability for downstream tasks of a low-resource\nlanguage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zihao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Handa_H/0/1/0/all/0/1\">Hisashi Handa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shirahama_K/0/1/0/all/0/1\">Kimiaki Shirahama</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Self-Training Vision Language BERTs with a Unified Conditional Model. (arXiv:2201.02010v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2201.02010","description":"<p>Natural language BERTs are trained with language corpus in a self-supervised\nmanner. Unlike natural language BERTs, vision language BERTs need paired data\nto train, which restricts the scale of VL-BERT pretraining. We propose a\nself-training approach that allows training VL-BERTs from unlabeled image data.\nThe proposed method starts with our unified conditional model -- a vision\nlanguage BERT model that can perform zero-shot conditional generation. Given\ndifferent conditions, the unified conditional model can generate captions,\ndense captions, and even questions. We use the labeled image data to train a\nteacher model and use the trained model to generate pseudo captions on\nunlabeled image data. We then combine the labeled data and pseudo labeled data\nto train a student model. The process is iterated by putting the student model\nas a new teacher. By using the proposed self-training approach and only 300k\nunlabeled extra data, we are able to get competitive or even better\nperformances compared to the models of similar model size trained with 3\nmillion extra image data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1\">Xiaofeng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lv_F/0/1/0/all/0/1\">Fengmao Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fayao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1\">Guosheng Lin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Analysis of Semantically-Aligned Speech-Text Embeddings. (arXiv:2204.01235v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.01235","description":"<p>Embeddings play an important role in end-to-end solutions for multi-modal\nlanguage processing problems. Although there has been some effort to understand\nthe properties of single-modality embedding spaces, particularly that of text,\ntheir cross-modal counterparts are less understood. In this work, we study some\nintrinsic properties of a joint speech-text embedding space, constructed by\nminimizing the distance between paired utterance and transcription inputs in a\nteacher-student model setup, that are informative for several prominent use\ncases. We found that incorporating automatic speech recognition through both\npretraining and multitask scenarios aid semantic alignment significantly,\nresulting in more tightly coupled embeddings. To analyse cross-modal embeddings\nwe utilise a quantitative retrieval accuracy metric for semantic alignment,\nzero-shot classification for generalisability, and probing of the encoders to\nobserve the extent of knowledge transfer from one modality to another.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huzaifah_M/0/1/0/all/0/1\">Muhammad Huzaifah</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kukanov_I/0/1/0/all/0/1\">Ivan Kukanov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Life is a Circus and We are the Clowns: Automatically Finding Analogies between Situations and Processes. (arXiv:2210.12197v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.12197","description":"<p>Analogy-making gives rise to reasoning, abstraction, flexible categorization\nand counterfactual inference -- abilities lacking in even the best AI systems\ntoday. Much research has suggested that analogies are key to non-brittle\nsystems that can adapt to new domains. Despite their importance, analogies\nreceived little attention in the NLP community, with most research focusing on\nsimple word analogies. Work that tackled more complex analogies relied heavily\non manually constructed, hard-to-scale input representations. In this work, we\nexplore a more realistic, challenging setup: our input is a pair of natural\nlanguage procedural texts, describing a situation or a process (e.g., how the\nheart works/how a pump works). Our goal is to automatically extract entities\nand their relations from the text and find a mapping between the different\ndomains based on relational similarity (e.g., blood is mapped to water). We\ndevelop an interpretable, scalable algorithm and demonstrate that it identifies\nthe correct mappings 87% of the time for procedural texts and 94% for stories\nfrom cognitive-psychology literature. We show it can extract analogies from a\nlarge dataset of procedural texts, achieving 79% precision (analogy prevalence\nin data: 3%). Lastly, we demonstrate that our algorithm is robust to\nparaphrasing the input texts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sultan_O/0/1/0/all/0/1\">Oren Sultan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shahaf_D/0/1/0/all/0/1\">Dafna Shahaf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InferEM: Inferring the Speaker's Intention for Empathetic Dialogue Generation. (arXiv:2212.06373v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.06373","description":"<p>Current approaches to empathetic response generation typically encode the\nentire dialogue history directly and put the output into a decoder to generate\nfriendly feedback. These methods focus on modelling contextual information but\nneglect capturing the direct intention of the speaker. We argue that the last\nutterance in the dialogue empirically conveys the intention of the speaker.\nConsequently, we propose a novel model named InferEM for empathetic response\ngeneration. We separately encode the last utterance and fuse it with the entire\ndialogue through the multi-head attention based intention fusion module to\ncapture the speaker's intention. Besides, we utilize previous utterances to\npredict the last utterance, which simulates human's psychology to guess what\nthe interlocutor may speak in advance. To balance the optimizing rates of the\nutterance prediction and response generation, a multi-task learning strategy is\ndesigned for InferEM. Experimental results demonstrate the plausibility and\nvalidity of InferEM in improving empathetic expression.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lv_G/0/1/0/all/0/1\">Guoqing Lv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaoping Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jiang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1\">Zhigang Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-01-19T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/"}}]}]}