{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-08-01T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI. (arXiv:2307.15715v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15715","description":"<p>Primary care professionals struggle to keep up to date with the latest\nscientific literature critical in guiding evidence-based practice related to\ntheir daily work. To help solve the above-mentioned problem, we employed\ngenerative artificial intelligence techniques based on large-scale language\nmodels to summarize abstracts of scientific papers. Our objective is to\ninvestigate the potential of generative artificial intelligence in diminishing\nthe cognitive load experienced by practitioners, thus exploring its ability to\nalleviate mental effort and burden. The study participants were provided with\ntwo use cases related to preventive care and behavior change, simulating a\nsearch for new scientific literature. The study included 113 university\nstudents from Slovenia and the United States randomized into three distinct\nstudy groups. The first group was assigned to the full abstracts. The second\ngroup was assigned to the short abstracts generated by AI. The third group had\nthe option to select a full abstract in addition to the AI-generated short\nsummary. Each use case study included ten retrieved abstracts. Our research\ndemonstrates that the use of generative AI for literature review is efficient\nand effective. The time needed to answer questions related to the content of\nabstracts was significantly lower in groups two and three compared to the first\ngroup using full abstracts. The results, however, also show significantly lower\naccuracy in extracted knowledge in cases where full abstract was not available.\nSuch a disruptive technology could significantly reduce the time required for\nhealthcare professionals to keep up with the most recent scientific literature;\nnevertheless, further developments are needed to help them comprehend the\nknowledge accurately.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stiglic_G/0/1/0/all/0/1\">Gregor Stiglic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kopitar_L/0/1/0/all/0/1\">Leon Kopitar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gosak_L/0/1/0/all/0/1\">Lucija Gosak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kocbek_P/0/1/0/all/0/1\">Primoz Kocbek</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1\">Zhe He</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chakraborty_P/0/1/0/all/0/1\">Prithwish Chakraborty</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meyer_P/0/1/0/all/0/1\">Pablo Meyer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bian_J/0/1/0/all/0/1\">Jiang Bian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Utilizing Large Language Models for Natural Interface to Pharmacology Databases. (arXiv:2307.15717v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15717","description":"<p>The drug development process necessitates that pharmacologists undertake\nvarious tasks, such as reviewing literature, formulating hypotheses, designing\nexperiments, and interpreting results. Each stage requires accessing and\nquerying vast amounts of information. In this abstract, we introduce a Large\nLanguage Model (LLM)-based Natural Language Interface designed to interact with\nstructured information stored in databases. Our experiments demonstrate the\nfeasibility and effectiveness of the proposed framework. This framework can\ngeneralize to query a wide range of pharmaceutical data and knowledge bases.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1\">Hong Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chuan Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1\">Jie Zhao</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Context-VQA: Towards Context-Aware and Purposeful Visual Question Answering. (arXiv:2307.15745v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15745","description":"<p>Visual question answering (VQA) has the potential to make the Internet more\naccessible in an interactive way, allowing people who cannot see images to ask\nquestions about them. However, multiple studies have shown that people who are\nblind or have low-vision prefer image explanations that incorporate the context\nin which an image appears, yet current VQA datasets focus on images in\nisolation. We argue that VQA models will not fully succeed at meeting people's\nneeds unless they take context into account. To further motivate and analyze\nthe distinction between different contexts, we introduce Context-VQA, a VQA\ndataset that pairs images with contexts, specifically types of websites (e.g.,\na shopping website). We find that the types of questions vary systematically\nacross contexts. For example, images presented in a travel context garner 2\ntimes more \"Where?\" questions, and images on social media and news garner 2.8\nand 1.8 times more \"Who?\" questions than the average. We also find that context\neffects are especially important when participants can't see the image. These\nresults demonstrate that context affects the types of questions asked and that\nVQA models should be context-sensitive to better meet people's needs,\nespecially in accessibility settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Naik_N/0/1/0/all/0/1\">Nandita Naik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1\">Christopher Potts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kreiss_E/0/1/0/all/0/1\">Elisa Kreiss</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Resume Evaluation through Latent Dirichlet Allocation and Natural Language Processing for Effective Candidate Selection. (arXiv:2307.15752v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15752","description":"<p>In this paper, we propose a method for resume rating using Latent Dirichlet\nAllocation (LDA) and entity detection with SpaCy. The proposed method first\nextracts relevant entities such as education, experience, and skills from the\nresume using SpaCy's Named Entity Recognition (NER). The LDA model then uses\nthese entities to rate the resume by assigning topic probabilities to each\nentity. Furthermore, we conduct a detailed analysis of the entity detection\nusing SpaCy's NER and report its evaluation metrics. Using LDA, our proposed\nsystem breaks down resumes into latent topics and extracts meaningful semantic\nrepresentations. With a vision to define our resume score to be more\ncontent-driven rather than a structure and keyword match driven, our model has\nachieved 77% accuracy with respect to only skills in consideration and an\noverall 82% accuracy with all attributes in consideration. (like college name,\nwork experience, degree and skills)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jagwani_V/0/1/0/all/0/1\">Vidhita Jagwani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meghani_S/0/1/0/all/0/1\">Smit Meghani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pai_K/0/1/0/all/0/1\">Krishna Pai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dhage_S/0/1/0/all/0/1\">Sudhir Dhage</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lessons in Reproducibility: Insights from NLP Studies in Materials Science. (arXiv:2307.15759v1 [physics.chem-ph])","link":"http://arxiv.org/abs/2307.15759","description":"<p>Natural Language Processing (NLP), a cornerstone field within artificial\nintelligence, has been increasingly utilized in the field of materials science\nliterature. Our study conducts a reproducibility analysis of two pioneering\nworks within this domain: \"Machine-learned and codified synthesis parameters of\noxide materials\" by Kim et al., and \"Unsupervised word embeddings capture\nlatent knowledge from materials science literature\" by Tshitoyan et al. We aim\nto comprehend these studies from a reproducibility perspective, acknowledging\ntheir significant influence on the field of materials informatics, rather than\ncritiquing them. Our study indicates that both papers offered thorough\nworkflows, tidy and well-documented codebases, and clear guidance for model\nevaluation. This makes it easier to replicate their results successfully and\npartially reproduce their findings. In doing so, they set commendable standards\nfor future materials science publications to aspire to. However, our analysis\nalso highlights areas for improvement such as to provide access to training\ndata where copyright restrictions permit, more transparency on model\narchitecture and the training process, and specifications of software\ndependency versions. We also cross-compare the word embedding models between\npapers, and find that some key differences in reproducibility and\ncross-compatibility are attributable to design choices outside the bounds of\nthe models themselves. In summary, our study appreciates the benchmark set by\nthese seminal papers while advocating for further enhancements in research\nreproducibility practices in the field of NLP for materials science. This\nbalance of understanding and continuous improvement will ultimately propel the\nintersecting domains of NLP and materials science literature into a future of\nexciting discoveries.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/physics/1/au:+Lei_X/0/1/0/all/0/1\">Xiangyun Lei</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Kim_E/0/1/0/all/0/1\">Edward Kim</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Baibakova_V/0/1/0/all/0/1\">Viktoriia Baibakova</a>, <a href=\"http://arxiv.org/find/physics/1/au:+Sun_S/0/1/0/all/0/1\">Shijing Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CHATREPORT: Democratizing Sustainability Disclosure Analysis through LLM-based Tools. (arXiv:2307.15770v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15770","description":"<p>In the face of climate change, are companies really taking substantial steps\ntoward more sustainable operations? A comprehensive answer lies in the dense,\ninformation-rich landscape of corporate sustainability reports. However, the\nsheer volume and complexity of these reports make human analysis very costly.\nTherefore, only a few entities worldwide have the resources to analyze these\nreports at scale, which leads to a lack of transparency in sustainability\nreporting. Empowering stakeholders with LLM-based automatic analysis tools can\nbe a promising way to democratize sustainability report analysis. However,\ndeveloping such tools is challenging due to (1) the hallucination of LLMs and\n(2) the inefficiency of bringing domain experts into the AI development loop.\nIn this paper, we ChatReport, a novel LLM-based system to automate the analysis\nof corporate sustainability reports, addressing existing challenges by (1)\nmaking the answers traceable to reduce the harm of hallucination and (2)\nactively involving domain experts in the development loop. We make our\nmethodology, annotated datasets, and generated analyses of 1015 reports\npublicly available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1\">Jingwei Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bingler_J/0/1/0/all/0/1\">Julia Bingler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Colesanti_Senni_C/0/1/0/all/0/1\">Chiara Colesanti-Senni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_M/0/1/0/all/0/1\">Mathias Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gostlow_G/0/1/0/all/0/1\">Glen Gostlow</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schimanski_T/0/1/0/all/0/1\">Tobias Schimanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stammbach_D/0/1/0/all/0/1\">Dominik Stammbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vaghefi_S/0/1/0/all/0/1\">Saeid Ashraf Vaghefi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Webersinke_N/0/1/0/all/0/1\">Nicolas Webersinke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wekhof_T/0/1/0/all/0/1\">Tobias Wekhof</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tingyu Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leippold_M/0/1/0/all/0/1\">Markus Leippold</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The Hydra Effect: Emergent Self-repair in Language Model Computations. (arXiv:2307.15771v1 [cs.LG])","link":"http://arxiv.org/abs/2307.15771","description":"<p>We investigate the internal structure of language model computations using\ncausal analysis and demonstrate two motifs: (1) a form of adaptive computation\nwhere ablations of one attention layer of a language model cause another layer\nto compensate (which we term the Hydra effect) and (2) a counterbalancing\nfunction of late MLP layers that act to downregulate the maximum-likelihood\ntoken. Our ablation studies demonstrate that language model layers are\ntypically relatively loosely coupled (ablations to one layer only affect a\nsmall number of downstream layers). Surprisingly, these effects occur even in\nlanguage models trained without any form of dropout. We analyse these effects\nin the context of factual recall and consider their implications for\ncircuit-level attribution in language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+McGrath_T/0/1/0/all/0/1\">Thomas McGrath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahtz_M/0/1/0/all/0/1\">Matthew Rahtz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1\">Janos Kramar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikulik_V/0/1/0/all/0/1\">Vladimir Mikulik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Legg_S/0/1/0/all/0/1\">Shane Legg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation. (arXiv:2307.15776v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15776","description":"<p>Injecting textual information into knowledge graph (KG) entity\nrepresentations has been a worthwhile expedition in terms of improving\nperformance in KG oriented tasks within the NLP community. External knowledge\noften adopted to enhance KG embeddings ranges from semantically rich lexical\ndependency parsed features to a set of relevant key words to entire text\ndescriptions supplied from an external corpus such as wikipedia and many more.\nDespite the gains this innovation (Text-enhanced KG embeddings) has made, the\nproposal in this work suggests that it can be improved even further. Instead of\nusing a single text description (which would not sufficiently represent an\nentity because of the inherent lexical ambiguity of text), we propose a\nmulti-task framework that jointly selects a set of text descriptions relevant\nto KG entities as well as align or augment KG embeddings with text\ndescriptions. Different from prior work that plugs formal entity descriptions\ndeclared in knowledge bases, this framework leverages a retriever model to\nselectively identify richer or highly relevant text descriptions to use in\naugmenting entities. Furthermore, the framework treats the number of\ndescriptions to use in augmentation process as a parameter, which allows the\nflexibility of enumerating across several numbers before identifying an\nappropriate number. Experiment results for Link Prediction demonstrate a 5.5%\nand 3.5% percentage increase in the Mean Reciprocal Rank (MRR) and Hits@10\nscores respectively, in comparison to text-enhanced knowledge graph\naugmentation methods using traditional CNNs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abaho_M/0/1/0/all/0/1\">Micheal Abaho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alfaifi_Y/0/1/0/all/0/1\">Yousef H. Alfaifi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM-Rec: Personalized Recommendation via Prompting Large Language Models. (arXiv:2307.15780v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15780","description":"<p>We investigate various prompting strategies for enhancing personalized\ncontent recommendation performance with large language models (LLMs) through\ninput augmentation. Our proposed approach, termed LLM-Rec, encompasses four\ndistinct prompting strategies: (1) basic prompting, (2) recommendation-driven\nprompting, (3) engagement-guided prompting, and (4) recommendation-driven +\nengagement-guided prompting. Our empirical experiments show that combining the\noriginal content description with the augmented input text generated by LLM\nusing these prompting strategies leads to improved recommendation performance.\nThis finding highlights the importance of incorporating diverse prompts and\ninput augmentation techniques to enhance the recommendation capabilities with\nlarge language models for personalized content recommendation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1\">Hanjia Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1\">Song Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1\">Hanqing Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1\">Yinglong Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1\">Jiebo Luo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control. (arXiv:2307.15818v1 [cs.RO])","link":"http://arxiv.org/abs/2307.15818","description":"<p>We study how vision-language models trained on Internet-scale data can be\nincorporated directly into end-to-end robotic control to boost generalization\nand enable emergent semantic reasoning. Our goal is to enable a single\nend-to-end trained model to both learn to map robot observations to actions and\nenjoy the benefits of large-scale pretraining on language and vision-language\ndata from the web. To this end, we propose to co-fine-tune state-of-the-art\nvision-language models on both robotic trajectory data and Internet-scale\nvision-language tasks, such as visual question answering. In contrast to other\napproaches, we propose a simple, general recipe to achieve this goal: in order\nto fit both natural language responses and robotic actions into the same\nformat, we express the actions as text tokens and incorporate them directly\ninto the training set of the model in the same way as natural language tokens.\nWe refer to such category of models as vision-language-action models (VLA) and\ninstantiate an example of such a model, which we call RT-2. Our extensive\nevaluation (6k evaluation trials) shows that our approach leads to performant\nrobotic policies and enables RT-2 to obtain a range of emergent capabilities\nfrom Internet-scale training. This includes significantly improved\ngeneralization to novel objects, the ability to interpret commands not present\nin the robot training data (such as placing an object onto a particular number\nor icon), and the ability to perform rudimentary reasoning in response to user\ncommands (such as picking up the smallest or largest object, or the one closest\nto another object). We further show that incorporating chain of thought\nreasoning allows RT-2 to perform multi-stage semantic reasoning, for example\nfiguring out which object to pick up for use as an improvised hammer (a rock),\nor which type of drink is best suited for someone who is tired (an energy\ndrink).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Brohan_A/0/1/0/all/0/1\">Anthony Brohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1\">Noah Brown</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Carbajal_J/0/1/0/all/0/1\">Justice Carbajal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chebotar_Y/0/1/0/all/0/1\">Yevgen Chebotar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1\">Krzysztof Choromanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_T/0/1/0/all/0/1\">Tianli Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Driess_D/0/1/0/all/0/1\">Danny Driess</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1\">Avinava Dubey</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1\">Chelsea Finn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Florence_P/0/1/0/all/0/1\">Pete Florence</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1\">Chuyuan Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arenas_M/0/1/0/all/0/1\">Montse Gonzalez Arenas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1\">Keerthana Gopalakrishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kehang Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1\">Karol Hausman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Herzog_A/0/1/0/all/0/1\">Alexander Herzog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsu_J/0/1/0/all/0/1\">Jasmine Hsu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ichter_B/0/1/0/all/0/1\">Brian Ichter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1\">Alex Irpan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1\">Nikhil Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Julian_R/0/1/0/all/0/1\">Ryan Julian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kalashnikov_D/0/1/0/all/0/1\">Dmitry Kalashnikov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kuang_Y/0/1/0/all/0/1\">Yuheng Kuang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leal_I/0/1/0/all/0/1\">Isabel Leal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1\">Lisa Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1\">Tsang-Wei Edward Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1\">Sergey Levine</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yao Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1\">Henryk Michalewski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1\">Igor Mordatch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pertsch_K/0/1/0/all/0/1\">Karl Pertsch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1\">Kanishka Rao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reymann_K/0/1/0/all/0/1\">Krista Reymann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1\">Michael Ryoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Salazar_G/0/1/0/all/0/1\">Grecia Salazar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sanketi_P/0/1/0/all/0/1\">Pannag Sanketi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1\">Pierre Sermanet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Jaspiar Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1\">Anikait Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1\">Radu Soricut</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1\">Huong Tran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vanhoucke_V/0/1/0/all/0/1\">Vincent Vanhoucke</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vuong_Q/0/1/0/all/0/1\">Quan Vuong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wahid_A/0/1/0/all/0/1\">Ayzaan Wahid</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welker_S/0/1/0/all/0/1\">Stefan Welker</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wohlhart_P/0/1/0/all/0/1\">Paul Wohlhart</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jialin Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1\">Fei Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1\">Ted Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1\">Peng Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Sichun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1\">Tianhe Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zitkovich_B/0/1/0/all/0/1\">Brianna Zitkovich</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dialogue Shaping: Empowering Agents through NPC Interaction. (arXiv:2307.15833v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15833","description":"<p>One major challenge in reinforcement learning (RL) is the large amount of\nsteps for the RL agent needs to converge in the training process and learn the\noptimal policy, especially in text-based game environments where the action\nspace is extensive. However, non-player characters (NPCs) sometimes hold some\nkey information about the game, which can potentially help to train RL agents\nfaster. Thus, this paper explores how to interact and converse with NPC agents\nto get the key information using large language models (LLMs), as well as\nincorporate this information to speed up RL agent's training using knowledge\ngraphs (KGs) and Story Shaping.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wei Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1\">Xiangyu Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1\">Mark Riedl</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ATESA-B{\\AE}RT: A Heterogeneous Ensemble Learning Model for Aspect-Based Sentiment Analysis. (arXiv:2307.15920v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15920","description":"<p>The increasing volume of online reviews has made possible the development of\nsentiment analysis models for determining the opinion of customers regarding\ndifferent products and services. Until now, sentiment analysis has proven to be\nan effective tool for determining the overall polarity of reviews. To improve\nthe granularity at the aspect level for a better understanding of the service\nor product, the task of aspect-based sentiment analysis aims to first identify\naspects and then determine the user's opinion about them. The complexity of\nthis task lies in the fact that the same review can present multiple aspects,\neach with its own polarity. Current solutions have poor performance on such\ndata. We address this problem by proposing ATESA-B{\\AE}RT, a heterogeneous\nensemble learning model for Aspect-Based Sentiment Analysis. Firstly, we divide\nour problem into two sub-tasks, i.e., Aspect Term Extraction and Aspect Term\nSentiment Analysis. Secondly, we use the \\textit{argmax} multi-class\nclassification on six transformers-based learners for each sub-task. Initial\nexperiments on two datasets prove that ATESA-B{\\AE}RT outperforms current\nstate-of-the-art solutions while solving the many aspects problem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Apostol_E/0/1/0/all/0/1\">Elena-Simona Apostol</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pisica_A/0/1/0/all/0/1\">Alin-Georgian Pisic&#x103;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Truica_C/0/1/0/all/0/1\">Ciprian-Octavian Truic&#x103;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GeneMask: Fast Pretraining of Gene Sequences to Enable Few-Shot Learning. (arXiv:2307.15933v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15933","description":"<p>Large-scale language models such as DNABert and LOGO aim to learn optimal\ngene representations and are trained on the entire Human Reference Genome.\nHowever, standard tokenization schemes involve a simple sliding window of\ntokens like k-mers that do not leverage any gene-based semantics and thus may\nlead to (trivial) masking of easily predictable sequences and subsequently\ninefficient Masked Language Modeling (MLM) training. Therefore, we propose a\nnovel masking algorithm, GeneMask, for MLM training of gene sequences, where we\nrandomly identify positions in a gene sequence as mask centers and locally\nselect the span around the mask center with the highest Normalized Pointwise\nMutual Information (NPMI) to mask. We observe that in the absence of\nhuman-understandable semantics in the genomics domain (in contrast, semantic\nunits like words and phrases are inherently available in NLP), GeneMask-based\nmodels substantially outperform the SOTA models (DNABert and LOGO) over four\nbenchmark gene sequence classification datasets in five few-shot settings (10\nto 1000-shot). More significantly, the GeneMask-based DNABert model is trained\nfor less than one-tenth of the number of epochs of the original SOTA model. We\nalso observe a strong correlation between top-ranked PMI tokens and conserved\nDNA sequence motifs, which may indicate the incorporation of latent genomic\ninformation. The codes (including trained models) and datasets are made\npublicly available at https://github.com/roysoumya/GeneMask.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1\">Soumyadeep Roy</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallat_J/0/1/0/all/0/1\">Jonas Wallat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1\">Sowmya S Sundaram</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nejdl_W/0/1/0/all/0/1\">Wolfgang Nejdl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1\">Niloy Ganguly</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Theory for Emergence of Complex Skills in Language Models. (arXiv:2307.15936v1 [cs.LG])","link":"http://arxiv.org/abs/2307.15936","description":"<p>A major driver of AI products today is the fact that new skills emerge in\nlanguage models when their parameter set and training corpora are scaled up.\nThis phenomenon is poorly understood, and a mechanistic explanation via\nmathematical analysis of gradient-based training seems difficult. The current\npaper takes a different approach, analysing emergence using the famous (and\nempirical) Scaling Laws of LLMs and a simple statistical framework.\nContributions include: (a) A statistical framework that relates cross-entropy\nloss of LLMs to competence on the basic skills that underlie language tasks.\n(b) Mathematical analysis showing that the Scaling Laws imply a strong form of\ninductive bias that allows the pre-trained model to learn very efficiently. We\ninformally call this {\\em slingshot generalization} since naively viewed it\nappears to give competence levels at skills that violate usual generalization\ntheory. (c) A key example of slingshot generalization, that competence at\nexecuting tasks involving $k$-tuples of skills emerges essentially at the same\nscaling and same rate as competence on the elementary skills themselves.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1\">Sanjeev Arora</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1\">Anirudh Goyal</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Codable Text Watermarking for Large Language Models. (arXiv:2307.15992v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15992","description":"<p>As large language models (LLMs) generate texts with increasing fluency and\nrealism, there is a growing need to identify the source of texts to prevent the\nabuse of LLMs. Text watermarking techniques have proven reliable in\ndistinguishing whether a text is generated by LLMs by injecting hidden patterns\ninto the generated texts. However, we argue that existing watermarking methods\nfor LLMs are encoding-inefficient (only contain one bit of information -\nwhether it is generated from an LLM or not) and cannot flexibly meet the\ndiverse information encoding needs (such as encoding model version, generation\ntime, user id, etc.) in different LLMs application scenarios. In this work, we\nconduct the first systematic study on the topic of Codable Text Watermarking\nfor LLMs (CTWL) that allows text watermarks to carry more customizable\ninformation. First of all, we study the taxonomy of LLM watermarking technology\nand give a mathematical formulation for CTWL. Additionally, we provide a\ncomprehensive evaluation system for CTWL: (1) watermarking success rate, (2)\nrobustness against various corruptions, (3) coding rate of payload information,\n(4) encoding and decoding efficiency, (5) impacts on the quality of the\ngenerated text. To meet the requirements of these non-Pareto-improving metrics,\nwe devise a CTWL method named Balance-Marking, based on the motivation of\nensuring that available and unavailable vocabularies for encoding information\nhave approximately equivalent probabilities. Compared to the random vocabulary\npartitioning extended from the existing work, a probability-balanced vocabulary\npartition can significantly improve the quality of the generated text.\nExtensive experimental results have shown that our method outperforms a direct\nbaseline under comprehensive evaluation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Lean Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1\">Wenkai Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Deli Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1\">Yankai Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1\">Fandong Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jie Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1\">Xu Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoCar: A Relationship Network-based Evaluation Method to Large Language Models. (arXiv:2307.15997v1 [cs.CL])","link":"http://arxiv.org/abs/2307.15997","description":"<p>Large language models (LLMs) have received increasing attention. However, due\nto the complexity of its capabilities, how to rationally evaluate the\ncapabilities of LLMs is still a task to be solved. We propose the RoCar method,\nwhich utilizes the defined basic schemas to randomly construct a task graph and\ngenerates natural language evaluation tasks based on the task graph to evaluate\nthe reasoning and memory abilities of LLMs respectively. Due to the very large\nrandomness of the task construction process, it is possible to ensure that none\nof the LLMs to be tested has directly learned the evaluation tasks,\nguaranteeing the fairness of the evaluation method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1\">Ming Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenfang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Chongyun Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Daling Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1\">Shi Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yifei Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Marrying Dialogue Systems with Data Visualization: Interactive Data Visualization Generation from Natural Language Conversations. (arXiv:2307.16013v1 [cs.AI])","link":"http://arxiv.org/abs/2307.16013","description":"<p>Data visualization (DV) has become the prevailing tool in the market due to\nits effectiveness into illustrating insights in vast amounts of data. To lower\nthe barrier of using DVs, automatic DV tasks, such as natural language question\n(NLQ) to visualization translation (formally called text-to-vis), have been\ninvestigated in the research community. However, text-to-vis assumes the NLQ to\nbe well-organized and expressed in a single sentence. However, in real-world\nsettings, complex DV is needed through consecutive exchanges between the DV\nsystem and the users. In this paper, we propose a new task named CoVis, short\nfor Conversational text-to-Visualization, aiming at constructing DVs through a\nseries of interactions between users and the system. Since it is the task which\nhas not been studied in the literature, we first build a benchmark dataset\nnamed Dial-NVBench, including dialogue sessions with a sequence of queries from\na user and responses from the system. Then, we propose a multi-modal neural\nnetwork named MMCoVisNet to answer these DV-related queries. In particular,\nMMCoVisNet first fully understands the dialogue context and determines the\ncorresponding responses. Then, it uses adaptive decoders to provide the\nappropriate replies: (i) a straightforward text decoder is used to produce\ngeneral responses, (ii) an SQL-form decoder is applied to synthesize data\nquerying responses, and (iii) a DV-form decoder tries to construct the\nappropriate DVs. We comparatively evaluate MMCoVisNet with other baselines over\nour proposed benchmark dataset. Experimental results validate that MMCoVisNet\nperforms better than existing baselines and achieves a state-of-the-art\nperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuanfeng Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1\">Xuefang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wong_R/0/1/0/all/0/1\">Raymond Chi-Wing Wong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback. (arXiv:2307.16039v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16039","description":"<p>A key technology for the development of large language models (LLMs) involves\ninstruction tuning that helps align the models' responses with human\nexpectations to realize impressive learning abilities. Two major approaches for\ninstruction tuning characterize supervised fine-tuning (SFT) and reinforcement\nlearning from human feedback (RLHF), which are currently applied to produce the\nbest commercial LLMs (e.g., ChatGPT). To improve the accessibility of LLMs for\nresearch and development efforts, various instruction-tuned open-source LLMs\nhave also been introduced recently, e.g., Alpaca, Vicuna, to name a few.\nHowever, existing open-source LLMs have only been instruction-tuned for English\nand a few popular languages, thus hindering their impacts and accessibility to\nmany other languages in the world. Among a few very recent work to explore\ninstruction tuning for LLMs in multiple languages, SFT has been used as the\nonly approach to instruction-tune LLMs for multiple languages. This has left a\nsignificant gap for fine-tuned LLMs based on RLHF in diverse languages and\nraised important questions on how RLHF can boost the performance of\nmultilingual instruction tuning. To overcome this issue, we present Okapi, the\nfirst system with instruction-tuned LLMs based on RLHF for multiple languages.\nOkapi introduces instruction and response-ranked data in 26 diverse languages\nto facilitate the experiments and development of future multilingual LLM\nresearch. We also present benchmark datasets to enable the evaluation of\ngenerative LLMs in multiple languages. Our experiments demonstrate the\nadvantages of RLHF for multilingual instruction over SFT for different base\nmodels and datasets. Our framework and resources are released at\n\\url{https://github.com/nlp-uoregon/Okapi}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_V/0/1/0/all/0/1\">Viet Dac Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1\">Chien Van Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ngo_N/0/1/0/all/0/1\">Nghia Trung Ngo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thuat Nguyen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1\">Franck Dernoncourt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1\">Ryan A. Rossi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1\">Thien Huu Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Extraction of the Romanian Academic Word List: Data and Methods. (arXiv:2307.16045v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16045","description":"<p>This paper presents the methodology and data used for the automatic\nextraction of the Romanian Academic Word List (Ro-AWL). Academic Word Lists are\nuseful in both L2 and L1 teaching contexts. For the Romanian language, no such\nresource exists so far. Ro-AWL has been generated by combining methods from\ncorpus and computational linguistics with L2 academic writing approaches. We\nuse two types of data: (a) existing data, such as the Romanian Frequency List\nbased on the ROMBAC corpus, and (b) self-compiled data, such as the expert\nacademic writing corpus EXPRES. For constructing the academic word list, we\nfollow the methodology for building the Academic Vocabulary List for the\nEnglish language. The distribution of Ro-AWL features (general distribution,\nPOS distribution) into four disciplinary datasets is in line with previous\nresearch. Ro-AWL is freely available and can be used for teaching, research and\nNLP applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bucur_A/0/1/0/all/0/1\">Ana-Maria Bucur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dinca_A/0/1/0/all/0/1\">Andreea Dinc&#x103;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chitez_M/0/1/0/all/0/1\">M&#x103;d&#x103;lina Chitez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rogobete_R/0/1/0/all/0/1\">Roxana Rogobete</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"\\`{I}r\\`{o}y\\`{i}nSpeech: A multi-purpose Yor\\`{u}b\\'{a} Speech Corpus. (arXiv:2307.16071v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16071","description":"<p>We introduce the \\`{I}r\\`{o}y\\`{i}nSpeech corpus -- a new dataset influenced\nby a desire to increase the amount of high quality, freely available,\ncontemporary Yor\\`{u}b\\'{a} speech. We release a multi-purpose dataset that can\nbe used for both TTS and ASR tasks. We curated text sentences from the news and\ncreative writing domains under an open license i.e., CC-BY-4.0 and had multiple\nspeakers record each sentence. We provide 5000 of our utterances to the Common\nVoice platform to crowdsource transcriptions online. The dataset has 38.5 hours\nof data in total, recorded by 80 volunteers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ogunremi_T/0/1/0/all/0/1\">Tolulope Ogunremi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tubosun_K/0/1/0/all/0/1\">Kola Tubosun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aremu_A/0/1/0/all/0/1\">Anuoluwapo Aremu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Orife_I/0/1/0/all/0/1\">Iroro Orife</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adelani_D/0/1/0/all/0/1\">David Ifeoluwa Adelani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Roll Up Your Sleeves: Working with a Collaborative and Engaging Task-Oriented Dialogue System. (arXiv:2307.16081v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16081","description":"<p>We introduce TacoBot, a user-centered task-oriented digital assistant\ndesigned to guide users through complex real-world tasks with multiple steps.\nCovering a wide range of cooking and how-to tasks, we aim to deliver a\ncollaborative and engaging dialogue experience. Equipped with language\nunderstanding, dialogue management, and response generation components\nsupported by a robust search engine, TacoBot ensures efficient task assistance.\nTo enhance the dialogue experience, we explore a series of data augmentation\nstrategies using LLMs to train advanced neural models continuously. TacoBot\nbuilds upon our successful participation in the inaugural Alexa Prize TaskBot\nChallenge, where our team secured third place among ten competing teams. We\noffer TacoBot as an open-source framework that serves as a practical example\nfor deploying task-oriented dialogue systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mo_L/0/1/0/all/0/1\">Lingbo Mo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1\">Shijie Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Ziru Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1\">Xiang Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lewis_A/0/1/0/all/0/1\">Ashley Lewis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sunit Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stevens_S/0/1/0/all/0/1\">Samuel Stevens</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tai_C/0/1/0/all/0/1\">Chang-You Tai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiang Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianshu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yu Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16082","description":"<p>Social platforms have emerged as a crucial platform for disseminating and\ndiscussing information about real-life events, which offers an excellent\nopportunity for early detection of newsworthy events. However, most existing\napproaches for event detection solely exploit keyword burstiness or network\nstructures to detect hot events. Thus, they often fail to identify emerging\nsocial events before reaching a trending state regarding the challenging nature\nof events and social data. Social data, e.g., tweets, is characterized by\nmisspellings, incompleteness, ambiguity, and irregular language, as well as\nvariation in aspects of opinions. Moreover, learning the evolving\ncharacteristics of the events utilizing limited contextual knowledge is almost\ninfeasible for machine learning models. To address these problems, in this\npaper, we propose a framework that exploits the lexical, semantic, and\ncontextual representations of streaming social data. In particular, we leverage\ncontextual knowledge to detect semantically related tweets in their earliest\nemergence and enhance the quality of produced clusters. We next produce a\ncluster chains for each event to show the evolving variation of the event\nthrough time. We conducted extensive experiments to evaluate our framework,\nvalidating the effectiveness of the proposed framework in detecting and\ndistinguishing social events.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Esfahani_M/0/1/0/all/0/1\">Mohammadali Sefidi Esfahani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbari_M/0/1/0/all/0/1\">Mohammad Akbari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension. (arXiv:2307.16125v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16125","description":"<p>Based on powerful Large Language Models (LLMs), recent generative Multimodal\nLarge Language Models (MLLMs) have gained prominence as a pivotal research\narea, exhibiting remarkable capability for both comprehension and generation.\nIn this work, we address the evaluation of generative comprehension in MLLMs as\na preliminary step towards a comprehensive assessment of generative models, by\nintroducing a benchmark named SEED-Bench. SEED-Bench consists of 19K multiple\nchoice questions with accurate human annotations (x 6 larger than existing\nbenchmarks), which spans 12 evaluation dimensions including the comprehension\nof both the image and video modality. We develop an advanced pipeline for\ngenerating multiple-choice questions that target specific evaluation\ndimensions, integrating both automatic filtering and manual verification\nprocesses. Multiple-choice questions with groundtruth options derived from\nhuman annotation enables an objective and efficient assessment of model\nperformance, eliminating the need for human or GPT intervention during\nevaluation. We further evaluate the performance of 18 models across all 12\ndimensions, covering both the spatial and temporal understanding. By revealing\nthe limitations of existing MLLMs through evaluation results, we aim for\nSEED-Bench to provide insights for motivating future research. We will launch\nand consistently maintain a leaderboard to provide a platform for the community\nto assess and investigate model capability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bohao Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1\">Rui Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1\">Guangzhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yuying Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yixiao Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1\">Ying Shan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"User-Controlled Knowledge Fusion in Large Language Models: Balancing Creativity and Hallucination. (arXiv:2307.16139v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16139","description":"<p>In modern dialogue systems, the use of Large Language Models (LLMs) has grown\nexponentially due to their capacity to generate diverse, relevant, and creative\nresponses. Despite their strengths, striking a balance between the LLMs'\ncreativity and their faithfulness to external knowledge remains a key\nchallenge. This paper presents an innovative user-controllable mechanism that\nmodulates the balance between an LLM's imaginative capabilities and its\nadherence to factual information. Our approach incorporates a numerical tag\nduring the fine-tuning phase of the LLM's training, representing the degree of\nfaithfulness to the reference knowledge in the generated responses. This degree\nis computed through an automated process that measures lexical overlap using\nROUGE scores, semantic similarity using Sentence-BERT embeddings, and an LLM's\nself-evaluation score. During model inference, users can manipulate this\nnumerical tag, thus controlling the degree of the LLM's reliance on external\nknowledge. We conduct extensive experiments across various scenarios,\ndemonstrating the adaptability of our method and its efficacy in ensuring the\nquality and accuracy of the LLM's responses. The results highlight the\npotential of our approach to enhance the versatility of LLMs while maintaining\na balance between creativity and hallucination.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chen Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Do LLMs Possess a Personality? Making the MBTI Test an Amazing Evaluation for Large Language Models. (arXiv:2307.16180v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16180","description":"<p>The field of large language models (LLMs) has made significant progress, and\ntheir knowledge storage capacity is approaching that of human beings.\nFurthermore, advanced techniques, such as prompt learning and reinforcement\nlearning, are being employed to address ethical concerns and hallucination\nproblems associated with LLMs, bringing them closer to aligning with human\nvalues. This situation naturally raises the question of whether LLMs with\nhuman-like abilities possess a human-like personality? In this paper, we aim to\ninvestigate the feasibility of using the Myers-Briggs Type Indicator (MBTI), a\nwidespread human personality assessment tool, as an evaluation metric for LLMs.\nSpecifically, extensive experiments will be conducted to explore: 1) the\npersonality types of different LLMs, 2) the possibility of changing the\npersonality types by prompt engineering, and 3) How does the training dataset\naffect the model's personality. Although the MBTI is not a rigorous assessment,\nit can still reflect the similarity between LLMs and human personality. In\npractice, the MBTI has the potential to serve as a rough indicator. Our codes\nare available at\nhttps://github.com/HarderThenHarder/transformers_tasks/tree/main/LLM/llms_mbti.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_K/0/1/0/all/0/1\">Keyu Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yawen Zeng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving TTS for Shanghainese: Addressing Tone Sandhi via Word Segmentation. (arXiv:2307.16199v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16199","description":"<p>Tone is a crucial component of the prosody of Shanghainese, a Wu Chinese\nvariety spoken primarily in urban Shanghai. Tone sandhi, which applies to all\nmulti-syllabic words in Shanghainese, then, is key to natural-sounding speech.\nUnfortunately, recent work on Shanghainese TTS (text-to-speech) such as Apple's\nVoiceOver has shown poor performance with tone sandhi, especially LD\n(left-dominant sandhi). Here I show that word segmentation during text\npreprocessing can improve the quality of tone sandhi production in TTS models.\nSyllables within the same word are annotated with a special symbol, which\nserves as a proxy for prosodic information of the domain of LD. Contrary to the\ncommon practice of using prosodic annotation mainly for static pauses, this\npaper demonstrates that prosodic annotation can also be applied to dynamic\ntonal phenomena. I anticipate this project to be a starting point for bringing\nformal linguistic accounts of Shanghainese into computational projects. Too\nlong have we been using the Mandarin models to approximate Shanghainese, but it\nis a different language with its own linguistic features, and its digitisation\nand revitalisation should be treated as such.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuanhao Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue Information Extraction. (arXiv:2307.16200v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16200","description":"<p>This paper focuses on term-status pair extraction from medical dialogues\n(MD-TSPE), which is essential in diagnosis dialogue systems and the automatic\nscribe of electronic medical records (EMRs). In the past few years, works on\nMD-TSPE have attracted increasing research attention, especially after the\nremarkable progress made by generative methods. However, these generative\nmethods output a whole sequence consisting of term-status pairs in one stage\nand ignore integrating prior knowledge, which demands a deeper understanding to\nmodel the relationship between terms and infer the status of each term. This\npaper presents a knowledge-enhanced two-stage generative framework (KTGF) to\naddress the above challenges. Using task-specific prompts, we employ a single\nmodel to complete the MD-TSPE through two phases in a unified generative form:\nwe generate all terms the first and then generate the status of each generated\nterm. In this way, the relationship between terms can be learned more\neffectively from the sequence containing only terms in the first phase, and our\ndesigned knowledge-enhanced prompt in the second phase can leverage the\ncategory and status candidates of the generated term for status generation.\nFurthermore, our proposed special status ``not mentioned\" makes more terms\navailable and enriches the training data in the second phase, which is critical\nin the low-resource setting. The experiments on the Chunyu and CMDD datasets\nshow that the proposed method achieves superior results compared to the\nstate-of-the-art models in the full training and low-resource settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zefa Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1\">Ziyi Ni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1\">Jing Shi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuang Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Bo Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Around the GLOBE: Numerical Aggregation Question-Answering on Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks. (arXiv:2307.16208v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16208","description":"<p>One of the key AI tools for textual corpora exploration is natural language\nquestion-answering (QA). Unlike keyword-based search engines, QA algorithms\nreceive and process natural language questions and produce precise answers to\nthese questions, rather than long lists of documents that need to be manually\nscanned by the users. State-of-the-art QA algorithms based on DNNs were\nsuccessfully employed in various domains. However, QA in the genealogical\ndomain is still underexplored, while researchers in this field (and other\nfields in humanities and social sciences) can highly benefit from the ability\nto ask questions in natural language, receive concrete answers and gain\ninsights hidden within large corpora. While some research has been recently\nconducted for factual QA in the genealogical domain, to the best of our\nknowledge, there is no previous research on the more challenging task of\nnumerical aggregation QA (i.e., answering questions combining aggregation\nfunctions, e.g., count, average, max). Numerical aggregation QA is critical for\ndistant reading and analysis for researchers (and the general public)\ninterested in investigating cultural heritage domains. Therefore, in this\nstudy, we present a new end-to-end methodology for numerical aggregation QA for\ngenealogical trees that includes: 1) an automatic method for training dataset\ngeneration; 2) a transformer-based table selection method, and 3) an optimized\ntransformer-based numerical aggregation QA model. The findings indicate that\nthe proposed architecture, GLOBE, outperforms the state-of-the-art models and\npipelines by achieving 87% accuracy for this task compared to only 21% by\ncurrent state-of-the-art models. This study may have practical implications for\ngenealogical information centers and museums, making genealogical data research\neasy and scalable for experts as well as the general public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suissa_O/0/1/0/all/0/1\">Omri Suissa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhitomirsky_Geffet_M/0/1/0/all/0/1\">Maayan Zhitomirsky-Geffet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmalech_A/0/1/0/all/0/1\">Avshalom Elmalech</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Toward a Period-Specific Optimized Neural Network for OCR Error Correction of Historical Hebrew Texts. (arXiv:2307.16213v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16213","description":"<p>Over the past few decades, large archives of paper-based historical\ndocuments, such as books and newspapers, have been digitized using the Optical\nCharacter Recognition (OCR) technology. Unfortunately, this broadly used\ntechnology is error-prone, especially when an OCRed document was written\nhundreds of years ago. Neural networks have shown great success in solving\nvarious text processing tasks, including OCR post-correction. The main\ndisadvantage of using neural networks for historical corpora is the lack of\nsufficiently large training datasets they require to learn from, especially for\nmorphologically-rich languages like Hebrew. Moreover, it is not clear what are\nthe optimal structure and values of hyperparameters (predefined parameters) of\nneural networks for OCR error correction in Hebrew due to its unique features.\nFurthermore, languages change across genres and periods. These changes may\naffect the accuracy of OCR post-correction neural network models. To overcome\nthese challenges, we developed a new multi-phase method for generating\nartificial training datasets with OCR errors and hyperparameters optimization\nfor building an effective neural network for OCR post-correction in Hebrew.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suissa_O/0/1/0/all/0/1\">Omri Suissa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhitomirsky_Geffet_M/0/1/0/all/0/1\">Maayan Zhitomirsky-Geffet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmalech_A/0/1/0/all/0/1\">Avshalom Elmalech</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Question Answering with Deep Neural Networks for Semi-Structured Heterogeneous Genealogical Knowledge Graphs. (arXiv:2307.16214v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16214","description":"<p>With the rising popularity of user-generated genealogical family trees, new\ngenealogical information systems have been developed. State-of-the-art natural\nquestion answering algorithms use deep neural network (DNN) architecture based\non self-attention networks. However, some of these models use sequence-based\ninputs and are not suitable to work with graph-based structure, while\ngraph-based DNN models rely on high levels of comprehensiveness of knowledge\ngraphs that is nonexistent in the genealogical domain. Moreover, these\nsupervised DNN models require training datasets that are absent in the\ngenealogical domain. This study proposes an end-to-end approach for question\nanswering using genealogical family trees by: 1) representing genealogical data\nas knowledge graphs, 2) converting them to texts, 3) combining them with\nunstructured texts, and 4) training a trans-former-based question answering\nmodel. To evaluate the need for a dedicated approach, a comparison between the\nfine-tuned model (Uncle-BERT) trained on the auto-generated genealogical\ndataset and state-of-the-art question-answering models was per-formed. The\nfindings indicate that there are significant differences between answering\ngenealogical questions and open-domain questions. Moreover, the proposed\nmethodology reduces complexity while increasing accuracy and may have practical\nimplications for genealogical research and real-world projects, making\ngenealogical data accessible to experts as well as the general public.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suissa_O/0/1/0/all/0/1\">Omri Suissa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhitomirsky_Geffet_M/0/1/0/all/0/1\">Maayan Zhitomirsky-Geffet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmalech_A/0/1/0/all/0/1\">Avshalom Elmalech</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text Analysis Using Deep Neural Networks in Digital Humanities and Information Science. (arXiv:2307.16217v1 [cs.LG])","link":"http://arxiv.org/abs/2307.16217","description":"<p>Combining computational technologies and humanities is an ongoing effort\naimed at making resources such as texts, images, audio, video, and other\nartifacts digitally available, searchable, and analyzable. In recent years,\ndeep neural networks (DNN) dominate the field of automatic text analysis and\nnatural language processing (NLP), in some cases presenting a super-human\nperformance. DNNs are the state-of-the-art machine learning algorithms solving\nmany NLP tasks that are relevant for Digital Humanities (DH) research, such as\nspell checking, language detection, entity extraction, author detection,\nquestion answering, and other tasks. These supervised algorithms learn patterns\nfrom a large number of \"right\" and \"wrong\" examples and apply them to new\nexamples. However, using DNNs for analyzing the text resources in DH research\npresents two main challenges: (un)availability of training data and a need for\ndomain adaptation. This paper explores these challenges by analyzing multiple\nuse-cases of DH studies in recent literature and their possible solutions and\nlays out a practical decision model for DH experts for when and how to choose\nthe appropriate deep learning approaches for their research. Moreover, in this\npaper, we aim to raise awareness of the benefits of utilizing deep learning\nmodels in the DH community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suissa_O/0/1/0/all/0/1\">Omri Suissa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmalech_A/0/1/0/all/0/1\">Avshalom Elmalech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhitomirsky_Geffet_M/0/1/0/all/0/1\">Maayan Zhitomirsky-Geffet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Optimizing the Neural Network Training for OCR Error Correction of Historical Hebrew Texts. (arXiv:2307.16220v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16220","description":"<p>Over the past few decades, large archives of paper-based documents such as\nbooks and newspapers have been digitized using Optical Character Recognition.\nThis technology is error-prone, especially for historical documents. To correct\nOCR errors, post-processing algorithms have been proposed based on natural\nlanguage analysis and machine learning techniques such as neural networks.\nNeural network's disadvantage is the vast amount of manually labeled data\nrequired for training, which is often unavailable. This paper proposes an\ninnovative method for training a light-weight neural network for Hebrew OCR\npost-correction using significantly less manually created data. The main\nresearch goal is to develop a method for automatically generating language and\ntask-specific training data to improve the neural network results for OCR\npost-correction, and to investigate which type of dataset is the most effective\nfor OCR post-correction of historical documents. To this end, a series of\nexperiments using several datasets was conducted. The evaluation corpus was\nbased on Hebrew newspapers from the JPress project. An analysis of historical\nOCRed newspapers was done to learn common language and corpus-specific OCR\nerrors. We found that training the network using the proposed method is more\neffective than using randomly generated errors. The results also show that the\nperformance of the neural network for OCR post-correction strongly depends on\nthe genre and area of the training data. Moreover, neural networks that were\ntrained with the proposed method outperform other state-of-the-art neural\nnetworks for OCR post-correction and complex spellcheckers. These results may\nhave practical implications for many digital humanities projects.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Suissa_O/0/1/0/all/0/1\">Omri Suissa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Elmalech_A/0/1/0/all/0/1\">Avshalom Elmalech</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhitomirsky_Geffet_M/0/1/0/all/0/1\">Maayan Zhitomirsky-Geffet</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Private Watermark for Large Language Models. (arXiv:2307.16230v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16230","description":"<p>Recently, text watermarking algorithms for large language models (LLMs) have\nbeen mitigating the potential harms of text generated by the LLMs, including\nfake news and copyright issues. However, the watermark detection of current\ntext algorithms requires the key from the generation process, making them\nsusceptible to breaches and counterfeiting. In this work, we propose the first\nprivate watermarking algorithm, which extends the current text watermarking\nalgorithms by using two different neural networks respectively for watermark\ngeneration and detection, rather than using the same key at both stages.\nMeanwhile, part of the parameters of the watermark generation and detection\nnetworks are shared, which makes the detection network achieve a high accuracy\nvery efficiently. Experiments show that our algorithm ensures high detection\naccuracy with minimal impact on generation and detection speed, due to the\nsmall parameter size of both networks. Additionally, our subsequent analysis\ndemonstrates the difficulty of reverting the watermark generation rules from\nthe detection network.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1\">Aiwei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1\">Leyi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xuming Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1\">Shu&#x27;ang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wen_L/0/1/0/all/0/1\">Lijie Wen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1\">Irwin King</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Recent Advances in Hierarchical Multi-label Text Classification: A Survey. (arXiv:2307.16265v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16265","description":"<p>Hierarchical multi-label text classification aims to classify the input text\ninto multiple labels, among which the labels are structured and hierarchical.\nIt is a vital task in many real world applications, e.g. scientific literature\narchiving. In this paper, we survey the recent progress of hierarchical\nmulti-label text classification, including the open sourced data sets, the main\nmethods, evaluation metrics, learning strategies and the current challenges. A\nfew future research directions are also listed for community to further improve\nthis field.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1\">Rundong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1\">Wenhan Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1\">Weijun Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1\">Yuxiang Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">He Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1\">Ruohua Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunfeng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1\">Ming Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mispronunciation detection using self-supervised speech representations. (arXiv:2307.16324v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16324","description":"<p>In recent years, self-supervised learning (SSL) models have produced\npromising results in a variety of speech-processing tasks, especially in\ncontexts of data scarcity. In this paper, we study the use of SSL models for\nthe task of mispronunciation detection for second language learners. We compare\ntwo downstream approaches: 1) training the model for phone recognition (PR)\nusing native English data, and 2) training a model directly for the target task\nusing non-native English data. We compare the performance of these two\napproaches for various SSL representations as well as a representation\nextracted from a traditional DNN-based speech recognition model. We evaluate\nthe models on L2Arctic and EpaDB, two datasets of non-native speech annotated\nwith pronunciation labels at the phone level. Overall, we find that using a\ndownstream model trained for the target task gives the best performance and\nthat most upstream models perform similarly for the task.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vidal_J/0/1/0/all/0/1\">Jazmin Vidal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Riera_P/0/1/0/all/0/1\">Pablo Riera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_L/0/1/0/all/0/1\">Luciana Ferrer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Distractor generation for multiple-choice questions with predictive prompting and large language models. (arXiv:2307.16338v1 [cs.CL])","link":"http://arxiv.org/abs/2307.16338","description":"<p>Large Language Models (LLMs) such as ChatGPT have demonstrated remarkable\nperformance across various tasks and have garnered significant attention from\nboth researchers and practitioners. However, in an educational context, we\nstill observe a performance gap in generating distractors -- i.e., plausible\nyet incorrect answers -- with LLMs for multiple-choice questions (MCQs). In\nthis study, we propose a strategy for guiding LLMs such as ChatGPT, in\ngenerating relevant distractors by prompting them with question items\nautomatically retrieved from a question bank as well-chosen in-context\nexamples. We evaluate our LLM-based solutions using a quantitative assessment\non an existing test set, as well as through quality annotations by human\nexperts, i.e., teachers. We found that on average 53% of the generated\ndistractors presented to the teachers were rated as high-quality, i.e.,\nsuitable for immediate use as is, outperforming the state-of-the-art model. We\nalso show the gains of our approach 1 in generating high-quality distractors by\ncomparing it with a zero-shot ChatGPT and a few-shot ChatGPT prompted with\nstatic examples.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bitew_S/0/1/0/all/0/1\">Semere Kiros Bitew</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1\">Johannes Deleu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1\">Chris Develder</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1\">Thomas Demeester</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Tackling Query-Focused Summarization as A Knowledge-Intensive Task: A Pilot Study. (arXiv:2112.07536v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2112.07536","description":"<p>Query-focused summarization (QFS) requires generating a summary given a query\nusing a set of relevant documents. However, such relevant documents should be\nannotated manually and thus are not readily available in realistic scenarios.\nTo address this limitation, we tackle the QFS task as a knowledge-intensive\n(KI) task without access to any relevant documents. Instead, we assume that\nthese documents are present in a large-scale knowledge corpus and should be\nretrieved first. To explore this new setting, we build a new dataset (KI-QFS)\nby adapting existing QFS datasets. In this dataset, answering the query\nrequires document retrieval from a knowledge corpus. We construct three\ndifferent knowledge corpora, and we further provide relevance annotations to\nenable retrieval evaluation. Finally, we benchmark the dataset with\nstate-of-the-art QFS models and retrieval-enhanced models. The experimental\nresults demonstrate that QFS models perform significantly worse on KI-QFS\ncompared to the original QFS task, indicating that the knowledge-intensive\nsetting is much more challenging and offers substantial room for improvement.\nWe believe that our investigation will inspire further research into addressing\nQFS in more realistic scenarios.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Weijia Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1\">Svitlana Vakulenko</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rajapakse_T/0/1/0/all/0/1\">Thilina Rajapakse</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1\">Yumo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1\">Evangelos Kanoulas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Reasoning Through Memorization: Nearest Neighbor Knowledge Graph Embeddings. (arXiv:2201.05575v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.05575","description":"<p>Previous knowledge graph embedding approaches usually map entities to\nrepresentations and utilize score functions to predict the target entities, yet\nthey typically struggle to reason rare or emerging unseen entities. In this\npaper, we propose kNN-KGE, a new knowledge graph embedding approach with\npre-trained language models, by linearly interpolating its entity distribution\nwith k-nearest neighbors. We compute the nearest neighbors based on the\ndistance in the entity embedding space from the knowledge store. Our approach\ncan allow rare or emerging entities to be memorized explicitly rather than\nimplicitly in model parameters. Experimental results demonstrate that our\napproach can improve inductive and transductive link prediction results and\nyield better performance for low-resource settings with only a few triples,\nwhich might be easier to reason via explicit memory. Code is available at\nhttps://github.com/zjunlp/KNN-KG.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1\">Peng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xin Xie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xiaohan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1\">Ningyu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Does Transliteration Help Multilingual Language Modeling?. (arXiv:2201.12501v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2201.12501","description":"<p>Script diversity presents a challenge to Multilingual Language Models (MLLM)\nby reducing lexical overlap among closely related languages. Therefore,\ntransliterating closely related languages that use different writing scripts to\na common script may improve the downstream task performance of MLLMs. We\nempirically measure the effect of transliteration on MLLMs in this context. We\nspecifically focus on the Indic languages, which have the highest script\ndiversity in the world, and we evaluate our models on the IndicGLUE benchmark.\nWe perform the Mann-Whitney U test to rigorously verify whether the effect of\ntransliteration is significant or not. We find that transliteration benefits\nthe low-resource languages without negatively affecting the comparatively\nhigh-resource languages. We also measure the cross-lingual representation\nsimilarity of the models using centered kernel alignment on parallel sentences\nfrom the FLORES-101 dataset. We find that for parallel sentences across\ndifferent languages, the transliteration-based model learns sentence\nrepresentations that are more similar.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Moosa_I/0/1/0/all/0/1\">Ibraheem Muhammad Moosa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akhter_M/0/1/0/all/0/1\">Mahmud Elahi Akhter</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Habib_A/0/1/0/all/0/1\">Ashfia Binte Habib</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Probing for the Usage of Grammatical Number. (arXiv:2204.08831v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2204.08831","description":"<p>A central quest of probing is to uncover how pre-trained models encode a\nlinguistic property within their representations. An encoding, however, might\nbe spurious-i.e., the model might not rely on it when making predictions. In\nthis paper, we try to find encodings that the model actually uses, introducing\na usage-based probing setup. We first choose a behavioral task which cannot be\nsolved without using the linguistic property. Then, we attempt to remove the\nproperty by intervening on the model's representations. We contend that, if an\nencoding is used by the model, its removal should harm the performance on the\nchosen behavioral task. As a case study, we focus on how BERT encodes\ngrammatical number, and on how it uses this encoding to solve the number\nagreement task. Experimentally, we find that BERT relies on a linear encoding\nof grammatical number to produce the correct behavioral output. We also find\nthat BERT uses a separate encoding of grammatical number for nouns and verbs.\nFinally, we identify in which layers information about grammatical number is\ntransferred from a noun to its head verb.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lasri_K/0/1/0/all/0/1\">Karim Lasri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lenci_A/0/1/0/all/0/1\">Alessandro Lenci</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poibeau_T/0/1/0/all/0/1\">Thierry Poibeau</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Boosting Cross-Domain Speech Recognition with Self-Supervision. (arXiv:2206.09783v2 [eess.AS] UPDATED)","link":"http://arxiv.org/abs/2206.09783","description":"<p>The cross-domain performance of automatic speech recognition (ASR) could be\nseverely hampered due to the mismatch between training and testing\ndistributions. Since the target domain usually lacks labeled data, and domain\nshifts exist at acoustic and linguistic levels, it is challenging to perform\nunsupervised domain adaptation (UDA) for ASR. Previous work has shown that\nself-supervised learning (SSL) or pseudo-labeling (PL) is effective in UDA by\nexploiting the self-supervisions of unlabeled data. However, these\nself-supervisions also face performance degradation in mismatched domain\ndistributions, which previous work fails to address. This work presents a\nsystematic UDA framework to fully utilize the unlabeled data with\nself-supervision in the pre-training and fine-tuning paradigm. On the one hand,\nwe apply continued pre-training and data replay techniques to mitigate the\ndomain mismatch of the SSL pre-trained model. On the other hand, we propose a\ndomain-adaptive fine-tuning approach based on the PL technique with three\nunique modifications: Firstly, we design a dual-branch PL method to decrease\nthe sensitivity to the erroneous pseudo-labels; Secondly, we devise an\nuncertainty-aware confidence filtering strategy to improve pseudo-label\ncorrectness; Thirdly, we introduce a two-step PL approach to incorporate target\ndomain linguistic knowledge, thus generating more accurate target domain\npseudo-labels. Experimental results on various cross-domain scenarios\ndemonstrate that the proposed approach effectively boosts the cross-domain\nperformance and significantly outperforms previous approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1\">Han Zhu</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Cheng_G/0/1/0/all/0/1\">Gaofeng Cheng</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Hou_W/0/1/0/all/0/1\">Wenxin Hou</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Zhang_P/0/1/0/all/0/1\">Pengyuan Zhang</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1\">Yonghong Yan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Isotropic Representation Can Improve Dense Retrieval. (arXiv:2209.00218v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2209.00218","description":"<p>The recent advancement in language representation modeling has broadly\naffected the design of dense retrieval models. In particular, many of the\nhigh-performing dense retrieval models evaluate representations of query and\ndocument using BERT, and subsequently apply a cosine-similarity based scoring\nto determine the relevance. BERT representations, however, are known to follow\nan anisotropic distribution of a narrow cone shape and such an anisotropic\ndistribution can be undesirable for the cosine-similarity based scoring. In\nthis work, we first show that BERT-based DR also follows an anisotropic\ndistribution. To cope with the problem, we introduce unsupervised\npost-processing methods of Normalizing Flow and whitening, and develop\ntoken-wise method in addition to the sequence-wise method for applying the\npost-processing methods to the representations of dense retrieval models. We\nshow that the proposed methods can effectively enhance the representations to\nbe isotropic, then we perform experiments with ColBERT and RepBERT to show that\nthe performance (NDCG at 10) of document re-ranking can be improved by\n5.17\\%$\\sim$8.09\\% for ColBERT and 6.88\\%$\\sim$22.81\\% for RepBERT. To examine\nthe potential of isotropic representation for improving the robustness of DR\nmodels, we investigate out-of-distribution tasks where the test dataset differs\nfrom the training dataset. The results show that isotropic representation can\nachieve a generally improved performance. For instance, when training dataset\nis MS-MARCO and test dataset is Robust04, isotropy post-processing can improve\nthe baseline performance by up to 24.98\\%. Furthermore, we show that an\nisotropic model trained with an out-of-distribution dataset can even outperform\na baseline model trained with the in-distribution dataset.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jung_E/0/1/0/all/0/1\">Euna Jung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1\">Jungwon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jaekeol Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1\">Sungyoon Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rhee_W/0/1/0/all/0/1\">Wonjong Rhee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"X$^2$-VLM: All-In-One Pre-trained Model For Vision-Language Tasks. (arXiv:2211.12402v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2211.12402","description":"<p>Vision language pre-training aims to learn alignments between vision and\nlanguage from a large amount of data. Most existing methods only learn\nimage-text alignments. Some others utilize pre-trained object detectors to\nleverage vision language alignments at the object level. In this paper, we\npropose to learn multi-grained vision language alignments by a unified\npre-training framework that learns multi-grained aligning and multi-grained\nlocalization simultaneously. Based on it, we present X$^2$-VLM, an all-in-one\nmodel with a flexible modular architecture, in which we further unify\nimage-text pre-training and video-text pre-training in one model. X$^2$-VLM is\nable to learn unlimited visual concepts associated with diverse text\ndescriptions. Experiment results show that X$^2$-VLM performs the best on base\nand large scale for both image-text and video-text tasks, making a good\ntrade-off between performance and model scale. Moreover, we show that the\nmodular design of X$^2$-VLM results in high transferability for it to be\nutilized in any language or domain. For example, by simply replacing the text\nencoder with XLM-R, X$^2$-VLM outperforms state-of-the-art multilingual\nmulti-modal pre-trained models without any multilingual pre-training. The code\nand pre-trained models are available at https://github.com/zengyan-97/X2-VLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinsong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Hang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiawei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jipeng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1\">Wangchunshu Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sources of Noise in Dialogue and How to Deal with Them. (arXiv:2212.02745v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.02745","description":"<p>Training dialogue systems often entails dealing with noisy training examples\nand unexpected user inputs. Despite their prevalence, there currently lacks an\naccurate survey of dialogue noise, nor is there a clear sense of the impact of\neach noise type on task performance. This paper addresses this gap by first\nconstructing a taxonomy of noise encountered by dialogue systems. In addition,\nwe run a series of experiments to show how different models behave when\nsubjected to varying levels of noise and types of noise. Our results reveal\nthat models are quite robust to label errors commonly tackled by existing\ndenoising algorithms, but that performance suffers from dialogue-specific\nnoise. Driven by these observations, we design a data cleaning algorithm\nspecialized for conversational settings and apply it as a proof-of-concept for\ntargeted dialogue denoising.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1\">Derek Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1\">Zhou Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't Forget Your ABC's: Evaluating the State-of-the-Art in Chat-Oriented Dialogue Systems. (arXiv:2212.09180v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.09180","description":"<p>Despite tremendous advancements in dialogue systems, stable evaluation still\nrequires human judgments producing notoriously high-variance metrics due to\ntheir inherent subjectivity. Moreover, methods and labels in dialogue\nevaluation are not fully standardized, especially for open-domain chats, with a\nlack of work to compare and assess the validity of those approaches. The use of\ninconsistent evaluation can misinform the performance of a dialogue system,\nwhich becomes a major hurdle to enhance it. Thus, a dimensional evaluation of\nchat-oriented open-domain dialogue systems that reliably measures several\naspects of dialogue capabilities is desired. This paper presents a novel human\nevaluation method to estimate the rates of many dialogue system behaviors. Our\nmethod is used to evaluate four state-of-the-art open-domain dialogue systems\nand compared with existing approaches. The analysis demonstrates that our\nbehavior method is more suitable than alternative Likert-style or comparative\napproaches for dimensional evaluation of these systems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Finch_S/0/1/0/all/0/1\">Sarah E. Finch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Finch_J/0/1/0/all/0/1\">James D. Finch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1\">Jinho D. Choi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog. (arXiv:2212.10008v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2212.10008","description":"<p>Many efforts have been made to construct dialog systems for different types\nof conversations, such as task-oriented dialog (TOD) and open-domain dialog\n(ODD). To better mimic human-level conversations that usually fuse various\ndialog modes, it is essential to build a system that can effectively handle\nboth TOD and ODD and access different knowledge sources. To address the lack of\navailable data for the fused task, we propose a framework for automatically\ngenerating dialogues that combine knowledge-grounded ODDs and TODs in various\nsettings. Additionally, we introduce a unified model PivotBot that is capable\nof appropriately adopting TOD and ODD modes and accessing different knowledge\nsources in order to effectively tackle the fused task. Evaluation results\ndemonstrate the superior ability of the proposed model to switch seamlessly\nbetween TOD and ODD tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Miaoran Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Baolin Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1\">Michel Galley</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1\">Jianfeng Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MEAformer: Multi-modal Entity Alignment Transformer for Meta Modality Hybrid. (arXiv:2212.14454v4 [cs.AI] UPDATED)","link":"http://arxiv.org/abs/2212.14454","description":"<p>Multi-modal entity alignment (MMEA) aims to discover identical entities\nacross different knowledge graphs (KGs) whose entities are associated with\nrelevant images. However, current MMEA algorithms rely on KG-level modality\nfusion strategies for multi-modal entity representation, which ignores the\nvariations of modality preferences of different entities, thus compromising\nrobustness against noise in modalities such as blurry images and relations.\nThis paper introduces MEAformer, a multi-modal entity alignment transformer\napproach for meta modality hybrid, which dynamically predicts the mutual\ncorrelation coefficients among modalities for more fine-grained entity-level\nmodality fusion and alignment. Experimental results demonstrate that our model\nnot only achieves SOTA performance in multiple training scenarios, including\nsupervised, unsupervised, iterative, and low-resource settings, but also has a\nlimited number of parameters, efficient runtime, and interpretability. Our code\nis available at https://github.com/zjukg/MEAformer.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1\">Zhuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaoyan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1\">Lingbing Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yin Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1\">Yufeng Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yichi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Geng_Y/0/1/0/all/0/1\">Yuxia Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jeff Z. Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1\">Wenting Song</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Huajun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Competence-Based Analysis of Language Models. (arXiv:2303.00333v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.00333","description":"<p>Despite the recent success of large pretrained language models (LMs) on a\nvariety of prompting tasks, these models can be alarmingly brittle to small\nchanges in inputs or application contexts. To better understand such behavior\nand motivate the design of more robust LMs, we propose a general experimental\nframework, CALM (Competence-based Analysis of Language Models), where targeted\ncausal interventions are utilized to damage an LM's internal representation of\nvarious linguistic properties in order to evaluate its use of each\nrepresentation in performing a given task. We implement these interventions as\ngradient-based adversarial attacks, which (in contrast to prior causal probing\nmethodologies) are able to target arbitrarily-encoded representations of\nrelational properties, and carry out a case study of this approach to analyze\nhow BERT-like LMs use representations of several relational properties in\nperforming associated relation prompting tasks. We find that, while the\nrepresentations LMs leverage in performing each task are highly entangled, they\nmay be meaningfully interpreted in terms of the tasks where they are most\nutilized; and more broadly, that CALM enables an expanded scope of inquiry in\nLM analysis that may be useful in predicting and explaining weaknesses of\nexisting LMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Davies_A/0/1/0/all/0/1\">Adam Davies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1\">Jize Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_C/0/1/0/all/0/1\">ChengXiang Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Hybrid Architecture for Out of Domain Intent Detection and Intent Discovery. (arXiv:2303.04134v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.04134","description":"<p>Intent Detection is one of the tasks of the Natural Language Understanding\n(NLU) unit in task-oriented dialogue systems. Out of Scope (OOS) and Out of\nDomain (OOD) inputs may run these systems into a problem. On the other side, a\nlabeled dataset is needed to train a model for Intent Detection in\ntask-oriented dialogue systems. The creation of a labeled dataset is\ntime-consuming and needs human resources. The purpose of this article is to\naddress mentioned problems. The task of identifying OOD/OOS inputs is named\nOOD/OOS Intent Detection. Also, discovering new intents and pseudo-labeling of\nOOD inputs is well known by Intent Discovery. In OOD intent detection part, we\nmake use of a Variational Autoencoder to distinguish between known and unknown\nintents independent of input data distribution. After that, an unsupervised\nclustering method is used to discover different unknown intents underlying\nOOD/OOS inputs. We also apply a non-linear dimensionality reduction on OOD/OOS\nrepresentations to make distances between representations more meaning full for\nclustering. Our results show that the proposed model for both OOD/OOS Intent\nDetection and Intent Discovery achieves great results and passes baselines in\nEnglish and Persian languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Akbari_M/0/1/0/all/0/1\">Masoud Akbari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohades_A/0/1/0/all/0/1\">Ali Mohades</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shirali_Shahreza_M/0/1/0/all/0/1\">M. Hassan Shirali-Shahreza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models. (arXiv:2303.10464v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2303.10464","description":"<p>The pre-training and fine-tuning paradigm has contributed to a number of\nbreakthroughs in Natural Language Processing (NLP). Instead of directly\ntraining on a downstream task, language models are first pre-trained on large\ndatasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then\nfine-tuned on task-specific data (e.g., natural language generation, text\nsummarization, etc.). Scaling the model and dataset size has helped improve the\nperformance of LLMs, but unfortunately, this also lead to highly prohibitive\ncomputational costs. Pre-training LLMs often require orders of magnitude more\nFLOPs than fine-tuning and the model capacity often remains the same between\nthe two phases. To achieve training efficiency w.r.t training FLOPs, we propose\nto decouple the model capacity between the two phases and introduce Sparse\nPre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits\nof using unstructured weight sparsity to train only a subset of weights during\npre-training (Sparse Pre-training) and then recover the representational\ncapacity by allowing the zeroed weights to learn (Dense Fine-tuning). We\ndemonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3\nXL model resulting in a 2.5x reduction in pre-training FLOPs, without a\nsignificant loss in accuracy on the downstream tasks relative to the dense\nbaseline. By rigorously evaluating multiple downstream tasks, we also establish\na relationship between sparsity, task complexity and dataset size. Our work\npresents a promising direction to train large GPT models at a fraction of the\ntraining FLOPs using weight sparsity, while retaining the benefits of\npre-trained textual representations for downstream tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thangarasa_V/0/1/0/all/0/1\">Vithursan Thangarasa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1\">Abhay Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marshall_W/0/1/0/all/0/1\">William Marshall</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianda Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leong_K/0/1/0/all/0/1\">Kevin Leong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeCoste_D/0/1/0/all/0/1\">Dennis DeCoste</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lie_S/0/1/0/all/0/1\">Sean Lie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1\">Shreyas Saxena</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT for Shaping the Future of Dentistry: The Potential of Multi-Modal Large Language Model. (arXiv:2304.03086v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.03086","description":"<p>The ChatGPT, a lite and conversational variant of Generative Pretrained\nTransformer 4 (GPT-4) developed by OpenAI, is one of the milestone Large\nLanguage Models (LLMs) with billions of parameters. LLMs have stirred up much\ninterest among researchers and practitioners in their impressive skills in\nnatural language processing tasks, which profoundly impact various fields. This\npaper mainly discusses the future applications of LLMs in dentistry. We\nintroduce two primary LLM deployment methods in dentistry, including automated\ndental diagnosis and cross-modal dental diagnosis, and examine their potential\napplications. Especially, equipped with a cross-modal encoder, a single LLM can\nmanage multi-source data and conduct advanced natural language reasoning to\nperform complex clinical operations. We also present cases to demonstrate the\npotential of a fully automatic Multi-Modal LLM AI system for dentistry clinical\napplication. While LLMs offer significant potential benefits, the challenges,\nsuch as data privacy, data quality, and model bias, need further study.\nOverall, LLMs have the potential to revolutionize dental diagnosis and\ntreatment, which indicates a promising avenue for clinical application and\nresearch in dentistry.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Hanyao Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_O/0/1/0/all/0/1\">Ou Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1\">Dongdong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jiayi Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zijin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1\">Shengxuan Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1\">Heng Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1\">Chuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1\">Renjie Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1\">Qian Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1\">Bing Shi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Are Large Language Models Ready for Healthcare? A Comparative Study on Clinical Language Understanding. (arXiv:2304.05368v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2304.05368","description":"<p>Large language models (LLMs) have made significant progress in various\ndomains, including healthcare. However, the specialized nature of clinical\nlanguage understanding tasks presents unique challenges and limitations that\nwarrant further investigation. In this study, we conduct a comprehensive\nevaluation of state-of-the-art LLMs, namely GPT-3.5, GPT-4, and Bard, within\nthe realm of clinical language understanding tasks. These tasks span a diverse\nrange, including named entity recognition, relation extraction, natural\nlanguage inference, semantic textual similarity, document classification, and\nquestion-answering. We also introduce a novel prompting strategy,\nself-questioning prompting (SQP), tailored to enhance LLMs' performance by\neliciting informative questions and answers pertinent to the clinical scenarios\nat hand. Our evaluation underscores the significance of task-specific learning\nstrategies and prompting techniques for improving LLMs' effectiveness in\nhealthcare-related tasks. Additionally, our in-depth error analysis on the\nchallenging relation extraction task offers valuable insights into error\ndistribution and potential avenues for improvement using SQP. Our study sheds\nlight on the practical implications of employing LLMs in the specialized domain\nof healthcare, serving as a foundation for future research and the development\nof potential applications in healthcare settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqing Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1\">Yun Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petzold_L/0/1/0/all/0/1\">Linda Petzold</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization. (arXiv:2304.14535v2 [cs.SD] UPDATED)","link":"http://arxiv.org/abs/2304.14535","description":"<p>Automatic speech recognition (ASR) has recently become an important challenge\nwhen using deep learning (DL). It requires large-scale training datasets and\nhigh computational and storage resources. Moreover, DL techniques and machine\nlearning (ML) approaches in general, hypothesize that training and testing data\ncome from the same domain, with the same input feature space and data\ndistribution characteristics. This assumption, however, is not applicable in\nsome real-world artificial intelligence (AI) applications. Moreover, there are\nsituations where gathering real data is challenging, expensive, or rarely\noccurring, which can not meet the data requirements of DL models. deep transfer\nlearning (DTL) has been introduced to overcome these issues, which helps\ndevelop high-performing models using real datasets that are small or slightly\ndifferent but related to the training data. This paper presents a comprehensive\nsurvey of DTL-based ASR frameworks to shed light on the latest developments and\nhelps academics and professionals understand current challenges. Specifically,\nafter presenting the DTL background, a well-designed taxonomy is adopted to\ninform the state-of-the-art. A critical analysis is then conducted to identify\nthe limitations and advantages of each framework. Moving on, a comparative\nstudy is introduced to highlight the current challenges before deriving\nopportunities for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kheddar_H/0/1/0/all/0/1\">Hamza Kheddar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Himeur_Y/0/1/0/all/0/1\">Yassine Himeur</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Al_Maadeed_S/0/1/0/all/0/1\">Somaya Al-Maadeed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amira_A/0/1/0/all/0/1\">Abbes Amira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bensaali_F/0/1/0/all/0/1\">Faycal Bensaali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constructing and Interpreting Causal Knowledge Graphs from News. (arXiv:2305.09359v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09359","description":"<p>Many financial jobs rely on news to learn about causal events in the past and\npresent, to make informed decisions and predictions about the future. With the\never-increasing amount of news available online, there is a need to automate\nthe extraction of causal events from unstructured texts. In this work, we\npropose a methodology to construct causal knowledge graphs (KGs) from news\nusing two steps: (1) Extraction of Causal Relations, and (2) Argument\nClustering and Representation into KG. We aim to build graphs that emphasize on\nrecall, precision and interpretability. For extraction, although many earlier\nworks already construct causal KGs from text, most adopt rudimentary\npattern-based methods. We close this gap by using the latest BERT-based\nextraction models alongside pattern-based ones. As a result, we achieved a high\nrecall, while still maintaining a high precision. For clustering, we utilized a\ntopic modelling approach to cluster our arguments, so as to increase the\nconnectivity of our graph. As a result, instead of 15,686 disconnected\nsubgraphs, we were able to obtain 1 connected graph that enables users to infer\nmore causal relationships from. Our final KG effectively captures and conveys\ncausal relationships, validated through experiments, multiple use cases and\nuser feedback.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tan_F/0/1/0/all/0/1\">Fiona Anting Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1\">Debdeep Paul</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yamaura_S/0/1/0/all/0/1\">Sahim Yamaura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koji_M/0/1/0/all/0/1\">Miura Koji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ng_S/0/1/0/all/0/1\">See-Kiong Ng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v4 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2305.15299","description":"<p>Large language models of artificial intelligence (AI), such as ChatGPT, find\nremarkable but controversial applicability in science and research. This paper\nreviews epistemological challenges, ethical and integrity risks in science\nconduct in the advent of generative AI. This is with the aim to lay new timely\nfoundations for a high-quality research ethics review. The role of AI language\nmodels as a research instrument and subject is scrutinized along with ethical\nimplications for scientists, participants and reviewers. New emerging practices\nfor research ethics review are discussed, concluding with ten recommendations\nthat shape a response for a more responsible research conduct in the era of AI.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pournaras_E/0/1/0/all/0/1\">Evangelos Pournaras</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Models are Bounded Pragmatic Speakers: Understanding RLHF from a Bayesian Cognitive Modeling Perspective. (arXiv:2305.17760v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.17760","description":"<p>How do language models \"think\"? This paper formulates a probabilistic\ncognitive model called the bounded pragmatic speaker, which can characterize\nthe operation of different variations of language models. Specifically, we\ndemonstrate that large language models fine-tuned with reinforcement learning\nfrom human feedback (Ouyang et al., 2022) embody a model of thought that\nconceptually resembles a fast-and-slow model (Kahneman, 2011), which\npsychologists have attributed to humans. We discuss the limitations of\nreinforcement learning from human feedback as a fast-and-slow model of thought\nand propose avenues for expanding this framework. In essence, our research\nhighlights the value of adopting a cognitive probabilistic modeling approach to\ngain insights into the comprehension, evaluation, and advancement of language\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nguyen_K/0/1/0/all/0/1\">Khanh Nguyen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions. (arXiv:2305.18339v2 [cs.CY] UPDATED)","link":"http://arxiv.org/abs/2305.18339","description":"<p>With the widespread use of large artificial intelligence (AI) models such as\nChatGPT, AI-generated content (AIGC) has garnered increasing attention and is\nleading a paradigm shift in content creation and knowledge representation. AIGC\nuses generative large AI algorithms to assist or replace humans in creating\nmassive, high-quality, and human-like content at a faster pace and lower cost,\nbased on user-provided prompts. Despite the recent significant progress in\nAIGC, security, privacy, ethical, and legal challenges still need to be\naddressed. This paper presents an in-depth survey of working principles,\nsecurity and privacy threats, state-of-the-art solutions, and future challenges\nof the AIGC paradigm. Specifically, we first explore the enabling technologies,\ngeneral architecture of AIGC, and discuss its working modes and key\ncharacteristics. Then, we investigate the taxonomy of security and privacy\nthreats to AIGC and highlight the ethical and societal implications of GPT and\nAIGC technologies. Furthermore, we review the state-of-the-art AIGC\nwatermarking approaches for regulatable AIGC paradigms regarding the AIGC model\nand its produced content. Finally, we identify future challenges and open\nresearch directions related to AIGC.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuntao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1\">Yanghe Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1\">Miao Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1\">Zhou Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luan_T/0/1/0/all/0/1\">Tom H. Luan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Forgotten Knowledge: Examining the Citational Amnesia in NLP. (arXiv:2305.18554v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.18554","description":"<p>Citing papers is the primary method through which modern scientific writing\ndiscusses and builds on past work. Collectively, citing a diverse set of papers\n(in time and area of study) is an indicator of how widely the community is\nreading. Yet, there is little work looking at broad temporal patterns of\ncitation. This work systematically and empirically examines: How far back in\ntime do we tend to go to cite papers? How has that changed over time, and what\nfactors correlate with this citational attention/amnesia? We chose NLP as our\ndomain of interest and analyzed approximately 71.5K papers to show and quantify\nseveral key trends in citation. Notably, around 62% of cited papers are from\nthe immediate five years prior to publication, whereas only about 17% are more\nthan ten years old. Furthermore, we show that the median age and age diversity\nof cited papers were steadily increasing from 1990 to 2014, but since then, the\ntrend has reversed, and current NLP papers have an all-time low temporal\ncitation diversity. Finally, we show that unlike the 1990s, the highly cited\npapers in the last decade were also papers with the least citation diversity,\nlikely contributing to the intense (and arguably harmful) recency focus. Code,\ndata, and a demo are available on the project homepage.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1\">Janvijay Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rungta_M/0/1/0/all/0/1\">Mukund Rungta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mohammad_S/0/1/0/all/0/1\">Saif M. Mohammad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Column Type Annotation using ChatGPT. (arXiv:2306.00745v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.00745","description":"<p>Column type annotation is the task of annotating the columns of a relational\ntable with the semantic type of the values contained in each column. Column\ntype annotation is an important pre-processing step for data search and data\nintegration in the context of data lakes. State-of-the-art column type\nannotation methods either rely on matching table columns to properties of a\nknowledge graph or fine-tune pre-trained language models such as BERT for\ncolumn type annotation. In this work, we take a different approach and explore\nusing ChatGPT for column type annotation. We evaluate different prompt designs\nin zero- and few-shot settings and experiment with providing task definitions\nand detailed instructions to the model. We further implement a two-step table\nannotation pipeline which first determines the class of the entities described\nin the table and depending on this class asks ChatGPT to annotate columns using\nonly the relevant subset of the overall vocabulary. Using instructions as well\nas the two-step pipeline, ChatGPT reaches F1 scores of over 85% in zero- and\none-shot setups. To reach a similar F1 score a RoBERTa model needs to be\nfine-tuned with 356 examples. This comparison shows that ChatGPT is able\ndeliver competitive results for the column type annotation task given no or\nonly a minimal amount of task-specific demonstrations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Korini_K/0/1/0/all/0/1\">Keti Korini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bizer_C/0/1/0/all/0/1\">Christian Bizer</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntax-aware Hybrid prompt model for Few-shot multi-modal sentiment analysis. (arXiv:2306.01312v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.01312","description":"<p>Multimodal Sentiment Analysis (MSA) has been a popular topic in natural\nlanguage processing nowadays, at both sentence and aspect level. However, the\nexisting approaches almost require large-size labeled datasets, which bring\nabout large consumption of time and resources. Therefore, it is practical to\nexplore the method for few-shot sentiment analysis in cross-modalities.\nPrevious works generally execute on textual modality, using the prompt-based\nmethods, mainly two types: hand-crafted prompts and learnable prompts. The\nexisting approach in few-shot multi-modality sentiment analysis task has\nutilized both methods, separately. We further design a hybrid pattern that can\ncombine one or more fixed hand-crafted prompts and learnable prompts and\nutilize the attention mechanisms to optimize the prompt encoder. The\nexperiments on both sentence-level and aspect-level datasets prove that we get\na significant outperformance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1\">Zikai Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1\">Haisong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_B/0/1/0/all/0/1\">Baiyou Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1\">Gang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_D/0/1/0/all/0/1\">Donghong Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Take the Hint: Improving Arabic Diacritization with Partially-Diacritized Text. (arXiv:2306.03557v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.03557","description":"<p>Automatic Arabic diacritization is useful in many applications, ranging from\nreading support for language learners to accurate pronunciation predictor for\ndownstream tasks like speech synthesis. While most of the previous works\nfocused on models that operate on raw non-diacritized text, production systems\ncan gain accuracy by first letting humans partly annotate ambiguous words. In\nthis paper, we propose 2SDiac, a multi-source model that can effectively\nsupport optional diacritics in input to inform all predictions. We also\nintroduce Guided Learning, a training scheme to leverage given diacritics in\ninput with different levels of random masking. We show that the provided hints\nduring test affect more output positions than those annotated. Moreover,\nexperiments on two common benchmarks show that our approach i) greatly\noutperforms the baseline also when evaluated on non-diacritized text; and ii)\nachieves state-of-the-art results while reducing the parameter count by over\n60%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bahar_P/0/1/0/all/0/1\">Parnia Bahar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gangi_M/0/1/0/all/0/1\">Mattia Di Gangi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rossenbach_N/0/1/0/all/0/1\">Nick Rossenbach</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zeineldeen_M/0/1/0/all/0/1\">Mohammad Zeineldeen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?. (arXiv:2307.02469v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2307.02469","description":"<p>Recent advancements in Large Language Models (LLMs) such as GPT4 have\ndisplayed exceptional multi-modal capabilities in following open-ended\ninstructions given images. However, the performance of these models heavily\nrelies on design choices such as network structures, training data, and\ntraining strategies, and these choices have not been extensively discussed in\nthe literature, making it difficult to quantify progress in this field. To\naddress this issue, this paper presents a systematic and comprehensive study,\nquantitatively and qualitatively, on training such models. We implement over 20\nvariants with controlled settings. Concretely, for network structures, we\ncompare different LLM backbones and model designs. For training data, we\ninvestigate the impact of data and sampling strategies. For instructions, we\nexplore the influence of diversified prompts on the instruction-following\nability of the trained models. For benchmarks, we contribute the first, to our\nbest knowledge, comprehensive evaluation set including both image and video\ntasks through crowd-sourcing. Based on our findings, we present Lynx, which\nperforms the most accurate multi-modal understanding while keeping the best\nmulti-modal generation ability compared to existing open-sourced GPT4-style\nmodels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zeng_Y/0/1/0/all/0/1\">Yan Zeng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanbo Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1\">Jiani Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xia_J/0/1/0/all/0/1\">Jiangnan Xia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_G/0/1/0/all/0/1\">Guoqiang Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1\">Yang Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuchen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_T/0/1/0/all/0/1\">Tao Kong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Lost in the Middle: How Language Models Use Long Contexts. (arXiv:2307.03172v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03172","description":"<p>While recent language models have the ability to take long contexts as input,\nrelatively little is known about how well they use longer context. We analyze\nlanguage model performance on two tasks that require identifying relevant\ninformation within their input contexts: multi-document question answering and\nkey-value retrieval. We find that performance is often highest when relevant\ninformation occurs at the beginning or end of the input context, and\nsignificantly degrades when models must access relevant information in the\nmiddle of long contexts. Furthermore, performance substantially decreases as\nthe input context grows longer, even for explicitly long-context models. Our\nanalysis provides a better understanding of how language models use their input\ncontext and provides new evaluation protocols for future long-context models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Nelson F. Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1\">Kevin Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hewitt_J/0/1/0/all/0/1\">John Hewitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paranjape_A/0/1/0/all/0/1\">Ashwin Paranjape</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bevilacqua_M/0/1/0/all/0/1\">Michele Bevilacqua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Petroni_F/0/1/0/all/0/1\">Fabio Petroni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1\">Percy Liang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Measuring Lexical Diversity in Texts: The Twofold Length Problem. (arXiv:2307.04626v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04626","description":"<p>The impact of text length on the estimation of lexical diversity has captured\nthe attention of the scientific community for more than a century. Numerous\nindices have been proposed, and many studies have been conducted to evaluate\nthem, but the problem remains. This methodological review provides a critical\nanalysis not only of the most commonly used indices in language learning\nstudies, but also of the length problem itself, as well as of the methodology\nfor evaluating the proposed solutions. The analysis of three datasets of\nEnglish language-learners' texts revealed that indices that reduce all texts to\nthe same length using a probabilistic or an algorithmic approach solve the\nlength dependency problem; however, all these indices failed to address the\nsecond problem, which is their sensitivity to the parameter that determines the\nlength to which the texts are reduced. The paper concludes with recommendations\nfor optimizing lexical diversity analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bestgen_Y/0/1/0/all/0/1\">Yves Bestgen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpreting deep embeddings for disease progression clustering. (arXiv:2307.06060v2 [stat.ML] UPDATED)","link":"http://arxiv.org/abs/2307.06060","description":"<p>We propose a novel approach for interpreting deep embeddings in the context\nof patient clustering. We evaluate our approach on a dataset of participants\nwith type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful\ninsights into disease progression patterns.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/stat/1/au:+Munoz_Farre_A/0/1/0/all/0/1\">Anna Munoz-Farre</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Poulakakis_Daktylidis_A/0/1/0/all/0/1\">Antonios Poulakakis-Daktylidis</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Kothalawala_D/0/1/0/all/0/1\">Dilini Mahesha Kothalawala</a>, <a href=\"http://arxiv.org/find/stat/1/au:+Rodriguez_Martinez_A/0/1/0/all/0/1\">Andrea Rodriguez-Martinez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Going Beyond Local: Global Graph-Enhanced Personalized News Recommendations. (arXiv:2307.06576v4 [cs.IR] UPDATED)","link":"http://arxiv.org/abs/2307.06576","description":"<p>Precisely recommending candidate news articles to users has always been a\ncore challenge for personalized news recommendation systems. Most recent works\nprimarily focus on using advanced natural language processing techniques to\nextract semantic information from rich textual data, employing content-based\nmethods derived from local historical news. However, this approach lacks a\nglobal perspective, failing to account for users' hidden motivations and\nbehaviors beyond semantic information. To address this challenge, we propose a\nnovel model called GLORY (Global-LOcal news Recommendation sYstem), which\ncombines global representations learned from other users with local\nrepresentations to enhance personalized recommendation systems. We accomplish\nthis by constructing a Global-aware Historical News Encoder, which includes a\nglobal news graph and employs gated graph neural networks to enrich news\nrepresentations, thereby fusing historical news representations by a historical\nnews aggregator. Similarly, we extend this approach to a Global Candidate News\nEncoder, utilizing a global entity graph and a candidate news aggregator to\nenhance candidate news representation. Evaluation results on two public news\ndatasets demonstrate that our method outperforms existing approaches.\nFurthermore, our model offers more diverse recommendations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Boming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Dairui Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Suzumura_T/0/1/0/all/0/1\">Toyotaro Suzumura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Ruihai Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1\">Irene Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT is Good but Bing Chat is Better for Vietnamese Students. (arXiv:2307.08272v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.08272","description":"<p>This study examines the efficacy of two SOTA large language models (LLMs),\nnamely ChatGPT and Microsoft Bing Chat (BingChat), in catering to the needs of\nVietnamese students. Although ChatGPT exhibits proficiency in multiple\ndisciplines, Bing Chat emerges as the more advantageous option. We conduct a\ncomparative analysis of their academic achievements in various disciplines,\nencompassing mathematics, literature, English language, physics, chemistry,\nbiology, history, geography, and civic education. The results of our study\nsuggest that BingChat demonstrates superior performance compared to ChatGPT\nacross a wide range of subjects, with the exception of literature, where\nChatGPT exhibits better performance. Additionally, BingChat utilizes the more\nadvanced GPT-4 technology in contrast to ChatGPT, which is built upon GPT-3.5.\nThis allows BingChat to improve to comprehension, reasoning and generation of\ncreative and informative text. Moreover, the fact that BingChat is accessible\nin Vietnam and its integration of hyperlinks and citations within responses\nserve to reinforce its superiority. In our analysis, it is evident that while\nChatGPT exhibits praiseworthy qualities, BingChat presents a more apdated\nsolutions for Vietnamese students.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Dao_X/0/1/0/all/0/1\">Xuan-Quy Dao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1\">Ngoc-Bich Le</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"L-Eval: Instituting Standardized Evaluation for Long Context Language Models. (arXiv:2307.11088v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11088","description":"<p>Recently, there has been growing interest in extending the context length of\ninstruction-following models in order to effectively process single-turn long\ninput (e.g. summarizing a paper) and conversations with more extensive\nhistories. While proprietary models such as GPT-4 and Claude have shown\nsignificant strides in handling extremely lengthy input, open-sourced models\nare still in the early stages of experimentation. It also remains unclear\nwhether extending the context can offer substantial gains over traditional\nmethods such as retrieval, and to what extent it improves upon their regular\ncounterparts in practical downstream tasks. To address this challenge, we\npropose instituting standardized evaluation for long context language models.\nConcretely, we develop L-Eval which contains 411 long documents and over 2,000\nhuman-labeled query-response pairs encompassing areas such as law, finance,\nschool lectures, lengthy conversations, news, long-form novels, and meetings.\nL-Eval also adopts diverse evaluation methods and instruction styles, enabling\na more reliable assessment of Long Context Language Models (LCLMs). Our\nfindings indicate that while open-source models typically lag behind commercial\nmodels, they still exhibit impressive performance compared with their regular\nversions. LLaMA2-13B achieves the best results on both open-ended tasks (win\n\\textbf{42}\\% vs turbo-16k-0613) and closed-ended tasks with only 4k context\nlength. We release our new evaluation suite, code, and all generation results\nincluding predictions from all open-sourced LCLMs, GPT4-32k, Cluade-100k at\n{\\url{https://github.com/OpenLMLab/LEval}}.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+An_C/0/1/0/all/0/1\">Chenxin An</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1\">Shansan Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_M/0/1/0/all/0/1\">Ming Zhong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1\">Mukai Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jun Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Applying QNLP to sentiment analysis in finance. (arXiv:2307.11788v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.11788","description":"<p>As an application domain where the slightest qualitative improvements can\nyield immense value, finance is a promising candidate for early quantum\nadvantage. Focusing on the rapidly advancing field of Quantum Natural Language\nProcessing (QNLP), we explore the practical applicability of the two central\napproaches DisCoCat and Quantum-Enhanced Long Short-Term Memory (QLSTM) to the\nproblem of sentiment analysis in finance. Utilizing a novel ChatGPT-based data\ngeneration approach, we conduct a case study with more than 1000 realistic\nsentences and find that QLSTMs can be trained substantially faster than\nDisCoCat while also achieving close to classical results for their available\nsoftware implementations.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stein_J/0/1/0/all/0/1\">Jonas Stein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Christ_I/0/1/0/all/0/1\">Ivo Christ</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kraus_N/0/1/0/all/0/1\">Nicolas Kraus</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mansky_M/0/1/0/all/0/1\">Maximilian Balthasar Mansky</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Muller_R/0/1/0/all/0/1\">Robert M&#xfc;ller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Linnhoff_Popien_C/0/1/0/all/0/1\">Claudia Linnhoff-Popien</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"XDLM: Cross-lingual Diffusion Language Model for Machine Translation. (arXiv:2307.13560v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.13560","description":"<p>Recently, diffusion models have excelled in image generation tasks and have\nalso been applied to neural language processing (NLP) for controllable text\ngeneration. However, the application of diffusion models in a cross-lingual\nsetting is less unexplored. Additionally, while pretraining with diffusion\nmodels has been studied within a single language, the potential of\ncross-lingual pretraining remains understudied. To address these gaps, we\npropose XDLM, a novel Cross-lingual diffusion model for machine translation,\nconsisting of pretraining and fine-tuning stages. In the pretraining stage, we\npropose TLDM, a new training objective for mastering the mapping between\ndifferent languages; in the fine-tuning stage, we build up the translation\nsystem based on the pretrained model. We evaluate the result on several machine\ntranslation benchmarks and outperformed both diffusion and Transformer\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Linyao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_A/0/1/0/all/0/1\">Aosong Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Boming Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zihui Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Gzip versus bag-of-words for text classification with KNN. (arXiv:2307.15002v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.15002","description":"<p>The effectiveness of compression distance in KNN-based text classification\n('gzip') has recently garnered lots of attention. In this note, we show that\nsimpler means can also be effective, and compression may not be needed. Indeed,\na 'bag-of-words' matching can achieve similar or better results, and is more\nefficient.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Opitz_J/0/1/0/all/0/1\">Juri Opitz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Geometric Notion of Causal Probing. (arXiv:2307.15054v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.15054","description":"<p>Large language models rely on real-valued representations of text to make\ntheir predictions. These representations contain information learned from the\ndata that the model has trained on, including knowledge of linguistic\nproperties and forms of demographic bias, e.g., based on gender. A growing body\nof work has considered removing information about concepts such as these using\northogonal projections onto subspaces of the representation space. We\ncontribute to this body of work by proposing a formal definition of\n$\\textit{intrinsic}$ information in a subspace of a language model's\nrepresentation space. We propose a counterfactual approach that avoids the\nfailure mode of spurious correlations (Kumar et al., 2022) by treating\ncomponents in the subspace and its orthogonal complement independently. We show\nthat our counterfactual notion of information in a subspace is optimized by a\n$\\textit{causal}$ concept subspace. Furthermore, this intervention allows us to\nattempt concept controlled generation by manipulating the value of the\nconceptual component of a representation. Empirically, we find that R-LACE\n(Ravfogel et al., 2022) returns a one-dimensional subspace containing roughly\nhalf of total concept information under our framework. Our causal controlled\nintervention shows that, for at least one model, the subspace returned by\nR-LACE can be used to manipulate the concept value of the generated word with\nprecision.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guerner_C/0/1/0/all/0/1\">Cl&#xe9;ment Guerner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Svete_A/0/1/0/all/0/1\">Anej Svete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1\">Alexander Warstadt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Hexatagging: Projective Dependency Parsing as Tagging. (arXiv:2306.05477v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2306.05477","description":"<p>We introduce a novel dependency parser, the hexatagger, that constructs\ndependency trees by tagging the words in a sentence with elements from a finite\nset of possible tags. In contrast to many approaches to dependency parsing, our\napproach is fully parallelizable at training time, i.e., the structure-building\nactions needed to build a dependency parse can be predicted in parallel to each\nother. Additionally, exact decoding is linear in time and space complexity.\nFurthermore, we derive a probabilistic dependency parser that predicts hexatags\nusing no more than a linear model with features from a pretrained language\nmodel, i.e., we forsake a bespoke architecture explicitly designed for the\ntask. Despite the generality and simplicity of our approach, we achieve\nstate-of-the-art performance of 96.4 LAS and 97.4 UAS on the Penn Treebank test\nset. Additionally, our parser's linear time complexity and parallelism\nsignificantly improve computational efficiency, with a roughly 10-times\nspeed-up over previous state-of-the-art models during decoding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1\">Afra Amini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Tianyu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Skill-it! A Data-Driven Skills Framework for Understanding and Training Language Models. (arXiv:2307.14430v1 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2307.14430","description":"<p>The quality of training data impacts the performance of pre-trained large\nlanguage models (LMs). Given a fixed budget of tokens, we study how to best\nselect data that leads to good downstream model performance across tasks. We\ndevelop a new framework based on a simple hypothesis: just as humans acquire\ninterdependent skills in a deliberate order, language models also follow a\nnatural order when learning a set of skills from their training data. If such\nan order exists, it can be utilized for improved understanding of LMs and for\ndata-efficient training. Using this intuition, our framework formalizes the\nnotion of a skill and of an ordered set of skills in terms of the associated\ndata. First, using both synthetic and real data, we demonstrate that these\nordered skill sets exist, and that their existence enables more advanced skills\nto be learned with less data when we train on their prerequisite skills.\nSecond, using our proposed framework, we introduce an online data sampling\nalgorithm, Skill-It, over mixtures of skills for both continual pre-training\nand fine-tuning regimes, where the objective is to efficiently learn multiple\nskills in the former and an individual skill in the latter. On the LEGO\nsynthetic in the continual pre-training setting, Skill-It obtains 36.5 points\nhigher accuracy than random sampling. On the Natural Instructions dataset in\nthe fine-tuning setting, Skill-It reduces the validation loss on the target\nskill by 13.6% versus training on data associated with the target skill itself.\nWe apply our skills framework on the recent RedPajama dataset to continually\npre-train a 3B-parameter LM, achieving higher accuracy on the LM Evaluation\nHarness with 1B tokens than the baseline approach of sampling uniformly over\ndata sources with 3B tokens.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Mayee F. Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roberts_N/0/1/0/all/0/1\">Nicholas Roberts</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhatia_K/0/1/0/all/0/1\">Kush Bhatia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jue Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Ce Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sala_F/0/1/0/all/0/1\">Frederic Sala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1\">Christopher R&#xe9;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-07-31T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","content":"http://purl.org/rss/1.0/modules/content/","syn":"http://purl.org/rss/1.0/modules/syndication/","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","dc":"http://purl.org/dc/elements/1.1/","admin":"http://webns.net/mvcb/"}}]}]}