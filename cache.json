{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-07-19T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"Cross-Lingual NER for Financial Transaction Data in Low-Resource Languages. (arXiv:2307.08714v1 [cs.CL])","link":"http://arxiv.org/abs/2307.08714","description":"<p>We propose an efficient modeling framework for cross-lingual named entity\nrecognition in semi-structured text data. Our approach relies on both knowledge\ndistillation and consistency training. The modeling framework leverages\nknowledge from a large language model (XLMRoBERTa) pre-trained on the source\nlanguage, with a student-teacher relationship (knowledge distillation). The\nstudent model incorporates unsupervised consistency training (with KL\ndivergence loss) on the low-resource target language.\n</p>\n<p>We employ two independent datasets of SMSs in English and Arabic, each\ncarrying semi-structured banking transaction information, and focus on\nexhibiting the transfer of knowledge from English to Arabic. With access to\nonly 30 labeled samples, our model can generalize the recognition of merchants,\namounts, and other fields from English to Arabic. We show that our modeling\napproach, while efficient, performs best overall when compared to\nstate-of-the-art approaches like DistilBERT pre-trained on the target language\nor a supervised model directly trained on labeled data in the target language.\n</p>\n<p>Our experiments show that it is enough to learn to recognize entities in\nEnglish to reach reasonable performance in a low-resource language in the\npresence of a few labeled samples of semi-structured data. The proposed\nframework has implications for developing multi-lingual applications,\nespecially in geographies where digital endeavors rely on both English and one\nor more low-resource language(s), sometimes mixed with English or employed\nsingly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1\">Sunisth Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Davide Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Boulenger_A/0/1/0/all/0/1\">Alexandre Boulenger</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ivrit.ai: A Comprehensive Dataset of Hebrew Speech for AI Research and Development. (arXiv:2307.08720v1 [eess.AS])","link":"http://arxiv.org/abs/2307.08720","description":"<p>We introduce \"ivrit.ai\", a comprehensive Hebrew speech dataset, addressing\nthe distinct lack of extensive, high-quality resources for advancing Automated\nSpeech Recognition (ASR) technology in Hebrew. With over 3,300 speech hours and\na over a thousand diverse speakers, ivrit.ai offers a substantial compilation\nof Hebrew speech across various contexts. It is delivered in three forms to\ncater to varying research needs: raw unprocessed audio; data post-Voice\nActivity Detection, and partially transcribed data. The dataset stands out for\nits legal accessibility, permitting use at no cost, thereby serving as a\ncrucial resource for researchers, developers, and commercial entities. ivrit.ai\nopens up numerous applications, offering vast potential to enhance AI\ncapabilities in Hebrew. Future efforts aim to expand ivrit.ai further, thereby\nadvancing Hebrew's standing in AI research and technology.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/eess/1/au:+Marmor_Y/0/1/0/all/0/1\">Yanir Marmor</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Misgav_K/0/1/0/all/0/1\">Kinneret Misgav</a>, <a href=\"http://arxiv.org/find/eess/1/au:+Lifshitz_Y/0/1/0/all/0/1\">Yair Lifshitz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A mixed policy to improve performance of language models on math problems. (arXiv:2307.08767v1 [cs.CL])","link":"http://arxiv.org/abs/2307.08767","description":"<p>When to solve math problems, most language models take a sampling strategy to\npredict next word according conditional probabilities. In the math reasoning\nstep, it may generate wrong answer. Considering math problems are\ndeterministic, we propose a mixed policy exploration approach to solve math\nproblems with reinforcement learning. In peculiar, we propose a two level token\nexploration policy: the abstract level explores next token with probability and\nthe second level is deterministic. Specifically, the abstract level policy will\ndecide whether the token is operator or operand with probability sampling,\nwhile the second level is deterministic to select next token with the highest\nscore in a greedy way. We test our method on GSM8K dataset with GPT-2 model,\nand demonstrate more than $2\\%$ performance gain. Our implementation is\navailable at https://github.com/vividitytech/math_lm_rl.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1\">Gang Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Performance Evaluation of Large Language Models for Extracting Molecular Interactions and Pathway Knowledge. (arXiv:2307.08813v1 [cs.CL])","link":"http://arxiv.org/abs/2307.08813","description":"<p>Understanding protein interactions and pathway knowledge is crucial for\nunraveling the complexities of living systems and investigating the underlying\nmechanisms of biological functions and complex diseases. While existing\ndatabases provide curated biological data from literature and other sources,\nthey are often incomplete and their maintenance is labor-intensive,\nnecessitating alternative approaches. In this study, we propose to harness the\ncapabilities of large language models to address these issues by automatically\nextracting such knowledge from the relevant scientific literature. Toward this\ngoal, in this work, we investigate the effectiveness of different large\nlanguage models in tasks that involve recognizing protein interactions,\npathways, and gene regulatory relations. We thoroughly evaluate the performance\nof various models, highlight the significant findings, and discuss both the\nfuture opportunities and the remaining challenges associated with this\napproach. The code and data are available at:\nhttps://github.com/boxorange/BioIE-LLM\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_G/0/1/0/all/0/1\">Gilchan Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoon_B/0/1/0/all/0/1\">Byung-Jun Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1\">Xihaier Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lopez_Marrero_V/0/1/0/all/0/1\">Vanessa L&#xf3;pez-Marrero</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Johnstone_P/0/1/0/all/0/1\">Patrick Johnstone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yoo_S/0/1/0/all/0/1\">Shinjae Yoo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alexander_F/0/1/0/all/0/1\">Francis J. Alexander</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Curriculum Learning for Graph Neural Networks: A Multiview Competence-based Approach. (arXiv:2307.08859v1 [cs.LG])","link":"http://arxiv.org/abs/2307.08859","description":"<p>A curriculum is a planned sequence of learning materials and an effective one\ncan make learning efficient and effective for both humans and machines. Recent\nstudies developed effective data-driven curriculum learning approaches for\ntraining graph neural networks in language applications. However, existing\ncurriculum learning approaches often employ a single criterion of difficulty in\ntheir training paradigms. In this paper, we propose a new perspective on\ncurriculum learning by introducing a novel approach that builds on graph\ncomplexity formalisms (as difficulty criteria) and model competence during\ntraining. The model consists of a scheduling scheme which derives effective\ncurricula by accounting for different views of sample difficulty and model\ncompetence during training. The proposed solution advances existing research in\ncurriculum learning for graph neural networks with the ability to incorporate a\nfine-grained spectrum of graph difficulty criteria in their training paradigms.\nExperimental results on real-world link prediction and node classification\ntasks illustrate the effectiveness of the proposed approach.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Vakil_N/0/1/0/all/0/1\">Nidhi Vakil</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amiri_H/0/1/0/all/0/1\">Hadi Amiri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models Perform Diagnostic Reasoning. (arXiv:2307.08922v1 [cs.CL])","link":"http://arxiv.org/abs/2307.08922","description":"<p>We explore the extension of chain-of-thought (CoT) prompting to medical\nreasoning for the task of automatic diagnosis. Motivated by doctors' underlying\nreasoning process, we present Diagnostic-Reasoning CoT (DR-CoT). Empirical\nresults demonstrate that by simply prompting large language models trained only\non general text corpus with two DR-CoT exemplars, the diagnostic accuracy\nimproves by 15% comparing to standard prompting. Moreover, the gap reaches a\npronounced 18% in out-domain settings. Our findings suggest expert-knowledge\nreasoning in large language models can be elicited through proper promptings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Cheng-Kuang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Wei-Lin Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hsin-Hsi Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Federated Large Language Model: A Position Paper. (arXiv:2307.08925v1 [cs.LG])","link":"http://arxiv.org/abs/2307.08925","description":"<p>Large scale language models (LLM) have received significant attention and\nfound diverse applications across various domains, but their development\nencounters challenges in real-world scenarios. These challenges arise due to\nthe scarcity of public domain data availability and the need to maintain\nprivacy with respect to private domain data. To address these issues, federated\nlearning (FL) has emerged as a promising technology that enables collaborative\ntraining of shared models while preserving decentralized data. We propose the\nconcept of federated LLM, which comprises three key components, i.e., federated\nLLM pre-training, federated LLM fine-tuning, and federated LLM prompt\nengineering. For each component, we discuss its advantage over traditional LLM\ntraining methods and propose specific engineering strategies for\nimplementation. Furthermore, we explore the novel challenges introduced by the\nintegration of FL and LLM. We analyze existing solutions and identify potential\nobstacles faced by these solutions within the context of federated LLM.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Chaochao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaohua Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Jun Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1\">Jianwei Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1\">Xiaolin Zheng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Teach model to answer questions after comprehending the document. (arXiv:2307.08931v1 [cs.CL])","link":"http://arxiv.org/abs/2307.08931","description":"<p>Multi-choice Machine Reading Comprehension (MRC) is a challenging extension\nof Natural Language Processing (NLP) that requires the ability to comprehend\nthe semantics and logical relationships between entities in a given text. The\nMRC task has traditionally been viewed as a process of answering questions\nbased on the given text. This single-stage approach has often led the network\nto concentrate on generating the correct answer, potentially neglecting the\ncomprehension of the text itself. As a result, many prevalent models have faced\nchallenges in performing well on this task when dealing with longer texts. In\nthis paper, we propose a two-stage knowledge distillation method that teaches\nthe model to better comprehend the document by dividing the MRC task into two\nseparate stages. Our experimental results show that the student model, when\nequipped with our method, achieves significant improvements, demonstrating the\neffectiveness of our method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1\">Ruiqing Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1\">Ping Jian</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"NTK-approximating MLP Fusion for Efficient Language Model Fine-tuning. (arXiv:2307.08941v1 [cs.LG])","link":"http://arxiv.org/abs/2307.08941","description":"<p>Fine-tuning a pre-trained language model (PLM) emerges as the predominant\nstrategy in many natural language processing applications. However, even\nfine-tuning the PLMs and doing inference are expensive, especially on edge\ndevices with low computing power. Some general approaches (e.g. quantization\nand distillation) have been widely studied to reduce the compute/memory of PLM\nfine-tuning, while very few one-shot compression techniques are explored. In\nthis paper, we investigate the neural tangent kernel (NTK)--which reveals the\ngradient descent dynamics of neural networks--of the multilayer perceptrons\n(MLP) modules in a PLM and propose to coin a lightweight PLM through\nNTK-approximating MLP fusion. To achieve this, we reconsider the MLP as a\nbundle of sub-MLPs, and cluster them into a given number of centroids, which\ncan then be restored as a compressed MLP and surprisingly shown to well\napproximate the NTK of the original PLM. Extensive experiments of PLM\nfine-tuning on both natural language understanding (NLU) and generation (NLG)\ntasks are provided to verify the effectiveness of the proposed method MLP\nfusion. Our code is available at https://github.com/weitianxin/MLP_Fusion.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1\">Tianxin Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1\">Zeming Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yifan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Jingrui He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mitigating Label Bias via Decoupled Confident Learning. (arXiv:2307.08945v1 [cs.LG])","link":"http://arxiv.org/abs/2307.08945","description":"<p>Growing concerns regarding algorithmic fairness have led to a surge in\nmethodologies to mitigate algorithmic bias. However, such methodologies largely\nassume that observed labels in training data are correct. This is problematic\nbecause bias in labels is pervasive across important domains, including\nhealthcare, hiring, and content moderation. In particular, human-generated\nlabels are prone to encoding societal biases. While the presence of labeling\nbias has been discussed conceptually, there is a lack of methodologies to\naddress this problem. We propose a pruning method -- Decoupled Confident\nLearning (DeCoLe) -- specifically designed to mitigate label bias. After\nillustrating its performance on a synthetic dataset, we apply DeCoLe in the\ncontext of hate speech detection, where label bias has been recognized as an\nimportant challenge, and show that it successfully identifies biased labels and\noutperforms competing approaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yunyi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+De_Arteaga_M/0/1/0/all/0/1\">Maria De-Arteaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saar_Tsechansky_M/0/1/0/all/0/1\">Maytal Saar-Tsechansky</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the (In)Effectiveness of Large Language Models for Chinese Text Correction. (arXiv:2307.09007v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09007","description":"<p>Recently, the development and progress of Large Language Models (LLMs) have\namazed the entire Artificial Intelligence community. As an outstanding\nrepresentative of LLMs and the foundation model that set off this wave of\nresearch on LLMs, ChatGPT has attracted more and more researchers to study its\ncapabilities and performance on various downstream Natural Language Processing\n(NLP) tasks. While marveling at ChatGPT's incredible performance on kinds of\ntasks, we notice that ChatGPT also has excellent multilingual processing\ncapabilities, such as Chinese. To explore the Chinese processing ability of\nChatGPT, we focus on Chinese Text Correction, a fundamental and challenging\nChinese NLP task. Specifically, we evaluate ChatGPT on the Chinese Grammatical\nError Correction (CGEC) and Chinese Spelling Check (CSC) tasks, which are two\nmain Chinese Text Correction scenarios. From extensive analyses and comparisons\nwith previous state-of-the-art fine-tuned models, we empirically find that the\nChatGPT currently has both amazing performance and unsatisfactory behavior for\nChinese Text Correction. We believe our findings will promote the landing and\napplication of LLMs in the Chinese NLP community.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yinghui Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haojing Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1\">Shirong Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1\">Yong Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangning Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1\">Feng Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1\">Hai-Tao Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1\">Qingyu Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How is ChatGPT's behavior changing over time?. (arXiv:2307.09009v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09009","description":"<p>GPT-3.5 and GPT-4 are the two most widely used large language model (LLM)\nservices. However, when and how these models are updated over time is opaque.\nHere, we evaluate the March 2023 and June 2023 versions of GPT-3.5 and GPT-4 on\nfour diverse tasks: 1) solving math problems, 2) answering sensitive/dangerous\nquestions, 3) generating code and 4) visual reasoning. We find that the\nperformance and behavior of both GPT-3.5 and GPT-4 can vary greatly over time.\nFor example, GPT-4 (March 2023) was very good at identifying prime numbers\n(accuracy 97.6%) but GPT-4 (June 2023) was very poor on these same questions\n(accuracy 2.4%). Interestingly GPT-3.5 (June 2023) was much better than GPT-3.5\n(March 2023) in this task. GPT-4 was less willing to answer sensitive questions\nin June than in March, and both GPT-4 and GPT-3.5 had more formatting mistakes\nin code generation in June than in March. Overall, our findings shows that the\nbehavior of the same LLM service can change substantially in a relatively short\namount of time, highlighting the need for continuous monitoring of LLM quality.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lingjiao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaharia_M/0/1/0/all/0/1\">Matei Zaharia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1\">James Zou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring acceptance of autonomous vehicle policies using KeyBERT and SNA: Targeting engineering students. (arXiv:2307.09014v1 [cs.SI])","link":"http://arxiv.org/abs/2307.09014","description":"<p>This study aims to explore user acceptance of Autonomous Vehicle (AV)\npolicies with improved text-mining methods. Recently, South Korean policymakers\nhave viewed Autonomous Driving Car (ADC) and Autonomous Driving Robot (ADR) as\nnext-generation means of transportation that will reduce the cost of\ntransporting passengers and goods. They support the construction of V2I and V2V\ncommunication infrastructures for ADC and recognize that ADR is equivalent to\npedestrians to promote its deployment into sidewalks. To fill the gap where\nend-user acceptance of these policies is not well considered, this study\napplied two text-mining methods to the comments of graduate students in the\nfields of Industrial, Mechanical, and Electronics-Electrical-Computer. One is\nthe Co-occurrence Network Analysis (CNA) based on TF-IWF and Dice coefficient,\nand the other is the Contextual Semantic Network Analysis (C-SNA) based on both\nKeyBERT, which extracts keywords that contextually represent the comments, and\ndouble cosine similarity. The reason for comparing these approaches is to\nbalance interest not only in the implications for the AV policies but also in\nthe need to apply quality text mining to this research domain. Significantly,\nthe limitation of frequency-based text mining, which does not reflect textual\ncontext, and the trade-off of adjusting thresholds in Semantic Network Analysis\n(SNA) were considered. As the results of comparing the two approaches, the\nC-SNA provided the information necessary to understand users' voices using\nfewer nodes and features than the CNA. The users who pre-emptively understood\nthe AV policies based on their engineering literacy and the given texts\nrevealed potential risks of the AV accident policies. This study adds\nsuggestions to manage these risks to support the successful deployment of AVs\non public roads.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1\">Jinwoo Ha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1\">Dongsoo Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards a Neural Era in Dialogue Management for Collaboration: A Literature Survey. (arXiv:2307.09021v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09021","description":"<p>Dialogue-based human-AI collaboration can revolutionize collaborative\nproblem-solving, creative exploration, and social support. To realize this\ngoal, the development of automated agents proficient in skills such as\nnegotiating, following instructions, establishing common ground, and\nprogressing shared tasks is essential. This survey begins by reviewing the\nevolution of dialogue management paradigms in collaborative dialogue systems,\nfrom traditional handcrafted and information-state based methods to AI\nplanning-inspired approaches. It then shifts focus to contemporary data-driven\ndialogue management techniques, which seek to transfer deep learning successes\nfrom form-filling and open-domain settings to collaborative contexts. The paper\nproceeds to analyze a selected set of recent works that apply neural approaches\nto collaborative dialogue management, spotlighting prevailing trends in the\nfield. This survey hopes to provide foundational background for future\nadvancements in collaborative dialogue management, particularly as the dialogue\nsystems community continues to embrace the potential of large language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mannekote_A/0/1/0/all/0/1\">Amogh Mannekote</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unleashing the Imagination of Text: A Novel Framework for Text-to-image Person Retrieval via Exploring the Power of Words. (arXiv:2307.09059v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09059","description":"<p>The goal of Text-to-image person retrieval is to retrieve person images from\na large gallery that match the given textual descriptions. The main challenge\nof this task lies in the significant differences in information representation\nbetween the visual and textual modalities. The textual modality conveys\nabstract and precise information through vocabulary and grammatical structures,\nwhile the visual modality conveys concrete and intuitive information through\nimages. To fully leverage the expressive power of textual representations, it\nis essential to accurately map abstract textual descriptions to specific\nimages.\n</p>\n<p>To address this issue, we propose a novel framework to Unleash the\nImagination of Text (UIT) in text-to-image person retrieval, aiming to fully\nexplore the power of words in sentences. Specifically, the framework employs\nthe pre-trained full CLIP model as a dual encoder for the images and texts ,\ntaking advantage of prior cross-modal alignment knowledge. The Text-guided\nImage Restoration auxiliary task is proposed with the aim of implicitly mapping\nabstract textual entities to specific image regions, facilitating alignment\nbetween textual and visual embeddings. Additionally, we introduce a cross-modal\ntriplet loss tailored for handling hard samples, enhancing the model's ability\nto distinguish minor differences.\n</p>\n<p>To focus the model on the key components within sentences, we propose a novel\ntext data augmentation technique. Our proposed methods achieve state-of-the-art\nresults on three popular benchmark datasets, and the source code will be made\npublicly available shortly.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1\">Delong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1\">Haiwen Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attention over pre-trained Sentence Embeddings for Long Document Classification. (arXiv:2307.09084v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09084","description":"<p>Despite being the current de-facto models in most NLP tasks, transformers are\noften limited to short sequences due to their quadratic attention complexity on\nthe number of tokens. Several attempts to address this issue were studied,\neither by reducing the cost of the self-attention computation or by modeling\nsmaller sequences and combining them through a recurrence mechanism or using a\nnew transformer model. In this paper, we suggest to take advantage of\npre-trained sentence transformers to start from semantically meaningful\nembeddings of the individual sentences, and then combine them through a small\nattention layer that scales linearly with the document length. We report the\nresults obtained by this simple architecture on three standard document\nclassification datasets. When compared with the current state-of-the-art models\nusing standard fine-tuning, the studied method obtains competitive results\n(even if there is no clear best model in this configuration). We also showcase\nthat the studied architecture obtains better results when freezing the\nunderlying transformers. A configuration that is useful when we need to avoid\ncomplete fine-tuning (e.g. when the same frozen transformer is shared by\ndifferent applications). Finally, two additional experiments are provided to\nfurther evaluate the relevancy of the studied architecture over simpler\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abdaoui_A/0/1/0/all/0/1\">Amine Abdaoui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1\">Sourav Dutta</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and Addressing Sociological Implications. (arXiv:2307.09162v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09162","description":"<p>Gender bias in artificial intelligence (AI) and natural language processing\nhas garnered significant attention due to its potential impact on societal\nperceptions and biases. This research paper aims to analyze gender bias in\nLarge Language Models (LLMs) with a focus on multiple comparisons between GPT-2\nand GPT-3.5, some prominent language models, to better understand its\nimplications. Through a comprehensive literature review, the study examines\nexisting research on gender bias in AI language models and identifies gaps in\nthe current knowledge. The methodology involves collecting and preprocessing\ndata from GPT-2 and GPT-3.5, and employing in-depth quantitative analysis\ntechniques to evaluate gender bias in the generated text. The findings shed\nlight on gendered word associations, language usage, and biased narratives\npresent in the outputs of these Large Language Models. The discussion explores\nthe ethical implications of gender bias and its potential consequences on\nsocial perceptions and marginalized communities. Additionally, the paper\npresents strategies for reducing gender bias in LLMs, including algorithmic\napproaches and data augmentation techniques. The research highlights the\nimportance of interdisciplinary collaborations and the role of sociological\nstudies in mitigating gender bias in AI models. By addressing these issues, we\ncan pave the way for more inclusive and unbiased AI systems that have a\npositive impact on society.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Thakur_V/0/1/0/all/0/1\">Vishesh Thakur</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automated Ableism: An Exploration of Explicit Disability Biases in Sentiment and Toxicity Analysis Models. (arXiv:2307.09209v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09209","description":"<p>We analyze sentiment analysis and toxicity detection models to detect the\npresence of explicit bias against people with disability (PWD). We employ the\nbias identification framework of Perturbation Sensitivity Analysis to examine\nconversations related to PWD on social media platforms, specifically Twitter\nand Reddit, in order to gain insight into how disability bias is disseminated\nin real-world social settings. We then create the \\textit{Bias Identification\nTest in Sentiment} (BITS) corpus to quantify explicit disability bias in any\nsentiment analysis and toxicity detection models. Our study utilizes BITS to\nuncover significant biases in four open AIaaS (AI as a Service) sentiment\nanalysis tools, namely TextBlob, VADER, Google Cloud Natural Language API,\nDistilBERT and two toxicity detection models, namely two versions of\nToxic-BERT. Our findings indicate that all of these models exhibit\nstatistically significant explicit bias against PWD.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Venkit_P/0/1/0/all/0/1\">Pranav Narayanan Venkit</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Srinath_M/0/1/0/all/0/1\">Mukund Srinath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilson_S/0/1/0/all/0/1\">Shomir Wilson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data. (arXiv:2307.09249v1 [cs.LG])","link":"http://arxiv.org/abs/2307.09249","description":"<p>Recent advancements in Natural Language Processing (NLP) have witnessed the\ngroundbreaking impact of pretrained models, yielding impressive outcomes across\nvarious tasks. This study seeks to extend the power of pretraining\nmethodologies to tabular data, a domain traditionally overlooked, yet\ninherently challenging due to the plethora of table schemas intrinsic to\ndifferent tasks. The primary research questions underpinning this work revolve\naround the adaptation to heterogeneous table structures, the establishment of a\nuniversal pretraining protocol for tabular data, the generalizability and\ntransferability of learned knowledge across tasks, the adaptation to diverse\ndownstream applications, and the incorporation of incremental columns over\ntime. In response to these challenges, we introduce UniTabE, a pioneering\nmethod designed to process tables in a uniform manner, devoid of constraints\nimposed by specific table structures. UniTabE's core concept relies on\nrepresenting each basic table element with a module, termed TabUnit. This is\nsubsequently followed by a Transformer encoder to refine the representation.\nMoreover, our model is designed to facilitate pretraining and finetuning\nthrough the utilization of free-form prompts. In order to implement the\npretraining phase, we curated an expansive tabular dataset comprising\napproximately 13 billion samples, meticulously gathered from the Kaggle\nplatform. Rigorous experimental testing and analyses were performed under a\nmyriad of scenarios to validate the effectiveness of our methodology. The\nexperimental results demonstrate UniTabE's superior performance against several\nbaseline models across a multitude of benchmark datasets. This, therefore,\nunderscores UniTabE's potential to significantly enhance the semantic\nrepresentation of tabular data, thereby marking a significant stride in the\nfield of tabular data analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1\">Yazheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuqi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1\">Guang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1\">Ledell Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qi Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PAC Neural Prediction Set Learning to Quantify the Uncertainty of Generative Language Models. (arXiv:2307.09254v1 [cs.LG])","link":"http://arxiv.org/abs/2307.09254","description":"<p>Uncertainty learning and quantification of models are crucial tasks to\nenhance the trustworthiness of the models. Importantly, the recent surge of\ngenerative language models (GLMs) emphasizes the need for reliable uncertainty\nquantification due to the concerns on generating hallucinated facts. In this\npaper, we propose to learn neural prediction set models that comes with the\nprobably approximately correct (PAC) guarantee for quantifying the uncertainty\nof GLMs. Unlike existing prediction set models, which are parameterized by a\nscalar value, we propose to parameterize prediction sets via neural networks,\nwhich achieves more precise uncertainty quantification but still satisfies the\nPAC guarantee. We demonstrate the efficacy of our method on four types of\nlanguage datasets and six types of models by showing that our method improves\nthe quantified uncertainty by $63\\%$ on average, compared to a standard\nbaseline method.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1\">Sangdon Park</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1\">Taesoo Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Text vectorization via transformer-based language models and n-gram perplexities. (arXiv:2307.09255v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09255","description":"<p>As the probability (and thus perplexity) of a text is calculated based on the\nproduct of the probabilities of individual tokens, it may happen that one\nunlikely token significantly reduces the probability (i.e., increase the\nperplexity) of some otherwise highly probable input, while potentially\nrepresenting a simple typographical error. Also, given that perplexity is a\nscalar value that refers to the entire input, information about the probability\ndistribution within it is lost in the calculation (a relatively good text that\nhas one unlikely token and another text in which each token is equally likely\nthey can have the same perplexity value), especially for longer texts. As an\nalternative to scalar perplexity this research proposes a simple algorithm used\nto calculate vector values based on n-gram perplexities within the input. Such\nrepresentations consider the previously mentioned aspects, and instead of a\nunique value, the relative perplexity of each text token is calculated, and\nthese values are combined into a single vector representing the input.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Skoric_M/0/1/0/all/0/1\">Mihailo &#x160;kori&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Linearized Relative Positional Encoding. (arXiv:2307.09270v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09270","description":"<p>Relative positional encoding is widely used in vanilla and linear\ntransformers to represent positional information. However, existing encoding\nmethods of a vanilla transformer are not always directly applicable to a linear\ntransformer, because the latter requires a decomposition of the query and key\nrepresentations into separate kernel functions. Nevertheless, principles for\ndesigning encoding methods suitable for linear transformers remain\nunderstudied. In this work, we put together a variety of existing linear\nrelative positional encoding approaches under a canonical form and further\npropose a family of linear relative positional encoding algorithms via unitary\ntransformation. Our formulation leads to a principled framework that can be\nused to develop new relative positional encoding methods that preserve linear\nspace-time complexity. Equipped with different models, the proposed linearized\nrelative positional encoding (LRPE) family derives effective encoding for\nvarious applications. Experiments show that compared with existing methods,\nLRPE achieves state-of-the-art performance in language modeling, text\nclassification, and image classification. Meanwhile, it emphasizes a general\nparadigm for designing broadly more relative positional encoding methods that\nare applicable to linear transformers. The code is available at\nhttps://github.com/OpenNLPLab/Lrpe.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1\">Zhen Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1\">Weixuan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1\">Kaiyue Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_H/0/1/0/all/0/1\">Hui Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1\">Dongxu Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaodong Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1\">Yuchao Dai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_L/0/1/0/all/0/1\">Lingpeng Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1\">Yiran Zhong</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Text Semantic Similarity Modeling through a 3D Siamese Network. (arXiv:2307.09274v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09274","description":"<p>Siamese networks have gained popularity as a method for modeling text\nsemantic similarity. Traditional methods rely on pooling operation to compress\nthe semantic representations from Transformer blocks in encoding, resulting in\ntwo-dimensional semantic vectors and the loss of hierarchical semantic\ninformation from Transformer blocks. Moreover, this limited structure of\nsemantic vectors is akin to a flattened landscape, which restricts the methods\nthat can be applied in downstream modeling, as they can only navigate this flat\nterrain. To address this issue, we propose a novel 3D Siamese network for text\nsemantic similarity modeling, which maps semantic information to a\nhigher-dimensional space. The three-dimensional semantic tensors not only\nretains more precise spatial and feature domain information but also provides\nthe necessary structural condition for comprehensive downstream modeling\nstrategies to capture them. Leveraging this structural advantage, we introduce\nseveral modules to reinforce this 3D framework, focusing on three aspects:\nfeature extraction, attention, and feature fusion. Our extensive experiments on\nfour text semantic similarity benchmarks demonstrate the effectiveness and\nefficiency of our 3D Siamese Network.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zang_J/0/1/0/all/0/1\">Jianxiang Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hui Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Llama 2: Open Foundation and Fine-Tuned Chat Models. (arXiv:2307.09288v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09288","description":"<p>In this work, we develop and release Llama 2, a collection of pretrained and\nfine-tuned large language models (LLMs) ranging in scale from 7 billion to 70\nbillion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for\ndialogue use cases. Our models outperform open-source chat models on most\nbenchmarks we tested, and based on our human evaluations for helpfulness and\nsafety, may be a suitable substitute for closed-source models. We provide a\ndetailed description of our approach to fine-tuning and safety improvements of\nLlama 2-Chat in order to enable the community to build on our work and\ncontribute to the responsible development of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Touvron_H/0/1/0/all/0/1\">Hugo Touvron</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martin_L/0/1/0/all/0/1\">Louis Martin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stone_K/0/1/0/all/0/1\">Kevin Stone</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Albert_P/0/1/0/all/0/1\">Peter Albert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1\">Amjad Almahairi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Babaei_Y/0/1/0/all/0/1\">Yasmine Babaei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bashlykov_N/0/1/0/all/0/1\">Nikolay Bashlykov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Batra_S/0/1/0/all/0/1\">Soumya Batra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhargava_P/0/1/0/all/0/1\">Prajjwal Bhargava</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bhosale_S/0/1/0/all/0/1\">Shruti Bhosale</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bikel_D/0/1/0/all/0/1\">Dan Bikel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blecher_L/0/1/0/all/0/1\">Lukas Blecher</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1\">Cristian Canton Ferrer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1\">Moya Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucurull_G/0/1/0/all/0/1\">Guillem Cucurull</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Esiobu_D/0/1/0/all/0/1\">David Esiobu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fernandes_J/0/1/0/all/0/1\">Jude Fernandes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1\">Jeremy Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1\">Wenyin Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fuller_B/0/1/0/all/0/1\">Brian Fuller</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1\">Cynthia Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1\">Vedanuj Goswami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1\">Naman Goyal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hartshorn_A/0/1/0/all/0/1\">Anthony Hartshorn</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1\">Saghar Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Hakan Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kardas_M/0/1/0/all/0/1\">Marcin Kardas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kerkez_V/0/1/0/all/0/1\">Viktor Kerkez</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kloumann_I/0/1/0/all/0/1\">Isabel Kloumann</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Korenev_A/0/1/0/all/0/1\">Artem Korenev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Koura_P/0/1/0/all/0/1\">Punit Singh Koura</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lachaux_M/0/1/0/all/0/1\">Marie-Anne Lachaux</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lavril_T/0/1/0/all/0/1\">Thibaut Lavril</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1\">Jenya Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liskovich_D/0/1/0/all/0/1\">Diana Liskovich</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yinghai Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Martinet_X/0/1/0/all/0/1\">Xavier Martinet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mihaylov_T/0/1/0/all/0/1\">Todor Mihaylov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1\">Pushkar Mishra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Molybog_I/0/1/0/all/0/1\">Igor Molybog</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1\">Yixin Nie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Poulton_A/0/1/0/all/0/1\">Andrew Poulton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reizenstein_J/0/1/0/all/0/1\">Jeremy Reizenstein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rungta_R/0/1/0/all/0/1\">Rashi Rungta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saladi_K/0/1/0/all/0/1\">Kalyan Saladi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schelten_A/0/1/0/all/0/1\">Alan Schelten</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1\">Ruan Silva</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Smith_E/0/1/0/all/0/1\">Eric Michael Smith</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Subramanian_R/0/1/0/all/0/1\">Ranjan Subramanian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1\">Xiaoqing Ellen Tan</a>, et al. (15 additional authors not shown)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-Modal Discussion Transformer: Integrating Text, Images and Graph Transformers to Detect Hate Speech on Social Media. (arXiv:2307.09312v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09312","description":"<p>We present the Multi-Modal Discussion Transformer (mDT), a novel multi-modal\ngraph-based transformer model for detecting hate speech in online social\nnetworks. In contrast to traditional text-only methods, our approach to\nlabelling a comment as hate speech centers around the holistic analysis of text\nand images. This is done by leveraging graph transformers to capture the\ncontextual relationships in the entire discussion that surrounds a comment,\nwith interwoven fusion layers to combine text and image embeddings instead of\nprocessing different modalities separately. We compare the performance of our\nmodel to baselines that only process text; we also conduct extensive ablation\nstudies. We conclude with future work for multimodal solutions to deliver\nsocial value in online contexts, arguing that capturing a holistic view of a\nconversation greatly advances the effort to detect anti-social behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hebert_L/0/1/0/all/0/1\">Liam Hebert</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1\">Gaurav Sahu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sreenivas_N/0/1/0/all/0/1\">Nanda Kishore Sreenivas</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Golab_L/0/1/0/all/0/1\">Lukasz Golab</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_R/0/1/0/all/0/1\">Robin Cohen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Adapting an ASR Foundation Model for Spoken Language Assessment. (arXiv:2307.09378v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09378","description":"<p>A crucial part of an accurate and reliable spoken language assessment system\nis the underlying ASR model. Recently, large-scale pre-trained ASR foundation\nmodels such as Whisper have been made available. As the output of these models\nis designed to be human readable, punctuation is added, numbers are presented\nin Arabic numeric form and abbreviations are included. Additionally, these\nmodels have a tendency to skip disfluencies and hesitations in the output.\nThough useful for readability, these attributes are not helpful for assessing\nthe ability of a candidate and providing feedback. Here a precise transcription\nof what a candidate said is needed. In this paper, we give a detailed analysis\nof Whisper outputs and propose two solutions: fine-tuning and soft prompt\ntuning. Experiments are conducted on both public speech corpora and an English\nlearner dataset. Results show that we can effectively alter the decoding\nbehaviour of Whisper to generate the exact words spoken in the response.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1\">Rao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_M/0/1/0/all/0/1\">Mengjie Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1\">Mark J. F. Gales</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Knill_K/0/1/0/all/0/1\">Kate M. Knill</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Zero-shot Query Reformulation for Conversational Search. (arXiv:2307.09384v1 [cs.IR])","link":"http://arxiv.org/abs/2307.09384","description":"<p>As the popularity of voice assistants continues to surge, conversational\nsearch has gained increased attention in Information Retrieval. However, data\nsparsity issues in conversational search significantly hinder the progress of\nsupervised conversational search methods. Consequently, researchers are\nfocusing more on zero-shot conversational search approaches. Nevertheless,\nexisting zero-shot methods face three primary limitations: they are not\nuniversally applicable to all retrievers, their effectiveness lacks sufficient\nexplainability, and they struggle to resolve common conversational ambiguities\ncaused by omission. To address these limitations, we introduce a novel\nZero-shot Query Reformulation (ZeQR) framework that reformulates queries based\non previous dialogue contexts without requiring supervision from conversational\nsearch data. Specifically, our framework utilizes language models designed for\nmachine reading comprehension tasks to explicitly resolve two common\nambiguities: coreference and omission, in raw queries. In comparison to\nexisting zero-shot methods, our approach is universally applicable to any\nretriever without additional adaptation or indexing. It also provides greater\nexplainability and effectively enhances query intent understanding because\nambiguities are explicitly and proactively resolved. Through extensive\nexperiments on four TREC conversational datasets, we demonstrate the\neffectiveness of our method, which consistently outperforms state-of-the-art\nbaselines.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Dayu Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1\">Hui Fang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How do software citation formats evolve over time? A longitudinal analysis of R programming language packages. (arXiv:2307.09390v1 [cs.DL])","link":"http://arxiv.org/abs/2307.09390","description":"<p>Under the data-driven research paradigm, research software has come to play\ncrucial roles in nearly every stage of scientific inquiry. Scholars are\nadvocating for the formal citation of software in academic publications,\ntreating it on par with traditional research outputs. However, software is\nhardly consistently cited: one software entity can be cited as different\nobjects, and the citations can change over time. These issues, however, are\nlargely overlooked in existing empirical research on software citation. To fill\nthe above gaps, the present study compares and analyzes a longitudinal dataset\nof citation formats of all R packages collected in 2021 and 2022, in order to\nunderstand the citation formats of R-language packages, important members in\nthe open-source software family, and how the citations evolve over time. In\nparticular, we investigate the different document types underlying the\ncitations and what metadata elements in the citation formats changed over time.\nFurthermore, we offer an in-depth analysis of the disciplinarity of journal\narticles cited as software (software papers). By undertaking this research, we\naim to contribute to a better understanding of the complexities associated with\nsoftware citation, shedding light on future software citation policies and\ninfrastructure.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yuzhuo Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1\">Kai Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation Evaluation. (arXiv:2307.09416v1 [cs.CV])","link":"http://arxiv.org/abs/2307.09416","description":"<p>Research in Image Generation has recently made significant progress,\nparticularly boosted by the introduction of Vision-Language models which are\nable to produce high-quality visual content based on textual inputs. Despite\nongoing advancements in terms of generation quality and realism, no methodical\nframeworks have been defined yet to quantitatively measure the quality of the\ngenerated content and the adherence with the prompted requests: so far, only\nhuman-based evaluations have been adopted for quality satisfaction and for\ncomparing different generative methods. We introduce a novel automated method\nfor Visual Concept Evaluation (ViCE), i.e. to assess consistency between a\ngenerated/edited image and the corresponding prompt/instructions, with a\nprocess inspired by the human cognitive behaviour. ViCE combines the strengths\nof Large Language Models (LLMs) and Visual Question Answering (VQA) into a\nunified pipeline, aiming to replicate the human cognitive process in quality\nassessment. This method outlines visual concepts, formulates image-specific\nverification questions, utilizes the Q&amp;A system to investigate the image, and\nscores the combined outcome. Although this brave new hypothesis of mimicking\nhumans in the image evaluation process is in its preliminary assessment stage,\nresults are promising and open the door to a new form of automatic evaluation\nwhich could have significant impact as the image generation or the image target\nediting tasks become more and more sophisticated.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Betti_F/0/1/0/all/0/1\">Federico Betti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Staiano_J/0/1/0/all/0/1\">Jacopo Staiano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1\">Lorenzo Baraldi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1\">Rita Cucchiara</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1\">Nicu Sebe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Pseudo Outlier Exposure for Out-of-Distribution Detection using Pretrained Transformers. (arXiv:2307.09455v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09455","description":"<p>For real-world language applications, detecting an out-of-distribution (OOD)\nsample is helpful to alert users or reject such unreliable samples. However,\nmodern over-parameterized language models often produce overconfident\npredictions for both in-distribution (ID) and OOD samples. In particular,\nlanguage models suffer from OOD samples with a similar semantic representation\nto ID samples since these OOD samples lie near the ID manifold. A rejection\nnetwork can be trained with ID and diverse outlier samples to detect test OOD\nsamples, but explicitly collecting auxiliary OOD datasets brings an additional\nburden for data collection. In this paper, we propose a simple but effective\nmethod called Pseudo Outlier Exposure (POE) that constructs a surrogate OOD\ndataset by sequentially masking tokens related to ID classes. The surrogate OOD\nsample introduced by POE shows a similar representation to ID data, which is\nmost effective in training a rejection network. Our method does not require any\nexternal OOD data and can be easily implemented within off-the-shelf\nTransformers. A comprehensive comparison with state-of-the-art algorithms\ndemonstrates POE's competitiveness on several text classification benchmarks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaeyoung Kim</a> (1), <a href=\"http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1\">Kyuheon Jung</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Na_D/0/1/0/all/0/1\">Dongbin Na</a> (3), <a href=\"http://arxiv.org/find/cs/1/au:+Jang_S/0/1/0/all/0/1\">Sion Jang</a> (4), <a href=\"http://arxiv.org/find/cs/1/au:+Park_E/0/1/0/all/0/1\">Eunbin Park</a> (2), <a href=\"http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1\">Sungchul Choi</a> (2) ((1) Gachon University, (2) Pukyong National University, (3) VUNO Inc, (4) Alchera Inc)"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A comparative analysis of SR-GAN models. (arXiv:2307.09456v1 [cs.CV])","link":"http://arxiv.org/abs/2307.09456","description":"<p>In this study, we evaluate the performance of multiple state-of-the-art SR\nGAN (Super Resolution Generative Adversarial Network) models, ESRGAN,\nReal-ESRGAN and EDSR, on a benchmark dataset of real-world images which undergo\ndegradation using a pipeline. Our results show that some models seem to\nsignificantly increase the resolution of the input images while preserving\ntheir visual quality, this is assessed using Tesseract OCR engine. We observe\nthat EDSR-BASE model from huggingface outperforms the remaining candidate\nmodels in terms of both quantitative metrics and subjective visual quality\nassessments with least compute overhead. Specifically, EDSR generates images\nwith higher peak signal-to-noise ratio (PSNR) and structural similarity index\n(SSIM) values and are seen to return high quality OCR results with Tesseract\nOCR engine. These findings suggest that EDSR is a robust and effective approach\nfor single-image super-resolution and may be particularly well-suited for\napplications where high-quality visual fidelity is critical and optimized\ncompute.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nikroo_F/0/1/0/all/0/1\">Fatemeh Rezapoor Nikroo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_A/0/1/0/all/0/1\">Ajinkya Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Anantha Sharma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tam_A/0/1/0/all/0/1\">Adrian Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1\">Kaarthik Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Noris_C/0/1/0/all/0/1\">Cleo Noris</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning. (arXiv:2307.09474v1 [cs.CL])","link":"http://arxiv.org/abs/2307.09474","description":"<p>Human-AI interactivity is a critical aspect that reflects the usability of\nmultimodal large language models (MLLMs). However, existing end-to-end MLLMs\nonly allow users to interact with them through language instructions, leading\nto the limitation of the interactive accuracy and efficiency. In this study, we\npresent precise referring instructions that utilize diverse reference\nrepresentations such as points and boxes as referring prompts to refer to the\nspecial region. This enables MLLMs to focus on the region of interest and\nachieve finer-grained interaction. Based on precise referring instruction, we\npropose ChatSpot, a unified end-to-end multimodal large language model that\nsupports diverse forms of interactivity including mouse clicks, drag-and-drop,\nand drawing boxes, which provides a more flexible and seamless interactive\nexperience. We also construct a multi-grained vision-language\ninstruction-following dataset based on existing datasets and GPT-4 generating.\nFurthermore, we design a series of evaluation tasks to assess the effectiveness\nof region recognition and interaction. Experimental results showcase ChatSpot's\npromising performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1\">Liang Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_E/0/1/0/all/0/1\">En Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1\">Zheng Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1\">Jinrong Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1\">Haoran Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1\">Hongyu Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1\">Jianjian Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1\">Yuang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_R/0/1/0/all/0/1\">Runpei Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1\">Chunrui Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xiangyu Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Overthinking the Truth: Understanding how Language Models Process False Demonstrations. (arXiv:2307.09476v1 [cs.LG])","link":"http://arxiv.org/abs/2307.09476","description":"<p>Modern language models can imitate complex patterns through few-shot\nlearning, enabling them to complete challenging tasks without fine-tuning.\nHowever, imitation can also lead models to reproduce inaccuracies or harmful\ncontent if present in the context. We study harmful imitation through the lens\nof a model's internal representations, and identify two related phenomena:\noverthinking and false induction heads. The first phenomenon, overthinking,\nappears when we decode predictions from intermediate layers, given correct vs.\nincorrect few-shot demonstrations. At early layers, both demonstrations induce\nsimilar model behavior, but the behavior diverges sharply at some \"critical\nlayer\", after which the accuracy given incorrect demonstrations progressively\ndecreases. The second phenomenon, false induction heads, are a possible\nmechanistic cause of overthinking: these are heads in late layers that attend\nto and copy false information from previous demonstrations, and whose ablation\nreduces overthinking. Beyond scientific understanding, our results suggest that\nstudying intermediate model computations could be a promising avenue for\nunderstanding and guarding against harmful model behaviors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Halawi_D/0/1/0/all/0/1\">Danny Halawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Denain_J/0/1/0/all/0/1\">Jean-Stanislas Denain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1\">Jacob Steinhardt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"On the Interpretability and Significance of Bias Metrics in Texts: a PMI-based Approach. (arXiv:2104.06474v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2104.06474","description":"<p>In recent years, word embeddings have been widely used to measure biases in\ntexts. Even if they have proven to be effective in detecting a wide variety of\nbiases, metrics based on word embeddings lack transparency and\ninterpretability. We analyze an alternative PMI-based metric to quantify biases\nin texts. It can be expressed as a function of conditional probabilities, which\nprovides a simple interpretation in terms of word co-occurrences. We also prove\nthat it can be approximated by an odds ratio, which allows estimating\nconfidence intervals and statistical significance of textual biases. This\napproach produces similar results to metrics based on word embeddings when\ncapturing gender gaps of the real world embedded in large corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Valentini_F/0/1/0/all/0/1\">Francisco Valentini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rosati_G/0/1/0/all/0/1\">Germ&#xe1;n Rosati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1\">Dami&#xe1;n Blasi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slezak_D/0/1/0/all/0/1\">Diego Fernandez Slezak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Altszyler_E/0/1/0/all/0/1\">Edgar Altszyler</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"InitialGAN: A Language GAN with Completely Random Initialization. (arXiv:2208.02531v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2208.02531","description":"<p>Text generative models trained via Maximum Likelihood Estimation (MLE) suffer\nfrom the notorious exposure bias problem, and Generative Adversarial Networks\n(GANs) are shown to have potential to tackle this problem. Existing language\nGANs adopt estimators like REINFORCE or continuous relaxations to model word\nprobabilities. The inherent limitations of such estimators lead current models\nto rely on pre-training techniques (MLE pre-training or pre-trained\nembeddings). Representation modeling methods which are free from those\nlimitations, however, are seldomly explored because of their poor performance\nin previous attempts. Our analyses reveal that invalid sampling methods and\nunhealthy gradients are the main contributors to such unsatisfactory\nperformance. In this work, we present two techniques to tackle these problems:\ndropout sampling and fully normalized LSTM. Based on these two techniques, we\npropose InitialGAN whose parameters are randomly initialized in full. Besides,\nwe introduce a new evaluation metric, Least Coverage Rate, to better evaluate\nthe quality of generated samples. The experimental results demonstrate that\nInitialGAN outperforms both MLE and other compared models. To the best of our\nknowledge, it is the first time a language GAN can outperform MLE without using\nany pre-training techniques.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ren_D/0/1/0/all/0/1\">Da Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1\">Qing Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe. (arXiv:2210.14348v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2210.14348","description":"<p>Privacy concerns have attracted increasing attention in data-driven products\ndue to the tendency of machine learning models to memorize sensitive training\ndata. Generating synthetic versions of such data with a formal privacy\nguarantee, such as differential privacy (DP), provides a promising path to\nmitigating these privacy concerns, but previous approaches in this direction\nhave typically failed to produce synthetic data of high quality. In this work,\nwe show that a simple and practical recipe in the text domain is effective:\nsimply fine-tuning a pretrained generative language model with DP enables the\nmodel to generate useful synthetic text with strong privacy protection. Through\nextensive empirical analyses on both benchmark and private customer data, we\ndemonstrate that our method produces synthetic text that is competitive in\nterms of utility with its non-private counterpart, meanwhile providing strong\nprotection against potential privacy leakages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1\">Xiang Yue</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Inan_H/0/1/0/all/0/1\">Huseyin A. Inan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuechen Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1\">Girish Kumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+McAnallen_J/0/1/0/all/0/1\">Julia McAnallen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shajari_H/0/1/0/all/0/1\">Hoda Shajari</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1\">Huan Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Levitan_D/0/1/0/all/0/1\">David Levitan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sim_R/0/1/0/all/0/1\">Robert Sim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Human Word Association based model for topic detection in social networks. (arXiv:2301.13066v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2301.13066","description":"<p>With the widespread use of social networks, detecting the topics discussed in\nthese networks has become a significant challenge. The current works are mainly\nbased on frequent pattern mining or semantic relations, and the language\nstructure is not considered. The meaning of language structural methods is to\ndiscover the relationship between words and how humans understand them.\nTherefore, this paper uses the Concept of the Imitation of the Mental Ability\nof Word Association to propose a topic detection framework in social networks.\nThis framework is based on the Human Word Association method. A special\nextraction algorithm has also been designed for this purpose. The performance\nof this method is evaluated on the FA-CUP dataset. It is a benchmark dataset in\nthe field of topic detection. The results show that the proposed method is a\ngood improvement compared to other methods, based on the Topic-recall and the\nkeyword F1 measure. Also, most of the previous works in the field of topic\ndetection are limited to the English language, and the Persian language,\nespecially microblogs written in this language, is considered a low-resource\nlanguage. Therefore, a data set of Telegram posts in the Farsi language has\nbeen collected. Applying the proposed method to this dataset also shows that\nthis method works better than other topic detection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khadivi_M/0/1/0/all/0/1\">Mehrdad Ranjbar Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbarpour_S/0/1/0/all/0/1\">Shahin Akbarpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1\">Mohammad-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anari_B/0/1/0/all/0/1\">Babak Anari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Execution-based Code Generation using Deep Reinforcement Learning. (arXiv:2301.13816v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.13816","description":"<p>The utilization of programming language (PL) models, pre-trained on\nlarge-scale code corpora, as a means of automating software engineering\nprocesses has demonstrated considerable potential in streamlining various code\ngeneration tasks such as code completion, code translation, and program\nsynthesis. However, current approaches mainly rely on supervised fine-tuning\nobjectives borrowed from text generation, neglecting unique sequence-level\ncharacteristics of code, including but not limited to compilability as well as\nsyntactic and functional correctness. To address this limitation, we propose\nPPOCoder, a new framework for code generation that synergistically combines\npre-trained PL models with Proximal Policy Optimization (PPO) which is a widely\nused deep reinforcement learning technique. By utilizing non-differentiable\nfeedback from code execution and structure alignment, PPOCoder seamlessly\nintegrates external code-specific knowledge into the model optimization\nprocess. It's important to note that PPOCoder is a task-agnostic and\nmodel-agnostic framework that can be used across different code generation\ntasks and PLs. Extensive experiments on three code generation tasks demonstrate\nthe effectiveness of our proposed approach compared to SOTA methods, achieving\nsignificant improvements in compilation success rates and functional\ncorrectness across different PLs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1\">Parshin Shojaee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1\">Aneesh Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tipirneni_S/0/1/0/all/0/1\">Sindhu Tipirneni</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1\">Chandan K. Reddy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Persian topic detection based on Human Word association and graph embedding. (arXiv:2302.09775v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2302.09775","description":"<p>In this paper, we propose a framework to detect topics in social media based\non Human Word Association. Identifying topics discussed in these media has\nbecome a critical and significant challenge. Most of the work done in this area\nis in English, but much has been done in the Persian language, especially\nmicroblogs written in Persian. Also, the existing works focused more on\nexploring frequent patterns or semantic relationships and ignored the\nstructural methods of language. In this paper, a topic detection framework\nusing HWA, a method for Human Word Association, is proposed. This method uses\nthe concept of imitation of mental ability for word association. This method\nalso calculates the Associative Gravity Force that shows how words are related.\nUsing this parameter, a graph can be generated. The topics can be extracted by\nembedding this graph and using clustering methods. This approach has been\napplied to a Persian language dataset collected from Telegram. Several\nexperimental studies have been performed to evaluate the proposed framework's\nperformance. Experimental results show that this approach works better than\nother topic detection methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ranjbar_Khadivi_M/0/1/0/all/0/1\">Mehrdad Ranjbar-Khadivi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akbarpour_S/0/1/0/all/0/1\">Shahin Akbarpour</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feizi_Derakhshi_M/0/1/0/all/0/1\">Mohammad-Reza Feizi-Derakhshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anari_B/0/1/0/all/0/1\">Babak Anari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Jointly Extracting Interventions, Outcomes, and Findings from RCT Reports with LLMs. (arXiv:2305.03642v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03642","description":"<p>Results from Randomized Controlled Trials (RCTs) establish the comparative\neffectiveness of interventions, and are in turn critical inputs for\nevidence-based care. However, results from RCTs are presented in (often\nunstructured) natural language articles describing the design, execution, and\noutcomes of trials; clinicians must manually extract findings pertaining to\ninterventions and outcomes of interest from such articles. This onerous manual\nprocess has motivated work on (semi-)automating extraction of structured\nevidence from trial reports. In this work we propose and evaluate a\ntext-to-text model built on instruction-tuned Large Language Models (LLMs) to\njointly extract Interventions, Outcomes, and Comparators (ICO elements) from\nclinical abstracts, and infer the associated results reported. Manual (expert)\nand automated evaluations indicate that framing evidence extraction as a\nconditional generation task and fine-tuning LLMs for this purpose realizes\nconsiderable ($\\sim$20 point absolute F1 score) gains over the previous SOTA.\nWe perform ablations and error analyses to assess aspects that contribute to\nmodel performance, and to highlight potential directions for further\nimprovements. We apply our model to a collection of published RCTs through\nmid-2022, and release a searchable database of structured findings:\n<a href=\"http://ico-relations.ebm-nlp.com\">this http URL</a>\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wadhwa_S/0/1/0/all/0/1\">Somin Wadhwa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+DeYoung_J/0/1/0/all/0/1\">Jay DeYoung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nye_B/0/1/0/all/0/1\">Benjamin Nye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Amir_S/0/1/0/all/0/1\">Silvio Amir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wallace_B/0/1/0/all/0/1\">Byron C. Wallace</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GIFT: Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding. (arXiv:2305.09360v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.09360","description":"<p>Addressing the issues of who saying what to whom in multi-party conversations\n(MPCs) has recently attracted a lot of research attention. However, existing\nmethods on MPC understanding typically embed interlocutors and utterances into\nsequential information flows, or utilize only the superficial of inherent graph\nstructures in MPCs. To this end, we present a plug-and-play and lightweight\nmethod named graph-induced fine-tuning (GIFT) which can adapt various\nTransformer-based pre-trained language models (PLMs) for universal MPC\nunderstanding. In detail, the full and equivalent connections among utterances\nin regular Transformer ignore the sparse but distinctive dependency of an\nutterance on another in MPCs. To distinguish different relationships between\nutterances, four types of edges are designed to integrate graph-induced signals\ninto attention mechanisms to refine PLMs originally designed for processing\nsequential texts. We evaluate GIFT by implementing it into three PLMs, and test\nthe performance on three downstream tasks including addressee recognition,\nspeaker identification and response selection. Experimental results show that\nGIFT can significantly improve the performance of three PLMs on three\ndownstream tasks and two benchmarks with only 4 additional parameters per\nencoding layer, achieving new state-of-the-art performance on MPC\nunderstanding.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1\">Jia-Chen Gu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1\">Zhen-Hua Ling</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Quan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Cong Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1\">Guoping Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Open-QA Evaluation. (arXiv:2305.12421v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.12421","description":"<p>This study focuses on the evaluation of the Open Question Answering (Open-QA)\ntask, which can directly estimate the factuality of large language models\n(LLMs). Current automatic evaluation methods have shown limitations, indicating\nthat human evaluation still remains the most reliable approach. We introduce a\nnew task, Evaluating QA Evaluation (QA-Eval) and the corresponding dataset\nEVOUNA, designed to assess the accuracy of AI-generated answers in relation to\nstandard answers within Open-QA. Our evaluation of these methods utilizes\nhuman-annotated results to measure their performance. Specifically, the work\ninvestigates methods that show high correlation with human evaluations, deeming\nthem more reliable. We also discuss the pitfalls of current methods and methods\nto improve LLM-based evaluators. We believe this new QA-Eval task and\ncorresponding dataset EVOUNA will facilitate the development of more effective\nautomatic evaluation tools and prove valuable for future research in this area.\nAll resources are available at \\url{https://github.com/wangcunxiang/QA-Eval}\nand it is under the Apache-2.0 License.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1\">Sirui Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1\">Qipeng Guo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1\">Zhikun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1\">Bowen Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1\">Xiangkun Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Two Failures of Self-Consistency in the Multi-Step Reasoning of LLMs. (arXiv:2305.14279v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.14279","description":"<p>Large language models (LLMs) have achieved widespread success on a variety of\nin-context few-shot tasks, but this success is typically evaluated via\ncorrectness rather than consistency. We argue that self-consistency is an\nimportant criteria for valid multi-step reasoning in tasks where the solution\nis composed of the answers to multiple sub-steps. We propose two types of\nself-consistency that are particularly important for multi-step reasoning --\nhypothetical consistency (a model's ability to predict what its output would be\nin a hypothetical other context) and compositional consistency (consistency of\na model's final outputs when intermediate sub-steps are replaced with the\nmodel's outputs for those steps). We demonstrate that multiple variants of the\nGPT-3/-4 models exhibit poor consistency rates across both types of consistency\non a variety of tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Angelica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Phang_J/0/1/0/all/0/1\">Jason Phang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Parrish_A/0/1/0/all/0/1\">Alicia Parrish</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padmakumar_V/0/1/0/all/0/1\">Vishakh Padmakumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1\">Chen Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1\">Samuel R. Bowman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SparseOptimizer: Sparsify Language Models through Moreau-Yosida Regularization and Accelerate via Compiler Co-design. (arXiv:2306.15656v3 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.15656","description":"<p>This paper introduces SparseOptimizer, a novel deep learning optimizer that\nexploits Moreau-Yosida regularization to naturally induce sparsity in large\nlanguage models such as BERT, ALBERT and GPT. Key to the design of\nSparseOptimizer is an embedded shrinkage operator, which imparts sparsity\ndirectly within the optimization process. This operator, backed by a sound\ntheoretical framework, includes an analytical solution, thereby reinforcing the\noptimizer's robustness and efficacy. Crucially, SparseOptimizer's plug-and-play\nfunctionality eradicates the need for code modifications, making it a\nuniversally adaptable tool for a wide array of large language models. Empirical\nevaluations on benchmark datasets such as GLUE, RACE, SQuAD1, and SQuAD2\nconfirm that SparseBERT and SparseALBERT, when sparsified using\nSparseOptimizer, achieve performance comparable to their dense counterparts,\nBERT and ALBERT, while significantly reducing their parameter count. Further,\nthis work proposes an innovative optimizer-compiler co-design strategy,\ndemonstrating the potential of inference acceleration (\\textbf{3.37x},\n\\textbf{6.30x}, and \\textbf{7.15x} in comparison with Pytorch, TensorFlow, and\nLLVM generic compile, respectively) in SparseBERT when paired with an\nappropriately designed compiler. This study represents a significant step\nforward in the evolution of efficient, scalable, and high-performing large\nlanguage models, setting a precedent for future exploration and optimization in\nthis domain. The SparseOptimizer code and SparseALBERT model will be publicly\navailable upon paper acceptance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1\">Fu-Ming Guo</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating GPT-3.5 and GPT-4 on Grammatical Error Correction for Brazilian Portuguese. (arXiv:2306.15788v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2306.15788","description":"<p>We investigate the effectiveness of GPT-3.5 and GPT-4, two large language\nmodels, as Grammatical Error Correction (GEC) tools for Brazilian Portuguese\nand compare their performance against Microsoft Word and Google Docs. We\nintroduce a GEC dataset for Brazilian Portuguese with four categories: Grammar,\nSpelling, Internet, and Fast typing. Our results show that while GPT-4 has\nhigher recall than other methods, LLMs tend to have lower precision, leading to\novercorrection. This study demonstrates the potential of LLMs as practical GEC\ntools for Brazilian Portuguese and encourages further exploration of LLMs for\nnon-English languages and other educational settings.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Penteado_M/0/1/0/all/0/1\">Maria Carolina Penteado</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Perez_F/0/1/0/all/0/1\">F&#xe1;bio Perez</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation. (arXiv:2307.02839v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.02839","description":"<p>News summary generation is an important task in the field of intelligence\nanalysis, which can provide accurate and comprehensive information to help\npeople better understand and respond to complex real-world events. However,\ntraditional news summary generation methods face some challenges, which are\nlimited by the model itself and the amount of training data, as well as the\ninfluence of text noise, making it difficult to generate reliable information\naccurately. In this paper, we propose a new paradigm for news summary\ngeneration using LLM with powerful natural language understanding and\ngenerative capabilities. We use LLM to extract multiple structured event\npatterns from the events contained in news paragraphs, evolve the event pattern\npopulation with genetic algorithm, and select the most adaptive event pattern\nto input into the LLM to generate news summaries. A News Summary Generator\n(NSG) is designed to select and evolve the event pattern populations and\ngenerate news summaries. The experimental results show that the news summary\ngenerator is able to generate accurate and reliable news summaries with some\ngeneralization ability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1\">Le Xiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xiaolin Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v5 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.03109","description":"<p>Large language models (LLMs) are gaining increasing popularity in both\nacademia and industry, owing to their unprecedented performance in various\napplications. As LLMs continue to play a vital role in both research and daily\nuse, their evaluation becomes increasingly critical, not only at the task\nlevel, but also at the society level for better understanding of their\npotential risks. Over the past years, significant efforts have been made to\nexamine LLMs from various perspectives. This paper presents a comprehensive\nreview of these evaluation methods for LLMs, focusing on three key dimensions:\nwhat to evaluate, where to evaluate, and how to evaluate. Firstly, we provide\nan overview from the perspective of evaluation tasks, encompassing general\nnatural language processing tasks, reasoning, medical usage, ethics,\neducations, natural and social sciences, agent applications, and other areas.\nSecondly, we answer the `where' and `how' questions by diving into the\nevaluation methods and benchmarks, which serve as crucial components in\nassessing performance of LLMs. Then, we summarize the success and failure cases\nof LLMs in different tasks. Finally, we shed light on several future challenges\nthat lie ahead in LLMs evaluation. Our aim is to offer invaluable insights to\nresearchers in the realm of LLMs evaluation, thereby aiding the development of\nmore proficient LLMs. Our key point is that evaluation should be treated as an\nessential discipline to better assist the development of LLMs. We consistently\nmaintain the related open-source materials at:\nhttps://github.com/MLGroupJLU/LLM-eval-survey.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yupeng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jindong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1\">Yuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1\">Kaijie Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1\">Hao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1\">Linyi Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1\">Xiaoyuan Yi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cunxiang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yidong Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wei Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yue Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1\">Yi Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1\">Qiang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1\">Xing Xie</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Secrets of RLHF in Large Language Models Part I: PPO. (arXiv:2307.04964v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2307.04964","description":"<p>Large language models (LLMs) have formulated a blueprint for the advancement\nof artificial general intelligence. Its primary objective is to function as a\nhuman-centric (helpful, honest, and harmless) assistant. Alignment with humans\nassumes paramount significance, and reinforcement learning with human feedback\n(RLHF) emerges as the pivotal technological paradigm underpinning this pursuit.\nCurrent technical routes usually include \\textbf{reward models} to measure\nhuman preferences, \\textbf{Proximal Policy Optimization} (PPO) to optimize\npolicy model outputs, and \\textbf{process supervision} to improve step-by-step\nreasoning capabilities. However, due to the challenges of reward design,\nenvironment interaction, and agent training, coupled with huge trial and error\ncost of large language models, there is a significant barrier for AI\nresearchers to motivate the development of technical alignment and safe landing\nof LLMs. The stable training of RLHF has still been a puzzle. In the first\nreport, we dissect the framework of RLHF, re-evaluate the inner workings of\nPPO, and explore how the parts comprising PPO algorithms impact policy agent\ntraining. We identify policy constraints being the key factor for the effective\nimplementation of the PPO algorithm. Therefore, we explore the PPO-max, an\nadvanced version of PPO algorithm, to efficiently improve the training\nstability of the policy model. Based on our main results, we perform a\ncomprehensive analysis of RLHF abilities compared with SFT models and ChatGPT.\nThe absence of open-source implementations has posed significant challenges to\nthe investigation of LLMs alignment. Therefore, we are eager to release\ntechnical reports, reward models and PPO codes, aiming to make modest\ncontributions to the advancement of LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1\">Rui Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dou_S/0/1/0/all/0/1\">Shihan Dou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1\">Songyang Gao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1\">Yuan Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1\">Wei Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1\">Binghai Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1\">Yan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jin_S/0/1/0/all/0/1\">Senjie Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1\">Qin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1\">Yuhao Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1\">Limao Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1\">Lu Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1\">Zhiheng Xi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1\">Nuo Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1\">Wenbin Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1\">Minghao Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1\">Cheng Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yin_Z/0/1/0/all/0/1\">Zhangyue Yin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weng_R/0/1/0/all/0/1\">Rongxiang Weng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1\">Wensen Cheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1\">Haoran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1\">Tianxiang Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1\">Hang Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1\">Tao Gui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qi Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1\">Xipeng Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1\">Xuanjing Huang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Communicative Agents for Software Development. (arXiv:2307.07924v2 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2307.07924","description":"<p>Software engineering is a domain characterized by intricate decision-making\nprocesses, often relying on nuanced intuition and consultation. Recent\nadvancements in deep learning have started to revolutionize software\nengineering practices through elaborate designs implemented at various stages\nof software development. In this paper, we present an innovative paradigm that\nleverages large language models (LLMs) throughout the entire software\ndevelopment process, streamlining and unifying key processes through natural\nlanguage communication, thereby eliminating the need for specialized models at\neach phase. At the core of this paradigm lies ChatDev, a virtual chat-powered\nsoftware development company that mirrors the established waterfall model,\nmeticulously dividing the development process into four distinct chronological\nstages: designing, coding, testing, and documenting. Each stage engages a team\nof agents, such as programmers, code reviewers, and test engineers, fostering\ncollaborative dialogue and facilitating a seamless workflow. The chat chain\nacts as a facilitator, breaking down each stage into atomic subtasks. This\nenables dual roles, allowing for proposing and validating solutions through\ncontext-aware communication, leading to efficient resolution of specific\nsubtasks. The instrumental analysis of ChatDev highlights its remarkable\nefficacy in software generation, enabling the completion of the entire software\ndevelopment process in under seven minutes at a cost of less than one dollar.\nIt not only identifies and alleviates potential vulnerabilities but also\nrectifies potential hallucinations while maintaining commendable efficiency and\ncost-effectiveness. The potential of ChatDev unveils fresh possibilities for\nintegrating LLMs into the realm of software development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_C/0/1/0/all/0/1\">Chen Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cong_X/0/1/0/all/0/1\">Xin Cong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Cheng Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1\">Weize Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yusheng Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1\">Juyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1\">Zhiyuan Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1\">Maosong Sun</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Life of PII -- A PII Obfuscation Transformer. (arXiv:2305.09550v2 [cs.CL] CROSS LISTED)","link":"http://arxiv.org/abs/2305.09550","description":"<p>Protecting sensitive information is crucial in today's world of Large\nLanguage Models (LLMs) and data-driven services. One common method used to\npreserve privacy is by using data perturbation techniques to reduce\noverreaching utility of (sensitive) Personal Identifiable Information (PII)\ndata while maintaining its statistical and semantic properties. Data\nperturbation methods often result in significant information loss, making them\nimpractical for use. In this paper, we propose 'Life of PII', a novel\nObfuscation Transformer framework for transforming PII into faux-PII while\npreserving the original information, intent, and context as much as possible.\nOur approach includes an API to interface with the given document, a\nconfiguration-based obfuscator, and a model based on the Transformer\narchitecture, which has shown high context preservation and performance in\nnatural language processing tasks and LLMs.\n</p>\n<p>Our Transformer-based approach learns mapping between the original PII and\nits transformed faux-PII representation, which we call \"obfuscated\" data. Our\nexperiments demonstrate that our method, called Life of PII, outperforms\ntraditional data perturbation techniques in terms of both utility preservation\nand privacy protection. We show that our approach can effectively reduce\nutility loss while preserving the original information, offering greater\nflexibility in the trade-off between privacy protection and data utility. Our\nwork provides a solution for protecting PII in various real-world applications.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Deshmukh_A/0/1/0/all/0/1\">Ajinkya Deshmukh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Banthia_S/0/1/0/all/0/1\">Saumya Banthia</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1\">Anantha Sharma</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-07-18T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"dc":"http://purl.org/dc/elements/1.1/","syn":"http://purl.org/rss/1.0/modules/syndication/","admin":"http://webns.net/mvcb/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/","content":"http://purl.org/rss/1.0/modules/content/"}}]}]}