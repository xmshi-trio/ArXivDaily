{"site_title":"ArxivDaily","project_name":"notfeed","project_version":"0.2.9","project_homepage":"https://github.com/NotCraft/NotFeed","days":[{"datetime":"2023-12-08T01:30:00Z","channels":[{"title":"cs.CL updates on arXiv.org","link":"http://export.arxiv.org/rss/cs.CL","description":"Computer Science -- Computation and Language (cs.CL) updates on the arXiv.org e-print archive","language":null,"copyright":null,"managing_editor":null,"webmaster":null,"pub_date":null,"last_build_date":null,"categories":[],"generator":null,"docs":null,"cloud":null,"rating":null,"ttl":null,"image":{"url":"http://arxiv.org/icons/sfx.gif","title":"arXiv.org","link":"http://arxiv.org/","width":null,"height":null,"description":null},"text_input":null,"skip_hours":[],"skip_days":[],"items":[{"title":"A Process for Topic Modelling Via Word Embeddings. (arXiv:2312.03705v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03705","description":"<p>This work combines algorithms based on word embeddings, dimensionality\nreduction, and clustering. The objective is to obtain topics from a set of\nunclassified texts. The algorithm to obtain the word embeddings is the BERT\nmodel, a neural network architecture widely used in NLP tasks. Due to the high\ndimensionality, a dimensionality reduction technique called UMAP is used. This\nmethod manages to reduce the dimensions while preserving part of the local and\nglobal information of the original data. K-Means is used as the clustering\nalgorithm to obtain the topics. Then, the topics are evaluated using the TF-IDF\nstatistics, Topic Diversity, and Topic Coherence to get the meaning of the\nwords on the clusters. The results of the process show good values, so the\ntopic modeling of this process is a viable option for classifying or clustering\ntexts without labels.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ulloa_D/0/1/0/all/0/1\">Diego Salda&#xf1;a Ulloa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"An Evaluation of State-of-the-Art Large Language Models for Sarcasm Detection. (arXiv:2312.03706v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03706","description":"<p>Sarcasm, as defined by Merriam-Webster, is the use of words by someone who\nmeans the opposite of what he is trying to say. In the field of sentimental\nanalysis of Natural Language Processing, the ability to correctly identify\nsarcasm is necessary for understanding people's true opinions. Because the use\nof sarcasm is often context-based, previous research has used language\nrepresentation models, such as Support Vector Machine (SVM) and Long Short-Term\nMemory (LSTM), to identify sarcasm with contextual-based information. Recent\ninnovations in NLP have provided more possibilities for detecting sarcasm. In\nBERT: Pre-training of Deep Bidirectional Transformers for Language\nUnderstanding, Jacob Devlin et al. (2018) introduced a new language\nrepresentation model and demonstrated higher precision in interpreting\ncontextualized language. As proposed by Hazarika et al. (2018), CASCADE is a\ncontext-driven model that produces good results for detecting sarcasm. This\nstudy analyzes a Reddit corpus using these two state-of-the-art models and\nevaluates their performance against baseline models to find the ideal approach\nto sarcasm detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1\">Juliann Zhou</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multi-label Text Classification using GloVe and Neural Network Models. (arXiv:2312.03707v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03707","description":"<p>This study addresses the challenges of multi-label text classification. The\ndifficulties arise from imbalanced data sets, varied text lengths, and numerous\nsubjective feature labels. Existing solutions include traditional machine\nlearning and deep neural networks for predictions. However, both approaches\nhave their limitations. Traditional machine learning often overlooks the\nassociations between words, while deep neural networks, despite their better\nclassification performance, come with increased training complexity and time.\nThis paper proposes a method utilizing the bag-of-words model approach based on\nthe GloVe model and the CNN-BiLSTM network. The principle is to use the word\nvector matrix trained by the GloVe model as the input for the text embedding\nlayer. Given that the GloVe model requires no further training, the neural\nnetwork model can be trained more efficiently. The method achieves an accuracy\nrate of 87.26% on the test set and an F1 score of 0.8737, showcasing promising\nresults.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Hongren Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Abstraction via exemplars? A representational case study on lexical category inference in BERT. (arXiv:2312.03708v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03708","description":"<p>Exemplar based accounts are often considered to be in direct opposition to\npure linguistic abstraction in explaining language learners' ability to\ngeneralize to novel expressions. However, the recent success of neural network\nlanguage models on linguistically sensitive tasks suggests that perhaps\nabstractions can arise via the encoding of exemplars. We provide empirical\nevidence for this claim by adapting an existing experiment that studies how an\nLM (BERT) generalizes the usage of novel tokens that belong to lexical\ncategories such as Noun/Verb/Adjective/Adverb from exposure to only a single\ninstance of their usage. We analyze the representational behavior of the novel\ntokens in these experiments, and find that BERT's capacity to generalize to\nunseen expressions involving the use of these novel tokens constitutes the\nmovement of novel token representations towards regions of known category\nexemplars in two-dimensional space. Our results suggest that learners' encoding\nof exemplars can indeed give rise to abstraction like behavior.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Misra_K/0/1/0/all/0/1\">Kanishka Misra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1\">Najoung Kim</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UID as a Guiding Metric for Automated Authorship Obfuscation. (arXiv:2312.03709v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03709","description":"<p>Protecting the anonymity of authors has become a difficult task given the\nrise of automated authorship attributors. These attributors are capable of\nattributing the author of a text amongst a pool of authors with great accuracy.\nIn order to counter the rise of these automated attributors, there has also\nbeen a rise of automated obfuscators. These obfuscators are capable of taking\nsome text, perturbing the text in some manner, and, if successful, deceive an\nautomated attributor in misattributing the wrong author. We devised three novel\nauthorship obfuscation methods that utilized a Psycho-linguistic theory known\nas Uniform Information Density (UID) theory. This theory states that humans\nevenly distribute information amongst speech or text so as to maximize\nefficiency. Utilizing this theory in our three obfuscation methods, we\nattempted to see how successfully we could deceive two separate attributors.\nObfuscating 50 human and 50 GPT-3 generated articles from the TuringBench\ndataset, we observed how well each method did on deceiving the attributors.\nWhile the quality of the obfuscation in terms of semantic preservation and\nsensical changes was high, we were not able to find any evidence to indicate\nUID was a viable guiding metric for obfuscation. However, due to restrictions\nin time we were unable to test a large enough sample of article or tune the\nparameters for our attributors to comment conclusively on UID in obfuscation.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abegg_N/0/1/0/all/0/1\">Nicholas Abegg</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Don't Overlook the Grammatical Gender: Bias Evaluation for Hindi-English Machine Translation. (arXiv:2312.03710v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03710","description":"<p>Neural Machine Translation (NMT) models, though state-of-the-art for\ntranslation, often reflect social biases, particularly gender bias. Existing\nevaluation benchmarks primarily focus on English as the source language of\ntranslation. For source languages other than English, studies often employ\ngender-neutral sentences for bias evaluation, whereas real-world sentences\nfrequently contain gender information in different forms. Therefore, it makes\nmore sense to evaluate for bias using such source sentences to determine if NMT\nmodels can discern gender from the grammatical gender cues rather than relying\non biased associations. To illustrate this, we create two gender-specific\nsentence sets in Hindi to automatically evaluate gender bias in various\nHindi-English (HI-EN) NMT systems. We emphasise the significance of tailoring\nbias evaluation test sets to account for grammatical gender markers in the\nsource language.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1\">Pushpdeep Singh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sentiment Analysis of Twitter Posts on Global Conflicts. (arXiv:2312.03715v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03715","description":"<p>Sentiment analysis of social media data is an emerging field with vast\napplications in various domains. In this study, we developed a sentiment\nanalysis model to analyze social media sentiment, especially tweets, during\nglobal conflicting scenarios. To establish our research experiment, we\nidentified a recent global dispute incident on Twitter and collected around\n31,000 filtered Tweets for several months to analyze human sentiment worldwide.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sasikumar_U/0/1/0/all/0/1\">Ujwal Sasikumar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zaman_A/0/1/0/all/0/1\">Ank Zaman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mawlood_Yunis_A/0/1/0/all/0/1\">Abdul-Rahman Mawlood-Yunis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatterjee_P/0/1/0/all/0/1\">Prosenjit Chatterjee</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Co-guiding for Multi-intent Spoken Language Understanding. (arXiv:2312.03716v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03716","description":"<p>Recent graph-based models for multi-intent SLU have obtained promising\nresults through modeling the guidance from the prediction of intents to the\ndecoding of slot filling. However, existing methods (1) only model the\nunidirectional guidance from intent to slot, while there are bidirectional\ninter-correlations between intent and slot; (2) adopt homogeneous graphs to\nmodel the interactions between the slot semantics nodes and intent label nodes,\nwhich limit the performance. In this paper, we propose a novel model termed\nCo-guiding Net, which implements a two-stage framework achieving the mutual\nguidances between the two tasks. In the first stage, the initial estimated\nlabels of both tasks are produced, and then they are leveraged in the second\nstage to model the mutual guidances. Specifically, we propose two heterogeneous\ngraph attention networks working on the proposed two heterogeneous semantics\nlabel graphs, which effectively represent the relations among the semantics\nnodes and label nodes. Besides, we further propose Co-guiding-SCL Net, which\nexploits the single-task and dual-task semantics contrastive relations. For the\nfirst stage, we propose single-task supervised contrastive learning, and for\nthe second stage, we propose co-guiding supervised contrastive learning, which\nconsiders the two tasks' mutual guidances in the contrastive learning\nprocedure. Experiment results on multi-intent SLU show that our model\noutperforms existing models by a large margin, obtaining a relative improvement\nof 21.3% over the previous best model on MixATIS dataset in overall accuracy.\nWe also evaluate our model on the zero-shot cross-lingual scenario and the\nresults show that our model can relatively improve the state-of-the-art model\nby 33.5% on average in terms of overall accuracy for the total 9 languages.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1\">Bowen Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1\">Ivor W. Tsang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models in Law: A Survey. (arXiv:2312.03718v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03718","description":"<p>The advent of artificial intelligence (AI) has significantly impacted the\ntraditional judicial industry. Moreover, recently, with the development of\nAI-generated content (AIGC), AI and law have found applications in various\ndomains, including image recognition, automatic text generation, and\ninteractive chat. With the rapid emergence and growing popularity of large\nmodels, it is evident that AI will drive transformation in the traditional\njudicial industry. However, the application of legal large language models\n(LLMs) is still in its nascent stage. Several challenges need to be addressed.\nIn this paper, we aim to provide a comprehensive survey of legal LLMs. We not\nonly conduct an extensive survey of LLMs, but also expose their applications in\nthe judicial system. We first provide an overview of AI technologies in the\nlegal field and showcase the recent research in LLMs. Then, we discuss the\npractical implementation presented by legal LLMs, such as providing legal\nadvice to users and assisting judges during trials. In addition, we explore the\nlimitations of legal LLMs, including data, algorithms, and judicial practice.\nFinally, we summarize practical recommendations and propose future development\ndirections to address these challenges.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lai_J/0/1/0/all/0/1\">Jinqi Lai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1\">Wensheng Gan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1\">Jiayang Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1\">Zhenlian Qi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1\">Philip S. Yu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Assessing AI Chatbots Performance in Comprehensive Standardized Test Preparation; A Case Study with GRE. (arXiv:2312.03719v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03719","description":"<p>This research paper presents a comprehensive evaluation of the performance of\nthree artificial 10 intelligence chatbots: Bing, ChatGPT, and GPT-4, in\naddressing standardized test questions. Graduate record examination, known as\nGRE, serves as a case study in this paper, encompassing both quantitative\nreasoning and verbal skills. A total of 137 quantitative reasoning questions,\nfeaturing diverse styles and 157 verbal questions categorized into varying\nlevels of difficulty (easy, medium, and hard) were administered to assess the\nchatbots' capabilities. This paper provides a detailed examination of the\nresults and their implications for the utilization of artificial intelligence\nin standardized test preparation by presenting the performance of each chatbot\nacross various skills and styles tested in the exam. Additionally, this paper\nexplores the proficiency of artificial intelligence in addressing image-based\nquestions and illustrates the uncertainty level of each chatbot. The results\nreveal varying degrees of success across the chatbots, demonstrating the\ninfluence of model sophistication and training data. GPT-4 emerged as the most\nproficient, especially in complex language understanding tasks, highlighting\nthe evolution of artificial intelligence in language comprehension and its\nability to pass the exam with a high score.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Abu_Haifa_M/0/1/0/all/0/1\">Mohammad Abu-Haifa</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Etawi_B/0/1/0/all/0/1\">Bara&#x27;a Etawi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alkhatatbeh_H/0/1/0/all/0/1\">Huthaifa Alkhatatbeh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ababneh_A/0/1/0/all/0/1\">Ayman Ababneh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Negotiating with LLMS: Prompt Hacks, Skill Gaps, and Reasoning Deficits. (arXiv:2312.03720v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03720","description":"<p>Large language models LLMs like ChatGPT have reached the 100 Mio user barrier\nin record time and might increasingly enter all areas of our life leading to a\ndiverse set of interactions between those Artificial Intelligence models and\nhumans. While many studies have discussed governance and regulations\ndeductively from first-order principles, few studies provide an inductive,\ndata-driven lens based on observing dialogues between humans and LLMs\nespecially when it comes to non-collaborative, competitive situations that have\nthe potential to pose a serious threat to people. In this work, we conduct a\nuser study engaging over 40 individuals across all age groups in price\nnegotiations with an LLM. We explore how people interact with an LLM,\ninvestigating differences in negotiation outcomes and strategies. Furthermore,\nwe highlight shortcomings of LLMs with respect to their reasoning capabilities\nand, in turn, susceptiveness to prompt hacking, which intends to manipulate the\nLLM to make agreements that are against its instructions or beyond any\nrationality. We also show that the negotiated prices humans manage to achieve\nspan a broad range, which points to a literacy gap in effectively interacting\nwith LLMs.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1\">Johannes Schneider</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Haag_S/0/1/0/all/0/1\">Steffi Haag</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kruse_L/0/1/0/all/0/1\">Leona Chandra Kruse</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Exploring the Robustness of Model-Graded Evaluations and Automated Interpretability. (arXiv:2312.03721v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03721","description":"<p>There has been increasing interest in evaluations of language models for a\nvariety of risks and characteristics. Evaluations relying on natural language\nunderstanding for grading can often be performed at scale by using other\nlanguage models. We test the robustness of these model-graded evaluations to\ninjections on different datasets including a new Deception Eval. These\ninjections resemble direct communication between the testee and the evaluator\nto change their grading. We extrapolate that future, more intelligent models\nmight manipulate or cooperate with their evaluation model. We find significant\nsusceptibility to these injections in state-of-the-art commercial models on all\nexamined evaluations. Furthermore, similar injections can be used on automated\ninterpretability frameworks to produce misleading model-written explanations.\nThe results inspire future work and should caution against unqualified trust in\nevaluations and automated interpretability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lermen_S/0/1/0/all/0/1\">Simon Lermen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kvapil_O/0/1/0/all/0/1\">Ond&#x159;ej Kvapil</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Leveraging AI-derived Data for Carbon Accounting: Information Extraction from Alternative Sources. (arXiv:2312.03722v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03722","description":"<p>Carbon accounting is a fundamental building block in our global path to\nemissions reduction and decarbonization, yet many challenges exist in achieving\nreliable and trusted carbon accounting measures. We motivate that carbon\naccounting not only needs to be more data-driven, but also more\nmethodologically sound. We discuss the need for alternative, more diverse data\nsources that can play a significant role on our path to trusted carbon\naccounting procedures and elaborate on not only why, but how Artificial\nIntelligence (AI) in general and Natural Language Processing (NLP) in\nparticular can unlock reasonable access to a treasure trove of alternative data\nsets in light of the recent advances in the field that better enable the\nutilization of unstructured data in this process. We present a case study of\nthe recent developments on real-world data via an NLP-powered analysis using\nOpenAI's GPT API on financial and shipping data. We conclude the paper with a\ndiscussion on how these methods and approaches can be integrated into a broader\nframework for AI-enabled integrative carbon accounting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Oladeji_O/0/1/0/all/0/1\">Olamide Oladeji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1\">Seyed Shahabeddin Mousavi</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ChatGPT Application In Summarizing An Evolution Of Deep Learning Techniques In Imaging: A Qualitative Study. (arXiv:2312.03723v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03723","description":"<p>The pursuit of article or text summarization has captured the attention of\nnatural language processing (NLP) practitioners, presenting itself as a\nformidable challenge. ChatGPT 3.5 exhibits the capacity to condense the content\nof up to 3000 tokens into a single page, aiming to retain pivotal information\nfrom a given text across diverse themes. In a conducted qualitative research\nendeavor, we selected seven scientific articles and employed the publicly\navailable ChatGPT service to generate summaries of these articles.\nSubsequently, we engaged six co-authors of the articles in a survey, presenting\nfive questions to evaluate the quality of the summaries compared to the\noriginal content. The findings revealed that the summaries produced by ChatGPT\neffectively encapsulated the crucial information present in the articles,\npreserving the principal message of each manuscript. Nonetheless, there was a\nslight diminishment in the technical depth of the summaries as opposed to the\noriginal articles. As a result, our conclusion underscores ChatGPT's text\nsummarization capability as a potent tool for extracting essential insights in\na manner more aligned with reporting than purely scientific discourse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sarraf_A/0/1/0/all/0/1\">Arman Sarraf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abbaspour_A/0/1/0/all/0/1\">Amirabbas Abbaspour</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer. (arXiv:2312.03724v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03724","description":"<p>Large Language Models (LLMs) have emerged as dominant tools for various\ntasks, particularly when tailored for a specific target by prompt tuning.\nNevertheless, concerns surrounding data privacy present obstacles due to the\ntuned prompts' dependency on sensitive private information. A practical\nsolution is to host a local LLM and optimize a soft prompt privately using\ndata. Yet, hosting a local model becomes problematic when model ownership is\nprotected. Alternative methods, like sending data to the model's provider for\ntraining, intensify these privacy issues facing an untrusted provider. In this\npaper, we present a novel solution called Differentially-Private Offsite Prompt\nTuning (DP-OPT) to address this challenge. Our approach involves tuning a\ndiscrete prompt on the client side and then applying it to the desired cloud\nmodels. We demonstrate that prompts suggested by LLMs themselves can be\ntransferred without compromising performance significantly. To ensure that the\nprompts do not leak private information, we introduce the first private prompt\ngeneration mechanism, by a differentially-private (DP) ensemble of in-context\nlearning with private demonstrations. With DP-OPT, generating\nprivacy-preserving prompts by Vicuna-7b can yield competitive performance\ncompared to non-private in-context learning on GPT3.5 or local private prompt\ntuning. Codes are available at https://github.com/VITA-Group/DP-OPT .\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hong_J/0/1/0/all/0/1\">Junyuan Hong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiachen T. Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1\">Chenhui Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1\">Zhangheng Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1\">Bo Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhangyang Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SCStory: Self-supervised and Continual Online Story Discovery. (arXiv:2312.03725v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03725","description":"<p>We present a framework SCStory for online story discovery, that helps people\ndigest rapidly published news article streams in real-time without human\nannotations. To organize news article streams into stories, existing approaches\ndirectly encode the articles and cluster them based on representation\nsimilarity. However, these methods yield noisy and inaccurate story discovery\nresults because the generic article embeddings do not effectively reflect the\nstory-indicative semantics in an article and cannot adapt to the rapidly\nevolving news article streams. SCStory employs self-supervised and continual\nlearning with a novel idea of story-indicative adaptive modeling of news\narticle streams. With a lightweight hierarchical embedding module that first\nlearns sentence representations and then article representations, SCStory\nidentifies story-relevant information of news articles and uses them to\ndiscover stories. The embedding module is continuously updated to adapt to\nevolving news streams with a contrastive learning objective, backed up by two\nunique techniques, confidence-aware memory replay and prioritized-augmentation,\nemployed for label absence and data scarcity problems. Thorough experiments on\nreal and the latest news data sets demonstrate that SCStory outperforms\nexisting state-of-the-art algorithms for unsupervised online story discovery.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1\">Susik Yoon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1\">Yu Meng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1\">Dongha Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1\">Jiawei Han</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interpretation modeling: Social grounding of sentences by reasoning over their implicit moral judgments. (arXiv:2312.03726v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03726","description":"<p>The social and implicit nature of human communication ramifies readers'\nunderstandings of written sentences. Single gold-standard interpretations\nrarely exist, challenging conventional assumptions in natural language\nprocessing. This work introduces the interpretation modeling (IM) task which\ninvolves modeling several interpretations of a sentence's underlying semantics\nto unearth layers of implicit meaning. To obtain these, IM is guided by\nmultiple annotations of social relation and common ground - in this work\napproximated by reader attitudes towards the author and their understanding of\nmoral judgments subtly embedded in the sentence. We propose a number of\nmodeling strategies that rely on one-to-one and one-to-many generation methods\nthat take inspiration from the philosophical study of interpretation. A\nfirst-of-its-kind IM dataset is curated to support experiments and analyses.\nThe modeling results, coupled with scrutiny of the dataset, underline the\nchallenges of IM as conflicting and complex interpretations are socially\nplausible. This interplay of diverse readings is affirmed by automated and\nhuman evaluations on the generated interpretations. Finally, toxicity analyses\nin the generated interpretations demonstrate the importance of IM for refining\nfilters of content and assisting content moderators in safeguarding the safety\nin online discourse.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Allein_L/0/1/0/all/0/1\">Liesbeth Allein</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Trusca_M/0/1/0/all/0/1\">Maria Mihaela Tru&#x15f;c&#x1ce;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moens_M/0/1/0/all/0/1\">Marie-Francine Moens</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Content-Localization based System for Analyzing Sentiment and Hate Behaviors in Low-Resource Dialectal Arabic: English to Levantine and Gulf. (arXiv:2312.03727v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03727","description":"<p>Even though online social movements can quickly become viral on social media,\nlanguages can be a barrier to timely monitoring and analyzing the underlying\nonline social behaviors (OSB). This is especially true for under-resourced\nlanguages on social media like dialectal Arabic; the primary language used by\nArabs on social media. Therefore, it is crucial to provide solutions to\nefficiently exploit resources from high-resourced languages to solve\nlanguage-dependent OSB analysis in under-resourced languages. This paper\nproposes to localize content of resources in high-resourced languages into\nunder-resourced Arabic dialects. Content localization goes beyond content\ntranslation that converts text from one language to another; content\nlocalization adapts culture, language nuances and regional preferences from one\nlanguage to a specific language/dialect. Automating understanding of the\nnatural and familiar day-to-day expressions in different regions, is the key to\nachieve a wider analysis of OSB especially for smart cities. In this paper, we\nutilize content-localization based neural machine translation to develop\nsentiment and hate classifiers for two low-resourced Arabic dialects: Levantine\nand Gulf. Not only this but we also leverage unsupervised learning to\nfacilitate the analysis of sentiment and hate predictions by inferring hidden\ntopics from the corresponding data and providing coherent interpretations of\nthose topics in their native language/dialects. The experimental evaluations\nand proof-of-concept COVID-19 case study on real data have validated the\neffectiveness of our proposed system in precisely distinguishing sentiments and\naccurately identifying hate content in both Levantine and Gulf Arabic dialects.\nOur findings shed light on the importance of considering the unique nature of\ndialects within the same language and ignoring the dialectal aspect would lead\nto misleading analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Alzamzami_F/0/1/0/all/0/1\">Fatimah Alzamzami</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saddik_A/0/1/0/all/0/1\">Abdulmotaleb El Saddik</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Real Customization or Just Marketing: Are Customized Versions of Chat GPT Useful?. (arXiv:2312.03728v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03728","description":"<p>Large Language Models (LLMs), as the case of OpenAI ChatGPT-4 Turbo, are\nrevolutionizing several industries, including higher education. In this\ncontext, LLMs can be personalized through a fine-tuning process to meet the\nstudent demands on every particular subject, like statistics. Recently, OpenAI\nhas launched the possibility to fine-tune their model with a natural language\nweb interface, enabling the possibility to create customized GPT version\ndeliberately conditioned to meet the demands of a specific task. The objective\nof this research is to assess the potential of the customized GPTs that have\nrecently been launched by OpenAI. After developing a Business Statistics\nVirtual Professor (BSVP), tailored for students at the Universidad Pontificia\nComillas, its behavior was evaluated and compared with that of ChatGPT-4 Turbo.\nThe results lead to several conclusions. Firstly, a substantial modification in\nthe style of communication was observed. Following the instructions it was\ntrained with, BSVP provided responses in a more relatable and friendly tone,\neven incorporating a few minor jokes. Secondly, and this is a matter of\nrelevance, when explicitly asked for something like, \"I would like to practice\na programming exercise similar to those in R practice 4,\" BSVP was capable of\nproviding a far superior response: having access to contextual documentation,\nit could fulfill the request, something beyond ChatGPT-4 Turbo's capabilities.\nOn the downside, the response times were generally higher. Lastly, regarding\noverall performance, quality, depth, and alignment with the specific content of\nthe course, no statistically significant differences were observed in the\nresponses between BSVP and ChatGPT-4 Turbo. It appears that customized\nassistants trained with prompts present advantages as virtual aids for\nstudents, yet they do not constitute a substantial improvement over ChatGPT-4\nTurbo.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Garrido_Merchan_E/0/1/0/all/0/1\">Eduardo C. Garrido-Merch&#xe1;n</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Arroyo_Barriguete_J/0/1/0/all/0/1\">Jose L. Arroyo-Barrig&#xfc;ete</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Borras_Pala_F/0/1/0/all/0/1\">Francisco Borr&#xe1;s-Pala</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Escobar_Torres_L/0/1/0/all/0/1\">Leandro Escobar-Torres</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ibarreta_C/0/1/0/all/0/1\">Carlos Mart&#xed;nez de Ibarreta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ortiz_Lozano_J/0/1/0/all/0/1\">Jose Mar&#xed;a Ortiz-Lozano</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rua_Vieites_A/0/1/0/all/0/1\">Antonio Rua-Vieites</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cognitive Dissonance: Why Do Language Model Outputs Disagree with Internal Representations of Truthfulness?. (arXiv:2312.03729v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03729","description":"<p>Neural language models (LMs) can be used to evaluate the truth of factual\nstatements in two ways: they can be either queried for statement probabilities,\nor probed for internal representations of truthfulness. Past work has found\nthat these two procedures sometimes disagree, and that probes tend to be more\naccurate than LM outputs. This has led some researchers to conclude that LMs\n\"lie\" or otherwise encode non-cooperative communicative intents. Is this an\naccurate description of today's LMs, or can query-probe disagreement arise in\nother ways? We identify three different classes of disagreement, which we term\nconfabulation, deception, and heterogeneity. In many cases, the superiority of\nprobes is simply attributable to better calibration on uncertain answers rather\nthan a greater fraction of correct, high-confidence answers. In some cases,\nqueries and probes perform better on different subsets of inputs, and accuracy\ncan further be improved by ensembling the two. Code is available at\ngithub.com/lingo-mit/lm-truthfulness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1\">Kevin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Casper_S/0/1/0/all/0/1\">Stephen Casper</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1\">Dylan Hadfield-Menell</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1\">Jacob Andreas</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News for Credible US Elections. (arXiv:2312.03730v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03730","description":"<p>In today's technologically driven world, the spread of fake news,\nparticularly during crucial events such as elections, presents an increasing\nchallenge to the integrity of information. To address this challenge, we\nintroduce FakeWatch ElectionShield, an innovative framework carefully designed\nto detect fake news. We have created a novel dataset of North American\nelection-related news articles through a blend of advanced language models\n(LMs) and thorough human verification, for precision and relevance. We propose\na model hub of LMs for identifying fake news. Our goal is to provide the\nresearch community with adaptable and accurate classification models in\nrecognizing the dynamic nature of misinformation. Extensive evaluation of fake\nnews classifiers on our dataset and a benchmark dataset shows our that while\nstate-of-the-art LMs slightly outperform the traditional ML models, classical\nmodels are still competitive with their balance of accuracy, explainability,\nand computational efficiency. This research sets the foundation for future\nstudies to address misinformation related to elections.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Khan_T/0/1/0/all/0/1\">Tahniat Khan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mizanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chatrath_V/0/1/0/all/0/1\">Veronica Chatrath</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bamgbose_O/0/1/0/all/0/1\">Oluwanifemi Bamgbose</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs. (arXiv:2312.03731v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03731","description":"<p>Graphs can inherently model interconnected objects on the Web, thereby\nfacilitating a series of Web applications, such as web analyzing and content\nrecommendation. Recently, Graph Neural Networks (GNNs) have emerged as a\nmainstream technique for graph representation learning. However, their efficacy\nwithin an end-to-end supervised framework is significantly tied to the\navailabilityof task-specific labels. To mitigate labeling costs and enhance\nrobustness in few-shot settings, pre-training on self-supervised tasks has\nemerged as a promising method, while prompting has been proposed to further\nnarrow the objective gap between pretext and downstream tasks. Although there\nhas been some initial exploration of prompt-based learning on graphs, they\nprimarily leverage a single pretext task, resulting in a limited subset of\ngeneral knowledge that could be learned from the pre-training data. Hence, in\nthis paper, we propose MultiGPrompt, a novel multi-task pre-training and\nprompting framework to exploit multiple pretext tasks for more comprehensive\npre-trained knowledge. First, in pre-training, we design a set of pretext\ntokens to synergize multiple pretext tasks. Second, we propose a dual-prompt\nmechanism consisting of composed and open prompts to leverage task-specific and\nglobal pre-training knowledge, to guide downstream tasks in few-shot settings.\nFinally, we conduct extensive experiments on six public datasets to evaluate\nand analyze MultiGPrompt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1\">Xingtong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1\">Chang Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Yuan Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1\">Xinming Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA. (arXiv:2312.03732v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03732","description":"<p>As large language models (LLMs) have become increasingly compute and memory\nintensive, parameter-efficient fine-tuning (PEFT) methods are now a common\nstrategy to fine-tune LLMs. A popular PEFT method is Low-Rank Adapters (LoRA),\nwhich adds trainable low-rank \"adapters\" to selected layers. Each adapter\nconsists of a low-rank matrix product, multiplicatively scaled by a\nrank-dependent factor. This scaling factor, which divides adapters by a factor\nof the rank, results in slowed learning and stunted performance for LoRA with\nhigher-rank adapters. Consequently, the use of LoRA in practice has generally\nbeen limited to very low ranks. In this work, we study the impact of the\nscaling factor on the learning process and prove that LoRA adapters should be\ndivided by a factor of the square root of the rank. Modifying LoRA with the\nappropriate scaling factor, which we call the rank-stabilized LoRA (rsLoRA)\nmethod, easily provides for a fine-tuning compute/performance trade-off, where\nlarger ranks can be used to trade off increased computational resources during\ntraining for better fine-tuning performance, with no change in inference\ncomputing cost.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kalajdzievski_D/0/1/0/all/0/1\">Damjan Kalajdzievski</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Methods to Estimate Large Language Model Confidence. (arXiv:2312.03733v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03733","description":"<p>Large Language Models have difficulty communicating uncertainty, which is a\nsignificant obstacle to applying LLMs to complex medical tasks. This study\nevaluates methods to measure LLM confidence when suggesting a diagnosis for\nchallenging clinical vignettes. GPT4 was asked a series of challenging case\nquestions using Chain of Thought and Self Consistency prompting. Multiple\nmethods were investigated to assess model confidence and evaluated on their\nability to predict the models observed accuracy. The methods evaluated were\nIntrinsic Confidence, SC Agreement Frequency and CoT Response Length. SC\nAgreement Frequency correlated with observed accuracy, yielding a higher Area\nunder the Receiver Operating Characteristic Curve compared to Intrinsic\nConfidence and CoT Length analysis. SC agreement is the most useful proxy for\nmodel confidence, especially for medical diagnosis. Model Intrinsic Confidence\nand CoT Response Length exhibit a weaker ability to differentiate between\ncorrect and incorrect answers, preventing them from being reliable and\ninterpretable markers for model confidence. We conclude GPT4 has a limited\nability to assess its own diagnostic accuracy. SC Agreement Frequency is the\nmost useful method to measure GPT4 confidence.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kotelanski_M/0/1/0/all/0/1\">Maia Kotelanski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gallo_R/0/1/0/all/0/1\">Robert Gallo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nayak_A/0/1/0/all/0/1\">Ashwin Nayak</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Savage_T/0/1/0/all/0/1\">Thomas Savage</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conditional Prompt Tuning for Multimodal Fusion. (arXiv:2312.03734v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03734","description":"<p>We show that the representation of one modality can effectively guide the\nprompting of another modality for parameter-efficient multimodal fusion.\nSpecifically, we first encode one modality and use its representation as a\nprior to conditionally prompt all frozen layers of the other modality. This is\nachieved by disentangling the vanilla prompt vectors into three types of\nspecialized prompts that adaptively capture global-level and instance-level\nfeatures. To better produce the instance-wise prompt, we introduce the mixture\nof prompt experts (MoPE) to dynamically route each instance to the most\nsuitable prompt experts for encoding. We further study a regularization term to\navoid degenerated prompt expert routing. Thanks to our design, our method can\neffectively transfer the pretrained knowledge in unimodal encoders for\ndownstream multimodal tasks. Compared with vanilla prompting, we show that our\nMoPE-based conditional prompting is more expressive, thereby scales better with\ntraining data and the total number of prompts. We also demonstrate that our\nprompt tuning is architecture-agnostic, thereby offering high modularity.\nExtensive experiments over three multimodal datasets demonstrate\nstate-of-the-art results, matching or surpassing the performance achieved\nthrough fine-tuning, while only necessitating 0.7% of the trainable parameters.\nCode will be released: https://github.com/songrise/ConditionalPrompt.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1\">Ruixiang Jiang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lingbo Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1\">Changwen Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Advancing State of the Art in Language Modeling. (arXiv:2312.03735v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03735","description":"<p>Generalization is arguably the most important goal of statistical language\nmodeling research. Publicly available benchmarks and papers published with an\nopen-source code have been critical to advancing the field. However, it is\noften very difficult, and sometimes even impossible, to reproduce the results\nfully as reported in publications. In this paper, we propose a simple framework\nthat should help advance the state of the art in language modeling in terms of\ngeneralization. We propose to publish not just the code, but also probabilities\non dev and test sets with future publications so that one can easily add the\nnew model into an ensemble. This has crucial advantages: it is much easier to\ndetermine whether a newly proposed model is actually complementary to the\ncurrent baseline. Therefore, instead of inventing new names for the old tricks,\nthe scientific community can advance faster. Finally, this approach promotes\ndiversity of ideas: one does not need to create an individual model that is the\nnew state of the art to attract attention; it will be sufficient to develop a\nnew model that learns patterns which other models do not. Thus, even a\nsuboptimal model can be found to have value. Remarkably, our approach has\nyielded new state-of-the-art results across various language modeling\nbenchmarks up to 10%.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Herel_D/0/1/0/all/0/1\">David Herel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mikolov_T/0/1/0/all/0/1\">Tomas Mikolov</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"De-identification of clinical free text using natural language processing: A systematic review of current approaches. (arXiv:2312.03736v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03736","description":"<p>Background: Electronic health records (EHRs) are a valuable resource for\ndata-driven medical research. However, the presence of protected health\ninformation (PHI) makes EHRs unsuitable to be shared for research purposes.\nDe-identification, i.e. the process of removing PHI is a critical step in\nmaking EHR data accessible. Natural language processing has repeatedly\ndemonstrated its feasibility in automating the de-identification process.\nObjectives: Our study aims to provide systematic evidence on how the\nde-identification of clinical free text has evolved in the last thirteen years,\nand to report on the performances and limitations of the current\nstate-of-the-art systems. In addition, we aim to identify challenges and\npotential research opportunities in this field. Methods: A systematic search in\nPubMed, Web of Science and the DBLP was conducted for studies published between\nJanuary 2010 and February 2023. Titles and abstracts were examined to identify\nthe relevant studies. Selected studies were then analysed in-depth, and\ninformation was collected on de-identification methodologies, data sources, and\nmeasured performance. Results: A total of 2125 publications were identified for\nthe title and abstract screening. 69 studies were found to be relevant. Machine\nlearning (37 studies) and hybrid (26 studies) approaches are predominant, while\nsix studies relied only on rules. Majority of the approaches were trained and\nevaluated on public corpora. The 2014 i2b2/UTHealth corpus is the most\nfrequently used (36 studies), followed by the 2006 i2b2 (18 studies) and 2016\nCEGS N-GRID (10 studies) corpora.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kovacevic_A/0/1/0/all/0/1\">Aleksandar Kova&#x10d;evi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Basaragin_B/0/1/0/all/0/1\">Bojana Ba&#x161;aragin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Milosevic_N/0/1/0/all/0/1\">Nikola Milo&#x161;evi&#x107;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nenadic_G/0/1/0/all/0/1\">Goran Nenadi&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Generic NLI approach for Classification of Sentiment Associated with Therapies. (arXiv:2312.03737v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03737","description":"<p>This paper describes our system for addressing SMM4H 2023 Shared Task 2 on\n\"Classification of sentiment associated with therapies (aspect-oriented)\". In\nour work, we adopt an approach based on Natural language inference (NLI) to\nformulate this task as a sentence pair classification problem, and train\ntransformer models to predict sentiment associated with a therapy on a given\ntext. Our best model achieved 75.22\\% F1-score which was 11\\% (4\\%) more than\nthe mean (median) score of all teams' submissions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kanagasabai_R/0/1/0/all/0/1\">Rajaraman Kanagasabai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Veeramani_A/0/1/0/all/0/1\">Anitha Veeramani</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntactic Fusion: Enhancing Aspect-Level Sentiment Analysis Through Multi-Tree Graph Integration. (arXiv:2312.03738v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03738","description":"<p>Recent progress in aspect-level sentiment classification has been propelled\nby the incorporation of graph neural networks (GNNs) leveraging syntactic\nstructures, particularly dependency trees. Nevertheless, the performance of\nthese models is often hampered by the innate inaccuracies of parsing\nalgorithms. To mitigate this challenge, we introduce SynthFusion, an innovative\ngraph ensemble method that amalgamates predictions from multiple parsers. This\nstrategy blends diverse dependency relations prior to the application of GNNs,\nenhancing robustness against parsing errors while avoiding extra computational\nburdens. SynthFusion circumvents the pitfalls of overparameterization and\ndiminishes the risk of overfitting, prevalent in models with stacked GNN\nlayers, by optimizing graph connectivity. Our empirical evaluations on the\nSemEval14 and Twitter14 datasets affirm that SynthFusion not only outshines\nmodels reliant on single dependency trees but also eclipses alternative\nensemble techniques, achieving this without an escalation in model complexity.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sunny_J/0/1/0/all/0/1\">Jane Sunny</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padraig_T/0/1/0/all/0/1\">Tom Padraig</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Terry_R/0/1/0/all/0/1\">Roggie Terry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_W/0/1/0/all/0/1\">Woods Ali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Syntax-Informed Interactive Model for Comprehensive Aspect-Based Sentiment Analysis. (arXiv:2312.03739v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03739","description":"<p>Aspect-based sentiment analysis (ABSA), a nuanced task in text analysis,\nseeks to discern sentiment orientation linked to specific aspect terms in text.\nTraditional approaches often overlook or inadequately model the explicit\nsyntactic structures of sentences, crucial for effective aspect term\nidentification and sentiment determination. Addressing this gap, we introduce\nan innovative model: Syntactic Dependency Enhanced Multi-Task Interaction\nArchitecture (SDEMTIA) for comprehensive ABSA. Our approach innovatively\nexploits syntactic knowledge (dependency relations and types) using a\nspecialized Syntactic Dependency Embedded Interactive Network (SDEIN). We also\nincorporate a novel and efficient message-passing mechanism within a multi-task\nlearning framework to bolster learning efficacy. Our extensive experiments on\nbenchmark datasets showcase our model's superiority, significantly surpassing\nexisting methods. Additionally, incorporating BERT as an auxiliary feature\nextractor further enhances our model's performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Galen_U/0/1/0/all/0/1\">Ullman Galen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_F/0/1/0/all/0/1\">Frey Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ali_W/0/1/0/all/0/1\">Woods Ali</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompting in Autoregressive Large Language Models. (arXiv:2312.03740v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03740","description":"<p>Autoregressive Large Language Models have transformed the landscape of\nNatural Language Processing. Pre-train and prompt paradigm has replaced the\nconventional approach of pre-training and fine-tuning for many downstream NLP\ntasks. This shift has been possible largely due to LLMs and innovative\nprompting techniques. LLMs have shown great promise for a variety of downstream\ntasks owing to their vast parameters and huge datasets that they are\npre-trained on. However, in order to fully realize their potential, their\noutputs must be guided towards the desired outcomes. Prompting, in which a\nspecific input or instruction is provided to guide the LLMs toward the intended\noutput, has become a tool for achieving this goal. In this paper, we discuss\nthe various prompting techniques that have been applied to fully harness the\npower of LLMs. We present a taxonomy of existing literature on prompting\ntechniques and provide a concise survey based on this taxonomy. Further, we\nidentify some open problems in the realm of prompting in autoregressive LLMs\nwhich could serve as a direction for future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bhandari_P/0/1/0/all/0/1\">Prabin Bhandari</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparing Generative Chatbots Based on Process Requirements. (arXiv:2312.03741v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03741","description":"<p>Business processes are commonly represented by modelling languages, such as\nEvent-driven Process Chain (EPC), Yet Another Workflow Language (YAWL), and the\nmost popular standard notation for modelling business processes, the Business\nProcess Model and Notation (BPMN). Most recently, chatbots, programs that allow\nusers to interact with a machine using natural language, have been increasingly\nused for business process execution support. A recent category of chatbots\nworth mentioning is generative-based chatbots, powered by Large Language Models\n(LLMs) such as OpenAI's Generative Pre-Trained Transformer (GPT) model and\nGoogle's Pathways Language Model (PaLM), which are trained on billions of\nparameters and support conversational intelligence. However, it is not clear\nwhether generative-based chatbots are able to understand and meet the\nrequirements of constructs such as those provided by BPMN for process execution\nsupport. This paper presents a case study to compare the performance of\nprominent generative models, GPT and PaLM, in the context of process execution\nsupport. The research sheds light into the challenging problem of using\nconversational approaches supported by generative chatbots as a means to\nunderstand process-aware modelling notations and support users to execute their\ntasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lins_L/0/1/0/all/0/1\">Luis Fernando Lins</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Nascimento_N/0/1/0/all/0/1\">Nathalia Nascimento</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alencar_P/0/1/0/all/0/1\">Paulo Alencar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oliveira_T/0/1/0/all/0/1\">Toacy Oliveira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cowan_D/0/1/0/all/0/1\">Donald Cowan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Clinical Risk Prediction Using Language Models: Benefits And Considerations. (arXiv:2312.03742v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03742","description":"<p>The utilization of Electronic Health Records (EHRs) for clinical risk\nprediction is on the rise. However, strict privacy regulations limit access to\ncomprehensive health records, making it challenging to apply standard machine\nlearning algorithms in practical real-world scenarios. Previous research has\naddressed this data limitation by incorporating medical ontologies and\nemploying transfer learning methods. In this study, we investigate the\npotential of leveraging language models (LMs) as a means to incorporate\nsupplementary domain knowledge for improving the performance of various\nEHR-based risk prediction tasks. Unlike applying LMs to unstructured EHR data\nsuch as clinical notes, this study focuses on using textual descriptions within\nstructured EHR to make predictions exclusively based on that information. We\nextensively compare against previous approaches across various data types and\nsizes. We find that employing LMs to represent structured EHRs, such as\ndiagnostic histories, leads to improved or at least comparable performance in\ndiverse risk prediction tasks. Furthermore, LM-based approaches offer numerous\nadvantages, including few-shot learning, the capability to handle previously\nunseen medical concepts, and adaptability to various medical vocabularies.\nNevertheless, we underscore, through various experiments, the importance of\nbeing cautious when employing such models, as concerns regarding the\nreliability of LMs persist.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1\">Angeela Acharya</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shrestha_S/0/1/0/all/0/1\">Sulabh Shrestha</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Anyi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Conte_J/0/1/0/all/0/1\">Joseph Conte</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Avramovic_S/0/1/0/all/0/1\">Sanja Avramovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sikdar_S/0/1/0/all/0/1\">Siddhartha Sikdar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Anastasopoulos_A/0/1/0/all/0/1\">Antonios Anastasopoulos</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1\">Sanmay Das</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Easy Data Augmentation in Sentiment Analysis of Cyberbullying. (arXiv:2312.03743v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03743","description":"<p>Instagram, a social media platform, has in the vicinity of 2 billion active\nusers in 2023. The platform allows users to post photos and videos with one\nanother. However, cyberbullying remains a significant problem for about 50% of\nyoung Indonesians. To address this issue, sentiment analysis for comment\nfiltering uses a Support Vector Machine (SVM) and Easy Data Augmentation (EDA).\nEDA will augment the dataset, enabling robust prediction and analysis of\ncyberbullying by introducing more variation. Based on the tests, SVM\ncombination with EDA results in a 2.52% increase in the k-Fold Cross Validation\nscore. Our proposed approach shows an improved accuracy of 92.5%, 2.5% higher\nthan that of the existing state-of-the-art method. To maintain the\nreproducibility and replicability of this research, the source code can be\naccessed at uns.id/eda_svm.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wirawan_A/0/1/0/all/0/1\">Alwan Wirawan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cahyono_H/0/1/0/all/0/1\">Hasan Dwi Cahyono</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Winarno/0/1/0/all/0/1\">Winarno</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Dynamic interactive group decision making method on two-dimensional language. (arXiv:2312.03744v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03744","description":"<p>The language evaluation information of the interactive group decision method\nat present is based on the one-dimension language variable. At the same time,\nmulti-attribute group decision making method based on two-dimension linguistic\ninformation only use single-stage and static evaluation method. In this paper,\nwe propose a dynamic group decision making method based on two-dimension\nlinguistic information, combining dynamic interactive group decision making\nmethods with two-dimensional language evaluation information The method first\nuse Two-Dimensional Uncertain Linguistic Generalized Weighted Aggregation\n(DULGWA) Operators to aggregate the preference information of each decision\nmaker, then adopting dynamic information entropy method to obtain weights of\nattributes at each stage. Finally we propose the group consistency index to\nquantify the termination conditions of group interaction. One example is given\nto verify the developed approach and to demonstrate its effectiveness\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yukun Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Evaluating Large Language Model Creativity from a Literary Perspective. (arXiv:2312.03746v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03746","description":"<p>This paper assesses the potential for large language models (LLMs) to serve\nas assistive tools in the creative writing process, by means of a single,\nin-depth case study. In the course of the study, we develop interactive and\nmulti-voice prompting strategies that interleave background descriptions (scene\nsetting, plot elements), instructions that guide composition, samples of text\nin the target style, and critical discussion of the given samples. We\nqualitatively evaluate the results from a literary critical perspective, as\nwell as from the standpoint of computational creativity (a sub-field of\nartificial intelligence). Our findings lend support to the view that the\nsophistication of the results that can be achieved with an LLM mirrors the\nsophistication of the prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1\">Murray Shanahan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clarke_C/0/1/0/all/0/1\">Catherine Clarke</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Classifying patient voice in social media data using neural networks: A comparison of AI models on different data sources and therapeutic domains. (arXiv:2312.03747v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03747","description":"<p>It is essential that healthcare professionals and members of the healthcare\ncommunity can access and easily understand patient experiences in the real\nworld, so that care standards can be improved and driven towards personalised\ndrug treatment. Social media platforms and message boards are deemed suitable\nsources of patient experience information, as patients have been observed to\ndiscuss and exchange knowledge, look for and provide support online. This paper\ntests the hypothesis that not all online patient experience information can be\ntreated and collected in the same way, as a result of the inherent differences\nin the way individuals talk about their journeys, in different therapeutic\ndomains and or data sources.\n</p>\n<p>We used linguistic analysis to understand and identify similarities between\ndatasets, across patient language, between data sources (Reddit, SocialGist)\nand therapeutic domains (cardiovascular, oncology, immunology, neurology). We\ndetected common vocabulary used by patients in the same therapeutic domain\nacross data sources, except for immunology patients, who use unique vocabulary\nbetween the two data sources, and compared to all other datasets. We combined\nlinguistically similar datasets to train classifiers (CNN, transformer) to\naccurately identify patient experience posts from social media, a task we refer\nto as patient voice classification. The cardiovascular and neurology\ntransformer classifiers perform the best in their respective comparisons for\nthe Reddit data source, achieving F1-scores of 0.865 and 1.0 respectively. The\noverall best performing classifier is the transformer classifier trained on all\ndata collected for this experiment, achieving F1-scores ranging between 0.863\nand 0.995 across all therapeutic domain and data source specific test datasets.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lysandrou_G/0/1/0/all/0/1\">Giorgos Lysandrou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Owen_R/0/1/0/all/0/1\">Roma English Owen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popovic_V/0/1/0/all/0/1\">Vanja Popovic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Brun_G/0/1/0/all/0/1\">Grant Le Brun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alex_B/0/1/0/all/0/1\">Beatrice Alex</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fairley_E/0/1/0/all/0/1\">Elizabeth A. L. Fairley</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Applying Large Language Models and Chain-of-Thought for Automatic Scoring. (arXiv:2312.03748v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03748","description":"<p>This study investigates the application of large language models (LLMs),\nspecifically GPT-3.5 and GPT-4, with Chain-of-Though (CoT)in the automatic\nscoring of student-written responses to science assessments. We focused on\novercoming the challenges of accessibility, technical complexity, and lack of\nexplainability that have previously limited the use of automatic assessment\ntools among researchers and educators. We used a testing dataset comprising six\nassessment tasks (three binomial and three trinomial) with 1,650 student\nresponses. We employed six prompt engineering strategies, combining zero-shot\nor few-shot learning with CoT, either alone or alongside item stem and scoring\nrubrics. Results indicated that few-shot (acc = .67) outperformed zero-shot\nlearning (acc = .60), with 12.6\\% increase. CoT, when used without item stem\nand scoring rubrics, did not significantly affect scoring accuracy (acc = .60).\nHowever, CoT prompting paired with contextual item stems and rubrics proved to\nbe a significant contributor to scoring accuracy (13.44\\% increase for\nzero-shot; 3.7\\% increase for few-shot). Using a novel approach PPEAS, we found\na more balanced accuracy across different proficiency categories, highlighting\nthe importance of domain-specific reasoning in enhancing the effectiveness of\nLLMs in scoring tasks. Additionally, we also found that GPT-4 demonstrated\nsuperior performance over GPT-3.5 in various scoring tasks, showing 8.64\\%\ndifference. The study revealed that the single-call strategy with GPT-4,\nparticularly using greedy sampling, outperformed other approaches, including\nensemble voting strategies. This study demonstrates the potential of LLMs in\nfacilitating automatic scoring, emphasizing that CoT enhances accuracy,\nparticularly when used with item stem and scoring rubrics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1\">Gyeong-Geon Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Latif_E/0/1/0/all/0/1\">Ehsan Latif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xuansheng Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1\">Ninghao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaoming Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conceptual Engineering Using Large Language Models. (arXiv:2312.03749v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03749","description":"<p>We describe a method, based on Jennifer Nado's definition of classification\nprocedures as targets of conceptual engineering, that implements such\nprocedures using a large language model. We then apply this method using data\nfrom the Wikidata knowledge graph to evaluate concept definitions from two\nparadigmatic conceptual engineering projects: the International Astronomical\nUnion's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN.\nWe discuss implications of this work for the theory and practice of conceptual\nengineering. The code and data can be found on GitHub.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Allen_B/0/1/0/all/0/1\">Bradley P. Allen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing the Influence of Fake News in the 2024 Elections: A Comprehensive Dataset. (arXiv:2312.03750v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03750","description":"<p>This work introduces a dataset focused on fake news in US political speeches,\nspecifically examining racial slurs and biases. By scraping and annotating\n40,000 news articles, using advanced NLP tools and human verification, we\nprovide a nuanced understanding of misinformation in political discourse. The\ndataset, designed for machine learning and bias analysis, is a critical\nresource for researchers, policymakers, and educators. It facilitates the\ndevelopment of strategies against misinformation and enhances media literacy,\nmarking a significant contribution to the study of fake news and political\ncommunication. Our dataset, focusing on the analysis of fake news in the\ncontext of the 2024 elections, is publicly accessible for community to work on\nfake news identification. Our dataset, focusing on the analysis of fake news in\nthe context of the 2024 elections, is publicly accessible.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1\">Mizanur Rahman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Which linguistic cues make people fall for fake news? A comparison of cognitive and affective processing. (arXiv:2312.03751v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03751","description":"<p>Fake news on social media has large, negative implications for society.\nHowever, little is known about what linguistic cues make people fall for fake\nnews and, hence, how to design effective countermeasures for social media. In\nthis study, we seek to understand which linguistic cues make people fall for\nfake news. Linguistic cues (e.g., adverbs, personal pronouns, positive emotion\nwords, negative emotion words) are important characteristics of any text and\nalso affect how people process real vs. fake news. Specifically, we compare the\nrole of linguistic cues across both cognitive processing (related to careful\nthinking) and affective processing (related to unconscious automatic\nevaluations). To this end, we performed a within-subject experiment where we\ncollected neurophysiological measurements of 42 subjects while these read a\nsample of 40 real and fake news articles. During our experiment, we measured\ncognitive processing through eye fixations, and affective processing in situ\nthrough heart rate variability. We find that users engage more in cognitive\nprocessing for longer fake news articles, while affective processing is more\npronounced for fake news written in analytic words. To the best of our\nknowledge, this is the first work studying the role of linguistic cues in fake\nnews processing. Altogether, our findings have important implications for\ndesigning online platforms that encourage users to engage in careful thinking\nand thus prevent them from falling for fake news.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Lutz_B/0/1/0/all/0/1\">Bernhard Lutz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adam_M/0/1/0/all/0/1\">Marc Adam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1\">Stefan Feuerriegel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Prollochs_N/0/1/0/all/0/1\">Nicolas Pr&#xf6;llochs</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Neumann_D/0/1/0/all/0/1\">Dirk Neumann</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Automatic Scoring of Students' Science Writing Using Hybrid Neural Network. (arXiv:2312.03752v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03752","description":"<p>This study explores the efficacy of a multi-perspective hybrid neural network\n(HNN) for scoring student responses in science education with an analytic\nrubric. We compared the accuracy of the HNN model with four ML approaches\n(BERT, AACR, Naive Bayes, and Logistic Regression). The results have shown that\nHHN achieved 8%, 3%, 1%, and 0.12% higher accuracy than Naive Bayes, Logistic\nRegression, AACR, and BERT, respectively, for five scoring aspects (p&lt;0.001).\nThe overall HNN's perceived accuracy (M = 96.23%, SD = 1.45%) is comparable to\nthe (training and inference) expensive BERT model's accuracy (M = 96.12%, SD =\n1.52%). We also have observed that HNN is x2 more efficient in training and\ninferencing than BERT and has comparable efficiency to the lightweight but less\naccurate Naive Bayes model. Our study confirmed the accuracy and efficiency of\nusing HNN to score students' science writing automatically.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Latif_E/0/1/0/all/0/1\">Ehsan Latif</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1\">Xiaoming Zhai</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"English to Arabic machine translation of mathematical documents. (arXiv:2312.03753v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03753","description":"<p>This paper is about the development of a machine translation system tailored\nspecifically for LATEX mathematical documents. The system focuses on\ntranslating English LATEX mathematical documents into Arabic LATEX, catering to\nthe growing demand for multilingual accessibility in scientific and\nmathematical literature. With the vast proliferation of LATEX mathematical\ndocuments the need for an efficient and accurate translation system has become\nincreasingly essential. This paper addresses the necessity for a robust\ntranslation tool that enables seamless communication and comprehension of\ncomplex mathematical content across language barriers. The proposed system\nleverages a Transformer model as the core of the translation system, ensuring\nenhanced accuracy and fluency in the translated Arabic LATEX documents.\nFurthermore, the integration of RyDArab, an Arabic mathematical TEX extension,\nalong with a rule-based translator for Arabic mathematical expressions,\ncontributes to the precise rendering of complex mathematical symbols and\nequations in the translated output. The paper discusses the architecture,\nmethodology, of the developed system, highlighting its efficacy in bridging the\nlanguage gap in the domain of mathematical documentation\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Eddahibi_M/0/1/0/all/0/1\">Mustapha Eddahibi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mensouri_M/0/1/0/all/0/1\">Mohammed Mensouri</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Near-real-time Earthquake-induced Fatality Estimation using Crowdsourced Data and Large-Language Models. (arXiv:2312.03755v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03755","description":"<p>When a damaging earthquake occurs, immediate information about casualties is\ncritical for time-sensitive decision-making by emergency response and aid\nagencies in the first hours and days. Systems such as Prompt Assessment of\nGlobal Earthquakes for Response (PAGER) by the U.S. Geological Survey (USGS)\nwere developed to provide a forecast within about 30 minutes of any significant\nearthquake globally. Traditional systems for estimating human loss in disasters\noften depend on manually collected early casualty reports from global media, a\nprocess that's labor-intensive and slow with notable time delays. Recently,\nsome systems have employed keyword matching and topic modeling to extract\nrelevant information from social media. However, these methods struggle with\nthe complex semantics in multilingual texts and the challenge of interpreting\never-changing, often conflicting reports of death and injury numbers from\nvarious unverified sources on social media platforms. In this work, we\nintroduce an end-to-end framework to significantly improve the timeliness and\naccuracy of global earthquake-induced human loss forecasting using\nmulti-lingual, crowdsourced social media. Our framework integrates (1) a\nhierarchical casualty extraction model built upon large language models, prompt\ndesign, and few-shot learning to retrieve quantitative human loss claims from\nsocial media, (2) a physical constraint-aware, dynamic-truth discovery model\nthat discovers the truthful human loss from massive noisy and potentially\nconflicting human loss claims, and (3) a Bayesian updating loss projection\nmodel that dynamically updates the final loss estimation using discovered\ntruths. We test the framework in real-time on a series of global earthquake\nevents in 2021 and 2022 and show that our framework streamlines casualty data\nretrieval, achieving speed and accuracy comparable to manual methods by USGS.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chenguang Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Engler_D/0/1/0/all/0/1\">Davis Engler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1\">Xuechun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1\">James Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wald_D/0/1/0/all/0/1\">David J. Wald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jaiswal_K/0/1/0/all/0/1\">Kishor Jaiswal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Susu Xu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LineConGraphs: Line Conversation Graphs for Effective Emotion Recognition using Graph Neural Networks. (arXiv:2312.03756v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03756","description":"<p>Emotion Recognition in Conversations (ERC) is a critical aspect of affective\ncomputing, and it has many practical applications in healthcare, education,\nchatbots, and social media platforms. Earlier approaches for ERC analysis\ninvolved modeling both speaker and long-term contextual information using graph\nneural network architectures. However, it is ideal to deploy\nspeaker-independent models for real-world applications. Additionally, long\ncontext windows can potentially create confusion in recognizing the emotion of\nan utterance in a conversation. To overcome these limitations, we propose novel\nline conversation graph convolutional network (LineConGCN) and graph attention\n(LineConGAT) models for ERC analysis. These models are speaker-independent and\nbuilt using a graph construction strategy for conversations -- line\nconversation graphs (LineConGraphs). The conversational context in\nLineConGraphs is short-term -- limited to one previous and future utterance,\nand speaker information is not part of the graph. We evaluate the performance\nof our proposed models on two benchmark datasets, IEMOCAP and MELD, and show\nthat our LineConGAT model outperforms the state-of-the-art methods with an\nF1-score of 64.58% and 76.50%. Moreover, we demonstrate that embedding\nsentiment shift information into line conversation graphs further enhances the\nERC performance in the case of GCN models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krishnan_G/0/1/0/all/0/1\">Gokul S Krishnan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Padi_S/0/1/0/all/0/1\">Sarala Padi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Greenberg_C/0/1/0/all/0/1\">Craig S. Greenberg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ravindran_B/0/1/0/all/0/1\">Balaraman Ravindran</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Manoch_D/0/1/0/all/0/1\">Dinesh Manoch</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sriram_R/0/1/0/all/0/1\">Ram D.Sriram</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Stock Movement and Volatility Prediction from Tweets, Macroeconomic Factors and Historical Prices. (arXiv:2312.03758v1 [cs.AI])","link":"http://arxiv.org/abs/2312.03758","description":"<p>Predicting stock market is vital for investors and policymakers, acting as a\nbarometer of the economic health. We leverage social media data, a potent\nsource of public sentiment, in tandem with macroeconomic indicators as\ngovernment-compiled statistics, to refine stock market predictions. However,\nprior research using tweet data for stock market prediction faces three\nchallenges. First, the quality of tweets varies widely. While many are filled\nwith noise and irrelevant details, only a few genuinely mirror the actual\nmarket scenario. Second, solely focusing on the historical data of a particular\nstock without considering its sector can lead to oversight. Stocks within the\nsame industry often exhibit correlated price behaviors. Lastly, simply\nforecasting the direction of price movement without assessing its magnitude is\nof limited value, as the extent of the rise or fall truly determines\nprofitability. In this paper, diverging from the conventional methods, we\npioneer an ECON. The framework has following advantages: First, ECON has an\nadept tweets filter that efficiently extracts and decodes the vast array of\ntweet data. Second, ECON discerns multi-level relationships among stocks,\nsectors, and macroeconomic factors through a self-aware mechanism in semantic\nspace. Third, ECON offers enhanced accuracy in predicting substantial stock\nprice fluctuations by capitalizing on stock price movement. We showcase the\nstate-of-the-art performance of our proposed model using a dataset,\nspecifically curated by us, for predicting stock market movements and\nvolatility.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1\">Shengkun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1\">YangXiao Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1\">Taoran Ji</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1\">Kaiqun Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1\">Linhan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1\">Chang-Tien Lu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"How should the advent of large language models affect the practice of science?. (arXiv:2312.03759v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03759","description":"<p>Large language models (LLMs) are being increasingly incorporated into\nscientific workflows. However, we have yet to fully grasp the implications of\nthis integration. How should the advent of large language models affect the\npractice of science? For this opinion piece, we have invited four diverse\ngroups of scientists to reflect on this query, sharing their perspectives and\nengaging in debate. Schulz et al. make the argument that working with LLMs is\nnot fundamentally different from working with human collaborators, while Bender\net al. argue that LLMs are often misused and over-hyped, and that their\nlimitations warrant a focus on more specialized, easily interpretable tools.\nMarelli et al. emphasize the importance of transparent attribution and\nresponsible use of LLMs. Finally, Botvinick and Gershman advocate that humans\nshould retain responsibility for determining the scientific roadmap. To\nfacilitate the discussion, the four perspectives are complemented with a\nresponse from each group. By putting these different perspectives in\nconversation, we aim to bring attention to important considerations within the\nacademic community regarding the adoption of LLMs and their impact on both\ncurrent and future scientific practices.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Binz_M/0/1/0/all/0/1\">Marcel Binz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alaniz_S/0/1/0/all/0/1\">Stephan Alaniz</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Roskies_A/0/1/0/all/0/1\">Adina Roskies</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Aczel_B/0/1/0/all/0/1\">Balazs Aczel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bergstrom_C/0/1/0/all/0/1\">Carl T. Bergstrom</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1\">Colin Allen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schad_D/0/1/0/all/0/1\">Daniel Schad</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wulff_D/0/1/0/all/0/1\">Dirk Wulff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+West_J/0/1/0/all/0/1\">Jevin D. West</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Qiong Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shiffrin_R/0/1/0/all/0/1\">Richard M. Shiffrin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1\">Samuel J. Gershman</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Popov_V/0/1/0/all/0/1\">Ven Popov</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bender_E/0/1/0/all/0/1\">Emily M. Bender</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marelli_M/0/1/0/all/0/1\">Marco Marelli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1\">Matthew M. Botvinick</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Akata_Z/0/1/0/all/0/1\">Zeynep Akata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schulz_E/0/1/0/all/0/1\">Eric Schulz</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mismatch Quest: Visual and Textual Feedback for Image-Text Misalignment. (arXiv:2312.03766v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03766","description":"<p>While existing image-text alignment models reach high quality binary\nassessments, they fall short of pinpointing the exact source of misalignment.\nIn this paper, we present a method to provide detailed textual and visual\nexplanation of detected misalignments between text-image pairs. We leverage\nlarge language models and visual grounding models to automatically construct a\ntraining set that holds plausible misaligned captions for a given image and\ncorresponding textual explanations and visual indicators. We also publish a new\nhuman curated test set comprising ground-truth textual and visual misalignment\nannotations. Empirical results show that fine-tuning vision language models on\nour training set enables them to articulate misalignments and visually indicate\nthem within images, outperforming strong baselines both on the binary alignment\nclassification and the explanation generation tasks. Our method code and human\ncurated test set are available at: https://mismatch-quest.github.io/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Gordon_B/0/1/0/all/0/1\">Brian Gordon</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bitton_Y/0/1/0/all/0/1\">Yonatan Bitton</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shafir_Y/0/1/0/all/0/1\">Yonatan Shafir</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Garg_R/0/1/0/all/0/1\">Roopal Garg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xi Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lischinski_D/0/1/0/all/0/1\">Dani Lischinski</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1\">Daniel Cohen-Or</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Szpektor_I/0/1/0/all/0/1\">Idan Szpektor</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"GPT vs Human for Scientific Reviews: A Dual Source Review on Applications of ChatGPT in Science. (arXiv:2312.03769v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03769","description":"<p>The new polymath Large Language Models (LLMs) can speed-up greatly scientific\nreviews, possibly using more unbiased quantitative metrics, facilitating\ncross-disciplinary connections, and identifying emerging trends and research\ngaps by analyzing large volumes of data. However, at the present time, they\nlack the required deep understanding of complex methodologies, they have\ndifficulty in evaluating innovative claims, and they are unable to assess\nethical issues and conflicts of interest. Herein, we consider 13 GPT-related\npapers across different scientific domains, reviewed by a human reviewer and\nSciSpace, a large language model, with the reviews evaluated by three distinct\ntypes of evaluators, namely GPT-3.5, a crowd panel, and GPT-4. We found that\n50% of SciSpace's responses to objective questions align with those of a human\nreviewer, with GPT-4 (informed evaluator) often rating the human reviewer\nhigher in accuracy, and SciSpace higher in structure, clarity, and\ncompleteness. In subjective questions, the uninformed evaluators (GPT-3.5 and\ncrowd panel) showed varying preferences between SciSpace and human responses,\nwith the crowd panel showing a preference for the human responses. However,\nGPT-4 rated them equally in accuracy and structure but favored SciSpace for\ncompleteness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1\">Chenxi Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Varghese_A/0/1/0/all/0/1\">Alan John Varghese</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oommen_V/0/1/0/all/0/1\">Vivek Oommen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1\">George Em Karniadakis</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"SmoothQuant+: Accurate and Efficient 4-bit Post-Training WeightQuantization for LLM. (arXiv:2312.03788v1 [cs.LG])","link":"http://arxiv.org/abs/2312.03788","description":"<p>Large language models (LLMs) have shown remarkable capabilities in various\ntasks. However their huge model size and the consequent demand for\ncomputational and memory resources also pose challenges to model deployment.\nCurrently, 4-bit post-training quantization (PTQ) has achieved some success in\nLLMs, reducing the memory footprint by approximately 75% compared to FP16\nmodels, albeit with some accuracy loss. In this paper, we propose SmoothQuant+,\nan accurate and efficient 4-bit weight-only PTQ that requires no additional\ntraining, which enables lossless in accuracy for LLMs for the first time. Based\non the fact that the loss of weight quantization is amplified by the activation\noutliers, SmoothQuant+ smoothes the activation outliers by channel before\nquantization, while adjusting the corresponding weights for mathematical\nequivalence, and then performs group-wise 4-bit weight quantization for linear\nlayers. We have integrated SmoothQuant+ into the vLLM framework, an advanced\nhigh-throughput inference engine specially developed for LLMs, and equipped it\nwith an efficient W4A16 CUDA kernels, so that vLLM can seamlessly support\nSmoothQuant+ 4-bit weight quantization. Our results show that, with\nSmoothQuant+, the Code Llama-34B model can be quantized and deployed on a A100\n40GB GPU, achieving lossless accuracy and a throughput increase of 1.9 to 4.0\ntimes compared to the FP16 model deployed on two A100 40GB GPUs. Moreover, the\nlatency per token is only 68% of the FP16 model deployed on two A100 40GB GPUs.\nThis is the state-of-the-art 4-bit weight quantization for LLMs as we know.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1\">Jiayi Pan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Chengcan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1\">Kaifu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1\">Yangguang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhenyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_B/0/1/0/all/0/1\">Bin Feng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparative Analysis of Multilingual Text Classification & Identification through Deep Learning and Embedding Visualization. (arXiv:2312.03789v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03789","description":"<p>This research conducts a comparative study on multilingual text\nclassification methods, utilizing deep learning and embedding visualization.\nThe study employs LangDetect, LangId, FastText, and Sentence Transformer on a\ndataset encompassing 17 languages. It explores dimensionality's impact on\nclustering, revealing FastText's clearer clustering in 2D visualization due to\nits extensive multilingual corpus training. Notably, the FastText multi-layer\nperceptron model achieved remarkable accuracy, precision, recall, and F1 score,\noutperforming the Sentence Transformer model. The study underscores the\neffectiveness of these techniques in multilingual text classification,\nemphasizing the importance of large multilingual corpora for training\nembeddings. It lays the groundwork for future research and assists\npractitioners in developing language detection and classification systems.\nAdditionally, it includes the comparison of multi-layer perceptron, LSTM, and\nConvolution models for classification.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wyawhare_A/0/1/0/all/0/1\">Arinjay Wyawhare</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Improving Activation Steering in Language Models with Mean-Centring. (arXiv:2312.03813v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03813","description":"<p>Recent work in activation steering has demonstrated the potential to better\ncontrol the outputs of Large Language Models (LLMs), but it involves finding\nsteering vectors. This is difficult because engineers do not typically know how\nfeatures are represented in these models. We seek to address this issue by\napplying the idea of mean-centring to steering vectors. We find that taking the\naverage of activations associated with a target dataset, and then subtracting\nthe mean of all training activations, results in effective steering vectors. We\ntest this method on a variety of models on natural language tasks by steering\naway from generating toxic text, and steering the completion of a story towards\na target genre. We also apply mean-centring to extract function vectors, more\neffectively triggering the execution of a range of natural language tasks by a\nsignificant margin (compared to previous baselines). This suggests that\nmean-centring can be used to easily improve the effectiveness of activation\nsteering in a wide range of contexts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jorgensen_O/0/1/0/all/0/1\">Ole Jorgensen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cope_D/0/1/0/all/0/1\">Dylan Cope</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schoots_N/0/1/0/all/0/1\">Nandi Schoots</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1\">Murray Shanahan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLM as OS (llmao), Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent Ecosystem. (arXiv:2312.03815v1 [cs.OS])","link":"http://arxiv.org/abs/2312.03815","description":"<p>This paper envisions a revolutionary AIOS-Agent ecosystem, where Large\nLanguage Model (LLM) serves as the (Artificial) Intelligent Operating System\n(IOS, or AIOS)--an operating system ``with soul''. Upon this foundation, a\ndiverse range of LLM-based AI Agent Applications (Agents, or AAPs) are\ndeveloped, enriching the AIOS-Agent ecosystem and signaling a paradigm shift\nfrom the traditional OS-APP ecosystem. We envision that LLM's impact will not\nbe limited to the AI application level, instead, it will in turn revolutionize\nthe design and implementation of computer system, architecture, software, and\nprogramming language, featured by several main concepts: LLM as OS\n(system-level), Agents as Applications (application-level), Natural Language as\nProgramming Interface (user-level), and Tools as Devices/Libraries\n(hardware/middleware-level).\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1\">Yingqiang Ge</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1\">Yujie Ren</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1\">Wenyue Hua</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1\">Shuyuan Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1\">Juntao Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yongfeng Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Alpha-CLIP: A CLIP Model Focusing on Wherever You Want. (arXiv:2312.03818v1 [cs.CV])","link":"http://arxiv.org/abs/2312.03818","description":"<p>Contrastive Language-Image Pre-training (CLIP) plays an essential role in\nextracting valuable content information from images across diverse tasks. It\naligns textual and visual modalities to comprehend the entire image, including\nall the details, even those irrelevant to specific tasks. However, for a finer\nunderstanding and controlled editing of images, it becomes crucial to focus on\nspecific regions of interest, which can be indicated as points, masks, or boxes\nby humans or perception models. To fulfill the requirements, we introduce\nAlpha-CLIP, an enhanced version of CLIP with an auxiliary alpha channel to\nsuggest attentive regions and fine-tuned with constructed millions of RGBA\nregion-text pairs. Alpha-CLIP not only preserves the visual recognition ability\nof CLIP but also enables precise control over the emphasis of image contents.\nIt demonstrates effectiveness in various tasks, including but not limited to\nopen-world recognition, multimodal large language models, and conditional 2D /\n3D generation. It has a strong potential to serve as a versatile tool for\nimage-related tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1\">Zeyi Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1\">Ye Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1\">Tong Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1\">Pan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zang_Y/0/1/0/all/0/1\">Yuhang Zang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1\">Shu Kong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1\">Yuanjun Xiong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1\">Dahua Lin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jiaqi Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient Large Language Models: A Survey. (arXiv:2312.03863v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03863","description":"<p>Large Language Models (LLMs) have demonstrated remarkable capabilities in\nimportant tasks such as natural language understanding, language generation,\nand complex reasoning and have the potential to make a substantial impact on\nour society. Such capabilities, however, come with the considerable resources\nthey demand, highlighting the strong need to develop effective techniques for\naddressing their efficiency challenges. In this survey, we provide a systematic\nand comprehensive review of efficient LLMs research. We organize the literature\nin a taxonomy consisting of three main categories, covering distinct yet\ninterconnected efficient LLMs topics from model-centric, data-centric, and\nframework-centric perspective, respectively. We have also created a GitHub\nrepository where we compile the papers featured in this survey at\nhttps://github.com/AIoT-MLSys-Lab/EfficientLLMs,\nhttps://github.com/AIoT-MLSys-Lab/Efficient-LLMs-Survey, and will actively\nmaintain this repository and incorporate new research as it emerges. We hope\nour survey can serve as a valuable resource to help researchers and\npractitioners gain a systematic understanding of the research developments in\nefficient LLMs and inspire them to contribute to this important and exciting\nfield.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wan_Z/0/1/0/all/0/1\">Zhongwei Wan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xin Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1\">Che Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alam_S/0/1/0/all/0/1\">Samiul Alam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1\">Yu Zheng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qu_Z/0/1/0/all/0/1\">Zhongnan Qu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1\">Shen Yan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1\">Yi Zhu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1\">Quanlu Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1\">Mosharaf Chowdhury</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1\">Mi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"The BigCode Project Governance Card. (arXiv:2312.03872v1 [cs.CY])","link":"http://arxiv.org/abs/2312.03872","description":"<p>This document serves as an overview of the different mechanisms and areas of\ngovernance in the BigCode project. It aims to support transparency by providing\nrelevant information about choices that were made during the project to the\nbroader public, and to serve as an example of intentional governance of an open\nresearch project that future endeavors can leverage to shape their own\napproach. The first section, Project Structure, covers the project\norganization, its stated goals and values, its internal decision processes, and\nits funding and resources. The second section, Data and Model Governance,\ncovers decisions relating to the questions of data subject consent, privacy,\nand model release.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+collaboration_BigCode/0/1/0/all/0/1\">BigCode collaboration</a>: <a href=\"http://arxiv.org/find/cs/1/au:+Hughes_S/0/1/0/all/0/1\">Sean Hughes</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Vries_H/0/1/0/all/0/1\">Harm de Vries</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1\">Jennifer Robinson</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ferrandis_C/0/1/0/all/0/1\">Carlos Mu&#xf1;oz Ferrandis</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Allal_L/0/1/0/all/0/1\">Loubna Ben Allal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Werra_L/0/1/0/all/0/1\">Leandro von Werra</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1\">Jennifer Ding</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Paquet_S/0/1/0/all/0/1\">Sebastien Paquet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jernite_Y/0/1/0/all/0/1\">Yacine Jernite</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Revisiting the Optimality of Word Lengths. (arXiv:2312.03897v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03897","description":"<p>Zipf (1935) posited that wordforms are optimized to minimize utterances'\ncommunicative costs. Under the assumption that cost is given by an utterance's\nlength, he supported this claim by showing that words' lengths are inversely\ncorrelated with their frequencies. Communicative cost, however, can be\noperationalized in different ways. Piantadosi et al. (2011) claim that cost\nshould be measured as the distance between an utterance's information rate and\nchannel capacity, which we dub the channel capacity hypothesis (CCH) here.\nFollowing this logic, they then proposed that a word's length should be\nproportional to the expected value of its surprisal (negative log-probability\nin context). In this work, we show that Piantadosi et al.'s derivation does not\nminimize CCH's cost, but rather a lower bound, which we term CCH-lower. We\npropose a novel derivation, suggesting an improved way to minimize CCH's cost.\nUnder this method, we find that a language's word lengths should instead be\nproportional to the surprisal's expectation plus its variance-to-mean ratio.\nExperimentally, we compare these three communicative cost functions: Zipf's,\nCCH-lower , and CCH. Across 13 languages and several experimental settings, we\nfind that length is better predicted by frequency than either of the other\nhypotheses. In fact, when surprisal's expectation, or expectation plus\nvariance-to-mean ratio, is estimated using better language models, it leads to\nworse word length predictions. We take these results as evidence that Zipf's\nlongstanding hypothesis holds.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1\">Tiago Pimentel</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1\">Clara Meister</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilcox_E/0/1/0/all/0/1\">Ethan Gotlieb Wilcox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mahowald_K/0/1/0/all/0/1\">Kyle Mahowald</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1\">Ryan Cotterell</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints. (arXiv:2312.03905v1 [cs.LG])","link":"http://arxiv.org/abs/2312.03905","description":"<p>Neuro-symbolic AI bridges the gap between purely symbolic and neural\napproaches to learning. This often requires maximizing the likelihood of a\nsymbolic constraint w.r.t the neural network's output distribution. Such output\ndistributions are typically assumed to be fully-factorized. This limits the\napplicability of neuro-symbolic learning to the more expressive autoregressive\ndistributions, e.g., transformers. Under such distributions, computing the\nlikelihood of even simple constraints is #P-hard. Instead of attempting to\nenforce the constraint on the entire output distribution, we propose to do so\non a random, local approximation thereof. More precisely, we optimize the\nlikelihood of the constraint under a pseudolikelihood-based approximation\ncentered around a model sample. Our approximation is factorized, allowing the\nreuse of solutions to sub-problems, a main tenet for efficiently computing\nneuro-symbolic losses. Moreover, it is a local, high-fidelity approximation of\nthe likelihood, exhibiting low entropy and KL-divergence around the model\nsample. We evaluate our approach on Sudoku and shortest-path prediction cast as\nautoregressive generation, and observe that we greatly improve upon the base\nmodel's ability to predict logically-consistent outputs. We also evaluate on\nthe task of detoxifying large language models. Using a simple constraint\ndisallowing a list of toxic words, we are able to steer the model's outputs\naway from toxic generations, achieving SoTA detoxification compared to previous\napproaches.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ahmed_K/0/1/0/all/0/1\">Kareem Ahmed</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1\">Kai-Wei Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1\">Guy Van den Broeck</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Collaboration or Corporate Capture? Quantifying NLP's Reliance on Industry Artifacts and Contributions. (arXiv:2312.03912v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03912","description":"<p>The advent of transformers, higher computational budgets, and big data has\nengendered remarkable progress in Natural Language Processing (NLP). Impressive\nperformance of industry pre-trained models has garnered public attention in\nrecent years and made news headlines. That these are industry models is\nnoteworthy. Rarely, if ever, are academic institutes producing exciting new NLP\nmodels. Using these models is critical for competing on NLP benchmarks and\ncorrespondingly to stay relevant in NLP research. We surveyed 100 papers\npublished at EMNLP 2022 to determine whether this phenomenon constitutes a\nreliance on industry for NLP publications.\n</p>\n<p>We find that there is indeed a substantial reliance. Citations of industry\nartifacts and contributions across categories is at least three times greater\nthan industry publication rates per year. Quantifying this reliance does not\nsettle how we ought to interpret the results. We discuss two possible\nperspectives in our discussion: 1) Is collaboration with industry still\ncollaboration in the absence of an alternative? Or 2) has free NLP inquiry been\ncaptured by the motivations and research direction of private corporations?\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Aitken_W/0/1/0/all/0/1\">Will Aitken</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdalla_M/0/1/0/all/0/1\">Mohamed Abdalla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rudie_K/0/1/0/all/0/1\">Karen Rudie</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stinson_C/0/1/0/all/0/1\">Catherine Stinson</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Cost-Effective In-Context Learning for Entity Resolution: A Design Space Exploration. (arXiv:2312.03987v1 [cs.CL])","link":"http://arxiv.org/abs/2312.03987","description":"<p>Entity resolution (ER) is an important data integration task with a wide\nspectrum of applications. The state-of-the-art solutions on ER rely on\npre-trained language models (PLMs), which require fine-tuning on a lot of\nlabeled matching/non-matching entity pairs. Recently, large languages models\n(LLMs), such as GPT-4, have shown the ability to perform many tasks without\ntuning model parameters, which is known as in-context learning (ICL) that\nfacilitates effective learning from a few labeled input context demonstrations.\nHowever, existing ICL approaches to ER typically necessitate providing a task\ndescription and a set of demonstrations for each entity pair and thus have\nlimitations on the monetary cost of interfacing LLMs. To address the problem,\nin this paper, we provide a comprehensive study to investigate how to develop a\ncost-effective batch prompting approach to ER. We introduce a framework BATCHER\nconsisting of demonstration selection and question batching and explore\ndifferent design choices that support batch prompting for ER. We also devise a\ncovering-based demonstration selection strategy that achieves an effective\nbalance between matching accuracy and monetary cost. We conduct a thorough\nevaluation to explore the design space and evaluate our proposed strategies.\nThrough extensive experiments, we find that batch prompting is very\ncost-effective for ER, compared with not only PLM-based methods fine-tuned with\nextensive labeled data but also LLM-based methods with manually designed\nprompting. We also provide guidance for selecting appropriate design choices\nfor batch prompting.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1\">Meihao Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1\">Xiaoyue Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1\">Ju Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chai_C/0/1/0/all/0/1\">Chengliang Chai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tang_N/0/1/0/all/0/1\">Nan Tang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1\">Guoliang Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1\">Xiaoyong Du</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Study on the Calibration of In-context Learning. (arXiv:2312.04021v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04021","description":"<p>Modern auto-regressive language models are trained to minimize log loss on\nbroad data by predicting the next token so they are expected to get calibrated\nanswers when framing a problem as a next-token prediction task. We study this\nfor in-context learning (ICL), a widely used way to adapt frozen large language\nmodels (LLMs) via crafting prompts, and investigate the trade-offs between\nperformance and calibration on a wide range of natural language understanding\nand reasoning tasks. We conduct extensive experiments to show that such\ntrade-offs may get worse as we increase model size, incorporate more ICL\nexamples, and fine-tune models using instruction, dialog, or reinforcement\nlearning from human feedback (RLHF) on carefully curated datasets. Furthermore,\nwe find that common recalibration techniques that are widely effective such as\ntemperature scaling provide limited gains in calibration errors, suggesting\nthat new methods may be required for settings where models are expected to be\nreliable.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1\">Hanlin Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yi-Fan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1\">Yaodong Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Madeka_D/0/1/0/all/0/1\">Dhruv Madeka</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1\">Dean Foster</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Hima Lakkaraju</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1\">Sham Kakade</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"RoAST: Robustifying Language Models via Adversarial Perturbation with Selective Training. (arXiv:2312.04032v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04032","description":"<p>Fine-tuning pre-trained language models (LMs) has become the de facto\nstandard in many NLP tasks. Nevertheless, fine-tuned LMs are still prone to\nrobustness issues, such as adversarial robustness and model calibration.\nSeveral perspectives of robustness for LMs have been studied independently, but\nlacking a unified consideration in multiple perspectives. In this paper, we\npropose Robustifying LMs via Adversarial perturbation with Selective Training\n(RoAST), a simple yet effective fine-tuning technique to enhance the\nmulti-perspective robustness of LMs in a unified way. RoAST effectively\nincorporates two important sources for the model robustness, robustness on the\nperturbed inputs and generalizable knowledge in pre-trained LMs. To be\nspecific, RoAST introduces adversarial perturbation during fine-tuning while\nthe model parameters are selectively updated upon their relative importance to\nminimize unnecessary deviation. Under a unified evaluation of fine-tuned LMs by\nincorporating four representative perspectives of model robustness, we\ndemonstrate the effectiveness of RoAST compared to state-of-the-art fine-tuning\nmethods on six different types of LMs, which indicates its usefulness in\npractice.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1\">Jaehyung Kim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1\">Yuning Mao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hou_R/0/1/0/all/0/1\">Rui Hou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1\">Hanchao Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1\">Davis Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1\">Pascale Fung</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1\">Qifan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1\">Fuli Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lifu Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khabsa_M/0/1/0/all/0/1\">Madian Khabsa</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Multimodal Misinformation Detection in a South African Social Media Environment. (arXiv:2312.04052v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04052","description":"<p>With the constant spread of misinformation on social media networks, a need\nhas arisen to continuously assess the veracity of digital content. This need\nhas inspired numerous research efforts on the development of misinformation\ndetection (MD) models. However, many models do not use all information\navailable to them and existing research contains a lack of relevant datasets to\ntrain the models, specifically within the South African social media\nenvironment. The aim of this paper is to investigate the transferability of\nknowledge of a MD model between different contextual environments. This\nresearch contributes a multimodal MD model capable of functioning in the South\nAfrican social media environment, as well as introduces a South African\nmisinformation dataset. The model makes use of multiple sources of information\nfor misinformation detection, namely: textual and visual elements. It uses\nbidirectional encoder representations from transformers (BERT) as the textual\nencoder and a residual network (ResNet) as the visual encoder. The model is\ntrained and evaluated on the Fakeddit dataset and a South African\nmisinformation dataset. Results show that using South African samples in the\ntraining of the model increases model performance, in a South African\ncontextual environment, and that a multimodal model retains significantly more\nknowledge than both the textual and visual unimodal models. Our study suggests\nthat the performance of a misinformation detection model is influenced by the\ncultural nuances of its operating environment and multimodal models assist in\nthe transferability of knowledge between different contextual environments.\nTherefore, local data should be incorporated into the training process of a\nmisinformation detection model in order to optimize model performance.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jager_A/0/1/0/all/0/1\">Amica De Jager</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Marivate_V/0/1/0/all/0/1\">Vukosi Marivate</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Modupe_A/0/1/0/all/0/1\">Abioudun Modupe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Comparing Large Language Model AI and Human-Generated Coaching Messages for Behavioral Weight Loss. (arXiv:2312.04059v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04059","description":"<p>Automated coaching messages for weight control can save time and costs, but\ntheir repetitive, generic nature may limit their effectiveness compared to\nhuman coaching. Large language model (LLM) based artificial intelligence (AI)\nchatbots, like ChatGPT, could offer more personalized and novel messages to\naddress repetition with their data-processing abilities. While LLM AI\ndemonstrates promise to encourage healthier lifestyles, studies have yet to\nexamine the feasibility and acceptability of LLM-based BWL coaching. 87 adults\nin a weight-loss trial rated ten coaching messages' helpfulness (five\nhuman-written, five ChatGPT-generated) using a 5-point Likert scale, providing\nadditional open-ended feedback to justify their ratings. Participants also\nidentified which messages they believed were AI-generated. The evaluation\noccurred in two phases: messages in Phase 1 were perceived as impersonal and\nnegative, prompting revisions for Phase 2 messages. In Phase 1, AI-generated\nmessages were rated less helpful than human-written ones, with 66 percent\nreceiving a helpfulness rating of 3 or higher. However, in Phase 2, the AI\nmessages matched the human-written ones regarding helpfulness, with 82% scoring\nthree or above. Additionally, 50% were misidentified as human-written,\nsuggesting AI's sophistication in mimicking human-generated content. A thematic\nanalysis of open-ended feedback revealed that participants appreciated AI's\nempathy and personalized suggestions but found them more formulaic, less\nauthentic, and too data-focused. This study reveals the preliminary feasibility\nand acceptability of LLM AIs, like ChatGPT, in crafting potentially effective\nweight control coaching messages. Our findings also underscore areas for future\nenhancement.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Zhuoran Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berry_M/0/1/0/all/0/1\">Michael P. Berry</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chwyl_C/0/1/0/all/0/1\">Christina Chwyl</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hsieh_G/0/1/0/all/0/1\">Gary Hsieh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1\">Jing Wei</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Forman_E/0/1/0/all/0/1\">Evan M. Forman</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Making Translators Privacy-aware on the User's Side. (arXiv:2312.04068v1 [cs.CR])","link":"http://arxiv.org/abs/2312.04068","description":"<p>We propose PRISM to enable users of machine translation systems to preserve\nthe privacy of data on their own initiative. There is a growing demand to apply\nmachine translation systems to data that require privacy protection. While\nseveral machine translation engines claim to prioritize privacy, the extent and\nspecifics of such protection are largely ambiguous. First, there is often a\nlack of clarity on how and to what degree the data is protected. Even if\nservice providers believe they have sufficient safeguards in place,\nsophisticated adversaries might still extract sensitive information. Second,\nvulnerabilities may exist outside of these protective measures, such as within\ncommunication channels, potentially leading to data leakage. As a result, users\nare hesitant to utilize machine translation engines for data demanding high\nlevels of privacy protection, thereby missing out on their benefits. PRISM\nresolves this problem. Instead of relying on the translation service to keep\ndata safe, PRISM provides the means to protect data on the user's side. This\napproach ensures that even machine translation engines with inadequate privacy\nmeasures can be used securely. For platforms already equipped with privacy\nsafeguards, PRISM acts as an additional protection layer, reinforcing their\nsecurity furthermore. PRISM adds these privacy features without significantly\ncompromising translation accuracy. Our experiments demonstrate the\neffectiveness of PRISM using real-world translators, T5 and ChatGPT\n(GPT-3.5-turbo), and the datasets with two languages. PRISM effectively\nbalances privacy protection with translation accuracy.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Sato_R/0/1/0/all/0/1\">Ryoma Sato</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing the Rationale-Input Alignment for Self-explaining Rationalization. (arXiv:2312.04103v1 [cs.AI])","link":"http://arxiv.org/abs/2312.04103","description":"<p>Rationalization empowers deep learning models with self-explaining\ncapabilities through a cooperative game, where a generator selects a\nsemantically consistent subset of the input as a rationale, and a subsequent\npredictor makes predictions based on the selected rationale. In this paper, we\ndiscover that rationalization is prone to a problem named \\emph{rationale\nshift}, which arises from the algorithmic bias of the cooperative game.\nRationale shift refers to a situation where the semantics of the selected\nrationale may deviate from the original input, but the predictor still produces\naccurate predictions based on the deviation, resulting in a compromised\ngenerator with misleading feedback.\n</p>\n<p>To address this issue, we first demonstrate the importance of the alignment\nbetween the rationale and the full input through both empirical observations\nand theoretical analysis. Subsequently, we introduce a novel approach called\nDAR (\\textbf{D}iscriminatively \\textbf{A}ligned \\textbf{R}ationalization),\nwhich utilizes an auxiliary module pretrained on the full input to\ndiscriminatively align the selected rationale and the original input. We\ntheoretically illustrate how DAR accomplishes the desired alignment, thereby\novercoming the rationale shift problem. The experiments on two widely used\nreal-world benchmarks show that the proposed method significantly improves the\nexplanation quality (measured by the overlap between the model-selected\nexplanation and the human-annotated rationale) as compared to state-of-the-art\ntechniques. Additionally, results on two synthetic settings further validate\nthe effectiveness of DAR in addressing the rationale shift problem.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1\">Wei Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haozhao Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1\">Jun Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhiying Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">YuanKai Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1\">Cheng Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1\">Ruixuan Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Analyzing the Inherent Response Tendency of LLMs: Real-World Instructions-Driven Jailbreak. (arXiv:2312.04127v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04127","description":"<p>Extensive work has been devoted to improving the safety mechanism of Large\nLanguage Models (LLMs). However, in specific scenarios, LLMs still generate\nharmful responses when faced with malicious instructions, a phenomenon referred\nto as \"Jailbreak Attack\". In our research, we introduce a novel jailbreak\nattack method (\\textbf{RADIAL}), which consists of two steps: 1) Inherent\nResponse Tendency Analysis: we analyze the inherent affirmation and rejection\ntendency of LLMs to react to real-world instructions. 2) Real-World\nInstructions-Driven Jailbreak: based on our analysis, we strategically choose\nseveral real-world instructions and embed malicious instructions into them to\namplify the LLM's potential to generate harmful responses. On three open-source\nhuman-aligned LLMs, our method achieves excellent jailbreak attack performance\nfor both Chinese and English malicious instructions. Besides, we guided\ndetailed ablation experiments and verified the effectiveness of our core idea\n\"Inherent Response Tendency Analysis\". Our exploration also exposes the\nvulnerability of LLMs to being induced into generating more detailed harmful\nresponses in subsequent rounds of dialogue.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1\">Yanrui Du</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1\">Sendong Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1\">Ming Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuhan Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Using a Large Language Model to generate a Design Structure Matrix. (arXiv:2312.04134v1 [cs.AI])","link":"http://arxiv.org/abs/2312.04134","description":"<p>The Design Structure Matrix (DSM) is an established method used in dependency\nmodelling, especially in the design of complex engineering systems. The\ngeneration of DSM is traditionally carried out through manual means and can\ninvolve interviewing experts to elicit critical system elements and the\nrelationships between them. Such manual approaches can be time-consuming and\ncostly. This paper presents a workflow that uses a Large Language Model (LLM)\nto support the generation of DSM and improve productivity. A prototype of the\nworkflow was developed in this work and applied on a diesel engine DSM\npublished previously. It was found that the prototype could reproduce 357 out\nof 462 DSM entries published (i.e. 77.3%), suggesting that the work can aid DSM\ngeneration. A no-code version of the prototype is made available online to\nsupport future research.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Koh_E/0/1/0/all/0/1\">Edwin C. Y. Koh</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Language Model Knowledge Distillation for Efficient Question Answering in Spanish. (arXiv:2312.04193v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04193","description":"<p>Recent advances in the development of pre-trained Spanish language models has\nled to significant progress in many Natural Language Processing (NLP) tasks,\nsuch as question answering. However, the lack of efficient models imposes a\nbarrier for the adoption of such models in resource-constrained environments.\nTherefore, smaller distilled models for the Spanish language could be proven to\nbe highly scalable and facilitate their further adoption on a variety of tasks\nand scenarios. In this work, we take one step in this direction by developing\nSpanishTinyRoBERTa, a compressed language model based on RoBERTa for efficient\nquestion answering in Spanish. To achieve this, we employ knowledge\ndistillation from a large model onto a lighter model that allows for a wider\nimplementation, even in areas with limited computational resources, whilst\nattaining negligible performance sacrifice. Our experiments show that the dense\ndistilled model can still preserve the performance of its larger counterpart,\nwhile significantly increasing inference speedup. This work serves as a\nstarting point for further research and investigation of model compression\nefforts for Spanish language models across various NLP tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Bazaga_A/0/1/0/all/0/1\">Adri&#xe1;n Bazaga</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1\">Pietro Li&#xf2;</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Micklem_G/0/1/0/all/0/1\">Gos Micklem</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Swap distance minimization in SOV languages. Cognitive and mathematical foundations. (arXiv:2312.04219v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04219","description":"<p>Distance minimization is a general principle of language. A special case of\nthis principle in the domain of word order is swap distance minimization. This\nprinciple predicts that variations from a canonical order that are reached by\nfewer swaps of adjacent constituents are lest costly and thus more likely. Here\nwe investigate the principle in the context of the triple formed by subject\n(S), object (O) and verb (V). We introduce the concept of word order rotation\nas a cognitive underpinning of that prediction. When the canonical order of a\nlanguage is SOV, the principle predicts SOV &lt; SVO, OSV &lt; VSO, OVS &lt; VOS, in\norder of increasing cognitive cost. We test the prediction in three flexible\norder SOV languages: Korean (Koreanic), Malayalam (Dravidian), and Sinhalese\n(Indo-European). Evidence of swap distance minimization is found in all three\nlanguages, but it is weaker in Sinhalese. Swap distance minimization is\nstronger than a preference for the canonical order in Korean and especially\nMalayalam.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1\">Ramon Ferrer-i-Cancho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Namboodiripad_S/0/1/0/all/0/1\">Savithry Namboodiripad</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PsyChat: A Client-Centric Dialogue System for Mental Health Support. (arXiv:2312.04262v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04262","description":"<p>Dialogue systems are increasingly integrated into mental health support to\nhelp clients facilitate exploration, gain insight, take action, and ultimately\nheal themselves. For a dialogue system to be practical and user-friendly, it\nshould be client-centric, focusing on the client's behaviors. However, existing\ndialogue systems publicly available for mental health support often concentrate\nsolely on the counselor's strategies rather than the behaviors expressed by\nclients. This can lead to the implementation of unreasonable or inappropriate\ncounseling strategies and corresponding responses from the dialogue system. To\naddress this issue, we propose PsyChat, a client-centric dialogue system that\nprovides psychological support through online chat. The client-centric dialogue\nsystem comprises five modules: client behavior recognition, counselor strategy\nselection, input packer, response generator intentionally fine-tuned to produce\nresponses, and response selection. Both automatic and human evaluations\ndemonstrate the effectiveness and practicality of our proposed dialogue system\nfor real-life mental health support. Furthermore, we employ our proposed\ndialogue system to simulate a real-world client-virtual-counselor interaction\nscenario. The system is capable of predicting the client's behaviors, selecting\nappropriate counselor strategies, and generating accurate and suitable\nresponses, as demonstrated in the scenario.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1\">Huachuan Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1\">Anqi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1\">Lizhi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1\">Zhenzhong Lan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Prompt Highlighter: Interactive Control for Multi-Modal LLMs. (arXiv:2312.04302v1 [cs.CV])","link":"http://arxiv.org/abs/2312.04302","description":"<p>This study targets a critical aspect of multi-modal LLMs' (LLMs&amp;VLMs)\ninference: explicit controllable text generation. Multi-modal LLMs empower\nmulti-modality understanding with the capability of semantic generation yet\nbring less explainability and heavier reliance on prompt contents due to their\nautoregressive generative nature. While manipulating prompt formats could\nimprove outputs, designing specific and precise prompts per task can be\nchallenging and ineffective. To tackle this issue, we introduce a novel\ninference method, Prompt Highlighter, which enables users to highlight specific\nprompt spans to interactively control the focus during generation. Motivated by\nthe classifier-free diffusion guidance, we form regular and unconditional\ncontext pairs based on highlighted tokens, demonstrating that the\nautoregressive generation in models can be guided in a classifier-free way.\nNotably, we find that, during inference, guiding the models with highlighted\ntokens through the attention weights leads to more desired outputs. Our\napproach is compatible with current LLMs and VLMs, achieving impressive\ncustomized generation results without training. Experiments confirm its\neffectiveness in focusing on input contexts and generating reliable content.\nWithout tuning on LLaVA-v1.5, our method secured 69.5 in the MMBench test and\n1552.5 in MME-perception. The code is available at:\nhttps://github.com/dvlab-research/Prompt-Highlighter/\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1\">Yuechen Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qian_S/0/1/0/all/0/1\">Shengju Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1\">Bohao Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1\">Shu Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1\">Jiaya Jia</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"nerblackbox: A High-level Library for Named Entity Recognition in Python. (arXiv:2312.04306v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04306","description":"<p>We present nerblackbox, a python library to facilitate the use of\nstate-of-the-art transformer-based models for named entity recognition. It\nprovides simple-to-use yet powerful methods to access data and models from a\nwide range of sources, for fully automated model training and evaluation as\nwell as versatile model inference. While many technical challenges are solved\nand hidden from the user by default, nerblackbox also offers fine-grained\ncontrol and a rich set of customizable features. It is thus targeted both at\napplication-oriented developers as well as machine learning experts and\nresearchers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Stollenwerk_F/0/1/0/all/0/1\">Felix Stollenwerk</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Beyond Surface: Probing LLaMA Across Scales and Layers. (arXiv:2312.04333v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04333","description":"<p>This paper presents an in-depth analysis of Large Language Models (LLMs),\nfocusing on LLaMA, a prominent open-source foundational model in natural\nlanguage processing. Instead of assessing LLaMA through its generative output,\nwe design multiple-choice tasks to probe its intrinsic understanding in\nhigh-order tasks such as reasoning and computation. We examine the model\nhorizontally, comparing different sizes, and vertically, assessing different\nlayers. We unveil several key and uncommon findings based on the designed\nprobing tasks: (1) Horizontally, enlarging model sizes almost could not\nautomatically impart additional knowledge or computational prowess. Instead, it\ncan enhance reasoning abilities, especially in math problem solving, and helps\nreduce hallucinations, but only beyond certain size thresholds; (2) In vertical\nanalysis, the lower layers of LLaMA lack substantial arithmetic and factual\nknowledge, showcasing logical thinking, multilingual and recognitive abilities,\nwith top layers housing most computational power and real-world knowledge.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1\">Nuo Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1\">Ning Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1\">Shining Liang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1\">Ming Gong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1\">Linjun Shou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1\">Dongmei Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Jia Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Merging by Matching Models in Task Subspaces. (arXiv:2312.04339v1 [cs.LG])","link":"http://arxiv.org/abs/2312.04339","description":"<p>Model merging aims to cheaply combine individual task-specific models into a\nsingle multitask model. In this work, we view past merging methods as\nleveraging different notions of a ''task subspace'' in which models are matched\nbefore being merged. We connect the task subspace of a given model to its loss\nlandscape and formalize how this approach to model merging can be seen as\nsolving a linear system of equations. While past work has generally been\nlimited to linear systems that have a closed-form solution, we consider using\nthe conjugate gradient method to find a solution. We show that using the\nconjugate gradient method can outperform closed-form solutions, enables merging\nvia linear systems that are otherwise intractable to solve, and flexibly allows\nchoosing from a wide variety of initializations and estimates for the ''task\nsubspace''. We ultimately demonstrate that our merging framework called\n''Matching Models in their Task Subspace'' (MaTS) achieves state-of-the-art\nresults in multitask and intermediate-task model merging. We release all of the\ncode and checkpoints used in our work at https://github.com/r-three/mats.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tam_D/0/1/0/all/0/1\">Derek Tam</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1\">Mohit Bansal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1\">Colin Raffel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on Prompt Engineering Strategies. (arXiv:2312.04344v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04344","description":"<p>OpenAI's latest large vision-language model (LVLM), GPT-4V(ision), has piqued\nconsiderable interest for its potential in medical applications. Despite its\npromise, recent studies and internal reviews highlight its underperformance in\nspecialized medical tasks. This paper explores the boundary of GPT-4V's\ncapabilities in medicine, particularly in processing complex imaging data from\nendoscopies, CT scans, and MRIs etc. Leveraging open-source datasets, we\nassessed its foundational competencies, identifying substantial areas for\nenhancement. Our research emphasizes prompt engineering, an often-underutilized\nstrategy for improving AI responsiveness. Through iterative testing, we refined\nthe model's prompts, significantly improving its interpretative accuracy and\nrelevance in medical imaging. From our comprehensive evaluations, we distilled\n10 effective prompt engineering techniques, each fortifying GPT-4V's medical\nacumen. These methodical enhancements facilitate more reliable, precise, and\nclinically valuable insights from GPT-4V, advancing its operability in critical\nhealthcare environments. Our findings are pivotal for those employing AI in\nmedicine, providing clear, actionable guidance on harnessing GPT-4V's full\ndiagnostic potential.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1\">Pengcheng Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1\">Ziyan Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1\">Zhongying Deng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Tianbin Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1\">Yanzhou Su</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haoyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1\">Jin Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1\">Yu Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1\">Junjun He</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"When Input Integers are Given in the Unary Numeral Representation. (arXiv:2312.04348v1 [cs.CC])","link":"http://arxiv.org/abs/2312.04348","description":"<p>Many NP-complete problems take integers as part of their input instances.\nThese input integers are generally binarized, that is, provided in the form of\nthe \"binary\" numeral representation, and the lengths of such binary forms are\nused as a basis unit to measure the computational complexity of the problems.\nIn sharp contrast, the \"unarization\" (or the \"unary\" numeral representation) of\nnumbers has been known to bring a remarkably different effect onto the\ncomputational complexity of the problems. When no computational-complexity\ndifference is observed between binarization and unarization of instances, on\nthe contrary, the problems are said to be strong NP-complete. This work\nattempts to spotlight an issue of how the unarization of instances affects the\ncomputational complexity of various combinatorial problems. We present numerous\nNP-complete (or even NP-hard) problems, which turn out to be easily solvable\nwhen input integers are represented in unary. We then discuss the computational\ncomplexities of such problems when taking unary-form integer inputs. We hope\nthat a list of such problems signifies the structural differences between\nstrong NP-completeness and non-strong NP-completeness.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yamakami_T/0/1/0/all/0/1\">Tomoyuki Yamakami</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04350","description":"<p>The ability to perform causal reasoning is widely considered a core feature\nof intelligence. In this work, we investigate whether large language models\n(LLMs) can coherently reason about causality. Much of the existing work in\nnatural language processing (NLP) focuses on evaluating commonsense causal\nreasoning in LLMs, thus failing to assess whether a model can perform causal\ninference in accordance with a set of well-defined formal rules. To address\nthis, we propose a new NLP task, causal inference in natural language, inspired\nby the \"causal inference engine\" postulated by Judea Pearl et al. We compose a\nlarge dataset, CLadder, with 10K samples: based on a collection of causal\ngraphs and queries (associational, interventional, and counterfactual), we\nobtain symbolic questions and ground-truth answers, through an oracle causal\ninference engine. These are then translated into natural language. We evaluate\nmultiple LLMs on our dataset, and we introduce and evaluate a bespoke\nchain-of-thought prompting strategy, CausalCoT. We show that our task is highly\nchallenging for LLMs, and we conduct an in-depth analysis to gain deeper\ninsight into the causal reasoning abilities of LLMs. Our data is open-sourced\nat https://huggingface.co/datasets/causalNLP/cladder, and our code can be found\nat https://github.com/causalNLP/cladder.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1\">Zhijing Jin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1\">Yuen Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leeb_F/0/1/0/all/0/1\">Felix Leeb</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gresele_L/0/1/0/all/0/1\">Luigi Gresele</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kamal_O/0/1/0/all/0/1\">Ojasv Kamal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lyu_Z/0/1/0/all/0/1\">Zhiheng Lyu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Blin_K/0/1/0/all/0/1\">Kevin Blin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adauto_F/0/1/0/all/0/1\">Fernando Gonzalez Adauto</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kleiman_Weiner_M/0/1/0/all/0/1\">Max Kleiman-Weiner</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1\">Mrinmaya Sachan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1\">Bernhard Sch&#xf6;lkopf</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PCoQA: Persian Conversational Question Answering Dataset. (arXiv:2312.04362v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04362","description":"<p>Humans seek information regarding a specific topic through performing a\nconversation containing a series of questions and answers. In the pursuit of\nconversational question answering research, we introduce the PCoQA, the first\n\\textbf{P}ersian \\textbf{Co}nversational \\textbf{Q}uestion \\textbf{A}nswering\ndataset, a resource comprising information-seeking dialogs encompassing a total\nof 9,026 contextually-driven questions. Each dialog involves a questioner, a\nresponder, and a document from the Wikipedia; The questioner asks several\ninter-connected questions from the text and the responder provides a span of\nthe document as the answer for each question. PCoQA is designed to present\nnovel challenges compared to previous question answering datasets including\nhaving more open-ended non-factual answers, longer answers, and fewer lexical\noverlaps. This paper not only presents the comprehensive PCoQA dataset but also\nreports the performance of various benchmark models. Our models include\nbaseline models and pre-trained models, which are leveraged to boost the\nperformance of the model. The dataset and benchmarks are available at our\nGithub page.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hemati_H/0/1/0/all/0/1\">Hamed Hematian Hemati</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toghyani_A/0/1/0/all/0/1\">Atousa Toghyani</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Souri_A/0/1/0/all/0/1\">Atena Souri</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Alavian_S/0/1/0/all/0/1\">Sayed Hesam Alavian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sameti_H/0/1/0/all/0/1\">Hossein Sameti</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Beigy_H/0/1/0/all/0/1\">Hamid Beigy</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LaMPilot: An Open Benchmark Dataset for Autonomous Driving with Language Model Programs. (arXiv:2312.04372v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04372","description":"<p>We present LaMPilot, a novel framework for planning in the field of\nautonomous driving, rethinking the task as a code-generation process that\nleverages established behavioral primitives. This approach aims to address the\nchallenge of interpreting and executing spontaneous user instructions such as\n\"overtake the car ahead,\" which have typically posed difficulties for existing\nframeworks. We introduce the LaMPilot benchmark specifically designed to\nquantitatively evaluate the efficacy of Large Language Models (LLMs) in\ntranslating human directives into actionable driving policies. We then evaluate\na wide range of state-of-the-art code generation language models on tasks from\nthe LaMPilot Benchmark. The results of the experiments showed that GPT-4, with\nhuman feedback, achieved an impressive task completion rate of 92.7% and a\nminimal collision rate of 0.9%. To encourage further investigation in this\narea, our code and dataset will be made available.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1\">Yunsheng Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1\">Can Cui</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1\">Xu Cao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ye_W/0/1/0/all/0/1\">Wenqian Ye</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Peiran Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1\">Juanwu Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Abdelraouf_A/0/1/0/all/0/1\">Amr Abdelraouf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1\">Rohit Gupta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1\">Kyungtae Han</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bera_A/0/1/0/all/0/1\">Aniket Bera</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1\">James M. Rehg</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Ziran Wang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization. (arXiv:2312.04440v1 [cs.CL])","link":"http://arxiv.org/abs/2312.04440","description":"<p>The performance of automatic summarization models has improved dramatically\nin recent years. Yet, there is still a gap in meeting specific information\nneeds of users in real-world scenarios, particularly when a targeted summary is\nsought, such as in the useful aspect-based summarization setting targeted in\nthis paper. Previous datasets and studies for this setting have predominantly\nconcentrated on a limited set of pre-defined aspects, focused solely on single\ndocument inputs, or relied on synthetic data. To advance research on more\nrealistic scenarios, we introduce OpenAsp, a benchmark for multi-document\n\\textit{open} aspect-based summarization. This benchmark is created using a\nnovel and cost-effective annotation protocol, by which an open aspect dataset\nis derived from existing generic multi-document summarization datasets. We\nanalyze the properties of OpenAsp showcasing its high-quality content. Further,\nwe show that the realistic open-aspect setting realized in OpenAsp poses a\nchallenge for current state-of-the-art summarization models, as well as for\nlarge language models.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Amar_S/0/1/0/all/0/1\">Shmuel Amar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schiff_L/0/1/0/all/0/1\">Liat Schiff</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ernst_O/0/1/0/all/0/1\">Ori Ernst</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shefer_A/0/1/0/all/0/1\">Asi Shefer</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shapira_O/0/1/0/all/0/1\">Ori Shapira</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1\">Ido Dagan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Deep Learning for Hate Speech Detection: A Comparative Study. (arXiv:2202.09517v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2202.09517","description":"<p>Automated hate speech detection is an important tool in combating the spread\nof hate speech, particularly in social media. Numerous methods have been\ndeveloped for the task, including a recent proliferation of deep-learning based\napproaches. A variety of datasets have also been developed, exemplifying\nvarious manifestations of the hate-speech detection problem. We present here a\nlarge-scale empirical comparison of deep and shallow hate-speech detection\nmethods, mediated through the three most commonly used datasets. Our goal is to\nilluminate progress in the area, and identify strengths and weaknesses in the\ncurrent state-of-the-art. We particularly focus our analysis on measures of\npractical performance, including detection accuracy, computational efficiency,\ncapability in using pre-trained models, and domain generalization. In doing so\nwe aim to provide guidance as to the use of hate-speech detection in practice,\nquantify the state-of-the-art, and identify future research directions. Code\nand dataset are available at\nhttps://github.com/jmjmalik22/Hate-Speech-Detection.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1\">Jitendra Singh Malik</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1\">Hezhe Qiao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1\">Guansong Pang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hengel_A/0/1/0/all/0/1\">Anton van den Hengel</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Constrained Few-Shot Learning: Human-Like Low Sample Complexity Learning and Non-Episodic Text Classification. (arXiv:2208.08089v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2208.08089","description":"<p>Few-shot learning (FSL) is an emergent paradigm of learning that attempts to\nlearn to reason with low sample complexity to mimic the way humans learn,\ngeneralise and extrapolate from only a few seen examples. While FSL attempts to\nmimic these human characteristics, fundamentally, the task of FSL as\nconventionally formulated using meta-learning with episodic-based training does\nnot in actuality align with how humans acquire and reason with knowledge. FSL\nwith episodic training, while only requires $K$ instances of each test class,\nstill requires a large number of labelled training instances from disjoint\nclasses. In this paper, we introduce the novel task of constrained few-shot\nlearning (CFSL), a special case of FSL where $M$, the number of instances of\neach training class is constrained such that $M \\leq K$ thus applying a similar\nrestriction during FSL training and test. We propose a method for CFSL\nleveraging Cat2Vec using a novel categorical contrastive loss inspired by\ncognitive theories such as fuzzy trace theory and prototype theory.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Mar_J/0/1/0/all/0/1\">Jaron Mar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1\">Jiamou Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"MAUVE Scores for Generative Models: Theory and Practice. (arXiv:2212.14578v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2212.14578","description":"<p>Generative artificial intelligence has made significant strides, producing\ntext indistinguishable from human prose and remarkably photorealistic images.\nAutomatically measuring how close the generated data distribution is to the\ntarget distribution is central to diagnosing existing models and developing\nbetter ones. We present MAUVE, a family of comparison measures between pairs of\ndistributions such as those encountered in the generative modeling of text or\nimages. These scores are statistical summaries of divergence frontiers\ncapturing two types of errors in generative modeling. We explore three\napproaches to statistically estimate these scores: vector quantization,\nnon-parametric estimation, and classifier-based estimation. We provide\nstatistical bounds for the vector quantization approach.\n</p>\n<p>Empirically, we find that the proposed scores paired with a range of\n$f$-divergences and statistical estimation methods can quantify the gaps\nbetween the distributions of human-written text and those of modern neural\nlanguage models by correlating with human judgments and identifying known\nproperties of the generated texts. We demonstrate in the vision domain that\nMAUVE can identify known properties of generated images on par with or better\nthan existing metrics. In conclusion, we present practical recommendations for\nusing MAUVE effectively with language and image modalities.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1\">Krishna Pillutla</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1\">Lang Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Thickstun_J/0/1/0/all/0/1\">John Thickstun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Welleck_S/0/1/0/all/0/1\">Sean Welleck</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1\">Swabha Swayamdipta</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1\">Rowan Zellers</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1\">Sewoong Oh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1\">Yejin Choi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Harchaoui_Z/0/1/0/all/0/1\">Zaid Harchaoui</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"A Stability Analysis of Fine-Tuning a Pre-Trained Model. (arXiv:2301.09820v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2301.09820","description":"<p>Fine-tuning a pre-trained model (such as BERT, ALBERT, RoBERTa, T5, GPT,\netc.) has proven to be one of the most promising paradigms in recent NLP\nresearch. However, numerous recent works indicate that fine-tuning suffers from\nthe instability problem, i.e., tuning the same model under the same setting\nresults in significantly different performance. Many recent works have proposed\ndifferent methods to solve this problem, but there is no theoretical\nunderstanding of why and how these methods work. In this paper, we propose a\nnovel theoretical stability analysis of fine-tuning that focuses on two\ncommonly used settings, namely, full fine-tuning and head tuning. We define the\nstability under each setting and prove the corresponding stability bounds. The\ntheoretical bounds explain why and how several existing methods can stabilize\nthe fine-tuning procedure. In addition to being able to explain most of the\nobserved empirical discoveries, our proposed theoretical analysis framework can\nalso help in the design of effective and provable methods. Based on our theory,\nwe propose three novel strategies to stabilize the fine-tuning procedure,\nnamely, Maximal Margin Regularizer (MMR), Multi-Head Loss (MHLoss), and Self\nUnsupervised Re-Training (SURT). We extensively evaluate our proposed\napproaches on 11 widely used real-world benchmark datasets, as well as hundreds\nof synthetic classification datasets. The experiment results show that our\nproposed methods significantly stabilize the fine-tuning procedure and also\ncorroborate our theoretical analysis.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1\">Zihao Fu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+So_A/0/1/0/all/0/1\">Anthony Man-Cho So</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Collier_N/0/1/0/all/0/1\">Nigel Collier</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"ZeroNLG: Aligning and Autoencoding Domains for Zero-Shot Multimodal and Multilingual Natural Language Generation. (arXiv:2303.06458v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2303.06458","description":"<p>Natural Language Generation (NLG) accepts input data in the form of images,\nvideos, or text and generates corresponding natural language text as output.\nExisting NLG methods mainly adopt a supervised approach and rely heavily on\ncoupled data-to-text pairs. However, for many targeted scenarios and for\nnon-English languages, sufficient quantities of labeled data are often not\navailable. To relax the dependency on labeled data of downstream tasks, we\npropose an intuitive and effective zero-shot learning framework, ZeroNLG, which\ncan deal with multiple NLG tasks, including image-to-text (image captioning),\nvideo-to-text (video captioning), and text-to-text (neural machine\ntranslation), across English, Chinese, German, and French within a unified\nframework. ZeroNLG does not require any labeled downstream pairs for training.\nDuring training, ZeroNLG (i) projects different domains (across modalities and\nlanguages) to corresponding coordinates in a shared common latent space; (ii)\nbridges different domains by aligning their corresponding coordinates in this\nspace; and (iii) builds an unsupervised multilingual auto-encoder to learn to\ngenerate text by reconstructing the input text given its coordinate in shared\nlatent space. Consequently, during inference, based on the data-to-text\npipeline, ZeroNLG can generate target sentences across different languages\ngiven the coordinate of input data in the common space. Within this unified\nframework, given visual (imaging or video) data as input, ZeroNLG can perform\nzero-shot visual captioning; given textual sentences as input, ZeroNLG can\nperform zero-shot machine translation. We present the results of extensive\nexperiments on twelve NLG tasks, showing that, without using any labeled\ndownstream pairs for training, ZeroNLG generates high-quality and believable\noutputs and significantly outperforms existing zero-shot methods.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1\">Bang Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1\">Fenglin Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1\">Yuexian Zou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1\">Xian Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1\">Yaowei Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1\">David A. Clifton</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Can Large Language Models Transform Computational Social Science?. (arXiv:2305.03514v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.03514","description":"<p>Large Language Models (LLMs) are capable of successfully performing many\nlanguage processing tasks zero-shot (without training data). If zero-shot LLMs\ncan also reliably classify and explain social phenomena like persuasiveness and\npolitical ideology, then LLMs could augment the Computational Social Science\n(CSS) pipeline in important ways. This work provides a road map for using LLMs\nas CSS tools. Towards this end, we contribute a set of prompting best practices\nand an extensive evaluation pipeline to measure the zero-shot performance of 13\nlanguage models on 25 representative English CSS benchmarks. On taxonomic\nlabeling tasks (classification), LLMs fail to outperform the best fine-tuned\nmodels but still achieve fair levels of agreement with humans. On free-form\ncoding tasks (generation), LLMs produce explanations that often exceed the\nquality of crowdworkers' gold references. We conclude that the performance of\ntoday's LLMs can augment the CSS research pipeline in two ways: (1) serving as\nzero-shot data annotators on human annotation teams, and (2) bootstrapping\nchallenging creative generation tasks (e.g., explaining the underlying\nattributes of a text). In summary, LLMs are posed to meaningfully participate\nin} social science analysis in partnership with humans.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ziems_C/0/1/0/all/0/1\">Caleb Ziems</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Held_W/0/1/0/all/0/1\">William Held</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shaikh_O/0/1/0/all/0/1\">Omar Shaikh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1\">Jiaao Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zhehao Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1\">Diyi Yang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Conversational Semantic Parsing using Dynamic Context Graphs. (arXiv:2305.06164v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.06164","description":"<p>In this paper we consider the task of conversational semantic parsing over\ngeneral purpose knowledge graphs (KGs) with millions of entities, and thousands\nof relation-types. We focus on models which are capable of interactively\nmapping user utterances into executable logical forms (e.g., Sparql) in the\ncontext of the conversational history. Our key idea is to represent information\nabout an utterance and its context via a subgraph which is created dynamically,\ni.e., the number of nodes varies per utterance. Rather than treating the\nsubgraph as a sequence, we exploit its underlying structure and encode it with\na graph neural network which further allows us to represent a large number of\n(unseen) nodes. Experimental results show that dynamic context modeling is\nsuperior to static approaches, delivering performance improvements across the\nboard (i.e., for simple and complex questions). Our results further confirm\nthat modeling the structure of context is better at processing discourse\ninformation, (i.e., at handling ellipsis and resolving coreference) and longer\ninteractions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1\">Parag Jain</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1\">Mirella Lapata</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Interactive Text-to-SQL Generation via Editable Step-by-Step Explanations. (arXiv:2305.07372v3 [cs.DB] UPDATED)","link":"http://arxiv.org/abs/2305.07372","description":"<p>Relational databases play an important role in this Big Data era. However, it\nis challenging for non-experts to fully unleash the analytical power of\nrelational databases, since they are not familiar with database languages such\nas SQL. Many techniques have been proposed to automatically generate SQL from\nnatural language, but they suffer from two issues: (1) they still make many\nmistakes, particularly for complex queries, and (2) they do not provide a\nflexible way for non-expert users to validate and refine the incorrect queries.\nTo address these issues, we introduce a new interaction mechanism that allows\nusers directly edit a step-by-step explanation of an incorrect SQL to fix SQL\nerrors. Experiments on the Spider benchmark show that our approach outperforms\nthree SOTA approaches by at least 31.6% in terms of execution accuracy. A user\nstudy with 24 participants further shows that our approach helped users solve\nsignificantly more SQL tasks with less time and higher confidence,\ndemonstrating its potential to expand access to databases, particularly for\nnon-experts.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1\">Yuan Tian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1\">Zheng Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ning_Z/0/1/0/all/0/1\">Zheng Ning</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1\">Toby Jia-Jun Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kummerfeld_J/0/1/0/all/0/1\">Jonathan K. Kummerfeld</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1\">Tianyi Zhang</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Post Hoc Explanations of Language Models Can Improve Language Models. (arXiv:2305.11426v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2305.11426","description":"<p>Large Language Models (LLMs) have demonstrated remarkable capabilities in\nperforming complex tasks. Moreover, recent research has shown that\nincorporating human-annotated rationales (e.g., Chain-of-Thought prompting)\nduring in-context learning can significantly enhance the performance of these\nmodels, particularly on tasks that require reasoning capabilities. However,\nincorporating such rationales poses challenges in terms of scalability as this\nrequires a high degree of human involvement. In this work, we present a novel\nframework, Amplifying Model Performance by Leveraging In-Context Learning with\nPost Hoc Explanations (AMPLIFY), which addresses the aforementioned challenges\nby automating the process of rationale generation. To this end, we leverage\npost hoc explanation methods which output attribution scores (explanations)\ncapturing the influence of each of the input features on model predictions.\nMore specifically, we construct automated natural language rationales that\nembed insights from post hoc explanations to provide corrective signals to\nLLMs. Extensive experimentation with real-world datasets demonstrates that our\nframework, AMPLIFY, leads to prediction accuracy improvements of about 10-25%\nover a wide range of tasks, including those where prior approaches which rely\non human-annotated rationales such as Chain-of-Thought prompting fall short.\nOur work makes one of the first attempts at highlighting the potential of post\nhoc explanations as valuable tools for enhancing the effectiveness of LLMs.\nFurthermore, we conduct additional empirical analyses and ablation studies to\ndemonstrate the impact of each of the components of AMPLIFY, which, in turn,\nleads to critical insights for refining in-context learning.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1\">Satyapriya Krishna</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1\">Jiaqi Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1\">Dylan Slack</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ghandeharioun_A/0/1/0/all/0/1\">Asma Ghandeharioun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1\">Sameer Singh</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1\">Himabindu Lakkaraju</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces. (arXiv:2306.00245v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2306.00245","description":"<p>Much of the previous work towards digital agents for graphical user\ninterfaces (GUIs) has relied on text-based representations (derived from HTML\nor other structured data sources), which are not always readily available.\nThese input representations have been often coupled with custom, task-specific\naction spaces. This paper focuses on creating agents that interact with the\ndigital world using the same conceptual interface that humans commonly use --\nvia pixel-based screenshots and a generic action space corresponding to\nkeyboard and mouse actions. Building upon recent progress in pixel-based\npretraining, we show, for the first time, that it is possible for such agents\nto outperform human crowdworkers on the MiniWob++ benchmark of GUI-based\ninstruction following tasks.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shaw_P/0/1/0/all/0/1\">Peter Shaw</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1\">Mandar Joshi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cohan_J/0/1/0/all/0/1\">James Cohan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1\">Jonathan Berant</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1\">Panupong Pasupat</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1\">Hexiang Hu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Khandelwal_U/0/1/0/all/0/1\">Urvashi Khandelwal</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1\">Kenton Lee</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Toutanova_K/0/1/0/all/0/1\">Kristina Toutanova</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models. (arXiv:2308.09778v2 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2308.09778","description":"<p>With pre-training of vision-and-language models (VLMs) on large-scale\ndatasets of image-text pairs, several recent works showed that these\npre-trained models lack fine-grained understanding, such as the ability to\ncount and recognize verbs, attributes, or relationships. The focus of this work\nis to study the ability of these models to understand spatial relations.\nPreviously, this has been tackled using image-text matching (e.g., Visual\nSpatial Reasoning benchmark) or visual question answering (e.g., GQA or VQAv2),\nboth showing poor performance and a large gap compared to human performance. In\nthis work, we use explainability tools to understand the causes of poor\nperformance better and present an alternative fine-grained, compositional\napproach for ranking spatial clauses. We combine the evidence from grounding\nnoun phrases corresponding to objects and their locations to compute the final\nrank of the spatial clause. We demonstrate the approach on representative VLMs\n(such as LXMERT, GPV, and MDETR) and compare and highlight their abilities to\nreason about spatial relationships.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Rajabi_N/0/1/0/all/0/1\">Navid Rajabi</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kosecka_J/0/1/0/all/0/1\">Jana Kosecka</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Attention-Driven Multi-Modal Fusion: Enhancing Sign Language Recognition and Translation. (arXiv:2309.01860v3 [cs.CV] UPDATED)","link":"http://arxiv.org/abs/2309.01860","description":"<p>In this paper, we devise a mechanism for the addition of multi-modal\ninformation with an existing pipeline for continuous sign language recognition\nand translation. In our procedure, we have incorporated optical flow\ninformation with RGB images to enrich the features with movement-related\ninformation. This work studies the feasibility of such modality inclusion using\na cross-modal encoder. The plugin we have used is very lightweight and doesn't\nneed to include a separate feature extractor for the new modality in an\nend-to-end manner. We have applied the changes in both sign language\nrecognition and translation, improving the result in each case. We have\nevaluated the performance on the RWTH-PHOENIX-2014 dataset for sign language\nrecognition and the RWTH-PHOENIX-2014T dataset for translation. On the\nrecognition task, our approach reduced the WER by 0.9, and on the translation\ntask, our approach increased most of the BLEU scores by ~0.6 on the test set.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Hakim_Z/0/1/0/all/0/1\">Zaber Ibn Abdul Hakim</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Swargo_R/0/1/0/all/0/1\">Rasman Mubtasim Swargo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Adnan_M/0/1/0/all/0/1\">Muhammad Abdullah Adnan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Large Language Models as Optimizers. (arXiv:2309.03409v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2309.03409","description":"<p>Optimization is ubiquitous. While derivative-based algorithms have been\npowerful tools for various problems, the absence of gradient imposes challenges\non many real-world applications. In this work, we propose Optimization by\nPROmpting (OPRO), a simple and effective approach to leverage large language\nmodels (LLMs) as optimizers, where the optimization task is described in\nnatural language. In each optimization step, the LLM generates new solutions\nfrom the prompt that contains previously generated solutions with their values,\nthen the new solutions are evaluated and added to the prompt for the next\noptimization step. We first showcase OPRO on linear regression and traveling\nsalesman problems, then move on to prompt optimization where the goal is to\nfind instructions that maximize the task accuracy. With a variety of LLMs, we\ndemonstrate that the best prompts optimized by OPRO outperform human-designed\nprompts by up to 8% on GSM8K, and by up to 50% on Big-Bench Hard tasks. Code at\nhttps://github.com/google-deepmind/opro.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1\">Chengrun Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xuezhi Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1\">Yifeng Lu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1\">Hanxiao Liu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1\">Quoc V. Le</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1\">Denny Zhou</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1\">Xinyun Chen</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs. (arXiv:2309.07311v4 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2309.07311","description":"<p>Most interpretability research in NLP focuses on understanding the behavior\nand features of a fully trained model. However, certain insights into model\nbehavior may only be accessible by observing the trajectory of the training\nprocess. We present a case study of syntax acquisition in masked language\nmodels (MLMs) that demonstrates how analyzing the evolution of interpretable\nartifacts throughout training deepens our understanding of emergent behavior.\nIn particular, we study Syntactic Attention Structure (SAS), a naturally\nemerging property of MLMs wherein specific Transformer heads tend to focus on\nspecific syntactic relations. We identify a brief window in pretraining when\nmodels abruptly acquire SAS, concurrent with a steep drop in loss. This\nbreakthrough precipitates the subsequent acquisition of linguistic\ncapabilities. We then examine the causal role of SAS by manipulating SAS during\ntraining, and demonstrate that SAS is necessary for the development of\ngrammatical capabilities. We further find that SAS competes with other\nbeneficial traits during training, and that briefly suppressing SAS improves\nmodel quality. These findings offer an interpretation of a real-world example\nof both simplicity bias and breakthrough training dynamics.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1\">Angelica Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Shwartz_Ziv_R/0/1/0/all/0/1\">Ravid Shwartz-Ziv</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1\">Kyunghyun Cho</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Leavitt_M/0/1/0/all/0/1\">Matthew L. Leavitt</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Saphra_N/0/1/0/all/0/1\">Naomi Saphra</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"UPAR: A Kantian-Inspired Prompting Framework for Enhancing Large Language Model Capabilities. (arXiv:2310.01441v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.01441","description":"<p>Large Language Models (LLMs) have demonstrated impressive inferential\ncapabilities, with numerous research endeavors devoted to enhancing this\ncapacity through prompting. Despite these efforts, a unified epistemological\nfoundation is still conspicuously absent. Drawing inspiration from Kant's a\npriori philosophy, we propose the UPAR prompting framework, designed to emulate\nthe structure of human cognition within LLMs. The UPAR framework is delineated\ninto four phases: \"Understand\", \"Plan\", \"Act\", and \"Reflect\", enabling the\nextraction of structured information from complex contexts, prior planning of\nsolutions, execution according to plan, and self-reflection. This structure\nsignificantly augments the explainability and accuracy of LLM inference,\nproducing a human-understandable and inspectable inferential trajectory.\nFurthermore, our work offers an epistemological foundation for existing\nprompting techniques, allowing for a possible systematic integration of these\nmethods. With GPT-4, our approach elevates the accuracy from COT baseline of\n22.92% to 58.33% in a challenging subset of GSM8K, and from 67.91% to 75.40% in\nthe causal judgment task. Without using few-shot examples or external tools,\nUPAR significantly outperforms existing prompting methods on SCIBENCH, a\nchallenging dataset containing collegiate-level mathematics, chemistry, and\nphysics scientific problems.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Geng_H/0/1/0/all/0/1\">Hejia Geng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1\">Boxun Xu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1\">Peng Li</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Harnessing the Power of Large Language Models for Empathetic Response Generation: Empirical Investigations and Improvements. (arXiv:2310.05140v3 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05140","description":"<p>Empathetic dialogue is an indispensable part of building harmonious social\nrelationships and contributes to the development of a helpful AI. Previous\napproaches are mainly based on fine small-scale language models. With the\nadvent of ChatGPT, the application effect of large language models (LLMs) in\nthis field has attracted great attention. This work empirically investigates\nthe performance of LLMs in generating empathetic responses and proposes three\nimprovement methods of semantically similar in-context learning, two-stage\ninteractive generation, and combination with the knowledge base. Extensive\nexperiments show that LLMs can significantly benefit from our proposed methods\nand is able to achieve state-of-the-art performance in both automatic and human\nevaluations. Additionally, we explore the possibility of GPT-4 simulating human\nevaluators.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1\">Yushan Qian</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1\">Wei-Nan Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1\">Ting Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Generative Judge for Evaluating Alignment. (arXiv:2310.05470v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.05470","description":"<p>The rapid development of Large Language Models (LLMs) has substantially\nexpanded the range of tasks they can address. In the field of Natural Language\nProcessing (NLP), researchers have shifted their focus from conventional NLP\ntasks (e.g., sequence tagging and parsing) towards tasks that revolve around\naligning with human needs (e.g., brainstorming and email writing). This shift\nin task distribution imposes new requirements on evaluating these aligned\nmodels regarding generality (i.e., assessing performance across diverse\nscenarios), flexibility (i.e., examining under different protocols), and\ninterpretability (i.e., scrutinizing models with explanations). In this paper,\nwe propose a generative judge with 13B parameters, Auto-J, designed to address\nthese challenges. Our model is trained on user queries and LLM-generated\nresponses under massive real-world scenarios and accommodates diverse\nevaluation protocols (e.g., pairwise response comparison and single-response\nevaluation) with well-structured natural language critiques. To demonstrate the\nefficacy of our approach, we construct a new testbed covering 58 different\nscenarios. Experimentally, Auto-J outperforms a series of strong competitors,\nincluding both open-source and closed-source models, by a large margin. We also\nprovide detailed analysis and case studies to further reveal the potential of\nour method and make a variety of resources public at\nhttps://github.com/GAIR-NLP/auto-j.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1\">Junlong Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1\">Shichao Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1\">Weizhe Yuan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fan_R/0/1/0/all/0/1\">Run-Ze Fan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1\">Hai Zhao</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1\">Pengfei Liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Unveiling the General Intelligence Factor in Language Models: A Psychometric Approach. (arXiv:2310.11616v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.11616","description":"<p>This study uncovers the factor of general intelligence, or g, in language\nmodels, extending the psychometric theory traditionally applied to humans and\ncertain animal species. Utilizing factor analysis on two extensive datasets -\nOpen LLM Leaderboard with 1,232 models and General Language Understanding\nEvaluation (GLUE) Leaderboard with 88 models - we find compelling evidence for\na unidimensional, highly stable g factor that accounts for 85% of the variance\nin model performance. The study also finds a moderate correlation of .49\nbetween model size and g. The discovery of g in language models offers a\nunified metric for model evaluation and opens new avenues for more robust,\ng-based model ability assessment. These findings lay the foundation for\nunderstanding and future research on artificial general intelligence from a\npsychometric perspective and have practical implications for model evaluation\nand development.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Ilic_D/0/1/0/all/0/1\">David Ili&#x107;</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization. (arXiv:2310.16427v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2310.16427","description":"<p>Highly effective, task-specific prompts are often heavily engineered by\nexperts to integrate detailed instructions and domain insights based on a deep\nunderstanding of both instincts of large language models (LLMs) and the\nintricacies of the target task. However, automating the generation of such\nexpert-level prompts remains elusive. Existing prompt optimization methods tend\nto overlook the depth of domain knowledge and struggle to efficiently explore\nthe vast space of expert-level prompts. Addressing this, we present\nPromptAgent, an optimization method that autonomously crafts prompts equivalent\nin quality to those handcrafted by experts. At its core, PromptAgent views\nprompt optimization as a strategic planning problem and employs a principled\nplanning algorithm, rooted in Monte Carlo tree search, to strategically\nnavigate the expert-level prompt space. Inspired by human-like trial-and-error\nexploration, PromptAgent induces precise expert-level insights and in-depth\ninstructions by reflecting on model errors and generating constructive error\nfeedback. Such a novel framework allows the agent to iteratively examine\nintermediate prompts (states), refine them based on error feedbacks (actions),\nsimulate future rewards, and search for high-reward paths leading to expert\nprompts. We apply PromptAgent to 12 tasks spanning three practical domains:\nBIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing\nit significantly outperforms strong Chain-of-Thought and recent prompt\noptimization baselines. Extensive analyses emphasize its capability to craft\nexpert-level, detailed, and domain-insightful prompts with great efficiency and\ngeneralizability.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1\">Xinyuan Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1\">Chenxi Li</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1\">Zhen Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Bai_F/0/1/0/all/0/1\">Fan Bai</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1\">Haotian Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1\">Jiayou Zhang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Jojic_N/0/1/0/all/0/1\">Nebojsa Jojic</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1\">Eric P. Xing</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1\">Zhiting Hu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Efficient LLM Inference on CPUs. (arXiv:2311.00502v2 [cs.LG] UPDATED)","link":"http://arxiv.org/abs/2311.00502","description":"<p>Large language models (LLMs) have demonstrated remarkable performance and\ntremendous potential across a wide range of tasks. However, deploying these\nmodels has been challenging due to the astronomical amount of model parameters,\nwhich requires a demand for large memory capacity and high memory bandwidth. In\nthis paper, we propose an effective approach that can make the deployment of\nLLMs more efficiently. We support an automatic INT4 weight-only quantization\nflow and design a special LLM runtime with highly-optimized kernels to\naccelerate the LLM inference on CPUs. We demonstrate the general applicability\nof our approach on popular LLMs including Llama2, Llama, GPT-NeoX, and showcase\nthe extreme inference efficiency on CPUs. The code is publicly available at:\nhttps://github.com/intel/intel-extension-for-transformers.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1\">Haihao Shen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1\">Hanwen Chang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1\">Bo Dong</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1\">Yu Luo</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1\">Hengyu Meng</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Trends in Integration of Knowledge and Large Language Models: A Survey and Taxonomy of Methods, Benchmarks, and Applications. (arXiv:2311.05876v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2311.05876","description":"<p>Large language models (LLMs) exhibit superior performance on various natural\nlanguage tasks, but they are susceptible to issues stemming from outdated data\nand domain-specific limitations. In order to address these challenges,\nresearchers have pursued two primary strategies, knowledge editing and\nretrieval augmentation, to enhance LLMs by incorporating external information\nfrom different aspects. Nevertheless, there is still a notable absence of a\ncomprehensive survey. In this paper, we propose a review to discuss the trends\nin integration of knowledge and large language models, including taxonomy of\nmethods, benchmarks, and applications. In addition, we conduct an in-depth\nanalysis of different methods and point out potential research directions in\nthe future. We hope this survey offers the community quick access and a\ncomprehensive overview of this research area, with the intention of inspiring\nfuture research endeavors.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1\">Zhangyin Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1\">Weitao Ma</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1\">Weijiang Yu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1\">Lei Huang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1\">Haotian Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1\">Qianglong Chen</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1\">Weihua Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1\">Xiaocheng Feng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1\">Bing Qin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+liu_T/0/1/0/all/0/1\">Ting liu</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"LLMs for Science: Usage for Code Generation and Data Analysis. (arXiv:2311.16733v3 [cs.SE] UPDATED)","link":"http://arxiv.org/abs/2311.16733","description":"<p>Large language models (LLMs) have been touted to enable increased\nproductivity in many areas of today's work life. Scientific research as an area\nof work is no exception: the potential of LLM-based tools to assist in the\ndaily work of scientists has become a highly discussed topic across\ndisciplines. However, we are only at the very onset of this subject of study.\nIt is still unclear how the potential of LLMs will materialise in research\npractice. With this study, we give first empirical evidence on the use of LLMs\nin the research process. We have investigated a set of use cases for LLM-based\ntools in scientific research, and conducted a first study to assess to which\ndegree current tools are helpful. In this paper we report specifically on use\ncases related to software engineering, such as generating application code and\ndeveloping scripts for data analytics. While we studied seemingly simple use\ncases, results across tools differ significantly. Our results highlight the\npromise of LLM-based tools in general, yet we also observe various issues,\nparticularly regarding the integrity of the output these tools provide.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Nejjar_M/0/1/0/all/0/1\">Mohamed Nejjar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Zacharias_L/0/1/0/all/0/1\">Luca Zacharias</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Stiehle_F/0/1/0/all/0/1\">Fabian Stiehle</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Weber_I/0/1/0/all/0/1\">Ingo Weber</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Navigating News Narratives: A Media Bias Analysis Dataset. (arXiv:2312.00168v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.00168","description":"<p>The proliferation of biased news narratives across various media platforms\nhas become a prominent challenge, influencing public opinion on critical topics\nlike politics, health, and climate change. This paper introduces the\n\"Navigating News Narratives: A Media Bias Analysis Dataset\", a comprehensive\ndataset to address the urgent need for tools to detect and analyze media bias.\nThis dataset encompasses a broad spectrum of biases, making it a unique and\nvaluable asset in the field of media studies and artificial intelligence. The\ndataset is available at\nhttps://huggingface.co/datasets/newsmediabias/news-bias-full-data.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1\">Shaina Raza</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Mark My Words: Analyzing and Evaluating Language Model Watermarks. (arXiv:2312.00273v2 [cs.CR] UPDATED)","link":"http://arxiv.org/abs/2312.00273","description":"<p>The capabilities of large language models have grown significantly in recent\nyears and so too have concerns about their misuse. In this context, the ability\nto distinguish machine-generated text from human-authored content becomes\nimportant. Prior works have proposed numerous schemes to watermark text, which\nwould benefit from a systematic evaluation framework. This work focuses on text\nwatermarking techniques - as opposed to image watermarks - and proposes\nMARKMYWORDS, a comprehensive benchmark for them under different tasks as well\nas practical attacks. We focus on three main metrics: quality, size (e.g. the\nnumber of tokens needed to detect a watermark), and tamper-resistance. Current\nwatermarking techniques are good enough to be deployed: Kirchenbauer et al. [1]\ncan watermark Llama2-7B-chat with no perceivable loss in quality, the watermark\ncan be detected with fewer than 100 tokens, and the scheme offers good\ntamper-resistance to simple attacks. We argue that watermark\nindistinguishability, a criteria emphasized in some prior works, is too strong\na requirement: schemes that slightly modify logit distributions outperform\ntheir indistinguishable counterparts with no noticeable loss in generation\nquality. We publicly release our benchmark\n(https://github.com/wagner-group/MarkMyWords)\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Piet_J/0/1/0/all/0/1\">Julien Piet</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sitawarin_C/0/1/0/all/0/1\">Chawin Sitawarin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Fang_V/0/1/0/all/0/1\">Vivian Fang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Mu_N/0/1/0/all/0/1\">Norman Mu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1\">David Wagner</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words. (arXiv:2312.02931v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.02931","description":"<p>Training on multiple modalities of input can augment the capabilities of a\nlanguage model. Here, we ask whether such a training regime can improve the\nquality and efficiency of these systems as well. We focus on text--audio and\nintroduce Whisbert, which is inspired by the text--image approach of FLAVA\n(Singh et al., 2022). In accordance with Babylm guidelines (Warstadt et al.,\n2023), we pretrain Whisbert on a dataset comprising only 100 million words plus\ntheir corresponding speech from the word-aligned version of the People's Speech\ndataset (Galvez et al., 2021). To assess the impact of multimodality, we\ncompare versions of the model that are trained on text only and on both audio\nand text simultaneously. We find that while Whisbert is able to perform well on\nmultimodal masked modeling and surpasses the Babylm baselines in most benchmark\ntasks, it struggles to optimize its complex objective and outperform its\ntext-only Whisbert baseline.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1\">Lukas Wolf</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tuckute_G/0/1/0/all/0/1\">Greta Tuckute</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Kotar_K/0/1/0/all/0/1\">Klemen Kotar</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Hosseini_E/0/1/0/all/0/1\">Eghbal Hosseini</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Regev_T/0/1/0/all/0/1\">Tamar Regev</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wilcox_E/0/1/0/all/0/1\">Ethan Wilcox</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1\">Alex Warstadt</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"Holmes: Towards Distributed Training Across Clusters with Heterogeneous NIC Environment. (arXiv:2312.03549v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03549","description":"<p>Large language models (LLMs) such as GPT-3, OPT, and LLaMA have demonstrated\nremarkable accuracy in a wide range of tasks. However, training these models\ncan incur significant expenses, often requiring tens of thousands of GPUs for\nmonths of continuous operation. Typically, this training is carried out in\nspecialized GPU clusters equipped with homogeneous high-speed Remote Direct\nMemory Access (RDMA) network interface cards (NICs). The acquisition and\nmaintenance of such dedicated clusters is challenging. Current LLM training\nframeworks, like Megatron-LM and Megatron-DeepSpeed, focus primarily on\noptimizing training within homogeneous cluster settings. In this paper, we\nintroduce Holmes, a training framework for LLMs that employs thoughtfully\ncrafted data and model parallelism strategies over the heterogeneous NIC\nenvironment. Our primary technical contribution lies in a novel scheduling\nmethod that intelligently allocates distinct computational tasklets in LLM\ntraining to specific groups of GPU devices based on the characteristics of\ntheir connected NICs. Furthermore, our proposed framework, utilizing pipeline\nparallel techniques, demonstrates scalability to multiple GPU clusters, even in\nscenarios without high-speed interconnects between nodes in distinct clusters.\nWe conducted comprehensive experiments that involved various scenarios in the\nheterogeneous NIC environment. In most cases, our framework achieves\nperformance levels close to those achievable with homogeneous RDMA-capable\nnetworks (InfiniBand or RoCE), significantly exceeding training efficiency\nwithin the pure Ethernet environment. Additionally, we verified that our\nframework outperforms other mainstream LLM frameworks under heterogeneous NIC\nenvironment in terms of training efficiency and can be seamlessly integrated\nwith them.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1\">Fei Yang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1\">Shuang Peng</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Sun_N/0/1/0/all/0/1\">Ning Sun</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1\">Fangyu Wang</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1\">Ke Tan</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1\">Fu Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1\">Jiezhong Qiu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Pan_A/0/1/0/all/0/1\">Aimin Pan</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}},{"title":"PROMISE: A Framework for Model-Driven Stateful Prompt Orchestration. (arXiv:2312.03699v2 [cs.CL] UPDATED)","link":"http://arxiv.org/abs/2312.03699","description":"<p>The advent of increasingly powerful language models has raised expectations\nfor language-based interactions. However, controlling these models is a\nchallenge, emphasizing the need to be able to investigate the feasibility and\nvalue of their application. We present PROMISE, a framework that facilitates\nthe development of complex language-based interactions with information\nsystems. Its use of state machine modeling concepts enables model-driven,\ndynamic prompt orchestration across hierarchically nested states and\ntransitions. This improves the control of the behavior of language models and\nthus enables their effective and efficient use. We show the benefits of PROMISE\nin the context of application scenarios within health information systems and\ndemonstrate its ability to handle complex interactions.\n</p>","author":null,"categories":[],"comments":null,"enclosure":null,"guid":null,"pub_date":null,"source":null,"content":null,"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":["<a href=\"http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1\">Wenyuan Wu</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Heierli_J/0/1/0/all/0/1\">Jasmin Heierli</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Meisterhans_M/0/1/0/all/0/1\">Max Meisterhans</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Moser_A/0/1/0/all/0/1\">Adrian Moser</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Farber_A/0/1/0/all/0/1\">Andri F&#xe4;rber</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Dolata_M/0/1/0/all/0/1\">Mateusz Dolata</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Gavagnin_E/0/1/0/all/0/1\">Elena Gavagnin</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Spindler_A/0/1/0/all/0/1\">Alexandre de Spindler</a>, <a href=\"http://arxiv.org/find/cs/1/au:+Schwabe_G/0/1/0/all/0/1\">Gerhard Schwabe</a>"],"dates":[],"descriptions":[],"formats":[],"identifiers":[],"languages":[],"publishers":[],"relations":[],"rights":[],"sources":[],"subjects":[],"titles":[],"types":[]}}],"extensions":{},"itunes_ext":null,"dublin_core_ext":{"contributors":[],"coverages":[],"creators":[],"dates":["2023-12-07T20:30:00-05:00"],"descriptions":[],"formats":[],"identifiers":[],"languages":["en-us"],"publishers":["help@arxiv.org"],"relations":[],"rights":[],"sources":[],"subjects":["Computer Science -- Computation and Language"],"titles":[],"types":[]},"syndication_ext":{"period":"DAILY","frequency":1,"base":"1901-01-01T00:00+00:00"},"namespaces":{"admin":"http://webns.net/mvcb/","syn":"http://purl.org/rss/1.0/modules/syndication/","content":"http://purl.org/rss/1.0/modules/content/","dc":"http://purl.org/dc/elements/1.1/","rdf":"http://www.w3.org/1999/02/22-rdf-syntax-ns#","taxo":"http://purl.org/rss/1.0/modules/taxonomy/"}}]}]}